{"textgrid.poem.48619": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "30. Auf einer abwesenden Jungfrauen Namenstag, den 4. September (1635)", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Seit da\u00df die liebliche ", "tokens": ["Seit", "da\u00df", "die", "lieb\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ART", "ADJA"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "nicht hier gewesen ist zur Stelle,", "tokens": ["nicht", "hier", "ge\u00b7we\u00b7sen", "ist", "zur", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAPP", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "seit hat man ganz von keiner Lust,", "tokens": ["seit", "hat", "man", "ganz", "von", "kei\u00b7ner", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "von keiner Zier, von keinem Lachen", "tokens": ["von", "kei\u00b7ner", "Zier", ",", "von", "kei\u00b7nem", "La\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und was uns sonst kan fr\u00f6lich machen", "tokens": ["und", "was", "uns", "sonst", "kan", "fr\u00f6\u00b7lich", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "VMFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "in dieser Gegend nichts gewu\u00dft.", "tokens": ["in", "die\u00b7ser", "Ge\u00b7gend", "nichts", "ge\u00b7wu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Er selbst, der Himmel, steht betr\u00fcbet,", "tokens": ["Er", "selbst", ",", "der", "Him\u00b7mel", ",", "steht", "be\u00b7tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ART", "NN", "$,", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "weil er nicht sieht, die er so liebet.", "tokens": ["weil", "er", "nicht", "sieht", ",", "die", "er", "so", "lie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Regnen weint die blasse Luft;", "tokens": ["Mit", "Reg\u00b7nen", "weint", "die", "blas\u00b7se", "Luft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die harten Seufzer, die sie f\u00fchret,", "tokens": ["die", "har\u00b7ten", "Seuf\u00b7zer", ",", "die", "sie", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die haben Land und See ger\u00fchret:", "tokens": ["die", "ha\u00b7ben", "Land", "und", "See", "ge\u00b7r\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "sie h\u00f6rt es nicht, die wird geruft.", "tokens": ["sie", "h\u00f6rt", "es", "nicht", ",", "die", "wird", "ge\u00b7ruft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die bleiche Sonne hat indessen", "tokens": ["Die", "blei\u00b7che", "Son\u00b7ne", "hat", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ganz ihres Glanzes hier vergessen:", "tokens": ["ganz", "ih\u00b7res", "Glan\u00b7zes", "hier", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sie, ihres Scheines Schein ist hin.", "tokens": ["sie", ",", "ih\u00b7res", "Schei\u00b7nes", "Schein", "ist", "hin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und da\u00df die N\u00e4chte dieser Erden", "tokens": ["Und", "da\u00df", "die", "N\u00e4ch\u00b7te", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "nun finsterer und l\u00e4nger werden,", "tokens": ["nun", "fins\u00b7te\u00b7rer", "und", "l\u00e4n\u00b7ger", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "das k\u00f6mmt von ihrem Abeziehn.", "tokens": ["das", "k\u00f6mmt", "von", "ih\u00b7rem", "A\u00b7be\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Den kranken Pol, die matten Nelken", "tokens": ["Den", "kran\u00b7ken", "Pol", ",", "die", "mat\u00b7ten", "Nel\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "sieht man, wenn sie noch stehn, verwelken.", "tokens": ["sieht", "man", ",", "wenn", "sie", "noch", "stehn", ",", "ver\u00b7wel\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die Winter-Rosen schrumpeln ein.", "tokens": ["Die", "Win\u00b7ter\u00b7Ro\u00b7sen", "schrum\u00b7peln", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Kraut ist frisch, kein Baum ist gr\u00fcne.", "tokens": ["Kein", "Kraut", "ist", "frisch", ",", "kein", "Baum", "ist", "gr\u00fc\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$,", "PIAT", "NN", "VAFIN", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Sonne, die vor ihnen schiene,", "tokens": ["Die", "Son\u00b7ne", ",", "die", "vor", "ih\u00b7nen", "schie\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "hat aufgeh\u00f6ret hier zu sein.", "tokens": ["hat", "auf\u00b7ge\u00b7h\u00f6\u00b7ret", "hier", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "ADV", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was anders k\u00f6nnen Hirt und Heerden", "tokens": ["Was", "an\u00b7ders", "k\u00f6n\u00b7nen", "Hirt", "und", "Heer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VMFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als leid' und traurig sich geberden?", "tokens": ["als", "leid'", "und", "trau\u00b7rig", "sich", "ge\u00b7ber\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "KON", "ADJD", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Lied erschallt, kein Tanz geschicht.", "tokens": ["Kein", "Lied", "er\u00b7schallt", ",", "kein", "Tanz", "ge\u00b7schicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Feld', im Pusch', im Tal', in Auen", "tokens": ["Im", "Feld'", ",", "im", "Pusch'", ",", "im", "Tal'", ",", "in", "Au\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ist nichts als stille Furcht zu schauen,", "tokens": ["ist", "nichts", "als", "stil\u00b7le", "Furcht", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "KOKOM", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "weil man die Freude selbst nicht sicht.", "tokens": ["weil", "man", "die", "Freu\u00b7de", "selbst", "nicht", "sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.6": {"line.1": {"text": "Zwar, so wir haben recht vernommen,", "tokens": ["Zwar", ",", "so", "wir", "ha\u00b7ben", "recht", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "so soll ihr sch\u00f6ner Tag sein kommen.", "tokens": ["so", "soll", "ihr", "sch\u00f6\u00b7ner", "Tag", "sein", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was aber kan di\u00df anders tun,", "tokens": ["Was", "a\u00b7ber", "kan", "di\u00df", "an\u00b7ders", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "PDS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als da\u00df es duppelt mehr uns kr\u00e4nket?", "tokens": ["als", "da\u00df", "es", "dup\u00b7pelt", "mehr", "uns", "kr\u00e4n\u00b7ket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PPER", "VVFIN", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die von uns werden soll beschenket,", "tokens": ["Die", "von", "uns", "wer\u00b7den", "soll", "be\u00b7schen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VAINF", "VMFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "die hier soll sein, wo ist sie nun?", "tokens": ["die", "hier", "soll", "sein", ",", "wo", "ist", "sie", "nun", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "VAINF", "$,", "PWAV", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ihr mehr als wir geehrten W\u00e4lder,", "tokens": ["Ihr", "mehr", "als", "wir", "ge\u00b7ehr\u00b7ten", "W\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KOUS", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ihr Wiesen, ihr bes\u00e4ten Felder,", "tokens": ["ihr", "Wie\u00b7sen", ",", "ihr", "be\u00b7s\u00e4\u00b7ten", "Fel\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "erkennt das Gl\u00fccke, diese Gunst!", "tokens": ["er\u00b7kennt", "das", "Gl\u00fc\u00b7cke", ",", "die\u00b7se", "Gunst", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Pflegt ihr, weil ihr sie k\u00f6nnet haben,", "tokens": ["Pflegt", "ihr", ",", "weil", "ihr", "sie", "k\u00f6n\u00b7net", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "KOUS", "PPER", "PPER", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und bindet die f\u00fcr uns mit Gaben,", "tokens": ["und", "bin\u00b7det", "die", "f\u00fcr", "uns", "mit", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "nach der wir w\u00fcndschen doch umsonst!", "tokens": ["nach", "der", "wir", "w\u00fcnd\u00b7schen", "doch", "um\u00b7sonst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Seit da\u00df die liebliche ", "tokens": ["Seit", "da\u00df", "die", "lieb\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ART", "ADJA"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "nicht hier gewesen ist zur Stelle,", "tokens": ["nicht", "hier", "ge\u00b7we\u00b7sen", "ist", "zur", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAPP", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "seit hat man ganz von keiner Lust,", "tokens": ["seit", "hat", "man", "ganz", "von", "kei\u00b7ner", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "von keiner Zier, von keinem Lachen", "tokens": ["von", "kei\u00b7ner", "Zier", ",", "von", "kei\u00b7nem", "La\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und was uns sonst kan fr\u00f6lich machen", "tokens": ["und", "was", "uns", "sonst", "kan", "fr\u00f6\u00b7lich", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "VMFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "in dieser Gegend nichts gewu\u00dft.", "tokens": ["in", "die\u00b7ser", "Ge\u00b7gend", "nichts", "ge\u00b7wu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Er selbst, der Himmel, steht betr\u00fcbet,", "tokens": ["Er", "selbst", ",", "der", "Him\u00b7mel", ",", "steht", "be\u00b7tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ART", "NN", "$,", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "weil er nicht sieht, die er so liebet.", "tokens": ["weil", "er", "nicht", "sieht", ",", "die", "er", "so", "lie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Regnen weint die blasse Luft;", "tokens": ["Mit", "Reg\u00b7nen", "weint", "die", "blas\u00b7se", "Luft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die harten Seufzer, die sie f\u00fchret,", "tokens": ["die", "har\u00b7ten", "Seuf\u00b7zer", ",", "die", "sie", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die haben Land und See ger\u00fchret:", "tokens": ["die", "ha\u00b7ben", "Land", "und", "See", "ge\u00b7r\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "sie h\u00f6rt es nicht, die wird geruft.", "tokens": ["sie", "h\u00f6rt", "es", "nicht", ",", "die", "wird", "ge\u00b7ruft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die bleiche Sonne hat indessen", "tokens": ["Die", "blei\u00b7che", "Son\u00b7ne", "hat", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ganz ihres Glanzes hier vergessen:", "tokens": ["ganz", "ih\u00b7res", "Glan\u00b7zes", "hier", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sie, ihres Scheines Schein ist hin.", "tokens": ["sie", ",", "ih\u00b7res", "Schei\u00b7nes", "Schein", "ist", "hin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und da\u00df die N\u00e4chte dieser Erden", "tokens": ["Und", "da\u00df", "die", "N\u00e4ch\u00b7te", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "nun finsterer und l\u00e4nger werden,", "tokens": ["nun", "fins\u00b7te\u00b7rer", "und", "l\u00e4n\u00b7ger", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "das k\u00f6mmt von ihrem Abeziehn.", "tokens": ["das", "k\u00f6mmt", "von", "ih\u00b7rem", "A\u00b7be\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Den kranken Pol, die matten Nelken", "tokens": ["Den", "kran\u00b7ken", "Pol", ",", "die", "mat\u00b7ten", "Nel\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "sieht man, wenn sie noch stehn, verwelken.", "tokens": ["sieht", "man", ",", "wenn", "sie", "noch", "stehn", ",", "ver\u00b7wel\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die Winter-Rosen schrumpeln ein.", "tokens": ["Die", "Win\u00b7ter\u00b7Ro\u00b7sen", "schrum\u00b7peln", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Kraut ist frisch, kein Baum ist gr\u00fcne.", "tokens": ["Kein", "Kraut", "ist", "frisch", ",", "kein", "Baum", "ist", "gr\u00fc\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$,", "PIAT", "NN", "VAFIN", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Sonne, die vor ihnen schiene,", "tokens": ["Die", "Son\u00b7ne", ",", "die", "vor", "ih\u00b7nen", "schie\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "hat aufgeh\u00f6ret hier zu sein.", "tokens": ["hat", "auf\u00b7ge\u00b7h\u00f6\u00b7ret", "hier", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "ADV", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Was anders k\u00f6nnen Hirt und Heerden", "tokens": ["Was", "an\u00b7ders", "k\u00f6n\u00b7nen", "Hirt", "und", "Heer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VMFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als leid' und traurig sich geberden?", "tokens": ["als", "leid'", "und", "trau\u00b7rig", "sich", "ge\u00b7ber\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "KON", "ADJD", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Lied erschallt, kein Tanz geschicht.", "tokens": ["Kein", "Lied", "er\u00b7schallt", ",", "kein", "Tanz", "ge\u00b7schicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Feld', im Pusch', im Tal', in Auen", "tokens": ["Im", "Feld'", ",", "im", "Pusch'", ",", "im", "Tal'", ",", "in", "Au\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ist nichts als stille Furcht zu schauen,", "tokens": ["ist", "nichts", "als", "stil\u00b7le", "Furcht", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "KOKOM", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "weil man die Freude selbst nicht sicht.", "tokens": ["weil", "man", "die", "Freu\u00b7de", "selbst", "nicht", "sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.13": {"line.1": {"text": "Zwar, so wir haben recht vernommen,", "tokens": ["Zwar", ",", "so", "wir", "ha\u00b7ben", "recht", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "so soll ihr sch\u00f6ner Tag sein kommen.", "tokens": ["so", "soll", "ihr", "sch\u00f6\u00b7ner", "Tag", "sein", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was aber kan di\u00df anders tun,", "tokens": ["Was", "a\u00b7ber", "kan", "di\u00df", "an\u00b7ders", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "PDS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als da\u00df es duppelt mehr uns kr\u00e4nket?", "tokens": ["als", "da\u00df", "es", "dup\u00b7pelt", "mehr", "uns", "kr\u00e4n\u00b7ket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PPER", "VVFIN", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die von uns werden soll beschenket,", "tokens": ["Die", "von", "uns", "wer\u00b7den", "soll", "be\u00b7schen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VAINF", "VMFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "die hier soll sein, wo ist sie nun?", "tokens": ["die", "hier", "soll", "sein", ",", "wo", "ist", "sie", "nun", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "VAINF", "$,", "PWAV", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ihr mehr als wir geehrten W\u00e4lder,", "tokens": ["Ihr", "mehr", "als", "wir", "ge\u00b7ehr\u00b7ten", "W\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KOUS", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ihr Wiesen, ihr bes\u00e4ten Felder,", "tokens": ["ihr", "Wie\u00b7sen", ",", "ihr", "be\u00b7s\u00e4\u00b7ten", "Fel\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "erkennt das Gl\u00fccke, diese Gunst!", "tokens": ["er\u00b7kennt", "das", "Gl\u00fc\u00b7cke", ",", "die\u00b7se", "Gunst", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Pflegt ihr, weil ihr sie k\u00f6nnet haben,", "tokens": ["Pflegt", "ihr", ",", "weil", "ihr", "sie", "k\u00f6n\u00b7net", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "KOUS", "PPER", "PPER", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und bindet die f\u00fcr uns mit Gaben,", "tokens": ["und", "bin\u00b7det", "die", "f\u00fcr", "uns", "mit", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "nach der wir w\u00fcndschen doch umsonst!", "tokens": ["nach", "der", "wir", "w\u00fcnd\u00b7schen", "doch", "um\u00b7sonst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}