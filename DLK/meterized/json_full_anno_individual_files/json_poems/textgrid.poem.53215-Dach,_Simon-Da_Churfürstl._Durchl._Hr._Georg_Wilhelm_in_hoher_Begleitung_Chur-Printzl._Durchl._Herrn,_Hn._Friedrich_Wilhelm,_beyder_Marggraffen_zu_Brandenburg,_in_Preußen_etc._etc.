{"textgrid.poem.53215": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Da Churf\u00fcrstl. Durchl. Hr. Georg Wilhelm in hoher Begleitung Chur-Printzl. Durchl. Herrn, Hn. Friedrich Wilhelm, beyder Marggraffen zu Brandenburg, in Preu\u00dfen etc. etc. Hertzogen etc. etc. hieselbst in K\u00f6nigsberg den 23sten HerbstM. 1638. erfreulichst einkahm", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Himmel wil mir wol, ich kan von Gl\u00fccke sagen,", "tokens": ["Der", "Him\u00b7mel", "wil", "mir", "wol", ",", "ich", "kan", "von", "Gl\u00fc\u00b7cke", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "$,", "PPER", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mars mag zufrieden seyn, da\u00df Deutschland sich mu\u00df klagen,", "tokens": ["Mars", "mag", "zu\u00b7frie\u00b7den", "seyn", ",", "da\u00df", "Deutschland", "sich", "mu\u00df", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADJD", "VAINF", "$,", "KOUS", "NE", "PRF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sein Leid nicht ab kan sehn, mag stillen seinen Muth,", "tokens": ["Sein", "Leid", "nicht", "ab", "kan", "sehn", ",", "mag", "stil\u00b7len", "sei\u00b7nen", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "PTKVZ", "VMFIN", "VVINF", "$,", "VMFIN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der uners\u00e4ttigt ist mit Raub' und MenschenBlut,", "tokens": ["Der", "un\u00b7er\u00b7s\u00e4t\u00b7tigt", "ist", "mit", "Raub'", "und", "Men\u00b7schen", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "APPR", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Weil das Verh\u00e4ngnu\u00df ja es anders nicht wil leiden.", "tokens": ["Weil", "das", "Ver\u00b7h\u00e4ng\u00b7nu\u00df", "ja", "es", "an\u00b7ders", "nicht", "wil", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "PPER", "ADV", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hie gleichwol f\u00e4hlt es ihm, ich wei\u00df mich zu bescheiden", "tokens": ["Hie", "gleich\u00b7wol", "f\u00e4hlt", "es", "ihm", ",", "ich", "wei\u00df", "mich", "zu", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So einer Huld und Gunst, dergleichen man kaum hat,", "tokens": ["So", "ei\u00b7ner", "Huld", "und", "Gunst", ",", "derg\u00b7lei\u00b7chen", "man", "kaum", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "NN", "$,", "PIS", "PIS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wozu denn sonderlich Dein Glimpf und kluger Rhat", "tokens": ["Wo\u00b7zu", "denn", "son\u00b7der\u00b7lich", "Dein", "Glimpf", "und", "klu\u00b7ger", "Rhat"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADJD", "PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Beh\u00fclfflich wolte seyn, Du Held von dem Gebl\u00fcte", "tokens": ["Be\u00b7h\u00fclf\u00b7flich", "wol\u00b7te", "seyn", ",", "Du", "Held", "von", "dem", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "VAINF", "$,", "PPER", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der hohen Brennen, Du, den Tapfferkeit und G\u00fcte", "tokens": ["Der", "ho\u00b7hen", "Bren\u00b7nen", ",", "Du", ",", "den", "Tapf\u00b7fer\u00b7keit", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "$,", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Weit \u00fcber F\u00fcrsten hebt, Du dieser Zeiten Lust,", "tokens": ["Weit", "\u00fc\u00b7ber", "F\u00fcrs\u00b7ten", "hebt", ",", "Du", "die\u00b7ser", "Zei\u00b7ten", "Lust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVFIN", "$,", "PPER", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und Bild der Vorigen. Schaw was Du jetzund thust,", "tokens": ["Und", "Bild", "der", "Vo\u00b7ri\u00b7gen", ".", "Schaw", "was", "Du", "je\u00b7tzund", "thust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "$.", "NN", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+--++-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Dich d\u00fcnckt, es were nichts in Friede mich zu setzen,", "tokens": ["Dich", "d\u00fcnckt", ",", "es", "we\u00b7re", "nichts", "in", "Frie\u00b7de", "mich", "zu", "set\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIS", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wenn Deine Gegenwart mich auch nicht solt' ergetzen", "tokens": ["Wenn", "Dei\u00b7ne", "Ge\u00b7gen\u00b7wart", "mich", "auch", "nicht", "solt'", "er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "ADV", "PTKNEG", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und zeugen, das Dein Sinn die Treu auff mich gewandt", "tokens": ["Und", "zeu\u00b7gen", ",", "das", "Dein", "Sinn", "die", "Treu", "auff", "mich", "ge\u00b7wandt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "ART", "NN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Als je bi\u00dfher ein Volck an Herren hat erkant,", "tokens": ["Als", "je", "bi\u00df\u00b7her", "ein", "Volck", "an", "Her\u00b7ren", "hat", "er\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die g\u00f6ttlich sind wie Du. Und wessen werd' ich innen?", "tokens": ["Die", "g\u00f6tt\u00b7lich", "sind", "wie", "Du", ".", "Und", "wes\u00b7sen", "werd'", "ich", "in\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KOKOM", "PPER", "$.", "KON", "VVINF", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Dein Sohn, der F\u00fcrsten Prei\u00df und Spiegel deiner Sinnen,", "tokens": ["Dein", "Sohn", ",", "der", "F\u00fcrs\u00b7ten", "Prei\u00df", "und", "Spie\u00b7gel", "dei\u00b7ner", "Sin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "NN", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die Hoffnung aller Welt und meine Zuversicht,", "tokens": ["Die", "Hoff\u00b7nung", "al\u00b7ler", "Welt", "und", "mei\u00b7ne", "Zu\u00b7ver\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "K\u00f6mpt auch und g\u00f6nnt einmahl mir seines Glantzes Licht,", "tokens": ["K\u00f6mpt", "auch", "und", "g\u00f6nnt", "ein\u00b7mahl", "mir", "sei\u00b7nes", "Glant\u00b7zes", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "ADV", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der wahren Liebe Pfandt. O eine grosse Gnade!", "tokens": ["Der", "wah\u00b7ren", "Lie\u00b7be", "Pfandt", ".", "O", "ei\u00b7ne", "gros\u00b7se", "Gna\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$.", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ein Zeugnus thewrer Huld und Freundligkeit! gerade", "tokens": ["Ein", "Zeug\u00b7nus", "thew\u00b7rer", "Huld", "und", "Freund\u00b7lig\u00b7keit", "!", "ge\u00b7ra\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Als in der Fewers-Brunst ein treuer Vater thut,", "tokens": ["Als", "in", "der", "Fe\u00b7wer\u00b7sBrunst", "ein", "treu\u00b7er", "Va\u00b7ter", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der zwar das eine Kind wil retten aus der Glut,", "tokens": ["Der", "zwar", "das", "ei\u00b7ne", "Kind", "wil", "ret\u00b7ten", "aus", "der", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ART", "NN", "VMFIN", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Doch f\u00fcr das ander auch, so der Gefahr entgangen,", "tokens": ["Doch", "f\u00fcr", "das", "an\u00b7der", "auch", ",", "so", "der", "Ge\u00b7fahr", "ent\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJD", "ADV", "$,", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Nicht minder Sorge tr\u00e4gt, indem es aus Verlangen", "tokens": ["Nicht", "min\u00b7der", "Sor\u00b7ge", "tr\u00e4gt", ",", "in\u00b7dem", "es", "aus", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "NN", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die Armlein nach ihm streckt und ohn auffh\u00f6ren klagt", "tokens": ["Die", "Arm\u00b7lein", "nach", "ihm", "streckt", "und", "ohn", "auff\u00b7h\u00f6\u00b7ren", "klagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "KON", "APPR", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Au\u00df Kummer, da\u00df er sich hat in den Brand gewagt,", "tokens": ["Au\u00df", "Kum\u00b7mer", ",", "da\u00df", "er", "sich", "hat", "in", "den", "Brand", "ge\u00b7wagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "PPER", "PRF", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So thut ihr gleichfals mir. Wie wil ich an Euch beyden", "tokens": ["So", "thut", "ihr", "gleich\u00b7fals", "mir", ".", "Wie", "wil", "ich", "an", "Euch", "bey\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPER", "$.", "PWAV", "VMFIN", "PPER", "APPR", "PPER", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ergetzen Hertz und Sinn, wil Seel' und Augen weiden,", "tokens": ["Er\u00b7get\u00b7zen", "Hertz", "und", "Sinn", ",", "wil", "Seel'", "und", "Au\u00b7gen", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$,", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wil sagen ungeschewt und aller Frewden voll,", "tokens": ["Wil", "sa\u00b7gen", "un\u00b7ge\u00b7schewt", "und", "al\u00b7ler", "Frew\u00b7den", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADJD", "KON", "PIAT", "NN", "ADJD", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.32": {"text": "Wie ich durch Euch erlangt das, was ich kan und sol.", "tokens": ["Wie", "ich", "durch", "Euch", "er\u00b7langt", "das", ",", "was", "ich", "kan", "und", "sol", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "VVFIN", "PDS", "$,", "PWS", "PPER", "VMFIN", "KON", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Nur zieht in Gnaden ein! Ihr seyd auch diesem Lande", "tokens": ["Nur", "zieht", "in", "Gna\u00b7den", "ein", "!", "Ihr", "seyd", "auch", "die\u00b7sem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Der Trost, so ihm geh\u00f6rt, seyd mir auch mit dem Bande", "tokens": ["Der", "Trost", ",", "so", "ihm", "ge\u00b7h\u00f6rt", ",", "seyd", "mir", "auch", "mit", "dem", "Ban\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Der Liebe fest verkn\u00fcpfft. Die\u00df edle Hertzogthum", "tokens": ["Der", "Lie\u00b7be", "fest", "ver\u00b7kn\u00fcpfft", ".", "Die\u00df", "ed\u00b7le", "Hert\u00b7zog\u00b7thum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVPP", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Heist Ewrentwegen so, Ihr Preussens h\u00f6chster Ruhm,", "tokens": ["Heist", "E\u00b7wrent\u00b7we\u00b7gen", "so", ",", "Ihr", "Preus\u00b7sens", "h\u00f6chs\u00b7ter", "Ruhm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Zieht ein und nemet war, wie alles Euch zu Ehren,", "tokens": ["Zieht", "ein", "und", "ne\u00b7met", "war", ",", "wie", "al\u00b7les", "Euch", "zu", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "KON", "VVFIN", "VAFIN", "$,", "PWAV", "PIS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Die Lufft, das Haff, die See sich lesst mit St\u00fcrmen h\u00f6ren!", "tokens": ["Die", "Lufft", ",", "das", "Haff", ",", "die", "See", "sich", "lesst", "mit", "St\u00fcr\u00b7men", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "PRF", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Der Herbst thut was er sol, er giebt dennoch bescheidt", "tokens": ["Der", "Herbst", "thut", "was", "er", "sol", ",", "er", "giebt", "den\u00b7noch", "be\u00b7scheidt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PWS", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "So gut er kan und mag, da\u00df Ihr zugegen seyd.", "tokens": ["So", "gut", "er", "kan", "und", "mag", ",", "da\u00df", "Ihr", "zu\u00b7ge\u00b7gen", "seyd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VMFIN", "KON", "VMFIN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Dies mercket Cynthia, drumb macht sie sich zur Stunde", "tokens": ["Dies", "mer\u00b7cket", "Cyn\u00b7thia", ",", "drumb", "macht", "sie", "sich", "zur", "Stun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NE", "$,", "PAV", "VVFIN", "PPER", "PRF", "APPRART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.42": {"text": "Zu ihrem J\u00e4ger-Volck, und nimpt die besten Hunde,", "tokens": ["Zu", "ih\u00b7rem", "J\u00e4\u00b7ger\u00b7Volck", ",", "und", "nimpt", "die", "bes\u00b7ten", "Hun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "H\u00e4lt fertig allen Zeug, schawt fleissig auff und wacht,", "tokens": ["H\u00e4lt", "fer\u00b7tig", "al\u00b7len", "Zeug", ",", "schawt", "fleis\u00b7sig", "auff", "und", "wacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PIAT", "NN", "$,", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Ob etwan Euch geliebt den Ernst der Wilden Schlacht", "tokens": ["Ob", "et\u00b7wan", "Euch", "ge\u00b7liebt", "den", "Ernst", "der", "Wil\u00b7den", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "VVPP", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Mit einer freyen Lust des Jagens zu vertauschen.", "tokens": ["Mit", "ei\u00b7ner", "frey\u00b7en", "Lust", "des", "Ja\u00b7gens", "zu", "ver\u00b7tau\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Man h\u00f6rt noch hie und da der B\u00e4ume Bl\u00e4tter rauschen,", "tokens": ["Man", "h\u00f6rt", "noch", "hie", "und", "da", "der", "B\u00e4u\u00b7me", "Bl\u00e4t\u00b7ter", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "KON", "ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Der B\u00e4ume, die ihr Laub nicht g\u00e4ntzlich hingelegt,", "tokens": ["Der", "B\u00e4u\u00b7me", ",", "die", "ihr", "Laub", "nicht", "g\u00e4ntz\u00b7lich", "hin\u00b7ge\u00b7legt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Es wird f\u00fcr Euch, Ihr auch der W\u00e4lder Pracht, gehegt.", "tokens": ["Es", "wird", "f\u00fcr", "Euch", ",", "Ihr", "auch", "der", "W\u00e4l\u00b7der", "Pracht", ",", "ge\u00b7hegt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "$,", "PPER", "ADV", "ART", "NN", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Nun kommt Ihr Helden? ja, ich aber mu\u00df gestehen,", "tokens": ["Nun", "kommt", "Ihr", "Hel\u00b7den", "?", "ja", ",", "ich", "a\u00b7ber", "mu\u00df", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "PTKANT", "$,", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Wie pr\u00e4chtig ich nun gleich Euch wolt' entgegen gehen,", "tokens": ["Wie", "pr\u00e4ch\u00b7tig", "ich", "nun", "gleich", "Euch", "wolt'", "ent\u00b7ge\u00b7gen", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ADV", "PPER", "VMFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Bezeugen meine Pflicht, mich schm\u00fccken umb und an,", "tokens": ["Be\u00b7zeu\u00b7gen", "mei\u00b7ne", "Pflicht", ",", "mich", "schm\u00fc\u00b7cken", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Da\u00df aller Witz und Kunst nichts dessen finden kan,", "tokens": ["Da\u00df", "al\u00b7ler", "Witz", "und", "Kunst", "nichts", "des\u00b7sen", "fin\u00b7den", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "KON", "NN", "PIS", "PDS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Was Ewre Zier erheischt, Doch weil auch alle Gaben,", "tokens": ["Was", "Ew\u00b7re", "Zier", "er\u00b7heischt", ",", "Doch", "weil", "auch", "al\u00b7le", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "KON", "KOUS", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "So dieses Leben f\u00fchrt, nicht das Verm\u00f6gen haben,", "tokens": ["So", "die\u00b7ses", "Le\u00b7ben", "f\u00fchrt", ",", "nicht", "das", "Ver\u00b7m\u00f6\u00b7gen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "$,", "PTKNEG", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Wird Ewre G\u00f6ttligkeit, Ihr meines Hertzens Schein,", "tokens": ["Wird", "Ew\u00b7re", "G\u00f6tt\u00b7lig\u00b7keit", ",", "Ihr", "mei\u00b7nes", "Hert\u00b7zens", "Schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Da\u00df mehr als g\u00fclden ist, gef\u00e4llig lassen seyn.", "tokens": ["Da\u00df", "mehr", "als", "g\u00fcl\u00b7den", "ist", ",", "ge\u00b7f\u00e4l\u00b7lig", "las\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KOKOM", "ADJD", "VAFIN", "$,", "ADJD", "VVINF", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Die\u00df hat Prussilia mich newlich h\u00f6ren lassen,", "tokens": ["Die\u00df", "hat", "Prus\u00b7si\u00b7lia", "mich", "new\u00b7lich", "h\u00f6\u00b7ren", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "PPER", "ADJD", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.58": {"text": "Auff die Art redte sie, so viel ich kunte fassen,", "tokens": ["Auff", "die", "Art", "red\u00b7te", "sie", ",", "so", "viel", "ich", "kun\u00b7te", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$,", "ADV", "ADV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Da dieses Helden-Paar au\u00df Brennus grossem Stamm',", "tokens": ["Da", "die\u00b7ses", "Hel\u00b7den\u00b7Paar", "au\u00df", "Bren\u00b7nus", "gros\u00b7sem", "Stamm'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "O Vaterland, bey dir hereingezogen kam", "tokens": ["O", "Va\u00b7ter\u00b7land", ",", "bey", "dir", "her\u00b7ein\u00b7ge\u00b7zo\u00b7gen", "kam"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "APPR", "PPER", "VVIZU", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Und unsern Wunsch erf\u00fcllt. Als sie noch kaum geendet", "tokens": ["Und", "un\u00b7sern", "Wunsch", "er\u00b7f\u00fcllt", ".", "Als", "sie", "noch", "kaum", "ge\u00b7en\u00b7det"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$.", "KOUS", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Die Worte, hat sie sich zum Nagot erst gewendet,", "tokens": ["Die", "Wor\u00b7te", ",", "hat", "sie", "sich", "zum", "Na\u00b7got", "erst", "ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "PPER", "PRF", "APPRART", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Dann zu dem Pregel hin, sie rief der Alle zu,", "tokens": ["Dann", "zu", "dem", "Pre\u00b7gel", "hin", ",", "sie", "rief", "der", "Al\u00b7le", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$,", "PPER", "VVFIN", "ART", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Auch, M\u00fcmmel, dir und sprach: Seyd ihr bi\u00dfher in Rhue", "tokens": ["Auch", ",", "M\u00fcm\u00b7mel", ",", "dir", "und", "sprach", ":", "Seyd", "ihr", "bi\u00df\u00b7her", "in", "Rhue"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "PPER", "KON", "VVFIN", "$.", "VAIMP", "PPER", "ADV", "APPR", "NE"], "meter": "-+-+-++-+--+", "measure": "iambic.hexa.chol"}, "line.65": {"text": "Und stiller Sicherheit bi\u00df in die See geflossen?", "tokens": ["Und", "stil\u00b7ler", "Si\u00b7cher\u00b7heit", "bi\u00df", "in", "die", "See", "ge\u00b7flos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.66": {"text": "Habt durch die Wiesen euch mit stoltzer Flut ergossen?", "tokens": ["Habt", "durch", "die", "Wie\u00b7sen", "euch", "mit", "stolt\u00b7zer", "Flut", "er\u00b7gos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "An beyden Ufern her der Nymphen Liedt geh\u00f6rt,", "tokens": ["An", "bey\u00b7den", "U\u00b7fern", "her", "der", "Nym\u00b7phen", "Liedt", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APZR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die Faunen lustig seyn? hat Phoebus euch geehrt?", "tokens": ["Die", "Fau\u00b7nen", "lus\u00b7tig", "seyn", "?", "hat", "Phoe\u00b7bus", "euch", "ge\u00b7ehrt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAINF", "$.", "VAFIN", "NE", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Wil sich Diane gern der Jagt und M\u00fch entladen", "tokens": ["Wil", "sich", "Di\u00b7a\u00b7ne", "gern", "der", "Jagt", "und", "M\u00fch", "ent\u00b7la\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "NE", "ADV", "ART", "VVFIN", "KON", "NN", "VVPP"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.70": {"text": "Mit ihren Najaden in ewren Str\u00f6men baden?", "tokens": ["Mit", "ih\u00b7ren", "Na\u00b7ja\u00b7den", "in", "ew\u00b7ren", "Str\u00f6\u00b7men", "ba\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.71": {"text": "Tr\u00e4gt ewer R\u00fccken Goldt und unersch\u00f6pftes Gut?", "tokens": ["Tr\u00e4gt", "e\u00b7wer", "R\u00fc\u00b7cken", "Goldt", "und", "un\u00b7er\u00b7sch\u00f6pf\u00b7tes", "Gut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Schl\u00e4gt alle Welt hier zu, sucht Nahrung, Schutz und Hut", "tokens": ["Schl\u00e4gt", "al\u00b7le", "Welt", "hier", "zu", ",", "sucht", "Nah\u00b7rung", ",", "Schutz", "und", "Hut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "ADV", "PTKVZ", "$,", "VVFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Und findet was sie sol? besorgt sich keiner Waffen,", "tokens": ["Und", "fin\u00b7det", "was", "sie", "sol", "?", "be\u00b7sorgt", "sich", "kei\u00b7ner", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PPER", "VMFIN", "$.", "VVFIN", "PRF", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Kan aller Sorgen frey jetzt wachen, jetzund schlaffen?", "tokens": ["Kan", "al\u00b7ler", "Sor\u00b7gen", "frey", "jetzt", "wa\u00b7chen", ",", "je\u00b7tzund", "schlaf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "ADJD", "ADV", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Seht, Kinder, Dieses Haupt, das solche Rhue uns schenckt,", "tokens": ["Seht", ",", "Kin\u00b7der", ",", "Die\u00b7ses", "Haupt", ",", "das", "sol\u00b7che", "Rhue", "uns", "schenckt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "PDAT", "NN", "$,", "PRELS", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Hat jetzt in Gnaden sich hieher zu uns gelenckt", "tokens": ["Hat", "jetzt", "in", "Gna\u00b7den", "sich", "hie\u00b7her", "zu", "uns", "ge\u00b7lenckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "NN", "PRF", "PAV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Und dieses Land erfrewt. Auff! uns wil jetzt geb\u00fchren,", "tokens": ["Und", "die\u00b7ses", "Land", "er\u00b7frewt", ".", "Auff", "!", "uns", "wil", "jetzt", "ge\u00b7b\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "$.", "NN", "$.", "PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.78": {"text": "So viel als m\u00f6glich ist, Sie pr\u00e4chtig einzuf\u00fchren", "tokens": ["So", "viel", "als", "m\u00f6g\u00b7lich", "ist", ",", "Sie", "pr\u00e4ch\u00b7tig", "ein\u00b7zu\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIAT", "KOKOM", "ADJD", "VAFIN", "$,", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Und den Gehorsam so zu geben an den Tag,", "tokens": ["Und", "den", "Ge\u00b7hor\u00b7sam", "so", "zu", "ge\u00b7ben", "an", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Ein jedes schicke sich so gut es kan und mag,", "tokens": ["Ein", "je\u00b7des", "schi\u00b7cke", "sich", "so", "gut", "es", "kan", "und", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VVFIN", "PRF", "ADV", "ADJD", "PPER", "VMFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Und ziehe statlich auff, wer unter Euch wird siegen,", "tokens": ["Und", "zie\u00b7he", "stat\u00b7lich", "auff", ",", "wer", "un\u00b7ter", "Euch", "wird", "sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$,", "PWS", "APPR", "PPER", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Der sol zu Lohn mein Bild von klarem Bernstein kriegen.", "tokens": ["Der", "sol", "zu", "Lohn", "mein", "Bild", "von", "kla\u00b7rem", "Bern\u00b7stein", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Sie wurden s\u00e4mptlich fro und stelleten sich dar,", "tokens": ["Sie", "wur\u00b7den", "s\u00e4mpt\u00b7lich", "fro", "und", "stel\u00b7le\u00b7ten", "sich", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD", "KON", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Eins tritt dem andern vor, es scheint ihr Bart und Haar", "tokens": ["Eins", "tritt", "dem", "an\u00b7dern", "vor", ",", "es", "scheint", "ihr", "Bart", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "PTKVZ", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Nur Gra\u00df und Schilff zu seyn. Der Nagot wolte pralen", "tokens": ["Nur", "Gra\u00df", "und", "Schilff", "zu", "seyn", ".", "Der", "Na\u00b7got", "wol\u00b7te", "pra\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN", "PTKZU", "VAINF", "$.", "ART", "NE", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Und hat ein sch\u00f6nes Schlo\u00df ihm k\u00fcnstlich lassen mahlen,", "tokens": ["Und", "hat", "ein", "sch\u00f6\u00b7nes", "Schlo\u00df", "ihm", "k\u00fcnst\u00b7lich", "las\u00b7sen", "mah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "PPER", "ADJD", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Daneben auch wie ihn der Weichsel-Strom erzeugt", "tokens": ["Da\u00b7ne\u00b7ben", "auch", "wie", "ihn", "der", "Weich\u00b7sel\u00b7Strom", "er\u00b7zeugt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "KOKOM", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Durch einer Nymphen Gunst, die jetzt ihm noch geneigt.", "tokens": ["Durch", "ei\u00b7ner", "Nym\u00b7phen", "Gunst", ",", "die", "jetzt", "ihm", "noch", "ge\u00b7neigt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Der Pregel aber wolt' hierinnen keinem weichen,", "tokens": ["Der", "Pre\u00b7gel", "a\u00b7ber", "wolt'", "hie\u00b7rin\u00b7nen", "kei\u00b7nem", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PAV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Trug einen Lorber-Krantz, der K\u00fcnste sch\u00f6nes Zeichen,", "tokens": ["Trug", "ei\u00b7nen", "Lor\u00b7ber\u00b7Krantz", ",", "der", "K\u00fcns\u00b7te", "sch\u00f6\u00b7nes", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Die er f\u00fcr andern n\u00e4hrt, auch Wahren allerhand", "tokens": ["Die", "er", "f\u00fcr", "an\u00b7dern", "n\u00e4hrt", ",", "auch", "Wah\u00b7ren", "al\u00b7ler\u00b7hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PIS", "VVFIN", "$,", "ADV", "NN", "PIAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Und G\u00fcter, die dem West und Norden sind bekant.", "tokens": ["Und", "G\u00fc\u00b7ter", ",", "die", "dem", "West", "und", "Nor\u00b7den", "sind", "be\u00b7kant", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ART", "NN", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Ihm folgt der M\u00fcmmel-Strom gebraten von der Sonnen,", "tokens": ["Ihm", "folgt", "der", "M\u00fcm\u00b7mel\u00b7Strom", "ge\u00b7bra\u00b7ten", "von", "der", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Tr\u00e4gt reiches Korn und Flachs, und was er sonst gewonnen", "tokens": ["Tr\u00e4gt", "rei\u00b7ches", "Korn", "und", "Flachs", ",", "und", "was", "er", "sonst", "ge\u00b7won\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJA", "NN", "KON", "NN", "$,", "KON", "PWS", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Durch seiner Russen flei\u00df, f\u00fchrt nach sich auff der Fahrt", "tokens": ["Durch", "sei\u00b7ner", "Rus\u00b7sen", "flei\u00df", ",", "f\u00fchrt", "nach", "sich", "auff", "der", "Fahrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "APPR", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Die Dudey und Schalmey, und B\u00e4ren vieler Art.", "tokens": ["Die", "Du\u00b7dey", "und", "Schal\u00b7mey", ",", "und", "B\u00e4\u00b7ren", "vie\u00b7ler", "Art", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "KON", "NN", "PIAT", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.97": {"text": "Die All' hatt' ihren Schmuck, zu welchem du auch kamest,", "tokens": ["Die", "All'", "hatt'", "ih\u00b7ren", "Schmuck", ",", "zu", "wel\u00b7chem", "du", "auch", "ka\u00b7mest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "PPOSAT", "NN", "$,", "APPR", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.98": {"text": "Du der Passargen-Flu\u00df, drangst dich hinzu und nahmest", "tokens": ["Du", "der", "Pas\u00b7sar\u00b7gen\u00b7Flu\u00df", ",", "drangst", "dich", "hin\u00b7zu", "und", "nah\u00b7mest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Den letzten Platz nicht ein. Sie stehen allerseit", "tokens": ["Den", "letz\u00b7ten", "Platz", "nicht", "ein", ".", "Sie", "ste\u00b7hen", "al\u00b7ler\u00b7seit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKVZ", "$.", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und f\u00fchren, wie geschiht, des Vorzugs halben Streit,", "tokens": ["Und", "f\u00fch\u00b7ren", ",", "wie", "ge\u00b7schiht", ",", "des", "Vor\u00b7zugs", "hal\u00b7ben", "Streit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "PWAV", "VVPP", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Als unverhofft ein Glantz und Leuchten sie umbgiebet.", "tokens": ["Als", "un\u00b7ver\u00b7hofft", "ein", "Glantz", "und", "Leuch\u00b7ten", "sie", "umb\u00b7gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Da vormals Juppiter die Semelen geliebet,", "tokens": ["Da", "vor\u00b7mals", "Jup\u00b7pi\u00b7ter", "die", "Se\u00b7me\u00b7len", "ge\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.103": {"text": "Sol er in solchem Plitz und hellen Glantzes Schein", "tokens": ["Sol", "er", "in", "sol\u00b7chem", "Plitz", "und", "hel\u00b7len", "Glant\u00b7zes", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "NN", "KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "In solchen Stralen nicht zu ihr gekommen seyn.", "tokens": ["In", "sol\u00b7chen", "Stra\u00b7len", "nicht", "zu", "ihr", "ge\u00b7kom\u00b7men", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKNEG", "APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Prussilia erschrickt. Hierauff hat man vernommen,", "tokens": ["Prus\u00b7si\u00b7lia", "er\u00b7schrickt", ".", "Hier\u00b7auff", "hat", "man", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$.", "PAV", "VAFIN", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.106": {"text": "Da\u00df drey G\u00f6ttinnen selbst ins Mittel seyn gekommen,", "tokens": ["Da\u00df", "drey", "G\u00f6t\u00b7tin\u00b7nen", "selbst", "ins", "Mit\u00b7tel", "seyn", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "ADV", "APPRART", "NN", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Die Erste ward vorau\u00df durch Trefligkeit und Pracht", "tokens": ["Die", "Ers\u00b7te", "ward", "vor\u00b7au\u00df", "durch", "Tre\u00b7flig\u00b7keit", "und", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "F\u00fcr Juno angesehn, dann wie bey heller Nacht", "tokens": ["F\u00fcr", "Ju\u00b7no", "an\u00b7ge\u00b7sehn", ",", "dann", "wie", "bey", "hel\u00b7ler", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$,", "ADV", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Des Mondens Kertze gl\u00e4ntzt, so sahe man auch scheinen", "tokens": ["Des", "Mon\u00b7dens", "Kert\u00b7ze", "gl\u00e4ntzt", ",", "so", "sa\u00b7he", "man", "auch", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Die Ihr am n\u00e4chsten stundt, ich muste g\u00e4ntzlich meinen,", "tokens": ["Die", "Ihr", "am", "n\u00e4chs\u00b7ten", "stundt", ",", "ich", "mus\u00b7te", "g\u00e4ntz\u00b7lich", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "ADJA", "VVFIN", "$,", "PPER", "VMFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Sie were Pallas gar, die Dritte, welcher Zier", "tokens": ["Sie", "we\u00b7re", "Pal\u00b7las", "gar", ",", "die", "Drit\u00b7te", ",", "wel\u00b7cher", "Zier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "NE", "ADV", "$,", "ART", "ADJA", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und Tugendt mich nicht treugt, gleich, edle Clio, dir.", "tokens": ["Und", "Tu\u00b7gendt", "mich", "nicht", "treugt", ",", "gleich", ",", "ed\u00b7le", "Clio", ",", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "PPER", "PTKNEG", "VVFIN", "$,", "ADV", "$,", "ADJA", "NN", "$,", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.113": {"text": "Sie sind f\u00fcr allen frey hin zu den F\u00fcrsten gangen,", "tokens": ["Sie", "sind", "f\u00fcr", "al\u00b7len", "frey", "hin", "zu", "den", "F\u00fcrs\u00b7ten", "gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "ADJD", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Und haben insgesampt Sie, unsern Schutz empfangen", "tokens": ["Und", "ha\u00b7ben", "ins\u00b7ge\u00b7sampt", "Sie", ",", "un\u00b7sern", "Schutz", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PPER", "$,", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Mit Reden, die ich nicht au\u00df Schwachheit mercken kan,", "tokens": ["Mit", "Re\u00b7den", ",", "die", "ich", "nicht", "au\u00df", "Schwach\u00b7heit", "mer\u00b7cken", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Doch hub die Erste fast mit diesen Worten an,", "tokens": ["Doch", "hub", "die", "Ers\u00b7te", "fast", "mit", "die\u00b7sen", "Wor\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADV", "APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Die sich au\u00df Ihrem Mund als einem Quel ergossen", "tokens": ["Die", "sich", "au\u00df", "Ih\u00b7rem", "Mund", "als", "ei\u00b7nem", "Quel", "er\u00b7gos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "KOKOM", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Und wie ein Honig-Seim und Nectar vor sich flossen:", "tokens": ["Und", "wie", "ein", "Ho\u00b7nig\u00b7Seim", "und", "Nec\u00b7tar", "vor", "sich", "flos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "F\u00fcrsten h\u00e4lt der Himmel Schutz", "tokens": ["F\u00fcrs\u00b7ten", "h\u00e4lt", "der", "Him\u00b7mel", "Schutz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mehr als sonst gemeinen Leuten,", "tokens": ["Mehr", "als", "sonst", "ge\u00b7mei\u00b7nen", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df Bellonen Macht und Trutz", "tokens": ["La\u00df", "Bel\u00b7lo\u00b7nen", "Macht", "und", "Trutz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch so grimmig sie bestreiten,", "tokens": ["Noch", "so", "grim\u00b7mig", "sie", "be\u00b7strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihre starcke Gegenwehr", "tokens": ["Ih\u00b7re", "star\u00b7cke", "Ge\u00b7gen\u00b7wehr"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist der Himmel und sein Heer.", "tokens": ["Ist", "der", "Him\u00b7mel", "und", "sein", "Heer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Held, den meine Seel erkiest,", "tokens": ["Held", ",", "den", "mei\u00b7ne", "Seel", "er\u00b7kiest", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dessen Gegenwart mein Leben", "tokens": ["Des\u00b7sen", "Ge\u00b7gen\u00b7wart", "mein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd mein h\u00f6chster Wolstand ist,", "tokens": ["Vnd", "mein", "h\u00f6chs\u00b7ter", "Wol\u00b7stand", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht gedencke darumb eben,", "tokens": ["Nicht", "ge\u00b7den\u00b7cke", "da\u00b7rumb", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PAV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das, weil du gefochten hast,", "tokens": ["Das", ",", "weil", "du", "ge\u00b7foch\u00b7ten", "hast", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ich geschwebt in Ruh und Rast:", "tokens": ["Ich", "ge\u00b7schwebt", "in", "Ruh", "und", "Rast", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Hat Penthesileen Macht", "tokens": ["Hat", "Pen\u00b7the\u00b7si\u00b7leen", "Macht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "NE", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Mich nicht an den Feind gehetzet,", "tokens": ["Mich", "nicht", "an", "den", "Feind", "ge\u00b7het\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hab' ich nicht in wilder Schlacht", "tokens": ["Hab'", "ich", "nicht", "in", "wil\u00b7der", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Spie\u00df und Schwerdt wie sie genetzet,", "tokens": ["Spie\u00df", "und", "Schwerdt", "wie", "sie", "ge\u00b7net\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KOKOM", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ey, so hab' ich doch gethan", "tokens": ["Ey", ",", "so", "hab'", "ich", "doch", "ge\u00b7than"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Was ich nur thun sol und kan.", "tokens": ["Was", "ich", "nur", "thun", "sol", "und", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVINF", "VMFIN", "KON", "VMFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Fragstu was? mein Feld-Geschrey", "tokens": ["Frags\u00b7tu", "was", "?", "mein", "Feld\u00b7Ge\u00b7schrey"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "PWS", "$.", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War in hitzigen Gebeten,", "tokens": ["War", "in", "hit\u00b7zi\u00b7gen", "Ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ich hiesse st\u00fcndlich frey", "tokens": ["Die", "ich", "hies\u00b7se", "st\u00fcnd\u00b7lich", "frey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "ADJD", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor den Thron des H\u00f6chsten treten,", "tokens": ["Vor", "den", "Thron", "des", "H\u00f6chs\u00b7ten", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meiner Pfeile Krafft und Kunst", "tokens": ["Mei\u00b7ner", "Pfei\u00b7le", "Krafft", "und", "Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "War der heissen Seufftzer Brunst.", "tokens": ["War", "der", "heis\u00b7sen", "Seufft\u00b7zer", "Brunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Meiner Thr\u00e4nen strenge Fluth,", "tokens": ["Mei\u00b7ner", "Thr\u00e4\u00b7nen", "stren\u00b7ge", "Fluth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die kein Augen-blick gehemmet,", "tokens": ["Die", "kein", "Au\u00b7gen\u00b7blick", "ge\u00b7hem\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat des Feindes Ubermuth", "tokens": ["Hat", "des", "Fein\u00b7des", "U\u00b7ber\u00b7muth"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehr als einmal fortgeschwemmet,", "tokens": ["Mehr", "als", "ein\u00b7mal", "fort\u00b7ge\u00b7schwem\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df sein Fundt und schlawer Raht", "tokens": ["Da\u00df", "sein", "Fundt", "und", "schla\u00b7wer", "Raht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nie sein Ziel erreichet hat.", "tokens": ["Nie", "sein", "Ziel", "er\u00b7rei\u00b7chet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Also bin ich jederzeit", "tokens": ["Al\u00b7so", "bin", "ich", "je\u00b7der\u00b7zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Th\u00e4tig, Heldt, wie du gewesen,", "tokens": ["Th\u00e4\u00b7tig", ",", "Heldt", ",", "wie", "du", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NE", "$,", "PWAV", "PPER", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und hab' einig das Geleit", "tokens": ["Und", "hab'", "ei\u00b7nig", "das", "Ge\u00b7leit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dir zu geben mir erlesen,", "tokens": ["Dir", "zu", "ge\u00b7ben", "mir", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Keiner Waffen wiederstandt", "tokens": ["Kei\u00b7ner", "Waf\u00b7fen", "wie\u00b7der\u00b7standt"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat mich von dir abgewandt.", "tokens": ["Hat", "mich", "von", "dir", "ab\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Meiner Sorgen M\u00fch und Flei\u00df", "tokens": ["Mei\u00b7ner", "Sor\u00b7gen", "M\u00fch", "und", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Folgte wo du bist geritten,", "tokens": ["Folg\u00b7te", "wo", "du", "bist", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWAV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wiederwillen, Staub und Schwei\u00df", "tokens": ["Wie\u00b7der\u00b7wil\u00b7len", ",", "Staub", "und", "Schwei\u00df"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab' ich auch wie du erlitten,", "tokens": ["Hab'", "ich", "auch", "wie", "du", "er\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "KOKOM", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Allen Kummer, Furcht und Pein", "tokens": ["Al\u00b7len", "Kum\u00b7mer", ",", "Furcht", "und", "Pein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht ich mir von wegen dein.", "tokens": ["Macht", "ich", "mir", "von", "we\u00b7gen", "dein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "APPR", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich war fertig, allem Thun", "tokens": ["Ich", "war", "fer\u00b7tig", ",", "al\u00b7lem", "Thun"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PIS", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit Gedancken vorzukommen,", "tokens": ["Mit", "Ge\u00b7dan\u00b7cken", "vor\u00b7zu\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses, sagt' ich, hat er nun,", "tokens": ["Die\u00b7ses", ",", "sagt'", "ich", ",", "hat", "er", "nun", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nachmals das ihm vorgenommen,", "tokens": ["Nach\u00b7mals", "das", "ihm", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jetzt gebeut er seiner Schar,", "tokens": ["Jetzt", "ge\u00b7beut", "er", "sei\u00b7ner", "Schar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Jetzt ger\u00e4ht er in Gefahr.", "tokens": ["Jetzt", "ge\u00b7r\u00e4ht", "er", "in", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Dein behertzter Helden-Sinn", "tokens": ["Dein", "be\u00b7hertz\u00b7ter", "Hel\u00b7den\u00b7Sinn"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dein au\u00dfge\u00fcbter Degen", "tokens": ["Und", "dein", "au\u00df\u00b7ge\u00b7\u00fcb\u00b7ter", "De\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Geht zwar frey und sicher hin", "tokens": ["Geht", "zwar", "frey", "und", "si\u00b7cher", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "ADJD", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und hat unten nie gelegen,", "tokens": ["Und", "hat", "un\u00b7ten", "nie", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber darumb, O mein Liecht,", "tokens": ["A\u00b7ber", "da\u00b7rumb", ",", "O", "mein", "Liecht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "NE", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bin ich frey von Furchten nicht.", "tokens": ["Bin", "ich", "frey", "von", "Furch\u00b7ten", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ithacus hat Sieg und Prei\u00df", "tokens": ["It\u00b7ha\u00b7cus", "hat", "Sieg", "und", "Prei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wieder seinen Feind erhalten", "tokens": ["Wie\u00b7der", "sei\u00b7nen", "Feind", "er\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sein Lieb mu\u00df wie ein Ei\u00df", "tokens": ["Und", "sein", "Lieb", "mu\u00df", "wie", "ein", "Ei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "KOKOM", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uber Ihm daheim erkalten,", "tokens": ["U\u00b7ber", "Ihm", "da\u00b7heim", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch Achilles sieget wol,", "tokens": ["Auch", "A\u00b7chil\u00b7les", "sie\u00b7get", "wol", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Noch ist Thetis \u00e4ngsten vol.", "tokens": ["Noch", "ist", "The\u00b7tis", "\u00e4ngs\u00b7ten", "vol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Nun, der gern mich h\u00f6ret, Gott,", "tokens": ["Nun", ",", "der", "gern", "mich", "h\u00f6\u00b7ret", ",", "Gott", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "ADV", "PPER", "VVFIN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Den ich darumb stets gepriesen,", "tokens": ["Den", "ich", "da\u00b7rumb", "stets", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PAV", "ADV", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Hat mich jetzt auch nicht mit Spott'", "tokens": ["Hat", "mich", "jetzt", "auch", "nicht", "mit", "Spott'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Verachtung abgewiesen,", "tokens": ["Und", "Ver\u00b7ach\u00b7tung", "ab\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schafft, da\u00df ich auff diesen Tag", "tokens": ["Schafft", ",", "da\u00df", "ich", "auff", "die\u00b7sen", "Tag"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich, mein Leben, sprechen mag.", "tokens": ["Dich", ",", "mein", "Le\u00b7ben", ",", "spre\u00b7chen", "mag."], "token_info": ["word", "punct", "word", "word", "punct", "word", "abbreviation"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Der gehofften Sonnen Schein", "tokens": ["Der", "ge\u00b7hoff\u00b7ten", "Son\u00b7nen", "Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan zur See nach rauhem wehen", "tokens": ["Kan", "zur", "See", "nach", "rau\u00b7hem", "we\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Leuten so gew\u00fcnscht nicht seyn,", "tokens": ["Leu\u00b7ten", "so", "ge\u00b7w\u00fcnscht", "nicht", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "PTKNEG", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als, nachdem ich dich gesehen,", "tokens": ["Als", ",", "nach\u00b7dem", "ich", "dich", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mich auff mein gehabtes Leidt", "tokens": ["Mich", "auff", "mein", "ge\u00b7hab\u00b7tes", "Leidt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Deine Gegenwart erfrewt.", "tokens": ["Dei\u00b7ne", "Ge\u00b7gen\u00b7wart", "er\u00b7frewt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Gott, der in uns n\u00e4hrt die Glut", "tokens": ["Gott", ",", "der", "in", "uns", "n\u00e4hrt", "die", "Glut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieser heissen Liebes-Flammen,", "tokens": ["Die\u00b7ser", "heis\u00b7sen", "Lie\u00b7bes\u00b7Flam\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasse ja durch seine Hut", "tokens": ["Las\u00b7se", "ja", "durch", "sei\u00b7ne", "Hut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns nach diesem nicht von sammen,", "tokens": ["Uns", "nach", "die\u00b7sem", "nicht", "von", "sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PDAT", "PTKNEG", "APPR", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Keines Gl\u00fcckes wieder-Sinn", "tokens": ["Kei\u00b7nes", "Gl\u00fc\u00b7ckes", "wie\u00b7der\u00b7Sinn"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nehme mir dein Beysein hin.", "tokens": ["Neh\u00b7me", "mir", "dein", "Bey\u00b7se\u00b7in", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.15": {"line.1": {"text": "Aber du, mein thewres Pfandt,", "tokens": ["A\u00b7ber", "du", ",", "mein", "thew\u00b7res", "Pfandt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sohn, durch den Wir sind genesen,", "tokens": ["Sohn", ",", "durch", "den", "Wir", "sind", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Es ist einig Gott bekant,", "tokens": ["Es", "ist", "ei\u00b7nig", "Gott", "be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie mir da zu Muth gewesen,", "tokens": ["Wie", "mir", "da", "zu", "Muth", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als die siche Lager stat", "tokens": ["Als", "die", "si\u00b7che", "La\u00b7ger", "stat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich fast hingenommen hatt'?", "tokens": ["Dich", "fast", "hin\u00b7ge\u00b7nom\u00b7men", "hatt'", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ich entbrandte vor Begier", "tokens": ["Ich", "ent\u00b7brand\u00b7te", "vor", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich in gegenwart zu schawen,", "tokens": ["Dich", "in", "ge\u00b7gen\u00b7wart", "zu", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "----+---", "measure": "unknown.measure.single"}, "line.3": {"text": "Doch du warest fern von hier,", "tokens": ["Doch", "du", "wa\u00b7rest", "fern", "von", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "APPR", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Keiner Botschafft wolt' ich trawen,", "tokens": ["Kei\u00b7ner", "Bot\u00b7schafft", "wolt'", "ich", "tra\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Anders wolte mir nichts ein,", "tokens": ["An\u00b7ders", "wol\u00b7te", "mir", "nichts", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als du w\u00fcrdest todt schon seyn.", "tokens": ["Als", "du", "w\u00fcr\u00b7dest", "todt", "schon", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "M\u00f6cht ich, hub ich an, mein Kind,", "tokens": ["M\u00f6cht", "ich", ",", "hub", "ich", "an", ",", "mein", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich zu guter letzt noch k\u00fcssen,", "tokens": ["Dich", "zu", "gu\u00b7ter", "letzt", "noch", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jetzt, da wir geschieden sind,", "tokens": ["Jetzt", ",", "da", "wir", "ge\u00b7schie\u00b7den", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Kan ich dich nicht einmal gr\u00fcssen,", "tokens": ["Kan", "ich", "dich", "nicht", "ein\u00b7mal", "gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wei\u00df nicht, wo durch meine Trew", "tokens": ["Wei\u00df", "nicht", ",", "wo", "durch", "mei\u00b7ne", "Trew"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Etwa dir zu rathen sey.", "tokens": ["Et\u00b7wa", "dir", "zu", "ra\u00b7then", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Ach! wie sehnlich wirstu nun", "tokens": ["Ach", "!", "wie", "sehn\u00b7lich", "wirs\u00b7tu", "nun"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "PWAV", "ADJD", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Verlangen nach mir tragen,", "tokens": ["Ein", "Ver\u00b7lan\u00b7gen", "nach", "mir", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wilt, ich sol dir Rettung thun,", "tokens": ["Wilt", ",", "ich", "sol", "dir", "Ret\u00b7tung", "thun", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PPER", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hast mir die\u00df und das zu sagen,", "tokens": ["Hast", "mir", "die\u00df", "und", "das", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "KON", "PDS", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ruffst mir, bi\u00df dir Krafft gebricht,", "tokens": ["Ruffst", "mir", ",", "bi\u00df", "dir", "Krafft", "ge\u00b7bricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aber Ach! ich h\u00f6r' es nicht.", "tokens": ["A\u00b7ber", "Ach", "!", "ich", "h\u00f6r'", "es", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ITJ", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Doch thut hie auch Gottes Hand", "tokens": ["Doch", "thut", "hie", "auch", "Got\u00b7tes", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was ich mir gew\u00fcnscht, mein Flehen", "tokens": ["Was", "ich", "mir", "ge\u00b7w\u00fcnscht", ",", "mein", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "PPER", "VVPP", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat er also umbgewandt,", "tokens": ["Hat", "er", "al\u00b7so", "umb\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ich dich, mein Schatz, kan sehen,", "tokens": ["Da\u00df", "ich", "dich", ",", "mein", "Schatz", ",", "kan", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "$,", "PPOSAT", "NN", "$,", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich, und unsre h\u00f6chste Rhue,", "tokens": ["Dich", ",", "und", "uns\u00b7re", "h\u00f6chs\u00b7te", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Deinen Vater, auch dazu.", "tokens": ["Dei\u00b7nen", "Va\u00b7ter", ",", "auch", "da\u00b7zu", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "O der hoch erfrewten Zeit!", "tokens": ["O", "der", "hoch", "er\u00b7frew\u00b7ten", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der uns so fern wil ergetzen", "tokens": ["Der", "uns", "so", "fern", "wil", "er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJD", "VMFIN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Woll' auch, was Euch beyderseit", "tokens": ["Woll'", "auch", ",", "was", "Euch", "bey\u00b7der\u00b7seit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "ADV", "$,", "PWS", "PPER", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch gebricht, gew\u00fcnscht ersetzen,", "tokens": ["Noch", "ge\u00b7bricht", ",", "ge\u00b7w\u00fcnscht", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVPP", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie Ihr mich in Rhue gestelt,", "tokens": ["Wie", "Ihr", "mich", "in", "Rhue", "ge\u00b7stelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPR", "NE", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wunsch des H\u00f6chsten, Trost der Welt.", "tokens": ["Wunsch", "des", "H\u00f6chs\u00b7ten", ",", "Trost", "der", "Welt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Die Rede hatte mir die Sinne so benommen,", "tokens": ["Die", "Re\u00b7de", "hat\u00b7te", "mir", "die", "Sin\u00b7ne", "so", "be\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ich fast zu mir selbst nicht wieder kunte kommen,", "tokens": ["Da\u00df", "ich", "fast", "zu", "mir", "selbst", "nicht", "wie\u00b7der", "kun\u00b7te", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "PTKNEG", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zuletzt besann' ich mich und sagte: Da\u00df must Du,", "tokens": ["Zu\u00b7letzt", "be\u00b7sann'", "ich", "mich", "und", "sag\u00b7te", ":", "Da\u00df", "must", "Du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "KON", "VVFIN", "$.", "KOUS", "VMFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O thewre Heldinn seyn, Du unsers F\u00fcrsten Rhue,", "tokens": ["O", "thew\u00b7re", "Hel\u00b7dinn", "seyn", ",", "Du", "un\u00b7sers", "F\u00fcrs\u00b7ten", "Rhue", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VAINF", "$,", "PPER", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Charlotta, durch die Gunst des Himmels Ihm gegeben", "tokens": ["Char\u00b7lot\u00b7ta", ",", "durch", "die", "Gunst", "des", "Him\u00b7mels", "Ihm", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ART", "NN", "ART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu seyn Sein h\u00f6chster Trost, Sein Auffenthalt und Leben,", "tokens": ["Zu", "seyn", "Sein", "h\u00f6chs\u00b7ter", "Trost", ",", "Sein", "Auf\u00b7fent\u00b7halt", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was aber hat man Dich f\u00fcr Juno angesehn?", "tokens": ["Was", "a\u00b7ber", "hat", "man", "Dich", "f\u00fcr", "Ju\u00b7no", "an\u00b7ge\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "PIS", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Verzeyh', O unser Liecht, was die\u00dffals ist geschehn.", "tokens": ["Ver\u00b7zey\u00b7h'", ",", "O", "un\u00b7ser", "Liecht", ",", "was", "die\u00df\u00b7fals", "ist", "ge\u00b7schehn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "NE", "PPOSAT", "NN", "$,", "PWS", "PDS", "VAFIN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Dein Ansehn, so an Dir nur himmlisch sich er\u00e4uget,", "tokens": ["Dein", "An\u00b7sehn", ",", "so", "an", "Dir", "nur", "himm\u00b7lisch", "sich", "er\u00b7\u00e4u\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "APPR", "PPER", "ADV", "ADJD", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ist dieses Irrthums Schuldt. Zwar Juno hat gezeuget", "tokens": ["Ist", "die\u00b7ses", "Irr\u00b7thums", "Schuldt", ".", "Zwar", "Ju\u00b7no", "hat", "ge\u00b7zeu\u00b7get"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "NN", "NE", "$.", "ADV", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den grimmen Bluthundt Mars, Du bringst an dieses Liecht", "tokens": ["Den", "grim\u00b7men", "Blut\u00b7hundt", "Mars", ",", "Du", "bringst", "an", "die\u00b7ses", "Liecht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den Herren, der uns Huld und Freundligkeit verspricht,", "tokens": ["Den", "Her\u00b7ren", ",", "der", "uns", "Huld", "und", "Freund\u00b7lig\u00b7keit", "ver\u00b7spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Du Ihm angeerbt, Du hast bey dem Gebl\u00fcte", "tokens": ["Die", "Du", "Ihm", "an\u00b7ge\u00b7erbt", ",", "Du", "hast", "bey", "dem", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPER", "VVPP", "$,", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Und hohen Ankunfft auch Dein F\u00fcrstliches Gem\u00fcte,", "tokens": ["Und", "ho\u00b7hen", "An\u00b7kunfft", "auch", "Dein", "F\u00fcrst\u00b7li\u00b7ches", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Gaben Ihm ertheilt. Durch Ha\u00df und wilden Brandt", "tokens": ["Die", "Ga\u00b7ben", "Ihm", "er\u00b7theilt", ".", "Durch", "Ha\u00df", "und", "wil\u00b7den", "Brandt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVFIN", "$.", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Hat Juno, wie man wei\u00df, viel L\u00e4nder umbgewandt", "tokens": ["Hat", "Ju\u00b7no", ",", "wie", "man", "wei\u00df", ",", "viel", "L\u00e4n\u00b7der", "umb\u00b7ge\u00b7wandt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NE", "$,", "PWAV", "PIS", "VVFIN", "$,", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und auff den Grundt zerst\u00f6rt, durch Langmuth Deiner Sinnen", "tokens": ["Und", "auff", "den", "Grundt", "zer\u00b7st\u00f6rt", ",", "durch", "Lang\u00b7muth", "Dei\u00b7ner", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "APPR", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und grosse Liebe wird viel feindliches Beginnen,", "tokens": ["Und", "gros\u00b7se", "Lie\u00b7be", "wird", "viel", "feind\u00b7li\u00b7ches", "Be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "O F\u00fcrstinn, eingestellt, Dein Wunsch ist fort und fort", "tokens": ["O", "F\u00fcrs\u00b7tinn", ",", "ein\u00b7ge\u00b7stellt", ",", "Dein", "Wunsch", "ist", "fort", "und", "fort"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "VVPP", "$,", "PPOSAT", "NN", "VAFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Nur Gl\u00fcck und guter Standt, Du bist ein s\u00fcsser Port", "tokens": ["Nur", "Gl\u00fcck", "und", "gu\u00b7ter", "Standt", ",", "Du", "bist", "ein", "s\u00fcs\u00b7ser", "Port"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Dem, der bedrenget ist. Wer weis sich wol der Armen", "tokens": ["Dem", ",", "der", "be\u00b7dren\u00b7get", "ist", ".", "Wer", "weis", "sich", "wol", "der", "Ar\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "VVFIN", "VAFIN", "$.", "PWS", "PTKVZ", "PRF", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und Widwen so wie Du, O Mutter, zu erbarmen?", "tokens": ["Und", "Wid\u00b7wen", "so", "wie", "Du", ",", "O", "Mut\u00b7ter", ",", "zu", "er\u00b7bar\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "KOKOM", "PPER", "$,", "NE", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die\u00df ist Dein eigen Lob, man tritt kaum vor Dich hin,", "tokens": ["Die\u00df", "ist", "Dein", "ei\u00b7gen", "Lob", ",", "man", "tritt", "kaum", "vor", "Dich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PIS", "VVFIN", "ADV", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So wallt Dir schon das Hertz, und treibet Deinen Sinn", "tokens": ["So", "wallt", "Dir", "schon", "das", "Hertz", ",", "und", "trei\u00b7bet", "Dei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Zu sehn nach H\u00fclff und Rhat, bey aller Noht der Deinen,", "tokens": ["Zu", "sehn", "nach", "H\u00fclff", "und", "Rhat", ",", "bey", "al\u00b7ler", "Noht", "der", "Dei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "KON", "NN", "$,", "APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ob schon die Augen nicht, so mu\u00df Dein Hertz doch weinen", "tokens": ["Ob", "schon", "die", "Au\u00b7gen", "nicht", ",", "so", "mu\u00df", "Dein", "Hertz", "doch", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKNEG", "$,", "ADV", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Au\u00df Wehmut, welche Dich f\u00fcr allen in der Welt", "tokens": ["Au\u00df", "Weh\u00b7mut", ",", "wel\u00b7che", "Dich", "f\u00fcr", "al\u00b7len", "in", "der", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "APPR", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Dem H\u00f6chsten, der Dich liebt, zum n\u00e4chsten hat gestellt", "tokens": ["Dem", "H\u00f6chs\u00b7ten", ",", "der", "Dich", "liebt", ",", "zum", "n\u00e4chs\u00b7ten", "hat", "ge\u00b7stellt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPRART", "ADJA", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und durch kein Gl\u00fcck und Fall wird folgends von ihm trennen,", "tokens": ["Und", "durch", "kein", "Gl\u00fcck", "und", "Fall", "wird", "fol\u00b7gends", "von", "ihm", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "KON", "NN", "VAFIN", "PIS", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Weil Du sehr eiffrig must nach seiner Liebe brennen.", "tokens": ["Weil", "Du", "sehr", "eif\u00b7frig", "must", "nach", "sei\u00b7ner", "Lie\u00b7be", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Das zeugt die Gottes-Furcht, mit der Du Tag und Nacht", "tokens": ["Das", "zeugt", "die", "Got\u00b7tes\u00b7Furcht", ",", "mit", "der", "Du", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die wehrte Zeit verbringst, die Deine beste Macht", "tokens": ["Die", "wehr\u00b7te", "Zeit", "ver\u00b7bringst", ",", "die", "Dei\u00b7ne", "bes\u00b7te", "Macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "F\u00fcr alles Ungl\u00fcck ist. Was aber wil mein Segel", "tokens": ["F\u00fcr", "al\u00b7les", "Un\u00b7gl\u00fcck", "ist", ".", "Was", "a\u00b7ber", "wil", "mein", "Se\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "$.", "PWS", "ADV", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Auff dieses weite Meer? Ich bleib' im stillen Pregel", "tokens": ["Auff", "die\u00b7ses", "wei\u00b7te", "Meer", "?", "Ich", "bleib'", "im", "stil\u00b7len", "Pre\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und lasse nicht mein Boht in solche Wellen ein.", "tokens": ["Und", "las\u00b7se", "nicht", "mein", "Boht", "in", "sol\u00b7che", "Wel\u00b7len", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wer solche Trefligkeit und dieser Gaben Schein", "tokens": ["Wer", "sol\u00b7che", "Tre\u00b7flig\u00b7keit", "und", "die\u00b7ser", "Ga\u00b7ben", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIAT", "NN", "KON", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Zu singen ihm getrawt, mu\u00df so geb\u00fcckt nicht gehen,", "tokens": ["Zu", "sin\u00b7gen", "ihm", "ge\u00b7trawt", ",", "mu\u00df", "so", "ge\u00b7b\u00fcckt", "nicht", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "VVPP", "$,", "VMFIN", "ADV", "VVFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Nicht irrdisch seyn wie ich, mu\u00df k\u00f6nnen sich erh\u00f6hen", "tokens": ["Nicht", "irr\u00b7disch", "seyn", "wie", "ich", ",", "mu\u00df", "k\u00f6n\u00b7nen", "sich", "er\u00b7h\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VAINF", "KOKOM", "PPER", "$,", "VMFIN", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Durch Lufft und Himmel weg. Auch Opitz w\u00fcrde fast", "tokens": ["Durch", "Lufft", "und", "Him\u00b7mel", "weg", ".", "Auch", "O\u00b7pitz", "w\u00fcr\u00b7de", "fast"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$.", "ADV", "NE", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Hierinnen furchtsam seyn und schewen diese Last,", "tokens": ["Hie\u00b7rin\u00b7nen", "furcht\u00b7sam", "seyn", "und", "sche\u00b7wen", "die\u00b7se", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAINF", "KON", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Ob seines Geistes Krafft schon viel bi\u00dfher getragen", "tokens": ["Ob", "sei\u00b7nes", "Geis\u00b7tes", "Krafft", "schon", "viel", "bi\u00df\u00b7her", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADV", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Und sich an manches Lob mit Rhum hat th\u00fcren wagen,", "tokens": ["Und", "sich", "an", "man\u00b7ches", "Lob", "mit", "Rhum", "hat", "th\u00fc\u00b7ren", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIAT", "NN", "APPR", "NN", "VAFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Wozu ich gantz nicht taug. Sey gl\u00fcckhafft umb und an", "tokens": ["Wo\u00b7zu", "ich", "gantz", "nicht", "taug", ".", "Sey", "gl\u00fcck\u00b7hafft", "umb", "und", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "PTKNEG", "VVFIN", "$.", "VAIMP", "ADJD", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und habe, was Dein Hertz ihm w\u00fcnschen sol und kan,", "tokens": ["Und", "ha\u00b7be", ",", "was", "Dein", "Hertz", "ihm", "w\u00fcn\u00b7schen", "sol", "und", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Du Spiegel dieser Zeit! Ich aber wil mich wenden", "tokens": ["Du", "Spie\u00b7gel", "die\u00b7ser", "Zeit", "!", "Ich", "a\u00b7ber", "wil", "mich", "wen\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "PDAT", "NN", "$.", "PPER", "ADV", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Zu meinen Seiten hin, wiewol mit schwachen H\u00e4nden,", "tokens": ["Zu", "mei\u00b7nen", "Sei\u00b7ten", "hin", ",", "wie\u00b7wol", "mit", "schwa\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "KOUS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wil singen, was darauff die Andre hat begunt,", "tokens": ["Wil", "sin\u00b7gen", ",", "was", "dar\u00b7auff", "die", "And\u00b7re", "hat", "be\u00b7gunt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PRELS", "PAV", "ART", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Von der ich dieses nur au\u00df Schwachheit fassen kunt:", "tokens": ["Von", "der", "ich", "die\u00b7ses", "nur", "au\u00df", "Schwach\u00b7heit", "fas\u00b7sen", "kunt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PDS", "ADV", "APPR", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Ob ich mich beth\u00f6rt entz\u00fcnde", "tokens": ["Ob", "ich", "mich", "be\u00b7th\u00f6rt", "ent\u00b7z\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit vergebner Fr\u00f6ligkeit,", "tokens": ["Mit", "ver\u00b7geb\u00b7ner", "Fr\u00f6\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder in der That empfinde,", "tokens": ["O\u00b7der", "in", "der", "That", "emp\u00b7fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wessen sich mein Hertz erfrewt?", "tokens": ["Wes\u00b7sen", "sich", "mein", "Hertz", "er\u00b7frewt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Seyd Ihr kommen oder nicht,", "tokens": ["Seyd", "Ihr", "kom\u00b7men", "o\u00b7der", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "VVINF", "KON", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihr, O unsre Zuversicht?", "tokens": ["Ihr", ",", "O", "uns\u00b7re", "Zu\u00b7ver\u00b7sicht", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Die in Furcht und Hoffnung hangen,", "tokens": ["Die", "in", "Furcht", "und", "Hoff\u00b7nung", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind zu zweiffeln angewehnt,", "tokens": ["Sind", "zu", "zweif\u00b7feln", "an\u00b7ge\u00b7wehnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gl\u00e4uben nicht, wann sie erlangen", "tokens": ["Gl\u00e4u\u00b7ben", "nicht", ",", "wann", "sie", "er\u00b7lan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "PWAV", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df, wornach sie sich gesehnt.", "tokens": ["Da\u00df", ",", "wor\u00b7nach", "sie", "sich", "ge\u00b7sehnt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "PPER", "PRF", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Was man hofft ohn Angst und Pein,", "tokens": ["Was", "man", "hofft", "ohn", "Angst", "und", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Geht gantz ungezweiffelt ein.", "tokens": ["Geht", "gantz", "un\u00b7ge\u00b7zweif\u00b7felt", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Nein, ich seh', es kan nicht triegen,", "tokens": ["Nein", ",", "ich", "seh'", ",", "es", "kan", "nicht", "trie\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine Frewd ist k\u00fcntlich war,", "tokens": ["Mei\u00b7ne", "Frewd", "ist", "k\u00fcnt\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr, mein hertzliches Begn\u00fcgen,", "tokens": ["Ihr", ",", "mein", "hertz\u00b7li\u00b7ches", "Be\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Macht es alles Sonnenklar,", "tokens": ["Macht", "es", "al\u00b7les", "Son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ewer Glantz nimpt meinem Sinn", "tokens": ["E\u00b7wer", "Glantz", "nimpt", "mei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Allen Traum und Irrthum hin.", "tokens": ["Al\u00b7len", "Traum", "und", "Irr\u00b7thum", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Ich bin von Euch \u00fcberf\u00fchret", "tokens": ["Ich", "bin", "von", "Euch", "\u00fc\u00b7berf\u00b7\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ewer s\u00fcssen Gegenwart,", "tokens": ["E\u00b7wer", "s\u00fcs\u00b7sen", "Ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob mir nicht zu thun geb\u00fchret,", "tokens": ["Ob", "mir", "nicht", "zu", "thun", "ge\u00b7b\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was die Zeit her ist erspart?", "tokens": ["Was", "die", "Zeit", "her", "ist", "er\u00b7spart", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APZR", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wend' ich jetzt nicht mein Gem\u00fct'", "tokens": ["Wend'", "ich", "jetzt", "nicht", "mein", "Ge\u00b7m\u00fct'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auff ein s\u00fcsses Frewden-Liedt?", "tokens": ["Auff", "ein", "s\u00fcs\u00b7ses", "Fre\u00b7wden\u00b7Liedt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Ja! was aber wollt, ihr Thr\u00e4nen?", "tokens": ["Ja", "!", "was", "a\u00b7ber", "wollt", ",", "ihr", "Thr\u00e4\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PWS", "ADV", "VMFIN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weinen ist zu zeiten gut,", "tokens": ["Wei\u00b7nen", "ist", "zu", "zei\u00b7ten", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jetzundt must ihr Euch entwehnen,", "tokens": ["Je\u00b7tzundt", "must", "ihr", "Euch", "ent\u00b7weh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine Augen, ewrer Flut,", "tokens": ["Mei\u00b7ne", "Au\u00b7gen", ",", "ew\u00b7rer", "Flut", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Warumb ihr geflossen seydt,", "tokens": ["Wa\u00b7rumb", "ihr", "ge\u00b7flos\u00b7sen", "seydt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "VAFIN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "Hat mich numehr hoch erfrewt.", "tokens": ["Hat", "mich", "nu\u00b7mehr", "hoch", "er\u00b7frewt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Gl\u00e4ubet diesen trewen Zeugen,", "tokens": ["Gl\u00e4u\u00b7bet", "die\u00b7sen", "tre\u00b7wen", "Zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mein Herr Vater, und auch du,", "tokens": ["Mein", "Herr", "Va\u00b7ter", ",", "und", "auch", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "KON", "ADV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00fcsser Bruder, ich wil schweigen,", "tokens": ["S\u00fcs\u00b7ser", "Bru\u00b7der", ",", "ich", "wil", "schwei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Gesicht helt doch nicht Rhue,", "tokens": ["Mein", "Ge\u00b7sicht", "helt", "doch", "nicht", "Rhue", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeigt durch stumme Redner an,", "tokens": ["Zeigt", "durch", "stum\u00b7me", "Red\u00b7ner", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie mein Hertz nach Euch gethan.", "tokens": ["Wie", "mein", "Hertz", "nach", "Euch", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Hat so fr\u00fc' der Sonnen Wagen", "tokens": ["Hat", "so", "fr\u00fc'", "der", "Son\u00b7nen", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Je auch auff zu seyn begehrt,", "tokens": ["Je", "auch", "auff", "zu", "seyn", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PTKZU", "VAINF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich \u00fcber seinen Tagen", "tokens": ["Da\u00df", "ich", "\u00fc\u00b7ber", "sei\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mich zum h\u00f6chsten nicht beschwert", "tokens": ["Mich", "zum", "h\u00f6chs\u00b7ten", "nicht", "be\u00b7schwert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "ADJA", "PTKNEG", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und gefleht umb diesen Tag,", "tokens": ["Und", "ge\u00b7fleht", "umb", "die\u00b7sen", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dar- ich Euch-an-sprechen mag?", "tokens": ["Dar", "ich", "Euch\u00b7an\u00b7spre\u00b7chen", "mag", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["TRUNC", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Keine Ruh hat mich umbfangen,", "tokens": ["Kei\u00b7ne", "Ruh", "hat", "mich", "umb\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und so still war keine Nacht,", "tokens": ["Und", "so", "still", "war", "kei\u00b7ne", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche nicht durch mein Verlangen", "tokens": ["Wel\u00b7che", "nicht", "durch", "mein", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00fcb' und schlafflo\u00df ward gemacht,", "tokens": ["Tr\u00fcb'", "und", "schlaf\u00b7flo\u00df", "ward", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mond' und Sterne wusten schon", "tokens": ["Mond'", "und", "Ster\u00b7ne", "wus\u00b7ten", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Meinen Leid- und Klage-Thon.", "tokens": ["Mei\u00b7nen", "Lei\u00b7d", "und", "Kla\u00b7ge\u00b7Thon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "TRUNC", "KON", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.30": {"line.1": {"text": "Nichts wolt' einen Muth mir geben,", "tokens": ["Nichts", "wolt'", "ei\u00b7nen", "Muth", "mir", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo man aller Lust vergist", "tokens": ["Wo", "man", "al\u00b7ler", "Lust", "ver\u00b7gist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nur Leidt tr\u00e4gt, war mein Leben,", "tokens": ["Und", "nur", "Leidt", "tr\u00e4gt", ",", "war", "mein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVFIN", "$,", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo mir das ein Leben ist,", "tokens": ["Wo", "mir", "das", "ein", "Le\u00b7ben", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "ART", "NN", "VAFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Mein Gebet ohn Ruh und Rast", "tokens": ["Mein", "Ge\u00b7bet", "ohn", "Ruh", "und", "Rast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "War bey Gott nur nicht verhast.", "tokens": ["War", "bey", "Gott", "nur", "nicht", "ver\u00b7hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Numehr habt Ihr zu ermessen,", "tokens": ["Nu\u00b7mehr", "habt", "Ihr", "zu", "er\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie mir wol zu muthe sey,", "tokens": ["Wie", "mir", "wol", "zu", "mu\u00b7the", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aller M\u00fch ist nun vergessen,", "tokens": ["Al\u00b7ler", "M\u00fch", "ist", "nun", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Gem\u00fcth' ist lo\u00df und frey,", "tokens": ["Mein", "Ge\u00b7m\u00fcth'", "ist", "lo\u00df", "und", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schickt der Sorgen Ach und Weh", "tokens": ["Schickt", "der", "Sor\u00b7gen", "Ach", "und", "Weh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auff die Wellen und die See.", "tokens": ["Auff", "die", "Wel\u00b7len", "und", "die", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Meine Stimme mu\u00df sich schwingen", "tokens": ["Mei\u00b7ne", "Stim\u00b7me", "mu\u00df", "sich", "schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch der Wolcken blawes Dach,", "tokens": ["Durch", "der", "Wol\u00b7cken", "bla\u00b7wes", "Dach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber was ich wei\u00df zu singen,", "tokens": ["A\u00b7ber", "was", "ich", "wei\u00df", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich treibe vor und nach", "tokens": ["Was", "ich", "trei\u00b7be", "vor", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "PTKVZ", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist: mein' Hoffnung, Trost und Zier", "tokens": ["Ist", ":", "mein'", "Hoff\u00b7nung", ",", "Trost", "und", "Zier"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$.", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Lebt, Gott Lob, und ist schon hier!", "tokens": ["Lebt", ",", "Gott", "Lob", ",", "und", "ist", "schon", "hier", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "NN", "$,", "KON", "VAFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Wer k\u00f6nte nicht hierau\u00df Dich, O Louyse, kennen?", "tokens": ["Wer", "k\u00f6n\u00b7te", "nicht", "hier\u00b7au\u00df", "Dich", ",", "O", "Lou\u00b7yse", ",", "ken\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "PAV", "PPER", "$,", "NE", "NE", "$,", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und wolte man dich gleich, Princessin, Pallas nennen,", "tokens": ["Und", "wol\u00b7te", "man", "dich", "gleich", ",", "Prin\u00b7ces\u00b7sin", ",", "Pal\u00b7las", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "PRF", "ADV", "$,", "NN", "$,", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was w\u00e4r' es gro\u00df gefehlt? Du bist mit dem begabt", "tokens": ["Was", "w\u00e4r'", "es", "gro\u00df", "ge\u00b7fehlt", "?", "Du", "bist", "mit", "dem", "be\u00b7gabt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADJD", "VVPP", "$.", "PPER", "VAFIN", "APPR", "ART", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das, wie man sagen wil, Minerve hat gehabt,", "tokens": ["Das", ",", "wie", "man", "sa\u00b7gen", "wil", ",", "Mi\u00b7ner\u00b7ve", "hat", "ge\u00b7habt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$,", "NN", "VAFIN", "VAPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Die Wei\u00dfheit, den Verstand: Du bist ein Bild der Jugend,", "tokens": ["Die", "Wei\u00df\u00b7heit", ",", "den", "Ver\u00b7stand", ":", "Du", "bist", "ein", "Bild", "der", "Ju\u00b7gend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Deinen Pracht und Licht, der Zucht geehrte Tugend", "tokens": ["Der", "Dei\u00b7nen", "Pracht", "und", "Licht", ",", "der", "Zucht", "ge\u00b7ehr\u00b7te", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "$,", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wohnt dir so sehr im Sinn und in Geberden bey,", "tokens": ["Wohnt", "dir", "so", "sehr", "im", "Sinn", "und", "in", "Ge\u00b7ber\u00b7den", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "KON", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Als ob sie nirgends sonst denn hie zu finden sey.", "tokens": ["Als", "ob", "sie", "nir\u00b7gends", "sonst", "denn", "hie", "zu", "fin\u00b7den", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die letzte schiene mir sehr frewdig vorzukommen,", "tokens": ["Die", "letz\u00b7te", "schie\u00b7ne", "mir", "sehr", "frew\u00b7dig", "vor\u00b7zu\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von Der ich, ist mir recht, in Einfalt die\u00df vernommen:", "tokens": ["Von", "Der", "ich", ",", "ist", "mir", "recht", ",", "in", "Ein\u00b7falt", "die\u00df", "ver\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "$,", "VAFIN", "PPER", "ADJD", "$,", "APPR", "NN", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Gnug geklaget, gnug geweint!", "tokens": ["Gnug", "ge\u00b7kla\u00b7get", ",", "gnug", "ge\u00b7weint", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kummer, \u00e4rgster Lebens-Feind,", "tokens": ["Kum\u00b7mer", ",", "\u00e4rgs\u00b7ter", "Le\u00b7bens\u00b7Feind", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geh und trolle dich von hinnen!", "tokens": ["Geh", "und", "trol\u00b7le", "dich", "von", "hin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PRF", "APPR", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zweyer Liebsten Ankunfft macht,", "tokens": ["Zwey\u00b7er", "Liebs\u00b7ten", "An\u00b7kunfft", "macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich singe gute Nacht", "tokens": ["Da\u00df", "ich", "sin\u00b7ge", "gu\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Trawrigkeit, du Pest der Sinnen!", "tokens": ["Traw\u00b7rig\u00b7keit", ",", "du", "Pest", "der", "Sin\u00b7nen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "O Herr Vater, s\u00fcsses Heil,", "tokens": ["O", "Herr", "Va\u00b7ter", ",", "s\u00fcs\u00b7ses", "Heil", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und mein Bruder, bestes Theil", "tokens": ["Und", "mein", "Bru\u00b7der", ",", "bes\u00b7tes", "Theil"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser Seelen, so dich liebet,", "tokens": ["Die\u00b7ser", "See\u00b7len", ",", "so", "dich", "lie\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kompt! dem H\u00f6chsten ist bekandt,", "tokens": ["Kompt", "!", "dem", "H\u00f6chs\u00b7ten", "ist", "be\u00b7kandt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie nach Euch sich dieses Landt", "tokens": ["Wie", "nach", "Euch", "sich", "die\u00b7ses", "Landt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "PPER", "PRF", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat gesehnet und betr\u00fcbet.", "tokens": ["Hat", "ge\u00b7seh\u00b7net", "und", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Kompt! mit Euch k\u00f6mpt Frewd' und Gl\u00fcck,", "tokens": ["Kompt", "!", "mit", "Euch", "k\u00f6mpt", "Fre\u00b7wd'", "und", "Gl\u00fcck", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "APPR", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Dieser helle Gnaden-Blick", "tokens": ["Die\u00b7ser", "hel\u00b7le", "Gna\u00b7den\u00b7Blick"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist an stat der g\u00fcldnen Sonnen,", "tokens": ["Ist", "an", "stat", "der", "g\u00fcld\u00b7nen", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich umb die\u00df gantze Feldt", "tokens": ["Die", "sich", "umb", "die\u00df", "gant\u00b7ze", "Feldt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "PDS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weit und breit verborgen helt,", "tokens": ["Weit", "und", "breit", "ver\u00b7bor\u00b7gen", "helt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil es ewren Glantz gewonnen.", "tokens": ["Weil", "es", "ew\u00b7ren", "Glantz", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Auff, Thalia, meine Zier,", "tokens": ["Auff", ",", "Tha\u00b7lia", ",", "mei\u00b7ne", "Zier", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "$,", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Komm und singe neben mir,", "tokens": ["Komm", "und", "sin\u00b7ge", "ne\u00b7ben", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlag auff den ber\u00fchmten Seiten!", "tokens": ["Schlag", "auff", "den", "be\u00b7r\u00fchm\u00b7ten", "Sei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Netze, Herbst, nicht als du thust,", "tokens": ["Net\u00b7ze", ",", "Herbst", ",", "nicht", "als", "du", "thust", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PTKNEG", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kehre dich in Vorjahrs Lust,", "tokens": ["Keh\u00b7re", "dich", "in", "Vor\u00b7jahrs", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Last, ihr Winde, lasst das Streiten!", "tokens": ["Last", ",", "ihr", "Win\u00b7de", ",", "lasst", "das", "Strei\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Komm gefl\u00fcgelt, sanffter Ost,", "tokens": ["Komm", "ge\u00b7fl\u00fc\u00b7gelt", ",", "sanff\u00b7ter", "Ost", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bring durch deiner Stimme Trost", "tokens": ["Bring", "durch", "dei\u00b7ner", "Stim\u00b7me", "Trost"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tulpen, Rosen und Violen!", "tokens": ["Tul\u00b7pen", ",", "Ro\u00b7sen", "und", "Vi\u00b7o\u00b7len", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lachst du meiner Bitte gar?", "tokens": ["Lachst", "du", "mei\u00b7ner", "Bit\u00b7te", "gar", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dencke nach, zu wessen Haar", "tokens": ["Den\u00b7cke", "nach", ",", "zu", "wes\u00b7sen", "Haar"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich mir jetzt wil Blumen holen.", "tokens": ["Ich", "mir", "jetzt", "wil", "Blu\u00b7men", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "VMFIN", "NN", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.39": {"line.1": {"text": "Vater, nimm was dir geb\u00fchrt,", "tokens": ["Va\u00b7ter", ",", "nimm", "was", "dir", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PWS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Den Gehorsam, welcher r\u00fchrt", "tokens": ["Den", "Ge\u00b7hor\u00b7sam", ",", "wel\u00b7cher", "r\u00fchrt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus des Hertzens tieffen H\u00f6len,", "tokens": ["Aus", "des", "Hert\u00b7zens", "tief\u00b7fen", "H\u00f6\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schaw auff meinen trewen Sinn,", "tokens": ["Schaw", "auff", "mei\u00b7nen", "tre\u00b7wen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weissest du nicht wer ich bin?", "tokens": ["Weis\u00b7sest", "du", "nicht", "wer", "ich", "bin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich, die Funcke deiner Seelen.", "tokens": ["Ich", ",", "die", "Fun\u00b7cke", "dei\u00b7ner", "See\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Hertzer Bruder, mich verdreusst,", "tokens": ["Hert\u00b7zer", "Bru\u00b7der", ",", "mich", "ver\u00b7dreusst", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich meiner Liebe Geist", "tokens": ["Da\u00df", "ich", "mei\u00b7ner", "Lie\u00b7be", "Geist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht so mercklich kunt kan geben:", "tokens": ["Nicht", "so", "merck\u00b7lich", "kunt", "kan", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PTKVZ", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meiner Zungen Krafft gebricht,", "tokens": ["Mei\u00b7ner", "Zun\u00b7gen", "Krafft", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Etwas anders wei\u00df ich nicht;", "tokens": ["Et\u00b7was", "an\u00b7ders", "wei\u00df", "ich", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kurtz, ich liebe dich, mein Leben!", "tokens": ["Kurtz", ",", "ich", "lie\u00b7be", "dich", ",", "mein", "Le\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Speis' und Tranck und alle Welt", "tokens": ["Speis'", "und", "Tranck", "und", "al\u00b7le", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward mir au\u00df dem Sinn gestelt,", "tokens": ["Ward", "mir", "au\u00df", "dem", "Sinn", "ge\u00b7stelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine Grabschafft woltt' ich wissen,", "tokens": ["Mei\u00b7ne", "Grab\u00b7schafft", "woltt'", "ich", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als das Fieber, und zuletzt", "tokens": ["Als", "das", "Fie\u00b7ber", ",", "und", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch der Todt schon an dich setzt'", "tokens": ["Auch", "der", "Todt", "schon", "an", "dich", "setzt'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dein Leben wolte schliessen.", "tokens": ["Und", "dein", "Le\u00b7ben", "wol\u00b7te", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Seyt, Ihr Parcen, ja so wildt,", "tokens": ["Seyt", ",", "Ihr", "Par\u00b7cen", ",", "ja", "so", "wildt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt ich, da\u00df ihr ihn, mein Bildt", "tokens": ["Sagt", "ich", ",", "da\u00df", "ihr", "ihn", ",", "mein", "Bildt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir nicht l\u00e4nger hie wolt lassen,", "tokens": ["Mir", "nicht", "l\u00e4n\u00b7ger", "hie", "wolt", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Thut nur dieses, und verleiht,", "tokens": ["Thut", "nur", "die\u00b7ses", ",", "und", "ver\u00b7leiht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "PDAT", "$,", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df wir uns erst beyderseit", "tokens": ["Da\u00df", "wir", "uns", "erst", "bey\u00b7der\u00b7seit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Recht gesegnen und umbfassen.", "tokens": ["Recht", "ge\u00b7seg\u00b7nen", "und", "umb\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Nun, des H\u00f6chsten Vater-Trew", "tokens": ["Nun", ",", "des", "H\u00f6chs\u00b7ten", "Va\u00b7ter\u00b7Trew"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat mein sehnliches Geschrey", "tokens": ["Hat", "mein", "sehn\u00b7li\u00b7ches", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lassen statt vor ihm gewinnen:", "tokens": ["Las\u00b7sen", "statt", "vor", "ihm", "ge\u00b7win\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott und Himmel sind dir hold,", "tokens": ["Gott", "und", "Him\u00b7mel", "sind", "dir", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dein Verh\u00e4ngnus mu\u00df nur Gold", "tokens": ["Dein", "Ver\u00b7h\u00e4ng\u00b7nus", "mu\u00df", "nur", "Gold"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dir zu deinem Leben spinnen.", "tokens": ["Dir", "zu", "dei\u00b7nem", "Le\u00b7ben", "spin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Wol uns allen, wol auch dir!", "tokens": ["Wol", "uns", "al\u00b7len", ",", "wol", "auch", "dir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PIS", "$,", "ADV", "ADV", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was man denckt und sagt allhier,", "tokens": ["Was", "man", "denckt", "und", "sagt", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "KON", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist von ewrem Wolergehen,", "tokens": ["Ist", "von", "ew\u00b7rem", "Wo\u00b7ler\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber niemand wird geschawt,", "tokens": ["A\u00b7ber", "nie\u00b7mand", "wird", "ge\u00b7schawt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der sich neben mir getrawt,", "tokens": ["Der", "sich", "ne\u00b7ben", "mir", "ge\u00b7trawt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPER", "VVPP", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.6": {"text": "Was das Hertz belangt, zu stehen.", "tokens": ["Was", "das", "Hertz", "be\u00b7langt", ",", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVPP", "$,", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Wie, wann zur See Neptun vom Vater Ocean", "tokens": ["Wie", ",", "wann", "zur", "See", "Nep\u00b7tun", "vom", "Va\u00b7ter", "O\u00b7cean"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "PWAV", "APPRART", "NN", "NE", "APPRART", "NN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ber\u00e4uscht nach Hause f\u00e4hrt durch seine nasse Bahn,", "tokens": ["Be\u00b7r\u00e4uscht", "nach", "Hau\u00b7se", "f\u00e4hrt", "durch", "sei\u00b7ne", "nas\u00b7se", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und etwan Triton lesst die See-Trompet erschallen,", "tokens": ["Und", "et\u00b7wan", "Tri\u00b7ton", "lesst", "die", "See\u00b7Trom\u00b7pet", "er\u00b7schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Doris sonderlich zu g\u00fcnstigem Gefallen,", "tokens": ["Der", "Do\u00b7ris", "son\u00b7der\u00b7lich", "zu", "g\u00fcns\u00b7ti\u00b7gem", "Ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die aus den Wellen schawt, die Faunen ohn gefehr", "tokens": ["Die", "aus", "den", "Wel\u00b7len", "schawt", ",", "die", "Fau\u00b7nen", "ohn", "ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als wildes tummes Volck sich umb das Ufer her", "tokens": ["Als", "wil\u00b7des", "tum\u00b7mes", "Volck", "sich", "umb", "das", "U\u00b7fer", "her"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Versamlen, und den Thon best\u00fcrtzt und Sinnlo\u00df h\u00f6ren,", "tokens": ["Ver\u00b7sam\u00b7len", ",", "und", "den", "Thon", "be\u00b7st\u00fcrtzt", "und", "Sinn\u00b7lo\u00df", "h\u00f6\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ART", "NN", "VVPP", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So kam es uns auch vor, was Hedwig da zu ehren", "tokens": ["So", "kam", "es", "uns", "auch", "vor", ",", "was", "Hed\u00b7wig", "da", "zu", "eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$,", "PRELS", "NE", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Den grossen F\u00fcrsten sang, denn Hedwich must' es seyn,", "tokens": ["Den", "gros\u00b7sen", "F\u00fcrs\u00b7ten", "sang", ",", "denn", "Hed\u00b7wich", "must'", "es", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "NE", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So viel die Rede Gab, die durch der Jugend Schein", "tokens": ["So", "viel", "die", "Re\u00b7de", "Gab", ",", "die", "durch", "der", "Ju\u00b7gend", "Schein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und g\u00f6ttliche Gestalt f\u00fcr Clio ward gesch\u00e4tzet.", "tokens": ["Und", "g\u00f6tt\u00b7li\u00b7che", "Ge\u00b7stalt", "f\u00fcr", "Clio", "ward", "ge\u00b7sch\u00e4t\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wir hatten allerseit uns \u00fcber dem entsetzet", "tokens": ["Wir", "hat\u00b7ten", "al\u00b7ler\u00b7seit", "uns", "\u00fc\u00b7ber", "dem", "ent\u00b7set\u00b7zet"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "APPR", "ART", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was vorgelauffen war, und niemand wuste da", "tokens": ["Was", "vor\u00b7ge\u00b7lauf\u00b7fen", "war", ",", "und", "nie\u00b7mand", "wus\u00b7te", "da"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVPP", "VAFIN", "$,", "KON", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was weiter sey zu thun, so das Prussilia,", "tokens": ["Was", "wei\u00b7ter", "sey", "zu", "thun", ",", "so", "das", "Prus\u00b7si\u00b7lia", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "PTKZU", "VVINF", "$,", "ADV", "ART", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Die kurtz zuvor viel Dienst und Pflicht auff sich genommen,", "tokens": ["Die", "kurtz", "zu\u00b7vor", "viel", "Dienst", "und", "Pflicht", "auff", "sich", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "PIAT", "NN", "KON", "NN", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und jederman hiedurch gemeinet vorzukommen,", "tokens": ["Und", "je\u00b7der\u00b7man", "hie\u00b7durch", "ge\u00b7mei\u00b7net", "vor\u00b7zu\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PAV", "VVPP", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Den Muht gantz sincken lie\u00df, sprach ihre V\u00f6lcker an:", "tokens": ["Den", "Muht", "gantz", "sin\u00b7cken", "lie\u00df", ",", "sprach", "ih\u00b7re", "V\u00f6l\u00b7cker", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ihr Kinder, h\u00f6rt und seht, da\u00df mein Thun gar nicht kan", "tokens": ["Ihr", "Kin\u00b7der", ",", "h\u00f6rt", "und", "seht", ",", "da\u00df", "mein", "Thun", "gar", "nicht", "kan"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "KON", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "ADV", "PTKNEG", "VMFIN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Gerahten als es sol, was wir im Sinne hatten,", "tokens": ["Ge\u00b7rah\u00b7ten", "als", "es", "sol", ",", "was", "wir", "im", "Sin\u00b7ne", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "VMFIN", "$,", "PRELS", "PPER", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wird gegen diesem Licht zur Nacht, zu finsterm Schatten.", "tokens": ["Wird", "ge\u00b7gen", "die\u00b7sem", "Licht", "zur", "Nacht", ",", "zu", "fins\u00b7term", "Schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "APPRART", "NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Wer sich mit etwas sonst hierauff hervorthun wil", "tokens": ["Wer", "sich", "mit", "et\u00b7was", "sonst", "hier\u00b7auff", "her\u00b7vor\u00b7thun", "wil"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPR", "PIS", "ADV", "PAV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wird wieder allen Danck zu einem Affen-Spiel", "tokens": ["Wird", "wie\u00b7der", "al\u00b7len", "Danck", "zu", "ei\u00b7nem", "Af\u00b7fen\u00b7Spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und mu\u00df verlachet seyn. Doch wollen wir gedencken,", "tokens": ["Und", "mu\u00df", "ver\u00b7la\u00b7chet", "seyn", ".", "Doch", "wol\u00b7len", "wir", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "VVPP", "VAINF", "$.", "KON", "VMFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Es werden sich auch noch zu unsrer Einfalt lencken", "tokens": ["Es", "wer\u00b7den", "sich", "auch", "noch", "zu", "uns\u00b7rer", "Ein\u00b7falt", "len\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Helden beyderseit, und zeugen durch den Schein", "tokens": ["Die", "Hel\u00b7den", "bey\u00b7der\u00b7seit", ",", "und", "zeu\u00b7gen", "durch", "den", "Schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der Gnaden \u00fcber uns, das Sie auch G\u00f6tter seyn,", "tokens": ["Der", "Gna\u00b7den", "\u00fc\u00b7ber", "uns", ",", "das", "Sie", "auch", "G\u00f6t\u00b7ter", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "PRELS", "PPER", "ADV", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die auff den Willen sehn und nach dem Hertzen fragen,", "tokens": ["Die", "auff", "den", "Wil\u00b7len", "sehn", "und", "nach", "dem", "Hert\u00b7zen", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVINF", "KON", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da\u00df offt bey ihnen wol so viel pflegt zu verschlagen", "tokens": ["Da\u00df", "offt", "bey", "ih\u00b7nen", "wol", "so", "viel", "pflegt", "zu", "ver\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPER", "ADV", "ADV", "ADV", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Als sonst ein feistes Rind, als hundert L\u00e4mmer Blut", "tokens": ["Als", "sonst", "ein", "feis\u00b7tes", "Rind", ",", "als", "hun\u00b7dert", "L\u00e4m\u00b7mer", "Blut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$,", "KOUS", "CARD", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und was der Gottes-Dienst zum Opffer mehr abthut.", "tokens": ["Und", "was", "der", "Got\u00b7tes\u00b7Dienst", "zum", "Opf\u00b7fer", "mehr", "ab\u00b7thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Damit wir aber so nicht von einander giengen,", "tokens": ["Da\u00b7mit", "wir", "a\u00b7ber", "so", "nicht", "von", "ein\u00b7an\u00b7der", "gien\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Trug sie mir auff zuletzt ein Liedchen noch zu singen", "tokens": ["Trug", "sie", "mir", "auff", "zu\u00b7letzt", "ein", "Lied\u00b7chen", "noch", "zu", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ADV", "ART", "NN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Auff solchen Frewden-Tag, zwar anfangs thurst ich nicht,", "tokens": ["Auff", "sol\u00b7chen", "Fre\u00b7wden\u00b7Tag", ",", "zwar", "an\u00b7fangs", "thurst", "ich", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Doch sagt' ich endlich selbst: Gehorsam, Dienst und Pflicht", "tokens": ["Doch", "sagt'", "ich", "end\u00b7lich", "selbst", ":", "Ge\u00b7hor\u00b7sam", ",", "Dienst", "und", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$.", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Mu\u00df seyn so gut es kan, den Willen zu bezeugen", "tokens": ["Mu\u00df", "seyn", "so", "gut", "es", "kan", ",", "den", "Wil\u00b7len", "zu", "be\u00b7zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "ADV", "ADJD", "PPER", "VMFIN", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Erheischt nicht allzeit Kunst. An diesem Tage schweigen,", "tokens": ["Er\u00b7heischt", "nicht", "all\u00b7zeit", "Kunst", ".", "An", "die\u00b7sem", "Ta\u00b7ge", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "NN", "$.", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Da alles singt und lacht, kriegt eines Undancks Lohn,", "tokens": ["Da", "al\u00b7les", "singt", "und", "lacht", ",", "kriegt", "ei\u00b7nes", "Un\u00b7dancks", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Drum fasst' ich einen Muht und sang auff diesen Thon:", "tokens": ["Drum", "fasst'", "ich", "ei\u00b7nen", "Muht", "und", "sang", "auff", "die\u00b7sen", "Thon", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Schallt, ihr helle Feldt-Trompeten!", "tokens": ["Schallt", ",", "ihr", "hel\u00b7le", "Feldt\u00b7Trom\u00b7pe\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blitzt und klinget, ihr Mu\u00dfqueten,", "tokens": ["Blitzt", "und", "klin\u00b7get", ",", "ihr", "Mu\u00df\u00b7que\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasst den wilden Drommel-Schlag", "tokens": ["Lasst", "den", "wil\u00b7den", "Drom\u00b7mel\u00b7Schlag"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns Geh\u00f6r und Sinn bet\u00e4uben!", "tokens": ["Uns", "Ge\u00b7h\u00f6r", "und", "Sinn", "be\u00b7t\u00e4u\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieses Wesen sol man treiben", "tokens": ["Die\u00b7ses", "We\u00b7sen", "sol", "man", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VMFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fort und fort den gantzen Tag!", "tokens": ["Fort", "und", "fort", "den", "gant\u00b7zen", "Tag", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKVZ", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Ihr Carthaunen und Gesch\u00fctze,", "tokens": ["Ihr", "Car\u00b7thau\u00b7nen", "und", "Ge\u00b7sch\u00fct\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wozu seydt ihr hie sonst n\u00fctze?", "tokens": ["Wo\u00b7zu", "seydt", "ihr", "hie", "sonst", "n\u00fct\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasset ewren Donner au\u00df!", "tokens": ["Las\u00b7set", "ew\u00b7ren", "Don\u00b7ner", "au\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lasst das Erdreich sich ersch\u00fcttern,", "tokens": ["Lasst", "das", "Er\u00b7dreich", "sich", "er\u00b7sch\u00fct\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "See und Haff und Pregel zittern,", "tokens": ["See", "und", "Haff", "und", "Pre\u00b7gel", "zit\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und erschreckt der Sternen Hau\u00df!", "tokens": ["Und", "er\u00b7schreckt", "der", "Ster\u00b7nen", "Hau\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Brandenburg, die Zucht der Helden,", "tokens": ["Bran\u00b7den\u00b7burg", ",", "die", "Zucht", "der", "Hel\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan Georg und Fridrich melden,", "tokens": ["Kan", "Ge\u00b7org", "und", "Frid\u00b7rich", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jenen, Vater, diesen, Sohn,", "tokens": ["Je\u00b7nen", ",", "Va\u00b7ter", ",", "die\u00b7sen", ",", "Sohn", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDS", "$,", "NN", "$,", "PDAT", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcrsten, die durch thewre Gaben", "tokens": ["F\u00fcrs\u00b7ten", ",", "die", "durch", "thew\u00b7re", "Ga\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alles \u00fcberstiegen haben,", "tokens": ["Al\u00b7les", "\u00fc\u00b7bers\u00b7tie\u00b7gen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch der hohen Sonnen Thron.", "tokens": ["Auch", "der", "ho\u00b7hen", "Son\u00b7nen", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Diese wil das Land empfangen,", "tokens": ["Die\u00b7se", "wil", "das", "Land", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsers Hertzogthums Verlangen,", "tokens": ["Un\u00b7sers", "Hert\u00b7zog\u00b7thums", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Solche Herren, welcher Prei\u00df", "tokens": ["Sol\u00b7che", "Her\u00b7ren", ",", "wel\u00b7cher", "Prei\u00df"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch der Alten Lob bezwinget", "tokens": ["Auch", "der", "Al\u00b7ten", "Lob", "be\u00b7zwin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und mit hellen Stralen dringet", "tokens": ["Und", "mit", "hel\u00b7len", "Stra\u00b7len", "drin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch der weiten Erden Krey\u00df.", "tokens": ["Durch", "der", "wei\u00b7ten", "Er\u00b7den", "Krey\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Lasst uns keiner Frewde sparen!", "tokens": ["Lasst", "uns", "kei\u00b7ner", "Frew\u00b7de", "spa\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ihr geht mit greisen Haren,", "tokens": ["Die", "ihr", "geht", "mit", "grei\u00b7sen", "Ha\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ihr an den Br\u00fcsten seyt,", "tokens": ["Die", "ihr", "an", "den", "Br\u00fcs\u00b7ten", "seyt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00fctter, J\u00fcngling' und Jungfrawen,", "tokens": ["M\u00fct\u00b7ter", ",", "J\u00fcng\u00b7ling'", "und", "Jung\u00b7fra\u00b7wen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "KON", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Arm und Reich, ihr m\u00fcsset schawen,", "tokens": ["Arm", "und", "Reich", ",", "ihr", "m\u00fcs\u00b7set", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Nach gew\u00fcnschter Fr\u00f6ligkeit.", "tokens": ["Nach", "ge\u00b7w\u00fcnschter", "Fr\u00f6\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.51": {"line.1": {"text": "Lasst der Kurtzweil Zaum und Z\u00fcgel,", "tokens": ["Lasst", "der", "Kurt\u00b7zweil", "Zaum", "und", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwingt den Zorn, und schiebt den Riegel", "tokens": ["Zwingt", "den", "Zorn", ",", "und", "schiebt", "den", "Rie\u00b7gel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Allen bleichen Sorgen vor,", "tokens": ["Al\u00b7len", "blei\u00b7chen", "Sor\u00b7gen", "vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ladet ein gew\u00fcnschte Sachen,", "tokens": ["La\u00b7det", "ein", "ge\u00b7w\u00fcnschte", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Sperret auff f\u00fcr Schertz und Lachen", "tokens": ["Sper\u00b7ret", "auff", "f\u00fcr", "Schertz", "und", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hin und wieder Th\u00fcr und Thor.", "tokens": ["Hin", "und", "wie\u00b7der", "Th\u00fcr", "und", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Euch, Ihr Helden, blo\u00df zu ehren,", "tokens": ["Euch", ",", "Ihr", "Hel\u00b7den", ",", "blo\u00df", "zu", "eh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euch lesst Jung und Alt sich h\u00f6ren,", "tokens": ["Euch", "lesst", "Jung", "und", "Alt", "sich", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "ADJD", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Euch wird keiner Lust gespart:", "tokens": ["Euch", "wird", "kei\u00b7ner", "Lust", "ge\u00b7spart", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was in H\u00e4usern jetzt geschiehet,", "tokens": ["Was", "in", "H\u00e4u\u00b7sern", "jetzt", "ge\u00b7schie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was man auff den Stra\u00dfen siehet,", "tokens": ["Was", "man", "auff", "den", "Stra\u00b7\u00dfen", "sie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "K\u00f6mpt von Ewrer Gegenwart.", "tokens": ["K\u00f6mpt", "von", "Ew\u00b7rer", "Ge\u00b7gen\u00b7wart", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Was, Ihr Lichter, werdet sp\u00fcren", "tokens": ["Was", ",", "Ihr", "Lich\u00b7ter", ",", "wer\u00b7det", "sp\u00fc\u00b7ren"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWS", "$,", "PPOSAT", "NN", "$,", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In den Fenstern, vor den Th\u00fcren,", "tokens": ["In", "den", "Fens\u00b7tern", ",", "vor", "den", "Th\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nimpt Euch s\u00e4mptlich fr\u00f6lich an,", "tokens": ["Nimpt", "Euch", "s\u00e4mpt\u00b7lich", "fr\u00f6\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kompt, O Hoffnung, wird gesungen", "tokens": ["Kompt", ",", "O", "Hoff\u00b7nung", ",", "wird", "ge\u00b7sun\u00b7gen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "NE", "NN", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mit der Kehlen, mit der Zungen,", "tokens": ["Mit", "der", "Keh\u00b7len", ",", "mit", "der", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit dem Hertzen wie man kan.", "tokens": ["Mit", "dem", "Hert\u00b7zen", "wie", "man", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KOKOM", "PIS", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Dieser Reuterey Gepr\u00e4nge,", "tokens": ["Die\u00b7ser", "Reu\u00b7te\u00b7rey", "Ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses Wesen, das Gedr\u00e4nge", "tokens": ["Die\u00b7ses", "We\u00b7sen", ",", "das", "Ge\u00b7dr\u00e4n\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Scheinet etwas zwar zu seyn,", "tokens": ["Schei\u00b7net", "et\u00b7was", "zwar", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber dieses geht vor allen,", "tokens": ["A\u00b7ber", "die\u00b7ses", "geht", "vor", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das man h\u00f6rt einhellig schallen:", "tokens": ["Das", "man", "h\u00f6rt", "ein\u00b7hel\u00b7lig", "schal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsre H\u00e4upter ziehen ein.", "tokens": ["Uns\u00b7re", "H\u00e4up\u00b7ter", "zie\u00b7hen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Der Himmel wil mir wol, ich kan von Gl\u00fccke sagen,", "tokens": ["Der", "Him\u00b7mel", "wil", "mir", "wol", ",", "ich", "kan", "von", "Gl\u00fc\u00b7cke", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "$,", "PPER", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mars mag zufrieden seyn, da\u00df Deutschland sich mu\u00df klagen,", "tokens": ["Mars", "mag", "zu\u00b7frie\u00b7den", "seyn", ",", "da\u00df", "Deutschland", "sich", "mu\u00df", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADJD", "VAINF", "$,", "KOUS", "NE", "PRF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sein Leid nicht ab kan sehn, mag stillen seinen Muth,", "tokens": ["Sein", "Leid", "nicht", "ab", "kan", "sehn", ",", "mag", "stil\u00b7len", "sei\u00b7nen", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "PTKVZ", "VMFIN", "VVINF", "$,", "VMFIN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der uners\u00e4ttigt ist mit Raub' und MenschenBlut,", "tokens": ["Der", "un\u00b7er\u00b7s\u00e4t\u00b7tigt", "ist", "mit", "Raub'", "und", "Men\u00b7schen", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "APPR", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Weil das Verh\u00e4ngnu\u00df ja es anders nicht wil leiden.", "tokens": ["Weil", "das", "Ver\u00b7h\u00e4ng\u00b7nu\u00df", "ja", "es", "an\u00b7ders", "nicht", "wil", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "PPER", "ADV", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hie gleichwol f\u00e4hlt es ihm, ich wei\u00df mich zu bescheiden", "tokens": ["Hie", "gleich\u00b7wol", "f\u00e4hlt", "es", "ihm", ",", "ich", "wei\u00df", "mich", "zu", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So einer Huld und Gunst, dergleichen man kaum hat,", "tokens": ["So", "ei\u00b7ner", "Huld", "und", "Gunst", ",", "derg\u00b7lei\u00b7chen", "man", "kaum", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "NN", "$,", "PIS", "PIS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wozu denn sonderlich Dein Glimpf und kluger Rhat", "tokens": ["Wo\u00b7zu", "denn", "son\u00b7der\u00b7lich", "Dein", "Glimpf", "und", "klu\u00b7ger", "Rhat"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADJD", "PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Beh\u00fclfflich wolte seyn, Du Held von dem Gebl\u00fcte", "tokens": ["Be\u00b7h\u00fclf\u00b7flich", "wol\u00b7te", "seyn", ",", "Du", "Held", "von", "dem", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "VAINF", "$,", "PPER", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der hohen Brennen, Du, den Tapfferkeit und G\u00fcte", "tokens": ["Der", "ho\u00b7hen", "Bren\u00b7nen", ",", "Du", ",", "den", "Tapf\u00b7fer\u00b7keit", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "$,", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Weit \u00fcber F\u00fcrsten hebt, Du dieser Zeiten Lust,", "tokens": ["Weit", "\u00fc\u00b7ber", "F\u00fcrs\u00b7ten", "hebt", ",", "Du", "die\u00b7ser", "Zei\u00b7ten", "Lust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVFIN", "$,", "PPER", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und Bild der Vorigen. Schaw was Du jetzund thust,", "tokens": ["Und", "Bild", "der", "Vo\u00b7ri\u00b7gen", ".", "Schaw", "was", "Du", "je\u00b7tzund", "thust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "$.", "NN", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+--++-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Dich d\u00fcnckt, es were nichts in Friede mich zu setzen,", "tokens": ["Dich", "d\u00fcnckt", ",", "es", "we\u00b7re", "nichts", "in", "Frie\u00b7de", "mich", "zu", "set\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIS", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wenn Deine Gegenwart mich auch nicht solt' ergetzen", "tokens": ["Wenn", "Dei\u00b7ne", "Ge\u00b7gen\u00b7wart", "mich", "auch", "nicht", "solt'", "er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "ADV", "PTKNEG", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und zeugen, das Dein Sinn die Treu auff mich gewandt", "tokens": ["Und", "zeu\u00b7gen", ",", "das", "Dein", "Sinn", "die", "Treu", "auff", "mich", "ge\u00b7wandt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "ART", "NN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Als je bi\u00dfher ein Volck an Herren hat erkant,", "tokens": ["Als", "je", "bi\u00df\u00b7her", "ein", "Volck", "an", "Her\u00b7ren", "hat", "er\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die g\u00f6ttlich sind wie Du. Und wessen werd' ich innen?", "tokens": ["Die", "g\u00f6tt\u00b7lich", "sind", "wie", "Du", ".", "Und", "wes\u00b7sen", "werd'", "ich", "in\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KOKOM", "PPER", "$.", "KON", "VVINF", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Dein Sohn, der F\u00fcrsten Prei\u00df und Spiegel deiner Sinnen,", "tokens": ["Dein", "Sohn", ",", "der", "F\u00fcrs\u00b7ten", "Prei\u00df", "und", "Spie\u00b7gel", "dei\u00b7ner", "Sin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "NN", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die Hoffnung aller Welt und meine Zuversicht,", "tokens": ["Die", "Hoff\u00b7nung", "al\u00b7ler", "Welt", "und", "mei\u00b7ne", "Zu\u00b7ver\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "K\u00f6mpt auch und g\u00f6nnt einmahl mir seines Glantzes Licht,", "tokens": ["K\u00f6mpt", "auch", "und", "g\u00f6nnt", "ein\u00b7mahl", "mir", "sei\u00b7nes", "Glant\u00b7zes", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "ADV", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der wahren Liebe Pfandt. O eine grosse Gnade!", "tokens": ["Der", "wah\u00b7ren", "Lie\u00b7be", "Pfandt", ".", "O", "ei\u00b7ne", "gros\u00b7se", "Gna\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$.", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ein Zeugnus thewrer Huld und Freundligkeit! gerade", "tokens": ["Ein", "Zeug\u00b7nus", "thew\u00b7rer", "Huld", "und", "Freund\u00b7lig\u00b7keit", "!", "ge\u00b7ra\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Als in der Fewers-Brunst ein treuer Vater thut,", "tokens": ["Als", "in", "der", "Fe\u00b7wer\u00b7sBrunst", "ein", "treu\u00b7er", "Va\u00b7ter", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der zwar das eine Kind wil retten aus der Glut,", "tokens": ["Der", "zwar", "das", "ei\u00b7ne", "Kind", "wil", "ret\u00b7ten", "aus", "der", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ART", "NN", "VMFIN", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Doch f\u00fcr das ander auch, so der Gefahr entgangen,", "tokens": ["Doch", "f\u00fcr", "das", "an\u00b7der", "auch", ",", "so", "der", "Ge\u00b7fahr", "ent\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJD", "ADV", "$,", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Nicht minder Sorge tr\u00e4gt, indem es aus Verlangen", "tokens": ["Nicht", "min\u00b7der", "Sor\u00b7ge", "tr\u00e4gt", ",", "in\u00b7dem", "es", "aus", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "NN", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die Armlein nach ihm streckt und ohn auffh\u00f6ren klagt", "tokens": ["Die", "Arm\u00b7lein", "nach", "ihm", "streckt", "und", "ohn", "auff\u00b7h\u00f6\u00b7ren", "klagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "KON", "APPR", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Au\u00df Kummer, da\u00df er sich hat in den Brand gewagt,", "tokens": ["Au\u00df", "Kum\u00b7mer", ",", "da\u00df", "er", "sich", "hat", "in", "den", "Brand", "ge\u00b7wagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "PPER", "PRF", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So thut ihr gleichfals mir. Wie wil ich an Euch beyden", "tokens": ["So", "thut", "ihr", "gleich\u00b7fals", "mir", ".", "Wie", "wil", "ich", "an", "Euch", "bey\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPER", "$.", "PWAV", "VMFIN", "PPER", "APPR", "PPER", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ergetzen Hertz und Sinn, wil Seel' und Augen weiden,", "tokens": ["Er\u00b7get\u00b7zen", "Hertz", "und", "Sinn", ",", "wil", "Seel'", "und", "Au\u00b7gen", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$,", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wil sagen ungeschewt und aller Frewden voll,", "tokens": ["Wil", "sa\u00b7gen", "un\u00b7ge\u00b7schewt", "und", "al\u00b7ler", "Frew\u00b7den", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADJD", "KON", "PIAT", "NN", "ADJD", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.32": {"text": "Wie ich durch Euch erlangt das, was ich kan und sol.", "tokens": ["Wie", "ich", "durch", "Euch", "er\u00b7langt", "das", ",", "was", "ich", "kan", "und", "sol", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "VVFIN", "PDS", "$,", "PWS", "PPER", "VMFIN", "KON", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Nur zieht in Gnaden ein! Ihr seyd auch diesem Lande", "tokens": ["Nur", "zieht", "in", "Gna\u00b7den", "ein", "!", "Ihr", "seyd", "auch", "die\u00b7sem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Der Trost, so ihm geh\u00f6rt, seyd mir auch mit dem Bande", "tokens": ["Der", "Trost", ",", "so", "ihm", "ge\u00b7h\u00f6rt", ",", "seyd", "mir", "auch", "mit", "dem", "Ban\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Der Liebe fest verkn\u00fcpfft. Die\u00df edle Hertzogthum", "tokens": ["Der", "Lie\u00b7be", "fest", "ver\u00b7kn\u00fcpfft", ".", "Die\u00df", "ed\u00b7le", "Hert\u00b7zog\u00b7thum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVPP", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Heist Ewrentwegen so, Ihr Preussens h\u00f6chster Ruhm,", "tokens": ["Heist", "E\u00b7wrent\u00b7we\u00b7gen", "so", ",", "Ihr", "Preus\u00b7sens", "h\u00f6chs\u00b7ter", "Ruhm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Zieht ein und nemet war, wie alles Euch zu Ehren,", "tokens": ["Zieht", "ein", "und", "ne\u00b7met", "war", ",", "wie", "al\u00b7les", "Euch", "zu", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "KON", "VVFIN", "VAFIN", "$,", "PWAV", "PIS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Die Lufft, das Haff, die See sich lesst mit St\u00fcrmen h\u00f6ren!", "tokens": ["Die", "Lufft", ",", "das", "Haff", ",", "die", "See", "sich", "lesst", "mit", "St\u00fcr\u00b7men", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "PRF", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Der Herbst thut was er sol, er giebt dennoch bescheidt", "tokens": ["Der", "Herbst", "thut", "was", "er", "sol", ",", "er", "giebt", "den\u00b7noch", "be\u00b7scheidt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PWS", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "So gut er kan und mag, da\u00df Ihr zugegen seyd.", "tokens": ["So", "gut", "er", "kan", "und", "mag", ",", "da\u00df", "Ihr", "zu\u00b7ge\u00b7gen", "seyd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VMFIN", "KON", "VMFIN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Dies mercket Cynthia, drumb macht sie sich zur Stunde", "tokens": ["Dies", "mer\u00b7cket", "Cyn\u00b7thia", ",", "drumb", "macht", "sie", "sich", "zur", "Stun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NE", "$,", "PAV", "VVFIN", "PPER", "PRF", "APPRART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.42": {"text": "Zu ihrem J\u00e4ger-Volck, und nimpt die besten Hunde,", "tokens": ["Zu", "ih\u00b7rem", "J\u00e4\u00b7ger\u00b7Volck", ",", "und", "nimpt", "die", "bes\u00b7ten", "Hun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "H\u00e4lt fertig allen Zeug, schawt fleissig auff und wacht,", "tokens": ["H\u00e4lt", "fer\u00b7tig", "al\u00b7len", "Zeug", ",", "schawt", "fleis\u00b7sig", "auff", "und", "wacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PIAT", "NN", "$,", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Ob etwan Euch geliebt den Ernst der Wilden Schlacht", "tokens": ["Ob", "et\u00b7wan", "Euch", "ge\u00b7liebt", "den", "Ernst", "der", "Wil\u00b7den", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "VVPP", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Mit einer freyen Lust des Jagens zu vertauschen.", "tokens": ["Mit", "ei\u00b7ner", "frey\u00b7en", "Lust", "des", "Ja\u00b7gens", "zu", "ver\u00b7tau\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Man h\u00f6rt noch hie und da der B\u00e4ume Bl\u00e4tter rauschen,", "tokens": ["Man", "h\u00f6rt", "noch", "hie", "und", "da", "der", "B\u00e4u\u00b7me", "Bl\u00e4t\u00b7ter", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "KON", "ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Der B\u00e4ume, die ihr Laub nicht g\u00e4ntzlich hingelegt,", "tokens": ["Der", "B\u00e4u\u00b7me", ",", "die", "ihr", "Laub", "nicht", "g\u00e4ntz\u00b7lich", "hin\u00b7ge\u00b7legt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Es wird f\u00fcr Euch, Ihr auch der W\u00e4lder Pracht, gehegt.", "tokens": ["Es", "wird", "f\u00fcr", "Euch", ",", "Ihr", "auch", "der", "W\u00e4l\u00b7der", "Pracht", ",", "ge\u00b7hegt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "$,", "PPER", "ADV", "ART", "NN", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Nun kommt Ihr Helden? ja, ich aber mu\u00df gestehen,", "tokens": ["Nun", "kommt", "Ihr", "Hel\u00b7den", "?", "ja", ",", "ich", "a\u00b7ber", "mu\u00df", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "PTKANT", "$,", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Wie pr\u00e4chtig ich nun gleich Euch wolt' entgegen gehen,", "tokens": ["Wie", "pr\u00e4ch\u00b7tig", "ich", "nun", "gleich", "Euch", "wolt'", "ent\u00b7ge\u00b7gen", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ADV", "PPER", "VMFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Bezeugen meine Pflicht, mich schm\u00fccken umb und an,", "tokens": ["Be\u00b7zeu\u00b7gen", "mei\u00b7ne", "Pflicht", ",", "mich", "schm\u00fc\u00b7cken", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Da\u00df aller Witz und Kunst nichts dessen finden kan,", "tokens": ["Da\u00df", "al\u00b7ler", "Witz", "und", "Kunst", "nichts", "des\u00b7sen", "fin\u00b7den", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "KON", "NN", "PIS", "PDS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Was Ewre Zier erheischt, Doch weil auch alle Gaben,", "tokens": ["Was", "Ew\u00b7re", "Zier", "er\u00b7heischt", ",", "Doch", "weil", "auch", "al\u00b7le", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "KON", "KOUS", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "So dieses Leben f\u00fchrt, nicht das Verm\u00f6gen haben,", "tokens": ["So", "die\u00b7ses", "Le\u00b7ben", "f\u00fchrt", ",", "nicht", "das", "Ver\u00b7m\u00f6\u00b7gen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "$,", "PTKNEG", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Wird Ewre G\u00f6ttligkeit, Ihr meines Hertzens Schein,", "tokens": ["Wird", "Ew\u00b7re", "G\u00f6tt\u00b7lig\u00b7keit", ",", "Ihr", "mei\u00b7nes", "Hert\u00b7zens", "Schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Da\u00df mehr als g\u00fclden ist, gef\u00e4llig lassen seyn.", "tokens": ["Da\u00df", "mehr", "als", "g\u00fcl\u00b7den", "ist", ",", "ge\u00b7f\u00e4l\u00b7lig", "las\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KOKOM", "ADJD", "VAFIN", "$,", "ADJD", "VVINF", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Die\u00df hat Prussilia mich newlich h\u00f6ren lassen,", "tokens": ["Die\u00df", "hat", "Prus\u00b7si\u00b7lia", "mich", "new\u00b7lich", "h\u00f6\u00b7ren", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "PPER", "ADJD", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.58": {"text": "Auff die Art redte sie, so viel ich kunte fassen,", "tokens": ["Auff", "die", "Art", "red\u00b7te", "sie", ",", "so", "viel", "ich", "kun\u00b7te", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$,", "ADV", "ADV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Da dieses Helden-Paar au\u00df Brennus grossem Stamm',", "tokens": ["Da", "die\u00b7ses", "Hel\u00b7den\u00b7Paar", "au\u00df", "Bren\u00b7nus", "gros\u00b7sem", "Stamm'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "O Vaterland, bey dir hereingezogen kam", "tokens": ["O", "Va\u00b7ter\u00b7land", ",", "bey", "dir", "her\u00b7ein\u00b7ge\u00b7zo\u00b7gen", "kam"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "APPR", "PPER", "VVIZU", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Und unsern Wunsch erf\u00fcllt. Als sie noch kaum geendet", "tokens": ["Und", "un\u00b7sern", "Wunsch", "er\u00b7f\u00fcllt", ".", "Als", "sie", "noch", "kaum", "ge\u00b7en\u00b7det"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$.", "KOUS", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Die Worte, hat sie sich zum Nagot erst gewendet,", "tokens": ["Die", "Wor\u00b7te", ",", "hat", "sie", "sich", "zum", "Na\u00b7got", "erst", "ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "PPER", "PRF", "APPRART", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Dann zu dem Pregel hin, sie rief der Alle zu,", "tokens": ["Dann", "zu", "dem", "Pre\u00b7gel", "hin", ",", "sie", "rief", "der", "Al\u00b7le", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$,", "PPER", "VVFIN", "ART", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Auch, M\u00fcmmel, dir und sprach: Seyd ihr bi\u00dfher in Rhue", "tokens": ["Auch", ",", "M\u00fcm\u00b7mel", ",", "dir", "und", "sprach", ":", "Seyd", "ihr", "bi\u00df\u00b7her", "in", "Rhue"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "PPER", "KON", "VVFIN", "$.", "VAIMP", "PPER", "ADV", "APPR", "NE"], "meter": "-+-+-++-+--+", "measure": "iambic.hexa.chol"}, "line.65": {"text": "Und stiller Sicherheit bi\u00df in die See geflossen?", "tokens": ["Und", "stil\u00b7ler", "Si\u00b7cher\u00b7heit", "bi\u00df", "in", "die", "See", "ge\u00b7flos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.66": {"text": "Habt durch die Wiesen euch mit stoltzer Flut ergossen?", "tokens": ["Habt", "durch", "die", "Wie\u00b7sen", "euch", "mit", "stolt\u00b7zer", "Flut", "er\u00b7gos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "An beyden Ufern her der Nymphen Liedt geh\u00f6rt,", "tokens": ["An", "bey\u00b7den", "U\u00b7fern", "her", "der", "Nym\u00b7phen", "Liedt", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APZR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die Faunen lustig seyn? hat Phoebus euch geehrt?", "tokens": ["Die", "Fau\u00b7nen", "lus\u00b7tig", "seyn", "?", "hat", "Phoe\u00b7bus", "euch", "ge\u00b7ehrt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAINF", "$.", "VAFIN", "NE", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Wil sich Diane gern der Jagt und M\u00fch entladen", "tokens": ["Wil", "sich", "Di\u00b7a\u00b7ne", "gern", "der", "Jagt", "und", "M\u00fch", "ent\u00b7la\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "NE", "ADV", "ART", "VVFIN", "KON", "NN", "VVPP"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.70": {"text": "Mit ihren Najaden in ewren Str\u00f6men baden?", "tokens": ["Mit", "ih\u00b7ren", "Na\u00b7ja\u00b7den", "in", "ew\u00b7ren", "Str\u00f6\u00b7men", "ba\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.71": {"text": "Tr\u00e4gt ewer R\u00fccken Goldt und unersch\u00f6pftes Gut?", "tokens": ["Tr\u00e4gt", "e\u00b7wer", "R\u00fc\u00b7cken", "Goldt", "und", "un\u00b7er\u00b7sch\u00f6pf\u00b7tes", "Gut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Schl\u00e4gt alle Welt hier zu, sucht Nahrung, Schutz und Hut", "tokens": ["Schl\u00e4gt", "al\u00b7le", "Welt", "hier", "zu", ",", "sucht", "Nah\u00b7rung", ",", "Schutz", "und", "Hut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "ADV", "PTKVZ", "$,", "VVFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Und findet was sie sol? besorgt sich keiner Waffen,", "tokens": ["Und", "fin\u00b7det", "was", "sie", "sol", "?", "be\u00b7sorgt", "sich", "kei\u00b7ner", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PPER", "VMFIN", "$.", "VVFIN", "PRF", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Kan aller Sorgen frey jetzt wachen, jetzund schlaffen?", "tokens": ["Kan", "al\u00b7ler", "Sor\u00b7gen", "frey", "jetzt", "wa\u00b7chen", ",", "je\u00b7tzund", "schlaf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "ADJD", "ADV", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Seht, Kinder, Dieses Haupt, das solche Rhue uns schenckt,", "tokens": ["Seht", ",", "Kin\u00b7der", ",", "Die\u00b7ses", "Haupt", ",", "das", "sol\u00b7che", "Rhue", "uns", "schenckt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "PDAT", "NN", "$,", "PRELS", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Hat jetzt in Gnaden sich hieher zu uns gelenckt", "tokens": ["Hat", "jetzt", "in", "Gna\u00b7den", "sich", "hie\u00b7her", "zu", "uns", "ge\u00b7lenckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "NN", "PRF", "PAV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Und dieses Land erfrewt. Auff! uns wil jetzt geb\u00fchren,", "tokens": ["Und", "die\u00b7ses", "Land", "er\u00b7frewt", ".", "Auff", "!", "uns", "wil", "jetzt", "ge\u00b7b\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "$.", "NN", "$.", "PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.78": {"text": "So viel als m\u00f6glich ist, Sie pr\u00e4chtig einzuf\u00fchren", "tokens": ["So", "viel", "als", "m\u00f6g\u00b7lich", "ist", ",", "Sie", "pr\u00e4ch\u00b7tig", "ein\u00b7zu\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIAT", "KOKOM", "ADJD", "VAFIN", "$,", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Und den Gehorsam so zu geben an den Tag,", "tokens": ["Und", "den", "Ge\u00b7hor\u00b7sam", "so", "zu", "ge\u00b7ben", "an", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Ein jedes schicke sich so gut es kan und mag,", "tokens": ["Ein", "je\u00b7des", "schi\u00b7cke", "sich", "so", "gut", "es", "kan", "und", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VVFIN", "PRF", "ADV", "ADJD", "PPER", "VMFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Und ziehe statlich auff, wer unter Euch wird siegen,", "tokens": ["Und", "zie\u00b7he", "stat\u00b7lich", "auff", ",", "wer", "un\u00b7ter", "Euch", "wird", "sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$,", "PWS", "APPR", "PPER", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Der sol zu Lohn mein Bild von klarem Bernstein kriegen.", "tokens": ["Der", "sol", "zu", "Lohn", "mein", "Bild", "von", "kla\u00b7rem", "Bern\u00b7stein", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Sie wurden s\u00e4mptlich fro und stelleten sich dar,", "tokens": ["Sie", "wur\u00b7den", "s\u00e4mpt\u00b7lich", "fro", "und", "stel\u00b7le\u00b7ten", "sich", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD", "KON", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Eins tritt dem andern vor, es scheint ihr Bart und Haar", "tokens": ["Eins", "tritt", "dem", "an\u00b7dern", "vor", ",", "es", "scheint", "ihr", "Bart", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "PTKVZ", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Nur Gra\u00df und Schilff zu seyn. Der Nagot wolte pralen", "tokens": ["Nur", "Gra\u00df", "und", "Schilff", "zu", "seyn", ".", "Der", "Na\u00b7got", "wol\u00b7te", "pra\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN", "PTKZU", "VAINF", "$.", "ART", "NE", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Und hat ein sch\u00f6nes Schlo\u00df ihm k\u00fcnstlich lassen mahlen,", "tokens": ["Und", "hat", "ein", "sch\u00f6\u00b7nes", "Schlo\u00df", "ihm", "k\u00fcnst\u00b7lich", "las\u00b7sen", "mah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "PPER", "ADJD", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Daneben auch wie ihn der Weichsel-Strom erzeugt", "tokens": ["Da\u00b7ne\u00b7ben", "auch", "wie", "ihn", "der", "Weich\u00b7sel\u00b7Strom", "er\u00b7zeugt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "KOKOM", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Durch einer Nymphen Gunst, die jetzt ihm noch geneigt.", "tokens": ["Durch", "ei\u00b7ner", "Nym\u00b7phen", "Gunst", ",", "die", "jetzt", "ihm", "noch", "ge\u00b7neigt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Der Pregel aber wolt' hierinnen keinem weichen,", "tokens": ["Der", "Pre\u00b7gel", "a\u00b7ber", "wolt'", "hie\u00b7rin\u00b7nen", "kei\u00b7nem", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PAV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Trug einen Lorber-Krantz, der K\u00fcnste sch\u00f6nes Zeichen,", "tokens": ["Trug", "ei\u00b7nen", "Lor\u00b7ber\u00b7Krantz", ",", "der", "K\u00fcns\u00b7te", "sch\u00f6\u00b7nes", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Die er f\u00fcr andern n\u00e4hrt, auch Wahren allerhand", "tokens": ["Die", "er", "f\u00fcr", "an\u00b7dern", "n\u00e4hrt", ",", "auch", "Wah\u00b7ren", "al\u00b7ler\u00b7hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PIS", "VVFIN", "$,", "ADV", "NN", "PIAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Und G\u00fcter, die dem West und Norden sind bekant.", "tokens": ["Und", "G\u00fc\u00b7ter", ",", "die", "dem", "West", "und", "Nor\u00b7den", "sind", "be\u00b7kant", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "ART", "NN", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Ihm folgt der M\u00fcmmel-Strom gebraten von der Sonnen,", "tokens": ["Ihm", "folgt", "der", "M\u00fcm\u00b7mel\u00b7Strom", "ge\u00b7bra\u00b7ten", "von", "der", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Tr\u00e4gt reiches Korn und Flachs, und was er sonst gewonnen", "tokens": ["Tr\u00e4gt", "rei\u00b7ches", "Korn", "und", "Flachs", ",", "und", "was", "er", "sonst", "ge\u00b7won\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJA", "NN", "KON", "NN", "$,", "KON", "PWS", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Durch seiner Russen flei\u00df, f\u00fchrt nach sich auff der Fahrt", "tokens": ["Durch", "sei\u00b7ner", "Rus\u00b7sen", "flei\u00df", ",", "f\u00fchrt", "nach", "sich", "auff", "der", "Fahrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "APPR", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Die Dudey und Schalmey, und B\u00e4ren vieler Art.", "tokens": ["Die", "Du\u00b7dey", "und", "Schal\u00b7mey", ",", "und", "B\u00e4\u00b7ren", "vie\u00b7ler", "Art", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "KON", "NN", "PIAT", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.97": {"text": "Die All' hatt' ihren Schmuck, zu welchem du auch kamest,", "tokens": ["Die", "All'", "hatt'", "ih\u00b7ren", "Schmuck", ",", "zu", "wel\u00b7chem", "du", "auch", "ka\u00b7mest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "PPOSAT", "NN", "$,", "APPR", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.98": {"text": "Du der Passargen-Flu\u00df, drangst dich hinzu und nahmest", "tokens": ["Du", "der", "Pas\u00b7sar\u00b7gen\u00b7Flu\u00df", ",", "drangst", "dich", "hin\u00b7zu", "und", "nah\u00b7mest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Den letzten Platz nicht ein. Sie stehen allerseit", "tokens": ["Den", "letz\u00b7ten", "Platz", "nicht", "ein", ".", "Sie", "ste\u00b7hen", "al\u00b7ler\u00b7seit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKVZ", "$.", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und f\u00fchren, wie geschiht, des Vorzugs halben Streit,", "tokens": ["Und", "f\u00fch\u00b7ren", ",", "wie", "ge\u00b7schiht", ",", "des", "Vor\u00b7zugs", "hal\u00b7ben", "Streit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "PWAV", "VVPP", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Als unverhofft ein Glantz und Leuchten sie umbgiebet.", "tokens": ["Als", "un\u00b7ver\u00b7hofft", "ein", "Glantz", "und", "Leuch\u00b7ten", "sie", "umb\u00b7gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Da vormals Juppiter die Semelen geliebet,", "tokens": ["Da", "vor\u00b7mals", "Jup\u00b7pi\u00b7ter", "die", "Se\u00b7me\u00b7len", "ge\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.103": {"text": "Sol er in solchem Plitz und hellen Glantzes Schein", "tokens": ["Sol", "er", "in", "sol\u00b7chem", "Plitz", "und", "hel\u00b7len", "Glant\u00b7zes", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "NN", "KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "In solchen Stralen nicht zu ihr gekommen seyn.", "tokens": ["In", "sol\u00b7chen", "Stra\u00b7len", "nicht", "zu", "ihr", "ge\u00b7kom\u00b7men", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKNEG", "APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Prussilia erschrickt. Hierauff hat man vernommen,", "tokens": ["Prus\u00b7si\u00b7lia", "er\u00b7schrickt", ".", "Hier\u00b7auff", "hat", "man", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$.", "PAV", "VAFIN", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.106": {"text": "Da\u00df drey G\u00f6ttinnen selbst ins Mittel seyn gekommen,", "tokens": ["Da\u00df", "drey", "G\u00f6t\u00b7tin\u00b7nen", "selbst", "ins", "Mit\u00b7tel", "seyn", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "ADV", "APPRART", "NN", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Die Erste ward vorau\u00df durch Trefligkeit und Pracht", "tokens": ["Die", "Ers\u00b7te", "ward", "vor\u00b7au\u00df", "durch", "Tre\u00b7flig\u00b7keit", "und", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "F\u00fcr Juno angesehn, dann wie bey heller Nacht", "tokens": ["F\u00fcr", "Ju\u00b7no", "an\u00b7ge\u00b7sehn", ",", "dann", "wie", "bey", "hel\u00b7ler", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$,", "ADV", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Des Mondens Kertze gl\u00e4ntzt, so sahe man auch scheinen", "tokens": ["Des", "Mon\u00b7dens", "Kert\u00b7ze", "gl\u00e4ntzt", ",", "so", "sa\u00b7he", "man", "auch", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Die Ihr am n\u00e4chsten stundt, ich muste g\u00e4ntzlich meinen,", "tokens": ["Die", "Ihr", "am", "n\u00e4chs\u00b7ten", "stundt", ",", "ich", "mus\u00b7te", "g\u00e4ntz\u00b7lich", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "ADJA", "VVFIN", "$,", "PPER", "VMFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Sie were Pallas gar, die Dritte, welcher Zier", "tokens": ["Sie", "we\u00b7re", "Pal\u00b7las", "gar", ",", "die", "Drit\u00b7te", ",", "wel\u00b7cher", "Zier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "NE", "ADV", "$,", "ART", "ADJA", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und Tugendt mich nicht treugt, gleich, edle Clio, dir.", "tokens": ["Und", "Tu\u00b7gendt", "mich", "nicht", "treugt", ",", "gleich", ",", "ed\u00b7le", "Clio", ",", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "PPER", "PTKNEG", "VVFIN", "$,", "ADV", "$,", "ADJA", "NN", "$,", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.113": {"text": "Sie sind f\u00fcr allen frey hin zu den F\u00fcrsten gangen,", "tokens": ["Sie", "sind", "f\u00fcr", "al\u00b7len", "frey", "hin", "zu", "den", "F\u00fcrs\u00b7ten", "gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "ADJD", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Und haben insgesampt Sie, unsern Schutz empfangen", "tokens": ["Und", "ha\u00b7ben", "ins\u00b7ge\u00b7sampt", "Sie", ",", "un\u00b7sern", "Schutz", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PPER", "$,", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Mit Reden, die ich nicht au\u00df Schwachheit mercken kan,", "tokens": ["Mit", "Re\u00b7den", ",", "die", "ich", "nicht", "au\u00df", "Schwach\u00b7heit", "mer\u00b7cken", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Doch hub die Erste fast mit diesen Worten an,", "tokens": ["Doch", "hub", "die", "Ers\u00b7te", "fast", "mit", "die\u00b7sen", "Wor\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADV", "APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Die sich au\u00df Ihrem Mund als einem Quel ergossen", "tokens": ["Die", "sich", "au\u00df", "Ih\u00b7rem", "Mund", "als", "ei\u00b7nem", "Quel", "er\u00b7gos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "KOKOM", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Und wie ein Honig-Seim und Nectar vor sich flossen:", "tokens": ["Und", "wie", "ein", "Ho\u00b7nig\u00b7Seim", "und", "Nec\u00b7tar", "vor", "sich", "flos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "F\u00fcrsten h\u00e4lt der Himmel Schutz", "tokens": ["F\u00fcrs\u00b7ten", "h\u00e4lt", "der", "Him\u00b7mel", "Schutz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mehr als sonst gemeinen Leuten,", "tokens": ["Mehr", "als", "sonst", "ge\u00b7mei\u00b7nen", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df Bellonen Macht und Trutz", "tokens": ["La\u00df", "Bel\u00b7lo\u00b7nen", "Macht", "und", "Trutz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch so grimmig sie bestreiten,", "tokens": ["Noch", "so", "grim\u00b7mig", "sie", "be\u00b7strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihre starcke Gegenwehr", "tokens": ["Ih\u00b7re", "star\u00b7cke", "Ge\u00b7gen\u00b7wehr"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist der Himmel und sein Heer.", "tokens": ["Ist", "der", "Him\u00b7mel", "und", "sein", "Heer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Held, den meine Seel erkiest,", "tokens": ["Held", ",", "den", "mei\u00b7ne", "Seel", "er\u00b7kiest", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dessen Gegenwart mein Leben", "tokens": ["Des\u00b7sen", "Ge\u00b7gen\u00b7wart", "mein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd mein h\u00f6chster Wolstand ist,", "tokens": ["Vnd", "mein", "h\u00f6chs\u00b7ter", "Wol\u00b7stand", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht gedencke darumb eben,", "tokens": ["Nicht", "ge\u00b7den\u00b7cke", "da\u00b7rumb", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PAV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das, weil du gefochten hast,", "tokens": ["Das", ",", "weil", "du", "ge\u00b7foch\u00b7ten", "hast", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ich geschwebt in Ruh und Rast:", "tokens": ["Ich", "ge\u00b7schwebt", "in", "Ruh", "und", "Rast", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Hat Penthesileen Macht", "tokens": ["Hat", "Pen\u00b7the\u00b7si\u00b7leen", "Macht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "NE", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Mich nicht an den Feind gehetzet,", "tokens": ["Mich", "nicht", "an", "den", "Feind", "ge\u00b7het\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hab' ich nicht in wilder Schlacht", "tokens": ["Hab'", "ich", "nicht", "in", "wil\u00b7der", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Spie\u00df und Schwerdt wie sie genetzet,", "tokens": ["Spie\u00df", "und", "Schwerdt", "wie", "sie", "ge\u00b7net\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KOKOM", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ey, so hab' ich doch gethan", "tokens": ["Ey", ",", "so", "hab'", "ich", "doch", "ge\u00b7than"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Was ich nur thun sol und kan.", "tokens": ["Was", "ich", "nur", "thun", "sol", "und", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVINF", "VMFIN", "KON", "VMFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.59": {"line.1": {"text": "Fragstu was? mein Feld-Geschrey", "tokens": ["Frags\u00b7tu", "was", "?", "mein", "Feld\u00b7Ge\u00b7schrey"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "PWS", "$.", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War in hitzigen Gebeten,", "tokens": ["War", "in", "hit\u00b7zi\u00b7gen", "Ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ich hiesse st\u00fcndlich frey", "tokens": ["Die", "ich", "hies\u00b7se", "st\u00fcnd\u00b7lich", "frey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "ADJD", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor den Thron des H\u00f6chsten treten,", "tokens": ["Vor", "den", "Thron", "des", "H\u00f6chs\u00b7ten", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meiner Pfeile Krafft und Kunst", "tokens": ["Mei\u00b7ner", "Pfei\u00b7le", "Krafft", "und", "Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "War der heissen Seufftzer Brunst.", "tokens": ["War", "der", "heis\u00b7sen", "Seufft\u00b7zer", "Brunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Meiner Thr\u00e4nen strenge Fluth,", "tokens": ["Mei\u00b7ner", "Thr\u00e4\u00b7nen", "stren\u00b7ge", "Fluth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die kein Augen-blick gehemmet,", "tokens": ["Die", "kein", "Au\u00b7gen\u00b7blick", "ge\u00b7hem\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat des Feindes Ubermuth", "tokens": ["Hat", "des", "Fein\u00b7des", "U\u00b7ber\u00b7muth"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehr als einmal fortgeschwemmet,", "tokens": ["Mehr", "als", "ein\u00b7mal", "fort\u00b7ge\u00b7schwem\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df sein Fundt und schlawer Raht", "tokens": ["Da\u00df", "sein", "Fundt", "und", "schla\u00b7wer", "Raht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nie sein Ziel erreichet hat.", "tokens": ["Nie", "sein", "Ziel", "er\u00b7rei\u00b7chet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Also bin ich jederzeit", "tokens": ["Al\u00b7so", "bin", "ich", "je\u00b7der\u00b7zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Th\u00e4tig, Heldt, wie du gewesen,", "tokens": ["Th\u00e4\u00b7tig", ",", "Heldt", ",", "wie", "du", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NE", "$,", "PWAV", "PPER", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und hab' einig das Geleit", "tokens": ["Und", "hab'", "ei\u00b7nig", "das", "Ge\u00b7leit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dir zu geben mir erlesen,", "tokens": ["Dir", "zu", "ge\u00b7ben", "mir", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Keiner Waffen wiederstandt", "tokens": ["Kei\u00b7ner", "Waf\u00b7fen", "wie\u00b7der\u00b7standt"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat mich von dir abgewandt.", "tokens": ["Hat", "mich", "von", "dir", "ab\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Meiner Sorgen M\u00fch und Flei\u00df", "tokens": ["Mei\u00b7ner", "Sor\u00b7gen", "M\u00fch", "und", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Folgte wo du bist geritten,", "tokens": ["Folg\u00b7te", "wo", "du", "bist", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWAV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wiederwillen, Staub und Schwei\u00df", "tokens": ["Wie\u00b7der\u00b7wil\u00b7len", ",", "Staub", "und", "Schwei\u00df"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab' ich auch wie du erlitten,", "tokens": ["Hab'", "ich", "auch", "wie", "du", "er\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "KOKOM", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Allen Kummer, Furcht und Pein", "tokens": ["Al\u00b7len", "Kum\u00b7mer", ",", "Furcht", "und", "Pein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht ich mir von wegen dein.", "tokens": ["Macht", "ich", "mir", "von", "we\u00b7gen", "dein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "APPR", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Ich war fertig, allem Thun", "tokens": ["Ich", "war", "fer\u00b7tig", ",", "al\u00b7lem", "Thun"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PIS", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit Gedancken vorzukommen,", "tokens": ["Mit", "Ge\u00b7dan\u00b7cken", "vor\u00b7zu\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses, sagt' ich, hat er nun,", "tokens": ["Die\u00b7ses", ",", "sagt'", "ich", ",", "hat", "er", "nun", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nachmals das ihm vorgenommen,", "tokens": ["Nach\u00b7mals", "das", "ihm", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jetzt gebeut er seiner Schar,", "tokens": ["Jetzt", "ge\u00b7beut", "er", "sei\u00b7ner", "Schar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Jetzt ger\u00e4ht er in Gefahr.", "tokens": ["Jetzt", "ge\u00b7r\u00e4ht", "er", "in", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Dein behertzter Helden-Sinn", "tokens": ["Dein", "be\u00b7hertz\u00b7ter", "Hel\u00b7den\u00b7Sinn"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dein au\u00dfge\u00fcbter Degen", "tokens": ["Und", "dein", "au\u00df\u00b7ge\u00b7\u00fcb\u00b7ter", "De\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Geht zwar frey und sicher hin", "tokens": ["Geht", "zwar", "frey", "und", "si\u00b7cher", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "ADJD", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und hat unten nie gelegen,", "tokens": ["Und", "hat", "un\u00b7ten", "nie", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber darumb, O mein Liecht,", "tokens": ["A\u00b7ber", "da\u00b7rumb", ",", "O", "mein", "Liecht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "NE", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bin ich frey von Furchten nicht.", "tokens": ["Bin", "ich", "frey", "von", "Furch\u00b7ten", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Ithacus hat Sieg und Prei\u00df", "tokens": ["It\u00b7ha\u00b7cus", "hat", "Sieg", "und", "Prei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wieder seinen Feind erhalten", "tokens": ["Wie\u00b7der", "sei\u00b7nen", "Feind", "er\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sein Lieb mu\u00df wie ein Ei\u00df", "tokens": ["Und", "sein", "Lieb", "mu\u00df", "wie", "ein", "Ei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "KOKOM", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uber Ihm daheim erkalten,", "tokens": ["U\u00b7ber", "Ihm", "da\u00b7heim", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch Achilles sieget wol,", "tokens": ["Auch", "A\u00b7chil\u00b7les", "sie\u00b7get", "wol", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Noch ist Thetis \u00e4ngsten vol.", "tokens": ["Noch", "ist", "The\u00b7tis", "\u00e4ngs\u00b7ten", "vol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "Nun, der gern mich h\u00f6ret, Gott,", "tokens": ["Nun", ",", "der", "gern", "mich", "h\u00f6\u00b7ret", ",", "Gott", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "ADV", "PPER", "VVFIN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Den ich darumb stets gepriesen,", "tokens": ["Den", "ich", "da\u00b7rumb", "stets", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PAV", "ADV", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Hat mich jetzt auch nicht mit Spott'", "tokens": ["Hat", "mich", "jetzt", "auch", "nicht", "mit", "Spott'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Verachtung abgewiesen,", "tokens": ["Und", "Ver\u00b7ach\u00b7tung", "ab\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schafft, da\u00df ich auff diesen Tag", "tokens": ["Schafft", ",", "da\u00df", "ich", "auff", "die\u00b7sen", "Tag"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich, mein Leben, sprechen mag.", "tokens": ["Dich", ",", "mein", "Le\u00b7ben", ",", "spre\u00b7chen", "mag."], "token_info": ["word", "punct", "word", "word", "punct", "word", "abbreviation"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.67": {"line.1": {"text": "Der gehofften Sonnen Schein", "tokens": ["Der", "ge\u00b7hoff\u00b7ten", "Son\u00b7nen", "Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan zur See nach rauhem wehen", "tokens": ["Kan", "zur", "See", "nach", "rau\u00b7hem", "we\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Leuten so gew\u00fcnscht nicht seyn,", "tokens": ["Leu\u00b7ten", "so", "ge\u00b7w\u00fcnscht", "nicht", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "PTKNEG", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als, nachdem ich dich gesehen,", "tokens": ["Als", ",", "nach\u00b7dem", "ich", "dich", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mich auff mein gehabtes Leidt", "tokens": ["Mich", "auff", "mein", "ge\u00b7hab\u00b7tes", "Leidt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Deine Gegenwart erfrewt.", "tokens": ["Dei\u00b7ne", "Ge\u00b7gen\u00b7wart", "er\u00b7frewt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Gott, der in uns n\u00e4hrt die Glut", "tokens": ["Gott", ",", "der", "in", "uns", "n\u00e4hrt", "die", "Glut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieser heissen Liebes-Flammen,", "tokens": ["Die\u00b7ser", "heis\u00b7sen", "Lie\u00b7bes\u00b7Flam\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasse ja durch seine Hut", "tokens": ["Las\u00b7se", "ja", "durch", "sei\u00b7ne", "Hut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns nach diesem nicht von sammen,", "tokens": ["Uns", "nach", "die\u00b7sem", "nicht", "von", "sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PDAT", "PTKNEG", "APPR", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Keines Gl\u00fcckes wieder-Sinn", "tokens": ["Kei\u00b7nes", "Gl\u00fc\u00b7ckes", "wie\u00b7der\u00b7Sinn"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nehme mir dein Beysein hin.", "tokens": ["Neh\u00b7me", "mir", "dein", "Bey\u00b7se\u00b7in", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.69": {"line.1": {"text": "Aber du, mein thewres Pfandt,", "tokens": ["A\u00b7ber", "du", ",", "mein", "thew\u00b7res", "Pfandt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sohn, durch den Wir sind genesen,", "tokens": ["Sohn", ",", "durch", "den", "Wir", "sind", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Es ist einig Gott bekant,", "tokens": ["Es", "ist", "ei\u00b7nig", "Gott", "be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie mir da zu Muth gewesen,", "tokens": ["Wie", "mir", "da", "zu", "Muth", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als die siche Lager stat", "tokens": ["Als", "die", "si\u00b7che", "La\u00b7ger", "stat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich fast hingenommen hatt'?", "tokens": ["Dich", "fast", "hin\u00b7ge\u00b7nom\u00b7men", "hatt'", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Ich entbrandte vor Begier", "tokens": ["Ich", "ent\u00b7brand\u00b7te", "vor", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich in gegenwart zu schawen,", "tokens": ["Dich", "in", "ge\u00b7gen\u00b7wart", "zu", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "----+---", "measure": "unknown.measure.single"}, "line.3": {"text": "Doch du warest fern von hier,", "tokens": ["Doch", "du", "wa\u00b7rest", "fern", "von", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "APPR", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Keiner Botschafft wolt' ich trawen,", "tokens": ["Kei\u00b7ner", "Bot\u00b7schafft", "wolt'", "ich", "tra\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Anders wolte mir nichts ein,", "tokens": ["An\u00b7ders", "wol\u00b7te", "mir", "nichts", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als du w\u00fcrdest todt schon seyn.", "tokens": ["Als", "du", "w\u00fcr\u00b7dest", "todt", "schon", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "M\u00f6cht ich, hub ich an, mein Kind,", "tokens": ["M\u00f6cht", "ich", ",", "hub", "ich", "an", ",", "mein", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich zu guter letzt noch k\u00fcssen,", "tokens": ["Dich", "zu", "gu\u00b7ter", "letzt", "noch", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jetzt, da wir geschieden sind,", "tokens": ["Jetzt", ",", "da", "wir", "ge\u00b7schie\u00b7den", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Kan ich dich nicht einmal gr\u00fcssen,", "tokens": ["Kan", "ich", "dich", "nicht", "ein\u00b7mal", "gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wei\u00df nicht, wo durch meine Trew", "tokens": ["Wei\u00df", "nicht", ",", "wo", "durch", "mei\u00b7ne", "Trew"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Etwa dir zu rathen sey.", "tokens": ["Et\u00b7wa", "dir", "zu", "ra\u00b7then", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "Ach! wie sehnlich wirstu nun", "tokens": ["Ach", "!", "wie", "sehn\u00b7lich", "wirs\u00b7tu", "nun"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "PWAV", "ADJD", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Verlangen nach mir tragen,", "tokens": ["Ein", "Ver\u00b7lan\u00b7gen", "nach", "mir", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wilt, ich sol dir Rettung thun,", "tokens": ["Wilt", ",", "ich", "sol", "dir", "Ret\u00b7tung", "thun", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PPER", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hast mir die\u00df und das zu sagen,", "tokens": ["Hast", "mir", "die\u00df", "und", "das", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "KON", "PDS", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ruffst mir, bi\u00df dir Krafft gebricht,", "tokens": ["Ruffst", "mir", ",", "bi\u00df", "dir", "Krafft", "ge\u00b7bricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aber Ach! ich h\u00f6r' es nicht.", "tokens": ["A\u00b7ber", "Ach", "!", "ich", "h\u00f6r'", "es", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ITJ", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.73": {"line.1": {"text": "Doch thut hie auch Gottes Hand", "tokens": ["Doch", "thut", "hie", "auch", "Got\u00b7tes", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was ich mir gew\u00fcnscht, mein Flehen", "tokens": ["Was", "ich", "mir", "ge\u00b7w\u00fcnscht", ",", "mein", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "PPER", "VVPP", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat er also umbgewandt,", "tokens": ["Hat", "er", "al\u00b7so", "umb\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ich dich, mein Schatz, kan sehen,", "tokens": ["Da\u00df", "ich", "dich", ",", "mein", "Schatz", ",", "kan", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "$,", "PPOSAT", "NN", "$,", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich, und unsre h\u00f6chste Rhue,", "tokens": ["Dich", ",", "und", "uns\u00b7re", "h\u00f6chs\u00b7te", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Deinen Vater, auch dazu.", "tokens": ["Dei\u00b7nen", "Va\u00b7ter", ",", "auch", "da\u00b7zu", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.74": {"line.1": {"text": "O der hoch erfrewten Zeit!", "tokens": ["O", "der", "hoch", "er\u00b7frew\u00b7ten", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der uns so fern wil ergetzen", "tokens": ["Der", "uns", "so", "fern", "wil", "er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJD", "VMFIN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Woll' auch, was Euch beyderseit", "tokens": ["Woll'", "auch", ",", "was", "Euch", "bey\u00b7der\u00b7seit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "ADV", "$,", "PWS", "PPER", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch gebricht, gew\u00fcnscht ersetzen,", "tokens": ["Noch", "ge\u00b7bricht", ",", "ge\u00b7w\u00fcnscht", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVPP", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie Ihr mich in Rhue gestelt,", "tokens": ["Wie", "Ihr", "mich", "in", "Rhue", "ge\u00b7stelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPR", "NE", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wunsch des H\u00f6chsten, Trost der Welt.", "tokens": ["Wunsch", "des", "H\u00f6chs\u00b7ten", ",", "Trost", "der", "Welt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "Die Rede hatte mir die Sinne so benommen,", "tokens": ["Die", "Re\u00b7de", "hat\u00b7te", "mir", "die", "Sin\u00b7ne", "so", "be\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ich fast zu mir selbst nicht wieder kunte kommen,", "tokens": ["Da\u00df", "ich", "fast", "zu", "mir", "selbst", "nicht", "wie\u00b7der", "kun\u00b7te", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "PTKNEG", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zuletzt besann' ich mich und sagte: Da\u00df must Du,", "tokens": ["Zu\u00b7letzt", "be\u00b7sann'", "ich", "mich", "und", "sag\u00b7te", ":", "Da\u00df", "must", "Du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "KON", "VVFIN", "$.", "KOUS", "VMFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O thewre Heldinn seyn, Du unsers F\u00fcrsten Rhue,", "tokens": ["O", "thew\u00b7re", "Hel\u00b7dinn", "seyn", ",", "Du", "un\u00b7sers", "F\u00fcrs\u00b7ten", "Rhue", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VAINF", "$,", "PPER", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Charlotta, durch die Gunst des Himmels Ihm gegeben", "tokens": ["Char\u00b7lot\u00b7ta", ",", "durch", "die", "Gunst", "des", "Him\u00b7mels", "Ihm", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ART", "NN", "ART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu seyn Sein h\u00f6chster Trost, Sein Auffenthalt und Leben,", "tokens": ["Zu", "seyn", "Sein", "h\u00f6chs\u00b7ter", "Trost", ",", "Sein", "Auf\u00b7fent\u00b7halt", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was aber hat man Dich f\u00fcr Juno angesehn?", "tokens": ["Was", "a\u00b7ber", "hat", "man", "Dich", "f\u00fcr", "Ju\u00b7no", "an\u00b7ge\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "PIS", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Verzeyh', O unser Liecht, was die\u00dffals ist geschehn.", "tokens": ["Ver\u00b7zey\u00b7h'", ",", "O", "un\u00b7ser", "Liecht", ",", "was", "die\u00df\u00b7fals", "ist", "ge\u00b7schehn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "NE", "PPOSAT", "NN", "$,", "PWS", "PDS", "VAFIN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Dein Ansehn, so an Dir nur himmlisch sich er\u00e4uget,", "tokens": ["Dein", "An\u00b7sehn", ",", "so", "an", "Dir", "nur", "himm\u00b7lisch", "sich", "er\u00b7\u00e4u\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "APPR", "PPER", "ADV", "ADJD", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ist dieses Irrthums Schuldt. Zwar Juno hat gezeuget", "tokens": ["Ist", "die\u00b7ses", "Irr\u00b7thums", "Schuldt", ".", "Zwar", "Ju\u00b7no", "hat", "ge\u00b7zeu\u00b7get"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "NN", "NE", "$.", "ADV", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den grimmen Bluthundt Mars, Du bringst an dieses Liecht", "tokens": ["Den", "grim\u00b7men", "Blut\u00b7hundt", "Mars", ",", "Du", "bringst", "an", "die\u00b7ses", "Liecht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den Herren, der uns Huld und Freundligkeit verspricht,", "tokens": ["Den", "Her\u00b7ren", ",", "der", "uns", "Huld", "und", "Freund\u00b7lig\u00b7keit", "ver\u00b7spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Du Ihm angeerbt, Du hast bey dem Gebl\u00fcte", "tokens": ["Die", "Du", "Ihm", "an\u00b7ge\u00b7erbt", ",", "Du", "hast", "bey", "dem", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPER", "VVPP", "$,", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Und hohen Ankunfft auch Dein F\u00fcrstliches Gem\u00fcte,", "tokens": ["Und", "ho\u00b7hen", "An\u00b7kunfft", "auch", "Dein", "F\u00fcrst\u00b7li\u00b7ches", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Gaben Ihm ertheilt. Durch Ha\u00df und wilden Brandt", "tokens": ["Die", "Ga\u00b7ben", "Ihm", "er\u00b7theilt", ".", "Durch", "Ha\u00df", "und", "wil\u00b7den", "Brandt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVFIN", "$.", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Hat Juno, wie man wei\u00df, viel L\u00e4nder umbgewandt", "tokens": ["Hat", "Ju\u00b7no", ",", "wie", "man", "wei\u00df", ",", "viel", "L\u00e4n\u00b7der", "umb\u00b7ge\u00b7wandt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NE", "$,", "PWAV", "PIS", "VVFIN", "$,", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und auff den Grundt zerst\u00f6rt, durch Langmuth Deiner Sinnen", "tokens": ["Und", "auff", "den", "Grundt", "zer\u00b7st\u00f6rt", ",", "durch", "Lang\u00b7muth", "Dei\u00b7ner", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "APPR", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und grosse Liebe wird viel feindliches Beginnen,", "tokens": ["Und", "gros\u00b7se", "Lie\u00b7be", "wird", "viel", "feind\u00b7li\u00b7ches", "Be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "O F\u00fcrstinn, eingestellt, Dein Wunsch ist fort und fort", "tokens": ["O", "F\u00fcrs\u00b7tinn", ",", "ein\u00b7ge\u00b7stellt", ",", "Dein", "Wunsch", "ist", "fort", "und", "fort"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "VVPP", "$,", "PPOSAT", "NN", "VAFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Nur Gl\u00fcck und guter Standt, Du bist ein s\u00fcsser Port", "tokens": ["Nur", "Gl\u00fcck", "und", "gu\u00b7ter", "Standt", ",", "Du", "bist", "ein", "s\u00fcs\u00b7ser", "Port"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Dem, der bedrenget ist. Wer weis sich wol der Armen", "tokens": ["Dem", ",", "der", "be\u00b7dren\u00b7get", "ist", ".", "Wer", "weis", "sich", "wol", "der", "Ar\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "VVFIN", "VAFIN", "$.", "PWS", "PTKVZ", "PRF", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und Widwen so wie Du, O Mutter, zu erbarmen?", "tokens": ["Und", "Wid\u00b7wen", "so", "wie", "Du", ",", "O", "Mut\u00b7ter", ",", "zu", "er\u00b7bar\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "KOKOM", "PPER", "$,", "NE", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die\u00df ist Dein eigen Lob, man tritt kaum vor Dich hin,", "tokens": ["Die\u00df", "ist", "Dein", "ei\u00b7gen", "Lob", ",", "man", "tritt", "kaum", "vor", "Dich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PIS", "VVFIN", "ADV", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So wallt Dir schon das Hertz, und treibet Deinen Sinn", "tokens": ["So", "wallt", "Dir", "schon", "das", "Hertz", ",", "und", "trei\u00b7bet", "Dei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Zu sehn nach H\u00fclff und Rhat, bey aller Noht der Deinen,", "tokens": ["Zu", "sehn", "nach", "H\u00fclff", "und", "Rhat", ",", "bey", "al\u00b7ler", "Noht", "der", "Dei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "KON", "NN", "$,", "APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ob schon die Augen nicht, so mu\u00df Dein Hertz doch weinen", "tokens": ["Ob", "schon", "die", "Au\u00b7gen", "nicht", ",", "so", "mu\u00df", "Dein", "Hertz", "doch", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKNEG", "$,", "ADV", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Au\u00df Wehmut, welche Dich f\u00fcr allen in der Welt", "tokens": ["Au\u00df", "Weh\u00b7mut", ",", "wel\u00b7che", "Dich", "f\u00fcr", "al\u00b7len", "in", "der", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "APPR", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Dem H\u00f6chsten, der Dich liebt, zum n\u00e4chsten hat gestellt", "tokens": ["Dem", "H\u00f6chs\u00b7ten", ",", "der", "Dich", "liebt", ",", "zum", "n\u00e4chs\u00b7ten", "hat", "ge\u00b7stellt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPRART", "ADJA", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und durch kein Gl\u00fcck und Fall wird folgends von ihm trennen,", "tokens": ["Und", "durch", "kein", "Gl\u00fcck", "und", "Fall", "wird", "fol\u00b7gends", "von", "ihm", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "KON", "NN", "VAFIN", "PIS", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Weil Du sehr eiffrig must nach seiner Liebe brennen.", "tokens": ["Weil", "Du", "sehr", "eif\u00b7frig", "must", "nach", "sei\u00b7ner", "Lie\u00b7be", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Das zeugt die Gottes-Furcht, mit der Du Tag und Nacht", "tokens": ["Das", "zeugt", "die", "Got\u00b7tes\u00b7Furcht", ",", "mit", "der", "Du", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die wehrte Zeit verbringst, die Deine beste Macht", "tokens": ["Die", "wehr\u00b7te", "Zeit", "ver\u00b7bringst", ",", "die", "Dei\u00b7ne", "bes\u00b7te", "Macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "F\u00fcr alles Ungl\u00fcck ist. Was aber wil mein Segel", "tokens": ["F\u00fcr", "al\u00b7les", "Un\u00b7gl\u00fcck", "ist", ".", "Was", "a\u00b7ber", "wil", "mein", "Se\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "$.", "PWS", "ADV", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Auff dieses weite Meer? Ich bleib' im stillen Pregel", "tokens": ["Auff", "die\u00b7ses", "wei\u00b7te", "Meer", "?", "Ich", "bleib'", "im", "stil\u00b7len", "Pre\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und lasse nicht mein Boht in solche Wellen ein.", "tokens": ["Und", "las\u00b7se", "nicht", "mein", "Boht", "in", "sol\u00b7che", "Wel\u00b7len", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wer solche Trefligkeit und dieser Gaben Schein", "tokens": ["Wer", "sol\u00b7che", "Tre\u00b7flig\u00b7keit", "und", "die\u00b7ser", "Ga\u00b7ben", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIAT", "NN", "KON", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Zu singen ihm getrawt, mu\u00df so geb\u00fcckt nicht gehen,", "tokens": ["Zu", "sin\u00b7gen", "ihm", "ge\u00b7trawt", ",", "mu\u00df", "so", "ge\u00b7b\u00fcckt", "nicht", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "VVPP", "$,", "VMFIN", "ADV", "VVFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Nicht irrdisch seyn wie ich, mu\u00df k\u00f6nnen sich erh\u00f6hen", "tokens": ["Nicht", "irr\u00b7disch", "seyn", "wie", "ich", ",", "mu\u00df", "k\u00f6n\u00b7nen", "sich", "er\u00b7h\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VAINF", "KOKOM", "PPER", "$,", "VMFIN", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Durch Lufft und Himmel weg. Auch Opitz w\u00fcrde fast", "tokens": ["Durch", "Lufft", "und", "Him\u00b7mel", "weg", ".", "Auch", "O\u00b7pitz", "w\u00fcr\u00b7de", "fast"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$.", "ADV", "NE", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Hierinnen furchtsam seyn und schewen diese Last,", "tokens": ["Hie\u00b7rin\u00b7nen", "furcht\u00b7sam", "seyn", "und", "sche\u00b7wen", "die\u00b7se", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAINF", "KON", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Ob seines Geistes Krafft schon viel bi\u00dfher getragen", "tokens": ["Ob", "sei\u00b7nes", "Geis\u00b7tes", "Krafft", "schon", "viel", "bi\u00df\u00b7her", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADV", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Und sich an manches Lob mit Rhum hat th\u00fcren wagen,", "tokens": ["Und", "sich", "an", "man\u00b7ches", "Lob", "mit", "Rhum", "hat", "th\u00fc\u00b7ren", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIAT", "NN", "APPR", "NN", "VAFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Wozu ich gantz nicht taug. Sey gl\u00fcckhafft umb und an", "tokens": ["Wo\u00b7zu", "ich", "gantz", "nicht", "taug", ".", "Sey", "gl\u00fcck\u00b7hafft", "umb", "und", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "PTKNEG", "VVFIN", "$.", "VAIMP", "ADJD", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und habe, was Dein Hertz ihm w\u00fcnschen sol und kan,", "tokens": ["Und", "ha\u00b7be", ",", "was", "Dein", "Hertz", "ihm", "w\u00fcn\u00b7schen", "sol", "und", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Du Spiegel dieser Zeit! Ich aber wil mich wenden", "tokens": ["Du", "Spie\u00b7gel", "die\u00b7ser", "Zeit", "!", "Ich", "a\u00b7ber", "wil", "mich", "wen\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "PDAT", "NN", "$.", "PPER", "ADV", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Zu meinen Seiten hin, wiewol mit schwachen H\u00e4nden,", "tokens": ["Zu", "mei\u00b7nen", "Sei\u00b7ten", "hin", ",", "wie\u00b7wol", "mit", "schwa\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "KOUS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wil singen, was darauff die Andre hat begunt,", "tokens": ["Wil", "sin\u00b7gen", ",", "was", "dar\u00b7auff", "die", "And\u00b7re", "hat", "be\u00b7gunt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PRELS", "PAV", "ART", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Von der ich dieses nur au\u00df Schwachheit fassen kunt:", "tokens": ["Von", "der", "ich", "die\u00b7ses", "nur", "au\u00df", "Schwach\u00b7heit", "fas\u00b7sen", "kunt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PDS", "ADV", "APPR", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.76": {"line.1": {"text": "Ob ich mich beth\u00f6rt entz\u00fcnde", "tokens": ["Ob", "ich", "mich", "be\u00b7th\u00f6rt", "ent\u00b7z\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit vergebner Fr\u00f6ligkeit,", "tokens": ["Mit", "ver\u00b7geb\u00b7ner", "Fr\u00f6\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder in der That empfinde,", "tokens": ["O\u00b7der", "in", "der", "That", "emp\u00b7fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wessen sich mein Hertz erfrewt?", "tokens": ["Wes\u00b7sen", "sich", "mein", "Hertz", "er\u00b7frewt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Seyd Ihr kommen oder nicht,", "tokens": ["Seyd", "Ihr", "kom\u00b7men", "o\u00b7der", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "VVINF", "KON", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihr, O unsre Zuversicht?", "tokens": ["Ihr", ",", "O", "uns\u00b7re", "Zu\u00b7ver\u00b7sicht", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.77": {"line.1": {"text": "Die in Furcht und Hoffnung hangen,", "tokens": ["Die", "in", "Furcht", "und", "Hoff\u00b7nung", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind zu zweiffeln angewehnt,", "tokens": ["Sind", "zu", "zweif\u00b7feln", "an\u00b7ge\u00b7wehnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gl\u00e4uben nicht, wann sie erlangen", "tokens": ["Gl\u00e4u\u00b7ben", "nicht", ",", "wann", "sie", "er\u00b7lan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "PWAV", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df, wornach sie sich gesehnt.", "tokens": ["Da\u00df", ",", "wor\u00b7nach", "sie", "sich", "ge\u00b7sehnt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "PPER", "PRF", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Was man hofft ohn Angst und Pein,", "tokens": ["Was", "man", "hofft", "ohn", "Angst", "und", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Geht gantz ungezweiffelt ein.", "tokens": ["Geht", "gantz", "un\u00b7ge\u00b7zweif\u00b7felt", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.78": {"line.1": {"text": "Nein, ich seh', es kan nicht triegen,", "tokens": ["Nein", ",", "ich", "seh'", ",", "es", "kan", "nicht", "trie\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine Frewd ist k\u00fcntlich war,", "tokens": ["Mei\u00b7ne", "Frewd", "ist", "k\u00fcnt\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr, mein hertzliches Begn\u00fcgen,", "tokens": ["Ihr", ",", "mein", "hertz\u00b7li\u00b7ches", "Be\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Macht es alles Sonnenklar,", "tokens": ["Macht", "es", "al\u00b7les", "Son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ewer Glantz nimpt meinem Sinn", "tokens": ["E\u00b7wer", "Glantz", "nimpt", "mei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Allen Traum und Irrthum hin.", "tokens": ["Al\u00b7len", "Traum", "und", "Irr\u00b7thum", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.79": {"line.1": {"text": "Ich bin von Euch \u00fcberf\u00fchret", "tokens": ["Ich", "bin", "von", "Euch", "\u00fc\u00b7berf\u00b7\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ewer s\u00fcssen Gegenwart,", "tokens": ["E\u00b7wer", "s\u00fcs\u00b7sen", "Ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob mir nicht zu thun geb\u00fchret,", "tokens": ["Ob", "mir", "nicht", "zu", "thun", "ge\u00b7b\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was die Zeit her ist erspart?", "tokens": ["Was", "die", "Zeit", "her", "ist", "er\u00b7spart", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APZR", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wend' ich jetzt nicht mein Gem\u00fct'", "tokens": ["Wend'", "ich", "jetzt", "nicht", "mein", "Ge\u00b7m\u00fct'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auff ein s\u00fcsses Frewden-Liedt?", "tokens": ["Auff", "ein", "s\u00fcs\u00b7ses", "Fre\u00b7wden\u00b7Liedt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.80": {"line.1": {"text": "Ja! was aber wollt, ihr Thr\u00e4nen?", "tokens": ["Ja", "!", "was", "a\u00b7ber", "wollt", ",", "ihr", "Thr\u00e4\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PWS", "ADV", "VMFIN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weinen ist zu zeiten gut,", "tokens": ["Wei\u00b7nen", "ist", "zu", "zei\u00b7ten", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jetzundt must ihr Euch entwehnen,", "tokens": ["Je\u00b7tzundt", "must", "ihr", "Euch", "ent\u00b7weh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine Augen, ewrer Flut,", "tokens": ["Mei\u00b7ne", "Au\u00b7gen", ",", "ew\u00b7rer", "Flut", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Warumb ihr geflossen seydt,", "tokens": ["Wa\u00b7rumb", "ihr", "ge\u00b7flos\u00b7sen", "seydt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "VAFIN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "Hat mich numehr hoch erfrewt.", "tokens": ["Hat", "mich", "nu\u00b7mehr", "hoch", "er\u00b7frewt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.81": {"line.1": {"text": "Gl\u00e4ubet diesen trewen Zeugen,", "tokens": ["Gl\u00e4u\u00b7bet", "die\u00b7sen", "tre\u00b7wen", "Zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mein Herr Vater, und auch du,", "tokens": ["Mein", "Herr", "Va\u00b7ter", ",", "und", "auch", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "KON", "ADV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00fcsser Bruder, ich wil schweigen,", "tokens": ["S\u00fcs\u00b7ser", "Bru\u00b7der", ",", "ich", "wil", "schwei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Gesicht helt doch nicht Rhue,", "tokens": ["Mein", "Ge\u00b7sicht", "helt", "doch", "nicht", "Rhue", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeigt durch stumme Redner an,", "tokens": ["Zeigt", "durch", "stum\u00b7me", "Red\u00b7ner", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie mein Hertz nach Euch gethan.", "tokens": ["Wie", "mein", "Hertz", "nach", "Euch", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.82": {"line.1": {"text": "Hat so fr\u00fc' der Sonnen Wagen", "tokens": ["Hat", "so", "fr\u00fc'", "der", "Son\u00b7nen", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Je auch auff zu seyn begehrt,", "tokens": ["Je", "auch", "auff", "zu", "seyn", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PTKZU", "VAINF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich \u00fcber seinen Tagen", "tokens": ["Da\u00df", "ich", "\u00fc\u00b7ber", "sei\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mich zum h\u00f6chsten nicht beschwert", "tokens": ["Mich", "zum", "h\u00f6chs\u00b7ten", "nicht", "be\u00b7schwert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "ADJA", "PTKNEG", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und gefleht umb diesen Tag,", "tokens": ["Und", "ge\u00b7fleht", "umb", "die\u00b7sen", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dar- ich Euch-an-sprechen mag?", "tokens": ["Dar", "ich", "Euch\u00b7an\u00b7spre\u00b7chen", "mag", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["TRUNC", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.83": {"line.1": {"text": "Keine Ruh hat mich umbfangen,", "tokens": ["Kei\u00b7ne", "Ruh", "hat", "mich", "umb\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und so still war keine Nacht,", "tokens": ["Und", "so", "still", "war", "kei\u00b7ne", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche nicht durch mein Verlangen", "tokens": ["Wel\u00b7che", "nicht", "durch", "mein", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00fcb' und schlafflo\u00df ward gemacht,", "tokens": ["Tr\u00fcb'", "und", "schlaf\u00b7flo\u00df", "ward", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mond' und Sterne wusten schon", "tokens": ["Mond'", "und", "Ster\u00b7ne", "wus\u00b7ten", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Meinen Leid- und Klage-Thon.", "tokens": ["Mei\u00b7nen", "Lei\u00b7d", "und", "Kla\u00b7ge\u00b7Thon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "TRUNC", "KON", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.84": {"line.1": {"text": "Nichts wolt' einen Muth mir geben,", "tokens": ["Nichts", "wolt'", "ei\u00b7nen", "Muth", "mir", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo man aller Lust vergist", "tokens": ["Wo", "man", "al\u00b7ler", "Lust", "ver\u00b7gist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nur Leidt tr\u00e4gt, war mein Leben,", "tokens": ["Und", "nur", "Leidt", "tr\u00e4gt", ",", "war", "mein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVFIN", "$,", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo mir das ein Leben ist,", "tokens": ["Wo", "mir", "das", "ein", "Le\u00b7ben", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "ART", "NN", "VAFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Mein Gebet ohn Ruh und Rast", "tokens": ["Mein", "Ge\u00b7bet", "ohn", "Ruh", "und", "Rast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "War bey Gott nur nicht verhast.", "tokens": ["War", "bey", "Gott", "nur", "nicht", "ver\u00b7hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.85": {"line.1": {"text": "Numehr habt Ihr zu ermessen,", "tokens": ["Nu\u00b7mehr", "habt", "Ihr", "zu", "er\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie mir wol zu muthe sey,", "tokens": ["Wie", "mir", "wol", "zu", "mu\u00b7the", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aller M\u00fch ist nun vergessen,", "tokens": ["Al\u00b7ler", "M\u00fch", "ist", "nun", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Gem\u00fcth' ist lo\u00df und frey,", "tokens": ["Mein", "Ge\u00b7m\u00fcth'", "ist", "lo\u00df", "und", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schickt der Sorgen Ach und Weh", "tokens": ["Schickt", "der", "Sor\u00b7gen", "Ach", "und", "Weh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auff die Wellen und die See.", "tokens": ["Auff", "die", "Wel\u00b7len", "und", "die", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.86": {"line.1": {"text": "Meine Stimme mu\u00df sich schwingen", "tokens": ["Mei\u00b7ne", "Stim\u00b7me", "mu\u00df", "sich", "schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch der Wolcken blawes Dach,", "tokens": ["Durch", "der", "Wol\u00b7cken", "bla\u00b7wes", "Dach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber was ich wei\u00df zu singen,", "tokens": ["A\u00b7ber", "was", "ich", "wei\u00df", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich treibe vor und nach", "tokens": ["Was", "ich", "trei\u00b7be", "vor", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "PTKVZ", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist: mein' Hoffnung, Trost und Zier", "tokens": ["Ist", ":", "mein'", "Hoff\u00b7nung", ",", "Trost", "und", "Zier"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$.", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Lebt, Gott Lob, und ist schon hier!", "tokens": ["Lebt", ",", "Gott", "Lob", ",", "und", "ist", "schon", "hier", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "NN", "$,", "KON", "VAFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.87": {"line.1": {"text": "Wer k\u00f6nte nicht hierau\u00df Dich, O Louyse, kennen?", "tokens": ["Wer", "k\u00f6n\u00b7te", "nicht", "hier\u00b7au\u00df", "Dich", ",", "O", "Lou\u00b7yse", ",", "ken\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "PAV", "PPER", "$,", "NE", "NE", "$,", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und wolte man dich gleich, Princessin, Pallas nennen,", "tokens": ["Und", "wol\u00b7te", "man", "dich", "gleich", ",", "Prin\u00b7ces\u00b7sin", ",", "Pal\u00b7las", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "PRF", "ADV", "$,", "NN", "$,", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was w\u00e4r' es gro\u00df gefehlt? Du bist mit dem begabt", "tokens": ["Was", "w\u00e4r'", "es", "gro\u00df", "ge\u00b7fehlt", "?", "Du", "bist", "mit", "dem", "be\u00b7gabt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADJD", "VVPP", "$.", "PPER", "VAFIN", "APPR", "ART", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das, wie man sagen wil, Minerve hat gehabt,", "tokens": ["Das", ",", "wie", "man", "sa\u00b7gen", "wil", ",", "Mi\u00b7ner\u00b7ve", "hat", "ge\u00b7habt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$,", "NN", "VAFIN", "VAPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Die Wei\u00dfheit, den Verstand: Du bist ein Bild der Jugend,", "tokens": ["Die", "Wei\u00df\u00b7heit", ",", "den", "Ver\u00b7stand", ":", "Du", "bist", "ein", "Bild", "der", "Ju\u00b7gend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Deinen Pracht und Licht, der Zucht geehrte Tugend", "tokens": ["Der", "Dei\u00b7nen", "Pracht", "und", "Licht", ",", "der", "Zucht", "ge\u00b7ehr\u00b7te", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "$,", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wohnt dir so sehr im Sinn und in Geberden bey,", "tokens": ["Wohnt", "dir", "so", "sehr", "im", "Sinn", "und", "in", "Ge\u00b7ber\u00b7den", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "KON", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Als ob sie nirgends sonst denn hie zu finden sey.", "tokens": ["Als", "ob", "sie", "nir\u00b7gends", "sonst", "denn", "hie", "zu", "fin\u00b7den", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die letzte schiene mir sehr frewdig vorzukommen,", "tokens": ["Die", "letz\u00b7te", "schie\u00b7ne", "mir", "sehr", "frew\u00b7dig", "vor\u00b7zu\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von Der ich, ist mir recht, in Einfalt die\u00df vernommen:", "tokens": ["Von", "Der", "ich", ",", "ist", "mir", "recht", ",", "in", "Ein\u00b7falt", "die\u00df", "ver\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "$,", "VAFIN", "PPER", "ADJD", "$,", "APPR", "NN", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.88": {"line.1": {"text": "Gnug geklaget, gnug geweint!", "tokens": ["Gnug", "ge\u00b7kla\u00b7get", ",", "gnug", "ge\u00b7weint", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kummer, \u00e4rgster Lebens-Feind,", "tokens": ["Kum\u00b7mer", ",", "\u00e4rgs\u00b7ter", "Le\u00b7bens\u00b7Feind", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geh und trolle dich von hinnen!", "tokens": ["Geh", "und", "trol\u00b7le", "dich", "von", "hin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PRF", "APPR", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zweyer Liebsten Ankunfft macht,", "tokens": ["Zwey\u00b7er", "Liebs\u00b7ten", "An\u00b7kunfft", "macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich singe gute Nacht", "tokens": ["Da\u00df", "ich", "sin\u00b7ge", "gu\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Trawrigkeit, du Pest der Sinnen!", "tokens": ["Traw\u00b7rig\u00b7keit", ",", "du", "Pest", "der", "Sin\u00b7nen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.89": {"line.1": {"text": "O Herr Vater, s\u00fcsses Heil,", "tokens": ["O", "Herr", "Va\u00b7ter", ",", "s\u00fcs\u00b7ses", "Heil", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und mein Bruder, bestes Theil", "tokens": ["Und", "mein", "Bru\u00b7der", ",", "bes\u00b7tes", "Theil"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser Seelen, so dich liebet,", "tokens": ["Die\u00b7ser", "See\u00b7len", ",", "so", "dich", "lie\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kompt! dem H\u00f6chsten ist bekandt,", "tokens": ["Kompt", "!", "dem", "H\u00f6chs\u00b7ten", "ist", "be\u00b7kandt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie nach Euch sich dieses Landt", "tokens": ["Wie", "nach", "Euch", "sich", "die\u00b7ses", "Landt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "PPER", "PRF", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat gesehnet und betr\u00fcbet.", "tokens": ["Hat", "ge\u00b7seh\u00b7net", "und", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.90": {"line.1": {"text": "Kompt! mit Euch k\u00f6mpt Frewd' und Gl\u00fcck,", "tokens": ["Kompt", "!", "mit", "Euch", "k\u00f6mpt", "Fre\u00b7wd'", "und", "Gl\u00fcck", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "APPR", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Dieser helle Gnaden-Blick", "tokens": ["Die\u00b7ser", "hel\u00b7le", "Gna\u00b7den\u00b7Blick"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist an stat der g\u00fcldnen Sonnen,", "tokens": ["Ist", "an", "stat", "der", "g\u00fcld\u00b7nen", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich umb die\u00df gantze Feldt", "tokens": ["Die", "sich", "umb", "die\u00df", "gant\u00b7ze", "Feldt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "PDS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weit und breit verborgen helt,", "tokens": ["Weit", "und", "breit", "ver\u00b7bor\u00b7gen", "helt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil es ewren Glantz gewonnen.", "tokens": ["Weil", "es", "ew\u00b7ren", "Glantz", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.91": {"line.1": {"text": "Auff, Thalia, meine Zier,", "tokens": ["Auff", ",", "Tha\u00b7lia", ",", "mei\u00b7ne", "Zier", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "$,", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Komm und singe neben mir,", "tokens": ["Komm", "und", "sin\u00b7ge", "ne\u00b7ben", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlag auff den ber\u00fchmten Seiten!", "tokens": ["Schlag", "auff", "den", "be\u00b7r\u00fchm\u00b7ten", "Sei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Netze, Herbst, nicht als du thust,", "tokens": ["Net\u00b7ze", ",", "Herbst", ",", "nicht", "als", "du", "thust", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PTKNEG", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kehre dich in Vorjahrs Lust,", "tokens": ["Keh\u00b7re", "dich", "in", "Vor\u00b7jahrs", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Last, ihr Winde, lasst das Streiten!", "tokens": ["Last", ",", "ihr", "Win\u00b7de", ",", "lasst", "das", "Strei\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.92": {"line.1": {"text": "Komm gefl\u00fcgelt, sanffter Ost,", "tokens": ["Komm", "ge\u00b7fl\u00fc\u00b7gelt", ",", "sanff\u00b7ter", "Ost", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bring durch deiner Stimme Trost", "tokens": ["Bring", "durch", "dei\u00b7ner", "Stim\u00b7me", "Trost"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tulpen, Rosen und Violen!", "tokens": ["Tul\u00b7pen", ",", "Ro\u00b7sen", "und", "Vi\u00b7o\u00b7len", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lachst du meiner Bitte gar?", "tokens": ["Lachst", "du", "mei\u00b7ner", "Bit\u00b7te", "gar", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dencke nach, zu wessen Haar", "tokens": ["Den\u00b7cke", "nach", ",", "zu", "wes\u00b7sen", "Haar"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich mir jetzt wil Blumen holen.", "tokens": ["Ich", "mir", "jetzt", "wil", "Blu\u00b7men", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "VMFIN", "NN", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.93": {"line.1": {"text": "Vater, nimm was dir geb\u00fchrt,", "tokens": ["Va\u00b7ter", ",", "nimm", "was", "dir", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PWS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Den Gehorsam, welcher r\u00fchrt", "tokens": ["Den", "Ge\u00b7hor\u00b7sam", ",", "wel\u00b7cher", "r\u00fchrt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus des Hertzens tieffen H\u00f6len,", "tokens": ["Aus", "des", "Hert\u00b7zens", "tief\u00b7fen", "H\u00f6\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schaw auff meinen trewen Sinn,", "tokens": ["Schaw", "auff", "mei\u00b7nen", "tre\u00b7wen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weissest du nicht wer ich bin?", "tokens": ["Weis\u00b7sest", "du", "nicht", "wer", "ich", "bin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich, die Funcke deiner Seelen.", "tokens": ["Ich", ",", "die", "Fun\u00b7cke", "dei\u00b7ner", "See\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.94": {"line.1": {"text": "Hertzer Bruder, mich verdreusst,", "tokens": ["Hert\u00b7zer", "Bru\u00b7der", ",", "mich", "ver\u00b7dreusst", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich meiner Liebe Geist", "tokens": ["Da\u00df", "ich", "mei\u00b7ner", "Lie\u00b7be", "Geist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht so mercklich kunt kan geben:", "tokens": ["Nicht", "so", "merck\u00b7lich", "kunt", "kan", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PTKVZ", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meiner Zungen Krafft gebricht,", "tokens": ["Mei\u00b7ner", "Zun\u00b7gen", "Krafft", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Etwas anders wei\u00df ich nicht;", "tokens": ["Et\u00b7was", "an\u00b7ders", "wei\u00df", "ich", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kurtz, ich liebe dich, mein Leben!", "tokens": ["Kurtz", ",", "ich", "lie\u00b7be", "dich", ",", "mein", "Le\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.95": {"line.1": {"text": "Speis' und Tranck und alle Welt", "tokens": ["Speis'", "und", "Tranck", "und", "al\u00b7le", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward mir au\u00df dem Sinn gestelt,", "tokens": ["Ward", "mir", "au\u00df", "dem", "Sinn", "ge\u00b7stelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine Grabschafft woltt' ich wissen,", "tokens": ["Mei\u00b7ne", "Grab\u00b7schafft", "woltt'", "ich", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als das Fieber, und zuletzt", "tokens": ["Als", "das", "Fie\u00b7ber", ",", "und", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch der Todt schon an dich setzt'", "tokens": ["Auch", "der", "Todt", "schon", "an", "dich", "setzt'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dein Leben wolte schliessen.", "tokens": ["Und", "dein", "Le\u00b7ben", "wol\u00b7te", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.96": {"line.1": {"text": "Seyt, Ihr Parcen, ja so wildt,", "tokens": ["Seyt", ",", "Ihr", "Par\u00b7cen", ",", "ja", "so", "wildt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt ich, da\u00df ihr ihn, mein Bildt", "tokens": ["Sagt", "ich", ",", "da\u00df", "ihr", "ihn", ",", "mein", "Bildt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir nicht l\u00e4nger hie wolt lassen,", "tokens": ["Mir", "nicht", "l\u00e4n\u00b7ger", "hie", "wolt", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Thut nur dieses, und verleiht,", "tokens": ["Thut", "nur", "die\u00b7ses", ",", "und", "ver\u00b7leiht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "PDAT", "$,", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df wir uns erst beyderseit", "tokens": ["Da\u00df", "wir", "uns", "erst", "bey\u00b7der\u00b7seit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Recht gesegnen und umbfassen.", "tokens": ["Recht", "ge\u00b7seg\u00b7nen", "und", "umb\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.97": {"line.1": {"text": "Nun, des H\u00f6chsten Vater-Trew", "tokens": ["Nun", ",", "des", "H\u00f6chs\u00b7ten", "Va\u00b7ter\u00b7Trew"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat mein sehnliches Geschrey", "tokens": ["Hat", "mein", "sehn\u00b7li\u00b7ches", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lassen statt vor ihm gewinnen:", "tokens": ["Las\u00b7sen", "statt", "vor", "ihm", "ge\u00b7win\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott und Himmel sind dir hold,", "tokens": ["Gott", "und", "Him\u00b7mel", "sind", "dir", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dein Verh\u00e4ngnus mu\u00df nur Gold", "tokens": ["Dein", "Ver\u00b7h\u00e4ng\u00b7nus", "mu\u00df", "nur", "Gold"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dir zu deinem Leben spinnen.", "tokens": ["Dir", "zu", "dei\u00b7nem", "Le\u00b7ben", "spin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.98": {"line.1": {"text": "Wol uns allen, wol auch dir!", "tokens": ["Wol", "uns", "al\u00b7len", ",", "wol", "auch", "dir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PIS", "$,", "ADV", "ADV", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was man denckt und sagt allhier,", "tokens": ["Was", "man", "denckt", "und", "sagt", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "KON", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist von ewrem Wolergehen,", "tokens": ["Ist", "von", "ew\u00b7rem", "Wo\u00b7ler\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber niemand wird geschawt,", "tokens": ["A\u00b7ber", "nie\u00b7mand", "wird", "ge\u00b7schawt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der sich neben mir getrawt,", "tokens": ["Der", "sich", "ne\u00b7ben", "mir", "ge\u00b7trawt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPER", "VVPP", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.6": {"text": "Was das Hertz belangt, zu stehen.", "tokens": ["Was", "das", "Hertz", "be\u00b7langt", ",", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVPP", "$,", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.99": {"line.1": {"text": "Wie, wann zur See Neptun vom Vater Ocean", "tokens": ["Wie", ",", "wann", "zur", "See", "Nep\u00b7tun", "vom", "Va\u00b7ter", "O\u00b7cean"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "PWAV", "APPRART", "NN", "NE", "APPRART", "NN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ber\u00e4uscht nach Hause f\u00e4hrt durch seine nasse Bahn,", "tokens": ["Be\u00b7r\u00e4uscht", "nach", "Hau\u00b7se", "f\u00e4hrt", "durch", "sei\u00b7ne", "nas\u00b7se", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und etwan Triton lesst die See-Trompet erschallen,", "tokens": ["Und", "et\u00b7wan", "Tri\u00b7ton", "lesst", "die", "See\u00b7Trom\u00b7pet", "er\u00b7schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Doris sonderlich zu g\u00fcnstigem Gefallen,", "tokens": ["Der", "Do\u00b7ris", "son\u00b7der\u00b7lich", "zu", "g\u00fcns\u00b7ti\u00b7gem", "Ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die aus den Wellen schawt, die Faunen ohn gefehr", "tokens": ["Die", "aus", "den", "Wel\u00b7len", "schawt", ",", "die", "Fau\u00b7nen", "ohn", "ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als wildes tummes Volck sich umb das Ufer her", "tokens": ["Als", "wil\u00b7des", "tum\u00b7mes", "Volck", "sich", "umb", "das", "U\u00b7fer", "her"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Versamlen, und den Thon best\u00fcrtzt und Sinnlo\u00df h\u00f6ren,", "tokens": ["Ver\u00b7sam\u00b7len", ",", "und", "den", "Thon", "be\u00b7st\u00fcrtzt", "und", "Sinn\u00b7lo\u00df", "h\u00f6\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ART", "NN", "VVPP", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So kam es uns auch vor, was Hedwig da zu ehren", "tokens": ["So", "kam", "es", "uns", "auch", "vor", ",", "was", "Hed\u00b7wig", "da", "zu", "eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$,", "PRELS", "NE", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Den grossen F\u00fcrsten sang, denn Hedwich must' es seyn,", "tokens": ["Den", "gros\u00b7sen", "F\u00fcrs\u00b7ten", "sang", ",", "denn", "Hed\u00b7wich", "must'", "es", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "NE", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So viel die Rede Gab, die durch der Jugend Schein", "tokens": ["So", "viel", "die", "Re\u00b7de", "Gab", ",", "die", "durch", "der", "Ju\u00b7gend", "Schein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und g\u00f6ttliche Gestalt f\u00fcr Clio ward gesch\u00e4tzet.", "tokens": ["Und", "g\u00f6tt\u00b7li\u00b7che", "Ge\u00b7stalt", "f\u00fcr", "Clio", "ward", "ge\u00b7sch\u00e4t\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wir hatten allerseit uns \u00fcber dem entsetzet", "tokens": ["Wir", "hat\u00b7ten", "al\u00b7ler\u00b7seit", "uns", "\u00fc\u00b7ber", "dem", "ent\u00b7set\u00b7zet"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "APPR", "ART", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was vorgelauffen war, und niemand wuste da", "tokens": ["Was", "vor\u00b7ge\u00b7lauf\u00b7fen", "war", ",", "und", "nie\u00b7mand", "wus\u00b7te", "da"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVPP", "VAFIN", "$,", "KON", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was weiter sey zu thun, so das Prussilia,", "tokens": ["Was", "wei\u00b7ter", "sey", "zu", "thun", ",", "so", "das", "Prus\u00b7si\u00b7lia", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "PTKZU", "VVINF", "$,", "ADV", "ART", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Die kurtz zuvor viel Dienst und Pflicht auff sich genommen,", "tokens": ["Die", "kurtz", "zu\u00b7vor", "viel", "Dienst", "und", "Pflicht", "auff", "sich", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "PIAT", "NN", "KON", "NN", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und jederman hiedurch gemeinet vorzukommen,", "tokens": ["Und", "je\u00b7der\u00b7man", "hie\u00b7durch", "ge\u00b7mei\u00b7net", "vor\u00b7zu\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PAV", "VVPP", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Den Muht gantz sincken lie\u00df, sprach ihre V\u00f6lcker an:", "tokens": ["Den", "Muht", "gantz", "sin\u00b7cken", "lie\u00df", ",", "sprach", "ih\u00b7re", "V\u00f6l\u00b7cker", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ihr Kinder, h\u00f6rt und seht, da\u00df mein Thun gar nicht kan", "tokens": ["Ihr", "Kin\u00b7der", ",", "h\u00f6rt", "und", "seht", ",", "da\u00df", "mein", "Thun", "gar", "nicht", "kan"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "KON", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "ADV", "PTKNEG", "VMFIN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Gerahten als es sol, was wir im Sinne hatten,", "tokens": ["Ge\u00b7rah\u00b7ten", "als", "es", "sol", ",", "was", "wir", "im", "Sin\u00b7ne", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "VMFIN", "$,", "PRELS", "PPER", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wird gegen diesem Licht zur Nacht, zu finsterm Schatten.", "tokens": ["Wird", "ge\u00b7gen", "die\u00b7sem", "Licht", "zur", "Nacht", ",", "zu", "fins\u00b7term", "Schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "APPRART", "NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Wer sich mit etwas sonst hierauff hervorthun wil", "tokens": ["Wer", "sich", "mit", "et\u00b7was", "sonst", "hier\u00b7auff", "her\u00b7vor\u00b7thun", "wil"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPR", "PIS", "ADV", "PAV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wird wieder allen Danck zu einem Affen-Spiel", "tokens": ["Wird", "wie\u00b7der", "al\u00b7len", "Danck", "zu", "ei\u00b7nem", "Af\u00b7fen\u00b7Spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und mu\u00df verlachet seyn. Doch wollen wir gedencken,", "tokens": ["Und", "mu\u00df", "ver\u00b7la\u00b7chet", "seyn", ".", "Doch", "wol\u00b7len", "wir", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "VVPP", "VAINF", "$.", "KON", "VMFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Es werden sich auch noch zu unsrer Einfalt lencken", "tokens": ["Es", "wer\u00b7den", "sich", "auch", "noch", "zu", "uns\u00b7rer", "Ein\u00b7falt", "len\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Helden beyderseit, und zeugen durch den Schein", "tokens": ["Die", "Hel\u00b7den", "bey\u00b7der\u00b7seit", ",", "und", "zeu\u00b7gen", "durch", "den", "Schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der Gnaden \u00fcber uns, das Sie auch G\u00f6tter seyn,", "tokens": ["Der", "Gna\u00b7den", "\u00fc\u00b7ber", "uns", ",", "das", "Sie", "auch", "G\u00f6t\u00b7ter", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "PRELS", "PPER", "ADV", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die auff den Willen sehn und nach dem Hertzen fragen,", "tokens": ["Die", "auff", "den", "Wil\u00b7len", "sehn", "und", "nach", "dem", "Hert\u00b7zen", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVINF", "KON", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da\u00df offt bey ihnen wol so viel pflegt zu verschlagen", "tokens": ["Da\u00df", "offt", "bey", "ih\u00b7nen", "wol", "so", "viel", "pflegt", "zu", "ver\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPER", "ADV", "ADV", "ADV", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Als sonst ein feistes Rind, als hundert L\u00e4mmer Blut", "tokens": ["Als", "sonst", "ein", "feis\u00b7tes", "Rind", ",", "als", "hun\u00b7dert", "L\u00e4m\u00b7mer", "Blut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$,", "KOUS", "CARD", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und was der Gottes-Dienst zum Opffer mehr abthut.", "tokens": ["Und", "was", "der", "Got\u00b7tes\u00b7Dienst", "zum", "Opf\u00b7fer", "mehr", "ab\u00b7thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Damit wir aber so nicht von einander giengen,", "tokens": ["Da\u00b7mit", "wir", "a\u00b7ber", "so", "nicht", "von", "ein\u00b7an\u00b7der", "gien\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Trug sie mir auff zuletzt ein Liedchen noch zu singen", "tokens": ["Trug", "sie", "mir", "auff", "zu\u00b7letzt", "ein", "Lied\u00b7chen", "noch", "zu", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ADV", "ART", "NN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Auff solchen Frewden-Tag, zwar anfangs thurst ich nicht,", "tokens": ["Auff", "sol\u00b7chen", "Fre\u00b7wden\u00b7Tag", ",", "zwar", "an\u00b7fangs", "thurst", "ich", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Doch sagt' ich endlich selbst: Gehorsam, Dienst und Pflicht", "tokens": ["Doch", "sagt'", "ich", "end\u00b7lich", "selbst", ":", "Ge\u00b7hor\u00b7sam", ",", "Dienst", "und", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$.", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Mu\u00df seyn so gut es kan, den Willen zu bezeugen", "tokens": ["Mu\u00df", "seyn", "so", "gut", "es", "kan", ",", "den", "Wil\u00b7len", "zu", "be\u00b7zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "ADV", "ADJD", "PPER", "VMFIN", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Erheischt nicht allzeit Kunst. An diesem Tage schweigen,", "tokens": ["Er\u00b7heischt", "nicht", "all\u00b7zeit", "Kunst", ".", "An", "die\u00b7sem", "Ta\u00b7ge", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "NN", "$.", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Da alles singt und lacht, kriegt eines Undancks Lohn,", "tokens": ["Da", "al\u00b7les", "singt", "und", "lacht", ",", "kriegt", "ei\u00b7nes", "Un\u00b7dancks", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Drum fasst' ich einen Muht und sang auff diesen Thon:", "tokens": ["Drum", "fasst'", "ich", "ei\u00b7nen", "Muht", "und", "sang", "auff", "die\u00b7sen", "Thon", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.100": {"line.1": {"text": "Schallt, ihr helle Feldt-Trompeten!", "tokens": ["Schallt", ",", "ihr", "hel\u00b7le", "Feldt\u00b7Trom\u00b7pe\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blitzt und klinget, ihr Mu\u00dfqueten,", "tokens": ["Blitzt", "und", "klin\u00b7get", ",", "ihr", "Mu\u00df\u00b7que\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasst den wilden Drommel-Schlag", "tokens": ["Lasst", "den", "wil\u00b7den", "Drom\u00b7mel\u00b7Schlag"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns Geh\u00f6r und Sinn bet\u00e4uben!", "tokens": ["Uns", "Ge\u00b7h\u00f6r", "und", "Sinn", "be\u00b7t\u00e4u\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieses Wesen sol man treiben", "tokens": ["Die\u00b7ses", "We\u00b7sen", "sol", "man", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VMFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fort und fort den gantzen Tag!", "tokens": ["Fort", "und", "fort", "den", "gant\u00b7zen", "Tag", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKVZ", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.101": {"line.1": {"text": "Ihr Carthaunen und Gesch\u00fctze,", "tokens": ["Ihr", "Car\u00b7thau\u00b7nen", "und", "Ge\u00b7sch\u00fct\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wozu seydt ihr hie sonst n\u00fctze?", "tokens": ["Wo\u00b7zu", "seydt", "ihr", "hie", "sonst", "n\u00fct\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasset ewren Donner au\u00df!", "tokens": ["Las\u00b7set", "ew\u00b7ren", "Don\u00b7ner", "au\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lasst das Erdreich sich ersch\u00fcttern,", "tokens": ["Lasst", "das", "Er\u00b7dreich", "sich", "er\u00b7sch\u00fct\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "See und Haff und Pregel zittern,", "tokens": ["See", "und", "Haff", "und", "Pre\u00b7gel", "zit\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und erschreckt der Sternen Hau\u00df!", "tokens": ["Und", "er\u00b7schreckt", "der", "Ster\u00b7nen", "Hau\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.102": {"line.1": {"text": "Brandenburg, die Zucht der Helden,", "tokens": ["Bran\u00b7den\u00b7burg", ",", "die", "Zucht", "der", "Hel\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan Georg und Fridrich melden,", "tokens": ["Kan", "Ge\u00b7org", "und", "Frid\u00b7rich", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jenen, Vater, diesen, Sohn,", "tokens": ["Je\u00b7nen", ",", "Va\u00b7ter", ",", "die\u00b7sen", ",", "Sohn", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDS", "$,", "NN", "$,", "PDAT", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcrsten, die durch thewre Gaben", "tokens": ["F\u00fcrs\u00b7ten", ",", "die", "durch", "thew\u00b7re", "Ga\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alles \u00fcberstiegen haben,", "tokens": ["Al\u00b7les", "\u00fc\u00b7bers\u00b7tie\u00b7gen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch der hohen Sonnen Thron.", "tokens": ["Auch", "der", "ho\u00b7hen", "Son\u00b7nen", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.103": {"line.1": {"text": "Diese wil das Land empfangen,", "tokens": ["Die\u00b7se", "wil", "das", "Land", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsers Hertzogthums Verlangen,", "tokens": ["Un\u00b7sers", "Hert\u00b7zog\u00b7thums", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Solche Herren, welcher Prei\u00df", "tokens": ["Sol\u00b7che", "Her\u00b7ren", ",", "wel\u00b7cher", "Prei\u00df"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch der Alten Lob bezwinget", "tokens": ["Auch", "der", "Al\u00b7ten", "Lob", "be\u00b7zwin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und mit hellen Stralen dringet", "tokens": ["Und", "mit", "hel\u00b7len", "Stra\u00b7len", "drin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch der weiten Erden Krey\u00df.", "tokens": ["Durch", "der", "wei\u00b7ten", "Er\u00b7den", "Krey\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.104": {"line.1": {"text": "Lasst uns keiner Frewde sparen!", "tokens": ["Lasst", "uns", "kei\u00b7ner", "Frew\u00b7de", "spa\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ihr geht mit greisen Haren,", "tokens": ["Die", "ihr", "geht", "mit", "grei\u00b7sen", "Ha\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ihr an den Br\u00fcsten seyt,", "tokens": ["Die", "ihr", "an", "den", "Br\u00fcs\u00b7ten", "seyt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00fctter, J\u00fcngling' und Jungfrawen,", "tokens": ["M\u00fct\u00b7ter", ",", "J\u00fcng\u00b7ling'", "und", "Jung\u00b7fra\u00b7wen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "KON", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Arm und Reich, ihr m\u00fcsset schawen,", "tokens": ["Arm", "und", "Reich", ",", "ihr", "m\u00fcs\u00b7set", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Nach gew\u00fcnschter Fr\u00f6ligkeit.", "tokens": ["Nach", "ge\u00b7w\u00fcnschter", "Fr\u00f6\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.105": {"line.1": {"text": "Lasst der Kurtzweil Zaum und Z\u00fcgel,", "tokens": ["Lasst", "der", "Kurt\u00b7zweil", "Zaum", "und", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwingt den Zorn, und schiebt den Riegel", "tokens": ["Zwingt", "den", "Zorn", ",", "und", "schiebt", "den", "Rie\u00b7gel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Allen bleichen Sorgen vor,", "tokens": ["Al\u00b7len", "blei\u00b7chen", "Sor\u00b7gen", "vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ladet ein gew\u00fcnschte Sachen,", "tokens": ["La\u00b7det", "ein", "ge\u00b7w\u00fcnschte", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Sperret auff f\u00fcr Schertz und Lachen", "tokens": ["Sper\u00b7ret", "auff", "f\u00fcr", "Schertz", "und", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hin und wieder Th\u00fcr und Thor.", "tokens": ["Hin", "und", "wie\u00b7der", "Th\u00fcr", "und", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.106": {"line.1": {"text": "Euch, Ihr Helden, blo\u00df zu ehren,", "tokens": ["Euch", ",", "Ihr", "Hel\u00b7den", ",", "blo\u00df", "zu", "eh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euch lesst Jung und Alt sich h\u00f6ren,", "tokens": ["Euch", "lesst", "Jung", "und", "Alt", "sich", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "ADJD", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Euch wird keiner Lust gespart:", "tokens": ["Euch", "wird", "kei\u00b7ner", "Lust", "ge\u00b7spart", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was in H\u00e4usern jetzt geschiehet,", "tokens": ["Was", "in", "H\u00e4u\u00b7sern", "jetzt", "ge\u00b7schie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was man auff den Stra\u00dfen siehet,", "tokens": ["Was", "man", "auff", "den", "Stra\u00b7\u00dfen", "sie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "K\u00f6mpt von Ewrer Gegenwart.", "tokens": ["K\u00f6mpt", "von", "Ew\u00b7rer", "Ge\u00b7gen\u00b7wart", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.107": {"line.1": {"text": "Was, Ihr Lichter, werdet sp\u00fcren", "tokens": ["Was", ",", "Ihr", "Lich\u00b7ter", ",", "wer\u00b7det", "sp\u00fc\u00b7ren"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWS", "$,", "PPOSAT", "NN", "$,", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In den Fenstern, vor den Th\u00fcren,", "tokens": ["In", "den", "Fens\u00b7tern", ",", "vor", "den", "Th\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nimpt Euch s\u00e4mptlich fr\u00f6lich an,", "tokens": ["Nimpt", "Euch", "s\u00e4mpt\u00b7lich", "fr\u00f6\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kompt, O Hoffnung, wird gesungen", "tokens": ["Kompt", ",", "O", "Hoff\u00b7nung", ",", "wird", "ge\u00b7sun\u00b7gen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "NE", "NN", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mit der Kehlen, mit der Zungen,", "tokens": ["Mit", "der", "Keh\u00b7len", ",", "mit", "der", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit dem Hertzen wie man kan.", "tokens": ["Mit", "dem", "Hert\u00b7zen", "wie", "man", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KOKOM", "PIS", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.108": {"line.1": {"text": "Dieser Reuterey Gepr\u00e4nge,", "tokens": ["Die\u00b7ser", "Reu\u00b7te\u00b7rey", "Ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses Wesen, das Gedr\u00e4nge", "tokens": ["Die\u00b7ses", "We\u00b7sen", ",", "das", "Ge\u00b7dr\u00e4n\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Scheinet etwas zwar zu seyn,", "tokens": ["Schei\u00b7net", "et\u00b7was", "zwar", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber dieses geht vor allen,", "tokens": ["A\u00b7ber", "die\u00b7ses", "geht", "vor", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das man h\u00f6rt einhellig schallen:", "tokens": ["Das", "man", "h\u00f6rt", "ein\u00b7hel\u00b7lig", "schal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsre H\u00e4upter ziehen ein.", "tokens": ["Uns\u00b7re", "H\u00e4up\u00b7ter", "zie\u00b7hen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}