{"textgrid.poem.41833": {"metadata": {"author": {"name": "Otto, Louise", "birth": "N.A.", "death": "N.A."}, "title": "5.", "genre": "verse", "period": "N.A.", "pub_year": 1857, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie ich geliebt, gestrebt, gek\u00e4mpft, gelitten:", "tokens": ["Wie", "ich", "ge\u00b7liebt", ",", "ge\u00b7strebt", ",", "ge\u00b7k\u00e4mpft", ",", "ge\u00b7lit\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "$,", "VVPP", "$,", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu ", "tokens": ["Zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Und also mag es bis zum Tode w\u00e4hren \u2013", "tokens": ["Und", "al\u00b7so", "mag", "es", "bis", "zum", "To\u00b7de", "w\u00e4h\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das ist noch jetzt zu Gott mein br\u00fcnstig Bitten.", "tokens": ["Das", "ist", "noch", "jetzt", "zu", "Gott", "mein", "br\u00fcns\u00b7tig", "Bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "NN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Noch jetzt, da schon das Alter kommt geschritten,", "tokens": ["Noch", "jetzt", ",", "da", "schon", "das", "Al\u00b7ter", "kommt", "ge\u00b7schrit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "ADV", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Statt Rosen nur noch winken reife Aehren,", "tokens": ["Statt", "Ro\u00b7sen", "nur", "noch", "win\u00b7ken", "rei\u00b7fe", "A\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Nicht k\u00fchne W\u00fcnsche mehr sich seufzend n\u00e4hren,", "tokens": ["Nicht", "k\u00fch\u00b7ne", "W\u00fcn\u00b7sche", "mehr", "sich", "seuf\u00b7zend", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "ADV", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Phantasie die Fl\u00fcgel l\u00e4ngst beschnitten.", "tokens": ["Der", "Phan\u00b7ta\u00b7sie", "die", "Fl\u00fc\u00b7gel", "l\u00e4ngst", "be\u00b7schnit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Noch jetzt will ich den Tr\u00e4umen nicht entsagen,", "tokens": ["Noch", "jetzt", "will", "ich", "den", "Tr\u00e4u\u00b7men", "nicht", "ent\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Noch jetzt will ich im Kampfe nicht erlahmen,", "tokens": ["Noch", "jetzt", "will", "ich", "im", "Kamp\u00b7fe", "nicht", "er\u00b7lah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "APPRART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Eintreten noch f\u00fcr gro\u00dfe Menschheitsfragen.", "tokens": ["Ein\u00b7tre\u00b7ten", "noch", "f\u00fcr", "gro\u00b7\u00dfe", "Menschheits\u00b7fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Noch jetzt will ich f\u00fcr die, so nach mir kamen,", "tokens": ["Noch", "jetzt", "will", "ich", "f\u00fcr", "die", ",", "so", "nach", "mir", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "APPR", "ART", "$,", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Wort, das k\u00fchne, auszusprechen wagen:", "tokens": ["Das", "Wort", ",", "das", "k\u00fch\u00b7ne", ",", "aus\u00b7zu\u00b7spre\u00b7chen", "wa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,", "VVIZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wie ich geliebt, gestrebt, gek\u00e4mpft, gelitten:", "tokens": ["Wie", "ich", "ge\u00b7liebt", ",", "ge\u00b7strebt", ",", "ge\u00b7k\u00e4mpft", ",", "ge\u00b7lit\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "$,", "VVPP", "$,", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu ", "tokens": ["Zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Und also mag es bis zum Tode w\u00e4hren \u2013", "tokens": ["Und", "al\u00b7so", "mag", "es", "bis", "zum", "To\u00b7de", "w\u00e4h\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das ist noch jetzt zu Gott mein br\u00fcnstig Bitten.", "tokens": ["Das", "ist", "noch", "jetzt", "zu", "Gott", "mein", "br\u00fcns\u00b7tig", "Bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "NN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Noch jetzt, da schon das Alter kommt geschritten,", "tokens": ["Noch", "jetzt", ",", "da", "schon", "das", "Al\u00b7ter", "kommt", "ge\u00b7schrit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "ADV", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Statt Rosen nur noch winken reife Aehren,", "tokens": ["Statt", "Ro\u00b7sen", "nur", "noch", "win\u00b7ken", "rei\u00b7fe", "A\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Nicht k\u00fchne W\u00fcnsche mehr sich seufzend n\u00e4hren,", "tokens": ["Nicht", "k\u00fch\u00b7ne", "W\u00fcn\u00b7sche", "mehr", "sich", "seuf\u00b7zend", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "ADV", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Phantasie die Fl\u00fcgel l\u00e4ngst beschnitten.", "tokens": ["Der", "Phan\u00b7ta\u00b7sie", "die", "Fl\u00fc\u00b7gel", "l\u00e4ngst", "be\u00b7schnit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Noch jetzt will ich den Tr\u00e4umen nicht entsagen,", "tokens": ["Noch", "jetzt", "will", "ich", "den", "Tr\u00e4u\u00b7men", "nicht", "ent\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Noch jetzt will ich im Kampfe nicht erlahmen,", "tokens": ["Noch", "jetzt", "will", "ich", "im", "Kamp\u00b7fe", "nicht", "er\u00b7lah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "APPRART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Eintreten noch f\u00fcr gro\u00dfe Menschheitsfragen.", "tokens": ["Ein\u00b7tre\u00b7ten", "noch", "f\u00fcr", "gro\u00b7\u00dfe", "Menschheits\u00b7fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Noch jetzt will ich f\u00fcr die, so nach mir kamen,", "tokens": ["Noch", "jetzt", "will", "ich", "f\u00fcr", "die", ",", "so", "nach", "mir", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "APPR", "ART", "$,", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Wort, das k\u00fchne, auszusprechen wagen:", "tokens": ["Das", "Wort", ",", "das", "k\u00fch\u00b7ne", ",", "aus\u00b7zu\u00b7spre\u00b7chen", "wa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,", "VVIZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}