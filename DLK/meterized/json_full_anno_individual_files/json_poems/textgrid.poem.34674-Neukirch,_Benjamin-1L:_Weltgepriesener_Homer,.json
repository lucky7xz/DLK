{"textgrid.poem.34674": {"metadata": {"author": {"name": "Neukirch, Benjamin", "birth": "N.A.", "death": "N.A."}, "title": "1L: Weltgepriesener Homer,", "genre": "verse", "period": "N.A.", "pub_year": 1697, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Weltgepriesener Homer,", "tokens": ["Welt\u00b7ge\u00b7prie\u00b7se\u00b7ner", "Ho\u00b7mer", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Dessen Kunst mit dir verschwunden,", "tokens": ["Des\u00b7sen", "Kunst", "mit", "dir", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Warum warst du doch so sehr", "tokens": ["Wa\u00b7rum", "warst", "du", "doch", "so", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "An Achilles Zeit gebunden?", "tokens": ["An", "A\u00b7chil\u00b7les", "Zeit", "ge\u00b7bun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Heute sollt'st du lebend sein,", "tokens": ["Heu\u00b7te", "sollt'st", "du", "le\u00b7bend", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da die ungestimmten Fl\u00f6ten", "tokens": ["Da", "die", "un\u00b7ge\u00b7stimm\u00b7ten", "Fl\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Soviel hungriger Poeten", "tokens": ["So\u00b7viel", "hung\u00b7ri\u00b7ger", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Fast auf allen Gassen schrei'n", "tokens": ["Fast", "auf", "al\u00b7len", "Gas\u00b7sen", "schrei'n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Und dennoch mit ihrem Klingen", "tokens": ["Und", "den\u00b7noch", "mit", "ih\u00b7rem", "Klin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Kaum ein hartes Lied erzwingen!", "tokens": ["Kaum", "ein", "har\u00b7tes", "Lied", "er\u00b7zwin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbo wie kommt es\u00ab \u2013 d\u00fcnket mich,", "tokens": ["\u00bb", "o", "wie", "kommt", "es", "\u00ab", "\u2013", "d\u00fcn\u00b7ket", "mich", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "KON", "VVFIN", "PPER", "$(", "$(", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrdest du voll Eifers fragen \u2013,", "tokens": ["W\u00fcr\u00b7dest", "du", "voll", "Ei\u00b7fers", "fra\u00b7gen", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "NN", "VVINF", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbda die muntern Brennen sich", "tokens": ["\u00bb", "da", "die", "mun\u00b7tern", "Bren\u00b7nen", "sich"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "ADJA", "NN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die halbe Welt geschlagen,", "tokens": ["Durch", "die", "hal\u00b7be", "Welt", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da der Barbar sich gescheut,", "tokens": ["Da", "der", "Bar\u00b7bar", "sich", "ge\u00b7scheut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da die R\u00f6mer, da die Griechen", "tokens": ["Da", "die", "R\u00f6\u00b7mer", ",", "da", "die", "Grie\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Ihrer strengen Faust gewichen,", "tokens": ["Ih\u00b7rer", "stren\u00b7gen", "Faust", "ge\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df doch ihre Tapferkeit,", "tokens": ["Da\u00df", "doch", "ih\u00b7re", "Tap\u00b7fer\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Die sich ja noch nie verloren,", "tokens": ["Die", "sich", "ja", "noch", "nie", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Keinen Dichter hat geboren?\u00ab", "tokens": ["Kei\u00b7nen", "Dich\u00b7ter", "hat", "ge\u00b7bo\u00b7ren", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbmich empfing ein solches Land,", "tokens": ["\u00bb", "mich", "emp\u00b7fing", "ein", "sol\u00b7ches", "Land", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo die Helden Menschen waren;", "tokens": ["Wo", "die", "Hel\u00b7den", "Men\u00b7schen", "wa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleichwohl wu\u00dft' ich mit Verstand", "tokens": ["Gleich\u00b7wohl", "wu\u00dft'", "ich", "mit", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie den G\u00f6ttern beizupaaren;", "tokens": ["Sie", "den", "G\u00f6t\u00b7tern", "bei\u00b7zu\u00b7paa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00e4tt' ich in der Mark gelebt,", "tokens": ["H\u00e4tt'", "ich", "in", "der", "Mark", "ge\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wo man mehr von einem Helden,", "tokens": ["Wo", "man", "mehr", "von", "ei\u00b7nem", "Hel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als von G\u00f6ttern, wei\u00df zu melden,", "tokens": ["Als", "von", "G\u00f6t\u00b7tern", ",", "wei\u00df", "zu", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "$,", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ach, wo h\u00e4tt' ich hingestrebt!", "tokens": ["Ach", ",", "wo", "h\u00e4tt'", "ich", "hin\u00b7ge\u00b7strebt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Ach, was h\u00e4tten unsre Zungen", "tokens": ["Ach", ",", "was", "h\u00e4t\u00b7ten", "uns\u00b7re", "Zun\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWS", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Nicht f\u00fcr Thaten abgesungen!\u00ab \u2013", "tokens": ["Nicht", "f\u00fcr", "Tha\u00b7ten", "ab\u00b7ge\u00b7sun\u00b7gen", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VVPP", "$.", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "O Homer, du klagest recht;", "tokens": ["O", "Ho\u00b7mer", ",", "du", "kla\u00b7gest", "recht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Denn wo", "tokens": ["Denn", "wo"], "token_info": ["word", "word"], "pos": ["KON", "PWAV"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Ist die Poesie zu schlecht,", "tokens": ["Ist", "die", "Poe\u00b7sie", "zu", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKA", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da\u00df sie nichts, als Sch\u00fcler, zeiget.", "tokens": ["Da\u00df", "sie", "nichts", ",", "als", "Sch\u00fc\u00b7ler", ",", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "$,", "KOUS", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Friedrich pflanzt ein K\u00f6nigreich;", "tokens": ["Fried\u00b7rich", "pflanzt", "ein", "K\u00f6\u00b7nig\u00b7reich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir vergessen unsre Reimen,", "tokens": ["Wir", "ver\u00b7ges\u00b7sen", "uns\u00b7re", "Rei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder, so wir ja Was tr\u00e4umen,", "tokens": ["O\u00b7der", ",", "so", "wir", "ja", "Was", "tr\u00e4u\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "PPER", "ADV", "PWS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist's kaum seiner Jugend gleich,", "tokens": ["Ist's", "kaum", "sei\u00b7ner", "Ju\u00b7gend", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Weil er l\u00e4ngst vorbeigegangen,", "tokens": ["Weil", "er", "l\u00e4ngst", "vor\u00b7bei\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Wo wir denken anzufangen.", "tokens": ["Wo", "wir", "den\u00b7ken", "an\u00b7zu\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVINF", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch du konntest mehr, als wir:", "tokens": ["Doch", "du", "konn\u00b7test", "mehr", ",", "als", "wir", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADV", "$,", "KOUS", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du schriebst tausend sch\u00f6ne L\u00fcgen;", "tokens": ["Du", "schriebst", "tau\u00b7send", "sch\u00f6\u00b7ne", "L\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deine Helden mu\u00dften dir,", "tokens": ["Dei\u00b7ne", "Hel\u00b7den", "mu\u00df\u00b7ten", "dir", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie und wann du wolltest, siegen.", "tokens": ["Wie", "und", "wann", "du", "woll\u00b7test", ",", "sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "KON", "PWAV", "PPER", "VMFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Friedrich aber glaubt es nicht;", "tokens": ["Fried\u00b7rich", "a\u00b7ber", "glaubt", "es", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Er geht fort und l\u00e4\u00dft uns sitzen.", "tokens": ["Er", "geht", "fort", "und", "l\u00e4\u00dft", "uns", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was fragt er, wie sehr wir schwitzen,", "tokens": ["Was", "fragt", "er", ",", "wie", "sehr", "wir", "schwit\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PWAV", "ADV", "PPER", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und wie viel uns Zeit gebricht!", "tokens": ["Und", "wie", "viel", "uns", "Zeit", "ge\u00b7bricht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Was wir ganze Jahre dichten,", "tokens": ["Was", "wir", "gan\u00b7ze", "Jah\u00b7re", "dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJA", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Kann er einen Tag verrichten.", "tokens": ["Kann", "er", "ei\u00b7nen", "Tag", "ver\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Eh' man einen Vers erzwingt,", "tokens": ["Eh'", "man", "ei\u00b7nen", "Vers", "er\u00b7zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df er Schl\u00f6sser aufzubauen;", "tokens": ["Wei\u00df", "er", "Schl\u00f6s\u00b7ser", "auf\u00b7zu\u00b7bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eh' man seine Chur besingt,", "tokens": ["Eh'", "man", "sei\u00b7ne", "Chur", "be\u00b7singt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4\u00dft er sich als K\u00f6nig schauen.", "tokens": ["L\u00e4\u00dft", "er", "sich", "als", "K\u00f6\u00b7nig", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "KOUS", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrde, Gl\u00fcck und", "tokens": ["W\u00fcr\u00b7de", ",", "Gl\u00fcck", "und"], "token_info": ["word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "NN", "KON"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Sind bei ihm vereinte Sachen.", "tokens": ["Sind", "bei", "ihm", "ver\u00b7ein\u00b7te", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ADJA", "NN", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.7": {"text": "Was sonst Kriege pflegt zu machen,", "tokens": ["Was", "sonst", "Krie\u00b7ge", "pflegt", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "F\u00e4llt ihm von sich selber zu;", "tokens": ["F\u00e4llt", "ihm", "von", "sich", "sel\u00b7ber", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PRF", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Was Viel' mit Geschenken heben,", "tokens": ["Was", "Viel'", "mit", "Ge\u00b7schen\u00b7ken", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Hat ihm Gott und Recht gegeben.", "tokens": ["Hat", "ihm", "Gott", "und", "Recht", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Andre erben ihren Thron;", "tokens": ["And\u00b7re", "er\u00b7ben", "ih\u00b7ren", "Thron", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er wollt' ihn vorher verdienen;", "tokens": ["Er", "wollt'", "ihn", "vor\u00b7her", "ver\u00b7die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Darum hat sein Wesen schon", "tokens": ["Da\u00b7rum", "hat", "sein", "We\u00b7sen", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4ngst uns k\u00f6niglich geschienen.", "tokens": ["L\u00e4ngst", "uns", "k\u00f6\u00b7nig\u00b7lich", "ge\u00b7schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was er nicht im Titul war,", "tokens": ["Was", "er", "nicht", "im", "Ti\u00b7tul", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "War er doch in aller Herzen;", "tokens": ["War", "er", "doch", "in", "al\u00b7ler", "Her\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn wir w\u00fcnschten es mit Schmerzen,", "tokens": ["Denn", "wir", "w\u00fcnschten", "es", "mit", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und es spricht ein Jeder klar,", "tokens": ["Und", "es", "spricht", "ein", "Je\u00b7der", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Da\u00df er, was jetzund geschehen,", "tokens": ["Da\u00df", "er", ",", "was", "je\u00b7tzund", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "Lange schon vorher gesehen.", "tokens": ["Lan\u00b7ge", "schon", "vor\u00b7her", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "O ihr Musen, wachet auf!", "tokens": ["O", "ihr", "Mu\u00b7sen", ",", "wa\u00b7chet", "auf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Friedrich duldet kein Verweilen.", "tokens": ["Fried\u00b7rich", "dul\u00b7det", "kein", "Ver\u00b7wei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00f6rdert unsern sp\u00e4ten Lauf,", "tokens": ["F\u00f6r\u00b7dert", "un\u00b7sern", "sp\u00e4\u00b7ten", "Lauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Um ihm schneller nachzueilen!", "tokens": ["Um", "ihm", "schnel\u00b7ler", "nach\u00b7zu\u00b7ei\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nun er Preu\u00dfens K\u00f6nig hei\u00dft,", "tokens": ["Nun", "er", "Preu\u00b7\u00dfens", "K\u00f6\u00b7nig", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird er auch bald Thaten \u00fcben,", "tokens": ["Wird", "er", "auch", "bald", "Tha\u00b7ten", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die uns Maro schon beschrieben,", "tokens": ["Die", "uns", "Ma\u00b7ro", "schon", "be\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NE", "ADV", "VVPP", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.8": {"text": "Aber auch in Fabeln schleu\u00dft.", "tokens": ["A\u00b7ber", "auch", "in", "Fa\u00b7beln", "schleu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Uns wird M\u00fch' genug verbleiben,", "tokens": ["Uns", "wird", "M\u00fch'", "ge\u00b7nug", "ver\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Wenn wir nur die Wahrheit schreiben.", "tokens": ["Wenn", "wir", "nur", "die", "Wahr\u00b7heit", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Vormals pflegte, wie bewu\u00dft,", "tokens": ["Vor\u00b7mals", "pfleg\u00b7te", ",", "wie", "be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kaisern dies gew\u00fcnscht zu werden:", "tokens": ["Kai\u00b7sern", "dies", "ge\u00b7w\u00fcnscht", "zu", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "VVPP", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbherrsche l\u00e4nger", "tokens": ["\u00bb", "herr\u00b7sche", "l\u00e4n\u00b7ger"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJA", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Besser, als Trajan, auf Erden!\u00ab", "tokens": ["Bes\u00b7ser", ",", "als", "Tra\u00b7jan", ",", "auf", "Er\u00b7den", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADJD", "$,", "KOUS", "NN", "$,", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeit und Wunsch ver\u00e4ndert sich,", "tokens": ["Zeit", "und", "Wunsch", "ver\u00b7\u00e4n\u00b7dert", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und man wird in Zukunft", "tokens": ["Und", "man", "wird", "in", "Zu\u00b7kunft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "\u00bbwer will Kron' und Zepter tragen,", "tokens": ["\u00bb", "wer", "will", "Kron'", "und", "Zep\u00b7ter", "tra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "NE", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Herrsche so, wie Friederich!\u00ab \u2013", "tokens": ["Herr\u00b7sche", "so", ",", "wie", "Frie\u00b7de\u00b7rich", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADV", "$,", "PWAV", "NE", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Himmel, lass' es, wie wir flehen,", "tokens": ["Him\u00b7mel", ",", "lass'", "es", ",", "wie", "wir", "fle\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Unserm K\u00f6nig wohl ergehen!", "tokens": ["Un\u00b7serm", "K\u00f6\u00b7nig", "wohl", "er\u00b7ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Weltgepriesener Homer,", "tokens": ["Welt\u00b7ge\u00b7prie\u00b7se\u00b7ner", "Ho\u00b7mer", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Dessen Kunst mit dir verschwunden,", "tokens": ["Des\u00b7sen", "Kunst", "mit", "dir", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Warum warst du doch so sehr", "tokens": ["Wa\u00b7rum", "warst", "du", "doch", "so", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "An Achilles Zeit gebunden?", "tokens": ["An", "A\u00b7chil\u00b7les", "Zeit", "ge\u00b7bun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Heute sollt'st du lebend sein,", "tokens": ["Heu\u00b7te", "sollt'st", "du", "le\u00b7bend", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da die ungestimmten Fl\u00f6ten", "tokens": ["Da", "die", "un\u00b7ge\u00b7stimm\u00b7ten", "Fl\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Soviel hungriger Poeten", "tokens": ["So\u00b7viel", "hung\u00b7ri\u00b7ger", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Fast auf allen Gassen schrei'n", "tokens": ["Fast", "auf", "al\u00b7len", "Gas\u00b7sen", "schrei'n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Und dennoch mit ihrem Klingen", "tokens": ["Und", "den\u00b7noch", "mit", "ih\u00b7rem", "Klin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Kaum ein hartes Lied erzwingen!", "tokens": ["Kaum", "ein", "har\u00b7tes", "Lied", "er\u00b7zwin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "\u00bbo wie kommt es\u00ab \u2013 d\u00fcnket mich,", "tokens": ["\u00bb", "o", "wie", "kommt", "es", "\u00ab", "\u2013", "d\u00fcn\u00b7ket", "mich", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "KON", "VVFIN", "PPER", "$(", "$(", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrdest du voll Eifers fragen \u2013,", "tokens": ["W\u00fcr\u00b7dest", "du", "voll", "Ei\u00b7fers", "fra\u00b7gen", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "NN", "VVINF", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbda die muntern Brennen sich", "tokens": ["\u00bb", "da", "die", "mun\u00b7tern", "Bren\u00b7nen", "sich"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "ADJA", "NN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die halbe Welt geschlagen,", "tokens": ["Durch", "die", "hal\u00b7be", "Welt", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da der Barbar sich gescheut,", "tokens": ["Da", "der", "Bar\u00b7bar", "sich", "ge\u00b7scheut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da die R\u00f6mer, da die Griechen", "tokens": ["Da", "die", "R\u00f6\u00b7mer", ",", "da", "die", "Grie\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Ihrer strengen Faust gewichen,", "tokens": ["Ih\u00b7rer", "stren\u00b7gen", "Faust", "ge\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df doch ihre Tapferkeit,", "tokens": ["Da\u00df", "doch", "ih\u00b7re", "Tap\u00b7fer\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Die sich ja noch nie verloren,", "tokens": ["Die", "sich", "ja", "noch", "nie", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Keinen Dichter hat geboren?\u00ab", "tokens": ["Kei\u00b7nen", "Dich\u00b7ter", "hat", "ge\u00b7bo\u00b7ren", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbmich empfing ein solches Land,", "tokens": ["\u00bb", "mich", "emp\u00b7fing", "ein", "sol\u00b7ches", "Land", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo die Helden Menschen waren;", "tokens": ["Wo", "die", "Hel\u00b7den", "Men\u00b7schen", "wa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleichwohl wu\u00dft' ich mit Verstand", "tokens": ["Gleich\u00b7wohl", "wu\u00dft'", "ich", "mit", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie den G\u00f6ttern beizupaaren;", "tokens": ["Sie", "den", "G\u00f6t\u00b7tern", "bei\u00b7zu\u00b7paa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00e4tt' ich in der Mark gelebt,", "tokens": ["H\u00e4tt'", "ich", "in", "der", "Mark", "ge\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wo man mehr von einem Helden,", "tokens": ["Wo", "man", "mehr", "von", "ei\u00b7nem", "Hel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als von G\u00f6ttern, wei\u00df zu melden,", "tokens": ["Als", "von", "G\u00f6t\u00b7tern", ",", "wei\u00df", "zu", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "$,", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ach, wo h\u00e4tt' ich hingestrebt!", "tokens": ["Ach", ",", "wo", "h\u00e4tt'", "ich", "hin\u00b7ge\u00b7strebt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Ach, was h\u00e4tten unsre Zungen", "tokens": ["Ach", ",", "was", "h\u00e4t\u00b7ten", "uns\u00b7re", "Zun\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWS", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Nicht f\u00fcr Thaten abgesungen!\u00ab \u2013", "tokens": ["Nicht", "f\u00fcr", "Tha\u00b7ten", "ab\u00b7ge\u00b7sun\u00b7gen", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VVPP", "$.", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "O Homer, du klagest recht;", "tokens": ["O", "Ho\u00b7mer", ",", "du", "kla\u00b7gest", "recht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Denn wo", "tokens": ["Denn", "wo"], "token_info": ["word", "word"], "pos": ["KON", "PWAV"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Ist die Poesie zu schlecht,", "tokens": ["Ist", "die", "Poe\u00b7sie", "zu", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKA", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da\u00df sie nichts, als Sch\u00fcler, zeiget.", "tokens": ["Da\u00df", "sie", "nichts", ",", "als", "Sch\u00fc\u00b7ler", ",", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "$,", "KOUS", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Friedrich pflanzt ein K\u00f6nigreich;", "tokens": ["Fried\u00b7rich", "pflanzt", "ein", "K\u00f6\u00b7nig\u00b7reich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir vergessen unsre Reimen,", "tokens": ["Wir", "ver\u00b7ges\u00b7sen", "uns\u00b7re", "Rei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder, so wir ja Was tr\u00e4umen,", "tokens": ["O\u00b7der", ",", "so", "wir", "ja", "Was", "tr\u00e4u\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "PPER", "ADV", "PWS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist's kaum seiner Jugend gleich,", "tokens": ["Ist's", "kaum", "sei\u00b7ner", "Ju\u00b7gend", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Weil er l\u00e4ngst vorbeigegangen,", "tokens": ["Weil", "er", "l\u00e4ngst", "vor\u00b7bei\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Wo wir denken anzufangen.", "tokens": ["Wo", "wir", "den\u00b7ken", "an\u00b7zu\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVINF", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Doch du konntest mehr, als wir:", "tokens": ["Doch", "du", "konn\u00b7test", "mehr", ",", "als", "wir", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADV", "$,", "KOUS", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du schriebst tausend sch\u00f6ne L\u00fcgen;", "tokens": ["Du", "schriebst", "tau\u00b7send", "sch\u00f6\u00b7ne", "L\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deine Helden mu\u00dften dir,", "tokens": ["Dei\u00b7ne", "Hel\u00b7den", "mu\u00df\u00b7ten", "dir", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie und wann du wolltest, siegen.", "tokens": ["Wie", "und", "wann", "du", "woll\u00b7test", ",", "sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "KON", "PWAV", "PPER", "VMFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Friedrich aber glaubt es nicht;", "tokens": ["Fried\u00b7rich", "a\u00b7ber", "glaubt", "es", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Er geht fort und l\u00e4\u00dft uns sitzen.", "tokens": ["Er", "geht", "fort", "und", "l\u00e4\u00dft", "uns", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was fragt er, wie sehr wir schwitzen,", "tokens": ["Was", "fragt", "er", ",", "wie", "sehr", "wir", "schwit\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PWAV", "ADV", "PPER", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und wie viel uns Zeit gebricht!", "tokens": ["Und", "wie", "viel", "uns", "Zeit", "ge\u00b7bricht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Was wir ganze Jahre dichten,", "tokens": ["Was", "wir", "gan\u00b7ze", "Jah\u00b7re", "dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJA", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Kann er einen Tag verrichten.", "tokens": ["Kann", "er", "ei\u00b7nen", "Tag", "ver\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Eh' man einen Vers erzwingt,", "tokens": ["Eh'", "man", "ei\u00b7nen", "Vers", "er\u00b7zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df er Schl\u00f6sser aufzubauen;", "tokens": ["Wei\u00df", "er", "Schl\u00f6s\u00b7ser", "auf\u00b7zu\u00b7bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eh' man seine Chur besingt,", "tokens": ["Eh'", "man", "sei\u00b7ne", "Chur", "be\u00b7singt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4\u00dft er sich als K\u00f6nig schauen.", "tokens": ["L\u00e4\u00dft", "er", "sich", "als", "K\u00f6\u00b7nig", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "KOUS", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrde, Gl\u00fcck und", "tokens": ["W\u00fcr\u00b7de", ",", "Gl\u00fcck", "und"], "token_info": ["word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "NN", "KON"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Sind bei ihm vereinte Sachen.", "tokens": ["Sind", "bei", "ihm", "ver\u00b7ein\u00b7te", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ADJA", "NN", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.7": {"text": "Was sonst Kriege pflegt zu machen,", "tokens": ["Was", "sonst", "Krie\u00b7ge", "pflegt", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "F\u00e4llt ihm von sich selber zu;", "tokens": ["F\u00e4llt", "ihm", "von", "sich", "sel\u00b7ber", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PRF", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Was Viel' mit Geschenken heben,", "tokens": ["Was", "Viel'", "mit", "Ge\u00b7schen\u00b7ken", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Hat ihm Gott und Recht gegeben.", "tokens": ["Hat", "ihm", "Gott", "und", "Recht", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Andre erben ihren Thron;", "tokens": ["And\u00b7re", "er\u00b7ben", "ih\u00b7ren", "Thron", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er wollt' ihn vorher verdienen;", "tokens": ["Er", "wollt'", "ihn", "vor\u00b7her", "ver\u00b7die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Darum hat sein Wesen schon", "tokens": ["Da\u00b7rum", "hat", "sein", "We\u00b7sen", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4ngst uns k\u00f6niglich geschienen.", "tokens": ["L\u00e4ngst", "uns", "k\u00f6\u00b7nig\u00b7lich", "ge\u00b7schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was er nicht im Titul war,", "tokens": ["Was", "er", "nicht", "im", "Ti\u00b7tul", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "War er doch in aller Herzen;", "tokens": ["War", "er", "doch", "in", "al\u00b7ler", "Her\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn wir w\u00fcnschten es mit Schmerzen,", "tokens": ["Denn", "wir", "w\u00fcnschten", "es", "mit", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und es spricht ein Jeder klar,", "tokens": ["Und", "es", "spricht", "ein", "Je\u00b7der", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Da\u00df er, was jetzund geschehen,", "tokens": ["Da\u00df", "er", ",", "was", "je\u00b7tzund", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "Lange schon vorher gesehen.", "tokens": ["Lan\u00b7ge", "schon", "vor\u00b7her", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "O ihr Musen, wachet auf!", "tokens": ["O", "ihr", "Mu\u00b7sen", ",", "wa\u00b7chet", "auf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Friedrich duldet kein Verweilen.", "tokens": ["Fried\u00b7rich", "dul\u00b7det", "kein", "Ver\u00b7wei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00f6rdert unsern sp\u00e4ten Lauf,", "tokens": ["F\u00f6r\u00b7dert", "un\u00b7sern", "sp\u00e4\u00b7ten", "Lauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Um ihm schneller nachzueilen!", "tokens": ["Um", "ihm", "schnel\u00b7ler", "nach\u00b7zu\u00b7ei\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nun er Preu\u00dfens K\u00f6nig hei\u00dft,", "tokens": ["Nun", "er", "Preu\u00b7\u00dfens", "K\u00f6\u00b7nig", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird er auch bald Thaten \u00fcben,", "tokens": ["Wird", "er", "auch", "bald", "Tha\u00b7ten", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die uns Maro schon beschrieben,", "tokens": ["Die", "uns", "Ma\u00b7ro", "schon", "be\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NE", "ADV", "VVPP", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.8": {"text": "Aber auch in Fabeln schleu\u00dft.", "tokens": ["A\u00b7ber", "auch", "in", "Fa\u00b7beln", "schleu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Uns wird M\u00fch' genug verbleiben,", "tokens": ["Uns", "wird", "M\u00fch'", "ge\u00b7nug", "ver\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Wenn wir nur die Wahrheit schreiben.", "tokens": ["Wenn", "wir", "nur", "die", "Wahr\u00b7heit", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Vormals pflegte, wie bewu\u00dft,", "tokens": ["Vor\u00b7mals", "pfleg\u00b7te", ",", "wie", "be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kaisern dies gew\u00fcnscht zu werden:", "tokens": ["Kai\u00b7sern", "dies", "ge\u00b7w\u00fcnscht", "zu", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "VVPP", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbherrsche l\u00e4nger", "tokens": ["\u00bb", "herr\u00b7sche", "l\u00e4n\u00b7ger"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJA", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Besser, als Trajan, auf Erden!\u00ab", "tokens": ["Bes\u00b7ser", ",", "als", "Tra\u00b7jan", ",", "auf", "Er\u00b7den", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADJD", "$,", "KOUS", "NN", "$,", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeit und Wunsch ver\u00e4ndert sich,", "tokens": ["Zeit", "und", "Wunsch", "ver\u00b7\u00e4n\u00b7dert", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und man wird in Zukunft", "tokens": ["Und", "man", "wird", "in", "Zu\u00b7kunft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "\u00bbwer will Kron' und Zepter tragen,", "tokens": ["\u00bb", "wer", "will", "Kron'", "und", "Zep\u00b7ter", "tra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "NE", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Herrsche so, wie Friederich!\u00ab \u2013", "tokens": ["Herr\u00b7sche", "so", ",", "wie", "Frie\u00b7de\u00b7rich", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADV", "$,", "PWAV", "NE", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Himmel, lass' es, wie wir flehen,", "tokens": ["Him\u00b7mel", ",", "lass'", "es", ",", "wie", "wir", "fle\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Unserm K\u00f6nig wohl ergehen!", "tokens": ["Un\u00b7serm", "K\u00f6\u00b7nig", "wohl", "er\u00b7ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}