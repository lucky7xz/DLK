{"textgrid.poem.42898": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie sie den Fallschirm mir zeigt und erkl\u00e4rt,", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie sie den Fallschirm mir zeigt und erkl\u00e4rt,", "tokens": ["Wie", "sie", "den", "Fall\u00b7schirm", "mir", "zeigt", "und", "er\u00b7kl\u00e4rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PPER", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kann ich nur halb zuh\u00f6rn und zusehen.", "tokens": ["Kann", "ich", "nur", "halb", "zu\u00b7h\u00f6rn", "und", "zu\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich mu\u00df daran denken, wie ganz verkehrt", "tokens": ["Ich", "mu\u00df", "da\u00b7ran", "den\u00b7ken", ",", "wie", "ganz", "ver\u00b7kehrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PAV", "VVINF", "$,", "PWAV", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Oft Frauen mit ihren Schirmen umgehen.", "tokens": ["Oft", "Frau\u00b7en", "mit", "ih\u00b7ren", "Schir\u00b7men", "um\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ich bin doch sonst kein solch Angstpeter.", "tokens": ["Ich", "bin", "doch", "sonst", "kein", "solch", "Angst\u00b7pe\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIAT", "PIAT", "NN", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Aber nun \u2013 \u2013 Und nun sind wir so weit,", "tokens": ["A\u00b7ber", "nun", "\u2013", "\u2013", "Und", "nun", "sind", "wir", "so", "weit", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "$(", "KON", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Vielmehr so hoch. Etwa zweitausend Meter!", "tokens": ["Viel\u00b7mehr", "so", "hoch", ".", "Et\u00b7wa", "zweit\u00b7au\u00b7send", "Me\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$.", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wir erheben uns. \u00bbAlles bereit?\u00ab", "tokens": ["Wir", "er\u00b7he\u00b7ben", "uns", ".", "\u00bb", "Al\u00b7les", "be\u00b7reit", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "$(", "PIS", "ADJD", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Ich \u00f6ffne die T\u00fcre.", "tokens": ["Ich", "\u00f6ff\u00b7ne", "die", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "\u00bbgott soll Sie erhalten", "tokens": ["\u00bb", "gott", "soll", "Sie", "er\u00b7hal\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Und Ihren seidenen Schirm entfalten.", "tokens": ["Und", "Ih\u00b7ren", "sei\u00b7de\u00b7nen", "Schirm", "ent\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Ich sch\u00f6sse mich tot, wenn ich jemals erf\u00fchre \u2013 \u2013\u00ab", "tokens": ["Ich", "sch\u00f6s\u00b7se", "mich", "tot", ",", "wenn", "ich", "je\u00b7mals", "er\u00b7f\u00fch\u00b7re", "\u2013", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$(", "$(", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Mir graust.", "tokens": ["Mir", "graust", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "+O", "measure": "unknown.measure.single"}, "line.2": {"text": "Das Frauenzimmer ist abgesaust.", "tokens": ["Das", "Frau\u00b7en\u00b7zim\u00b7mer", "ist", "ab\u00b7ge\u00b7saust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich blicke ihr nach. Einmal \u00fcberschl\u00e4gt sie", "tokens": ["Ich", "bli\u00b7cke", "ihr", "nach", ".", "Ein\u00b7mal", "\u00fc\u00b7bersc\u00b7hl\u00e4gt", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich, wird ein Punkt, dann ein P\u00fcnktchen, und, ach,", "tokens": ["Sich", ",", "wird", "ein", "Punkt", ",", "dann", "ein", "P\u00fcnkt\u00b7chen", ",", "und", ",", "ach", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "$,", "VAFIN", "ART", "NN", "$,", "ADV", "ART", "NN", "$,", "KON", "$,", "ITJ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Pl\u00f6tzlich ein sonnig blitzendes Dach,", "tokens": ["Pl\u00f6tz\u00b7lich", "ein", "son\u00b7nig", "blit\u00b7zen\u00b7des", "Dach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und ich wei\u00df: Das Dach tr\u00e4gt sie.", "tokens": ["Und", "ich", "wei\u00df", ":", "Das", "Dach", "tr\u00e4gt", "sie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich schlie\u00dfe die T\u00fcre und rei\u00dfe die Watte", "tokens": ["Ich", "schlie\u00b7\u00dfe", "die", "T\u00fc\u00b7re", "und", "rei\u00b7\u00dfe", "die", "Wat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Aus meinen Ohren. Ich f\u00fchle mich frei", "tokens": ["Aus", "mei\u00b7nen", "Oh\u00b7ren", ".", "Ich", "f\u00fch\u00b7le", "mich", "frei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PRF", "ADJD"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und sicher. Und \u00e4rgre mich doch dabei,", "tokens": ["Und", "si\u00b7cher", ".", "Und", "\u00e4r\u00b7gre", "mich", "doch", "da\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "KON", "VVFIN", "PPER", "ADV", "PAV", "$,"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Weil sie mehr Schneid als ich hatte.", "tokens": ["Weil", "sie", "mehr", "Schneid", "als", "ich", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "KOUS", "PPER", "VAFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Wie sie den Fallschirm mir zeigt und erkl\u00e4rt,", "tokens": ["Wie", "sie", "den", "Fall\u00b7schirm", "mir", "zeigt", "und", "er\u00b7kl\u00e4rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PPER", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kann ich nur halb zuh\u00f6rn und zusehen.", "tokens": ["Kann", "ich", "nur", "halb", "zu\u00b7h\u00f6rn", "und", "zu\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich mu\u00df daran denken, wie ganz verkehrt", "tokens": ["Ich", "mu\u00df", "da\u00b7ran", "den\u00b7ken", ",", "wie", "ganz", "ver\u00b7kehrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PAV", "VVINF", "$,", "PWAV", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Oft Frauen mit ihren Schirmen umgehen.", "tokens": ["Oft", "Frau\u00b7en", "mit", "ih\u00b7ren", "Schir\u00b7men", "um\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ich bin doch sonst kein solch Angstpeter.", "tokens": ["Ich", "bin", "doch", "sonst", "kein", "solch", "Angst\u00b7pe\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIAT", "PIAT", "NN", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Aber nun \u2013 \u2013 Und nun sind wir so weit,", "tokens": ["A\u00b7ber", "nun", "\u2013", "\u2013", "Und", "nun", "sind", "wir", "so", "weit", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "$(", "KON", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Vielmehr so hoch. Etwa zweitausend Meter!", "tokens": ["Viel\u00b7mehr", "so", "hoch", ".", "Et\u00b7wa", "zweit\u00b7au\u00b7send", "Me\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$.", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wir erheben uns. \u00bbAlles bereit?\u00ab", "tokens": ["Wir", "er\u00b7he\u00b7ben", "uns", ".", "\u00bb", "Al\u00b7les", "be\u00b7reit", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "$(", "PIS", "ADJD", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Ich \u00f6ffne die T\u00fcre.", "tokens": ["Ich", "\u00f6ff\u00b7ne", "die", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "\u00bbgott soll Sie erhalten", "tokens": ["\u00bb", "gott", "soll", "Sie", "er\u00b7hal\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Und Ihren seidenen Schirm entfalten.", "tokens": ["Und", "Ih\u00b7ren", "sei\u00b7de\u00b7nen", "Schirm", "ent\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Ich sch\u00f6sse mich tot, wenn ich jemals erf\u00fchre \u2013 \u2013\u00ab", "tokens": ["Ich", "sch\u00f6s\u00b7se", "mich", "tot", ",", "wenn", "ich", "je\u00b7mals", "er\u00b7f\u00fch\u00b7re", "\u2013", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$(", "$(", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.5": {"line.1": {"text": "Mir graust.", "tokens": ["Mir", "graust", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "+O", "measure": "unknown.measure.single"}, "line.2": {"text": "Das Frauenzimmer ist abgesaust.", "tokens": ["Das", "Frau\u00b7en\u00b7zim\u00b7mer", "ist", "ab\u00b7ge\u00b7saust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich blicke ihr nach. Einmal \u00fcberschl\u00e4gt sie", "tokens": ["Ich", "bli\u00b7cke", "ihr", "nach", ".", "Ein\u00b7mal", "\u00fc\u00b7bersc\u00b7hl\u00e4gt", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich, wird ein Punkt, dann ein P\u00fcnktchen, und, ach,", "tokens": ["Sich", ",", "wird", "ein", "Punkt", ",", "dann", "ein", "P\u00fcnkt\u00b7chen", ",", "und", ",", "ach", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "$,", "VAFIN", "ART", "NN", "$,", "ADV", "ART", "NN", "$,", "KON", "$,", "ITJ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Pl\u00f6tzlich ein sonnig blitzendes Dach,", "tokens": ["Pl\u00f6tz\u00b7lich", "ein", "son\u00b7nig", "blit\u00b7zen\u00b7des", "Dach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und ich wei\u00df: Das Dach tr\u00e4gt sie.", "tokens": ["Und", "ich", "wei\u00df", ":", "Das", "Dach", "tr\u00e4gt", "sie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich schlie\u00dfe die T\u00fcre und rei\u00dfe die Watte", "tokens": ["Ich", "schlie\u00b7\u00dfe", "die", "T\u00fc\u00b7re", "und", "rei\u00b7\u00dfe", "die", "Wat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Aus meinen Ohren. Ich f\u00fchle mich frei", "tokens": ["Aus", "mei\u00b7nen", "Oh\u00b7ren", ".", "Ich", "f\u00fch\u00b7le", "mich", "frei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PRF", "ADJD"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und sicher. Und \u00e4rgre mich doch dabei,", "tokens": ["Und", "si\u00b7cher", ".", "Und", "\u00e4r\u00b7gre", "mich", "doch", "da\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "KON", "VVFIN", "PPER", "ADV", "PAV", "$,"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Weil sie mehr Schneid als ich hatte.", "tokens": ["Weil", "sie", "mehr", "Schneid", "als", "ich", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "KOUS", "PPER", "VAFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}}}}