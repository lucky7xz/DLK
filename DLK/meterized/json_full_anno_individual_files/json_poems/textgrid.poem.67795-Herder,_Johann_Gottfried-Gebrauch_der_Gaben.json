{"textgrid.poem.67795": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Gebrauch der Gaben", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Gabe nimmt sich Niemand, sie", "tokens": ["Die", "Ga\u00b7be", "nimmt", "sich", "Nie\u00b7mand", ",", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "PIS", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird ihm von Gott verliehen;", "tokens": ["Wird", "ihm", "von", "Gott", "ver\u00b7lie\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur wer sie mi\u00dfbraucht, dem wird nie", "tokens": ["Nur", "wer", "sie", "mi\u00df\u00b7braucht", ",", "dem", "wird", "nie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PWS", "PPER", "VVPP", "$,", "PDS", "VAFIN", "ADV"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Der Mi\u00dfgebrauch verziehen;", "tokens": ["Der", "Mi\u00df\u00b7ge\u00b7brauch", "ver\u00b7zie\u00b7hen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wer sie nicht brauchet ganz und recht,", "tokens": ["Wer", "sie", "nicht", "brau\u00b7chet", "ganz", "und", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VVFIN", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist ein verworfner, b\u00f6ser Knecht.", "tokens": ["Ist", "ein", "ver\u00b7worf\u00b7ner", ",", "b\u00f6\u00b7ser", "Knecht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Herr, lehre mich Zufriedenheit", "tokens": ["Herr", ",", "leh\u00b7re", "mich", "Zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch rechten Brauch der Gabe!", "tokens": ["Durch", "rech\u00b7ten", "Brauch", "der", "Ga\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weit \u00fcber meine Dankbarkeit", "tokens": ["Weit", "\u00fc\u00b7ber", "mei\u00b7ne", "Dank\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Reicht, was ich von Dir habe.", "tokens": ["Reicht", ",", "was", "ich", "von", "Dir", "ha\u00b7be", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "APPR", "PPER", "VAFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "H\u00e4tt' ich gethan auch noch so viel,", "tokens": ["H\u00e4tt'", "ich", "ge\u00b7than", "auch", "noch", "so", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "ADV", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie ferne bin ich noch vom Ziel!", "tokens": ["Wie", "fer\u00b7ne", "bin", "ich", "noch", "vom", "Ziel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wo irgend eine Thr\u00e4ne flie\u00dft,", "tokens": ["Wo", "ir\u00b7gend", "ei\u00b7ne", "Thr\u00e4\u00b7ne", "flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ich wol trocknen k\u00f6nnte,", "tokens": ["Die", "ich", "wol", "trock\u00b7nen", "k\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo irgend sich ein Gram ergie\u00dft,", "tokens": ["Wo", "ir\u00b7gend", "sich", "ein", "Gram", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der mir Zutrauen g\u00f6nnte,", "tokens": ["Der", "mir", "Zu\u00b7trau\u00b7en", "g\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ich nicht, was ich soll, gethan:", "tokens": ["Und", "ich", "nicht", ",", "was", "ich", "soll", ",", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "$,", "PWS", "PPER", "VMFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "O Herr, das Nichtthun klagt mich an!", "tokens": ["O", "Herr", ",", "das", "Nicht\u00b7thun", "klagt", "mich", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wo M\u00e4ngel ich und Irrthum sah", "tokens": ["Wo", "M\u00e4n\u00b7gel", "ich", "und", "Irr\u00b7thum", "sah"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "PPER", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(wie viele sind hienieden!),", "tokens": ["(", "wie", "vie\u00b7le", "sind", "hien\u00b7ie\u00b7den", "!", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PWAV", "PIS", "VAFIN", "ADV", "$.", "$(", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mein Gewissen trat mir nah:", "tokens": ["Und", "mein", "Ge\u00b7wis\u00b7sen", "trat", "mir", "nah", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdie Pflicht ist Dir beschieden;", "tokens": ["\u00bb", "die", "Pflicht", "ist", "Dir", "be\u00b7schie\u00b7den", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Zu helfen hier ist s\u00fc\u00dfe M\u00fch!\u00ab", "tokens": ["Zu", "hel\u00b7fen", "hier", "ist", "s\u00fc\u00b7\u00dfe", "M\u00fch", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "VAFIN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie oft, Herr, unterlie\u00df ich sie!", "tokens": ["Wie", "oft", ",", "Herr", ",", "un\u00b7ter\u00b7lie\u00df", "ich", "sie", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und doch ist Menschenseligkeit", "tokens": ["Und", "doch", "ist", "Men\u00b7schen\u00b7se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Erf\u00fcllen, was die Pflicht gebeut", "tokens": ["Er\u00b7f\u00fcl\u00b7len", ",", "was", "die", "Pflicht", "ge\u00b7beut"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und treu ich leisten sollte.", "tokens": ["Und", "treu", "ich", "leis\u00b7ten", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was Niemand als ich konnte thun,", "tokens": ["Was", "Nie\u00b7mand", "als", "ich", "konn\u00b7te", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "KOKOM", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu thun, hei\u00dft in der Pflicht beruhn.", "tokens": ["Zu", "thun", ",", "hei\u00dft", "in", "der", "Pflicht", "be\u00b7ruhn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VVFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Erbarmen, Herr, und Liebe hebt", "tokens": ["Er\u00b7bar\u00b7men", ",", "Herr", ",", "und", "Lie\u00b7be", "hebt"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns \u00fcber alles Streben;", "tokens": ["Uns", "\u00fc\u00b7ber", "al\u00b7les", "Stre\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In guter Menschen Herzen lebt", "tokens": ["In", "gu\u00b7ter", "Men\u00b7schen", "Her\u00b7zen", "lebt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich wol das sch\u00f6nste Leben;", "tokens": ["Sich", "wol", "das", "sch\u00f6ns\u00b7te", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr Andre wirken, ist uns Ruhm", "tokens": ["F\u00fcr", "And\u00b7re", "wir\u00b7ken", ",", "ist", "uns", "Ruhm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIS", "VVINF", "$,", "VAFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Trost und Evangelium.", "tokens": ["Und", "Trost", "und", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und ach, wie viel verstrichen schon", "tokens": ["Und", "ach", ",", "wie", "viel", "ver\u00b7stri\u00b7chen", "schon"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PWAV", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir Tag' und Jahr' und Kr\u00e4fte!", "tokens": ["Mir", "Tag'", "und", "Jahr'", "und", "Kr\u00e4f\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ist verhallt des Lebens Ton,", "tokens": ["Und", "ist", "ver\u00b7hallt", "des", "Le\u00b7bens", "Ton", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vertrocknet seine S\u00e4fte:", "tokens": ["Ver\u00b7trock\u00b7net", "sei\u00b7ne", "S\u00e4f\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wer t\u00e4glich seinen Tag verlor,", "tokens": ["Wer", "t\u00e4g\u00b7lich", "sei\u00b7nen", "Tag", "ver\u00b7lor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist bis zum letzten Tag ein Thor.", "tokens": ["Ist", "bis", "zum", "letz\u00b7ten", "Tag", "ein", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Herr, hilf mir, da\u00df ich werde bald,", "tokens": ["Herr", ",", "hilf", "mir", ",", "da\u00df", "ich", "wer\u00b7de", "bald", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "$,", "KOUS", "PPER", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was je ich werden sollte,", "tokens": ["Was", "je", "ich", "wer\u00b7den", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPER", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und eh die letzte Stunde schallt,", "tokens": ["Und", "eh", "die", "letz\u00b7te", "Stun\u00b7de", "schallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich es ernstlich wollte!", "tokens": ["Da\u00df", "ich", "es", "ernst\u00b7lich", "woll\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Im Tod und Leben ist uns wohl,", "tokens": ["Im", "Tod", "und", "Le\u00b7ben", "ist", "uns", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn man das ist, was man sein soll.", "tokens": ["Wenn", "man", "das", "ist", ",", "was", "man", "sein", "soll", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PDS", "VAFIN", "$,", "PRELS", "PIS", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Die Gabe nimmt sich Niemand, sie", "tokens": ["Die", "Ga\u00b7be", "nimmt", "sich", "Nie\u00b7mand", ",", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "PIS", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird ihm von Gott verliehen;", "tokens": ["Wird", "ihm", "von", "Gott", "ver\u00b7lie\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur wer sie mi\u00dfbraucht, dem wird nie", "tokens": ["Nur", "wer", "sie", "mi\u00df\u00b7braucht", ",", "dem", "wird", "nie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PWS", "PPER", "VVPP", "$,", "PDS", "VAFIN", "ADV"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Der Mi\u00dfgebrauch verziehen;", "tokens": ["Der", "Mi\u00df\u00b7ge\u00b7brauch", "ver\u00b7zie\u00b7hen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wer sie nicht brauchet ganz und recht,", "tokens": ["Wer", "sie", "nicht", "brau\u00b7chet", "ganz", "und", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VVFIN", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist ein verworfner, b\u00f6ser Knecht.", "tokens": ["Ist", "ein", "ver\u00b7worf\u00b7ner", ",", "b\u00f6\u00b7ser", "Knecht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Herr, lehre mich Zufriedenheit", "tokens": ["Herr", ",", "leh\u00b7re", "mich", "Zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch rechten Brauch der Gabe!", "tokens": ["Durch", "rech\u00b7ten", "Brauch", "der", "Ga\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weit \u00fcber meine Dankbarkeit", "tokens": ["Weit", "\u00fc\u00b7ber", "mei\u00b7ne", "Dank\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Reicht, was ich von Dir habe.", "tokens": ["Reicht", ",", "was", "ich", "von", "Dir", "ha\u00b7be", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "APPR", "PPER", "VAFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "H\u00e4tt' ich gethan auch noch so viel,", "tokens": ["H\u00e4tt'", "ich", "ge\u00b7than", "auch", "noch", "so", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "ADV", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie ferne bin ich noch vom Ziel!", "tokens": ["Wie", "fer\u00b7ne", "bin", "ich", "noch", "vom", "Ziel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wo irgend eine Thr\u00e4ne flie\u00dft,", "tokens": ["Wo", "ir\u00b7gend", "ei\u00b7ne", "Thr\u00e4\u00b7ne", "flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ich wol trocknen k\u00f6nnte,", "tokens": ["Die", "ich", "wol", "trock\u00b7nen", "k\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo irgend sich ein Gram ergie\u00dft,", "tokens": ["Wo", "ir\u00b7gend", "sich", "ein", "Gram", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der mir Zutrauen g\u00f6nnte,", "tokens": ["Der", "mir", "Zu\u00b7trau\u00b7en", "g\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ich nicht, was ich soll, gethan:", "tokens": ["Und", "ich", "nicht", ",", "was", "ich", "soll", ",", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "$,", "PWS", "PPER", "VMFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "O Herr, das Nichtthun klagt mich an!", "tokens": ["O", "Herr", ",", "das", "Nicht\u00b7thun", "klagt", "mich", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wo M\u00e4ngel ich und Irrthum sah", "tokens": ["Wo", "M\u00e4n\u00b7gel", "ich", "und", "Irr\u00b7thum", "sah"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "PPER", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(wie viele sind hienieden!),", "tokens": ["(", "wie", "vie\u00b7le", "sind", "hien\u00b7ie\u00b7den", "!", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PWAV", "PIS", "VAFIN", "ADV", "$.", "$(", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mein Gewissen trat mir nah:", "tokens": ["Und", "mein", "Ge\u00b7wis\u00b7sen", "trat", "mir", "nah", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdie Pflicht ist Dir beschieden;", "tokens": ["\u00bb", "die", "Pflicht", "ist", "Dir", "be\u00b7schie\u00b7den", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Zu helfen hier ist s\u00fc\u00dfe M\u00fch!\u00ab", "tokens": ["Zu", "hel\u00b7fen", "hier", "ist", "s\u00fc\u00b7\u00dfe", "M\u00fch", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "VAFIN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie oft, Herr, unterlie\u00df ich sie!", "tokens": ["Wie", "oft", ",", "Herr", ",", "un\u00b7ter\u00b7lie\u00df", "ich", "sie", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und doch ist Menschenseligkeit", "tokens": ["Und", "doch", "ist", "Men\u00b7schen\u00b7se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Erf\u00fcllen, was die Pflicht gebeut", "tokens": ["Er\u00b7f\u00fcl\u00b7len", ",", "was", "die", "Pflicht", "ge\u00b7beut"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und treu ich leisten sollte.", "tokens": ["Und", "treu", "ich", "leis\u00b7ten", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was Niemand als ich konnte thun,", "tokens": ["Was", "Nie\u00b7mand", "als", "ich", "konn\u00b7te", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "KOKOM", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu thun, hei\u00dft in der Pflicht beruhn.", "tokens": ["Zu", "thun", ",", "hei\u00dft", "in", "der", "Pflicht", "be\u00b7ruhn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VVFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Erbarmen, Herr, und Liebe hebt", "tokens": ["Er\u00b7bar\u00b7men", ",", "Herr", ",", "und", "Lie\u00b7be", "hebt"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns \u00fcber alles Streben;", "tokens": ["Uns", "\u00fc\u00b7ber", "al\u00b7les", "Stre\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In guter Menschen Herzen lebt", "tokens": ["In", "gu\u00b7ter", "Men\u00b7schen", "Her\u00b7zen", "lebt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich wol das sch\u00f6nste Leben;", "tokens": ["Sich", "wol", "das", "sch\u00f6ns\u00b7te", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr Andre wirken, ist uns Ruhm", "tokens": ["F\u00fcr", "And\u00b7re", "wir\u00b7ken", ",", "ist", "uns", "Ruhm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIS", "VVINF", "$,", "VAFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Trost und Evangelium.", "tokens": ["Und", "Trost", "und", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und ach, wie viel verstrichen schon", "tokens": ["Und", "ach", ",", "wie", "viel", "ver\u00b7stri\u00b7chen", "schon"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PWAV", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir Tag' und Jahr' und Kr\u00e4fte!", "tokens": ["Mir", "Tag'", "und", "Jahr'", "und", "Kr\u00e4f\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ist verhallt des Lebens Ton,", "tokens": ["Und", "ist", "ver\u00b7hallt", "des", "Le\u00b7bens", "Ton", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vertrocknet seine S\u00e4fte:", "tokens": ["Ver\u00b7trock\u00b7net", "sei\u00b7ne", "S\u00e4f\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wer t\u00e4glich seinen Tag verlor,", "tokens": ["Wer", "t\u00e4g\u00b7lich", "sei\u00b7nen", "Tag", "ver\u00b7lor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist bis zum letzten Tag ein Thor.", "tokens": ["Ist", "bis", "zum", "letz\u00b7ten", "Tag", "ein", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Herr, hilf mir, da\u00df ich werde bald,", "tokens": ["Herr", ",", "hilf", "mir", ",", "da\u00df", "ich", "wer\u00b7de", "bald", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "$,", "KOUS", "PPER", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was je ich werden sollte,", "tokens": ["Was", "je", "ich", "wer\u00b7den", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPER", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und eh die letzte Stunde schallt,", "tokens": ["Und", "eh", "die", "letz\u00b7te", "Stun\u00b7de", "schallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich es ernstlich wollte!", "tokens": ["Da\u00df", "ich", "es", "ernst\u00b7lich", "woll\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Im Tod und Leben ist uns wohl,", "tokens": ["Im", "Tod", "und", "Le\u00b7ben", "ist", "uns", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn man das ist, was man sein soll.", "tokens": ["Wenn", "man", "das", "ist", ",", "was", "man", "sein", "soll", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PDS", "VAFIN", "$,", "PRELS", "PIS", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}