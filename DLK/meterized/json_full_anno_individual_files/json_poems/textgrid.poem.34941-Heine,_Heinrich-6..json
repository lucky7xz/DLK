{"textgrid.poem.34941": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "6.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dem einen die Perle, dem andern die Truhe,", "tokens": ["Dem", "ei\u00b7nen", "die", "Per\u00b7le", ",", "dem", "an\u00b7dern", "die", "Tru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ART", "NN", "$,", "PRELS", "PIS", "ART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "O Wilhelm Wisetzki, du starbest so fruhe \u2013", "tokens": ["O", "Wil\u00b7helm", "Wi\u00b7setz\u00b7ki", ",", "du", "star\u00b7best", "so", "fru\u00b7he", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,", "PPER", "VVFIN", "ADV", "ADJA", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.2": {"line.1": {"text": "Der Balken brach, worauf er geklommen,", "tokens": ["Der", "Bal\u00b7ken", "brach", ",", "wo\u00b7rauf", "er", "ge\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ist er im Wasser umgekommen \u2013", "tokens": ["Da", "ist", "er", "im", "Was\u00b7ser", "um\u00b7ge\u00b7kom\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.3": {"line.1": {"text": "Wir folgten der Leiche, dem lieblichen Knaben,", "tokens": ["Wir", "folg\u00b7ten", "der", "Lei\u00b7che", ",", "dem", "lieb\u00b7li\u00b7chen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sie haben ihn unter Maiblumen begraben \u2013", "tokens": ["Sie", "ha\u00b7ben", "ihn", "un\u00b7ter", "Maib\u00b7lu\u00b7men", "be\u00b7gra\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.4": {"line.1": {"text": "Bist klug gewesen, du bist entronnen", "tokens": ["Bist", "klug", "ge\u00b7we\u00b7sen", ",", "du", "bist", "ent\u00b7ron\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "VAPP", "$,", "PPER", "VAFIN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den St\u00fcrmen, hast fr\u00fch ein Obdach gewonnen \u2013", "tokens": ["Den", "St\u00fcr\u00b7men", ",", "hast", "fr\u00fch", "ein", "Ob\u00b7dach", "ge\u00b7won\u00b7nen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "ADJD", "ART", "NN", "VVPP", "$("], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.5": {"line.1": {"text": "Bist fr\u00fch entronnen, bist klug gewesen,", "tokens": ["Bist", "fr\u00fch", "ent\u00b7ron\u00b7nen", ",", "bist", "klug", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVINF", "$,", "VAFIN", "ADJD", "VAPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Noch eh' du erkranktest, bist du genesen \u2013", "tokens": ["Noch", "eh'", "du", "er\u00b7krank\u00b7test", ",", "bist", "du", "ge\u00b7ne\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+--+-+----", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.6": {"line.1": {"text": "Seit langen Jahren, wie oft, o Kleiner,", "tokens": ["Seit", "lan\u00b7gen", "Jah\u00b7ren", ",", "wie", "oft", ",", "o", "Klei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PWAV", "ADV", "$,", "FM", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Neid und Wehmut gedenk ich deiner \u2013", "tokens": ["Mit", "Neid", "und", "Weh\u00b7mut", "ge\u00b7denk", "ich", "dei\u00b7ner", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PPOSAT", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.7": {"line.1": {"text": "Dem einen die Perle, dem andern die Truhe,", "tokens": ["Dem", "ei\u00b7nen", "die", "Per\u00b7le", ",", "dem", "an\u00b7dern", "die", "Tru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ART", "NN", "$,", "PRELS", "PIS", "ART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "O Wilhelm Wisetzki, du starbest so fruhe \u2013", "tokens": ["O", "Wil\u00b7helm", "Wi\u00b7setz\u00b7ki", ",", "du", "star\u00b7best", "so", "fru\u00b7he", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,", "PPER", "VVFIN", "ADV", "ADJA", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.8": {"line.1": {"text": "Der Balken brach, worauf er geklommen,", "tokens": ["Der", "Bal\u00b7ken", "brach", ",", "wo\u00b7rauf", "er", "ge\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ist er im Wasser umgekommen \u2013", "tokens": ["Da", "ist", "er", "im", "Was\u00b7ser", "um\u00b7ge\u00b7kom\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.9": {"line.1": {"text": "Wir folgten der Leiche, dem lieblichen Knaben,", "tokens": ["Wir", "folg\u00b7ten", "der", "Lei\u00b7che", ",", "dem", "lieb\u00b7li\u00b7chen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sie haben ihn unter Maiblumen begraben \u2013", "tokens": ["Sie", "ha\u00b7ben", "ihn", "un\u00b7ter", "Maib\u00b7lu\u00b7men", "be\u00b7gra\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.10": {"line.1": {"text": "Bist klug gewesen, du bist entronnen", "tokens": ["Bist", "klug", "ge\u00b7we\u00b7sen", ",", "du", "bist", "ent\u00b7ron\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "VAPP", "$,", "PPER", "VAFIN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den St\u00fcrmen, hast fr\u00fch ein Obdach gewonnen \u2013", "tokens": ["Den", "St\u00fcr\u00b7men", ",", "hast", "fr\u00fch", "ein", "Ob\u00b7dach", "ge\u00b7won\u00b7nen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "ADJD", "ART", "NN", "VVPP", "$("], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.11": {"line.1": {"text": "Bist fr\u00fch entronnen, bist klug gewesen,", "tokens": ["Bist", "fr\u00fch", "ent\u00b7ron\u00b7nen", ",", "bist", "klug", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVINF", "$,", "VAFIN", "ADJD", "VAPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Noch eh' du erkranktest, bist du genesen \u2013", "tokens": ["Noch", "eh'", "du", "er\u00b7krank\u00b7test", ",", "bist", "du", "ge\u00b7ne\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+--+-+----", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.12": {"line.1": {"text": "Seit langen Jahren, wie oft, o Kleiner,", "tokens": ["Seit", "lan\u00b7gen", "Jah\u00b7ren", ",", "wie", "oft", ",", "o", "Klei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PWAV", "ADV", "$,", "FM", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Neid und Wehmut gedenk ich deiner \u2013", "tokens": ["Mit", "Neid", "und", "Weh\u00b7mut", "ge\u00b7denk", "ich", "dei\u00b7ner", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PPOSAT", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch die Katze, die Katz' ist gerettet.", "tokens": ["Doch", "die", "Kat\u00b7ze", ",", "die", "Katz'", "ist", "ge\u00b7ret\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}}}}