{"textgrid.poem.64185": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Maria Stuart und Sir Gordon", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "An Englands Grenze harret die sch\u00f6ne S\u00fcnderin:", "tokens": ["An", "En\u00b7glands", "Gren\u00b7ze", "har\u00b7ret", "die", "sch\u00f6\u00b7ne", "S\u00fcn\u00b7de\u00b7rin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch nicht mehr steht nach London, nach anderm steht ihr Sinn.", "tokens": ["Doch", "nicht", "mehr", "steht", "nach", "Lon\u00b7don", ",", "nach", "an\u00b7derm", "steht", "ihr", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVFIN", "APPR", "NE", "$,", "APPR", "PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Er steht nach neuer Liebe, nach neuem Gl\u00fcck und Wahn:", "tokens": ["Er", "steht", "nach", "neu\u00b7er", "Lie\u00b7be", ",", "nach", "neu\u00b7em", "Gl\u00fcck", "und", "Wahn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das war Sir Leslie Gordon, der hatt' es ihr angetan.", "tokens": ["Das", "war", "Sir", "Les\u00b7lie", "Gor\u00b7don", ",", "der", "hatt'", "es", "ihr", "an\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "NE", "NE", "$,", "PRELS", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Er nahm in Gordon Castle die Fl\u00fccht'ge gastlich auf, \u2013", "tokens": ["Er", "nahm", "in", "Gor\u00b7don", "Cast\u00b7le", "die", "Fl\u00fccht'\u00b7ge", "gast\u00b7lich", "auf", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NE", "ART", "NN", "ADJD", "PTKVZ", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er ahnte nicht, welch' Unheil er lud zu sich herauf!", "tokens": ["Er", "ahn\u00b7te", "nicht", ",", "welch'", "Un\u00b7heil", "er", "lud", "zu", "sich", "her\u00b7auf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAT", "NN", "PPER", "VVFIN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+--+---+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Mit h\u00f6f'schen Rittersitten er dient' ihr als Vasall", "tokens": ["Mit", "h\u00f6f'\u00b7schen", "Rit\u00b7ter\u00b7sit\u00b7ten", "er", "dient'", "ihr", "als", "Va\u00b7sall"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "PPER", "KOUS", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und schaute kalten Auges die s\u00fc\u00dfe Sch\u00f6nheit all.", "tokens": ["Und", "schau\u00b7te", "kal\u00b7ten", "Au\u00b7ges", "die", "s\u00fc\u00b7\u00dfe", "Sch\u00f6n\u00b7heit", "all", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "ART", "ADJA", "NN", "PIAT", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Das konnte sie nicht tragen: \u2013 nicht lag's in ihrer Art: \u2013", "tokens": ["Das", "konn\u00b7te", "sie", "nicht", "tra\u00b7gen", ":", "\u2013", "nicht", "lag's", "in", "ih\u00b7rer", "Art", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "VVINF", "$.", "$(", "PTKNEG", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch hatt' in ihrer N\u00e4he kein Mann sein Herz gewahrt.", "tokens": ["Noch", "hatt'", "in", "ih\u00b7rer", "N\u00e4\u00b7he", "kein", "Mann", "sein", "Herz", "ge\u00b7wahrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "PIAT", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Tief sah sie in sein Auge, und als das blieb so k\u00fchl,", "tokens": ["Tief", "sah", "sie", "in", "sein", "Au\u00b7ge", ",", "und", "als", "das", "blieb", "so", "k\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "KON", "KOUS", "PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Entflammt' das eigne Herz ihr bezwingendes Gef\u00fchl.", "tokens": ["Ent\u00b7flammt'", "das", "eig\u00b7ne", "Herz", "ihr", "be\u00b7zwin\u00b7gen\u00b7des", "Ge\u00b7f\u00fchl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie rang mit ihrer Liebe, und ihre Liebe gewann,", "tokens": ["Sie", "rang", "mit", "ih\u00b7rer", "Lie\u00b7be", ",", "und", "ih\u00b7re", "Lie\u00b7be", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und eines Abends trat sie vor den geliebten Mann:", "tokens": ["Und", "ei\u00b7nes", "A\u00b7bends", "trat", "sie", "vor", "den", "ge\u00b7lieb\u00b7ten", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Gesenkten Hauptes, gleitend, wie geheime Liebe tut,", "tokens": ["Ge\u00b7senk\u00b7ten", "Haup\u00b7tes", ",", "glei\u00b7tend", ",", "wie", "ge\u00b7hei\u00b7me", "Lie\u00b7be", "tut", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "$,", "PWAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Vertausendfacht ihr Liebreiz durch leise rieselnde Glut.", "tokens": ["Ver\u00b7tau\u00b7send\u00b7facht", "ihr", "Lieb\u00b7reiz", "durch", "lei\u00b7se", "rie\u00b7seln\u00b7de", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "\u00bbsir Leslie,\u00ab haucht sie bittend, \u00bbSir Leslie, gebt mich frei,", "tokens": ["\u00bb", "sir", "Les\u00b7lie", ",", "\u00ab", "haucht", "sie", "bit\u00b7tend", ",", "\u00bb", "Sir", "Les\u00b7lie", ",", "gebt", "mich", "frei", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "NE", "$,", "$(", "VVFIN", "PPER", "VVPP", "$,", "$(", "NN", "NE", "$,", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mir tr\u00e4umte schwer, mir tr\u00e4umte, da\u00df ich Eure Gefangne sei.\u00ab", "tokens": ["Mir", "tr\u00e4um\u00b7te", "schwer", ",", "mir", "tr\u00e4um\u00b7te", ",", "da\u00df", "ich", "Eu\u00b7re", "Ge\u00b7fang\u00b7ne", "sei", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.10": {"line.1": {"text": "\u00bbdies Schlo\u00df ist Euer, K\u00f6n'gin \u2013 gefangen? Ihr sprecht im Scherz!\u00ab", "tokens": ["\u00bb", "dies", "Schlo\u00df", "ist", "Eu\u00b7er", ",", "K\u00f6n'\u00b7gin", "\u2013", "ge\u00b7fan\u00b7gen", "?", "Ihr", "sprecht", "im", "Scherz", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "NN", "VAFIN", "PPOSAT", "$,", "NN", "$(", "PTKVZ", "$.", "PPER", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbich sprech' im tiefsten Jammer und gefangen ist \u2013 mein Herz.\u00ab", "tokens": ["\u00bb", "ich", "sprech'", "im", "tiefs\u00b7ten", "Jam\u00b7mer", "und", "ge\u00b7fan\u00b7gen", "ist", "\u2013", "mein", "Herz", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "KON", "ADJD", "VAFIN", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.11": {"line.1": {"text": "Und sie dr\u00fcckt die verschlungnen H\u00e4nde vor die Stirne marmorwei\u00df:", "tokens": ["Und", "sie", "dr\u00fcckt", "die", "ver\u00b7schlung\u00b7nen", "H\u00e4n\u00b7de", "vor", "die", "Stir\u00b7ne", "mar\u00b7mor\u00b7wei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "\u00bbich liebe dich, Leslie Gordon, Mary Stuart liebt dich hei\u00df.\u00ab", "tokens": ["\u00bb", "ich", "lie\u00b7be", "dich", ",", "Les\u00b7lie", "Gor\u00b7don", ",", "Ma\u00b7ry", "Stu\u00b7art", "liebt", "dich", "hei\u00df", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "NE", "NE", "$,", "NE", "NE", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.12": {"line.1": {"text": "Da trat Sir Leslie Gordon zur\u00fcck zwei Schritte weit:", "tokens": ["Da", "trat", "Sir", "Les\u00b7lie", "Gor\u00b7don", "zu\u00b7r\u00fcck", "zwei", "Schrit\u00b7te", "weit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "NE", "PTKVZ", "CARD", "NN", "ADJD", "$."], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Und stolz sprach er und eisig: \u00bbLady Stuart, das tut mir leid.", "tokens": ["Und", "stolz", "sprach", "er", "und", "ei\u00b7sig", ":", "\u00bb", "La\u00b7dy", "Stu\u00b7art", ",", "das", "tut", "mir", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "KON", "ADJD", "$.", "$(", "NE", "NE", "$,", "PDS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.13": {"line.1": {"text": "Ihr liebt mir zu geschwinde: \u2013 ich kann nicht folgen so schnell:", "tokens": ["Ihr", "liebt", "mir", "zu", "ge\u00b7schwin\u00b7de", ":", "\u2013", "ich", "kann", "nicht", "fol\u00b7gen", "so", "schnell", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "$.", "$(", "PPER", "VMFIN", "PTKNEG", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sir Cecil und Sir Darnley und Rizzio und Bothwell: \u2013", "tokens": ["Sir", "Ce\u00b7cil", "und", "Sir", "Darn\u00b7ley", "und", "Riz\u00b7zio", "und", "Both\u00b7well", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NE", "KON", "NN", "NE", "KON", "NE", "KON", "NN", "$.", "$("], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.14": {"line.1": {"text": "Und meint Ihr, Leslie Gordon, der w\u00e4re der F\u00fcnfte? Nein!", "tokens": ["Und", "meint", "Ihr", ",", "Les\u00b7lie", "Gor\u00b7don", ",", "der", "w\u00e4\u00b7re", "der", "F\u00fcnf\u00b7te", "?", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "NE", "NE", "$,", "PRELS", "VAFIN", "ART", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Lady Stuart, es wollen die Gordons \u00fcberall die Ersten sein.\u00ab", "tokens": ["La\u00b7dy", "Stu\u00b7art", ",", "es", "wol\u00b7len", "die", "Gor\u00b7dons", "\u00fc\u00b7be\u00b7rall", "die", "Ers\u00b7ten", "sein", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VMFIN", "ART", "NN", "ADV", "ART", "NN", "VAINF", "$.", "$("], "meter": "+-+--+--+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.15": {"line.1": {"text": "Da hob das Haupt Maria, das sie tief vor ihm gebeugt,", "tokens": ["Da", "hob", "das", "Haupt", "Ma\u00b7ria", ",", "das", "sie", "tief", "vor", "ihm", "ge\u00b7beugt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "$,", "PRELS", "PPER", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein Blick voll tiefsten Liebens und Vorwurfs auf ihn fleugt:", "tokens": ["Ein", "Blick", "voll", "tiefs\u00b7ten", "Lie\u00b7bens", "und", "Vor\u00b7wurfs", "auf", "ihn", "fleugt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "KON", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbwohl hab' ich das verdienet \u2013 doch nicht aus deinem Mund!", "tokens": ["\u00bb", "wohl", "hab'", "ich", "das", "ver\u00b7die\u00b7net", "\u2013", "doch", "nicht", "aus", "dei\u00b7nem", "Mund", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PDS", "VVFIN", "$(", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Auf! sattelt meine Rosse, nach London geht's zur Stund'!\u00ab", "tokens": ["Auf", "!", "sat\u00b7telt", "mei\u00b7ne", "Ros\u00b7se", ",", "nach", "Lon\u00b7don", "geht's", "zur", "Stund'", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPOSAT", "NN", "$,", "APPR", "NE", "NE", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "Und Leslie Gordon sah ihr betroffnen Blickes nach", "tokens": ["Und", "Les\u00b7lie", "Gor\u00b7don", "sah", "ihr", "be\u00b7troff\u00b7nen", "Bli\u00b7ckes", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und Scham und Schmerz und Reue sich brandend in ihm brach.", "tokens": ["Und", "Scham", "und", "Schmerz", "und", "Reu\u00b7e", "sich", "bran\u00b7dend", "in", "ihm", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "PRF", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "\u00bbsie schmachtet im dumpfen Tower, vom Mord das Haupt bedroht,", "tokens": ["\u00bb", "sie", "schmach\u00b7tet", "im", "dum\u00b7pfen", "To\u00b7wer", ",", "vom", "Mord", "das", "Haupt", "be\u00b7droht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und ich hab' sie gesto\u00dfen von mir in den bittern Tod.", "tokens": ["Und", "ich", "hab'", "sie", "ge\u00b7sto\u00b7\u00dfen", "von", "mir", "in", "den", "bit\u00b7tern", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "APPR", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.19": {"line.1": {"text": "Das s\u00fc\u00dfeste Weib auf Erden bot Herz mir, Hand und Heil,", "tokens": ["Das", "s\u00fc\u00b7\u00dfes\u00b7te", "Weib", "auf", "Er\u00b7den", "bot", "Herz", "mir", ",", "Hand", "und", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "NN", "PPER", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und ich zum Dank entgegen stie\u00df sie dem Henkerbeil.", "tokens": ["Und", "ich", "zum", "Dank", "ent\u00b7ge\u00b7gen", "stie\u00df", "sie", "dem", "Hen\u00b7ker\u00b7beil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "PTKVZ", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "O nur noch einmal k\u00fcssen den Staub von deinen Schuh'n,", "tokens": ["O", "nur", "noch", "ein\u00b7mal", "k\u00fcs\u00b7sen", "den", "Staub", "von", "dei\u00b7nen", "Schuh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sonst kann in Himmel und H\u00f6lle meine Seele nimmer ruhn.", "tokens": ["Sonst", "kann", "in", "Him\u00b7mel", "und", "H\u00f6l\u00b7le", "mei\u00b7ne", "See\u00b7le", "nim\u00b7mer", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "KON", "NN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.21": {"line.1": {"text": "Nein, nein, du sollst nicht sterben, ich rette dich, bei Gott,", "tokens": ["Nein", ",", "nein", ",", "du", "sollst", "nicht", "ster\u00b7ben", ",", "ich", "ret\u00b7te", "dich", ",", "bei", "Gott", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "PPER", "VVFIN", "PPER", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich rette dich, Maria, oder teile dein Schafott.\u00ab \u2013", "tokens": ["Ich", "ret\u00b7te", "dich", ",", "Ma\u00b7ria", ",", "o\u00b7der", "tei\u00b7le", "dein", "Scha\u00b7fott", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NE", "$,", "KON", "NN", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.22": {"line.1": {"text": "Zu London im alten Tower hielt man zu scharfe Wacht,", "tokens": ["Zu", "Lon\u00b7don", "im", "al\u00b7ten", "To\u00b7wer", "hielt", "man", "zu", "schar\u00b7fe", "Wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "ADJA", "NN", "VVFIN", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Am Tage vor Maria ward er zum Tod gebracht.", "tokens": ["Am", "Ta\u00b7ge", "vor", "Ma\u00b7ria", "ward", "er", "zum", "Tod", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.23": {"line.1": {"text": "Fest schritt er aufs Ger\u00fcste: \u00bbHier ist der Vortritt", "tokens": ["Fest", "schritt", "er", "aufs", "Ge\u00b7r\u00fcs\u00b7te", ":", "\u00bb", "Hier", "ist", "der", "Vor\u00b7tritt"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "APPRART", "NN", "$.", "$(", "ADV", "VAFIN", "ART", "NN"], "meter": "+--+-+-++-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Sagt ihr, es m\u00fcssen die Gordons \u00fcberall die Ersten sein.\u00ab", "tokens": ["Sagt", "ihr", ",", "es", "m\u00fcs\u00b7sen", "die", "Gor\u00b7dons", "\u00fc\u00b7be\u00b7rall", "die", "Ers\u00b7ten", "sein", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VMFIN", "ART", "NN", "ADV", "ART", "NN", "VAINF", "$.", "$("], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.24": {"line.1": {"text": "An Englands Grenze harret die sch\u00f6ne S\u00fcnderin:", "tokens": ["An", "En\u00b7glands", "Gren\u00b7ze", "har\u00b7ret", "die", "sch\u00f6\u00b7ne", "S\u00fcn\u00b7de\u00b7rin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch nicht mehr steht nach London, nach anderm steht ihr Sinn.", "tokens": ["Doch", "nicht", "mehr", "steht", "nach", "Lon\u00b7don", ",", "nach", "an\u00b7derm", "steht", "ihr", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVFIN", "APPR", "NE", "$,", "APPR", "PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.25": {"line.1": {"text": "Er steht nach neuer Liebe, nach neuem Gl\u00fcck und Wahn:", "tokens": ["Er", "steht", "nach", "neu\u00b7er", "Lie\u00b7be", ",", "nach", "neu\u00b7em", "Gl\u00fcck", "und", "Wahn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das war Sir Leslie Gordon, der hatt' es ihr angetan.", "tokens": ["Das", "war", "Sir", "Les\u00b7lie", "Gor\u00b7don", ",", "der", "hatt'", "es", "ihr", "an\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "NE", "NE", "$,", "PRELS", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.26": {"line.1": {"text": "Er nahm in Gordon Castle die Fl\u00fccht'ge gastlich auf, \u2013", "tokens": ["Er", "nahm", "in", "Gor\u00b7don", "Cast\u00b7le", "die", "Fl\u00fccht'\u00b7ge", "gast\u00b7lich", "auf", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NE", "ART", "NN", "ADJD", "PTKVZ", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er ahnte nicht, welch' Unheil er lud zu sich herauf!", "tokens": ["Er", "ahn\u00b7te", "nicht", ",", "welch'", "Un\u00b7heil", "er", "lud", "zu", "sich", "her\u00b7auf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAT", "NN", "PPER", "VVFIN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+--+---+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.27": {"line.1": {"text": "Mit h\u00f6f'schen Rittersitten er dient' ihr als Vasall", "tokens": ["Mit", "h\u00f6f'\u00b7schen", "Rit\u00b7ter\u00b7sit\u00b7ten", "er", "dient'", "ihr", "als", "Va\u00b7sall"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "PPER", "KOUS", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und schaute kalten Auges die s\u00fc\u00dfe Sch\u00f6nheit all.", "tokens": ["Und", "schau\u00b7te", "kal\u00b7ten", "Au\u00b7ges", "die", "s\u00fc\u00b7\u00dfe", "Sch\u00f6n\u00b7heit", "all", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "ART", "ADJA", "NN", "PIAT", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.28": {"line.1": {"text": "Das konnte sie nicht tragen: \u2013 nicht lag's in ihrer Art: \u2013", "tokens": ["Das", "konn\u00b7te", "sie", "nicht", "tra\u00b7gen", ":", "\u2013", "nicht", "lag's", "in", "ih\u00b7rer", "Art", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "VVINF", "$.", "$(", "PTKNEG", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch hatt' in ihrer N\u00e4he kein Mann sein Herz gewahrt.", "tokens": ["Noch", "hatt'", "in", "ih\u00b7rer", "N\u00e4\u00b7he", "kein", "Mann", "sein", "Herz", "ge\u00b7wahrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "PIAT", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.29": {"line.1": {"text": "Tief sah sie in sein Auge, und als das blieb so k\u00fchl,", "tokens": ["Tief", "sah", "sie", "in", "sein", "Au\u00b7ge", ",", "und", "als", "das", "blieb", "so", "k\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "KON", "KOUS", "PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Entflammt' das eigne Herz ihr bezwingendes Gef\u00fchl.", "tokens": ["Ent\u00b7flammt'", "das", "eig\u00b7ne", "Herz", "ihr", "be\u00b7zwin\u00b7gen\u00b7des", "Ge\u00b7f\u00fchl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.30": {"line.1": {"text": "Sie rang mit ihrer Liebe, und ihre Liebe gewann,", "tokens": ["Sie", "rang", "mit", "ih\u00b7rer", "Lie\u00b7be", ",", "und", "ih\u00b7re", "Lie\u00b7be", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und eines Abends trat sie vor den geliebten Mann:", "tokens": ["Und", "ei\u00b7nes", "A\u00b7bends", "trat", "sie", "vor", "den", "ge\u00b7lieb\u00b7ten", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.31": {"line.1": {"text": "Gesenkten Hauptes, gleitend, wie geheime Liebe tut,", "tokens": ["Ge\u00b7senk\u00b7ten", "Haup\u00b7tes", ",", "glei\u00b7tend", ",", "wie", "ge\u00b7hei\u00b7me", "Lie\u00b7be", "tut", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "$,", "PWAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Vertausendfacht ihr Liebreiz durch leise rieselnde Glut.", "tokens": ["Ver\u00b7tau\u00b7send\u00b7facht", "ihr", "Lieb\u00b7reiz", "durch", "lei\u00b7se", "rie\u00b7seln\u00b7de", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.32": {"line.1": {"text": "\u00bbsir Leslie,\u00ab haucht sie bittend, \u00bbSir Leslie, gebt mich frei,", "tokens": ["\u00bb", "sir", "Les\u00b7lie", ",", "\u00ab", "haucht", "sie", "bit\u00b7tend", ",", "\u00bb", "Sir", "Les\u00b7lie", ",", "gebt", "mich", "frei", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "NE", "$,", "$(", "VVFIN", "PPER", "VVPP", "$,", "$(", "NN", "NE", "$,", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mir tr\u00e4umte schwer, mir tr\u00e4umte, da\u00df ich Eure Gefangne sei.\u00ab", "tokens": ["Mir", "tr\u00e4um\u00b7te", "schwer", ",", "mir", "tr\u00e4um\u00b7te", ",", "da\u00df", "ich", "Eu\u00b7re", "Ge\u00b7fang\u00b7ne", "sei", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.33": {"line.1": {"text": "\u00bbdies Schlo\u00df ist Euer, K\u00f6n'gin \u2013 gefangen? Ihr sprecht im Scherz!\u00ab", "tokens": ["\u00bb", "dies", "Schlo\u00df", "ist", "Eu\u00b7er", ",", "K\u00f6n'\u00b7gin", "\u2013", "ge\u00b7fan\u00b7gen", "?", "Ihr", "sprecht", "im", "Scherz", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "NN", "VAFIN", "PPOSAT", "$,", "NN", "$(", "PTKVZ", "$.", "PPER", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbich sprech' im tiefsten Jammer und gefangen ist \u2013 mein Herz.\u00ab", "tokens": ["\u00bb", "ich", "sprech'", "im", "tiefs\u00b7ten", "Jam\u00b7mer", "und", "ge\u00b7fan\u00b7gen", "ist", "\u2013", "mein", "Herz", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "KON", "ADJD", "VAFIN", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.34": {"line.1": {"text": "Und sie dr\u00fcckt die verschlungnen H\u00e4nde vor die Stirne marmorwei\u00df:", "tokens": ["Und", "sie", "dr\u00fcckt", "die", "ver\u00b7schlung\u00b7nen", "H\u00e4n\u00b7de", "vor", "die", "Stir\u00b7ne", "mar\u00b7mor\u00b7wei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "\u00bbich liebe dich, Leslie Gordon, Mary Stuart liebt dich hei\u00df.\u00ab", "tokens": ["\u00bb", "ich", "lie\u00b7be", "dich", ",", "Les\u00b7lie", "Gor\u00b7don", ",", "Ma\u00b7ry", "Stu\u00b7art", "liebt", "dich", "hei\u00df", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "NE", "NE", "$,", "NE", "NE", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.35": {"line.1": {"text": "Da trat Sir Leslie Gordon zur\u00fcck zwei Schritte weit:", "tokens": ["Da", "trat", "Sir", "Les\u00b7lie", "Gor\u00b7don", "zu\u00b7r\u00fcck", "zwei", "Schrit\u00b7te", "weit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "NE", "PTKVZ", "CARD", "NN", "ADJD", "$."], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Und stolz sprach er und eisig: \u00bbLady Stuart, das tut mir leid.", "tokens": ["Und", "stolz", "sprach", "er", "und", "ei\u00b7sig", ":", "\u00bb", "La\u00b7dy", "Stu\u00b7art", ",", "das", "tut", "mir", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "KON", "ADJD", "$.", "$(", "NE", "NE", "$,", "PDS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.36": {"line.1": {"text": "Ihr liebt mir zu geschwinde: \u2013 ich kann nicht folgen so schnell:", "tokens": ["Ihr", "liebt", "mir", "zu", "ge\u00b7schwin\u00b7de", ":", "\u2013", "ich", "kann", "nicht", "fol\u00b7gen", "so", "schnell", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "$.", "$(", "PPER", "VMFIN", "PTKNEG", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sir Cecil und Sir Darnley und Rizzio und Bothwell: \u2013", "tokens": ["Sir", "Ce\u00b7cil", "und", "Sir", "Darn\u00b7ley", "und", "Riz\u00b7zio", "und", "Both\u00b7well", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NE", "KON", "NN", "NE", "KON", "NE", "KON", "NN", "$.", "$("], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.37": {"line.1": {"text": "Und meint Ihr, Leslie Gordon, der w\u00e4re der F\u00fcnfte? Nein!", "tokens": ["Und", "meint", "Ihr", ",", "Les\u00b7lie", "Gor\u00b7don", ",", "der", "w\u00e4\u00b7re", "der", "F\u00fcnf\u00b7te", "?", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "NE", "NE", "$,", "PRELS", "VAFIN", "ART", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Lady Stuart, es wollen die Gordons \u00fcberall die Ersten sein.\u00ab", "tokens": ["La\u00b7dy", "Stu\u00b7art", ",", "es", "wol\u00b7len", "die", "Gor\u00b7dons", "\u00fc\u00b7be\u00b7rall", "die", "Ers\u00b7ten", "sein", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VMFIN", "ART", "NN", "ADV", "ART", "NN", "VAINF", "$.", "$("], "meter": "+-+--+--+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.38": {"line.1": {"text": "Da hob das Haupt Maria, das sie tief vor ihm gebeugt,", "tokens": ["Da", "hob", "das", "Haupt", "Ma\u00b7ria", ",", "das", "sie", "tief", "vor", "ihm", "ge\u00b7beugt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "$,", "PRELS", "PPER", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein Blick voll tiefsten Liebens und Vorwurfs auf ihn fleugt:", "tokens": ["Ein", "Blick", "voll", "tiefs\u00b7ten", "Lie\u00b7bens", "und", "Vor\u00b7wurfs", "auf", "ihn", "fleugt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "KON", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.39": {"line.1": {"text": "\u00bbwohl hab' ich das verdienet \u2013 doch nicht aus deinem Mund!", "tokens": ["\u00bb", "wohl", "hab'", "ich", "das", "ver\u00b7die\u00b7net", "\u2013", "doch", "nicht", "aus", "dei\u00b7nem", "Mund", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PDS", "VVFIN", "$(", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Auf! sattelt meine Rosse, nach London geht's zur Stund'!\u00ab", "tokens": ["Auf", "!", "sat\u00b7telt", "mei\u00b7ne", "Ros\u00b7se", ",", "nach", "Lon\u00b7don", "geht's", "zur", "Stund'", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPOSAT", "NN", "$,", "APPR", "NE", "NE", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.40": {"line.1": {"text": "Und Leslie Gordon sah ihr betroffnen Blickes nach", "tokens": ["Und", "Les\u00b7lie", "Gor\u00b7don", "sah", "ihr", "be\u00b7troff\u00b7nen", "Bli\u00b7ckes", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und Scham und Schmerz und Reue sich brandend in ihm brach.", "tokens": ["Und", "Scham", "und", "Schmerz", "und", "Reu\u00b7e", "sich", "bran\u00b7dend", "in", "ihm", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "PRF", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.41": {"line.1": {"text": "\u00bbsie schmachtet im dumpfen Tower, vom Mord das Haupt bedroht,", "tokens": ["\u00bb", "sie", "schmach\u00b7tet", "im", "dum\u00b7pfen", "To\u00b7wer", ",", "vom", "Mord", "das", "Haupt", "be\u00b7droht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und ich hab' sie gesto\u00dfen von mir in den bittern Tod.", "tokens": ["Und", "ich", "hab'", "sie", "ge\u00b7sto\u00b7\u00dfen", "von", "mir", "in", "den", "bit\u00b7tern", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "APPR", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.42": {"line.1": {"text": "Das s\u00fc\u00dfeste Weib auf Erden bot Herz mir, Hand und Heil,", "tokens": ["Das", "s\u00fc\u00b7\u00dfes\u00b7te", "Weib", "auf", "Er\u00b7den", "bot", "Herz", "mir", ",", "Hand", "und", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "NN", "PPER", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und ich zum Dank entgegen stie\u00df sie dem Henkerbeil.", "tokens": ["Und", "ich", "zum", "Dank", "ent\u00b7ge\u00b7gen", "stie\u00df", "sie", "dem", "Hen\u00b7ker\u00b7beil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "PTKVZ", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.43": {"line.1": {"text": "O nur noch einmal k\u00fcssen den Staub von deinen Schuh'n,", "tokens": ["O", "nur", "noch", "ein\u00b7mal", "k\u00fcs\u00b7sen", "den", "Staub", "von", "dei\u00b7nen", "Schuh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sonst kann in Himmel und H\u00f6lle meine Seele nimmer ruhn.", "tokens": ["Sonst", "kann", "in", "Him\u00b7mel", "und", "H\u00f6l\u00b7le", "mei\u00b7ne", "See\u00b7le", "nim\u00b7mer", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "KON", "NN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.44": {"line.1": {"text": "Nein, nein, du sollst nicht sterben, ich rette dich, bei Gott,", "tokens": ["Nein", ",", "nein", ",", "du", "sollst", "nicht", "ster\u00b7ben", ",", "ich", "ret\u00b7te", "dich", ",", "bei", "Gott", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "PPER", "VVFIN", "PPER", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich rette dich, Maria, oder teile dein Schafott.\u00ab \u2013", "tokens": ["Ich", "ret\u00b7te", "dich", ",", "Ma\u00b7ria", ",", "o\u00b7der", "tei\u00b7le", "dein", "Scha\u00b7fott", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NE", "$,", "KON", "NN", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.45": {"line.1": {"text": "Zu London im alten Tower hielt man zu scharfe Wacht,", "tokens": ["Zu", "Lon\u00b7don", "im", "al\u00b7ten", "To\u00b7wer", "hielt", "man", "zu", "schar\u00b7fe", "Wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "ADJA", "NN", "VVFIN", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Am Tage vor Maria ward er zum Tod gebracht.", "tokens": ["Am", "Ta\u00b7ge", "vor", "Ma\u00b7ria", "ward", "er", "zum", "Tod", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.46": {"line.1": {"text": "Fest schritt er aufs Ger\u00fcste: \u00bbHier ist der Vortritt", "tokens": ["Fest", "schritt", "er", "aufs", "Ge\u00b7r\u00fcs\u00b7te", ":", "\u00bb", "Hier", "ist", "der", "Vor\u00b7tritt"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "APPRART", "NN", "$.", "$(", "ADV", "VAFIN", "ART", "NN"], "meter": "+--+-+-++-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Sagt ihr, es m\u00fcssen die Gordons \u00fcberall die Ersten sein.\u00ab", "tokens": ["Sagt", "ihr", ",", "es", "m\u00fcs\u00b7sen", "die", "Gor\u00b7dons", "\u00fc\u00b7be\u00b7rall", "die", "Ers\u00b7ten", "sein", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VMFIN", "ART", "NN", "ADV", "ART", "NN", "VAINF", "$.", "$("], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}}}}}