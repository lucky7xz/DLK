{"dta.poem.10682": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Hochzeit Gedichte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Nach dem die Welt gegr\u00fcndt vnd jhr Termin gesteckt/", "tokens": ["Nach", "dem", "die", "Welt", "ge\u00b7gr\u00fcndt", "vnd", "jhr", "Ter\u00b7min", "ge\u00b7steckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VVPP", "KON", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach dem die sch\u00f6ne Lufft rundt vmb sich au\u00dfgestreckt/", "tokens": ["Nach", "dem", "die", "sch\u00f6\u00b7ne", "Lufft", "rundt", "vmb", "sich", "au\u00df\u00b7ge\u00b7streckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "VVFIN", "APPR", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd auch die wilde See/ die nah\u2019 vnd weit zukommen", "tokens": ["Vnd", "auch", "die", "wil\u00b7de", "See", "/", "die", "nah'", "vnd", "weit", "zu\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$(", "ART", "NN", "KON", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Pflegt nach de\u00df Monats lauff/ jhr \u00f6rter eingenommen/", "tokens": ["Pflegt", "nach", "de\u00df", "Mo\u00b7nats", "lauff", "/", "jhr", "\u00f6r\u00b7ter", "ein\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "ART", "NN", "PTKVZ", "$(", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sah Jupiter hinab/ vnd sp\u00fcrete niemandt/", "tokens": ["Sah", "Ju\u00b7pi\u00b7ter", "hin\u00b7ab", "/", "vnd", "sp\u00fc\u00b7re\u00b7te", "nie\u00b7mandt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "$(", "KON", "VVFIN", "PIS", "$("], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der di\u00df gewaltig Hau\u00df brecht vnder seine Hand.", "tokens": ["Der", "di\u00df", "ge\u00b7wal\u00b7tig", "Hau\u00df", "brecht", "vn\u00b7der", "sei\u00b7ne", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "ADJD", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drumb von seins Vatters de\u00df Saturnus Leib er hiebe", "tokens": ["Drumb", "von", "seins", "Vat\u00b7ters", "de\u00df", "Sa\u00b7tur\u00b7nus", "Leib", "er", "hie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Das theil so sch\u00e4ndtlich ist/ doch n\u00f6tig in der Liebe.", "tokens": ["Das", "theil", "so", "sch\u00e4ndt\u00b7lich", "ist", "/", "doch", "n\u00f6\u00b7tig", "in", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VAFIN", "$(", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vnd warff es in das Meer/ darau\u00df ein Schaum herkam/", "tokens": ["Vnd", "warff", "es", "in", "das", "Meer", "/", "dar\u00b7au\u00df", "ein", "Schaum", "her\u00b7kam", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "PAV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Davon das geyle Weib die Venus Vrsprung nam/", "tokens": ["Da\u00b7von", "das", "gey\u00b7le", "Weib", "die", "Ve\u00b7nus", "Vr\u00b7sprung", "nam", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Das geyle Weib/ das Weib das aller G\u00f6tter Sinnen/", "tokens": ["Das", "gey\u00b7le", "Weib", "/", "das", "Weib", "das", "al\u00b7ler", "G\u00f6t\u00b7ter", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "ART", "PIAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit jhrem blinden Kind hat listig rauben k\u00f6nnen/", "tokens": ["Mit", "jhrem", "blin\u00b7den", "Kind", "hat", "lis\u00b7tig", "rau\u00b7ben", "k\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "VVINF", "VMINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Sie haben gantz vnd gar gebracht in kurtzer Zeit", "tokens": ["Sie", "ha\u00b7ben", "gantz", "vnd", "gar", "ge\u00b7bracht", "in", "kurt\u00b7zer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "KON", "ADV", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das Menschliche Geschlecht in jhre Dienstbarkeit/", "tokens": ["Das", "Menschli\u00b7che", "Ge\u00b7schlecht", "in", "jhre", "Dienst\u00b7bar\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Sie theten vber di\u00df ein \u00e4rger wesen f\u00fchren/", "tokens": ["Sie", "the\u00b7ten", "vber", "di\u00df", "ein", "\u00e4r\u00b7ger", "we\u00b7sen", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDS", "ART", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Beweisen jhre Macht auch an den stummen Thieren/", "tokens": ["Be\u00b7wei\u00b7sen", "jhre", "Macht", "auch", "an", "den", "stum\u00b7men", "Thie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "So das nun vberal durchau\u00df nichts leben kan/", "tokens": ["So", "das", "nun", "vbe\u00b7ral", "durch\u00b7au\u00df", "nichts", "le\u00b7ben", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADV", "ADV", "ADV", "PIS", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.18": {"text": "Es mu\u00df jhr vnd dem Kindt allzeit sein vnderthan/", "tokens": ["Es", "mu\u00df", "jhr", "vnd", "dem", "Kindt", "all\u00b7zeit", "sein", "vn\u00b7der\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "KON", "ART", "NN", "ADV", "PPOSAT", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Das Kindt/ das lose Kindt/ das mit dem Pfeil vnd Bogen/", "tokens": ["Das", "Kindt", "/", "das", "lo\u00b7se", "Kindt", "/", "das", "mit", "dem", "Pfeil", "vnd", "Bo\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJA", "NN", "$(", "PDS", "APPR", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So sehr viel hundert Jahr ist durch die Lufft geflogen/", "tokens": ["So", "sehr", "viel", "hun\u00b7dert", "Jahr", "ist", "durch", "die", "Lufft", "ge\u00b7flo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "CARD", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Vnd hat sein grosses Reich gewaltig starck vermehrt/", "tokens": ["Vnd", "hat", "sein", "gros\u00b7ses", "Reich", "ge\u00b7wal\u00b7tig", "starck", "ver\u00b7mehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN", "ADJD", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ja auch die Mutter selbst ohn alle schew versehrt/", "tokens": ["Ja", "auch", "die", "Mut\u00b7ter", "selbst", "ohn", "al\u00b7le", "schew", "ver\u00b7sehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "ADV", "APPR", "PIS", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Das Joch mu\u00dft jhr doch auch noch angeworffen werden/", "tokens": ["Das", "Joch", "mu\u00dft", "jhr", "doch", "auch", "noch", "an\u00b7ge\u00b7worf\u00b7fen", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ADV", "ADV", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Von jhrem eignen Sohn/ der Herr ist dieser Erden/", "tokens": ["Von", "jhrem", "eig\u00b7nen", "Sohn", "/", "der", "Herr", "ist", "die\u00b7ser", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "ART", "NN", "VAFIN", "PDAT", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.25": {"text": "Vnd Printz der weiten Welt/ der helt die Lufft vor sein/", "tokens": ["Vnd", "Printz", "der", "wei\u00b7ten", "Welt", "/", "der", "helt", "die", "Lufft", "vor", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "ADJA", "NN", "$(", "ART", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die zierlich ist gewirckt mit lichten sternelein/", "tokens": ["Die", "zier\u00b7lich", "ist", "ge\u00b7wirckt", "mit", "lich\u00b7ten", "ster\u00b7ne\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die mit der strahlen glantz gehn auff der weissen strassen/", "tokens": ["Die", "mit", "der", "strah\u00b7len", "glantz", "gehn", "auff", "der", "weis\u00b7sen", "stras\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Vnd in der holen Kaut Lufft/ Erdt vnd See vmbfassen.", "tokens": ["Vnd", "in", "der", "ho\u00b7len", "Kaut", "Lufft", "/", "Erdt", "vnd", "See", "vmb\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN", "$(", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Nun la\u00dft vns doch besehn wohin der sch\u00f6ne Sohn/", "tokens": ["Nun", "la\u00dft", "vns", "doch", "be\u00b7sehn", "wo\u00b7hin", "der", "sch\u00f6\u00b7ne", "Sohn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "VVINF", "PWAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Der grosse kleine Gott gebauet seinen Thron/", "tokens": ["Der", "gros\u00b7se", "klei\u00b7ne", "Gott", "ge\u00b7bau\u00b7et", "sei\u00b7nen", "Thron", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Er hat jhm au\u00dferwehlt der Augen Thron zu eigen/", "tokens": ["Er", "hat", "jhm", "au\u00b7\u00dfer\u00b7wehlt", "der", "Au\u00b7gen", "Thron", "zu", "ei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "ART", "NN", "NN", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die vns sein K\u00f6nigreich/ als klare Spiegel/ zeigen.", "tokens": ["Die", "vns", "sein", "K\u00f6\u00b7nig\u00b7reich", "/", "als", "kla\u00b7re", "Spie\u00b7gel", "/", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "$(", "KOUS", "ADJA", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Der Augenapffel ist die Kugel dieser Welt/", "tokens": ["Der", "Au\u00b7gen\u00b7apf\u00b7fel", "ist", "die", "Ku\u00b7gel", "die\u00b7ser", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Das Wasser aber/ das der Apffel in sich helt/", "tokens": ["Das", "Was\u00b7ser", "a\u00b7ber", "/", "das", "der", "Apf\u00b7fel", "in", "sich", "helt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "PRELS", "ART", "NN", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Das sind die milden Quell so au\u00df den Bergen schiessen/", "tokens": ["Das", "sind", "die", "mil\u00b7den", "Quell", "so", "au\u00df", "den", "Ber\u00b7gen", "schies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Vnd durch das gr\u00fcne Thal mit sanfftem rauschen fliessen.", "tokens": ["Vnd", "durch", "das", "gr\u00fc\u00b7ne", "Thal", "mit", "sanff\u00b7tem", "rau\u00b7schen", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Der Circkel runde Krantz/ der vmb den Apffel geht/", "tokens": ["Der", "Cir\u00b7ckel", "run\u00b7de", "Krantz", "/", "der", "vmb", "den", "Apf\u00b7fel", "geht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Das ist die wilde See die nach der Erden steht/", "tokens": ["Das", "ist", "die", "wil\u00b7de", "See", "die", "nach", "der", "Er\u00b7den", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Der Augen weisser Platz so sich vmbher ergeusset/", "tokens": ["Der", "Au\u00b7gen", "weis\u00b7ser", "Platz", "so", "sich", "vm\u00b7bher", "er\u00b7geus\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADV", "PRF", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Das ist die klare Lufft/ die Erdt vnd See beschleusset.", "tokens": ["Das", "ist", "die", "kla\u00b7re", "Lufft", "/", "die", "Erdt", "vnd", "See", "be\u00b7schleus\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Es ist ein wunder ding da\u00df das vierdt Element", "tokens": ["Es", "ist", "ein", "wun\u00b7der", "ding", "da\u00df", "das", "vierdt", "E\u00b7le\u00b7ment"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "KOUS", "ART", "CARD", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.42": {"text": "Auch in den Augen nicht von andern ist getrennt/", "tokens": ["Auch", "in", "den", "Au\u00b7gen", "nicht", "von", "an\u00b7dern", "ist", "ge\u00b7trennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKNEG", "APPR", "PIS", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Das Fewer/ so durchs Meer gantz hell vnd lieblich blicket/", "tokens": ["Das", "Fe\u00b7wer", "/", "so", "durchs", "Meer", "gantz", "hell", "vnd", "lieb\u00b7lich", "bli\u00b7cket", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "APPRART", "NN", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Vnd mit dem sch\u00f6nen schein vns Muth vnd sinn entz\u00fccket.", "tokens": ["Vnd", "mit", "dem", "sch\u00f6\u00b7nen", "schein", "vns", "Muth", "vnd", "sinn", "ent\u00b7z\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Das Fewer/ so den Weg jhm durch die Augen nimbt/", "tokens": ["Das", "Fe\u00b7wer", "/", "so", "den", "Weg", "jhm", "durch", "die", "Au\u00b7gen", "nimbt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ART", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Vnd vnvermerckter sach in vnser Hertzen k\u00fcmpt/", "tokens": ["Vnd", "vn\u00b7ver\u00b7merck\u00b7ter", "sach", "in", "vn\u00b7ser", "Hert\u00b7zen", "k\u00fcmpt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Da ruht es ohne Ruh/ da hebt es an zu brennen/", "tokens": ["Da", "ruht", "es", "oh\u00b7ne", "Ruh", "/", "da", "hebt", "es", "an", "zu", "bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$(", "ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Da\u00df wir der Liebe krafft vnd vns in vns nit kennen.", "tokens": ["Da\u00df", "wir", "der", "Lie\u00b7be", "krafft", "vnd", "vns", "in", "vns", "nit", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "KON", "PPER", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Was Wunder ist es dann/ da\u00df er mit seinem Band/", "tokens": ["Was", "Wun\u00b7der", "ist", "es", "dann", "/", "da\u00df", "er", "mit", "sei\u00b7nem", "Band", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Die Welt bezwungen hat durch seine schwache Hand/", "tokens": ["Die", "Welt", "be\u00b7zwun\u00b7gen", "hat", "durch", "sei\u00b7ne", "schwa\u00b7che", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Der tausent Welten hat/ die Augen/ da er zeugen", "tokens": ["Der", "tau\u00b7sent", "Wel\u00b7ten", "hat", "/", "die", "Au\u00b7gen", "/", "da", "er", "zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "VAFIN", "$(", "ART", "NN", "$(", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Vnd kl\u00e4rlich darthun kan/ wie er vns k\u00f6nne beugen?", "tokens": ["Vnd", "kl\u00e4r\u00b7lich", "dar\u00b7thun", "kan", "/", "wie", "er", "vns", "k\u00f6n\u00b7ne", "beu\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "VMFIN", "$(", "PWAV", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Di\u00df ists/ das euch bezwang/ di\u00df ists/ Herr Br\u00e4utigam/", "tokens": ["Di\u00df", "ists", "/", "das", "euch", "be\u00b7zwang", "/", "di\u00df", "ists", "/", "Herr", "Br\u00e4u\u00b7ti\u00b7gam", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "PRELS", "PPER", "VVFIN", "$(", "PDS", "VAFIN", "$(", "NN", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Di\u00df ist die newe Welt so ewer Hertz einnam/", "tokens": ["Di\u00df", "ist", "die", "ne\u00b7we", "Welt", "so", "e\u00b7wer", "Hertz", "ein\u00b7nam", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "War euch auch wol zu muth/ gabt jhr euch auch verlohren/", "tokens": ["War", "euch", "auch", "wol", "zu", "muth", "/", "gabt", "jhr", "euch", "auch", "ver\u00b7loh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$(", "VVFIN", "PPER", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Als die vier Element zugleiche sich verschworen/", "tokens": ["Als", "die", "vier", "E\u00b7le\u00b7ment", "zu\u00b7glei\u00b7che", "sich", "ver\u00b7schwo\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "CARD", "NN", "VVFIN", "PRF", "VVINF", "$("], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.57": {"text": "Zu liefern eine Schlacht/ die in der Augen Welt", "tokens": ["Zu", "lie\u00b7fern", "ei\u00b7ne", "Schlacht", "/", "die", "in", "der", "Au\u00b7gen", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ART", "NN", "$(", "ART", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Sich alle l\u00e4gerten/ vnd gaben sich zu feldt?", "tokens": ["Sich", "al\u00b7le", "l\u00e4\u00b7ger\u00b7ten", "/", "vnd", "ga\u00b7ben", "sich", "zu", "feldt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIS", "VVFIN", "$(", "KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Ihr habt euch warlich wol die Rechnung machen k\u00f6nnen/", "tokens": ["Ihr", "habt", "euch", "war\u00b7lich", "wol", "die", "Rech\u00b7nung", "ma\u00b7chen", "k\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "VMINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Da\u00df vier so starcke Feind euch w\u00fcrden angewinnen/", "tokens": ["Da\u00df", "vier", "so", "star\u00b7cke", "Feind", "euch", "w\u00fcr\u00b7den", "an\u00b7ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "ADV", "ADJA", "NN", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Ihr thut auch was jhr wolt/ jhr brauchet alle Kunst/", "tokens": ["Ihr", "thut", "auch", "was", "jhr", "wolt", "/", "jhr", "brau\u00b7chet", "al\u00b7le", "Kunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PWS", "PPER", "VMFIN", "$(", "PPER", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Ich halte nur darf\u00fcr die Arbeit sey vmbsunst/", "tokens": ["Ich", "hal\u00b7te", "nur", "dar\u00b7f\u00fcr", "die", "Ar\u00b7beit", "sey", "vmbsunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "ART", "NN", "VAFIN", "ADV", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.63": {"text": "Bey dreyen were Rath/ dem vierden zuentfliehen/", "tokens": ["Bey", "drey\u00b7en", "we\u00b7re", "Rath", "/", "dem", "vier\u00b7den", "zu\u00b7ent\u00b7flie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "VAFIN", "NN", "$(", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Dem Fewer/ wei\u00df ich nicht ob man sich darff bem\u00fchen.", "tokens": ["Dem", "Fe\u00b7wer", "/", "wei\u00df", "ich", "nicht", "ob", "man", "sich", "darff", "be\u00b7m\u00fc\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "PPER", "PTKNEG", "KOUS", "PIS", "PRF", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Was laufft jhr viel vnd sucht? die H\u00fclff ist bey der Hand", "tokens": ["Was", "laufft", "jhr", "viel", "vnd", "sucht", "?", "die", "H\u00fclff", "ist", "bey", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "$.", "ART", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wer hie genesen will/ der mu\u00df doch zudem Brandt/", "tokens": ["Wer", "hie", "ge\u00b7ne\u00b7sen", "will", "/", "der", "mu\u00df", "doch", "zu\u00b7dem", "Brandt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVINF", "VMFIN", "$(", "ART", "VMFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "So erstlich jhn entz\u00fcndt: di\u00df sein Achilles Wunden/", "tokens": ["So", "erst\u00b7lich", "jhn", "ent\u00b7z\u00fcndt", ":", "di\u00df", "sein", "A\u00b7chil\u00b7les", "Wun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVPP", "$.", "PDS", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die niemand heilt/ als der/ von dem man sie empfunden.", "tokens": ["Die", "nie\u00b7mand", "heilt", "/", "als", "der", "/", "von", "dem", "man", "sie", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$(", "KOUS", "ART", "$(", "APPR", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Was gibet man den an? das bitten ist das best/", "tokens": ["Was", "gi\u00b7bet", "man", "den", "an", "?", "das", "bit\u00b7ten", "ist", "das", "best", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ART", "PTKVZ", "$.", "PDS", "VVINF", "VAFIN", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.70": {"text": "Es ist ein Hertz von Stein/ so sich nicht biegen lest/", "tokens": ["Es", "ist", "ein", "Hertz", "von", "Stein", "/", "so", "sich", "nicht", "bie\u00b7gen", "lest", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "$(", "ADV", "PRF", "PTKNEG", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Nit lengst hab ich geh\u00f6rt von einer Feldg\u00f6ttinnen/", "tokens": ["Nit", "lengst", "hab", "ich", "ge\u00b7h\u00f6rt", "von", "ei\u00b7ner", "Feld\u00b7g\u00f6t\u00b7tin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Wie jhr/ Herr Breutigam/ habt pflegen zu beginnen/", "tokens": ["Wie", "jhr", "/", "Herr", "Breu\u00b7ti\u00b7gam", "/", "habt", "pfle\u00b7gen", "zu", "be\u00b7gin\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$(", "NN", "NE", "$(", "VAFIN", "VVINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Ein sehnlich Klagelied/ das Wald/ Feld/ Berg vnd Thal", "tokens": ["Ein", "sehn\u00b7lich", "Kla\u00b7ge\u00b7lied", "/", "das", "Wald", "/", "Feld", "/", "Berg", "vnd", "Thal"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "$(", "ART", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Es haben widerholt mit kl\u00e4glichem Nachschall/", "tokens": ["Es", "ha\u00b7ben", "wi\u00b7der\u00b7holt", "mit", "kl\u00e4g\u00b7li\u00b7chem", "Nach\u00b7schall", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.75": {"text": "Die Nyinfen haben es mit Wehmut auch vernom men/", "tokens": ["Die", "Ny\u00b7in\u00b7fen", "ha\u00b7ben", "es", "mit", "Weh\u00b7mut", "auch", "ver\u00b7nom", "men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPR", "NN", "ADV", "APPRART", "NN", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.76": {"text": "Vnd mein ", "tokens": ["Vnd", "mein"], "token_info": ["word", "word"], "pos": ["KON", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}, "line.77": {"text": "All mein Leiden/ Lieb vnd Schmertze", "tokens": ["All", "mein", "Lei\u00b7den", "/", "Lieb", "vnd", "Schmert\u00b7ze"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.78": {"text": "Hatmein Hertze", "tokens": ["Hat\u00b7mein", "Hert\u00b7ze"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.79": {"text": "Gantz vmbringt mit Trawrigkeit/", "tokens": ["Gantz", "vm\u00b7bringt", "mit", "Traw\u00b7rig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.80": {"text": "Als ein forchtsam Hirsch mu\u00df eilen", "tokens": ["Als", "ein", "forcht\u00b7sam", "Hirsch", "mu\u00df", "ei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.81": {"text": "F\u00fcr den Pfeilen/", "tokens": ["F\u00fcr", "den", "Pfei\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.82": {"text": "Flieg vnd renn ich jederzeit.", "tokens": ["Flieg", "vnd", "renn", "ich", "je\u00b7der\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.83": {"text": "Ich vollf\u00fchre meine Klage", "tokens": ["Ich", "voll\u00b7f\u00fch\u00b7re", "mei\u00b7ne", "Kla\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.84": {"text": "Nacht vnd Tage/", "tokens": ["Nacht", "vnd", "Ta\u00b7ge", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.85": {"text": "Denckend an der Liebe quell/", "tokens": ["Den\u00b7ckend", "an", "der", "Lie\u00b7be", "quell", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.86": {"text": "Stets die Threnen mich begiessen/", "tokens": ["Stets", "die", "Thre\u00b7nen", "mich", "be\u00b7gies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.87": {"text": "Die da fliessen/", "tokens": ["Die", "da", "flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.88": {"text": "Als zwey B\u00e4che von Cristall.", "tokens": ["Als", "zwey", "B\u00e4\u00b7che", "von", "Cris\u00b7tall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.89": {"text": "Wolt jhr demnach/ Jungfraw/ geben", "tokens": ["Wolt", "jhr", "dem\u00b7nach", "/", "Jung\u00b7fraw", "/", "ge\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VMFIN", "PPER", "PAV", "$(", "NN", "$(", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.90": {"text": "Meinem Leben", "tokens": ["Mei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.91": {"text": "H\u00fclff vnd Trost in diesem Leidt/", "tokens": ["H\u00fclff", "vnd", "Trost", "in", "die\u00b7sem", "Leidt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "PDAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.92": {"text": "So erbarmt euch doch bey zeiten/", "tokens": ["So", "er\u00b7barmt", "euch", "doch", "bey", "zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.93": {"text": "Thut bereiten", "tokens": ["Thut", "be\u00b7rei\u00b7ten"], "token_info": ["word", "word"], "pos": ["NE", "VVINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.94": {"text": "Nach dem Trawren Lust vnd Frewd.", "tokens": ["Nach", "dem", "Traw\u00b7ren", "Lust", "vnd", "Frewd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.95": {"text": "Ehe da\u00df sich bey mir beginnen", "tokens": ["E\u00b7he", "da\u00df", "sich", "bey", "mir", "be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "PRF", "APPR", "PPER", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.96": {"text": "Alle Sinnen", "tokens": ["Al\u00b7le", "Sin\u00b7nen"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.97": {"text": "Zu verliern/ vnd aller Muth/", "tokens": ["Zu", "ver\u00b7li\u00b7ern", "/", "vnd", "al\u00b7ler", "Muth", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "KON", "PIAT", "NN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.98": {"text": "Rettet mich von dem Elende/", "tokens": ["Ret\u00b7tet", "mich", "von", "dem", "E\u00b7len\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "$("], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.99": {"text": "Ehe das Ende", "tokens": ["E\u00b7he", "das", "En\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.100": {"text": "Selbst bey mir das beste thut/", "tokens": ["Selbst", "bey", "mir", "das", "bes\u00b7te", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "ART", "ADJA", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.101": {"text": "Ach Printzessin/ ach Jungfrawe/", "tokens": ["Ach", "Print\u00b7zes\u00b7sin", "/", "ach", "Jung\u00b7fra\u00b7we", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$(", "XY", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "Euch ich trawe/", "tokens": ["Euch", "ich", "tra\u00b7we", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVFIN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.103": {"text": "Ihr seid meine Medicin", "tokens": ["Ihr", "seid", "mei\u00b7ne", "Me\u00b7di\u00b7cin"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.104": {"text": "Vor das weinen/ vor das klagen/", "tokens": ["Vor", "das", "wei\u00b7nen", "/", "vor", "das", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVINF", "$(", "APPR", "PDS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.105": {"text": "La\u00dft mich sagen/", "tokens": ["La\u00dft", "mich", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.106": {"text": "Da\u00df ich ewer Diener bin.", "tokens": ["Da\u00df", "ich", "e\u00b7wer", "Die\u00b7ner", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.107": {"text": "Wie solte sie jhm thun? jhr werdet doch gewehrt/", "tokens": ["Wie", "sol\u00b7te", "sie", "jhm", "thun", "?", "jhr", "wer\u00b7det", "doch", "ge\u00b7wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Kein Mannes Tropffen fellt vergebens zu der Erdt/", "tokens": ["Kein", "Man\u00b7nes", "Tropf\u00b7fen", "fellt", "ver\u00b7ge\u00b7bens", "zu", "der", "Erdt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Vnd was ist besser Rath/ eins hat gebrandt das ander/", "tokens": ["Vnd", "was", "ist", "bes\u00b7ser", "Rath", "/", "eins", "hat", "ge\u00b7brandt", "das", "an\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ADJD", "NN", "$(", "PIS", "VAFIN", "VVPP", "ART", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Als da\u00df jhr nun zugleich geneset mit einander?", "tokens": ["Als", "da\u00df", "jhr", "nun", "zu\u00b7gleich", "ge\u00b7ne\u00b7set", "mit", "ein\u00b7an\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ADV", "VVFIN", "APPR", "PRF", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.111": {"text": "Geht an/ jhr liebes par/ was trettet jhr beseit?", "tokens": ["Geht", "an", "/", "jhr", "lie\u00b7bes", "par", "/", "was", "tret\u00b7tet", "jhr", "be\u00b7seit", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$(", "PPOSAT", "ADJA", "FM", "$(", "PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Es ist jetzund gleich recht/ jetzt ist die beste zeit/", "tokens": ["Es", "ist", "je\u00b7tzund", "gleich", "recht", "/", "jetzt", "ist", "die", "bes\u00b7te", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$(", "ADV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Da\u00df jhr die Hitze lescht. Was wolt jhr viel verziehen.", "tokens": ["Da\u00df", "jhr", "die", "Hit\u00b7ze", "lescht", ".", "Was", "wolt", "jhr", "viel", "ver\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$.", "PWS", "VMFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Was wolt jhr selber das/ so jhr gew\u00fcnschet fliehen?", "tokens": ["Was", "wolt", "jhr", "sel\u00b7ber", "das", "/", "so", "jhr", "ge\u00b7w\u00fcn\u00b7schet", "flie\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ART", "$(", "ADV", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Was ist es/ Jungfraw Braut/ wolt jhr zu r\u00fccke gehn?", "tokens": ["Was", "ist", "es", "/", "Jung\u00b7fraw", "Braut", "/", "wolt", "jhr", "zu", "r\u00fc\u00b7cke", "gehn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$(", "NN", "NN", "$(", "VMFIN", "PPER", "PTKZU", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Es hilfft gewi\u00df euch nicht/ jhr m\u00fcsset doch gestehn/", "tokens": ["Es", "hilfft", "ge\u00b7wi\u00df", "euch", "nicht", "/", "jhr", "m\u00fcs\u00b7set", "doch", "ge\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "PTKNEG", "$(", "PPER", "VMFIN", "ADV", "VVPP", "$("], "meter": "-+-+-++-+--+", "measure": "iambic.hexa.chol"}, "line.117": {"text": "Es ist nun fort mehr alt/ da\u00df man nit kan vertreiben", "tokens": ["Es", "ist", "nun", "fort", "mehr", "alt", "/", "da\u00df", "man", "nit", "kan", "ver\u00b7trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKVZ", "ADV", "ADJD", "$(", "KOUS", "PIS", "PTKNEG", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Zugleich der liebe Brunst/ vnd dannoch Jungfraw bleiben/", "tokens": ["Zu\u00b7gleich", "der", "lie\u00b7be", "Brunst", "/", "vnd", "dan\u00b7noch", "Jung\u00b7fraw", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$(", "KON", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Der Br\u00e4utigam der kompt/ er gehet vff euch zu/", "tokens": ["Der", "Br\u00e4u\u00b7ti\u00b7gam", "der", "kompt", "/", "er", "ge\u00b7het", "vff", "euch", "zu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ART", "VVFIN", "$(", "PPER", "VVFIN", "APPR", "PPER", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Jungfraw/ es ist das best/ jhr gebet euch zu Ruh/", "tokens": ["Jung\u00b7fraw", "/", "es", "ist", "das", "best", "/", "jhr", "ge\u00b7bet", "euch", "zu", "Ruh", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VAFIN", "PDS", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.121": {"text": "Es ist der nechste Rath/ da\u00df man ein Hertze fasse/", "tokens": ["Es", "ist", "der", "nechs\u00b7te", "Rath", "/", "da\u00df", "man", "ein", "Hert\u00b7ze", "fas\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "KOUS", "PIS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Vnd was man nit vermag zu halten/ willig lasse.", "tokens": ["Vnd", "was", "man", "nit", "ver\u00b7mag", "zu", "hal\u00b7ten", "/", "wil\u00b7lig", "las\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PTKNEG", "VVFIN", "PTKZU", "VVINF", "$(", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Trett ab/ jhr Jungfr\u00e4wlein/ die Braut hat jetzt nit Zeit/", "tokens": ["Trett", "ab", "/", "jhr", "Jung\u00b7fr\u00e4w\u00b7lein", "/", "die", "Braut", "hat", "jetzt", "nit", "Zeit", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$(", "PPOSAT", "NN", "$(", "ART", "NN", "VAFIN", "ADV", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "La\u00dft sie zu Bette gehn/ h\u00f6rt auff von ewrem streit/", "tokens": ["La\u00dft", "sie", "zu", "Bet\u00b7te", "gehn", "/", "h\u00f6rt", "auff", "von", "ew\u00b7rem", "streit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "NN", "VVINF", "$(", "VVFIN", "APPR", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Zu einem andern streit mu\u00df sie sich jetzund kehren/", "tokens": ["Zu", "ei\u00b7nem", "an\u00b7dern", "streit", "mu\u00df", "sie", "sich", "je\u00b7tzund", "keh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "O da\u00df wir allesampt in solchem streiten weren.", "tokens": ["O", "da\u00df", "wir", "al\u00b7le\u00b7sampt", "in", "sol\u00b7chem", "strei\u00b7ten", "we\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPER", "ADV", "APPR", "PIAT", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}