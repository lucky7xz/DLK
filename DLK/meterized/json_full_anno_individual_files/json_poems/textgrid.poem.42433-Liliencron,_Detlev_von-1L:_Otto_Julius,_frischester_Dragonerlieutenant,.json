{"textgrid.poem.42433": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Otto Julius, frischester Dragonerlieutenant,", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Otto Julius, frischester Dragonerlieutenant,", "tokens": ["Ot\u00b7to", "Ju\u00b7lius", ",", "fri\u00b7sches\u00b7ter", "Dra\u00b7go\u00b7ner\u00b7lie\u00b7u\u00b7ten\u00b7ant", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,"], "meter": "+-+--+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Mit den roten Backen, mit dem weichen Schnurrbart,", "tokens": ["Mit", "den", "ro\u00b7ten", "Ba\u00b7cken", ",", "mit", "dem", "wei\u00b7chen", "Schnurr\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Mit der m\u00e4chtigen Dichterstirn, mit gro\u00dfen, klugen", "tokens": ["Mit", "der", "m\u00e4ch\u00b7ti\u00b7gen", "Dich\u00b7ter\u00b7stirn", ",", "mit", "gro\u00b7\u00dfen", ",", "klu\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "$,", "ADJA"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Augen, die, ob mit Pince-nez, ob ohne Klemmer,", "tokens": ["Au\u00b7gen", ",", "die", ",", "ob", "mit", "Pin\u00b7ce\u00b7nez", ",", "ob", "oh\u00b7ne", "Klem\u00b7mer", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "$,", "KOUS", "APPR", "NE", "$,", "KOUS", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Wunderbaren Wechsel zeigen immerw\u00e4hrend,", "tokens": ["Wun\u00b7der\u00b7ba\u00b7ren", "Wech\u00b7sel", "zei\u00b7gen", "im\u00b7mer\u00b7w\u00e4h\u00b7rend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Einst, erinnerst du dich dessen, sa\u00dfen oft wir", "tokens": ["Einst", ",", "e\u00b7rin\u00b7nerst", "du", "dich", "des\u00b7sen", ",", "sa\u00b7\u00dfen", "oft", "wir"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "PRF", "PDS", "$,", "VVFIN", "ADV", "PPER"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Bis zum Hahnenruf im M\u00fcnchner Rathauskeller.", "tokens": ["Bis", "zum", "Hah\u00b7nen\u00b7ruf", "im", "M\u00fcnch\u00b7ner", "Rat\u00b7haus\u00b7kel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.8": {"text": "Und wir tranken Ale und Porter, Ale und Porter", "tokens": ["Und", "wir", "tran\u00b7ken", "A\u00b7le", "und", "Por\u00b7ter", ",", "A\u00b7le", "und", "Por\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "NE", "KON", "NN", "$,", "NE", "KON", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Zu der K\u00fcche Meisterwerken, Beef und Fischen.", "tokens": ["Zu", "der", "K\u00fc\u00b7che", "Meis\u00b7ter\u00b7wer\u00b7ken", ",", "Beef", "und", "Fi\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Kniffst du nicht der Kellnerin, der h\u00fcbschen Betti,", "tokens": ["Kniffst", "du", "nicht", "der", "Kell\u00b7ne\u00b7rin", ",", "der", "h\u00fcb\u00b7schen", "Bet\u00b7ti", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Betti'n aus dem Ursulinerinnenkloster,", "tokens": ["Bet\u00b7ti'n", "aus", "dem", "Ur\u00b7su\u00b7li\u00b7ne\u00b7rin\u00b7nen\u00b7klos\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+---+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Gern, doch sanft, doch sanfter st\u00e4rker dr\u00fcckend.", "tokens": ["Gern", ",", "doch", "sanft", ",", "doch", "sanf\u00b7ter", "st\u00e4r\u00b7ker", "dr\u00fc\u00b7ckend", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "In die wei\u00dfen Arme, da\u00df sie leise Au schrie?", "tokens": ["In", "die", "wei\u00b7\u00dfen", "Ar\u00b7me", ",", "da\u00df", "sie", "lei\u00b7se", "Au", "schrie", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "ADJD", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "F\u00fcr vorz\u00fcgliche Zigarren, feinster Kenner,", "tokens": ["F\u00fcr", "vor\u00b7z\u00fcg\u00b7li\u00b7che", "Zi\u00b7gar\u00b7ren", ",", "feins\u00b7ter", "Ken\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Sorgtest du, das soll dir nicht vergessen werden.", "tokens": ["Sorg\u00b7test", "du", ",", "das", "soll", "dir", "nicht", "ver\u00b7ges\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PDS", "VMFIN", "PPER", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Jene herzvertrauten Offenbarungs-N\u00e4chte,", "tokens": ["Je\u00b7ne", "herz\u00b7ver\u00b7trau\u00b7ten", "Of\u00b7fen\u00b7ba\u00b7rungs\u00b7N\u00e4ch\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Die wir mit einander trinkend, plaudernd, lachend,", "tokens": ["Die", "wir", "mit", "ein\u00b7an\u00b7der", "trin\u00b7kend", ",", "plau\u00b7dernd", ",", "la\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PRF", "VVPP", "$,", "VVPP", "$,", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Rauchend sa\u00dfen unten am Gedecke Betti's,", "tokens": ["Rau\u00b7chend", "sa\u00b7\u00dfen", "un\u00b7ten", "am", "Ge\u00b7de\u00b7cke", "Bet\u00b7ti's", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "APPRART", "NN", "NE", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Diese sind mir eben wieder eingefallen,", "tokens": ["Die\u00b7se", "sind", "mir", "e\u00b7ben", "wie\u00b7der", "ein\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Als ich heute deinen Brief in H\u00e4nden hatte,", "tokens": ["Als", "ich", "heu\u00b7te", "dei\u00b7nen", "Brief", "in", "H\u00e4n\u00b7den", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Dem ich schreckensvoll, doch nur im ersten Teile,", "tokens": ["Dem", "ich", "schre\u00b7ckens\u00b7voll", ",", "doch", "nur", "im", "ers\u00b7ten", "Tei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "$,", "ADV", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Eine Kursabweichung zu entnehmen glaubte,", "tokens": ["Ei\u00b7ne", "Kur\u00b7sab\u00b7wei\u00b7chung", "zu", "ent\u00b7neh\u00b7men", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Die mir s\u00e4uerlich und muff verraten w\u00fcrde,", "tokens": ["Die", "mir", "s\u00e4u\u00b7er\u00b7lich", "und", "muff", "ver\u00b7ra\u00b7ten", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "KON", "VMFIN", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Da\u00df du dich verlobt mit Fr\u00e4ulein W\u00fcrdeengel,", "tokens": ["Da\u00df", "du", "dich", "ver\u00b7lobt", "mit", "Fr\u00e4u\u00b7lein", "W\u00fcr\u00b7deen\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Tochter Seiner Excellenz, des Herrn Philisters.", "tokens": ["Toch\u00b7ter", "Sei\u00b7ner", "Ex\u00b7cel\u00b7lenz", ",", "des", "Herrn", "Phi\u00b7lis\u00b7ters", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "ART", "NN", "NE", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.3": {"line.1": {"text": "Wenn erlauscht die guten Deutschen damals h\u00e4tten,", "tokens": ["Wenn", "er\u00b7lauscht", "die", "gu\u00b7ten", "Deut\u00b7schen", "da\u00b7mals", "h\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVPP", "ART", "ADJA", "NN", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Was wir sprachen, ausgelassen uns erz\u00e4hlten,", "tokens": ["Was", "wir", "spra\u00b7chen", ",", "aus\u00b7ge\u00b7las\u00b7sen", "uns", "er\u00b7z\u00e4hl\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Glaube mir, sie h\u00e4tten uns zu Staub gesteinigt:", "tokens": ["Glau\u00b7be", "mir", ",", "sie", "h\u00e4t\u00b7ten", "uns", "zu", "Staub", "ge\u00b7stei\u00b7nigt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "So der Liebe R\u00e4tsel lachend zu entziffern,", "tokens": ["So", "der", "Lie\u00b7be", "R\u00e4t\u00b7sel", "la\u00b7chend", "zu", "ent\u00b7zif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "So die Welt uns lachend um den Kopf zu schlagen.", "tokens": ["So", "die", "Welt", "uns", "la\u00b7chend", "um", "den", "Kopf", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "ADJD", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Glaube mir, sie h\u00e4tten uns zu Staub gesteinigt.", "tokens": ["Glau\u00b7be", "mir", ",", "sie", "h\u00e4t\u00b7ten", "uns", "zu", "Staub", "ge\u00b7stei\u00b7nigt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Und die Kritiker, es w\u00fcrden diese freilich,", "tokens": ["Und", "die", "Kri\u00b7ti\u00b7ker", ",", "es", "w\u00fcr\u00b7den", "die\u00b7se", "frei\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "VAFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Wenn sie die Epistel an dich lesen m\u00f6chten,", "tokens": ["Wenn", "sie", "die", "E\u00b7pis\u00b7tel", "an", "dich", "le\u00b7sen", "m\u00f6ch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Erst im Sechstroch\u00e4us fehlersuchend w\u00fchlen,", "tokens": ["Erst", "im", "Sechs\u00b7troc\u00b7h\u00e4us", "feh\u00b7ler\u00b7su\u00b7chend", "w\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Aber dann, o Himmel, welche Lehrerschelte", "tokens": ["A\u00b7ber", "dann", ",", "o", "Him\u00b7mel", ",", "wel\u00b7che", "Leh\u00b7rer\u00b7schel\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$,", "FM", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "M\u00fc\u00dften wir erleben: \u00bbUnmoralisch! Scheuslich!", "tokens": ["M\u00fc\u00df\u00b7ten", "wir", "er\u00b7le\u00b7ben", ":", "\u00bb", "Un\u00b7mo\u00b7ra\u00b7lisch", "!", "Scheus\u00b7lich", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$.", "$(", "ADJD", "$.", "ADJD", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Seht die beiden als der tiefsten H\u00f6lle Diener.\u00ab", "tokens": ["Seht", "die", "bei\u00b7den", "als", "der", "tiefs\u00b7ten", "H\u00f6l\u00b7le", "Die\u00b7ner", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "PIAT", "KOKOM", "ART", "ADJA", "NN", "NN", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Wenn wir gegenseitig unsere Liebesh\u00e4ndel", "tokens": ["Wenn", "wir", "ge\u00b7gen\u00b7sei\u00b7tig", "un\u00b7se\u00b7re", "Lie\u00b7bes\u00b7h\u00e4n\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Uns zum Besten gaben: Du mir die Geschichte", "tokens": ["Uns", "zum", "Bes\u00b7ten", "ga\u00b7ben", ":", "Du", "mir", "die", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$.", "PPER", "PPER", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Deines schlanken, dunkel\u00e4ugigen Waschermadls,", "tokens": ["Dei\u00b7nes", "schlan\u00b7ken", ",", "dun\u00b7ke\u00b7l\u00e4u\u00b7gi\u00b7gen", "Wa\u00b7scher\u00b7madls", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Das zu dir sich heimlich nachts in's Fenster dr\u00e4ngte,", "tokens": ["Das", "zu", "dir", "sich", "heim\u00b7lich", "nachts", "in's", "Fens\u00b7ter", "dr\u00e4ng\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "PRF", "ADJD", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Das dich so begl\u00fcckt mit ihren sechszehn Jahren;", "tokens": ["Das", "dich", "so", "be\u00b7gl\u00fcckt", "mit", "ih\u00b7ren", "sechs\u00b7zehn", "Jah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "VVPP", "APPR", "PPOSAT", "CARD", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wie sie, trennungstraurig habest du geholfen,", "tokens": ["Wie", "sie", ",", "tren\u00b7nungs\u00b7trau\u00b7rig", "ha\u00b7best", "du", "ge\u00b7hol\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Heimlich in der Fr\u00fche wieder sich entfernte", "tokens": ["Heim\u00b7lich", "in", "der", "Fr\u00fc\u00b7he", "wie\u00b7der", "sich", "ent\u00b7fern\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "ADV", "PRF", "VVFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Auf dem gleichen Weg; wie du dem muntren Kerlchen", "tokens": ["Auf", "dem", "glei\u00b7chen", "Weg", ";", "wie", "du", "dem", "mun\u00b7tren", "Kerl\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Nachgeschaut; wie rote kleine Morgenwolken", "tokens": ["Nach\u00b7ge\u00b7schaut", ";", "wie", "ro\u00b7te", "klei\u00b7ne", "Mor\u00b7gen\u00b7wol\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$.", "PWAV", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Himmelsheilig ihr die Kinderstirn begl\u00e4nzten,", "tokens": ["Him\u00b7mels\u00b7hei\u00b7lig", "ihr", "die", "Kin\u00b7ders\u00b7tirn", "be\u00b7gl\u00e4nz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Ihr, die durch den Tau, am Wassersturz der Isar,", "tokens": ["Ihr", ",", "die", "durch", "den", "Tau", ",", "am", "Was\u00b7ser\u00b7sturz", "der", "I\u00b7sar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPR", "ART", "NN", "$,", "APPRART", "NN", "ART", "NE", "$,"], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Schnellen, scheuen, leichten Schrittes sei entschwunden.", "tokens": ["Schnel\u00b7len", ",", "scheu\u00b7en", ",", "leich\u00b7ten", "Schrit\u00b7tes", "sei", "ent\u00b7schwun\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Hie\u00df Jeanette nicht dein reizend Waschermadl?", "tokens": ["Hie\u00df", "Jea\u00b7net\u00b7te", "nicht", "dein", "rei\u00b7zend", "Wa\u00b7scher\u00b7madl", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "PPOSAT", "ADJD", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.14": {"text": "Wenn von meinem Schneidermadl ich erz\u00e4hlte", "tokens": ["Wenn", "von", "mei\u00b7nem", "Schnei\u00b7der\u00b7madl", "ich", "er\u00b7z\u00e4hl\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "\u2013 Denk an das \u00bbGer\u00fcmpfe\u00ab edler Wackernasen:", "tokens": ["\u2013", "Denk", "an", "das", "\u00bb", "Ge\u00b7r\u00fcmp\u00b7fe", "\u00ab", "ed\u00b7ler", "Wa\u00b7cker\u00b7na\u00b7sen", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "APPR", "ART", "$(", "NN", "$(", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "\u00bbwaschermadel, Schneidermadel: Die Bekanntschaft\u00ab \u2013", "tokens": ["\u00bb", "wa\u00b7scher\u00b7ma\u00b7del", ",", "Schnei\u00b7der\u00b7ma\u00b7del", ":", "Die", "Be\u00b7kannt\u00b7schaft", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "$.", "ART", "NN", "$(", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.17": {"text": "Wenn von meinem Schneidermadl ich erz\u00e4hlte,", "tokens": ["Wenn", "von", "mei\u00b7nem", "Schnei\u00b7der\u00b7madl", "ich", "er\u00b7z\u00e4hl\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Die, nicht anders ging's derweil, mir immer wieder", "tokens": ["Die", ",", "nicht", "an\u00b7ders", "ging's", "der\u00b7weil", ",", "mir", "im\u00b7mer", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "$,", "PTKNEG", "ADV", "VVFIN", "ADV", "$,", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.19": {"text": "Stoffe brachte, R\u00f6cke, Hosen, Westen holte.", "tokens": ["Stof\u00b7fe", "brach\u00b7te", ",", "R\u00f6\u00b7cke", ",", "Ho\u00b7sen", ",", "Wes\u00b7ten", "hol\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "$,", "NN", "$,", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.20": {"text": "War nichts mehr zum Flicken vorr\u00e4tig im Schranke,", "tokens": ["War", "nichts", "mehr", "zum", "Fli\u00b7cken", "vor\u00b7r\u00e4\u00b7tig", "im", "Schran\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "APPRART", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.21": {"text": "Trennten N\u00e4hte wir, zerrissen Unterfutter.", "tokens": ["Trenn\u00b7ten", "N\u00e4h\u00b7te", "wir", ",", "zer\u00b7ris\u00b7sen", "Un\u00b7ter\u00b7fut\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.22": {"text": "Die mich mit den sechszehn Jahren hurtig k\u00fc\u00dfte,", "tokens": ["Die", "mich", "mit", "den", "sechs\u00b7zehn", "Jah\u00b7ren", "hur\u00b7tig", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "CARD", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.23": {"text": "K\u00fc\u00dfte, bis die wenigen Minuten schwanden.", "tokens": ["K\u00fc\u00df\u00b7te", ",", "bis", "die", "we\u00b7ni\u00b7gen", "Mi\u00b7nu\u00b7ten", "schwan\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.24": {"text": "Sp\u00e4ter ward es besser, durch des M\u00e4dchens Schlauheit,", "tokens": ["Sp\u00e4\u00b7ter", "ward", "es", "bes\u00b7ser", ",", "durch", "des", "M\u00e4d\u00b7chens", "Schlau\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.25": {"text": "Eine Stunde blieb sie, stundenlang und l\u00e4nger,", "tokens": ["Ei\u00b7ne", "Stun\u00b7de", "blieb", "sie", ",", "stun\u00b7den\u00b7lang", "und", "l\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.26": {"text": "Bis die erste hei\u00dfe Liebesnacht herankam.", "tokens": ["Bis", "die", "ers\u00b7te", "hei\u00b7\u00dfe", "Lie\u00b7bes\u00b7nacht", "her\u00b7an\u00b7kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.27": {"text": "Wie sie nun am andern Morgen \u00e4ngstlich fortschlich,", "tokens": ["Wie", "sie", "nun", "am", "an\u00b7dern", "Mor\u00b7gen", "\u00e4ngst\u00b7lich", "fort\u00b7schlich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPRART", "ADJA", "NN", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.28": {"text": "Warf sie ungeschickt vom Teller ihrer Rechten,", "tokens": ["Warf", "sie", "un\u00b7ge\u00b7schickt", "vom", "Tel\u00b7ler", "ih\u00b7rer", "Rech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.29": {"text": "Ihre Finger spreizend, mir ihr letztes Gr\u00fc\u00dfen:", "tokens": ["Ih\u00b7re", "Fin\u00b7ger", "sprei\u00b7zend", ",", "mir", "ihr", "letz\u00b7tes", "Gr\u00fc\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.30": {"text": "R\u00fchrend war es mir, wie dir, dem ich's vertraute.", "tokens": ["R\u00fch\u00b7rend", "war", "es", "mir", ",", "wie", "dir", ",", "dem", "ich's", "ver\u00b7trau\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PPER", "$,", "PWAV", "PPER", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.31": {"text": "Saugend war ihr Ku\u00df, ein wenig unanmutig,", "tokens": ["Sau\u00b7gend", "war", "ihr", "Ku\u00df", ",", "ein", "we\u00b7nig", "un\u00b7an\u00b7mu\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "NN", "$,", "ART", "PIS", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.32": {"text": "Ganz, als s\u00f6ge noch sie an der Mutter Br\u00fcsten;", "tokens": ["Ganz", ",", "als", "s\u00f6\u00b7ge", "noch", "sie", "an", "der", "Mut\u00b7ter", "Br\u00fcs\u00b7ten", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "NN", "ADV", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.33": {"text": "Doch Natur, Natur, jungwilde Ungez\u00e4hmtheit.", "tokens": ["Doch", "Na\u00b7tur", ",", "Na\u00b7tur", ",", "jung\u00b7wil\u00b7de", "Un\u00b7ge\u00b7z\u00e4hmt\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.5": {"line.1": {"text": "Denkst du noch an unser kleines Abenteuer", "tokens": ["Denkst", "du", "noch", "an", "un\u00b7ser", "klei\u00b7nes", "A\u00b7bent\u00b7eu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "\u2013 Cenz und Loni nannten sich die h\u00fcbschen Fr\u00e4tzchen \u2013,", "tokens": ["\u2013", "Cenz", "und", "Lo\u00b7ni", "nann\u00b7ten", "sich", "die", "h\u00fcb\u00b7schen", "Fr\u00e4tz\u00b7chen", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "KON", "NE", "VVFIN", "PRF", "ART", "ADJA", "NN", "$(", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Das Boccaz zum Vater h\u00e4tte haben k\u00f6nnen:", "tokens": ["Das", "Boc\u00b7caz", "zum", "Va\u00b7ter", "h\u00e4t\u00b7te", "ha\u00b7ben", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "VAINF", "VMFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Durch gemeinsam ausgef\u00fchrte kleine Fahrten", "tokens": ["Durch", "ge\u00b7mein\u00b7sam", "aus\u00b7ge\u00b7f\u00fchr\u00b7te", "klei\u00b7ne", "Fahr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Waren n\u00e4her wir zu Viert bekannt geworden.", "tokens": ["Wa\u00b7ren", "n\u00e4\u00b7her", "wir", "zu", "Viert", "be\u00b7kannt", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "APPR", "CARD", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Als wir eine Wette machten auf die Treue", "tokens": ["Als", "wir", "ei\u00b7ne", "Wet\u00b7te", "mach\u00b7ten", "auf", "die", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Unsrer Sch\u00e4tzchen, und zur gleichbestimmten Stunde", "tokens": ["Uns\u00b7rer", "Sch\u00e4tz\u00b7chen", ",", "und", "zur", "gleich\u00b7bes\u00b7timm\u00b7ten", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Jede an den andern sandten nach Gew\u00fcnschtem,", "tokens": ["Je\u00b7de", "an", "den", "an\u00b7dern", "sand\u00b7ten", "nach", "Ge\u00b7w\u00fcnschtem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "ART", "ADJA", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Wie uns dann nach einigem Gesichterschneiden", "tokens": ["Wie", "uns", "dann", "nach", "ei\u00b7ni\u00b7gem", "Ge\u00b7sich\u00b7ter\u00b7schnei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.10": {"text": "\u2013 Zuckten nicht sekundenlang zwei durstige Dolche \u2013,", "tokens": ["\u2013", "Zuck\u00b7ten", "nicht", "se\u00b7kun\u00b7den\u00b7lang", "zwei", "durs\u00b7ti\u00b7ge", "Dol\u00b7che", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "PTKNEG", "VVFIN", "CARD", "ADJA", "NN", "$(", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.11": {"text": "Da wir uns das Wort gegeben, wahr zu sprechen,", "tokens": ["Da", "wir", "uns", "das", "Wort", "ge\u00b7ge\u00b7ben", ",", "wahr", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "VVPP", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.12": {"text": "Ein nicht enden wollendes Gel\u00e4chter sch\u00fcttert.", "tokens": ["Ein", "nicht", "en\u00b7den", "wol\u00b7len\u00b7des", "Ge\u00b7l\u00e4ch\u00b7ter", "sch\u00fct\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "VVINF", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "L\u00fcstern nach verbotnem Speck ist jedes M\u00e4uschen.", "tokens": ["L\u00fcs\u00b7tern", "nach", "ver\u00b7bot\u00b7nem", "Speck", "ist", "je\u00b7des", "M\u00e4u\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Spricht nicht irgendwo ein alter Lebensk\u00fcnstler,", "tokens": ["Spricht", "nicht", "ir\u00b7gend\u00b7wo", "ein", "al\u00b7ter", "Le\u00b7bens\u00b7k\u00fcnst\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Da\u00df erg\u00f6tzlich sei der Wechsel in der Liebe?", "tokens": ["Da\u00df", "er\u00b7g\u00f6tz\u00b7lich", "sei", "der", "Wech\u00b7sel", "in", "der", "Lie\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Apage!", "tokens": ["A\u00b7pa\u00b7ge", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.17": {"text": "Doch was ich sagen wollte, Lieber:", "tokens": ["Doch", "was", "ich", "sa\u00b7gen", "woll\u00b7te", ",", "Lie\u00b7ber", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Blieb dir jener Winterabend im Ged\u00e4chtnis?:", "tokens": ["Blieb", "dir", "je\u00b7ner", "Win\u00b7ter\u00b7a\u00b7bend", "im", "Ge\u00b7d\u00e4cht\u00b7nis", "?", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "APPRART", "NN", "$.", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.19": {"text": "Beim Burgurder, Nuits, bei deinem Lieblingsweine,", "tokens": ["Beim", "Bur\u00b7gur\u00b7der", ",", "Nuits", ",", "bei", "dei\u00b7nem", "Lieb\u00b7lings\u00b7wei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Sa\u00dfen wir schon lange. Alles war gegangen.", "tokens": ["Sa\u00b7\u00dfen", "wir", "schon", "lan\u00b7ge", ".", "Al\u00b7les", "war", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$.", "PIS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.21": {"text": "Unter Aufsicht des Ratskellerk\u00fcfermeisters", "tokens": ["Un\u00b7ter", "Auf\u00b7sicht", "des", "Rats\u00b7kel\u00b7ler\u00b7k\u00fc\u00b7fer\u00b7meis\u00b7ters"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.22": {"text": "War der Zug, je zwei auf zwei, der Kellnerinnen", "tokens": ["War", "der", "Zug", ",", "je", "zwei", "auf", "zwei", ",", "der", "Kell\u00b7ne\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "ADV", "CARD", "APPR", "CARD", "$,", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.23": {"text": "In das Nebenhaus zum Schlafen abgezogen.", "tokens": ["In", "das", "Ne\u00b7ben\u00b7haus", "zum", "Schla\u00b7fen", "ab\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.24": {"text": "Nur ein Piccolo, die einzige Bedienung,", "tokens": ["Nur", "ein", "Pic\u00b7co\u00b7lo", ",", "die", "ein\u00b7zi\u00b7ge", "Be\u00b7die\u00b7nung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Lag, entschlummert, \u00fcber einer gro\u00dfen Zeitung,", "tokens": ["Lag", ",", "ent\u00b7schlum\u00b7mert", ",", "\u00fc\u00b7ber", "ei\u00b7ner", "gro\u00b7\u00dfen", "Zei\u00b7tung", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.26": {"text": "Und ein Blumenm\u00e4dchen schlief an einer S\u00e4ule,", "tokens": ["Und", "ein", "Blu\u00b7men\u00b7m\u00e4d\u00b7chen", "schlief", "an", "ei\u00b7ner", "S\u00e4u\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.27": {"text": "Blassen Antlitzes, das wunderbar sich abhob", "tokens": ["Blas\u00b7sen", "Ant\u00b7lit\u00b7zes", ",", "das", "wun\u00b7der\u00b7bar", "sich", "ab\u00b7hob"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADJD", "PRF", "VVFIN"], "meter": "+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.28": {"text": "Aus den dunkelroten Rosen, die dem Korbe", "tokens": ["Aus", "den", "dun\u00b7kel\u00b7ro\u00b7ten", "Ro\u00b7sen", ",", "die", "dem", "Kor\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.29": {"text": "Sich entsch\u00fcttet hatten um die m\u00fcden Schl\u00e4fen.", "tokens": ["Sich", "ent\u00b7sch\u00fct\u00b7tet", "hat\u00b7ten", "um", "die", "m\u00fc\u00b7den", "Schl\u00e4\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "VAFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.30": {"text": "Pl\u00f6tzlich durch die mittern\u00e4chtige Stille klang ein", "tokens": ["Pl\u00f6tz\u00b7lich", "durch", "die", "mit\u00b7ter\u00b7n\u00e4ch\u00b7ti\u00b7ge", "Stil\u00b7le", "klang", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "VVFIN", "ART"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.31": {"text": "Dumpfes, mattes Rauschen; und ein uralt M\u00e4nnchen", "tokens": ["Dum\u00b7pfes", ",", "mat\u00b7tes", "Rau\u00b7schen", ";", "und", "ein", "ur\u00b7alt", "M\u00e4nn\u00b7chen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADJA", "NN", "$.", "KON", "ART", "NN", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.32": {"text": "Stand an unserm Tische, sich vor uns verneigend:", "tokens": ["Stand", "an", "un\u00b7serm", "Ti\u00b7sche", ",", "sich", "vor", "uns", "ver\u00b7nei\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,", "PRF", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.33": {"text": "\u00bbihr da, Dichterlinge, thut mir den Gefallen,", "tokens": ["\u00bb", "ihr", "da", ",", "Dich\u00b7ter\u00b7lin\u00b7ge", ",", "thut", "mir", "den", "Ge\u00b7fal\u00b7len", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.34": {"text": "Sagt mir, weshalb redet ihr so unabl\u00e4ssig", "tokens": ["Sagt", "mir", ",", "we\u00b7shalb", "re\u00b7det", "ihr", "so", "un\u00b7ab\u00b7l\u00e4s\u00b7sig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.35": {"text": "Naseweis von unsrer guten deutschen Dichtung?", "tokens": ["Na\u00b7se\u00b7weis", "von", "uns\u00b7rer", "gu\u00b7ten", "deut\u00b7schen", "Dich\u00b7tung", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.36": {"text": "Besser w\u00e4r's, statt immerfort zu raisonnieren,", "tokens": ["Bes\u00b7ser", "w\u00e4r's", ",", "statt", "im\u00b7mer\u00b7fort", "zu", "rai\u00b7son\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "KOUI", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.37": {"text": "Wenn ihre eure Kritzeleien so dem Landsmann", "tokens": ["Wenn", "ih\u00b7re", "eu\u00b7re", "Krit\u00b7ze\u00b7lei\u00b7en", "so", "dem", "Lands\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "PPOSAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Dem gewohnten Lotternachmittagsschlafsopha", "tokens": ["Dem", "ge\u00b7wohn\u00b7ten", "Lot\u00b7ter\u00b7nach\u00b7mit\u00b7tags\u00b7schlaf\u00b7so\u00b7pha"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.39": {"text": "N\u00e4her r\u00fccktet, da\u00df er's m\u00fchelos verdaute.", "tokens": ["N\u00e4\u00b7her", "r\u00fcck\u00b7tet", ",", "da\u00df", "er's", "m\u00fc\u00b7he\u00b7los", "ver\u00b7dau\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.40": {"text": "Und es w\u00fcrden euch die Portemonnaies bald voll sein,", "tokens": ["Und", "es", "w\u00fcr\u00b7den", "euch", "die", "Por\u00b7te\u00b7mon\u00b7nai\u00b7es", "bald", "voll", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VAINF", "$,"], "meter": "--+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.41": {"text": "K\u00f6nntet ihr euch endlich doch entschlie\u00dfen: einzig", "tokens": ["K\u00f6nn\u00b7tet", "ihr", "euch", "end\u00b7lich", "doch", "ent\u00b7schlie\u00b7\u00dfen", ":", "ein\u00b7zig"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$.", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.42": {"text": "Eure Feder einzutauchen dieser Weise,", "tokens": ["Eu\u00b7re", "Fe\u00b7der", "ein\u00b7zu\u00b7tau\u00b7chen", "die\u00b7ser", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVIZU", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.43": {"text": "Da\u00df sie tr\u00e4uft von faden Honigseimgeschichten,", "tokens": ["Da\u00df", "sie", "tr\u00e4uft", "von", "fa\u00b7den", "Ho\u00b7ni\u00b7gseim\u00b7ge\u00b7schich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.44": {"text": "F\u00fcr die deutschen Bilderfibeln eingerichtet.\u00ab", "tokens": ["F\u00fcr", "die", "deut\u00b7schen", "Bil\u00b7der\u00b7fi\u00b7beln", "ein\u00b7ge\u00b7rich\u00b7tet", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.45": {"text": "W\u00fctend sprangst du auf, ich hielt dich fest am Rockscho\u00df,", "tokens": ["W\u00fc\u00b7tend", "sprangst", "du", "auf", ",", "ich", "hielt", "dich", "fest", "am", "Rock\u00b7scho\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PRF", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.46": {"text": "Sonst, wahrhaftig, h\u00e4ttest du dem armen M\u00e4nnchen", "tokens": ["Sonst", ",", "wahr\u00b7haf\u00b7tig", ",", "h\u00e4t\u00b7test", "du", "dem", "ar\u00b7men", "M\u00e4nn\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADJD", "$,", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.47": {"text": "Sicher das Genick gebrochen, und du flammtest:", "tokens": ["Si\u00b7cher", "das", "Ge\u00b7nick", "ge\u00b7bro\u00b7chen", ",", "und", "du", "flamm\u00b7test", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.48": {"text": "\u00bbfort, Versucher, fort mit deinem Klingebeutel,", "tokens": ["\u00bb", "fort", ",", "Ver\u00b7su\u00b7cher", ",", "fort", "mit", "dei\u00b7nem", "Klin\u00b7ge\u00b7beu\u00b7tel", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "NN", "$,", "PTKVZ", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.49": {"text": "Troll' dich in dein Nichts zur\u00fcck, verdammter H\u00e4mmling!", "tokens": ["Troll'", "dich", "in", "dein", "Nichts", "zu\u00b7r\u00fcck", ",", "ver\u00b7damm\u00b7ter", "H\u00e4mm\u00b7ling", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.50": {"text": "Schreiben wir, so schreiben uns wir und den wenigen", "tokens": ["Schrei\u00b7ben", "wir", ",", "so", "schrei\u00b7ben", "uns", "wir", "und", "den", "we\u00b7ni\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PPER", "KON", "ART", "PIAT"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.51": {"text": "Gleichgesinnten, freiheitsfr\u00f6hlichstolzen Herzen.", "tokens": ["Gleich\u00b7ge\u00b7sinn\u00b7ten", ",", "frei\u00b7heits\u00b7fr\u00f6h\u00b7lich\u00b7stol\u00b7zen", "Her\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.52": {"text": "Unaussprechlich schnuppe ist f\u00fcr uns der Leser.\u00ab", "tokens": ["Un\u00b7aus\u00b7sprech\u00b7lich", "schnup\u00b7pe", "ist", "f\u00fcr", "uns", "der", "Le\u00b7ser", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "VAFIN", "APPR", "PPER", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.6": {"line.1": {"text": "Alles ist mir eben wieder eingefallen,", "tokens": ["Al\u00b7les", "ist", "mir", "e\u00b7ben", "wie\u00b7der", "ein\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Als ich heute deinen Brief in H\u00e4nden hatte,", "tokens": ["Als", "ich", "heu\u00b7te", "dei\u00b7nen", "Brief", "in", "H\u00e4n\u00b7den", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Dem ich schreckensvoll, doch nur im ersten Teile,", "tokens": ["Dem", "ich", "schre\u00b7ckens\u00b7voll", ",", "doch", "nur", "im", "ers\u00b7ten", "Tei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "$,", "ADV", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Eine Kursabweichung zu entnehmen glaubte,", "tokens": ["Ei\u00b7ne", "Kur\u00b7sab\u00b7wei\u00b7chung", "zu", "ent\u00b7neh\u00b7men", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Die mir s\u00e4uerlich und muff verraten w\u00fcrde,", "tokens": ["Die", "mir", "s\u00e4u\u00b7er\u00b7lich", "und", "muff", "ver\u00b7ra\u00b7ten", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "KON", "VMFIN", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Da\u00df du dich verlobt mit Fr\u00e4ulein W\u00fcrdengel,", "tokens": ["Da\u00df", "du", "dich", "ver\u00b7lobt", "mit", "Fr\u00e4u\u00b7lein", "W\u00fcr\u00b7den\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Tochter Seiner Excellenz, des Herrn Philisters.", "tokens": ["Toch\u00b7ter", "Sei\u00b7ner", "Ex\u00b7cel\u00b7lenz", ",", "des", "Herrn", "Phi\u00b7lis\u00b7ters", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "ART", "NN", "NE", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.7": {"line.1": {"text": "Otto Julius, frischester Dragonerlieutenant,", "tokens": ["Ot\u00b7to", "Ju\u00b7lius", ",", "fri\u00b7sches\u00b7ter", "Dra\u00b7go\u00b7ner\u00b7lie\u00b7u\u00b7ten\u00b7ant", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,"], "meter": "+-+--+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Mit den roten Backen, mit dem weichen Schnurrbart,", "tokens": ["Mit", "den", "ro\u00b7ten", "Ba\u00b7cken", ",", "mit", "dem", "wei\u00b7chen", "Schnurr\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Mit der m\u00e4chtigen Dichterstirn, mit gro\u00dfen, klugen", "tokens": ["Mit", "der", "m\u00e4ch\u00b7ti\u00b7gen", "Dich\u00b7ter\u00b7stirn", ",", "mit", "gro\u00b7\u00dfen", ",", "klu\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "$,", "ADJA"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Augen, die, ob mit Pince-nez, ob ohne Klemmer,", "tokens": ["Au\u00b7gen", ",", "die", ",", "ob", "mit", "Pin\u00b7ce\u00b7nez", ",", "ob", "oh\u00b7ne", "Klem\u00b7mer", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "$,", "KOUS", "APPR", "NE", "$,", "KOUS", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Wunderbaren Wechsel zeigen immerw\u00e4hrend,", "tokens": ["Wun\u00b7der\u00b7ba\u00b7ren", "Wech\u00b7sel", "zei\u00b7gen", "im\u00b7mer\u00b7w\u00e4h\u00b7rend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Einst, erinnerst du dich dessen, sa\u00dfen oft wir", "tokens": ["Einst", ",", "e\u00b7rin\u00b7nerst", "du", "dich", "des\u00b7sen", ",", "sa\u00b7\u00dfen", "oft", "wir"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "PRF", "PDS", "$,", "VVFIN", "ADV", "PPER"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Bis zum Hahnenruf im M\u00fcnchner Rathauskeller.", "tokens": ["Bis", "zum", "Hah\u00b7nen\u00b7ruf", "im", "M\u00fcnch\u00b7ner", "Rat\u00b7haus\u00b7kel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.8": {"text": "Und wir tranken Ale und Porter, Ale und Porter", "tokens": ["Und", "wir", "tran\u00b7ken", "A\u00b7le", "und", "Por\u00b7ter", ",", "A\u00b7le", "und", "Por\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "NE", "KON", "NN", "$,", "NE", "KON", "NN"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Zu der K\u00fcche Meisterwerken, Beef und Fischen.", "tokens": ["Zu", "der", "K\u00fc\u00b7che", "Meis\u00b7ter\u00b7wer\u00b7ken", ",", "Beef", "und", "Fi\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Kniffst du nicht der Kellnerin, der h\u00fcbschen Betti,", "tokens": ["Kniffst", "du", "nicht", "der", "Kell\u00b7ne\u00b7rin", ",", "der", "h\u00fcb\u00b7schen", "Bet\u00b7ti", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Betti'n aus dem Ursulinerinnenkloster,", "tokens": ["Bet\u00b7ti'n", "aus", "dem", "Ur\u00b7su\u00b7li\u00b7ne\u00b7rin\u00b7nen\u00b7klos\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+---+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Gern, doch sanft, doch sanfter st\u00e4rker dr\u00fcckend.", "tokens": ["Gern", ",", "doch", "sanft", ",", "doch", "sanf\u00b7ter", "st\u00e4r\u00b7ker", "dr\u00fc\u00b7ckend", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "In die wei\u00dfen Arme, da\u00df sie leise Au schrie?", "tokens": ["In", "die", "wei\u00b7\u00dfen", "Ar\u00b7me", ",", "da\u00df", "sie", "lei\u00b7se", "Au", "schrie", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "ADJD", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "F\u00fcr vorz\u00fcgliche Zigarren, feinster Kenner,", "tokens": ["F\u00fcr", "vor\u00b7z\u00fcg\u00b7li\u00b7che", "Zi\u00b7gar\u00b7ren", ",", "feins\u00b7ter", "Ken\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Sorgtest du, das soll dir nicht vergessen werden.", "tokens": ["Sorg\u00b7test", "du", ",", "das", "soll", "dir", "nicht", "ver\u00b7ges\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PDS", "VMFIN", "PPER", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.8": {"line.1": {"text": "Jene herzvertrauten Offenbarungs-N\u00e4chte,", "tokens": ["Je\u00b7ne", "herz\u00b7ver\u00b7trau\u00b7ten", "Of\u00b7fen\u00b7ba\u00b7rungs\u00b7N\u00e4ch\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Die wir mit einander trinkend, plaudernd, lachend,", "tokens": ["Die", "wir", "mit", "ein\u00b7an\u00b7der", "trin\u00b7kend", ",", "plau\u00b7dernd", ",", "la\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PRF", "VVPP", "$,", "VVPP", "$,", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Rauchend sa\u00dfen unten am Gedecke Betti's,", "tokens": ["Rau\u00b7chend", "sa\u00b7\u00dfen", "un\u00b7ten", "am", "Ge\u00b7de\u00b7cke", "Bet\u00b7ti's", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "APPRART", "NN", "NE", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Diese sind mir eben wieder eingefallen,", "tokens": ["Die\u00b7se", "sind", "mir", "e\u00b7ben", "wie\u00b7der", "ein\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Als ich heute deinen Brief in H\u00e4nden hatte,", "tokens": ["Als", "ich", "heu\u00b7te", "dei\u00b7nen", "Brief", "in", "H\u00e4n\u00b7den", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Dem ich schreckensvoll, doch nur im ersten Teile,", "tokens": ["Dem", "ich", "schre\u00b7ckens\u00b7voll", ",", "doch", "nur", "im", "ers\u00b7ten", "Tei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "$,", "ADV", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Eine Kursabweichung zu entnehmen glaubte,", "tokens": ["Ei\u00b7ne", "Kur\u00b7sab\u00b7wei\u00b7chung", "zu", "ent\u00b7neh\u00b7men", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Die mir s\u00e4uerlich und muff verraten w\u00fcrde,", "tokens": ["Die", "mir", "s\u00e4u\u00b7er\u00b7lich", "und", "muff", "ver\u00b7ra\u00b7ten", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "KON", "VMFIN", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Da\u00df du dich verlobt mit Fr\u00e4ulein W\u00fcrdeengel,", "tokens": ["Da\u00df", "du", "dich", "ver\u00b7lobt", "mit", "Fr\u00e4u\u00b7lein", "W\u00fcr\u00b7deen\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Tochter Seiner Excellenz, des Herrn Philisters.", "tokens": ["Toch\u00b7ter", "Sei\u00b7ner", "Ex\u00b7cel\u00b7lenz", ",", "des", "Herrn", "Phi\u00b7lis\u00b7ters", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "ART", "NN", "NE", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.9": {"line.1": {"text": "Wenn erlauscht die guten Deutschen damals h\u00e4tten,", "tokens": ["Wenn", "er\u00b7lauscht", "die", "gu\u00b7ten", "Deut\u00b7schen", "da\u00b7mals", "h\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVPP", "ART", "ADJA", "NN", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Was wir sprachen, ausgelassen uns erz\u00e4hlten,", "tokens": ["Was", "wir", "spra\u00b7chen", ",", "aus\u00b7ge\u00b7las\u00b7sen", "uns", "er\u00b7z\u00e4hl\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Glaube mir, sie h\u00e4tten uns zu Staub gesteinigt:", "tokens": ["Glau\u00b7be", "mir", ",", "sie", "h\u00e4t\u00b7ten", "uns", "zu", "Staub", "ge\u00b7stei\u00b7nigt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "So der Liebe R\u00e4tsel lachend zu entziffern,", "tokens": ["So", "der", "Lie\u00b7be", "R\u00e4t\u00b7sel", "la\u00b7chend", "zu", "ent\u00b7zif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "So die Welt uns lachend um den Kopf zu schlagen.", "tokens": ["So", "die", "Welt", "uns", "la\u00b7chend", "um", "den", "Kopf", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "ADJD", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Glaube mir, sie h\u00e4tten uns zu Staub gesteinigt.", "tokens": ["Glau\u00b7be", "mir", ",", "sie", "h\u00e4t\u00b7ten", "uns", "zu", "Staub", "ge\u00b7stei\u00b7nigt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Und die Kritiker, es w\u00fcrden diese freilich,", "tokens": ["Und", "die", "Kri\u00b7ti\u00b7ker", ",", "es", "w\u00fcr\u00b7den", "die\u00b7se", "frei\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "VAFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Wenn sie die Epistel an dich lesen m\u00f6chten,", "tokens": ["Wenn", "sie", "die", "E\u00b7pis\u00b7tel", "an", "dich", "le\u00b7sen", "m\u00f6ch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Erst im Sechstroch\u00e4us fehlersuchend w\u00fchlen,", "tokens": ["Erst", "im", "Sechs\u00b7troc\u00b7h\u00e4us", "feh\u00b7ler\u00b7su\u00b7chend", "w\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Aber dann, o Himmel, welche Lehrerschelte", "tokens": ["A\u00b7ber", "dann", ",", "o", "Him\u00b7mel", ",", "wel\u00b7che", "Leh\u00b7rer\u00b7schel\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$,", "FM", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "M\u00fc\u00dften wir erleben: \u00bbUnmoralisch! Scheuslich!", "tokens": ["M\u00fc\u00df\u00b7ten", "wir", "er\u00b7le\u00b7ben", ":", "\u00bb", "Un\u00b7mo\u00b7ra\u00b7lisch", "!", "Scheus\u00b7lich", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$.", "$(", "ADJD", "$.", "ADJD", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Seht die beiden als der tiefsten H\u00f6lle Diener.\u00ab", "tokens": ["Seht", "die", "bei\u00b7den", "als", "der", "tiefs\u00b7ten", "H\u00f6l\u00b7le", "Die\u00b7ner", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "PIAT", "KOKOM", "ART", "ADJA", "NN", "NN", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.10": {"line.1": {"text": "Wenn wir gegenseitig unsere Liebesh\u00e4ndel", "tokens": ["Wenn", "wir", "ge\u00b7gen\u00b7sei\u00b7tig", "un\u00b7se\u00b7re", "Lie\u00b7bes\u00b7h\u00e4n\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Uns zum Besten gaben: Du mir die Geschichte", "tokens": ["Uns", "zum", "Bes\u00b7ten", "ga\u00b7ben", ":", "Du", "mir", "die", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$.", "PPER", "PPER", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Deines schlanken, dunkel\u00e4ugigen Waschermadls,", "tokens": ["Dei\u00b7nes", "schlan\u00b7ken", ",", "dun\u00b7ke\u00b7l\u00e4u\u00b7gi\u00b7gen", "Wa\u00b7scher\u00b7madls", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Das zu dir sich heimlich nachts in's Fenster dr\u00e4ngte,", "tokens": ["Das", "zu", "dir", "sich", "heim\u00b7lich", "nachts", "in's", "Fens\u00b7ter", "dr\u00e4ng\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "PRF", "ADJD", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Das dich so begl\u00fcckt mit ihren sechszehn Jahren;", "tokens": ["Das", "dich", "so", "be\u00b7gl\u00fcckt", "mit", "ih\u00b7ren", "sechs\u00b7zehn", "Jah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "VVPP", "APPR", "PPOSAT", "CARD", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wie sie, trennungstraurig habest du geholfen,", "tokens": ["Wie", "sie", ",", "tren\u00b7nungs\u00b7trau\u00b7rig", "ha\u00b7best", "du", "ge\u00b7hol\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Heimlich in der Fr\u00fche wieder sich entfernte", "tokens": ["Heim\u00b7lich", "in", "der", "Fr\u00fc\u00b7he", "wie\u00b7der", "sich", "ent\u00b7fern\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "ADV", "PRF", "VVFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Auf dem gleichen Weg; wie du dem muntren Kerlchen", "tokens": ["Auf", "dem", "glei\u00b7chen", "Weg", ";", "wie", "du", "dem", "mun\u00b7tren", "Kerl\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Nachgeschaut; wie rote kleine Morgenwolken", "tokens": ["Nach\u00b7ge\u00b7schaut", ";", "wie", "ro\u00b7te", "klei\u00b7ne", "Mor\u00b7gen\u00b7wol\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$.", "PWAV", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Himmelsheilig ihr die Kinderstirn begl\u00e4nzten,", "tokens": ["Him\u00b7mels\u00b7hei\u00b7lig", "ihr", "die", "Kin\u00b7ders\u00b7tirn", "be\u00b7gl\u00e4nz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Ihr, die durch den Tau, am Wassersturz der Isar,", "tokens": ["Ihr", ",", "die", "durch", "den", "Tau", ",", "am", "Was\u00b7ser\u00b7sturz", "der", "I\u00b7sar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPR", "ART", "NN", "$,", "APPRART", "NN", "ART", "NE", "$,"], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Schnellen, scheuen, leichten Schrittes sei entschwunden.", "tokens": ["Schnel\u00b7len", ",", "scheu\u00b7en", ",", "leich\u00b7ten", "Schrit\u00b7tes", "sei", "ent\u00b7schwun\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Hie\u00df Jeanette nicht dein reizend Waschermadl?", "tokens": ["Hie\u00df", "Jea\u00b7net\u00b7te", "nicht", "dein", "rei\u00b7zend", "Wa\u00b7scher\u00b7madl", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "PPOSAT", "ADJD", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.14": {"text": "Wenn von meinem Schneidermadl ich erz\u00e4hlte", "tokens": ["Wenn", "von", "mei\u00b7nem", "Schnei\u00b7der\u00b7madl", "ich", "er\u00b7z\u00e4hl\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "\u2013 Denk an das \u00bbGer\u00fcmpfe\u00ab edler Wackernasen:", "tokens": ["\u2013", "Denk", "an", "das", "\u00bb", "Ge\u00b7r\u00fcmp\u00b7fe", "\u00ab", "ed\u00b7ler", "Wa\u00b7cker\u00b7na\u00b7sen", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "APPR", "ART", "$(", "NN", "$(", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "\u00bbwaschermadel, Schneidermadel: Die Bekanntschaft\u00ab \u2013", "tokens": ["\u00bb", "wa\u00b7scher\u00b7ma\u00b7del", ",", "Schnei\u00b7der\u00b7ma\u00b7del", ":", "Die", "Be\u00b7kannt\u00b7schaft", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "$.", "ART", "NN", "$(", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.17": {"text": "Wenn von meinem Schneidermadl ich erz\u00e4hlte,", "tokens": ["Wenn", "von", "mei\u00b7nem", "Schnei\u00b7der\u00b7madl", "ich", "er\u00b7z\u00e4hl\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Die, nicht anders ging's derweil, mir immer wieder", "tokens": ["Die", ",", "nicht", "an\u00b7ders", "ging's", "der\u00b7weil", ",", "mir", "im\u00b7mer", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "$,", "PTKNEG", "ADV", "VVFIN", "ADV", "$,", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.19": {"text": "Stoffe brachte, R\u00f6cke, Hosen, Westen holte.", "tokens": ["Stof\u00b7fe", "brach\u00b7te", ",", "R\u00f6\u00b7cke", ",", "Ho\u00b7sen", ",", "Wes\u00b7ten", "hol\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "$,", "NN", "$,", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.20": {"text": "War nichts mehr zum Flicken vorr\u00e4tig im Schranke,", "tokens": ["War", "nichts", "mehr", "zum", "Fli\u00b7cken", "vor\u00b7r\u00e4\u00b7tig", "im", "Schran\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "APPRART", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.21": {"text": "Trennten N\u00e4hte wir, zerrissen Unterfutter.", "tokens": ["Trenn\u00b7ten", "N\u00e4h\u00b7te", "wir", ",", "zer\u00b7ris\u00b7sen", "Un\u00b7ter\u00b7fut\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.22": {"text": "Die mich mit den sechszehn Jahren hurtig k\u00fc\u00dfte,", "tokens": ["Die", "mich", "mit", "den", "sechs\u00b7zehn", "Jah\u00b7ren", "hur\u00b7tig", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "CARD", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.23": {"text": "K\u00fc\u00dfte, bis die wenigen Minuten schwanden.", "tokens": ["K\u00fc\u00df\u00b7te", ",", "bis", "die", "we\u00b7ni\u00b7gen", "Mi\u00b7nu\u00b7ten", "schwan\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.24": {"text": "Sp\u00e4ter ward es besser, durch des M\u00e4dchens Schlauheit,", "tokens": ["Sp\u00e4\u00b7ter", "ward", "es", "bes\u00b7ser", ",", "durch", "des", "M\u00e4d\u00b7chens", "Schlau\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.25": {"text": "Eine Stunde blieb sie, stundenlang und l\u00e4nger,", "tokens": ["Ei\u00b7ne", "Stun\u00b7de", "blieb", "sie", ",", "stun\u00b7den\u00b7lang", "und", "l\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.26": {"text": "Bis die erste hei\u00dfe Liebesnacht herankam.", "tokens": ["Bis", "die", "ers\u00b7te", "hei\u00b7\u00dfe", "Lie\u00b7bes\u00b7nacht", "her\u00b7an\u00b7kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.27": {"text": "Wie sie nun am andern Morgen \u00e4ngstlich fortschlich,", "tokens": ["Wie", "sie", "nun", "am", "an\u00b7dern", "Mor\u00b7gen", "\u00e4ngst\u00b7lich", "fort\u00b7schlich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPRART", "ADJA", "NN", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.28": {"text": "Warf sie ungeschickt vom Teller ihrer Rechten,", "tokens": ["Warf", "sie", "un\u00b7ge\u00b7schickt", "vom", "Tel\u00b7ler", "ih\u00b7rer", "Rech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.29": {"text": "Ihre Finger spreizend, mir ihr letztes Gr\u00fc\u00dfen:", "tokens": ["Ih\u00b7re", "Fin\u00b7ger", "sprei\u00b7zend", ",", "mir", "ihr", "letz\u00b7tes", "Gr\u00fc\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.30": {"text": "R\u00fchrend war es mir, wie dir, dem ich's vertraute.", "tokens": ["R\u00fch\u00b7rend", "war", "es", "mir", ",", "wie", "dir", ",", "dem", "ich's", "ver\u00b7trau\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PPER", "$,", "PWAV", "PPER", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.31": {"text": "Saugend war ihr Ku\u00df, ein wenig unanmutig,", "tokens": ["Sau\u00b7gend", "war", "ihr", "Ku\u00df", ",", "ein", "we\u00b7nig", "un\u00b7an\u00b7mu\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "NN", "$,", "ART", "PIS", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.32": {"text": "Ganz, als s\u00f6ge noch sie an der Mutter Br\u00fcsten;", "tokens": ["Ganz", ",", "als", "s\u00f6\u00b7ge", "noch", "sie", "an", "der", "Mut\u00b7ter", "Br\u00fcs\u00b7ten", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "NN", "ADV", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.33": {"text": "Doch Natur, Natur, jungwilde Ungez\u00e4hmtheit.", "tokens": ["Doch", "Na\u00b7tur", ",", "Na\u00b7tur", ",", "jung\u00b7wil\u00b7de", "Un\u00b7ge\u00b7z\u00e4hmt\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.11": {"line.1": {"text": "Denkst du noch an unser kleines Abenteuer", "tokens": ["Denkst", "du", "noch", "an", "un\u00b7ser", "klei\u00b7nes", "A\u00b7bent\u00b7eu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "\u2013 Cenz und Loni nannten sich die h\u00fcbschen Fr\u00e4tzchen \u2013,", "tokens": ["\u2013", "Cenz", "und", "Lo\u00b7ni", "nann\u00b7ten", "sich", "die", "h\u00fcb\u00b7schen", "Fr\u00e4tz\u00b7chen", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "KON", "NE", "VVFIN", "PRF", "ART", "ADJA", "NN", "$(", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Das Boccaz zum Vater h\u00e4tte haben k\u00f6nnen:", "tokens": ["Das", "Boc\u00b7caz", "zum", "Va\u00b7ter", "h\u00e4t\u00b7te", "ha\u00b7ben", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "VAINF", "VMFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Durch gemeinsam ausgef\u00fchrte kleine Fahrten", "tokens": ["Durch", "ge\u00b7mein\u00b7sam", "aus\u00b7ge\u00b7f\u00fchr\u00b7te", "klei\u00b7ne", "Fahr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Waren n\u00e4her wir zu Viert bekannt geworden.", "tokens": ["Wa\u00b7ren", "n\u00e4\u00b7her", "wir", "zu", "Viert", "be\u00b7kannt", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "APPR", "CARD", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Als wir eine Wette machten auf die Treue", "tokens": ["Als", "wir", "ei\u00b7ne", "Wet\u00b7te", "mach\u00b7ten", "auf", "die", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Unsrer Sch\u00e4tzchen, und zur gleichbestimmten Stunde", "tokens": ["Uns\u00b7rer", "Sch\u00e4tz\u00b7chen", ",", "und", "zur", "gleich\u00b7bes\u00b7timm\u00b7ten", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Jede an den andern sandten nach Gew\u00fcnschtem,", "tokens": ["Je\u00b7de", "an", "den", "an\u00b7dern", "sand\u00b7ten", "nach", "Ge\u00b7w\u00fcnschtem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "ART", "ADJA", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Wie uns dann nach einigem Gesichterschneiden", "tokens": ["Wie", "uns", "dann", "nach", "ei\u00b7ni\u00b7gem", "Ge\u00b7sich\u00b7ter\u00b7schnei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.10": {"text": "\u2013 Zuckten nicht sekundenlang zwei durstige Dolche \u2013,", "tokens": ["\u2013", "Zuck\u00b7ten", "nicht", "se\u00b7kun\u00b7den\u00b7lang", "zwei", "durs\u00b7ti\u00b7ge", "Dol\u00b7che", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "PTKNEG", "VVFIN", "CARD", "ADJA", "NN", "$(", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.11": {"text": "Da wir uns das Wort gegeben, wahr zu sprechen,", "tokens": ["Da", "wir", "uns", "das", "Wort", "ge\u00b7ge\u00b7ben", ",", "wahr", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "VVPP", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.12": {"text": "Ein nicht enden wollendes Gel\u00e4chter sch\u00fcttert.", "tokens": ["Ein", "nicht", "en\u00b7den", "wol\u00b7len\u00b7des", "Ge\u00b7l\u00e4ch\u00b7ter", "sch\u00fct\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "VVINF", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "L\u00fcstern nach verbotnem Speck ist jedes M\u00e4uschen.", "tokens": ["L\u00fcs\u00b7tern", "nach", "ver\u00b7bot\u00b7nem", "Speck", "ist", "je\u00b7des", "M\u00e4u\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "Spricht nicht irgendwo ein alter Lebensk\u00fcnstler,", "tokens": ["Spricht", "nicht", "ir\u00b7gend\u00b7wo", "ein", "al\u00b7ter", "Le\u00b7bens\u00b7k\u00fcnst\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Da\u00df erg\u00f6tzlich sei der Wechsel in der Liebe?", "tokens": ["Da\u00df", "er\u00b7g\u00f6tz\u00b7lich", "sei", "der", "Wech\u00b7sel", "in", "der", "Lie\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Apage!", "tokens": ["A\u00b7pa\u00b7ge", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.17": {"text": "Doch was ich sagen wollte, Lieber:", "tokens": ["Doch", "was", "ich", "sa\u00b7gen", "woll\u00b7te", ",", "Lie\u00b7ber", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Blieb dir jener Winterabend im Ged\u00e4chtnis?:", "tokens": ["Blieb", "dir", "je\u00b7ner", "Win\u00b7ter\u00b7a\u00b7bend", "im", "Ge\u00b7d\u00e4cht\u00b7nis", "?", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "APPRART", "NN", "$.", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.19": {"text": "Beim Burgurder, Nuits, bei deinem Lieblingsweine,", "tokens": ["Beim", "Bur\u00b7gur\u00b7der", ",", "Nuits", ",", "bei", "dei\u00b7nem", "Lieb\u00b7lings\u00b7wei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Sa\u00dfen wir schon lange. Alles war gegangen.", "tokens": ["Sa\u00b7\u00dfen", "wir", "schon", "lan\u00b7ge", ".", "Al\u00b7les", "war", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$.", "PIS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.21": {"text": "Unter Aufsicht des Ratskellerk\u00fcfermeisters", "tokens": ["Un\u00b7ter", "Auf\u00b7sicht", "des", "Rats\u00b7kel\u00b7ler\u00b7k\u00fc\u00b7fer\u00b7meis\u00b7ters"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.22": {"text": "War der Zug, je zwei auf zwei, der Kellnerinnen", "tokens": ["War", "der", "Zug", ",", "je", "zwei", "auf", "zwei", ",", "der", "Kell\u00b7ne\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "ADV", "CARD", "APPR", "CARD", "$,", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.23": {"text": "In das Nebenhaus zum Schlafen abgezogen.", "tokens": ["In", "das", "Ne\u00b7ben\u00b7haus", "zum", "Schla\u00b7fen", "ab\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.24": {"text": "Nur ein Piccolo, die einzige Bedienung,", "tokens": ["Nur", "ein", "Pic\u00b7co\u00b7lo", ",", "die", "ein\u00b7zi\u00b7ge", "Be\u00b7die\u00b7nung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Lag, entschlummert, \u00fcber einer gro\u00dfen Zeitung,", "tokens": ["Lag", ",", "ent\u00b7schlum\u00b7mert", ",", "\u00fc\u00b7ber", "ei\u00b7ner", "gro\u00b7\u00dfen", "Zei\u00b7tung", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.26": {"text": "Und ein Blumenm\u00e4dchen schlief an einer S\u00e4ule,", "tokens": ["Und", "ein", "Blu\u00b7men\u00b7m\u00e4d\u00b7chen", "schlief", "an", "ei\u00b7ner", "S\u00e4u\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.27": {"text": "Blassen Antlitzes, das wunderbar sich abhob", "tokens": ["Blas\u00b7sen", "Ant\u00b7lit\u00b7zes", ",", "das", "wun\u00b7der\u00b7bar", "sich", "ab\u00b7hob"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADJD", "PRF", "VVFIN"], "meter": "+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.28": {"text": "Aus den dunkelroten Rosen, die dem Korbe", "tokens": ["Aus", "den", "dun\u00b7kel\u00b7ro\u00b7ten", "Ro\u00b7sen", ",", "die", "dem", "Kor\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.29": {"text": "Sich entsch\u00fcttet hatten um die m\u00fcden Schl\u00e4fen.", "tokens": ["Sich", "ent\u00b7sch\u00fct\u00b7tet", "hat\u00b7ten", "um", "die", "m\u00fc\u00b7den", "Schl\u00e4\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "VAFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.30": {"text": "Pl\u00f6tzlich durch die mittern\u00e4chtige Stille klang ein", "tokens": ["Pl\u00f6tz\u00b7lich", "durch", "die", "mit\u00b7ter\u00b7n\u00e4ch\u00b7ti\u00b7ge", "Stil\u00b7le", "klang", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "VVFIN", "ART"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.31": {"text": "Dumpfes, mattes Rauschen; und ein uralt M\u00e4nnchen", "tokens": ["Dum\u00b7pfes", ",", "mat\u00b7tes", "Rau\u00b7schen", ";", "und", "ein", "ur\u00b7alt", "M\u00e4nn\u00b7chen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADJA", "NN", "$.", "KON", "ART", "NN", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.32": {"text": "Stand an unserm Tische, sich vor uns verneigend:", "tokens": ["Stand", "an", "un\u00b7serm", "Ti\u00b7sche", ",", "sich", "vor", "uns", "ver\u00b7nei\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,", "PRF", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.33": {"text": "\u00bbihr da, Dichterlinge, thut mir den Gefallen,", "tokens": ["\u00bb", "ihr", "da", ",", "Dich\u00b7ter\u00b7lin\u00b7ge", ",", "thut", "mir", "den", "Ge\u00b7fal\u00b7len", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.34": {"text": "Sagt mir, weshalb redet ihr so unabl\u00e4ssig", "tokens": ["Sagt", "mir", ",", "we\u00b7shalb", "re\u00b7det", "ihr", "so", "un\u00b7ab\u00b7l\u00e4s\u00b7sig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.35": {"text": "Naseweis von unsrer guten deutschen Dichtung?", "tokens": ["Na\u00b7se\u00b7weis", "von", "uns\u00b7rer", "gu\u00b7ten", "deut\u00b7schen", "Dich\u00b7tung", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.36": {"text": "Besser w\u00e4r's, statt immerfort zu raisonnieren,", "tokens": ["Bes\u00b7ser", "w\u00e4r's", ",", "statt", "im\u00b7mer\u00b7fort", "zu", "rai\u00b7son\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "KOUI", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.37": {"text": "Wenn ihre eure Kritzeleien so dem Landsmann", "tokens": ["Wenn", "ih\u00b7re", "eu\u00b7re", "Krit\u00b7ze\u00b7lei\u00b7en", "so", "dem", "Lands\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "PPOSAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Dem gewohnten Lotternachmittagsschlafsopha", "tokens": ["Dem", "ge\u00b7wohn\u00b7ten", "Lot\u00b7ter\u00b7nach\u00b7mit\u00b7tags\u00b7schlaf\u00b7so\u00b7pha"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.39": {"text": "N\u00e4her r\u00fccktet, da\u00df er's m\u00fchelos verdaute.", "tokens": ["N\u00e4\u00b7her", "r\u00fcck\u00b7tet", ",", "da\u00df", "er's", "m\u00fc\u00b7he\u00b7los", "ver\u00b7dau\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.40": {"text": "Und es w\u00fcrden euch die Portemonnaies bald voll sein,", "tokens": ["Und", "es", "w\u00fcr\u00b7den", "euch", "die", "Por\u00b7te\u00b7mon\u00b7nai\u00b7es", "bald", "voll", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VAINF", "$,"], "meter": "--+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.41": {"text": "K\u00f6nntet ihr euch endlich doch entschlie\u00dfen: einzig", "tokens": ["K\u00f6nn\u00b7tet", "ihr", "euch", "end\u00b7lich", "doch", "ent\u00b7schlie\u00b7\u00dfen", ":", "ein\u00b7zig"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$.", "ADJD"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.42": {"text": "Eure Feder einzutauchen dieser Weise,", "tokens": ["Eu\u00b7re", "Fe\u00b7der", "ein\u00b7zu\u00b7tau\u00b7chen", "die\u00b7ser", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVIZU", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.43": {"text": "Da\u00df sie tr\u00e4uft von faden Honigseimgeschichten,", "tokens": ["Da\u00df", "sie", "tr\u00e4uft", "von", "fa\u00b7den", "Ho\u00b7ni\u00b7gseim\u00b7ge\u00b7schich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.44": {"text": "F\u00fcr die deutschen Bilderfibeln eingerichtet.\u00ab", "tokens": ["F\u00fcr", "die", "deut\u00b7schen", "Bil\u00b7der\u00b7fi\u00b7beln", "ein\u00b7ge\u00b7rich\u00b7tet", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.45": {"text": "W\u00fctend sprangst du auf, ich hielt dich fest am Rockscho\u00df,", "tokens": ["W\u00fc\u00b7tend", "sprangst", "du", "auf", ",", "ich", "hielt", "dich", "fest", "am", "Rock\u00b7scho\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PRF", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.46": {"text": "Sonst, wahrhaftig, h\u00e4ttest du dem armen M\u00e4nnchen", "tokens": ["Sonst", ",", "wahr\u00b7haf\u00b7tig", ",", "h\u00e4t\u00b7test", "du", "dem", "ar\u00b7men", "M\u00e4nn\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADJD", "$,", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.47": {"text": "Sicher das Genick gebrochen, und du flammtest:", "tokens": ["Si\u00b7cher", "das", "Ge\u00b7nick", "ge\u00b7bro\u00b7chen", ",", "und", "du", "flamm\u00b7test", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.48": {"text": "\u00bbfort, Versucher, fort mit deinem Klingebeutel,", "tokens": ["\u00bb", "fort", ",", "Ver\u00b7su\u00b7cher", ",", "fort", "mit", "dei\u00b7nem", "Klin\u00b7ge\u00b7beu\u00b7tel", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "NN", "$,", "PTKVZ", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.49": {"text": "Troll' dich in dein Nichts zur\u00fcck, verdammter H\u00e4mmling!", "tokens": ["Troll'", "dich", "in", "dein", "Nichts", "zu\u00b7r\u00fcck", ",", "ver\u00b7damm\u00b7ter", "H\u00e4mm\u00b7ling", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.50": {"text": "Schreiben wir, so schreiben uns wir und den wenigen", "tokens": ["Schrei\u00b7ben", "wir", ",", "so", "schrei\u00b7ben", "uns", "wir", "und", "den", "we\u00b7ni\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PPER", "KON", "ART", "PIAT"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.51": {"text": "Gleichgesinnten, freiheitsfr\u00f6hlichstolzen Herzen.", "tokens": ["Gleich\u00b7ge\u00b7sinn\u00b7ten", ",", "frei\u00b7heits\u00b7fr\u00f6h\u00b7lich\u00b7stol\u00b7zen", "Her\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.52": {"text": "Unaussprechlich schnuppe ist f\u00fcr uns der Leser.\u00ab", "tokens": ["Un\u00b7aus\u00b7sprech\u00b7lich", "schnup\u00b7pe", "ist", "f\u00fcr", "uns", "der", "Le\u00b7ser", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "VAFIN", "APPR", "PPER", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.12": {"line.1": {"text": "Alles ist mir eben wieder eingefallen,", "tokens": ["Al\u00b7les", "ist", "mir", "e\u00b7ben", "wie\u00b7der", "ein\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Als ich heute deinen Brief in H\u00e4nden hatte,", "tokens": ["Als", "ich", "heu\u00b7te", "dei\u00b7nen", "Brief", "in", "H\u00e4n\u00b7den", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Dem ich schreckensvoll, doch nur im ersten Teile,", "tokens": ["Dem", "ich", "schre\u00b7ckens\u00b7voll", ",", "doch", "nur", "im", "ers\u00b7ten", "Tei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "$,", "ADV", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Eine Kursabweichung zu entnehmen glaubte,", "tokens": ["Ei\u00b7ne", "Kur\u00b7sab\u00b7wei\u00b7chung", "zu", "ent\u00b7neh\u00b7men", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Die mir s\u00e4uerlich und muff verraten w\u00fcrde,", "tokens": ["Die", "mir", "s\u00e4u\u00b7er\u00b7lich", "und", "muff", "ver\u00b7ra\u00b7ten", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "KON", "VMFIN", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Da\u00df du dich verlobt mit Fr\u00e4ulein W\u00fcrdengel,", "tokens": ["Da\u00df", "du", "dich", "ver\u00b7lobt", "mit", "Fr\u00e4u\u00b7lein", "W\u00fcr\u00b7den\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Tochter Seiner Excellenz, des Herrn Philisters.", "tokens": ["Toch\u00b7ter", "Sei\u00b7ner", "Ex\u00b7cel\u00b7lenz", ",", "des", "Herrn", "Phi\u00b7lis\u00b7ters", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "ART", "NN", "NE", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}}}}