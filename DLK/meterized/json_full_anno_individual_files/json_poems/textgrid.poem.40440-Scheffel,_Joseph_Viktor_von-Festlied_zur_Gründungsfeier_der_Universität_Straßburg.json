{"textgrid.poem.40440": {"metadata": {"author": {"name": "Scheffel, Joseph Viktor von", "birth": "N.A.", "death": "N.A."}, "title": "Festlied zur Gr\u00fcndungsfeier der Universit\u00e4t Stra\u00dfburg", "genre": "verse", "period": "N.A.", "pub_year": 1856, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Heut trennt unser minniglich Sehnen", "tokens": ["Heut", "trennt", "un\u00b7ser", "min\u00b7nig\u00b7lich", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Kein deutscher, kein gallischer Rhein,", "tokens": ["Kein", "deut\u00b7scher", ",", "kein", "gal\u00b7li\u00b7scher", "Rhein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "$,", "PIAT", "ADJA", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Wir ziehen gleich Lohengrins Schw\u00e4nen", "tokens": ["Wir", "zie\u00b7hen", "gleich", "Lo\u00b7hen\u00b7grins", "Schw\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NE", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Maifr\u00f6hlich in \u00bbStrazzeburc\u00ab ein;", "tokens": ["Mai\u00b7fr\u00f6h\u00b7lich", "in", "\u00bb", "Straz\u00b7ze\u00b7burc", "\u00ab", "ein", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "APPR", "$(", "NE", "$(", "PTKVZ", "$."], "meter": "++--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Der Hochschulen jungj\u00fcngste Schwester", "tokens": ["Der", "Hoch\u00b7schu\u00b7len", "jung\u00b7j\u00fcngs\u00b7te", "Schwes\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Sei als br\u00e4utliches Ziel uns ersehn:", "tokens": ["Sei", "als", "br\u00e4ut\u00b7li\u00b7ches", "Ziel", "uns", "er\u00b7sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Sie steht noch im ersten Semester,", "tokens": ["Sie", "steht", "noch", "im", "ers\u00b7ten", "Se\u00b7mes\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Drum ist sie auch jung noch und sch\u00f6n.", "tokens": ["Drum", "ist", "sie", "auch", "jung", "noch", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADJD", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wo Gottfried den Tristan gesungen,", "tokens": ["Wo", "Gott\u00b7fried", "den", "Tris\u00b7tan", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wo Erwin sein M\u00fcnster erbaut,", "tokens": ["Wo", "Er\u00b7win", "sein", "M\u00fcns\u00b7ter", "er\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PPOSAT", "NN", "VVPP", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wo Gutenbergs Kunst sich erschwungen,", "tokens": ["Wo", "Gu\u00b7ten\u00b7bergs", "Kunst", "sich", "er\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "PRF", "VVPP", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da ist uns der Boden vertraut.", "tokens": ["Da", "ist", "uns", "der", "Bo\u00b7den", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Was sonst noch zu Argentoratum", "tokens": ["Was", "sonst", "noch", "zu", "Ar\u00b7gen\u00b7to\u00b7ra\u00b7tum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "ADV", "APPR", "NE"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Einst R\u00f6mer \u2013 und andre gemacht,", "tokens": ["Einst", "R\u00f6\u00b7mer", "\u2013", "und", "and\u00b7re", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$(", "KON", "PIS", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Dem sei als entschwundenem Fatum", "tokens": ["Dem", "sei", "als", "ent\u00b7schwun\u00b7de\u00b7nem", "Fa\u00b7tum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "KOKOM", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ein s\u00fchnend Glas Lethe gebracht!", "tokens": ["Ein", "s\u00fch\u00b7nend", "Glas", "Le\u00b7the", "ge\u00b7bracht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbes konnt' ja nicht immer so bleiben", "tokens": ["\u00bb", "es", "konnt'", "ja", "nicht", "im\u00b7mer", "so", "blei\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PTKNEG", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier unter dem wechselnden Mond\u00ab,", "tokens": ["Hier", "un\u00b7ter", "dem", "wech\u00b7seln\u00b7den", "Mond", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$(", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "So w\u00fcrde Sch\u00f6pflinus jetzt schreiben,", "tokens": ["So", "w\u00fcr\u00b7de", "Sch\u00f6pf\u00b7li\u00b7nus", "jetzt", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der als Jubelgreis einst hier gewohnt;", "tokens": ["Der", "als", "Ju\u00b7bel\u00b7greis", "einst", "hier", "ge\u00b7wohnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOUS", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Doch wenn unter pflegenden H\u00e4nden", "tokens": ["Doch", "wenn", "un\u00b7ter", "pfle\u00b7gen\u00b7den", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Die Wissenschaft stolz erst floriert,", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "stolz", "erst", "flo\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wird durch die deutschen Studenten", "tokens": ["So", "wird", "durch", "die", "deut\u00b7schen", "Stu\u00b7den\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Alsatia \u00bbneu illustriert\u00ab.", "tokens": ["Al\u00b7sa\u00b7tia", "\u00bb", "neu", "il\u00b7lust\u00b7riert", "\u00ab", "."], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["FM.la", "$(", "ADJD", "VVFIN", "$(", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.4": {"line.1": {"text": "Was schaust du noch trauernd nach Westen,", "tokens": ["Was", "schaust", "du", "noch", "trau\u00b7ernd", "nach", "Wes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Els\u00e4ssischer Landsmann und Freund?", "tokens": ["El\u00b7s\u00e4s\u00b7si\u00b7scher", "Lands\u00b7mann", "und", "Freund", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Du z\u00e4hlst ja schon heut zu den Besten,", "tokens": ["Du", "z\u00e4hlst", "ja", "schon", "heut", "zu", "den", "Bes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Die unsre Matrikel vereint.", "tokens": ["Die", "uns\u00b7re", "Mat\u00b7ri\u00b7kel", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bedenk', was die Reben all' wollen", "tokens": ["Be\u00b7denk'", ",", "was", "die", "Re\u00b7ben", "all'", "wol\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PRELS", "ART", "NN", "PIS", "VMFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Von Wolxheim hinauf bis nach Thann:", "tokens": ["Von", "Wolx\u00b7heim", "hin\u00b7auf", "bis", "nach", "Thann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "ADV", "APPR", "NE", "$."], "meter": "-++-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Der reift zum Schmollieren heran!", "tokens": ["Der", "reift", "zum", "Schmol\u00b7lie\u00b7ren", "he\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wir gr\u00fcnden ein kerngesund Wesen", "tokens": ["Wir", "gr\u00fcn\u00b7den", "ein", "kern\u00b7ge\u00b7sund", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und scheiden erst, wenn uns als Trost", "tokens": ["Und", "schei\u00b7den", "erst", ",", "wenn", "uns", "als", "Trost"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das s\u00e4mtliche Moos der Vogesen", "tokens": ["Das", "s\u00e4mt\u00b7li\u00b7che", "Moos", "der", "Vo\u00b7ge\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die eigenen H\u00e4upter bemoost.", "tokens": ["Die", "ei\u00b7ge\u00b7nen", "H\u00e4up\u00b7ter", "be\u00b7moost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Sto\u00dft an drum: Neustra\u00dfburg soll leben,", "tokens": ["Sto\u00dft", "an", "drum", ":", "Neus\u00b7tra\u00df\u00b7burg", "soll", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PAV", "$.", "NE", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Soll wachsen und kraftvoll gedeihn,", "tokens": ["Soll", "wach\u00b7sen", "und", "kraft\u00b7voll", "ge\u00b7deihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "ADJD", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Heut trennt unser minniglich Sehnen", "tokens": ["Heut", "trennt", "un\u00b7ser", "min\u00b7nig\u00b7lich", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Kein deutscher, kein gallischer Rhein,", "tokens": ["Kein", "deut\u00b7scher", ",", "kein", "gal\u00b7li\u00b7scher", "Rhein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "$,", "PIAT", "ADJA", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Wir ziehen gleich Lohengrins Schw\u00e4nen", "tokens": ["Wir", "zie\u00b7hen", "gleich", "Lo\u00b7hen\u00b7grins", "Schw\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NE", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Maifr\u00f6hlich in \u00bbStrazzeburc\u00ab ein;", "tokens": ["Mai\u00b7fr\u00f6h\u00b7lich", "in", "\u00bb", "Straz\u00b7ze\u00b7burc", "\u00ab", "ein", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "APPR", "$(", "NE", "$(", "PTKVZ", "$."], "meter": "++--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Der Hochschulen jungj\u00fcngste Schwester", "tokens": ["Der", "Hoch\u00b7schu\u00b7len", "jung\u00b7j\u00fcngs\u00b7te", "Schwes\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Sei als br\u00e4utliches Ziel uns ersehn:", "tokens": ["Sei", "als", "br\u00e4ut\u00b7li\u00b7ches", "Ziel", "uns", "er\u00b7sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Sie steht noch im ersten Semester,", "tokens": ["Sie", "steht", "noch", "im", "ers\u00b7ten", "Se\u00b7mes\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Drum ist sie auch jung noch und sch\u00f6n.", "tokens": ["Drum", "ist", "sie", "auch", "jung", "noch", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADJD", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wo Gottfried den Tristan gesungen,", "tokens": ["Wo", "Gott\u00b7fried", "den", "Tris\u00b7tan", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wo Erwin sein M\u00fcnster erbaut,", "tokens": ["Wo", "Er\u00b7win", "sein", "M\u00fcns\u00b7ter", "er\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PPOSAT", "NN", "VVPP", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wo Gutenbergs Kunst sich erschwungen,", "tokens": ["Wo", "Gu\u00b7ten\u00b7bergs", "Kunst", "sich", "er\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "PRF", "VVPP", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da ist uns der Boden vertraut.", "tokens": ["Da", "ist", "uns", "der", "Bo\u00b7den", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Was sonst noch zu Argentoratum", "tokens": ["Was", "sonst", "noch", "zu", "Ar\u00b7gen\u00b7to\u00b7ra\u00b7tum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "ADV", "APPR", "NE"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Einst R\u00f6mer \u2013 und andre gemacht,", "tokens": ["Einst", "R\u00f6\u00b7mer", "\u2013", "und", "and\u00b7re", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$(", "KON", "PIS", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Dem sei als entschwundenem Fatum", "tokens": ["Dem", "sei", "als", "ent\u00b7schwun\u00b7de\u00b7nem", "Fa\u00b7tum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "KOKOM", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ein s\u00fchnend Glas Lethe gebracht!", "tokens": ["Ein", "s\u00fch\u00b7nend", "Glas", "Le\u00b7the", "ge\u00b7bracht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbes konnt' ja nicht immer so bleiben", "tokens": ["\u00bb", "es", "konnt'", "ja", "nicht", "im\u00b7mer", "so", "blei\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PTKNEG", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier unter dem wechselnden Mond\u00ab,", "tokens": ["Hier", "un\u00b7ter", "dem", "wech\u00b7seln\u00b7den", "Mond", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$(", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "So w\u00fcrde Sch\u00f6pflinus jetzt schreiben,", "tokens": ["So", "w\u00fcr\u00b7de", "Sch\u00f6pf\u00b7li\u00b7nus", "jetzt", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der als Jubelgreis einst hier gewohnt;", "tokens": ["Der", "als", "Ju\u00b7bel\u00b7greis", "einst", "hier", "ge\u00b7wohnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOUS", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Doch wenn unter pflegenden H\u00e4nden", "tokens": ["Doch", "wenn", "un\u00b7ter", "pfle\u00b7gen\u00b7den", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Die Wissenschaft stolz erst floriert,", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "stolz", "erst", "flo\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wird durch die deutschen Studenten", "tokens": ["So", "wird", "durch", "die", "deut\u00b7schen", "Stu\u00b7den\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Alsatia \u00bbneu illustriert\u00ab.", "tokens": ["Al\u00b7sa\u00b7tia", "\u00bb", "neu", "il\u00b7lust\u00b7riert", "\u00ab", "."], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["FM.la", "$(", "ADJD", "VVFIN", "$(", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.9": {"line.1": {"text": "Was schaust du noch trauernd nach Westen,", "tokens": ["Was", "schaust", "du", "noch", "trau\u00b7ernd", "nach", "Wes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Els\u00e4ssischer Landsmann und Freund?", "tokens": ["El\u00b7s\u00e4s\u00b7si\u00b7scher", "Lands\u00b7mann", "und", "Freund", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Du z\u00e4hlst ja schon heut zu den Besten,", "tokens": ["Du", "z\u00e4hlst", "ja", "schon", "heut", "zu", "den", "Bes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Die unsre Matrikel vereint.", "tokens": ["Die", "uns\u00b7re", "Mat\u00b7ri\u00b7kel", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bedenk', was die Reben all' wollen", "tokens": ["Be\u00b7denk'", ",", "was", "die", "Re\u00b7ben", "all'", "wol\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PRELS", "ART", "NN", "PIS", "VMFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Von Wolxheim hinauf bis nach Thann:", "tokens": ["Von", "Wolx\u00b7heim", "hin\u00b7auf", "bis", "nach", "Thann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "ADV", "APPR", "NE", "$."], "meter": "-++-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Der reift zum Schmollieren heran!", "tokens": ["Der", "reift", "zum", "Schmol\u00b7lie\u00b7ren", "he\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wir gr\u00fcnden ein kerngesund Wesen", "tokens": ["Wir", "gr\u00fcn\u00b7den", "ein", "kern\u00b7ge\u00b7sund", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und scheiden erst, wenn uns als Trost", "tokens": ["Und", "schei\u00b7den", "erst", ",", "wenn", "uns", "als", "Trost"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das s\u00e4mtliche Moos der Vogesen", "tokens": ["Das", "s\u00e4mt\u00b7li\u00b7che", "Moos", "der", "Vo\u00b7ge\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die eigenen H\u00e4upter bemoost.", "tokens": ["Die", "ei\u00b7ge\u00b7nen", "H\u00e4up\u00b7ter", "be\u00b7moost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Sto\u00dft an drum: Neustra\u00dfburg soll leben,", "tokens": ["Sto\u00dft", "an", "drum", ":", "Neus\u00b7tra\u00df\u00b7burg", "soll", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PAV", "$.", "NE", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Soll wachsen und kraftvoll gedeihn,", "tokens": ["Soll", "wach\u00b7sen", "und", "kraft\u00b7voll", "ge\u00b7deihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "ADJD", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}}}}