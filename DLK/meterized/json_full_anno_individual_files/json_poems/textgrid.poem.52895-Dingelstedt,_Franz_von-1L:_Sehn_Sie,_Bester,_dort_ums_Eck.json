{"textgrid.poem.52895": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sehn Sie, Bester, dort ums Eck", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sehn Sie, Bester, dort ums Eck", "tokens": ["Sehn", "Sie", ",", "Bes\u00b7ter", ",", "dort", "ums", "Eck"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jenen pr\u00e4chtgen Wagen rollen?", "tokens": ["Je\u00b7nen", "pr\u00e4cht\u00b7gen", "Wa\u00b7gen", "rol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer das war? \u2013 Nur keinen Schreck,", "tokens": ["Wer", "das", "war", "?", "\u2013", "Nur", "kei\u00b7nen", "Schreck", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VAFIN", "$.", "$(", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn Sie's wirklich wissen wollen!", "tokens": ["Wenn", "Sie's", "wirk\u00b7lich", "wis\u00b7sen", "wol\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Das war ER \u2013 Ich nenn' ihn nicht,", "tokens": ["Das", "war", "Er", "\u2013", "Ich", "nenn'", "ihn", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Deutschland wei\u00df schon, wen ich meine,", "tokens": ["Deutschland", "wei\u00df", "schon", ",", "wen", "ich", "mei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Unser Hort und unser Licht,", "tokens": ["Un\u00b7ser", "Hort", "und", "un\u00b7ser", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er, der Einzle, Einz'ge, Eine!", "tokens": ["Er", ",", "der", "Einz\u00b7le", ",", "Einz'\u00b7ge", ",", "Ei\u00b7ne", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "$,", "NN", "$,", "ART", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Glauben nicht, was so ein Mann", "tokens": ["Glau\u00b7ben", "nicht", ",", "was", "so", "ein", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles unsrer guten Stadt frommt,", "tokens": ["Al\u00b7les", "uns\u00b7rer", "gu\u00b7ten", "Stadt", "frommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was er will und was er kann,", "tokens": ["Was", "er", "will", "und", "was", "er", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "KON", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ganz vornehmlich, wenn's ins Blatt kommt.", "tokens": ["Ganz", "vor\u00b7nehm\u00b7lich", ",", "wenn's", "ins", "Blatt", "kommt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und wie er bei Jud' und Christ", "tokens": ["Und", "wie", "er", "bei", "Jud'", "und", "Christ"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "APPR", "NE", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "F\u00fcr jedwede fremde Not mild", "tokens": ["F\u00fcr", "jed\u00b7we\u00b7de", "frem\u00b7de", "Not", "mild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stets bereit zu helfen ist,", "tokens": ["Stets", "be\u00b7reit", "zu", "hel\u00b7fen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "PaTER PATRIAE, von Rothschild.", "tokens": ["Pa\u00b7TER", "PaT\u00b7RI\u00b7AE", ",", "von", "Roth\u00b7schild", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Ja, wie er ganz fein und fern", "tokens": ["Ja", ",", "wie", "er", "ganz", "fein", "und", "fern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PWAV", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Selbst im Gro\u00dfen f\u00fcr die Welt sorgt,", "tokens": ["Selbst", "im", "Gro\u00b7\u00dfen", "f\u00fcr", "die", "Welt", "sorgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil er kriegeslust'gen Herrn", "tokens": ["Weil", "er", "krie\u00b7ges\u00b7lust'\u00b7gen", "Herrn"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so gleich sein sch\u00f6nes Geld borgt.", "tokens": ["Nicht", "so", "gleich", "sein", "sch\u00f6\u00b7nes", "Geld", "borgt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ach! und die enorme Pracht", "tokens": ["Ach", "!", "und", "die", "en\u00b7or\u00b7me", "Pracht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seiner G\u00e4rten, Parks und Villen,", "tokens": ["Sei\u00b7ner", "G\u00e4r\u00b7ten", ",", "Parks", "und", "Vil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlafzimmer, nicht f\u00fcr die Nacht,", "tokens": ["Schlaf\u00b7zim\u00b7mer", ",", "nicht", "f\u00fcr", "die", "Nacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nur zum Sehn um Gotteswillen!", "tokens": ["Nur", "zum", "Sehn", "um", "Got\u00b7tes\u00b7wil\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Bilder unter schwarzem Flor,", "tokens": ["Bil\u00b7der", "un\u00b7ter", "schwar\u00b7zem", "Flor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses konserviert sie besser,", "tokens": ["Die\u00b7ses", "kon\u00b7ser\u00b7viert", "sie", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und an jedem Eisentor", "tokens": ["Und", "an", "je\u00b7dem", "Ei\u00b7sen\u00b7tor"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Drei gewicht'ge H\u00e4ngeschl\u00f6sser!", "tokens": ["Drei", "ge\u00b7wicht'\u00b7ge", "H\u00e4n\u00b7ge\u00b7schl\u00f6s\u00b7ser", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sehn Sie! Wieder dort ums Eck!", "tokens": ["Sehn", "Sie", "!", "Wie\u00b7der", "dort", "ums", "Eck", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Livree, der Staat von Federn,", "tokens": ["Die", "Liv\u00b7ree", ",", "der", "Staat", "von", "Fe\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Rappen mit 'nem wei\u00dfen Fleck,", "tokens": ["Rap\u00b7pen", "mit", "'nem", "wei\u00b7\u00dfen", "Fleck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Englisch all's bis zu den R\u00e4dern!", "tokens": ["Eng\u00b7lisch", "all's", "bis", "zu", "den", "R\u00e4\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Und dem Kutscher hat heut fr\u00fch", "tokens": ["Und", "dem", "Kut\u00b7scher", "hat", "heut", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Frau Baronin noch geraten:", "tokens": ["Frau", "Ba\u00b7ro\u00b7nin", "noch", "ge\u00b7ra\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Halt dich schepp, dann meinen sie,", "tokens": ["Halt", "dich", "schepp", ",", "dann", "mei\u00b7nen", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir sein von die Diplomaten.", "tokens": ["Wir", "sein", "von", "die", "Dip\u00b7lo\u00b7ma\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Sehn Sie, Bester, dort ums Eck", "tokens": ["Sehn", "Sie", ",", "Bes\u00b7ter", ",", "dort", "ums", "Eck"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jenen pr\u00e4chtgen Wagen rollen?", "tokens": ["Je\u00b7nen", "pr\u00e4cht\u00b7gen", "Wa\u00b7gen", "rol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer das war? \u2013 Nur keinen Schreck,", "tokens": ["Wer", "das", "war", "?", "\u2013", "Nur", "kei\u00b7nen", "Schreck", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VAFIN", "$.", "$(", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn Sie's wirklich wissen wollen!", "tokens": ["Wenn", "Sie's", "wirk\u00b7lich", "wis\u00b7sen", "wol\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Das war ER \u2013 Ich nenn' ihn nicht,", "tokens": ["Das", "war", "Er", "\u2013", "Ich", "nenn'", "ihn", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Deutschland wei\u00df schon, wen ich meine,", "tokens": ["Deutschland", "wei\u00df", "schon", ",", "wen", "ich", "mei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Unser Hort und unser Licht,", "tokens": ["Un\u00b7ser", "Hort", "und", "un\u00b7ser", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er, der Einzle, Einz'ge, Eine!", "tokens": ["Er", ",", "der", "Einz\u00b7le", ",", "Einz'\u00b7ge", ",", "Ei\u00b7ne", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "$,", "NN", "$,", "ART", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Glauben nicht, was so ein Mann", "tokens": ["Glau\u00b7ben", "nicht", ",", "was", "so", "ein", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles unsrer guten Stadt frommt,", "tokens": ["Al\u00b7les", "uns\u00b7rer", "gu\u00b7ten", "Stadt", "frommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was er will und was er kann,", "tokens": ["Was", "er", "will", "und", "was", "er", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "KON", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ganz vornehmlich, wenn's ins Blatt kommt.", "tokens": ["Ganz", "vor\u00b7nehm\u00b7lich", ",", "wenn's", "ins", "Blatt", "kommt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und wie er bei Jud' und Christ", "tokens": ["Und", "wie", "er", "bei", "Jud'", "und", "Christ"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "APPR", "NE", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "F\u00fcr jedwede fremde Not mild", "tokens": ["F\u00fcr", "jed\u00b7we\u00b7de", "frem\u00b7de", "Not", "mild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stets bereit zu helfen ist,", "tokens": ["Stets", "be\u00b7reit", "zu", "hel\u00b7fen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "PaTER PATRIAE, von Rothschild.", "tokens": ["Pa\u00b7TER", "PaT\u00b7RI\u00b7AE", ",", "von", "Roth\u00b7schild", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Ja, wie er ganz fein und fern", "tokens": ["Ja", ",", "wie", "er", "ganz", "fein", "und", "fern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PWAV", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Selbst im Gro\u00dfen f\u00fcr die Welt sorgt,", "tokens": ["Selbst", "im", "Gro\u00b7\u00dfen", "f\u00fcr", "die", "Welt", "sorgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil er kriegeslust'gen Herrn", "tokens": ["Weil", "er", "krie\u00b7ges\u00b7lust'\u00b7gen", "Herrn"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so gleich sein sch\u00f6nes Geld borgt.", "tokens": ["Nicht", "so", "gleich", "sein", "sch\u00f6\u00b7nes", "Geld", "borgt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Ach! und die enorme Pracht", "tokens": ["Ach", "!", "und", "die", "en\u00b7or\u00b7me", "Pracht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seiner G\u00e4rten, Parks und Villen,", "tokens": ["Sei\u00b7ner", "G\u00e4r\u00b7ten", ",", "Parks", "und", "Vil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlafzimmer, nicht f\u00fcr die Nacht,", "tokens": ["Schlaf\u00b7zim\u00b7mer", ",", "nicht", "f\u00fcr", "die", "Nacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nur zum Sehn um Gotteswillen!", "tokens": ["Nur", "zum", "Sehn", "um", "Got\u00b7tes\u00b7wil\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Bilder unter schwarzem Flor,", "tokens": ["Bil\u00b7der", "un\u00b7ter", "schwar\u00b7zem", "Flor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses konserviert sie besser,", "tokens": ["Die\u00b7ses", "kon\u00b7ser\u00b7viert", "sie", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und an jedem Eisentor", "tokens": ["Und", "an", "je\u00b7dem", "Ei\u00b7sen\u00b7tor"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Drei gewicht'ge H\u00e4ngeschl\u00f6sser!", "tokens": ["Drei", "ge\u00b7wicht'\u00b7ge", "H\u00e4n\u00b7ge\u00b7schl\u00f6s\u00b7ser", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Sehn Sie! Wieder dort ums Eck!", "tokens": ["Sehn", "Sie", "!", "Wie\u00b7der", "dort", "ums", "Eck", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Livree, der Staat von Federn,", "tokens": ["Die", "Liv\u00b7ree", ",", "der", "Staat", "von", "Fe\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Rappen mit 'nem wei\u00dfen Fleck,", "tokens": ["Rap\u00b7pen", "mit", "'nem", "wei\u00b7\u00dfen", "Fleck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Englisch all's bis zu den R\u00e4dern!", "tokens": ["Eng\u00b7lisch", "all's", "bis", "zu", "den", "R\u00e4\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Und dem Kutscher hat heut fr\u00fch", "tokens": ["Und", "dem", "Kut\u00b7scher", "hat", "heut", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Frau Baronin noch geraten:", "tokens": ["Frau", "Ba\u00b7ro\u00b7nin", "noch", "ge\u00b7ra\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Halt dich schepp, dann meinen sie,", "tokens": ["Halt", "dich", "schepp", ",", "dann", "mei\u00b7nen", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir sein von die Diplomaten.", "tokens": ["Wir", "sein", "von", "die", "Dip\u00b7lo\u00b7ma\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}