{"dta.poem.10161": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Gr\u00f6sse der Seelen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nachdem, mit Dunckelheit, die falben Schatten", "tokens": ["Nach\u00b7dem", ",", "mit", "Dun\u00b7ckel\u00b7heit", ",", "die", "fal\u00b7ben", "Schat\u00b7ten"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "$,", "APPR", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Den Kreis der Welt bereits bedecket hatten;", "tokens": ["Den", "Kreis", "der", "Welt", "be\u00b7reits", "be\u00b7de\u00b7cket", "hat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Befand ich neulich mich auf einer H\u00f6he.", "tokens": ["Be\u00b7fand", "ich", "neu\u00b7lich", "mich", "auf", "ei\u00b7ner", "H\u00f6\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Indem ich nun allein bald hie bald dahin gehe,", "tokens": ["In\u00b7dem", "ich", "nun", "al\u00b7lein", "bald", "hie", "bald", "da\u00b7hin", "ge\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "ADV", "PAV", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Seh ich von selbiger, in einer grossen Weite,", "tokens": ["Seh", "ich", "von", "sel\u00b7bi\u00b7ger", ",", "in", "ei\u00b7ner", "gros\u00b7sen", "Wei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Und eben ja so grossen Breite,", "tokens": ["Und", "e\u00b7ben", "ja", "so", "gros\u00b7sen", "Brei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nicht ohn empfindliches Vergn\u00fcgen,", "tokens": ["Nicht", "ohn", "emp\u00b7find\u00b7li\u00b7ches", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den fernen Horizont im halben Circkel liegen.", "tokens": ["Den", "fer\u00b7nen", "Ho\u00b7ri\u00b7zont", "im", "hal\u00b7ben", "Cir\u00b7ckel", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Himmel schien dadurch, als h\u00e4tt\u2019 er runde Grenzen.", "tokens": ["Der", "Him\u00b7mel", "schien", "da\u00b7durch", ",", "als", "h\u00e4tt'", "er", "run\u00b7de", "Gren\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$,", "KOKOM", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Indem ich nun, \u00fcm der Gestirne Gl\u00e4nzen", "tokens": ["In\u00b7dem", "ich", "nun", ",", "\u00fcm", "der", "Ge\u00b7stir\u00b7ne", "Gl\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "$,", "KOUI", "ART", "NN", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Bewundernd anzusehn, den Scheitel gantz zur\u00fccke", "tokens": ["Be\u00b7wun\u00b7dernd", "an\u00b7zu\u00b7sehn", ",", "den", "Schei\u00b7tel", "gantz", "zu\u00b7r\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "VVIZU", "$,", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Augen aufw\u00e4rts kehrt\u2019, und meine Blicke", "tokens": ["Die", "Au\u00b7gen", "auf\u00b7w\u00e4rts", "kehrt'", ",", "und", "mei\u00b7ne", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In solchem Stand ein wenig abw\u00e4rts senckte,", "tokens": ["In", "sol\u00b7chem", "Stand", "ein", "we\u00b7nig", "ab\u00b7w\u00e4rts", "senck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie \u00fcm der R\u00fcnd an den Gesichts-Kreis lenckte,", "tokens": ["Sie", "\u00fcm", "der", "R\u00fcnd", "an", "den", "Ge\u00b7sichts\u00b7Kreis", "lenck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und, wie der Kreis es gab, zuletzt sie aufw\u00e4rts zog;", "tokens": ["Und", ",", "wie", "der", "Kreis", "es", "gab", ",", "zu\u00b7letzt", "sie", "auf\u00b7w\u00e4rts", "zog", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "PPER", "VVFIN", "$,", "ADV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So kam dadurch der ganze Himmel mir", "tokens": ["So", "kam", "da\u00b7durch", "der", "gan\u00b7ze", "Him\u00b7mel", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PAV", "ART", "ADJA", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Als ein unme\u00dfbar ", "tokens": ["Als", "ein", "un\u00b7me\u00df\u00b7bar"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "ADJD"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Es senckte sich mein Aug\u2019 in diese Tieff\u2019 hinein,", "tokens": ["Es", "senck\u00b7te", "sich", "mein", "Aug'", "in", "die\u00b7se", "Tief\u00b7f'", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "So weit ich sehen kunt; allein", "tokens": ["So", "weit", "ich", "se\u00b7hen", "kunt", ";", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "PTKVZ", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Seele senckte sich weit tieffer; und das Heer", "tokens": ["Die", "See\u00b7le", "senck\u00b7te", "sich", "weit", "tief\u00b7fer", ";", "und", "das", "Heer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "ADJD", "$.", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der in dem hohlen Raum verhandnen Sternen", "tokens": ["Der", "in", "dem", "hoh\u00b7len", "Raum", "ver\u00b7hand\u00b7nen", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Erf\u00fcllte meinen Geist noch mehr.", "tokens": ["Er\u00b7f\u00fcll\u00b7te", "mei\u00b7nen", "Geist", "noch", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Denn da in dieser Tieff\u2019, ohn Ende, keine Schrancken,", "tokens": ["Denn", "da", "in", "die\u00b7ser", "Tief\u00b7f'", ",", "ohn", "En\u00b7de", ",", "kei\u00b7ne", "Schran\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PDAT", "NN", "$,", "APPR", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Auch ewig sinckenden Gedancken,", "tokens": ["Auch", "e\u00b7wig", "sin\u00b7cken\u00b7den", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zu finden, m\u00f6glich sind,", "tokens": ["Zu", "fin\u00b7den", ",", "m\u00f6g\u00b7lich", "sind", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Und aller Zahlen Heer der Sternen Meng\u2019 und Zahlen", "tokens": ["Und", "al\u00b7ler", "Zah\u00b7len", "Heer", "der", "Ster\u00b7nen", "Meng'", "und", "Zah\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "NN", "ART", "NN", "NE", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nicht vorzustellen, abzumahlen,", "tokens": ["Nicht", "vor\u00b7zu\u00b7stel\u00b7len", ",", "ab\u00b7zu\u00b7mah\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "VVIZU", "$,", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und auszudrucken taugt; so stutzt ich dergestalt,", "tokens": ["Und", "aus\u00b7zu\u00b7dru\u00b7cken", "taugt", ";", "so", "stutzt", "ich", "der\u00b7ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIZU", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df, bey dem grossen ", "tokens": ["Da\u00df", ",", "bey", "dem", "gros\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["KOUS", "$,", "APPR", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "O! welche Tieffe!", "tokens": ["O", "!", "wel\u00b7che", "Tief\u00b7fe", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "PWAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "O! welche Tieffe! welche H\u00f6h!", "tokens": ["O", "!", "wel\u00b7che", "Tief\u00b7fe", "!", "wel\u00b7che", "H\u00f6h", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "PWAT", "NN", "$.", "PWAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Worinn, wohin ich mich auch wende,", "tokens": ["Wo\u00b7rinn", ",", "wo\u00b7hin", "ich", "mich", "auch", "wen\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ich doch kein Ende,", "tokens": ["Ich", "doch", "kein", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Wol aber viele Billionen ", "tokens": ["Wol", "a\u00b7ber", "vie\u00b7le", "Bil\u00b7li\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Von Billionen Sternen seh!", "tokens": ["Von", "Bil\u00b7li\u00b7o\u00b7nen", "Ster\u00b7nen", "seh", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Indem ich also voll Verwundrung steh\u2019,", "tokens": ["In\u00b7dem", "ich", "al\u00b7so", "voll", "Ver\u00b7wund\u00b7rung", "steh'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und die Unendlichkeit von dieses Raumes H\u00f6he,", "tokens": ["Und", "die", "Un\u00b7end\u00b7lich\u00b7keit", "von", "die\u00b7ses", "Rau\u00b7mes", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und die Unendlichkeit der Zahl im Sternen-Heer", "tokens": ["Und", "die", "Un\u00b7end\u00b7lich\u00b7keit", "der", "Zahl", "im", "Ster\u00b7nen\u00b7Heer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Erstaunt und halb entz\u00fccket sehe;", "tokens": ["Er\u00b7staunt", "und", "halb", "ent\u00b7z\u00fc\u00b7cket", "se\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Kehr ich die ausgespannten Blicke", "tokens": ["Kehr", "ich", "die", "aus\u00b7ge\u00b7spann\u00b7ten", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Von ungefehr", "tokens": ["Von", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word"], "pos": ["APPR", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.25": {"text": "Auf mich zur\u00fccke", "tokens": ["Auf", "mich", "zu\u00b7r\u00fc\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.26": {"text": "Und fand, bey diesem Raum\u2019 und aller Sternen Schein,", "tokens": ["Und", "fand", ",", "bey", "die\u00b7sem", "Raum'", "und", "al\u00b7ler", "Ster\u00b7nen", "Schein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "PDAT", "NN", "KON", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Mich wunderbarlich gro\u00df und klein.", "tokens": ["Mich", "wun\u00b7der\u00b7bar\u00b7lich", "gro\u00df", "und", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}