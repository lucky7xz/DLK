{"textgrid.poem.37896": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Der stolze Sch\u00e4fersmann", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und als der Sch\u00e4fer \u00fcber die Br\u00fccke trieb,", "tokens": ["Und", "als", "der", "Sch\u00e4\u00b7fer", "\u00fc\u00b7ber", "die", "Br\u00fc\u00b7cke", "trieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ein Edelmann ihm entgegen ritt:", "tokens": ["Ein", "E\u00b7del\u00b7mann", "ihm", "ent\u00b7ge\u00b7gen", "ritt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp entgegen ritt.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ent\u00b7ge\u00b7gen", "ritt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Edelmann th\u00e4t sein H\u00fctlein ab,", "tokens": ["Der", "E\u00b7del\u00b7mann", "th\u00e4t", "sein", "H\u00fct\u00b7lein", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Er bot dem Sch\u00e4fer 'n guten Tag:", "tokens": ["Er", "bot", "dem", "Sch\u00e4\u00b7fer", "'n", "gu\u00b7ten", "Tag", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp 'n guten Tag.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "'n", "gu\u00b7ten", "Tag", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ach Edelmann la\u00df dein H\u00fctlein stahn,", "tokens": ["Ach", "E\u00b7del\u00b7mann", "la\u00df", "dein", "H\u00fct\u00b7lein", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich bin ein armer Sch\u00e4fersmann:", "tokens": ["Ich", "bin", "ein", "ar\u00b7mer", "Sch\u00e4\u00b7fers\u00b7mann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hopp, hopp, hopp ein Sch\u00e4fersmann.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ein", "Sch\u00e4\u00b7fers\u00b7mann", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bist du ein armer Sch\u00e4fersmann,", "tokens": ["Bist", "du", "ein", "ar\u00b7mer", "Sch\u00e4\u00b7fers\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Und hast doch Edelmanns Kleider an:", "tokens": ["Und", "hast", "doch", "E\u00b7del\u00b7manns", "Klei\u00b7der", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp Edelmanns Kleider an.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "E\u00b7del\u00b7manns", "Klei\u00b7der", "an", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJA", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Was geht dich's lumpigen Edelmann an,", "tokens": ["Was", "geht", "dich's", "lum\u00b7pi\u00b7gen", "E\u00b7del\u00b7mann", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Wenn sie mein Vater bezahlen kann:", "tokens": ["Wenn", "sie", "mein", "Va\u00b7ter", "be\u00b7zah\u00b7len", "kann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp bezahlen kann.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "be\u00b7zah\u00b7len", "kann", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Edelmann ward voll Grimm und Zorn,", "tokens": ["Der", "E\u00b7del\u00b7mann", "ward", "voll", "Grimm", "und", "Zorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "NE", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Er schmi\u00df den Sch\u00e4fer in tiefsten Thurn:", "tokens": ["Er", "schmi\u00df", "den", "Sch\u00e4\u00b7fer", "in", "tiefs\u00b7ten", "Thurn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp in tiefsten Thurn.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "in", "tiefs\u00b7ten", "Thurn", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Als es des Sch\u00e4fers sein Mutter erfuhr,", "tokens": ["Als", "es", "des", "Sch\u00e4\u00b7fers", "sein", "Mut\u00b7ter", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "---+--+--+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Da macht sie fr\u00fch sich auf die Spur:", "tokens": ["Da", "macht", "sie", "fr\u00fch", "sich", "auf", "die", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hopp, hopp, hopp auf die Spur.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "auf", "die", "Spur", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ach Edelmann, gieb meinen Sohn heraus,", "tokens": ["Ach", "E\u00b7del\u00b7mann", ",", "gieb", "mei\u00b7nen", "Sohn", "he\u00b7raus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich will dir geben eine Tonne Golds:", "tokens": ["Ich", "will", "dir", "ge\u00b7ben", "ei\u00b7ne", "Ton\u00b7ne", "Golds", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp eine Tonne Golds.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ei\u00b7ne", "Ton\u00b7ne", "Golds", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Eine Tonne Golds ist mir kein Geld,", "tokens": ["Ei\u00b7ne", "Ton\u00b7ne", "Golds", "ist", "mir", "kein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Der Sch\u00e4fer soll lenken ins weite Feld:", "tokens": ["Der", "Sch\u00e4\u00b7fer", "soll", "len\u00b7ken", "ins", "wei\u00b7te", "Feld", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VVINF", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp ins weite Feld.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ins", "wei\u00b7te", "Feld", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und als es dem Sch\u00e4fer sein Vater erfuhr,", "tokens": ["Und", "als", "es", "dem", "Sch\u00e4\u00b7fer", "sein", "Va\u00b7ter", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Er machte sich fr\u00fch wohl auf die Spur:", "tokens": ["Er", "mach\u00b7te", "sich", "fr\u00fch", "wohl", "auf", "die", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp wohl auf die Spur.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "wohl", "auf", "die", "Spur", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ITJ", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ach Edelmann gieb meinen Sohn heraus,", "tokens": ["Ach", "E\u00b7del\u00b7mann", "gieb", "mei\u00b7nen", "Sohn", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich will dir geben zwey Tonnen Golds:", "tokens": ["Ich", "will", "dir", "ge\u00b7ben", "zwey", "Ton\u00b7nen", "Golds", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "CARD", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp zwey Tonnen Golds.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "zwey", "Ton\u00b7nen", "Golds", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "XY", "CARD", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Zwey Tonnen Golds ist mir kein Geld,", "tokens": ["Zwey", "Ton\u00b7nen", "Golds", "ist", "mir", "kein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Der Sch\u00e4fer soll lenken ins weite Feld;", "tokens": ["Der", "Sch\u00e4\u00b7fer", "soll", "len\u00b7ken", "ins", "wei\u00b7te", "Feld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VVINF", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp ins weite Feld.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ins", "wei\u00b7te", "Feld", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und als das des Sch\u00e4fers Schatz erfuhr,", "tokens": ["Und", "als", "das", "des", "Sch\u00e4\u00b7fers", "Schatz", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Sie machte sich fr\u00fch wohl auf die Spur:", "tokens": ["Sie", "mach\u00b7te", "sich", "fr\u00fch", "wohl", "auf", "die", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp wohl auf die Spur.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "wohl", "auf", "die", "Spur", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ITJ", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Ach Edelmann gieb meinen Schatz heraus,", "tokens": ["Ach", "E\u00b7del\u00b7mann", "gieb", "mei\u00b7nen", "Schatz", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich will dir geben ein Perlenstrau\u00df:", "tokens": ["Ich", "will", "dir", "ge\u00b7ben", "ein", "Per\u00b7len\u00b7strau\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp 'n Perlenstrau\u00df.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "'n", "Per\u00b7len\u00b7strau\u00df", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Ein Perlenstrau\u00df kostet mir viel Geld,", "tokens": ["Ein", "Per\u00b7len\u00b7strau\u00df", "kos\u00b7tet", "mir", "viel", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Der Sch\u00e4fer soll lenken bei dir ins Feld:", "tokens": ["Der", "Sch\u00e4\u00b7fer", "soll", "len\u00b7ken", "bei", "dir", "ins", "Feld", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VVINF", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp bei dir ins Feld.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "bei", "dir", "ins", "Feld", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Und als der Sch\u00e4fer \u00fcber die Br\u00fccke trieb,", "tokens": ["Und", "als", "der", "Sch\u00e4\u00b7fer", "\u00fc\u00b7ber", "die", "Br\u00fc\u00b7cke", "trieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ein Edelmann ihm entgegen ritt:", "tokens": ["Ein", "E\u00b7del\u00b7mann", "ihm", "ent\u00b7ge\u00b7gen", "ritt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp entgegen ritt.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ent\u00b7ge\u00b7gen", "ritt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Der Edelmann th\u00e4t sein H\u00fctlein ab,", "tokens": ["Der", "E\u00b7del\u00b7mann", "th\u00e4t", "sein", "H\u00fct\u00b7lein", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Er bot dem Sch\u00e4fer 'n guten Tag:", "tokens": ["Er", "bot", "dem", "Sch\u00e4\u00b7fer", "'n", "gu\u00b7ten", "Tag", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp 'n guten Tag.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "'n", "gu\u00b7ten", "Tag", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Ach Edelmann la\u00df dein H\u00fctlein stahn,", "tokens": ["Ach", "E\u00b7del\u00b7mann", "la\u00df", "dein", "H\u00fct\u00b7lein", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich bin ein armer Sch\u00e4fersmann:", "tokens": ["Ich", "bin", "ein", "ar\u00b7mer", "Sch\u00e4\u00b7fers\u00b7mann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hopp, hopp, hopp ein Sch\u00e4fersmann.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ein", "Sch\u00e4\u00b7fers\u00b7mann", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Bist du ein armer Sch\u00e4fersmann,", "tokens": ["Bist", "du", "ein", "ar\u00b7mer", "Sch\u00e4\u00b7fers\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Und hast doch Edelmanns Kleider an:", "tokens": ["Und", "hast", "doch", "E\u00b7del\u00b7manns", "Klei\u00b7der", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp Edelmanns Kleider an.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "E\u00b7del\u00b7manns", "Klei\u00b7der", "an", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJA", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "Was geht dich's lumpigen Edelmann an,", "tokens": ["Was", "geht", "dich's", "lum\u00b7pi\u00b7gen", "E\u00b7del\u00b7mann", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Wenn sie mein Vater bezahlen kann:", "tokens": ["Wenn", "sie", "mein", "Va\u00b7ter", "be\u00b7zah\u00b7len", "kann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp bezahlen kann.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "be\u00b7zah\u00b7len", "kann", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Der Edelmann ward voll Grimm und Zorn,", "tokens": ["Der", "E\u00b7del\u00b7mann", "ward", "voll", "Grimm", "und", "Zorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "NE", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Er schmi\u00df den Sch\u00e4fer in tiefsten Thurn:", "tokens": ["Er", "schmi\u00df", "den", "Sch\u00e4\u00b7fer", "in", "tiefs\u00b7ten", "Thurn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp in tiefsten Thurn.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "in", "tiefs\u00b7ten", "Thurn", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Als es des Sch\u00e4fers sein Mutter erfuhr,", "tokens": ["Als", "es", "des", "Sch\u00e4\u00b7fers", "sein", "Mut\u00b7ter", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "---+--+--+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Da macht sie fr\u00fch sich auf die Spur:", "tokens": ["Da", "macht", "sie", "fr\u00fch", "sich", "auf", "die", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hopp, hopp, hopp auf die Spur.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "auf", "die", "Spur", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Ach Edelmann, gieb meinen Sohn heraus,", "tokens": ["Ach", "E\u00b7del\u00b7mann", ",", "gieb", "mei\u00b7nen", "Sohn", "he\u00b7raus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich will dir geben eine Tonne Golds:", "tokens": ["Ich", "will", "dir", "ge\u00b7ben", "ei\u00b7ne", "Ton\u00b7ne", "Golds", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp eine Tonne Golds.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ei\u00b7ne", "Ton\u00b7ne", "Golds", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Eine Tonne Golds ist mir kein Geld,", "tokens": ["Ei\u00b7ne", "Ton\u00b7ne", "Golds", "ist", "mir", "kein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Der Sch\u00e4fer soll lenken ins weite Feld:", "tokens": ["Der", "Sch\u00e4\u00b7fer", "soll", "len\u00b7ken", "ins", "wei\u00b7te", "Feld", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VVINF", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp ins weite Feld.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ins", "wei\u00b7te", "Feld", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Und als es dem Sch\u00e4fer sein Vater erfuhr,", "tokens": ["Und", "als", "es", "dem", "Sch\u00e4\u00b7fer", "sein", "Va\u00b7ter", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Er machte sich fr\u00fch wohl auf die Spur:", "tokens": ["Er", "mach\u00b7te", "sich", "fr\u00fch", "wohl", "auf", "die", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp wohl auf die Spur.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "wohl", "auf", "die", "Spur", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ITJ", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Ach Edelmann gieb meinen Sohn heraus,", "tokens": ["Ach", "E\u00b7del\u00b7mann", "gieb", "mei\u00b7nen", "Sohn", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich will dir geben zwey Tonnen Golds:", "tokens": ["Ich", "will", "dir", "ge\u00b7ben", "zwey", "Ton\u00b7nen", "Golds", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "CARD", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp zwey Tonnen Golds.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "zwey", "Ton\u00b7nen", "Golds", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "XY", "CARD", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Zwey Tonnen Golds ist mir kein Geld,", "tokens": ["Zwey", "Ton\u00b7nen", "Golds", "ist", "mir", "kein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Der Sch\u00e4fer soll lenken ins weite Feld;", "tokens": ["Der", "Sch\u00e4\u00b7fer", "soll", "len\u00b7ken", "ins", "wei\u00b7te", "Feld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VVINF", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp ins weite Feld.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "ins", "wei\u00b7te", "Feld", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Und als das des Sch\u00e4fers Schatz erfuhr,", "tokens": ["Und", "als", "das", "des", "Sch\u00e4\u00b7fers", "Schatz", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Sie machte sich fr\u00fch wohl auf die Spur:", "tokens": ["Sie", "mach\u00b7te", "sich", "fr\u00fch", "wohl", "auf", "die", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp wohl auf die Spur.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "wohl", "auf", "die", "Spur", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ITJ", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Ach Edelmann gieb meinen Schatz heraus,", "tokens": ["Ach", "E\u00b7del\u00b7mann", "gieb", "mei\u00b7nen", "Schatz", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Ich will dir geben ein Perlenstrau\u00df:", "tokens": ["Ich", "will", "dir", "ge\u00b7ben", "ein", "Per\u00b7len\u00b7strau\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopp, hopp, hopp 'n Perlenstrau\u00df.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "'n", "Per\u00b7len\u00b7strau\u00df", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Ein Perlenstrau\u00df kostet mir viel Geld,", "tokens": ["Ein", "Per\u00b7len\u00b7strau\u00df", "kos\u00b7tet", "mir", "viel", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Der Sch\u00e4fer soll lenken bei dir ins Feld:", "tokens": ["Der", "Sch\u00e4\u00b7fer", "soll", "len\u00b7ken", "bei", "dir", "ins", "Feld", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "VVINF", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hopp, hopp, hopp bei dir ins Feld.", "tokens": ["Hopp", ",", "hopp", ",", "hopp", "bei", "dir", "ins", "Feld", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "ADJD", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}