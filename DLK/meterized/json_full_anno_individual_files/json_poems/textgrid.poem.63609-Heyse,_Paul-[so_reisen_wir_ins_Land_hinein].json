{"textgrid.poem.63609": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "[so reisen wir ins Land hinein]", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So reisen wir ins Land hinein", "tokens": ["So", "rei\u00b7sen", "wir", "ins", "Land", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Sonn' und Mond und Blitzesschein,", "tokens": ["Bei", "Sonn'", "und", "Mond", "und", "Blit\u00b7zes\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und immer reist auf Schritt und Tritt", "tokens": ["Und", "im\u00b7mer", "reist", "auf", "Schritt", "und", "Tritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein kleiner blasser Schatten mit.", "tokens": ["Ein", "klei\u00b7ner", "blas\u00b7ser", "Schat\u00b7ten", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und wo die Erde sch\u00f6ner bl\u00fcht,", "tokens": ["Und", "wo", "die", "Er\u00b7de", "sch\u00f6\u00b7ner", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein M\u00fcndchen weher zuckt und gl\u00fcht,", "tokens": ["Sein", "M\u00fcnd\u00b7chen", "we\u00b7her", "zuckt", "und", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wo die Sonne goldner lacht,", "tokens": ["Und", "wo", "die", "Son\u00b7ne", "gold\u00b7ner", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sucht er uns tr\u00fcber heim zu Nacht.", "tokens": ["Sucht", "er", "uns", "tr\u00fc\u00b7ber", "heim", "zu", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PAV", "PTKVZ", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was suchst du, blasser Schatten, hier,", "tokens": ["Was", "suchst", "du", ",", "blas\u00b7ser", "Schat\u00b7ten", ",", "hier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du kleiner blinder Passagier?", "tokens": ["Du", "klei\u00b7ner", "blin\u00b7der", "Pas\u00b7sa\u00b7gier", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ach, dir versagt ist alle Lust,", "tokens": ["Ach", ",", "dir", "ver\u00b7sagt", "ist", "al\u00b7le", "Lust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVPP", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und uns erstarrt dein Hauch die Brust.", "tokens": ["Und", "uns", "er\u00b7starrt", "dein", "Hauch", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie war dein Auge warm und hell,", "tokens": ["Wie", "war", "dein", "Au\u00b7ge", "warm", "und", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Lebenswonnenzauberquell!", "tokens": ["Ein", "Le\u00b7bens\u00b7won\u00b7nen\u00b7zau\u00b7ber\u00b7quell", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und jetzt \u2013 o hab Erbarmen, Kind!", "tokens": ["Und", "jetzt", "\u2013", "o", "hab", "Er\u00b7bar\u00b7men", ",", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "$(", "FM", "VAFIN", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du siehst ja, wie wir elend sind.", "tokens": ["Du", "siehst", "ja", ",", "wie", "wir", "e\u00b7lend", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wir dr\u00e4ngen dich ja nicht zur\u00fcck,", "tokens": ["Wir", "dr\u00e4n\u00b7gen", "dich", "ja", "nicht", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch komm mit sanftem Geisterblick,", "tokens": ["Doch", "komm", "mit", "sanf\u00b7tem", "Geis\u00b7ter\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht alles Holden ganz beraubt! \u2013", "tokens": ["Nicht", "al\u00b7les", "Hol\u00b7den", "ganz", "be\u00b7raubt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Umsonst! Er sch\u00fcttelt still das Haupt.", "tokens": ["Um\u00b7sonst", "!", "Er", "sch\u00fct\u00b7telt", "still", "das", "Haupt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sein armes bleiches M\u00fcndchen bebt:", "tokens": ["Sein", "ar\u00b7mes", "blei\u00b7ches", "M\u00fcnd\u00b7chen", "bebt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie habt ihr nur mich \u00fcberlebt!", "tokens": ["Wie", "habt", "ihr", "nur", "mich", "\u00fc\u00b7ber\u00b7lebt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun komm' ich, wie ich kommen mu\u00df,", "tokens": ["Nun", "komm'", "ich", ",", "wie", "ich", "kom\u00b7men", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun haltet Treue bis zum Schlu\u00df. \u2013", "tokens": ["Nun", "hal\u00b7tet", "Treu\u00b7e", "bis", "zum", "Schlu\u00df", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So reisen wir ins Land hinein", "tokens": ["So", "rei\u00b7sen", "wir", "ins", "Land", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Sonn' und Mond und Blitzesschein,", "tokens": ["Bei", "Sonn'", "und", "Mond", "und", "Blit\u00b7zes\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mit uns wandert unser Kind,", "tokens": ["Und", "mit", "uns", "wan\u00b7dert", "un\u00b7ser", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis auch wir andern Schatten sind.", "tokens": ["Bis", "auch", "wir", "an\u00b7dern", "Schat\u00b7ten", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "So reisen wir ins Land hinein", "tokens": ["So", "rei\u00b7sen", "wir", "ins", "Land", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Sonn' und Mond und Blitzesschein,", "tokens": ["Bei", "Sonn'", "und", "Mond", "und", "Blit\u00b7zes\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und immer reist auf Schritt und Tritt", "tokens": ["Und", "im\u00b7mer", "reist", "auf", "Schritt", "und", "Tritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein kleiner blasser Schatten mit.", "tokens": ["Ein", "klei\u00b7ner", "blas\u00b7ser", "Schat\u00b7ten", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und wo die Erde sch\u00f6ner bl\u00fcht,", "tokens": ["Und", "wo", "die", "Er\u00b7de", "sch\u00f6\u00b7ner", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein M\u00fcndchen weher zuckt und gl\u00fcht,", "tokens": ["Sein", "M\u00fcnd\u00b7chen", "we\u00b7her", "zuckt", "und", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wo die Sonne goldner lacht,", "tokens": ["Und", "wo", "die", "Son\u00b7ne", "gold\u00b7ner", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sucht er uns tr\u00fcber heim zu Nacht.", "tokens": ["Sucht", "er", "uns", "tr\u00fc\u00b7ber", "heim", "zu", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PAV", "PTKVZ", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Was suchst du, blasser Schatten, hier,", "tokens": ["Was", "suchst", "du", ",", "blas\u00b7ser", "Schat\u00b7ten", ",", "hier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du kleiner blinder Passagier?", "tokens": ["Du", "klei\u00b7ner", "blin\u00b7der", "Pas\u00b7sa\u00b7gier", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ach, dir versagt ist alle Lust,", "tokens": ["Ach", ",", "dir", "ver\u00b7sagt", "ist", "al\u00b7le", "Lust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVPP", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und uns erstarrt dein Hauch die Brust.", "tokens": ["Und", "uns", "er\u00b7starrt", "dein", "Hauch", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wie war dein Auge warm und hell,", "tokens": ["Wie", "war", "dein", "Au\u00b7ge", "warm", "und", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Lebenswonnenzauberquell!", "tokens": ["Ein", "Le\u00b7bens\u00b7won\u00b7nen\u00b7zau\u00b7ber\u00b7quell", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und jetzt \u2013 o hab Erbarmen, Kind!", "tokens": ["Und", "jetzt", "\u2013", "o", "hab", "Er\u00b7bar\u00b7men", ",", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "$(", "FM", "VAFIN", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du siehst ja, wie wir elend sind.", "tokens": ["Du", "siehst", "ja", ",", "wie", "wir", "e\u00b7lend", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wir dr\u00e4ngen dich ja nicht zur\u00fcck,", "tokens": ["Wir", "dr\u00e4n\u00b7gen", "dich", "ja", "nicht", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch komm mit sanftem Geisterblick,", "tokens": ["Doch", "komm", "mit", "sanf\u00b7tem", "Geis\u00b7ter\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht alles Holden ganz beraubt! \u2013", "tokens": ["Nicht", "al\u00b7les", "Hol\u00b7den", "ganz", "be\u00b7raubt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Umsonst! Er sch\u00fcttelt still das Haupt.", "tokens": ["Um\u00b7sonst", "!", "Er", "sch\u00fct\u00b7telt", "still", "das", "Haupt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sein armes bleiches M\u00fcndchen bebt:", "tokens": ["Sein", "ar\u00b7mes", "blei\u00b7ches", "M\u00fcnd\u00b7chen", "bebt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie habt ihr nur mich \u00fcberlebt!", "tokens": ["Wie", "habt", "ihr", "nur", "mich", "\u00fc\u00b7ber\u00b7lebt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun komm' ich, wie ich kommen mu\u00df,", "tokens": ["Nun", "komm'", "ich", ",", "wie", "ich", "kom\u00b7men", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun haltet Treue bis zum Schlu\u00df. \u2013", "tokens": ["Nun", "hal\u00b7tet", "Treu\u00b7e", "bis", "zum", "Schlu\u00df", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "So reisen wir ins Land hinein", "tokens": ["So", "rei\u00b7sen", "wir", "ins", "Land", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Sonn' und Mond und Blitzesschein,", "tokens": ["Bei", "Sonn'", "und", "Mond", "und", "Blit\u00b7zes\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mit uns wandert unser Kind,", "tokens": ["Und", "mit", "uns", "wan\u00b7dert", "un\u00b7ser", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis auch wir andern Schatten sind.", "tokens": ["Bis", "auch", "wir", "an\u00b7dern", "Schat\u00b7ten", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}