{"textgrid.poem.56833": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbkr\u00fccken, Kr\u00fccken! gebt uns Kr\u00fccken!", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbkr\u00fccken, Kr\u00fccken! gebt uns Kr\u00fccken!", "tokens": ["\u00bb", "kr\u00fc\u00b7cken", ",", "Kr\u00fc\u00b7cken", "!", "gebt", "uns", "Kr\u00fc\u00b7cken", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "$,", "NN", "$.", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, wie geht die Menschheit lahm,", "tokens": ["Ach", ",", "wie", "geht", "die", "Menschheit", "lahm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "seit man, neu sie zu begl\u00fccken,", "tokens": ["seit", "man", ",", "neu", "sie", "zu", "be\u00b7gl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ihr die alten St\u00fctzen nahm.", "tokens": ["ihr", "die", "al\u00b7ten", "St\u00fct\u00b7zen", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Brillen, Brillen! gebt uns Brillen!", "tokens": ["Bril\u00b7len", ",", "Bril\u00b7len", "!", "gebt", "uns", "Bril\u00b7len", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gr\u00fcn und blau und gelb und rot!", "tokens": ["gr\u00fcn", "und", "blau", "und", "gelb", "und", "rot", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Volles Licht ist f\u00fcr Pupillen", "tokens": ["Vol\u00b7les", "Licht", "ist", "f\u00fcr", "Pu\u00b7pil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "unsrer Art der sichre Tod.", "tokens": ["uns\u00b7rer", "Art", "der", "sich\u00b7re", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "L\u00fcgen, L\u00fcgen! gebt uns L\u00fcgen!", "tokens": ["L\u00fc\u00b7gen", ",", "L\u00fc\u00b7gen", "!", "gebt", "uns", "L\u00fc\u00b7gen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, die Wahrheit ist so roh!", "tokens": ["Ach", ",", "die", "Wahr\u00b7heit", "ist", "so", "roh", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wahrheit macht uns kein Vergn\u00fcgen,", "tokens": ["Wahr\u00b7heit", "macht", "uns", "kein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00fcgen machen fett und froh!", "tokens": ["L\u00fc\u00b7gen", "ma\u00b7chen", "fett", "und", "froh", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "G\u00e4ngelb\u00e4nder, Schaukelpferde,", "tokens": ["G\u00e4n\u00b7gel\u00b7b\u00e4n\u00b7der", ",", "Schau\u00b7kel\u00b7pfer\u00b7de", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Himmel, H\u00f6lle und Moral \u2013", "tokens": ["Him\u00b7mel", ",", "H\u00f6l\u00b7le", "und", "Mo\u00b7ral", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und dich selbst gib deiner Herde", "tokens": ["und", "dich", "selbst", "gib", "dei\u00b7ner", "Her\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "VVIMP", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "neu zur\u00fcck, oh gro\u00dfer Baal!\u00ab", "tokens": ["neu", "zu\u00b7r\u00fcck", ",", "oh", "gro\u00b7\u00dfer", "Baal", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PTKVZ", "$,", "ADJD", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbkr\u00fccken, Kr\u00fccken! gebt uns Kr\u00fccken!", "tokens": ["\u00bb", "kr\u00fc\u00b7cken", ",", "Kr\u00fc\u00b7cken", "!", "gebt", "uns", "Kr\u00fc\u00b7cken", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "$,", "NN", "$.", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, wie geht die Menschheit lahm,", "tokens": ["Ach", ",", "wie", "geht", "die", "Menschheit", "lahm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "seit man, neu sie zu begl\u00fccken,", "tokens": ["seit", "man", ",", "neu", "sie", "zu", "be\u00b7gl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ihr die alten St\u00fctzen nahm.", "tokens": ["ihr", "die", "al\u00b7ten", "St\u00fct\u00b7zen", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Brillen, Brillen! gebt uns Brillen!", "tokens": ["Bril\u00b7len", ",", "Bril\u00b7len", "!", "gebt", "uns", "Bril\u00b7len", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gr\u00fcn und blau und gelb und rot!", "tokens": ["gr\u00fcn", "und", "blau", "und", "gelb", "und", "rot", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Volles Licht ist f\u00fcr Pupillen", "tokens": ["Vol\u00b7les", "Licht", "ist", "f\u00fcr", "Pu\u00b7pil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "unsrer Art der sichre Tod.", "tokens": ["uns\u00b7rer", "Art", "der", "sich\u00b7re", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "L\u00fcgen, L\u00fcgen! gebt uns L\u00fcgen!", "tokens": ["L\u00fc\u00b7gen", ",", "L\u00fc\u00b7gen", "!", "gebt", "uns", "L\u00fc\u00b7gen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, die Wahrheit ist so roh!", "tokens": ["Ach", ",", "die", "Wahr\u00b7heit", "ist", "so", "roh", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wahrheit macht uns kein Vergn\u00fcgen,", "tokens": ["Wahr\u00b7heit", "macht", "uns", "kein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00fcgen machen fett und froh!", "tokens": ["L\u00fc\u00b7gen", "ma\u00b7chen", "fett", "und", "froh", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "G\u00e4ngelb\u00e4nder, Schaukelpferde,", "tokens": ["G\u00e4n\u00b7gel\u00b7b\u00e4n\u00b7der", ",", "Schau\u00b7kel\u00b7pfer\u00b7de", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Himmel, H\u00f6lle und Moral \u2013", "tokens": ["Him\u00b7mel", ",", "H\u00f6l\u00b7le", "und", "Mo\u00b7ral", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und dich selbst gib deiner Herde", "tokens": ["und", "dich", "selbst", "gib", "dei\u00b7ner", "Her\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "VVIMP", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "neu zur\u00fcck, oh gro\u00dfer Baal!\u00ab", "tokens": ["neu", "zu\u00b7r\u00fcck", ",", "oh", "gro\u00b7\u00dfer", "Baal", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PTKVZ", "$,", "ADJD", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}