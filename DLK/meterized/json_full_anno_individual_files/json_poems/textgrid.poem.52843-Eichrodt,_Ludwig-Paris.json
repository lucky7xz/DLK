{"textgrid.poem.52843": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Paris", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer niemals in Paris gewest,", "tokens": ["Wer", "nie\u00b7mals", "in", "Pa\u00b7ris", "ge\u00b7west", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ist kein deutscher Mann nicht,", "tokens": ["Der", "ist", "kein", "deut\u00b7scher", "Mann", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wer einmal dort ist, kneipt sich fest,", "tokens": ["Wer", "ein\u00b7mal", "dort", "ist", ",", "kneipt", "sich", "fest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VAFIN", "$,", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sagt Adies, ich kann nicht.", "tokens": ["Und", "sagt", "A\u00b7dies", ",", "ich", "kann", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "$,", "PPER", "VMFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Die hochwohll\u00f6bliche Polizei", "tokens": ["Die", "hoch\u00b7wohl\u00b7l\u00f6b\u00b7li\u00b7che", "Po\u00b7li\u00b7zei"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sorgt schon, da\u00df er noch fortkommt;", "tokens": ["Sorgt", "schon", ",", "da\u00df", "er", "noch", "fort\u00b7kommt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Man h\u00e4lt sein Maul und lebt dann frei,", "tokens": ["Man", "h\u00e4lt", "sein", "Maul", "und", "lebt", "dann", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn man nicht gleich als Lord kommt.", "tokens": ["Wenn", "man", "nicht", "gleich", "als", "Lord", "kommt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "KOUS", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.3": {"line.1": {"text": "Der Engell\u00e4nder spricht allein", "tokens": ["Der", "En\u00b7gel\u00b7l\u00e4n\u00b7der", "spricht", "al\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ihm der Schnabel g'wachsen,", "tokens": ["Wie", "ihm", "der", "Schna\u00b7bel", "g'\u00b7wach\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Denn wer versteht auch das Latein", "tokens": ["Denn", "wer", "ver\u00b7steht", "auch", "das", "La\u00b7tein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Von einem Angelsachsen?", "tokens": ["Von", "ei\u00b7nem", "An\u00b7gel\u00b7sach\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die Deutschen halten einfach 's Maul,", "tokens": ["Die", "Deut\u00b7schen", "hal\u00b7ten", "ein\u00b7fach", "'s", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Italiener schweigen,", "tokens": ["Die", "I\u00b7ta\u00b7li\u00b7e\u00b7ner", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die T\u00fcrken sind von selbst zu faul,", "tokens": ["Die", "T\u00fcr\u00b7ken", "sind", "von", "selbst", "zu", "faul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ungarn, glaub' ich, geigen.", "tokens": ["Die", "Un\u00b7garn", ",", "glaub'", "ich", ",", "gei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und Geld verdient man dort wie Heu,", "tokens": ["Und", "Geld", "ver\u00b7dient", "man", "dort", "wie", "Heu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "ADV", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und la\u00dft es nur so springen,", "tokens": ["Und", "la\u00dft", "es", "nur", "so", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und gibt's Krawall, ist man dabei,", "tokens": ["Und", "gibt's", "Kra\u00b7wall", ",", "ist", "man", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VAFIN", "PIS", "PAV", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Und ich geh' jetzt nach Bingen.", "tokens": ["Und", "ich", "geh'", "jetzt", "nach", "Bin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wer niemals in Paris gewest,", "tokens": ["Wer", "nie\u00b7mals", "in", "Pa\u00b7ris", "ge\u00b7west", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ist kein deutscher Mann nicht,", "tokens": ["Der", "ist", "kein", "deut\u00b7scher", "Mann", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wer einmal dort ist, kneipt sich fest,", "tokens": ["Wer", "ein\u00b7mal", "dort", "ist", ",", "kneipt", "sich", "fest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VAFIN", "$,", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sagt Adies, ich kann nicht.", "tokens": ["Und", "sagt", "A\u00b7dies", ",", "ich", "kann", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "$,", "PPER", "VMFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Die hochwohll\u00f6bliche Polizei", "tokens": ["Die", "hoch\u00b7wohl\u00b7l\u00f6b\u00b7li\u00b7che", "Po\u00b7li\u00b7zei"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sorgt schon, da\u00df er noch fortkommt;", "tokens": ["Sorgt", "schon", ",", "da\u00df", "er", "noch", "fort\u00b7kommt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Man h\u00e4lt sein Maul und lebt dann frei,", "tokens": ["Man", "h\u00e4lt", "sein", "Maul", "und", "lebt", "dann", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn man nicht gleich als Lord kommt.", "tokens": ["Wenn", "man", "nicht", "gleich", "als", "Lord", "kommt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "KOUS", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.8": {"line.1": {"text": "Der Engell\u00e4nder spricht allein", "tokens": ["Der", "En\u00b7gel\u00b7l\u00e4n\u00b7der", "spricht", "al\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ihm der Schnabel g'wachsen,", "tokens": ["Wie", "ihm", "der", "Schna\u00b7bel", "g'\u00b7wach\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Denn wer versteht auch das Latein", "tokens": ["Denn", "wer", "ver\u00b7steht", "auch", "das", "La\u00b7tein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Von einem Angelsachsen?", "tokens": ["Von", "ei\u00b7nem", "An\u00b7gel\u00b7sach\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Die Deutschen halten einfach 's Maul,", "tokens": ["Die", "Deut\u00b7schen", "hal\u00b7ten", "ein\u00b7fach", "'s", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Italiener schweigen,", "tokens": ["Die", "I\u00b7ta\u00b7li\u00b7e\u00b7ner", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die T\u00fcrken sind von selbst zu faul,", "tokens": ["Die", "T\u00fcr\u00b7ken", "sind", "von", "selbst", "zu", "faul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ungarn, glaub' ich, geigen.", "tokens": ["Die", "Un\u00b7garn", ",", "glaub'", "ich", ",", "gei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und Geld verdient man dort wie Heu,", "tokens": ["Und", "Geld", "ver\u00b7dient", "man", "dort", "wie", "Heu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "ADV", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und la\u00dft es nur so springen,", "tokens": ["Und", "la\u00dft", "es", "nur", "so", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und gibt's Krawall, ist man dabei,", "tokens": ["Und", "gibt's", "Kra\u00b7wall", ",", "ist", "man", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VAFIN", "PIS", "PAV", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Und ich geh' jetzt nach Bingen.", "tokens": ["Und", "ich", "geh'", "jetzt", "nach", "Bin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}