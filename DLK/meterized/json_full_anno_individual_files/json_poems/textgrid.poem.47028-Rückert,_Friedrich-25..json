{"textgrid.poem.47028": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "25.", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbich will sonst keinen als den sch\u00f6nsten haben,", "tokens": ["\u00bb", "ich", "will", "sonst", "kei\u00b7nen", "als", "den", "sch\u00f6ns\u00b7ten", "ha\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PIAT", "KOKOM", "ART", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(die Liebste hat's gesprochen unverhohlen)", "tokens": ["(", "die", "Liebs\u00b7te", "hat's", "ge\u00b7spro\u00b7chen", "un\u00b7ver\u00b7hoh\u00b7len", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "VVPP", "ADJD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn nicht der sch\u00f6nste kommt, mich heimzuholen,", "tokens": ["Wenn", "nicht", "der", "sch\u00f6ns\u00b7te", "kommt", ",", "mich", "heim\u00b7zu\u00b7ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "VVFIN", "$,", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So la\u00df ich mich als Jungfr\u00e4ulein begraben.", "tokens": ["So", "la\u00df", "ich", "mich", "als", "Jung\u00b7fr\u00e4u\u00b7lein", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PRF", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Der sch\u00f6nste ganz mit allen Sch\u00f6nheitsgaben", "tokens": ["Der", "sch\u00f6ns\u00b7te", "ganz", "mit", "al\u00b7len", "Sch\u00f6n\u00b7heits\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ger\u00fcstet von der Scheitel bis zur Sohlen;", "tokens": ["Ge\u00b7r\u00fcs\u00b7tet", "von", "der", "Schei\u00b7tel", "bis", "zur", "Soh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und da\u00df er sei der sch\u00f6nste, unverstohlen", "tokens": ["Und", "da\u00df", "er", "sei", "der", "sch\u00f6ns\u00b7te", ",", "un\u00b7ver\u00b7stoh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "ART", "ADJA", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Soll's auf der Stirn ihm stehn mit Goldbuchstaben;", "tokens": ["Soll's", "auf", "der", "Stirn", "ihm", "stehn", "mit", "Gold\u00b7buch\u00b7sta\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da\u00df ich auch sicher bin, da\u00df keiner Dirne", "tokens": ["Da\u00df", "ich", "auch", "si\u00b7cher", "bin", ",", "da\u00df", "kei\u00b7ner", "Dir\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Grunde hier und auf der ganzen Erden", "tokens": ["Im", "Grun\u00b7de", "hier", "und", "auf", "der", "gan\u00b7zen", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein sch\u00f6nerer zu teil werd' als der meine.", "tokens": ["Ein", "sch\u00f6\u00b7ne\u00b7rer", "zu", "teil", "werd'", "als", "der", "mei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "NN", "VAFIN", "KOKOM", "ART", "PPOSAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Find' ich geschrieben das an seiner Stirne,", "tokens": ["Find'", "ich", "ge\u00b7schrie\u00b7ben", "das", "an", "sei\u00b7ner", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "ART", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So will ich mich nicht l\u00e4nger stolz geb\u00e4rden,", "tokens": ["So", "will", "ich", "mich", "nicht", "l\u00e4n\u00b7ger", "stolz", "ge\u00b7b\u00e4r\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "PTKNEG", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da, will ich sprechen, nimm mich, ich bin deine.\u00ab", "tokens": ["Da", ",", "will", "ich", "spre\u00b7chen", ",", "nimm", "mich", ",", "ich", "bin", "dei\u00b7ne", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "VMFIN", "PPER", "VVINF", "$,", "VVIMP", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "\u00bbich will sonst keinen als den sch\u00f6nsten haben,", "tokens": ["\u00bb", "ich", "will", "sonst", "kei\u00b7nen", "als", "den", "sch\u00f6ns\u00b7ten", "ha\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PIAT", "KOKOM", "ART", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(die Liebste hat's gesprochen unverhohlen)", "tokens": ["(", "die", "Liebs\u00b7te", "hat's", "ge\u00b7spro\u00b7chen", "un\u00b7ver\u00b7hoh\u00b7len", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "VVPP", "ADJD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn nicht der sch\u00f6nste kommt, mich heimzuholen,", "tokens": ["Wenn", "nicht", "der", "sch\u00f6ns\u00b7te", "kommt", ",", "mich", "heim\u00b7zu\u00b7ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "VVFIN", "$,", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So la\u00df ich mich als Jungfr\u00e4ulein begraben.", "tokens": ["So", "la\u00df", "ich", "mich", "als", "Jung\u00b7fr\u00e4u\u00b7lein", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PRF", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Der sch\u00f6nste ganz mit allen Sch\u00f6nheitsgaben", "tokens": ["Der", "sch\u00f6ns\u00b7te", "ganz", "mit", "al\u00b7len", "Sch\u00f6n\u00b7heits\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ger\u00fcstet von der Scheitel bis zur Sohlen;", "tokens": ["Ge\u00b7r\u00fcs\u00b7tet", "von", "der", "Schei\u00b7tel", "bis", "zur", "Soh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und da\u00df er sei der sch\u00f6nste, unverstohlen", "tokens": ["Und", "da\u00df", "er", "sei", "der", "sch\u00f6ns\u00b7te", ",", "un\u00b7ver\u00b7stoh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "ART", "ADJA", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Soll's auf der Stirn ihm stehn mit Goldbuchstaben;", "tokens": ["Soll's", "auf", "der", "Stirn", "ihm", "stehn", "mit", "Gold\u00b7buch\u00b7sta\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Da\u00df ich auch sicher bin, da\u00df keiner Dirne", "tokens": ["Da\u00df", "ich", "auch", "si\u00b7cher", "bin", ",", "da\u00df", "kei\u00b7ner", "Dir\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Grunde hier und auf der ganzen Erden", "tokens": ["Im", "Grun\u00b7de", "hier", "und", "auf", "der", "gan\u00b7zen", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein sch\u00f6nerer zu teil werd' als der meine.", "tokens": ["Ein", "sch\u00f6\u00b7ne\u00b7rer", "zu", "teil", "werd'", "als", "der", "mei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "NN", "VAFIN", "KOKOM", "ART", "PPOSAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Find' ich geschrieben das an seiner Stirne,", "tokens": ["Find'", "ich", "ge\u00b7schrie\u00b7ben", "das", "an", "sei\u00b7ner", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "ART", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So will ich mich nicht l\u00e4nger stolz geb\u00e4rden,", "tokens": ["So", "will", "ich", "mich", "nicht", "l\u00e4n\u00b7ger", "stolz", "ge\u00b7b\u00e4r\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "PTKNEG", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da, will ich sprechen, nimm mich, ich bin deine.\u00ab", "tokens": ["Da", ",", "will", "ich", "spre\u00b7chen", ",", "nimm", "mich", ",", "ich", "bin", "dei\u00b7ne", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "VMFIN", "PPER", "VVINF", "$,", "VVIMP", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}