{"textgrid.poem.46309": {"metadata": {"author": {"name": "Spee, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[o Gott, wan ich all wolthat dein]", "genre": "verse", "period": "N.A.", "pub_year": 1613, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O Gott, wan ich all wolthat dein", "tokens": ["O", "Gott", ",", "wan", "ich", "all", "wolt\u00b7hat", "dein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "PWAV", "PPER", "PIAT", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit reiffem sinn betrachte,", "tokens": ["Mit", "reif\u00b7fem", "sinn", "be\u00b7trach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da spritzen mir beid augen mein,", "tokens": ["Da", "sprit\u00b7zen", "mir", "beid", "au\u00b7gen", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr wunder schier verschmachte.", "tokens": ["F\u00fcr", "wun\u00b7der", "schier", "ver\u00b7schmach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Mich r\u00fchret ein gar stille brunst,", "tokens": ["Mich", "r\u00fch\u00b7ret", "ein", "gar", "stil\u00b7le", "brunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gek\u00fclt in frewdenz\u00e4hren,", "tokens": ["Ge\u00b7k\u00fclt", "in", "frew\u00b7den\u00b7z\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weil kr\u00f6nest vns mit gnad, vnd gunst,", "tokens": ["Weil", "kr\u00f6\u00b7nest", "vns", "mit", "gnad", ",", "vnd", "gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch mehr dan wir begeren!", "tokens": ["Noch", "mehr", "dan", "wir", "be\u00b7ge\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.3": {"line.1": {"text": "Gleich wie von s\u00fcssem Sonnenschein", "tokens": ["Gleich", "wie", "von", "s\u00fcs\u00b7sem", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gar sittiglich thut schmeltzen,", "tokens": ["Gar", "sit\u00b7tig\u00b7lich", "thut", "schmelt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Schnee, wan er Crystallenrein", "tokens": ["Der", "Schnee", ",", "wan", "er", "Crys\u00b7tal\u00b7len\u00b7rein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fleust ab von stoltzen feltzen:", "tokens": ["Fleust", "ab", "von", "stolt\u00b7zen", "felt\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Also wan deine gnaden straal", "tokens": ["Al\u00b7so", "wan", "dei\u00b7ne", "gna\u00b7den", "straal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Auf vns so lieblich scheinen,", "tokens": ["Auf", "vns", "so", "lieb\u00b7lich", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da rinnen mir die z\u00e4hr ohn zahl,", "tokens": ["Da", "rin\u00b7nen", "mir", "die", "z\u00e4hr", "ohn", "zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar s\u00fc\u00dflich ich mu\u00df weinen.", "tokens": ["Gar", "s\u00fc\u00df\u00b7lich", "ich", "mu\u00df", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Mir hertz vnd augen schmeltzen gar,", "tokens": ["Mir", "hertz", "vnd", "au\u00b7gen", "schmelt\u00b7zen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "All adren sich erwarmen,", "tokens": ["All", "ad\u00b7ren", "sich", "er\u00b7war\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd strecken mir die Feuchte dar,", "tokens": ["Vnd", "stre\u00b7cken", "mir", "die", "Feuch\u00b7te", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An z\u00e4hr mag nie verarmen.", "tokens": ["An", "z\u00e4hr", "mag", "nie", "ver\u00b7ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wan ich schon w\u00f6lt auffh\u00f6ren ger,", "tokens": ["Wan", "ich", "schon", "w\u00f6lt", "auff\u00b7h\u00f6\u00b7ren", "ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVIZU", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Vnd meine br\u00fcnnlein schlie\u00dfen;", "tokens": ["Vnd", "mei\u00b7ne", "br\u00fcnn\u00b7lein", "schlie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch nie sie w\u00f6llen scheinen l\u00e4hr,", "tokens": ["Doch", "nie", "sie", "w\u00f6l\u00b7len", "schei\u00b7nen", "l\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Starck w\u00f6llen sie noch fliessen:", "tokens": ["Starck", "w\u00f6l\u00b7len", "sie", "noch", "flies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Im lauff noch immer w\u00f6llen sein", "tokens": ["Im", "lauff", "noch", "im\u00b7mer", "w\u00f6l\u00b7len", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "ADV", "VVFIN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wasserb\u00e4chlein kleine,", "tokens": ["Die", "was\u00b7ser\u00b7b\u00e4ch\u00b7lein", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd mir albeide wangen mein", "tokens": ["Vnd", "mir", "al\u00b7bei\u00b7de", "wan\u00b7gen", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "PIS", "VVFIN", "PPOSAT"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Noch w\u00e4schen also reine.", "tokens": ["Noch", "w\u00e4\u00b7schen", "al\u00b7so", "rei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ey was soll ich nun widerumb,", "tokens": ["Ey", "was", "soll", "ich", "nun", "wi\u00b7de\u00b7rumb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "VMFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ey was dem Herren geben?", "tokens": ["Ey", "was", "dem", "Her\u00b7ren", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allweil wir ob so gro\u00dfer Summ", "tokens": ["All\u00b7weil", "wir", "ob", "so", "gro\u00b7\u00dfer", "Summ"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "KOUS", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In lauter wolthat schweben.", "tokens": ["In", "lau\u00b7ter", "wolt\u00b7hat", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Vmbzinglet seind wir vberall,", "tokens": ["Vm\u00b7bzing\u00b7let", "seind", "wir", "vbe\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Seind vmb, vnd vmb bezogen", "tokens": ["Seind", "vmb", ",", "vnd", "vmb", "be\u00b7zo\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "APPR", "$,", "KON", "APPR", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit lauter gnad auff allen fall:", "tokens": ["Mit", "lau\u00b7ter", "gnad", "auff", "al\u00b7len", "fall", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gott, Gott ist vns gewogen.", "tokens": ["Gott", ",", "Gott", "ist", "vns", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Sein milte gnad, vnd g\u00fctigkeit", "tokens": ["Sein", "mil\u00b7te", "gnad", ",", "vnd", "g\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Walt vber vns mit hauffen", "tokens": ["Walt", "vber", "vns", "mit", "hauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "APPR", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Ein Meer ist seine miltigkeit:", "tokens": ["Ein", "Meer", "ist", "sei\u00b7ne", "mil\u00b7tig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da m\u00fc\u00dfen wir ersauffen.", "tokens": ["Da", "m\u00fc\u00b7\u00dfen", "wir", "er\u00b7sauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "O Gott, wan ich all wolthat dein", "tokens": ["O", "Gott", ",", "wan", "ich", "all", "wolt\u00b7hat", "dein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "PWAV", "PPER", "PIAT", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit reiffem sinn betrachte,", "tokens": ["Mit", "reif\u00b7fem", "sinn", "be\u00b7trach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da spritzen mir beid augen mein,", "tokens": ["Da", "sprit\u00b7zen", "mir", "beid", "au\u00b7gen", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr wunder schier verschmachte.", "tokens": ["F\u00fcr", "wun\u00b7der", "schier", "ver\u00b7schmach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Mich r\u00fchret ein gar stille brunst,", "tokens": ["Mich", "r\u00fch\u00b7ret", "ein", "gar", "stil\u00b7le", "brunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gek\u00fclt in frewdenz\u00e4hren,", "tokens": ["Ge\u00b7k\u00fclt", "in", "frew\u00b7den\u00b7z\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weil kr\u00f6nest vns mit gnad, vnd gunst,", "tokens": ["Weil", "kr\u00f6\u00b7nest", "vns", "mit", "gnad", ",", "vnd", "gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch mehr dan wir begeren!", "tokens": ["Noch", "mehr", "dan", "wir", "be\u00b7ge\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.13": {"line.1": {"text": "Gleich wie von s\u00fcssem Sonnenschein", "tokens": ["Gleich", "wie", "von", "s\u00fcs\u00b7sem", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gar sittiglich thut schmeltzen,", "tokens": ["Gar", "sit\u00b7tig\u00b7lich", "thut", "schmelt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Schnee, wan er Crystallenrein", "tokens": ["Der", "Schnee", ",", "wan", "er", "Crys\u00b7tal\u00b7len\u00b7rein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fleust ab von stoltzen feltzen:", "tokens": ["Fleust", "ab", "von", "stolt\u00b7zen", "felt\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Also wan deine gnaden straal", "tokens": ["Al\u00b7so", "wan", "dei\u00b7ne", "gna\u00b7den", "straal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Auf vns so lieblich scheinen,", "tokens": ["Auf", "vns", "so", "lieb\u00b7lich", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da rinnen mir die z\u00e4hr ohn zahl,", "tokens": ["Da", "rin\u00b7nen", "mir", "die", "z\u00e4hr", "ohn", "zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar s\u00fc\u00dflich ich mu\u00df weinen.", "tokens": ["Gar", "s\u00fc\u00df\u00b7lich", "ich", "mu\u00df", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Mir hertz vnd augen schmeltzen gar,", "tokens": ["Mir", "hertz", "vnd", "au\u00b7gen", "schmelt\u00b7zen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "All adren sich erwarmen,", "tokens": ["All", "ad\u00b7ren", "sich", "er\u00b7war\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd strecken mir die Feuchte dar,", "tokens": ["Vnd", "stre\u00b7cken", "mir", "die", "Feuch\u00b7te", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An z\u00e4hr mag nie verarmen.", "tokens": ["An", "z\u00e4hr", "mag", "nie", "ver\u00b7ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Wan ich schon w\u00f6lt auffh\u00f6ren ger,", "tokens": ["Wan", "ich", "schon", "w\u00f6lt", "auff\u00b7h\u00f6\u00b7ren", "ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVIZU", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Vnd meine br\u00fcnnlein schlie\u00dfen;", "tokens": ["Vnd", "mei\u00b7ne", "br\u00fcnn\u00b7lein", "schlie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch nie sie w\u00f6llen scheinen l\u00e4hr,", "tokens": ["Doch", "nie", "sie", "w\u00f6l\u00b7len", "schei\u00b7nen", "l\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Starck w\u00f6llen sie noch fliessen:", "tokens": ["Starck", "w\u00f6l\u00b7len", "sie", "noch", "flies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Im lauff noch immer w\u00f6llen sein", "tokens": ["Im", "lauff", "noch", "im\u00b7mer", "w\u00f6l\u00b7len", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "ADV", "VVFIN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wasserb\u00e4chlein kleine,", "tokens": ["Die", "was\u00b7ser\u00b7b\u00e4ch\u00b7lein", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd mir albeide wangen mein", "tokens": ["Vnd", "mir", "al\u00b7bei\u00b7de", "wan\u00b7gen", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "PIS", "VVFIN", "PPOSAT"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Noch w\u00e4schen also reine.", "tokens": ["Noch", "w\u00e4\u00b7schen", "al\u00b7so", "rei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Ey was soll ich nun widerumb,", "tokens": ["Ey", "was", "soll", "ich", "nun", "wi\u00b7de\u00b7rumb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "VMFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ey was dem Herren geben?", "tokens": ["Ey", "was", "dem", "Her\u00b7ren", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allweil wir ob so gro\u00dfer Summ", "tokens": ["All\u00b7weil", "wir", "ob", "so", "gro\u00b7\u00dfer", "Summ"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "KOUS", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In lauter wolthat schweben.", "tokens": ["In", "lau\u00b7ter", "wolt\u00b7hat", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Vmbzinglet seind wir vberall,", "tokens": ["Vm\u00b7bzing\u00b7let", "seind", "wir", "vbe\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Seind vmb, vnd vmb bezogen", "tokens": ["Seind", "vmb", ",", "vnd", "vmb", "be\u00b7zo\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "APPR", "$,", "KON", "APPR", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit lauter gnad auff allen fall:", "tokens": ["Mit", "lau\u00b7ter", "gnad", "auff", "al\u00b7len", "fall", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gott, Gott ist vns gewogen.", "tokens": ["Gott", ",", "Gott", "ist", "vns", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Sein milte gnad, vnd g\u00fctigkeit", "tokens": ["Sein", "mil\u00b7te", "gnad", ",", "vnd", "g\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Walt vber vns mit hauffen", "tokens": ["Walt", "vber", "vns", "mit", "hauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "APPR", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Ein Meer ist seine miltigkeit:", "tokens": ["Ein", "Meer", "ist", "sei\u00b7ne", "mil\u00b7tig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da m\u00fc\u00dfen wir ersauffen.", "tokens": ["Da", "m\u00fc\u00b7\u00dfen", "wir", "er\u00b7sauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}