{"dta.poem.23745": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "Die kleinen Leute.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1767", "urn": "urn:nbn:de:kobv:b4-20643-5", "language": ["de:0.57", "et:0.42"], "booktitle": "Wei\u00dfe, Christian Felix: Lieder f\u00fcr Kinder. Leipzig, 1767."}, "poem": {"stanza.1": {"line.1": {"text": "In Lilliput, ich glaub es kaum,", "tokens": ["In", "Lil\u00b7li\u00b7put", ",", "ich", "glaub", "es", "kaum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch Swift erz\u00e4hlts, sind Leute", "tokens": ["Doch", "Swift", "er\u00b7z\u00e4hlts", ",", "sind", "Leu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NE", "NE", "$,", "VAFIN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So gro\u00df, als ungef\u00e4hr mein Daum:", "tokens": ["So", "gro\u00df", ",", "als", "un\u00b7ge\u00b7f\u00e4hr", "mein", "Daum", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man denk erst in der Weite!", "tokens": ["Man", "denk", "erst", "in", "der", "Wei\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da m\u00fcssen sie gewi\u00df so klein,", "tokens": ["Da", "m\u00fcs\u00b7sen", "sie", "ge\u00b7wi\u00df", "so", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als bey uns eine M\u00fccke seyn.", "tokens": ["Als", "bey", "uns", "ei\u00b7ne", "M\u00fc\u00b7cke", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "O w\u00e4r ich dort, wie gro\u00df w\u00e4r ich!", "tokens": ["O", "w\u00e4r", "ich", "dort", ",", "wie", "gro\u00df", "w\u00e4r", "ich", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man nennte mich den Riesen,", "tokens": ["Man", "nenn\u00b7te", "mich", "den", "Rie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mit den Fingern w\u00fcrd auf mich,", "tokens": ["Und", "mit", "den", "Fin\u00b7gern", "w\u00fcrd", "auf", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo man mich s\u00e4h, gewiesen!", "tokens": ["Wo", "man", "mich", "s\u00e4h", ",", "ge\u00b7wie\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "ADJD", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dort, spr\u00e4chen sie, dort gehet er!", "tokens": ["Dort", ",", "spr\u00e4\u00b7chen", "sie", ",", "dort", "ge\u00b7het", "er", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Und vor mir gieng das Schrecken her.", "tokens": ["Und", "vor", "mir", "gieng", "das", "Schre\u00b7cken", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch wenn ich nun nicht kl\u00fcger w\u00e4r,", "tokens": ["Doch", "wenn", "ich", "nun", "nicht", "kl\u00fc\u00b7ger", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als itzt; sie aber w\u00e4ren", "tokens": ["Als", "itzt", ";", "sie", "a\u00b7ber", "w\u00e4\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "$.", "PPER", "ADV", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gesitteter, verst\u00e4ndiger,", "tokens": ["Ge\u00b7sit\u00b7te\u00b7ter", ",", "ver\u00b7st\u00e4n\u00b7di\u00b7ger", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie! w\u00fcrden sie mich ehren?", "tokens": ["Wie", "!", "w\u00fcr\u00b7den", "sie", "mich", "eh\u00b7ren", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich glaube kaum. Sie w\u00fcrden schreyn:", "tokens": ["Ich", "glau\u00b7be", "kaum", ".", "Sie", "w\u00fcr\u00b7den", "schreyn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gro\u00df an Gestalt, am Geiste klein!", "tokens": ["Gro\u00df", "an", "Ge\u00b7stalt", ",", "am", "Geis\u00b7te", "klein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}