{"dta.poem.12469": {"metadata": {"author": {"name": "Herwegh, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Bei Hamburgs Brand.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1843", "urn": "urn:nbn:de:kobv:b4-200905192440", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein freies Wort in Hamburgs Flammen!", "tokens": ["Ein", "frei\u00b7es", "Wort", "in", "Ham\u00b7burgs", "Flam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn in den Flammen seht ihr's gern;", "tokens": ["Denn", "in", "den", "Flam\u00b7men", "seht", "ih\u00b7r's", "gern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es wird mich F\u00fcrst und Volk verdammen", "tokens": ["Es", "wird", "mich", "F\u00fcrst", "und", "Volk", "ver\u00b7dam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und doch \u2014 ich find' kein Lied, ihr Herrn;", "tokens": ["Und", "doch", "ich", "find'", "kein", "Lied", ",", "ihr", "Herrn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "PPER", "VVFIN", "PIAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kaum will ein Laut sich in mir regen,", "tokens": ["Kaum", "will", "ein", "Laut", "sich", "in", "mir", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "APPR", "PRF", "APPR", "PPER", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Laut f\u00fcr den Philistersegen,", "tokens": ["Ein", "Laut", "f\u00fcr", "den", "Phi\u00b7lis\u00b7ter\u00b7se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der aus der hei\u00dfen Asche bricht;", "tokens": ["Der", "aus", "der", "hei\u00b7\u00dfen", "A\u00b7sche", "bricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "La\u00dft mich ein Spr\u00fcchlein niederlegen:", "tokens": ["La\u00dft", "mich", "ein", "Spr\u00fcch\u00b7lein", "nie\u00b7der\u00b7le\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ihr wi\u00dft, ich bin ein schlechter Reimer,", "tokens": ["Ihr", "wi\u00dft", ",", "ich", "bin", "ein", "schlech\u00b7ter", "Rei\u00b7mer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die\u00df liegt trotz eurer Nacht am Tag;", "tokens": ["Die\u00df", "liegt", "trotz", "eu\u00b7rer", "Nacht", "am", "Tag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch ist mein Vers kein Wassereimer,", "tokens": ["Doch", "ist", "mein", "Vers", "kein", "Was\u00b7se\u00b7rei\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den man zum L\u00f6schen f\u00fcllen mag;", "tokens": ["Den", "man", "zum", "L\u00f6\u00b7schen", "f\u00fcl\u00b7len", "mag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich jauchzte, als die Feuerzungen", "tokens": ["Ich", "jauchz\u00b7te", ",", "als", "die", "Feu\u00b7er\u00b7zun\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "J\u00fcngst so beredt durch's Land geklungen,", "tokens": ["J\u00fcngst", "so", "be\u00b7redt", "durch's", "Land", "ge\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPRART", "NN", "VVPP", "$,"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.7": {"text": "Ja, Feuer! rief noch mein Gedicht;", "tokens": ["Ja", ",", "Feu\u00b7er", "!", "rief", "noch", "mein", "Ge\u00b7dicht", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$.", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich hab' den St\u00fcrmen zugesungen:", "tokens": ["Ich", "hab'", "den", "St\u00fcr\u00b7men", "zu\u00b7ge\u00b7sun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bewahrt das Feuer und das Licht!", "tokens": ["Be\u00b7wahrt", "das", "Feu\u00b7er", "und", "das", "Licht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Manch trocken Auge ward gefeuchtet,", "tokens": ["Manch", "tro\u00b7cken", "Au\u00b7ge", "ward", "ge\u00b7feuch\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Manch kalte Seele wurde hei\u00df,", "tokens": ["Manch", "kal\u00b7te", "See\u00b7le", "wur\u00b7de", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und gl\u00fchend hat das Eis geleuchtet,", "tokens": ["Und", "gl\u00fc\u00b7hend", "hat", "das", "Eis", "ge\u00b7leuch\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das starre, deutsche Gletschereis;", "tokens": ["Das", "star\u00b7re", ",", "deut\u00b7sche", "Glet\u00b7sche\u00b7reis", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Bund der Eintracht ward beschworen,", "tokens": ["Der", "Bund", "der", "Ein\u00b7tracht", "ward", "be\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das Feuer hat uns neu geboren,", "tokens": ["Das", "Feu\u00b7er", "hat", "uns", "neu", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des Rheines Wasser konnt' es nicht \u2014", "tokens": ["Des", "Rhei\u00b7nes", "Was\u00b7ser", "konnt'", "es", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "O sei kein Funke drum verloren:", "tokens": ["O", "sei", "kein", "Fun\u00b7ke", "drum", "ver\u00b7lo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIAT", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bewahrt das Feuer und das Licht!", "tokens": ["Be\u00b7wahrt", "das", "Feu\u00b7er", "und", "das", "Licht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}