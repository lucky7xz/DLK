{"textgrid.poem.60716": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Bertrand und Raton \u2013 dieser war ein Kater,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bertrand und Raton \u2013 dieser war ein Kater,", "tokens": ["Ber\u00b7trand", "und", "Ra\u00b7ton", "\u2013", "die\u00b7ser", "war", "ein", "Ka\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$(", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Jener ein Affe \u2013 waren Hausgenossen", "tokens": ["Je\u00b7ner", "ein", "Af\u00b7fe", "\u2013", "wa\u00b7ren", "Haus\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "ART", "NN", "$(", "VAFIN", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Desselben Herrn; trotz ihrer argen Possen", "tokens": ["Des\u00b7sel\u00b7ben", "Herrn", ";", "trotz", "ih\u00b7rer", "ar\u00b7gen", "Pos\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "$.", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "War er dem Paar ein guter Pflegevater.", "tokens": ["War", "er", "dem", "Paar", "ein", "gu\u00b7ter", "Pfle\u00b7ge\u00b7va\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie f\u00fcrchteten kein peinliches Gericht.", "tokens": ["Sie", "f\u00fcrch\u00b7te\u00b7ten", "kein", "pein\u00b7li\u00b7ches", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Fand man im Hause einen Schaden,", "tokens": ["Fand", "man", "im", "Hau\u00b7se", "ei\u00b7nen", "Scha\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So brauchte den Verdacht man nicht", "tokens": ["So", "brauch\u00b7te", "den", "Ver\u00b7dacht", "man", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PIS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Unschuldigen Nachbarn aufzuladen.", "tokens": ["Un\u00b7schul\u00b7di\u00b7gen", "Nach\u00b7barn", "auf\u00b7zu\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVIZU", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Bertrands Zerst\u00f6rungslust war gro\u00df,", "tokens": ["Ber\u00b7trands", "Zer\u00b7st\u00f6\u00b7rungs\u00b7lust", "war", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Und Raton mochte K\u00e4se gerne leiden", "tokens": ["Und", "Ra\u00b7ton", "moch\u00b7te", "K\u00e4\u00b7se", "ger\u00b7ne", "lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und ging auf diesen statt auf M\u00e4use los.", "tokens": ["Und", "ging", "auf", "die\u00b7sen", "statt", "auf", "M\u00e4u\u00b7se", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Einst sahen unsre lockren beiden", "tokens": ["Einst", "sa\u00b7hen", "uns\u00b7re", "lock\u00b7ren", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Kastanien im Kamine r\u00f6sten.", "tokens": ["Kas\u00b7ta\u00b7ni\u00b7en", "im", "Ka\u00b7mi\u00b7ne", "r\u00f6s\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVFIN", "$."], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.14": {"text": "Ach, wie ergaunert man sie blo\u00df?", "tokens": ["Ach", ",", "wie", "er\u00b7gau\u00b7nert", "man", "sie", "blo\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VVFIN", "PIS", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der Spa\u00df w\u00e4r zwiefach: erstens tr\u00f6sten", "tokens": ["Der", "Spa\u00df", "w\u00e4r", "zwie\u00b7fach", ":", "ers\u00b7tens", "tr\u00f6s\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Sie dessen Gaumen, der mit Lust sich dran vergn\u00fcgt,", "tokens": ["Sie", "des\u00b7sen", "Gau\u00b7men", ",", "der", "mit", "Lust", "sich", "dran", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "NN", "$,", "PRELS", "APPR", "NN", "PRF", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und zweitens wird Verdru\u00df dem dritten zugef\u00fcgt.", "tokens": ["Und", "zwei\u00b7tens", "wird", "Ver\u00b7dru\u00df", "dem", "drit\u00b7ten", "zu\u00b7ge\u00b7f\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "NN", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Zu Raton sagte Bertrand alsogleich:", "tokens": ["Zu", "Ra\u00b7ton", "sag\u00b7te", "Ber\u00b7trand", "al\u00b7so\u00b7gleich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "\u00bbhier, Br\u00fcderlein, mach deinen Meisterstreich", "tokens": ["\u00bb", "hier", ",", "Br\u00fc\u00b7derl\u00b7ein", ",", "mach", "dei\u00b7nen", "Meis\u00b7ter\u00b7streich"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "$,", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und hol sie uns. O h\u00e4tte Gott mich Affen,", "tokens": ["Und", "hol", "sie", "uns", ".", "O", "h\u00e4t\u00b7te", "Gott", "mich", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$.", "NE", "VAFIN", "NN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Kastanien aus der Glut zu scharrn, erschaffen,", "tokens": ["Kas\u00b7ta\u00b7ni\u00b7en", "aus", "der", "Glut", "zu", "scharrn", ",", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.22": {"text": "So h\u00e4tten wir schon unsre Freude dran!\u00ab", "tokens": ["So", "h\u00e4t\u00b7ten", "wir", "schon", "uns\u00b7re", "Freu\u00b7de", "dran", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Raton war stolz. Er nickte und begann", "tokens": ["Ra\u00b7ton", "war", "stolz", ".", "Er", "nick\u00b7te", "und", "be\u00b7gann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.24": {"text": "Ganz sacht die Asche mit der Pfote zu entfernen.", "tokens": ["Ganz", "sacht", "die", "A\u00b7sche", "mit", "der", "Pfo\u00b7te", "zu", "ent\u00b7fer\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Er zog die Krallen schnell zur\u00fcck.", "tokens": ["Er", "zog", "die", "Kral\u00b7len", "schnell", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Ach, solche Arbeit war ein hei\u00dfes St\u00fcck!", "tokens": ["Ach", ",", "sol\u00b7che", "Ar\u00b7beit", "war", "ein", "hei\u00b7\u00dfes", "St\u00fcck", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PIAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Indes, er m\u00fchte sich, die neue Kunst zu lernen,", "tokens": ["In\u00b7des", ",", "er", "m\u00fch\u00b7te", "sich", ",", "die", "neu\u00b7e", "Kunst", "zu", "ler\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "PRF", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und legte nach und nach Kastanien frei.", "tokens": ["Und", "leg\u00b7te", "nach", "und", "nach", "Kas\u00b7ta\u00b7ni\u00b7en", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "KON", "APPR", "NE", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Die erste flog heraus, es folgten zwei und drei,", "tokens": ["Die", "ers\u00b7te", "flog", "he\u00b7raus", ",", "es", "folg\u00b7ten", "zwei", "und", "drei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "CARD", "KON", "CARD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und Bertrand hinter ihm ergriff und knackte sie.", "tokens": ["Und", "Ber\u00b7trand", "hin\u00b7ter", "ihm", "er\u00b7griff", "und", "knack\u00b7te", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "PPER", "VVFIN", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Da kam die Magd und schimpfte auf das Vieh", "tokens": ["Da", "kam", "die", "Magd", "und", "schimpf\u00b7te", "auf", "das", "Vieh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Und hat das Gaunerpaar geschwind geschieden.", "tokens": ["Und", "hat", "das", "Gau\u00b7ner\u00b7paar", "ge\u00b7schwind", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Man sagt, Raton war unzufrieden.", "tokens": ["Man", "sagt", ",", "Ra\u00b7ton", "war", "un\u00b7zu\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So sind es meistens auch die Prinzen,", "tokens": ["So", "sind", "es", "meis\u00b7tens", "auch", "die", "Prin\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die, stolz des Amts, wozu man sie ernannt,", "tokens": ["Die", ",", "stolz", "des", "Amts", ",", "wo\u00b7zu", "man", "sie", "er\u00b7nannt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "ART", "NN", "$,", "PWAV", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fcr einen K\u00f6nig sich in den Provinzen", "tokens": ["F\u00fcr", "ei\u00b7nen", "K\u00f6\u00b7nig", "sich", "in", "den", "Pro\u00b7vin\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Finger haben arg verbrannt.", "tokens": ["Die", "Fin\u00b7ger", "ha\u00b7ben", "arg", "ver\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Bertrand und Raton \u2013 dieser war ein Kater,", "tokens": ["Ber\u00b7trand", "und", "Ra\u00b7ton", "\u2013", "die\u00b7ser", "war", "ein", "Ka\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$(", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Jener ein Affe \u2013 waren Hausgenossen", "tokens": ["Je\u00b7ner", "ein", "Af\u00b7fe", "\u2013", "wa\u00b7ren", "Haus\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "ART", "NN", "$(", "VAFIN", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Desselben Herrn; trotz ihrer argen Possen", "tokens": ["Des\u00b7sel\u00b7ben", "Herrn", ";", "trotz", "ih\u00b7rer", "ar\u00b7gen", "Pos\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "$.", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "War er dem Paar ein guter Pflegevater.", "tokens": ["War", "er", "dem", "Paar", "ein", "gu\u00b7ter", "Pfle\u00b7ge\u00b7va\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie f\u00fcrchteten kein peinliches Gericht.", "tokens": ["Sie", "f\u00fcrch\u00b7te\u00b7ten", "kein", "pein\u00b7li\u00b7ches", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Fand man im Hause einen Schaden,", "tokens": ["Fand", "man", "im", "Hau\u00b7se", "ei\u00b7nen", "Scha\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So brauchte den Verdacht man nicht", "tokens": ["So", "brauch\u00b7te", "den", "Ver\u00b7dacht", "man", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PIS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Unschuldigen Nachbarn aufzuladen.", "tokens": ["Un\u00b7schul\u00b7di\u00b7gen", "Nach\u00b7barn", "auf\u00b7zu\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVIZU", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Bertrands Zerst\u00f6rungslust war gro\u00df,", "tokens": ["Ber\u00b7trands", "Zer\u00b7st\u00f6\u00b7rungs\u00b7lust", "war", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Und Raton mochte K\u00e4se gerne leiden", "tokens": ["Und", "Ra\u00b7ton", "moch\u00b7te", "K\u00e4\u00b7se", "ger\u00b7ne", "lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und ging auf diesen statt auf M\u00e4use los.", "tokens": ["Und", "ging", "auf", "die\u00b7sen", "statt", "auf", "M\u00e4u\u00b7se", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Einst sahen unsre lockren beiden", "tokens": ["Einst", "sa\u00b7hen", "uns\u00b7re", "lock\u00b7ren", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Kastanien im Kamine r\u00f6sten.", "tokens": ["Kas\u00b7ta\u00b7ni\u00b7en", "im", "Ka\u00b7mi\u00b7ne", "r\u00f6s\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVFIN", "$."], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.14": {"text": "Ach, wie ergaunert man sie blo\u00df?", "tokens": ["Ach", ",", "wie", "er\u00b7gau\u00b7nert", "man", "sie", "blo\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VVFIN", "PIS", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der Spa\u00df w\u00e4r zwiefach: erstens tr\u00f6sten", "tokens": ["Der", "Spa\u00df", "w\u00e4r", "zwie\u00b7fach", ":", "ers\u00b7tens", "tr\u00f6s\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Sie dessen Gaumen, der mit Lust sich dran vergn\u00fcgt,", "tokens": ["Sie", "des\u00b7sen", "Gau\u00b7men", ",", "der", "mit", "Lust", "sich", "dran", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "NN", "$,", "PRELS", "APPR", "NN", "PRF", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und zweitens wird Verdru\u00df dem dritten zugef\u00fcgt.", "tokens": ["Und", "zwei\u00b7tens", "wird", "Ver\u00b7dru\u00df", "dem", "drit\u00b7ten", "zu\u00b7ge\u00b7f\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "NN", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Zu Raton sagte Bertrand alsogleich:", "tokens": ["Zu", "Ra\u00b7ton", "sag\u00b7te", "Ber\u00b7trand", "al\u00b7so\u00b7gleich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "\u00bbhier, Br\u00fcderlein, mach deinen Meisterstreich", "tokens": ["\u00bb", "hier", ",", "Br\u00fc\u00b7derl\u00b7ein", ",", "mach", "dei\u00b7nen", "Meis\u00b7ter\u00b7streich"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "$,", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und hol sie uns. O h\u00e4tte Gott mich Affen,", "tokens": ["Und", "hol", "sie", "uns", ".", "O", "h\u00e4t\u00b7te", "Gott", "mich", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$.", "NE", "VAFIN", "NN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Kastanien aus der Glut zu scharrn, erschaffen,", "tokens": ["Kas\u00b7ta\u00b7ni\u00b7en", "aus", "der", "Glut", "zu", "scharrn", ",", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.22": {"text": "So h\u00e4tten wir schon unsre Freude dran!\u00ab", "tokens": ["So", "h\u00e4t\u00b7ten", "wir", "schon", "uns\u00b7re", "Freu\u00b7de", "dran", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Raton war stolz. Er nickte und begann", "tokens": ["Ra\u00b7ton", "war", "stolz", ".", "Er", "nick\u00b7te", "und", "be\u00b7gann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.24": {"text": "Ganz sacht die Asche mit der Pfote zu entfernen.", "tokens": ["Ganz", "sacht", "die", "A\u00b7sche", "mit", "der", "Pfo\u00b7te", "zu", "ent\u00b7fer\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Er zog die Krallen schnell zur\u00fcck.", "tokens": ["Er", "zog", "die", "Kral\u00b7len", "schnell", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Ach, solche Arbeit war ein hei\u00dfes St\u00fcck!", "tokens": ["Ach", ",", "sol\u00b7che", "Ar\u00b7beit", "war", "ein", "hei\u00b7\u00dfes", "St\u00fcck", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PIAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Indes, er m\u00fchte sich, die neue Kunst zu lernen,", "tokens": ["In\u00b7des", ",", "er", "m\u00fch\u00b7te", "sich", ",", "die", "neu\u00b7e", "Kunst", "zu", "ler\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "PRF", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und legte nach und nach Kastanien frei.", "tokens": ["Und", "leg\u00b7te", "nach", "und", "nach", "Kas\u00b7ta\u00b7ni\u00b7en", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "KON", "APPR", "NE", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Die erste flog heraus, es folgten zwei und drei,", "tokens": ["Die", "ers\u00b7te", "flog", "he\u00b7raus", ",", "es", "folg\u00b7ten", "zwei", "und", "drei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "CARD", "KON", "CARD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und Bertrand hinter ihm ergriff und knackte sie.", "tokens": ["Und", "Ber\u00b7trand", "hin\u00b7ter", "ihm", "er\u00b7griff", "und", "knack\u00b7te", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "PPER", "VVFIN", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Da kam die Magd und schimpfte auf das Vieh", "tokens": ["Da", "kam", "die", "Magd", "und", "schimpf\u00b7te", "auf", "das", "Vieh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Und hat das Gaunerpaar geschwind geschieden.", "tokens": ["Und", "hat", "das", "Gau\u00b7ner\u00b7paar", "ge\u00b7schwind", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Man sagt, Raton war unzufrieden.", "tokens": ["Man", "sagt", ",", "Ra\u00b7ton", "war", "un\u00b7zu\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "So sind es meistens auch die Prinzen,", "tokens": ["So", "sind", "es", "meis\u00b7tens", "auch", "die", "Prin\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die, stolz des Amts, wozu man sie ernannt,", "tokens": ["Die", ",", "stolz", "des", "Amts", ",", "wo\u00b7zu", "man", "sie", "er\u00b7nannt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "ART", "NN", "$,", "PWAV", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fcr einen K\u00f6nig sich in den Provinzen", "tokens": ["F\u00fcr", "ei\u00b7nen", "K\u00f6\u00b7nig", "sich", "in", "den", "Pro\u00b7vin\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Finger haben arg verbrannt.", "tokens": ["Die", "Fin\u00b7ger", "ha\u00b7ben", "arg", "ver\u00b7brannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}