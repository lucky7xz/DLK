{"dta.poem.19299": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "32.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195090", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn du ein bergiges Gel\u00e4nde steigst empor;", "tokens": ["Wenn", "du", "ein", "ber\u00b7gi\u00b7ges", "Ge\u00b7l\u00e4n\u00b7de", "steigst", "em\u00b7por", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Als steigest du hinab, kommt dirs zuweilen vor.", "tokens": ["Als", "stei\u00b7gest", "du", "hin\u00b7ab", ",", "kommt", "dirs", "zu\u00b7wei\u00b7len", "vor", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Denn bis von einer H\u00f6h zur andern wird gestiegen,", "tokens": ["Denn", "bis", "von", "ei\u00b7ner", "H\u00f6h", "zur", "an\u00b7dern", "wird", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APPRART", "ADJA", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gehts \u00fcber Senkungen, die zwischen beiden liegen.", "tokens": ["Gehts", "\u00fc\u00b7ber", "Sen\u00b7kun\u00b7gen", ",", "die", "zwi\u00b7schen", "bei\u00b7den", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "PRELS", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}}, "stanza.3": {"line.1": {"text": "Und eh nicht, als erreicht der andre Gipfel ist,", "tokens": ["Und", "eh", "nicht", ",", "als", "er\u00b7reicht", "der", "and\u00b7re", "Gip\u00b7fel", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PTKNEG", "$,", "KOUS", "VVPP", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erkennest du, da\u00df du gestiegen wirklich bist.", "tokens": ["Er\u00b7ken\u00b7nest", "du", ",", "da\u00df", "du", "ge\u00b7stie\u00b7gen", "wirk\u00b7lich", "bist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "VVPP", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die Aussicht, schon zuvor gewonnen, dann geschwunden,", "tokens": ["Die", "Aus\u00b7sicht", ",", "schon", "zu\u00b7vor", "ge\u00b7won\u00b7nen", ",", "dann", "ge\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADV", "VVPP", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat wieder nun, und zwar erweitert, sich gefunden.", "tokens": ["Hat", "wie\u00b7der", "nun", ",", "und", "zwar", "er\u00b7wei\u00b7tert", ",", "sich", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "$,", "KON", "ADV", "VVPP", "$,", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Doch auch zur Niederung wo du dich schienst zu neigen,", "tokens": ["Doch", "auch", "zur", "Nie\u00b7de\u00b7rung", "wo", "du", "dich", "schienst", "zu", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "PWAV", "PPER", "PRF", "ADJD", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Wahrheit warst du dort begriffen schon im Steigen,", "tokens": ["In", "Wahr\u00b7heit", "warst", "du", "dort", "be\u00b7grif\u00b7fen", "schon", "im", "Stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "VVPP", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Nur niedrer im Bezug auf das woher du kamest,", "tokens": ["Nur", "nie\u00b7drer", "im", "Be\u00b7zug", "auf", "das", "wo\u00b7her", "du", "ka\u00b7mest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPRART", "NN", "APPR", "ART", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "H\u00f6her an sich, weil du den Weg zur H\u00f6he nahmest.", "tokens": ["H\u00f6\u00b7her", "an", "sich", ",", "weil", "du", "den", "Weg", "zur", "H\u00f6\u00b7he", "nah\u00b7mest", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "$,", "KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Es ist naturgem\u00e4\u00df der Weg, o geh ihn nur!", "tokens": ["Es", "ist", "na\u00b7tur\u00b7ge\u00b7m\u00e4\u00df", "der", "Weg", ",", "o", "geh", "ihn", "nur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,", "FM", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Selbst keinen andern ist gegangen die Natur,", "tokens": ["Selbst", "kei\u00b7nen", "an\u00b7dern", "ist", "ge\u00b7gan\u00b7gen", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "VAFIN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Als sie mit Bildnertrieb und sch\u00f6pferischem Witze", "tokens": ["Als", "sie", "mit", "Bild\u00b7ner\u00b7trieb", "und", "sch\u00f6p\u00b7fe\u00b7ri\u00b7schem", "Wit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durchs Reich der Formen klomm von Spitz' empor zu Spitze.", "tokens": ["Durchs", "Reich", "der", "For\u00b7men", "klomm", "von", "Spitz'", "em\u00b7por", "zu", "Spit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "APPR", "NN", "PTKVZ", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Sie konnte nicht umhin, in ihrem Vorwertsstreben", "tokens": ["Sie", "konn\u00b7te", "nicht", "um\u00b7hin", ",", "in", "ih\u00b7rem", "Vor\u00b7werts\u00b7stre\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "PTKVZ", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich hier zu senken, um dort wieder sich zu heben.", "tokens": ["Sich", "hier", "zu", "sen\u00b7ken", ",", "um", "dort", "wie\u00b7der", "sich", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PTKZU", "VVINF", "$,", "KOUI", "ADV", "ADV", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Sie hatte sich vom Gras mit windgeknicktem Halme", "tokens": ["Sie", "hat\u00b7te", "sich", "vom", "Gras", "mit", "wind\u00b7ge\u00b7knick\u00b7tem", "Hal\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Emporgehoben schon zum stolzen Schaft der Palme.", "tokens": ["Em\u00b7por\u00b7ge\u00b7ho\u00b7ben", "schon", "zum", "stol\u00b7zen", "Schaft", "der", "Pal\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Dann hat sie sich bequemt und sich herabgelassen,", "tokens": ["Dann", "hat", "sie", "sich", "be\u00b7quemt", "und", "sich", "her\u00b7ab\u00b7ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ADJD", "KON", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Bildungen von Kraut und Strauch sich zu befassen.", "tokens": ["Mit", "Bil\u00b7dun\u00b7gen", "von", "Kraut", "und", "Strauch", "sich", "zu", "be\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Sie dacht' an Palmen nicht zur\u00fcck beim niedern Strauch,", "tokens": ["Sie", "dacht'", "an", "Pal\u00b7men", "nicht", "zu\u00b7r\u00fcck", "beim", "nie\u00b7dern", "Strauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKNEG", "PTKVZ", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie dachte vorwerts an der Rose Liebeshauch.", "tokens": ["Sie", "dach\u00b7te", "vor\u00b7werts", "an", "der", "Ro\u00b7se", "Lie\u00b7bes\u00b7hauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Und als sie hingelangt zum G\u00f6tterbild der Rose,", "tokens": ["Und", "als", "sie", "hin\u00b7ge\u00b7langt", "zum", "G\u00f6t\u00b7ter\u00b7bild", "der", "Ro\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Stieg sie von ihm hinab, und schuf den Wurm im Moose.", "tokens": ["Stieg", "sie", "von", "ihm", "hin\u00b7ab", ",", "und", "schuf", "den", "Wurm", "im", "Moo\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Der Rose dachte sie beim W\u00fcrmlein auch nicht mehr;", "tokens": ["Der", "Ro\u00b7se", "dach\u00b7te", "sie", "beim", "W\u00fcrm\u00b7lein", "auch", "nicht", "mehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie dacht', indem es lebt', ein ganzes Lebensheer.", "tokens": ["Sie", "dacht'", ",", "in\u00b7dem", "es", "lebt'", ",", "ein", "gan\u00b7zes", "Le\u00b7bens\u00b7heer", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Ein gro\u00dfer R\u00fcckschritt schien von dort zu hier gethan,", "tokens": ["Ein", "gro\u00b7\u00dfer", "R\u00fcck\u00b7schritt", "schien", "von", "dort", "zu", "hier", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADV", "APPR", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der gr\u00f6ste Vorschritt war die Senkung ihrer Bahn.", "tokens": ["Der", "gr\u00f6s\u00b7te", "Vor\u00b7schritt", "war", "die", "Sen\u00b7kung", "ih\u00b7rer", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Und als hinauf, hinab, die Ordnungen von Thier", "tokens": ["Und", "als", "hin\u00b7auf", ",", "hin\u00b7ab", ",", "die", "Ord\u00b7nun\u00b7gen", "von", "Thier"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "$,", "PTKVZ", "$,", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zu Thier hindurch, sie kam zu L\u00f6we, Ro\u00df und Stier;", "tokens": ["Zu", "Thier", "hin\u00b7durch", ",", "sie", "kam", "zu", "L\u00f6\u00b7we", ",", "Ro\u00df", "und", "Stier", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "$,", "PPER", "VVFIN", "APPR", "NE", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Da sann sie deren Herrn und ihren zu erschaffen,", "tokens": ["Da", "sann", "sie", "de\u00b7ren", "Herrn", "und", "ih\u00b7ren", "zu", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "NN", "KON", "PPOSAT", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und schuf zur Menschenvorbereitung erst den Affen.", "tokens": ["Und", "schuf", "zur", "Men\u00b7schen\u00b7vor\u00b7be\u00b7rei\u00b7tung", "erst", "den", "Af\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Das war der tiefste Fall, den sie zuletzt gethan,", "tokens": ["Das", "war", "der", "tiefs\u00b7te", "Fall", ",", "den", "sie", "zu\u00b7letzt", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um sich zum h\u00f6chsten Schwung zu heben himmelan.", "tokens": ["Um", "sich", "zum", "h\u00f6chs\u00b7ten", "Schwung", "zu", "he\u00b7ben", "him\u00b7me\u00b7lan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "APPRART", "ADJA", "NN", "PTKZU", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Drum tr\u00f6st' ein K\u00fcnstler sich, wenn ihm ein Bild mislingt,", "tokens": ["Drum", "tr\u00f6st'", "ein", "K\u00fcnst\u00b7ler", "sich", ",", "wenn", "ihm", "ein", "Bild", "mis\u00b7lingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "PRF", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist er sich nur bewu\u00dft, da\u00df er zum H\u00f6chsten ringt.", "tokens": ["Ist", "er", "sich", "nur", "be\u00b7wu\u00dft", ",", "da\u00df", "er", "zum", "H\u00f6chs\u00b7ten", "ringt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "ADJD", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}