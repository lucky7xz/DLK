{"textgrid.poem.60708": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie hasse ich die Meinung des Gemeinen,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie hasse ich die Meinung des Gemeinen,", "tokens": ["Wie", "has\u00b7se", "ich", "die", "Mei\u00b7nung", "des", "Ge\u00b7mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie mu\u00df er mir doch klein und dumm erscheinen,", "tokens": ["Wie", "mu\u00df", "er", "mir", "doch", "klein", "und", "dumm", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "ADV", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er, dessen Denken stets am Staube klebt", "tokens": ["Er", ",", "des\u00b7sen", "Den\u00b7ken", "stets", "am", "Stau\u00b7be", "klebt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "NN", "ADV", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und dennoch sich so gerne \u00fcberhebt,", "tokens": ["Und", "den\u00b7noch", "sich", "so", "ger\u00b7ne", "\u00fc\u00b7ber\u00b7hebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der stets aus engstem Winkel alle Dinge sieht", "tokens": ["Der", "stets", "aus", "engs\u00b7tem", "Win\u00b7kel", "al\u00b7le", "Din\u00b7ge", "sieht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und das Erhabne ins Gemeine niederzieht.", "tokens": ["Und", "das", "Er\u00b7hab\u00b7ne", "ins", "Ge\u00b7mei\u00b7ne", "nie\u00b7der\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das mu\u00dfte auch der Lehrer Epikurs erkennen,", "tokens": ["Das", "mu\u00df\u00b7te", "auch", "der", "Leh\u00b7rer", "E\u00b7pi\u00b7kurs", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn seinem Volk gefiel es, ihn verr\u00fcckt zu nennen;", "tokens": ["Denn", "sei\u00b7nem", "Volk", "ge\u00b7fiel", "es", ",", "ihn", "ver\u00b7r\u00fcckt", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vor allem hat er dieses bald erkannt:", "tokens": ["Vor", "al\u00b7lem", "hat", "er", "die\u00b7ses", "bald", "er\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Propheten gelten nichts im eignen Vaterland.", "tokens": ["Pro\u00b7phe\u00b7ten", "gel\u00b7ten", "nichts", "im", "eig\u00b7nen", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "In Wirklichkeit war wohl das Volk nicht bei Verstand", "tokens": ["In", "Wirk\u00b7lich\u00b7keit", "war", "wohl", "das", "Volk", "nicht", "bei", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "ADV", "ART", "NN", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und Demokrit der Weiseste in seiner Mitte.", "tokens": ["Und", "De\u00b7mo\u00b7krit", "der", "Wei\u00b7ses\u00b7te", "in", "sei\u00b7ner", "Mit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das Volk der Abderiten n\u00e4mlich bat", "tokens": ["Das", "Volk", "der", "Ab\u00b7de\u00b7ri\u00b7ten", "n\u00e4m\u00b7lich", "bat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "\u2013 Und \u00e4u\u00dferst dringend machten sie die Bitte \u2013", "tokens": ["\u2013", "Und", "\u00e4u\u00b7\u00dferst", "drin\u00b7gend", "mach\u00b7ten", "sie", "die", "Bit\u00b7te", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Den kundigsten der \u00c4rzte, Hippokrat,", "tokens": ["Den", "kun\u00b7digs\u00b7ten", "der", "\u00c4rz\u00b7te", ",", "Hip\u00b7po\u00b7krat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "Er m\u00f6ge doch zu Hilfe eilen,", "tokens": ["Er", "m\u00f6\u00b7ge", "doch", "zu", "Hil\u00b7fe", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Des Kranken irren Geist zu heilen.", "tokens": ["Des", "Kran\u00b7ken", "ir\u00b7ren", "Geist", "zu", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Abderas Bote sagte etwa so,", "tokens": ["Ab\u00b7de\u00b7ras", "Bo\u00b7te", "sag\u00b7te", "et\u00b7wa", "so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.19": {"text": "Und seine Tr\u00e4nen rannen bei dem Wort:", "tokens": ["Und", "sei\u00b7ne", "Tr\u00e4\u00b7nen", "ran\u00b7nen", "bei", "dem", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "\u00bbdes Demokrit Verstand ist g\u00e4nzlich fort,", "tokens": ["\u00bb", "des", "De\u00b7mo\u00b7krit", "Ver\u00b7stand", "ist", "g\u00e4nz\u00b7lich", "fort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "VAFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Das viele Lesen hat ihn dumm gemacht;", "tokens": ["Das", "vie\u00b7le", "Le\u00b7sen", "hat", "ihn", "dumm", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Was w\u00e4ren doch wir Abderiten froh,", "tokens": ["Was", "w\u00e4\u00b7ren", "doch", "wir", "Ab\u00b7de\u00b7ri\u00b7ten", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Wenn zur Vernunft er wiederum erwacht.", "tokens": ["Wenn", "zur", "Ver\u00b7nunft", "er", "wie\u00b7de\u00b7rum", "er\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Er sagt, man k\u00f6nne nicht die Welt in Zahlen fassen,", "tokens": ["Er", "sagt", ",", "man", "k\u00f6n\u00b7ne", "nicht", "die", "Welt", "in", "Zah\u00b7len", "fas\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PIS", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und will noch Tolleres uns glauben lassen.", "tokens": ["Und", "will", "noch", "Tol\u00b7le\u00b7res", "uns", "glau\u00b7ben", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJA", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und nicht genug an dem, er spricht auch von Atomen,", "tokens": ["Und", "nicht", "ge\u00b7nug", "an", "dem", ",", "er", "spricht", "auch", "von", "A\u00b7to\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "APPR", "ART", "$,", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So wie ein andrer wohl von seinen Kindern spricht;", "tokens": ["So", "wie", "ein", "an\u00b7drer", "wohl", "von", "sei\u00b7nen", "Kin\u00b7dern", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und ohne da\u00df er sich vom Platz bewegt,", "tokens": ["Und", "oh\u00b7ne", "da\u00df", "er", "sich", "vom", "Platz", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Erhebt er sich zu allen Himmelsdomen,", "tokens": ["Er\u00b7hebt", "er", "sich", "zu", "al\u00b7len", "Him\u00b7mels\u00b7do\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "An die er k\u00fchn den Ma\u00dfstab legt.", "tokens": ["An", "die", "er", "k\u00fchn", "den", "Ma\u00df\u00b7stab", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Er kennt das Weltall, doch sich selber nicht.", "tokens": ["Er", "kennt", "das", "Wel\u00b7tall", ",", "doch", "sich", "sel\u00b7ber", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "PRF", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Wie mitteilsam ist er doch einst gewesen,", "tokens": ["Wie", "mit\u00b7teil\u00b7sam", "ist", "er", "doch", "einst", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "ADV", "VAPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Der jetzt nur mit sich selber spricht;", "tokens": ["Der", "jetzt", "nur", "mit", "sich", "sel\u00b7ber", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "O kommt und la\u00dft den armen Mann genesen!\u00ab", "tokens": ["O", "kommt", "und", "la\u00dft", "den", "ar\u00b7men", "Mann", "ge\u00b7ne\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "KON", "VVIMP", "ART", "ADJA", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Hippokrates kam solche Kunde seltsam vor,", "tokens": ["Hip\u00b7po\u00b7kra\u00b7tes", "kam", "sol\u00b7che", "Kun\u00b7de", "selt\u00b7sam", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.36": {"text": "Doch ging er hin, und das Geschick erkor", "tokens": ["Doch", "ging", "er", "hin", ",", "und", "das", "Ge\u00b7schick", "er\u00b7kor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "ART", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "F\u00fcr die Begegnung den gerechten Augenblick.", "tokens": ["F\u00fcr", "die", "Be\u00b7geg\u00b7nung", "den", "ge\u00b7rech\u00b7ten", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Denn Hippokrat traf ihn, von dem es hie\u00df,", "tokens": ["Denn", "Hip\u00b7po\u00b7krat", "traf", "ihn", ",", "von", "dem", "es", "hie\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Da\u00df die Vernunft ihn l\u00e4ngst verlie\u00df,", "tokens": ["Da\u00df", "die", "Ver\u00b7nunft", "ihn", "l\u00e4ngst", "ver\u00b7lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Dabei, wie er mit ernstem Forscherblick", "tokens": ["Da\u00b7bei", ",", "wie", "er", "mit", "erns\u00b7tem", "For\u00b7scher\u00b7blick"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "$,", "PWAV", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Zu finden strebte, wo bei Mensch und Tier", "tokens": ["Zu", "fin\u00b7den", "streb\u00b7te", ",", "wo", "bei", "Mensch", "und", "Tier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VVFIN", "$,", "PWAV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.42": {"text": "Der Sitz f\u00fcr den Verstand zu suchen sei:", "tokens": ["Der", "Sitz", "f\u00fcr", "den", "Ver\u00b7stand", "zu", "su\u00b7chen", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Ob Herz, ob Hirn wohl w\u00e4re sein Revier.", "tokens": ["Ob", "Herz", ",", "ob", "Hirn", "wohl", "w\u00e4\u00b7re", "sein", "Re\u00b7vier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "So sa\u00df er da im Schatten k\u00fchler B\u00e4ume", "tokens": ["So", "sa\u00df", "er", "da", "im", "Schat\u00b7ten", "k\u00fch\u00b7ler", "B\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.45": {"text": "Und sp\u00e4hte in die Windungen und R\u00e4ume", "tokens": ["Und", "sp\u00e4h\u00b7te", "in", "die", "Win\u00b7dun\u00b7gen", "und", "R\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Von eines Menschenhirnes Labyrinth,", "tokens": ["Von", "ei\u00b7nes", "Men\u00b7schen\u00b7hir\u00b7nes", "La\u00b7by\u00b7rinth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.47": {"text": "Und weise B\u00fccher lagen ihm zu F\u00fc\u00dfen.", "tokens": ["Und", "wei\u00b7se", "B\u00fc\u00b7cher", "la\u00b7gen", "ihm", "zu", "F\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.48": {"text": "F\u00fcr die Natur rundum ist unser Forscher blind,", "tokens": ["F\u00fcr", "die", "Na\u00b7tur", "run\u00b7dum", "ist", "un\u00b7ser", "For\u00b7scher", "blind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Der auch des Freundes Nahen erst gewahrt,", "tokens": ["Der", "auch", "des", "Freun\u00b7des", "Na\u00b7hen", "erst", "ge\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.50": {"text": "Als schon vertraute Worte ihn begr\u00fc\u00dfen.", "tokens": ["Als", "schon", "ver\u00b7trau\u00b7te", "Wor\u00b7te", "ihn", "be\u00b7gr\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "Und weil der Weise gerne Worte spart", "tokens": ["Und", "weil", "der", "Wei\u00b7se", "ger\u00b7ne", "Wor\u00b7te", "spart"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.52": {"text": "Und ihm leichtfertiges Geplauder fremd", "tokens": ["Und", "ihm", "leicht\u00b7fer\u00b7ti\u00b7ges", "Ge\u00b7plau\u00b7der", "fremd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJA", "NN", "ADJD"], "meter": "+-++-+-+-+", "measure": "zehnsilber"}, "line.53": {"text": "Und hier den Geistesflug kein Lauscher hemmt,", "tokens": ["Und", "hier", "den", "Geis\u00b7tes\u00b7flug", "kein", "Lau\u00b7scher", "hemmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "So sprechen sie von Mensch und Menschenseelen,", "tokens": ["So", "spre\u00b7chen", "sie", "von", "Mensch", "und", "Men\u00b7schen\u00b7see\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.55": {"text": "Und auch die Nutzanwendung lassen sie nicht fehlen.", "tokens": ["Und", "auch", "die", "Nut\u00b7zan\u00b7wen\u00b7dung", "las\u00b7sen", "sie", "nicht", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Es ist nicht n\u00f6tig, da\u00df ich lang und breit", "tokens": ["Es", "ist", "nicht", "n\u00f6\u00b7tig", ",", "da\u00df", "ich", "lang", "und", "breit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.57": {"text": "Euch hier berichte jede Einzelheit.", "tokens": ["Euch", "hier", "be\u00b7rich\u00b7te", "je\u00b7de", "Ein\u00b7zel\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "Das Vorgesagte mag als Weisung euch gen\u00fcgen,", "tokens": ["Das", "Vor\u00b7ge\u00b7sag\u00b7te", "mag", "als", "Wei\u00b7sung", "euch", "ge\u00b7n\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "KOUS", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Da\u00df man des Volkes Urteil, eh man's glaubt, ermi\u00dft,", "tokens": ["Da\u00df", "man", "des", "Vol\u00b7kes", "Ur\u00b7teil", ",", "eh", "man's", "glaubt", ",", "er\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "NN", "$,", "KOUS", "PIS", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Und straft zugleich den Ausspruch L\u00fcgen,", "tokens": ["Und", "straft", "zu\u00b7gleich", "den", "Aus\u00b7spruch", "L\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "Da\u00df Volkes Stimme Gottes Stimme ist.", "tokens": ["Da\u00df", "Vol\u00b7kes", "Stim\u00b7me", "Got\u00b7tes", "Stim\u00b7me", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wie hasse ich die Meinung des Gemeinen,", "tokens": ["Wie", "has\u00b7se", "ich", "die", "Mei\u00b7nung", "des", "Ge\u00b7mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie mu\u00df er mir doch klein und dumm erscheinen,", "tokens": ["Wie", "mu\u00df", "er", "mir", "doch", "klein", "und", "dumm", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "ADV", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er, dessen Denken stets am Staube klebt", "tokens": ["Er", ",", "des\u00b7sen", "Den\u00b7ken", "stets", "am", "Stau\u00b7be", "klebt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "NN", "ADV", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und dennoch sich so gerne \u00fcberhebt,", "tokens": ["Und", "den\u00b7noch", "sich", "so", "ger\u00b7ne", "\u00fc\u00b7ber\u00b7hebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der stets aus engstem Winkel alle Dinge sieht", "tokens": ["Der", "stets", "aus", "engs\u00b7tem", "Win\u00b7kel", "al\u00b7le", "Din\u00b7ge", "sieht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und das Erhabne ins Gemeine niederzieht.", "tokens": ["Und", "das", "Er\u00b7hab\u00b7ne", "ins", "Ge\u00b7mei\u00b7ne", "nie\u00b7der\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das mu\u00dfte auch der Lehrer Epikurs erkennen,", "tokens": ["Das", "mu\u00df\u00b7te", "auch", "der", "Leh\u00b7rer", "E\u00b7pi\u00b7kurs", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn seinem Volk gefiel es, ihn verr\u00fcckt zu nennen;", "tokens": ["Denn", "sei\u00b7nem", "Volk", "ge\u00b7fiel", "es", ",", "ihn", "ver\u00b7r\u00fcckt", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vor allem hat er dieses bald erkannt:", "tokens": ["Vor", "al\u00b7lem", "hat", "er", "die\u00b7ses", "bald", "er\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Propheten gelten nichts im eignen Vaterland.", "tokens": ["Pro\u00b7phe\u00b7ten", "gel\u00b7ten", "nichts", "im", "eig\u00b7nen", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "In Wirklichkeit war wohl das Volk nicht bei Verstand", "tokens": ["In", "Wirk\u00b7lich\u00b7keit", "war", "wohl", "das", "Volk", "nicht", "bei", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "ADV", "ART", "NN", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und Demokrit der Weiseste in seiner Mitte.", "tokens": ["Und", "De\u00b7mo\u00b7krit", "der", "Wei\u00b7ses\u00b7te", "in", "sei\u00b7ner", "Mit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das Volk der Abderiten n\u00e4mlich bat", "tokens": ["Das", "Volk", "der", "Ab\u00b7de\u00b7ri\u00b7ten", "n\u00e4m\u00b7lich", "bat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "\u2013 Und \u00e4u\u00dferst dringend machten sie die Bitte \u2013", "tokens": ["\u2013", "Und", "\u00e4u\u00b7\u00dferst", "drin\u00b7gend", "mach\u00b7ten", "sie", "die", "Bit\u00b7te", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Den kundigsten der \u00c4rzte, Hippokrat,", "tokens": ["Den", "kun\u00b7digs\u00b7ten", "der", "\u00c4rz\u00b7te", ",", "Hip\u00b7po\u00b7krat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "Er m\u00f6ge doch zu Hilfe eilen,", "tokens": ["Er", "m\u00f6\u00b7ge", "doch", "zu", "Hil\u00b7fe", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Des Kranken irren Geist zu heilen.", "tokens": ["Des", "Kran\u00b7ken", "ir\u00b7ren", "Geist", "zu", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Abderas Bote sagte etwa so,", "tokens": ["Ab\u00b7de\u00b7ras", "Bo\u00b7te", "sag\u00b7te", "et\u00b7wa", "so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.19": {"text": "Und seine Tr\u00e4nen rannen bei dem Wort:", "tokens": ["Und", "sei\u00b7ne", "Tr\u00e4\u00b7nen", "ran\u00b7nen", "bei", "dem", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "\u00bbdes Demokrit Verstand ist g\u00e4nzlich fort,", "tokens": ["\u00bb", "des", "De\u00b7mo\u00b7krit", "Ver\u00b7stand", "ist", "g\u00e4nz\u00b7lich", "fort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "VAFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Das viele Lesen hat ihn dumm gemacht;", "tokens": ["Das", "vie\u00b7le", "Le\u00b7sen", "hat", "ihn", "dumm", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Was w\u00e4ren doch wir Abderiten froh,", "tokens": ["Was", "w\u00e4\u00b7ren", "doch", "wir", "Ab\u00b7de\u00b7ri\u00b7ten", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Wenn zur Vernunft er wiederum erwacht.", "tokens": ["Wenn", "zur", "Ver\u00b7nunft", "er", "wie\u00b7de\u00b7rum", "er\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Er sagt, man k\u00f6nne nicht die Welt in Zahlen fassen,", "tokens": ["Er", "sagt", ",", "man", "k\u00f6n\u00b7ne", "nicht", "die", "Welt", "in", "Zah\u00b7len", "fas\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PIS", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und will noch Tolleres uns glauben lassen.", "tokens": ["Und", "will", "noch", "Tol\u00b7le\u00b7res", "uns", "glau\u00b7ben", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJA", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und nicht genug an dem, er spricht auch von Atomen,", "tokens": ["Und", "nicht", "ge\u00b7nug", "an", "dem", ",", "er", "spricht", "auch", "von", "A\u00b7to\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "APPR", "ART", "$,", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So wie ein andrer wohl von seinen Kindern spricht;", "tokens": ["So", "wie", "ein", "an\u00b7drer", "wohl", "von", "sei\u00b7nen", "Kin\u00b7dern", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und ohne da\u00df er sich vom Platz bewegt,", "tokens": ["Und", "oh\u00b7ne", "da\u00df", "er", "sich", "vom", "Platz", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Erhebt er sich zu allen Himmelsdomen,", "tokens": ["Er\u00b7hebt", "er", "sich", "zu", "al\u00b7len", "Him\u00b7mels\u00b7do\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "An die er k\u00fchn den Ma\u00dfstab legt.", "tokens": ["An", "die", "er", "k\u00fchn", "den", "Ma\u00df\u00b7stab", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Er kennt das Weltall, doch sich selber nicht.", "tokens": ["Er", "kennt", "das", "Wel\u00b7tall", ",", "doch", "sich", "sel\u00b7ber", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "PRF", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Wie mitteilsam ist er doch einst gewesen,", "tokens": ["Wie", "mit\u00b7teil\u00b7sam", "ist", "er", "doch", "einst", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "ADV", "VAPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Der jetzt nur mit sich selber spricht;", "tokens": ["Der", "jetzt", "nur", "mit", "sich", "sel\u00b7ber", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "O kommt und la\u00dft den armen Mann genesen!\u00ab", "tokens": ["O", "kommt", "und", "la\u00dft", "den", "ar\u00b7men", "Mann", "ge\u00b7ne\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "KON", "VVIMP", "ART", "ADJA", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Hippokrates kam solche Kunde seltsam vor,", "tokens": ["Hip\u00b7po\u00b7kra\u00b7tes", "kam", "sol\u00b7che", "Kun\u00b7de", "selt\u00b7sam", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.36": {"text": "Doch ging er hin, und das Geschick erkor", "tokens": ["Doch", "ging", "er", "hin", ",", "und", "das", "Ge\u00b7schick", "er\u00b7kor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "ART", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "F\u00fcr die Begegnung den gerechten Augenblick.", "tokens": ["F\u00fcr", "die", "Be\u00b7geg\u00b7nung", "den", "ge\u00b7rech\u00b7ten", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Denn Hippokrat traf ihn, von dem es hie\u00df,", "tokens": ["Denn", "Hip\u00b7po\u00b7krat", "traf", "ihn", ",", "von", "dem", "es", "hie\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Da\u00df die Vernunft ihn l\u00e4ngst verlie\u00df,", "tokens": ["Da\u00df", "die", "Ver\u00b7nunft", "ihn", "l\u00e4ngst", "ver\u00b7lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Dabei, wie er mit ernstem Forscherblick", "tokens": ["Da\u00b7bei", ",", "wie", "er", "mit", "erns\u00b7tem", "For\u00b7scher\u00b7blick"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "$,", "PWAV", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Zu finden strebte, wo bei Mensch und Tier", "tokens": ["Zu", "fin\u00b7den", "streb\u00b7te", ",", "wo", "bei", "Mensch", "und", "Tier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VVFIN", "$,", "PWAV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.42": {"text": "Der Sitz f\u00fcr den Verstand zu suchen sei:", "tokens": ["Der", "Sitz", "f\u00fcr", "den", "Ver\u00b7stand", "zu", "su\u00b7chen", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Ob Herz, ob Hirn wohl w\u00e4re sein Revier.", "tokens": ["Ob", "Herz", ",", "ob", "Hirn", "wohl", "w\u00e4\u00b7re", "sein", "Re\u00b7vier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "So sa\u00df er da im Schatten k\u00fchler B\u00e4ume", "tokens": ["So", "sa\u00df", "er", "da", "im", "Schat\u00b7ten", "k\u00fch\u00b7ler", "B\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.45": {"text": "Und sp\u00e4hte in die Windungen und R\u00e4ume", "tokens": ["Und", "sp\u00e4h\u00b7te", "in", "die", "Win\u00b7dun\u00b7gen", "und", "R\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Von eines Menschenhirnes Labyrinth,", "tokens": ["Von", "ei\u00b7nes", "Men\u00b7schen\u00b7hir\u00b7nes", "La\u00b7by\u00b7rinth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.47": {"text": "Und weise B\u00fccher lagen ihm zu F\u00fc\u00dfen.", "tokens": ["Und", "wei\u00b7se", "B\u00fc\u00b7cher", "la\u00b7gen", "ihm", "zu", "F\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.48": {"text": "F\u00fcr die Natur rundum ist unser Forscher blind,", "tokens": ["F\u00fcr", "die", "Na\u00b7tur", "run\u00b7dum", "ist", "un\u00b7ser", "For\u00b7scher", "blind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Der auch des Freundes Nahen erst gewahrt,", "tokens": ["Der", "auch", "des", "Freun\u00b7des", "Na\u00b7hen", "erst", "ge\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.50": {"text": "Als schon vertraute Worte ihn begr\u00fc\u00dfen.", "tokens": ["Als", "schon", "ver\u00b7trau\u00b7te", "Wor\u00b7te", "ihn", "be\u00b7gr\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "Und weil der Weise gerne Worte spart", "tokens": ["Und", "weil", "der", "Wei\u00b7se", "ger\u00b7ne", "Wor\u00b7te", "spart"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.52": {"text": "Und ihm leichtfertiges Geplauder fremd", "tokens": ["Und", "ihm", "leicht\u00b7fer\u00b7ti\u00b7ges", "Ge\u00b7plau\u00b7der", "fremd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJA", "NN", "ADJD"], "meter": "+-++-+-+-+", "measure": "zehnsilber"}, "line.53": {"text": "Und hier den Geistesflug kein Lauscher hemmt,", "tokens": ["Und", "hier", "den", "Geis\u00b7tes\u00b7flug", "kein", "Lau\u00b7scher", "hemmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "So sprechen sie von Mensch und Menschenseelen,", "tokens": ["So", "spre\u00b7chen", "sie", "von", "Mensch", "und", "Men\u00b7schen\u00b7see\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.55": {"text": "Und auch die Nutzanwendung lassen sie nicht fehlen.", "tokens": ["Und", "auch", "die", "Nut\u00b7zan\u00b7wen\u00b7dung", "las\u00b7sen", "sie", "nicht", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Es ist nicht n\u00f6tig, da\u00df ich lang und breit", "tokens": ["Es", "ist", "nicht", "n\u00f6\u00b7tig", ",", "da\u00df", "ich", "lang", "und", "breit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.57": {"text": "Euch hier berichte jede Einzelheit.", "tokens": ["Euch", "hier", "be\u00b7rich\u00b7te", "je\u00b7de", "Ein\u00b7zel\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "Das Vorgesagte mag als Weisung euch gen\u00fcgen,", "tokens": ["Das", "Vor\u00b7ge\u00b7sag\u00b7te", "mag", "als", "Wei\u00b7sung", "euch", "ge\u00b7n\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "KOUS", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Da\u00df man des Volkes Urteil, eh man's glaubt, ermi\u00dft,", "tokens": ["Da\u00df", "man", "des", "Vol\u00b7kes", "Ur\u00b7teil", ",", "eh", "man's", "glaubt", ",", "er\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "NN", "$,", "KOUS", "PIS", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Und straft zugleich den Ausspruch L\u00fcgen,", "tokens": ["Und", "straft", "zu\u00b7gleich", "den", "Aus\u00b7spruch", "L\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "Da\u00df Volkes Stimme Gottes Stimme ist.", "tokens": ["Da\u00df", "Vol\u00b7kes", "Stim\u00b7me", "Got\u00b7tes", "Stim\u00b7me", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}