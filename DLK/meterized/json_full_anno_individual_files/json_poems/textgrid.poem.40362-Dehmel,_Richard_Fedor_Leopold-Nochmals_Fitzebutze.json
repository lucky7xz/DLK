{"textgrid.poem.40362": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Nochmals Fitzebutze", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lieber, \u00df\u00f6ner Hampelmann!", "tokens": ["Lie\u00b7ber", ",", "\u00df\u00f6\u00b7ner", "Ham\u00b7pel\u00b7mann", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fing die kleine Detta an.", "tokens": ["fing", "die", "klei\u00b7ne", "Det\u00b7ta", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bin dho\u00df, und Du bist tlein;", "tokens": ["Ich", "bin", "dho\u00df", ",", "und", "Du", "bist", "tlein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "$,", "KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "willst du Fitzebutze sein?", "tokens": ["willst", "du", "Fit\u00b7ze\u00b7but\u00b7ze", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "tomm!", "tokens": ["tomm", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-", "measure": "single.down"}}, "stanza.2": {"line.1": {"text": "Tomm auf Haterns dho\u00dfen Tuhl,", "tokens": ["Tomm", "auf", "Ha\u00b7terns", "dho\u00b7\u00dfen", "Tuhl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vitzliputze, Blitzepul!", "tokens": ["Vitz\u00b7li\u00b7put\u00b7ze", ",", "Blit\u00b7ze\u00b7pul", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hater sagt, man wei\u00df es nicht,", "tokens": ["Ha\u00b7ter", "sagt", ",", "man", "wei\u00df", "es", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wie man deinen Namen sp'icht;", "tokens": ["wie", "man", "dei\u00b7nen", "Na\u00b7men", "sp'\u00b7icht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "pst!", "tokens": ["pst", "!"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}}, "stanza.3": {"line.1": {"text": "Pst, sagt Hater, Fitzebott", "tokens": ["Pst", ",", "sagt", "Ha\u00b7ter", ",", "Fit\u00b7ze\u00b7bott"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$,", "VVFIN", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "war eimal ein lieber Dott,", "tokens": ["war", "ei\u00b7mal", "ein", "lie\u00b7ber", "Dott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "der auf einem Tuhle sa\u00df", "tokens": ["der", "auf", "ei\u00b7nem", "Tuh\u00b7le", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und sebratne Men\u00dfen a\u00df;", "tokens": ["und", "seb\u00b7rat\u00b7ne", "Men\u00b7\u00dfen", "a\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "huh! \u2013", "tokens": ["huh", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ADJD", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Huh, da sah der Hampelmann", "tokens": ["Huh", ",", "da", "sah", "der", "Ham\u00b7pel\u00b7mann"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "furchtbar gro\u00df die Detta an,", "tokens": ["furcht\u00b7bar", "gro\u00df", "die", "Det\u00b7ta", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und sein alter Bommelhut", "tokens": ["und", "sein", "al\u00b7ter", "Bom\u00b7mel\u00b7hut"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "kullerte vom Stuhl vor Wut,", "tokens": ["kul\u00b7ler\u00b7te", "vom", "Stuhl", "vor", "Wut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "plumps.", "tokens": ["plumps", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-", "measure": "single.down"}}, "stanza.5": {"line.1": {"text": "Plum\u00df, sprach Detta; willste woll!", "tokens": ["Plum\u00df", ",", "sprach", "Det\u00b7ta", ";", "wills\u00b7te", "woll", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "NE", "$.", "VMFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sei doch nich so \u00dfrecklich doll!", "tokens": ["sei", "doch", "nich", "so", "\u00dfreck\u00b7lich", "doll", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mutter sagt, der liebe Dott", "tokens": ["Mut\u00b7ter", "sagt", ",", "der", "lie\u00b7be", "Dott"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "donnert nicht in einem f'ot;", "tokens": ["don\u00b7nert", "nicht", "in", "ei\u00b7nem", "f'\u00b7ot", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "nein!", "tokens": ["nein", "!"], "token_info": ["word", "punct"], "pos": ["PTKANT", "$."], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Nein, sagt Mutti, Dott ist dut,", "tokens": ["Nein", ",", "sagt", "Mut\u00b7ti", ",", "Dott", "ist", "dut", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "NN", "$,", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn man a'tig beten tut.", "tokens": ["wenn", "man", "a'\u00b7tig", "be\u00b7ten", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fitzebutze, h\u00f6r mal an,", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "h\u00f6r", "mal", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was die Detta alles kann;", "tokens": ["was", "die", "Det\u00b7ta", "al\u00b7les", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PIS", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ei! \u2013", "tokens": ["ei", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ITJ", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.7": {"line.1": {"text": "Ei, da sa\u00df der Blitzepul", "tokens": ["Ei", ",", "da", "sa\u00df", "der", "Blit\u00b7ze\u00b7pul"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "m\u00e4uschenstill auf seinem Stuhl,", "tokens": ["m\u00e4u\u00b7schen\u00b7still", "auf", "sei\u00b7nem", "Stuhl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und sprach heimlich alles nach,", "tokens": ["und", "sprach", "heim\u00b7lich", "al\u00b7les", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was die kleine Detta sprach;", "tokens": ["was", "die", "klei\u00b7ne", "Det\u00b7ta", "sprach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ah!", "tokens": ["ah", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}}, "stanza.8": {"line.1": {"text": "Ah, die sprach ja nun sofort", "tokens": ["Ah", ",", "die", "sprach", "ja", "nun", "so\u00b7fort"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVFIN", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "alles richtig, jedes Wort!", "tokens": ["al\u00b7les", "rich\u00b7tig", ",", "je\u00b7des", "Wort", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "ADJD", "$,", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, ihr Klugen: merkt ihr was?", "tokens": ["Ja", ",", "ihr", "Klu\u00b7gen", ":", "merkt", "ihr", "was", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dumm tun tat sie blos zum Spa\u00df.", "tokens": ["dumm", "tun", "tat", "sie", "blos", "zum", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Also h\u00f6rt!", "tokens": ["Al\u00b7so", "h\u00f6rt", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Lieber, \u00df\u00f6ner Hampelmann!", "tokens": ["Lie\u00b7ber", ",", "\u00df\u00f6\u00b7ner", "Ham\u00b7pel\u00b7mann", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fing die kleine Detta an.", "tokens": ["fing", "die", "klei\u00b7ne", "Det\u00b7ta", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bin dho\u00df, und Du bist tlein;", "tokens": ["Ich", "bin", "dho\u00df", ",", "und", "Du", "bist", "tlein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "$,", "KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "willst du Fitzebutze sein?", "tokens": ["willst", "du", "Fit\u00b7ze\u00b7but\u00b7ze", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "tomm!", "tokens": ["tomm", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-", "measure": "single.down"}}, "stanza.10": {"line.1": {"text": "Tomm auf Haterns dho\u00dfen Tuhl,", "tokens": ["Tomm", "auf", "Ha\u00b7terns", "dho\u00b7\u00dfen", "Tuhl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vitzliputze, Blitzepul!", "tokens": ["Vitz\u00b7li\u00b7put\u00b7ze", ",", "Blit\u00b7ze\u00b7pul", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hater sagt, man wei\u00df es nicht,", "tokens": ["Ha\u00b7ter", "sagt", ",", "man", "wei\u00df", "es", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wie man deinen Namen sp'icht;", "tokens": ["wie", "man", "dei\u00b7nen", "Na\u00b7men", "sp'\u00b7icht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "pst!", "tokens": ["pst", "!"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}}, "stanza.11": {"line.1": {"text": "Pst, sagt Hater, Fitzebott", "tokens": ["Pst", ",", "sagt", "Ha\u00b7ter", ",", "Fit\u00b7ze\u00b7bott"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$,", "VVFIN", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "war eimal ein lieber Dott,", "tokens": ["war", "ei\u00b7mal", "ein", "lie\u00b7ber", "Dott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "der auf einem Tuhle sa\u00df", "tokens": ["der", "auf", "ei\u00b7nem", "Tuh\u00b7le", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und sebratne Men\u00dfen a\u00df;", "tokens": ["und", "seb\u00b7rat\u00b7ne", "Men\u00b7\u00dfen", "a\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "huh! \u2013", "tokens": ["huh", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ADJD", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.12": {"line.1": {"text": "Huh, da sah der Hampelmann", "tokens": ["Huh", ",", "da", "sah", "der", "Ham\u00b7pel\u00b7mann"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "furchtbar gro\u00df die Detta an,", "tokens": ["furcht\u00b7bar", "gro\u00df", "die", "Det\u00b7ta", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und sein alter Bommelhut", "tokens": ["und", "sein", "al\u00b7ter", "Bom\u00b7mel\u00b7hut"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "kullerte vom Stuhl vor Wut,", "tokens": ["kul\u00b7ler\u00b7te", "vom", "Stuhl", "vor", "Wut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "plumps.", "tokens": ["plumps", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-", "measure": "single.down"}}, "stanza.13": {"line.1": {"text": "Plum\u00df, sprach Detta; willste woll!", "tokens": ["Plum\u00df", ",", "sprach", "Det\u00b7ta", ";", "wills\u00b7te", "woll", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "NE", "$.", "VMFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sei doch nich so \u00dfrecklich doll!", "tokens": ["sei", "doch", "nich", "so", "\u00dfreck\u00b7lich", "doll", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mutter sagt, der liebe Dott", "tokens": ["Mut\u00b7ter", "sagt", ",", "der", "lie\u00b7be", "Dott"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "donnert nicht in einem f'ot;", "tokens": ["don\u00b7nert", "nicht", "in", "ei\u00b7nem", "f'\u00b7ot", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "nein!", "tokens": ["nein", "!"], "token_info": ["word", "punct"], "pos": ["PTKANT", "$."], "meter": "+", "measure": "single.up"}}, "stanza.14": {"line.1": {"text": "Nein, sagt Mutti, Dott ist dut,", "tokens": ["Nein", ",", "sagt", "Mut\u00b7ti", ",", "Dott", "ist", "dut", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "NN", "$,", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn man a'tig beten tut.", "tokens": ["wenn", "man", "a'\u00b7tig", "be\u00b7ten", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fitzebutze, h\u00f6r mal an,", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "h\u00f6r", "mal", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was die Detta alles kann;", "tokens": ["was", "die", "Det\u00b7ta", "al\u00b7les", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PIS", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ei! \u2013", "tokens": ["ei", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ITJ", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.15": {"line.1": {"text": "Ei, da sa\u00df der Blitzepul", "tokens": ["Ei", ",", "da", "sa\u00df", "der", "Blit\u00b7ze\u00b7pul"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "m\u00e4uschenstill auf seinem Stuhl,", "tokens": ["m\u00e4u\u00b7schen\u00b7still", "auf", "sei\u00b7nem", "Stuhl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und sprach heimlich alles nach,", "tokens": ["und", "sprach", "heim\u00b7lich", "al\u00b7les", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was die kleine Detta sprach;", "tokens": ["was", "die", "klei\u00b7ne", "Det\u00b7ta", "sprach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ah!", "tokens": ["ah", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}}, "stanza.16": {"line.1": {"text": "Ah, die sprach ja nun sofort", "tokens": ["Ah", ",", "die", "sprach", "ja", "nun", "so\u00b7fort"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVFIN", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "alles richtig, jedes Wort!", "tokens": ["al\u00b7les", "rich\u00b7tig", ",", "je\u00b7des", "Wort", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "ADJD", "$,", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, ihr Klugen: merkt ihr was?", "tokens": ["Ja", ",", "ihr", "Klu\u00b7gen", ":", "merkt", "ihr", "was", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dumm tun tat sie blos zum Spa\u00df.", "tokens": ["dumm", "tun", "tat", "sie", "blos", "zum", "Spa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Also h\u00f6rt!", "tokens": ["Al\u00b7so", "h\u00f6rt", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}