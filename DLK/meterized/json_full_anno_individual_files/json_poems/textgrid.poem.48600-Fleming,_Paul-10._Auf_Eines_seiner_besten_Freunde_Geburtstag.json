{"textgrid.poem.48600": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "10. Auf Eines seiner besten Freunde Geburtstag", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sind wir itzt nicht in dem Maien,", "tokens": ["Sind", "wir", "itzt", "nicht", "in", "dem", "Mai\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "in der besten Jahreszeit,", "tokens": ["in", "der", "bes\u00b7ten", "Jah\u00b7res\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da man Alles sich sieht freuen,", "tokens": ["da", "man", "Al\u00b7les", "sich", "sieht", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "PRF", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was sich reget weit und breit,", "tokens": ["was", "sich", "re\u00b7get", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "da die stolze Welt sich putzt", "tokens": ["da", "die", "stol\u00b7ze", "Welt", "sich", "putzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und in jungem Schmucke stutzt?", "tokens": ["und", "in", "jun\u00b7gem", "Schmu\u00b7cke", "stutzt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Du nur wilst dich nicht bequemen", "tokens": ["Du", "nur", "wilst", "dich", "nicht", "be\u00b7que\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "PTKNEG", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "zu der s\u00fc\u00dfen Liebligkeit", "tokens": ["zu", "der", "s\u00fc\u00b7\u00dfen", "Lieb\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und die Freude mitte nehmen,", "tokens": ["und", "die", "Freu\u00b7de", "mit\u00b7te", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so sich giebet dieser Zeit?", "tokens": ["so", "sich", "gie\u00b7bet", "die\u00b7ser", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du nur tust nicht, kleine Welt,", "tokens": ["Du", "nur", "tust", "nicht", ",", "klei\u00b7ne", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "was der gro\u00dfen so gef\u00e4llt?", "tokens": ["was", "der", "gro\u00b7\u00dfen", "so", "ge\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Gib den m\u00fcden B\u00fcchern Feier!", "tokens": ["Gib", "den", "m\u00fc\u00b7den", "B\u00fc\u00b7chern", "Fei\u00b7er", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tu die matte Feder hin!", "tokens": ["Tu", "die", "mat\u00b7te", "Fe\u00b7der", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was du hast erlebet heuer,", "tokens": ["Was", "du", "hast", "er\u00b7le\u00b7bet", "heu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wird dirs \u00fcbers Jahr nachziehn?", "tokens": ["wird", "dirs", "\u00fc\u00b7bers", "Jahr", "nach\u00b7ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ists, dem du dich verbannst", "tokens": ["Was", "ists", ",", "dem", "du", "dich", "ver\u00b7bannst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "PPER", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und in ein solch Joch dich spannst?", "tokens": ["und", "in", "ein", "solch", "Joch", "dich", "spannst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Was der von Stagyr geschrieben,", "tokens": ["Was", "der", "von", "Sta\u00b7gyr", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Plato, was du hast erdacht,", "tokens": ["Pla\u00b7to", ",", "was", "du", "hast", "er\u00b7dacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "das ist Alles nach euch blieben;", "tokens": ["das", "ist", "Al\u00b7les", "nach", "euch", "blie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ihr nur gabet gute Nacht.", "tokens": ["ihr", "nur", "ga\u00b7bet", "gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist denn di\u00df die gro\u00dfe Frucht,", "tokens": ["Ist", "denn", "di\u00df", "die", "gro\u00b7\u00dfe", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "die man in dem Schreiben sucht?", "tokens": ["die", "man", "in", "dem", "Schrei\u00b7ben", "sucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Mein! Was hilft es doch dem Dichter,", "tokens": ["Mein", "!", "Was", "hilft", "es", "doch", "dem", "Dich\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df sein Flei\u00df ihn \u00fcberlebt?", "tokens": ["da\u00df", "sein", "Flei\u00df", "ihn", "\u00fc\u00b7ber\u00b7lebt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwar ein Ieder ist hier Richter,", "tokens": ["Zwar", "ein", "Ie\u00b7der", "ist", "hier", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df er hat auf Ruhm gestrebt.", "tokens": ["da\u00df", "er", "hat", "auf", "Ruhm", "ge\u00b7strebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber was geneu\u00dfts der Man,", "tokens": ["A\u00b7ber", "was", "ge\u00b7neu\u00dfts", "der", "Man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "ART", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der schon l\u00e4ngst ist beigetan?", "tokens": ["der", "schon", "l\u00e4ngst", "ist", "bei\u00b7ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Eh' man etwas T\u00fcchtigs schreibet,", "tokens": ["Eh'", "man", "et\u00b7was", "T\u00fcch\u00b7tigs", "schrei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lauft f\u00fcrwar viel Zeit vorbei.", "tokens": ["lauft", "f\u00fcr\u00b7war", "viel", "Zeit", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was ists, das nach uns bleibet?", "tokens": ["Und", "was", "ists", ",", "das", "nach", "uns", "blei\u00b7bet", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein vergebliches Geschrei,", "tokens": ["Ein", "ver\u00b7geb\u00b7li\u00b7ches", "Ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "das derselbe doch nicht h\u00f6ret,", "tokens": ["das", "der\u00b7sel\u00b7be", "doch", "nicht", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PDAT", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der darmitte wird geehret.", "tokens": ["der", "dar\u00b7mit\u00b7te", "wird", "ge\u00b7eh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Geben dir die G\u00f6tter Gaben", "tokens": ["Ge\u00b7ben", "dir", "die", "G\u00f6t\u00b7ter", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und verehren dich mit Kunst,", "tokens": ["und", "ver\u00b7eh\u00b7ren", "dich", "mit", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df du des kanst Ehre haben", "tokens": ["da\u00df", "du", "des", "kanst", "Eh\u00b7re", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und verdienen Vieler Gunst,", "tokens": ["und", "ver\u00b7die\u00b7nen", "Vie\u00b7ler", "Gunst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "so gedenk doch auch darbei,", "tokens": ["so", "ge\u00b7denk", "doch", "auch", "dar\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wie ein eitel Ding das sei!", "tokens": ["wie", "ein", "ei\u00b7tel", "Ding", "das", "sei", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PDS", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wo sind Perianders Schriften,", "tokens": ["Wo", "sind", "Pe\u00b7ri\u00b7an\u00b7ders", "Schrif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Chilon, Thales, Pittakus?", "tokens": ["Chi\u00b7lon", ",", "Tha\u00b7les", ",", "Pit\u00b7ta\u00b7kus", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ihr Flei\u00df flog nach den L\u00fcften,", "tokens": ["Weil", "ihr", "Flei\u00df", "flog", "nach", "den", "L\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sind die Namen auch Verdru\u00df.", "tokens": ["sind", "die", "Na\u00b7men", "auch", "Ver\u00b7dru\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie viel hundert Andre sein", "tokens": ["Wie", "viel", "hun\u00b7dert", "And\u00b7re", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "CARD", "PIS", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mit dem Namen gangen ein!", "tokens": ["mit", "dem", "Na\u00b7men", "gan\u00b7gen", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Haben sie bei ihrer M\u00fche", "tokens": ["Ha\u00b7ben", "sie", "bei", "ih\u00b7rer", "M\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "nicht Ergetzligkeit gehabt", "tokens": ["nicht", "Er\u00b7getz\u00b7lig\u00b7keit", "ge\u00b7habt"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "NN", "VAPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und sich, wenns die Zeit verliehe,", "tokens": ["und", "sich", ",", "wenns", "die", "Zeit", "ver\u00b7lie\u00b7he", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht mit lieber Lust erlabt,", "tokens": ["nicht", "mit", "lie\u00b7ber", "Lust", "er\u00b7labt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "was denn wird wol ihre sein,", "tokens": ["was", "denn", "wird", "wol", "ih\u00b7re", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "PPOSAT", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "nun auch nicht mehr ist ihr Schein?", "tokens": ["nun", "auch", "nicht", "mehr", "ist", "ihr", "Schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Lebe, weil du bist im Leben,", "tokens": ["Le\u00b7be", ",", "weil", "du", "bist", "im", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und gebrauche deiner Lust;", "tokens": ["und", "ge\u00b7brau\u00b7che", "dei\u00b7ner", "Lust", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "doch sei nicht zu sehr ergeben", "tokens": ["doch", "sei", "nicht", "zu", "sehr", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PTKNEG", "PTKA", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dem, das du bald meiden mu\u00dft!", "tokens": ["dem", ",", "das", "du", "bald", "mei\u00b7den", "mu\u00dft", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denke, da\u00df du auch einmal", "tokens": ["Den\u00b7ke", ",", "da\u00df", "du", "auch", "ein\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wol berechnest deine Zahl!", "tokens": ["wol", "be\u00b7rech\u00b7nest", "dei\u00b7ne", "Zahl", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Gott verwehrt uns keine Freuden,", "tokens": ["Gott", "ver\u00b7wehrt", "uns", "kei\u00b7ne", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wann sie Freuden bleiben nur,", "tokens": ["wann", "sie", "Freu\u00b7den", "blei\u00b7ben", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn wir hierbei nur vermeiden,", "tokens": ["wenn", "wir", "hier\u00b7bei", "nur", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was lockt auf der Wollust Spur.", "tokens": ["was", "lockt", "auf", "der", "Wol\u00b7lust", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und wie kan di\u00df Freude sein,", "tokens": ["Und", "wie", "kan", "di\u00df", "Freu\u00b7de", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PDS", "NN", "VAINF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "was sie nur ist auf den Schein?", "tokens": ["was", "sie", "nur", "ist", "auf", "den", "Schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Was hilft das zu Tode-Saufen,", "tokens": ["Was", "hilft", "das", "zu", "To\u00b7de\u00b7\u00b7Sau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDS", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "das Verleihen seinen Leib,", "tokens": ["das", "Ver\u00b7lei\u00b7hen", "sei\u00b7nen", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "das um Wollust Reue-Kaufen,", "tokens": ["das", "um", "Wol\u00b7lust", "Reu\u00b7e\u00b7Kau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Borgen eines Andern Weib?", "tokens": ["Bor\u00b7gen", "ei\u00b7nes", "An\u00b7dern", "Weib", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist das Freude, hei\u00dft das Lust,", "tokens": ["Ist", "das", "Freu\u00b7de", ",", "hei\u00dft", "das", "Lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df du Schande haben mu\u00dft?", "tokens": ["da\u00df", "du", "Schan\u00b7de", "ha\u00b7ben", "mu\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Was f\u00fcr Freuden mir behagen,", "tokens": ["Was", "f\u00fcr", "Freu\u00b7den", "mir", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sind von schn\u00f6den L\u00fcsten weit.", "tokens": ["sind", "von", "schn\u00f6\u00b7den", "L\u00fcs\u00b7ten", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Worzu mich die Sinnen tragen,", "tokens": ["Wor\u00b7zu", "mich", "die", "Sin\u00b7nen", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ist verg\u00f6nnte Fr\u00f6ligkeit.", "tokens": ["ist", "ver\u00b7g\u00f6nn\u00b7te", "Fr\u00f6\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ist ehrbar, was ger\u00fchmt,", "tokens": ["Was", "ist", "ehr\u00b7bar", ",", "was", "ge\u00b7r\u00fchmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "$,", "PRELS", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "was bedachte Weisen ziemt,", "tokens": ["was", "be\u00b7dach\u00b7te", "Wei\u00b7sen", "ziemt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "was die m\u00fcde Seele speiset", "tokens": ["was", "die", "m\u00fc\u00b7de", "See\u00b7le", "spei\u00b7set"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und den lassen Leib ergetzt,", "tokens": ["und", "den", "las\u00b7sen", "Leib", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "was zum h\u00f6chsten Gut uns weiset", "tokens": ["was", "zum", "h\u00f6chs\u00b7ten", "Gut", "uns", "wei\u00b7set"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPRART", "ADJA", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und in sanften Wolstand setzt:", "tokens": ["und", "in", "sanf\u00b7ten", "Wol\u00b7stand", "setzt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ich, du, der und alle wir", "tokens": ["ich", ",", "du", ",", "der", "und", "al\u00b7le", "wir"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PPER", "$,", "PRELS", "KON", "PIS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "sind von dessen wegen hier.", "tokens": ["sind", "von", "des\u00b7sen", "we\u00b7gen", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDS", "APPR", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Itzund la\u00df dich von mir f\u00fchren", "tokens": ["It\u00b7zund", "la\u00df", "dich", "von", "mir", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in der feuchten ", "tokens": ["in", "der", "feuch\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "da\u00df wir sehn die Flora zieren", "tokens": ["da\u00df", "wir", "sehn", "die", "Flo\u00b7ra", "zie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ihrer langen Wiesen Saal,", "tokens": ["ih\u00b7rer", "lan\u00b7gen", "Wie\u00b7sen", "Saal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wie sie um die B\u00e4ume tanzt", "tokens": ["wie", "sie", "um", "die", "B\u00e4u\u00b7me", "tanzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "und manch sch\u00f6nes Bl\u00fcmlein pflanzt!", "tokens": ["und", "manch", "sch\u00f6\u00b7nes", "Bl\u00fcm\u00b7lein", "pflanzt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ist schon hier nichts aus Idumen", "tokens": ["Ist", "schon", "hier", "nichts", "aus", "I\u00b7du\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und was her k\u00f6mmt \u00fcber See,", "tokens": ["und", "was", "her", "k\u00f6mmt", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APZR", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ei, so sind doch Maienblumen,", "tokens": ["ei", ",", "so", "sind", "doch", "Mai\u00b7en\u00b7blu\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "feister Schmergel, dicker Klee.", "tokens": ["feis\u00b7ter", "Schmer\u00b7gel", ",", "di\u00b7cker", "Klee", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Haben wir schon Fremdes nicht,", "tokens": ["Ha\u00b7ben", "wir", "schon", "Frem\u00b7des", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "doch an Lust drum nichts gebricht.", "tokens": ["doch", "an", "Lust", "drum", "nichts", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PAV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Der gesunde Tau sinkt nieder,", "tokens": ["Der", "ge\u00b7sun\u00b7de", "Tau", "sinkt", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das gezogne Kind der Nacht,", "tokens": ["das", "ge\u00b7zog\u00b7ne", "Kind", "der", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der der matten Kr\u00e4uter Glieder", "tokens": ["der", "der", "mat\u00b7ten", "Kr\u00e4u\u00b7ter", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wieder steif und saftig macht,", "tokens": ["wie\u00b7der", "steif", "und", "saf\u00b7tig", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der die welken Blumen tr\u00e4nkt", "tokens": ["der", "die", "wel\u00b7ken", "Blu\u00b7men", "tr\u00e4nkt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und in ihre Scho\u00df sich senkt.", "tokens": ["und", "in", "ih\u00b7re", "Scho\u00df", "sich", "senkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Zynthius streckt her von oben", "tokens": ["Zynt\u00b7hi\u00b7us", "streckt", "her", "von", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ADV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "seines Goldes reinen Schein,", "tokens": ["sei\u00b7nes", "Gol\u00b7des", "rei\u00b7nen", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn er itzt sein H\u00e4upt erhoben", "tokens": ["wenn", "er", "itzt", "sein", "H\u00e4upt", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und f\u00e4ngt munter an zu sein,", "tokens": ["und", "f\u00e4ngt", "mun\u00b7ter", "an", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wenn er seine Glut aufsteckt", "tokens": ["wenn", "er", "sei\u00b7ne", "Glut", "auf\u00b7steckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und die faule Welt erweckt.", "tokens": ["und", "die", "fau\u00b7le", "Welt", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Vor ihm her k\u00f6mt hergegangen", "tokens": ["Vor", "ihm", "her", "k\u00f6mt", "her\u00b7ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "APZR", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die Zertreiberin der Nacht", "tokens": ["die", "Zer\u00b7trei\u00b7be\u00b7rin", "der", "Nacht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "in den purpurbraunen Wangen,", "tokens": ["in", "den", "pur\u00b7pur\u00b7brau\u00b7nen", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der Anemonen Tracht,", "tokens": ["in", "der", "A\u00b7ne\u00b7mo\u00b7nen", "Tracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die denn balde, wenn er k\u00f6mmt,", "tokens": ["die", "denn", "bal\u00b7de", ",", "wenn", "er", "k\u00f6mmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "schamrot ihren Abschied nimmt.", "tokens": ["scham\u00b7rot", "ih\u00b7ren", "Ab\u00b7schied", "nimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Und itzt ist vor zweien Stunden,", "tokens": ["Und", "itzt", "ist", "vor", "zwei\u00b7en", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "APPR", "CARD", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "als es noch war tiefe Nacht,", "tokens": ["als", "es", "noch", "war", "tie\u00b7fe", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "eh' es Iemand hat empfunden,", "tokens": ["eh'", "es", "Ie\u00b7mand", "hat", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schon die Nachtigal erwacht,", "tokens": ["schon", "die", "Nach\u00b7ti\u00b7gal", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "welche denn verf\u00fchret schon", "tokens": ["wel\u00b7che", "denn", "ver\u00b7f\u00fch\u00b7ret", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["PRELS", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "manchen lieben s\u00fc\u00dfen Ton.", "tokens": ["man\u00b7chen", "lie\u00b7ben", "s\u00fc\u00b7\u00dfen", "Ton", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Nun begr\u00fc\u00dfen auch die Andern,", "tokens": ["Nun", "be\u00b7gr\u00fc\u00b7\u00dfen", "auch", "die", "An\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die kein Nest mehr halten mag", "tokens": ["die", "kein", "Nest", "mehr", "hal\u00b7ten", "mag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "ADV", "VVINF", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und durch freie L\u00fcfte wandern,", "tokens": ["und", "durch", "frei\u00b7e", "L\u00fcf\u00b7te", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "durch ihr Lied den jungen Tag.", "tokens": ["durch", "ihr", "Lied", "den", "jun\u00b7gen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Keines will vom Andern ein", "tokens": ["Kei\u00b7nes", "will", "vom", "An\u00b7dern", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPRART", "ADJA", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "in der Kunst getrieben sein.", "tokens": ["in", "der", "Kunst", "ge\u00b7trie\u00b7ben", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Siehst du, wie sich lieblich gatten", "tokens": ["Siehst", "du", ",", "wie", "sich", "lieb\u00b7lich", "gat\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "PRF", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hier ein P\u00e4rlein, dort ein Paar", "tokens": ["hier", "ein", "P\u00e4r\u00b7lein", ",", "dort", "ein", "Paar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "in der jungen Bl\u00e4tter Schatten?", "tokens": ["in", "der", "jun\u00b7gen", "Bl\u00e4t\u00b7ter", "Schat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie die stumme Wasserschaar", "tokens": ["Wie", "die", "stum\u00b7me", "Was\u00b7ser\u00b7schaar"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "an den sanften Ufern ringet", "tokens": ["an", "den", "sanf\u00b7ten", "U\u00b7fern", "rin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und sich um die Bulschaft dringet?", "tokens": ["und", "sich", "um", "die", "Bul\u00b7schaft", "drin\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Und die ausversch\u00e4mten Fr\u00f6sche", "tokens": ["Und", "die", "aus\u00b7ver\u00b7sch\u00e4m\u00b7ten", "Fr\u00f6\u00b7sche"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "haben Hochzeit schon gemacht,", "tokens": ["ha\u00b7ben", "Hoch\u00b7zeit", "schon", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "treiben ihr Koaxgew\u00e4sche", "tokens": ["trei\u00b7ben", "ihr", "Ko\u00b7ax\u00b7ge\u00b7w\u00e4\u00b7sche"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "von fr\u00fch' an bis in die Nacht;", "tokens": ["von", "fr\u00fch'", "an", "bis", "in", "die", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "APPR", "KON", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "von der Nacht bis wieder fr\u00fch'", "tokens": ["von", "der", "Nacht", "bis", "wie\u00b7der", "fr\u00fch'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "h\u00f6ret man sie schweigen nie.", "tokens": ["h\u00f6\u00b7ret", "man", "sie", "schwei\u00b7gen", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Hier la\u00df uns ein wenig schauen,", "tokens": ["Hier", "la\u00df", "uns", "ein", "we\u00b7nig", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ART", "PIS", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wie der Fischer Reusen legt,", "tokens": ["wie", "der", "Fi\u00b7scher", "Reu\u00b7sen", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wie der Feldman baut die Auen,", "tokens": ["wie", "der", "Feld\u00b7man", "baut", "die", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie der G\u00e4rtner B\u00e4ume hegt,", "tokens": ["wie", "der", "G\u00e4rt\u00b7ner", "B\u00e4u\u00b7me", "hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "oder wie die dicke Saat", "tokens": ["o\u00b7der", "wie", "die", "di\u00b7cke", "Saat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "halb schon gleich vorschosset hat!", "tokens": ["halb", "schon", "gleich", "vor\u00b7schos\u00b7set", "hat", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Dorte stehen feiste Rinder", "tokens": ["Dor\u00b7te", "ste\u00b7hen", "feis\u00b7te", "Rin\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in der Weide bis an Bauch.", "tokens": ["in", "der", "Wei\u00b7de", "bis", "an", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier sind Ziegen, so nichts minder", "tokens": ["Hier", "sind", "Zie\u00b7gen", ",", "so", "nichts", "min\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "$,", "ADV", "PIS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "blaten um den fetten Strauch.", "tokens": ["bla\u00b7ten", "um", "den", "fet\u00b7ten", "Strauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier gehn L\u00e4mmer, so f\u00fcr Lust", "tokens": ["Hier", "gehn", "L\u00e4m\u00b7mer", ",", "so", "f\u00fcr", "Lust"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "scherzen bei gesunder Kost.", "tokens": ["scher\u00b7zen", "bei", "ge\u00b7sun\u00b7der", "Kost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Hast du der Lust satt gepflogen,", "tokens": ["Hast", "du", "der", "Lust", "satt", "ge\u00b7pflo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wol! so lege dich mit mir", "tokens": ["wol", "!", "so", "le\u00b7ge", "dich", "mit", "mir"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "VVFIN", "PRF", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "unter den gew\u00f6lbten Bogen", "tokens": ["un\u00b7ter", "den", "ge\u00b7w\u00f6lb\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dieser hohen Linden hier,", "tokens": ["die\u00b7ser", "ho\u00b7hen", "Lin\u00b7den", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NE", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da denn solche sanfte Rast", "tokens": ["da", "denn", "sol\u00b7che", "sanf\u00b7te", "Rast"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "uns benimmt der Glieder Last!", "tokens": ["uns", "be\u00b7nimmt", "der", "Glie\u00b7der", "Last", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Was die V\u00f6gel tiriliren,", "tokens": ["Was", "die", "V\u00f6\u00b7gel", "ti\u00b7ri\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das hallt wider durch die Kluft;", "tokens": ["das", "hallt", "wi\u00b7der", "durch", "die", "Kluft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "was wir hier f\u00fcr Reden f\u00fchren,", "tokens": ["was", "wir", "hier", "f\u00fcr", "Re\u00b7den", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das verschweigt die stille Luft.", "tokens": ["das", "ver\u00b7schweigt", "die", "stil\u00b7le", "Luft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und da werd' ich melden viel,", "tokens": ["Und", "da", "werd'", "ich", "mel\u00b7den", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "das ich itzt nur denken will.", "tokens": ["das", "ich", "itzt", "nur", "den\u00b7ken", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "und was er mir macht f\u00fcr Plagen,", "tokens": ["und", "was", "er", "mir", "macht", "f\u00fcr", "Pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "seit er mir entrissen sich.", "tokens": ["seit", "er", "mir", "ent\u00b7ris\u00b7sen", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seit er sich von mir gewandt,", "tokens": ["Seit", "er", "sich", "von", "mir", "ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "bin ich selbst mir unbekant.", "tokens": ["bin", "ich", "selbst", "mir", "un\u00b7be\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Achtmal hat nun, als ich z\u00e4hle,", "tokens": ["Acht\u00b7mal", "hat", "nun", ",", "als", "ich", "z\u00e4h\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ph\u00f6be volle H\u00f6rner kriegt,", "tokens": ["Ph\u00f6\u00b7be", "vol\u00b7le", "H\u00f6r\u00b7ner", "kriegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df zoh' hin die fromme Seele,", "tokens": ["da\u00df", "zoh'", "hin", "die", "from\u00b7me", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df der liebe Leib erliegt,", "tokens": ["da\u00df", "der", "lie\u00b7be", "Leib", "er\u00b7liegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und so lange sterb' ich hin,", "tokens": ["und", "so", "lan\u00b7ge", "sterb'", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "weil ich ohn' mein Leben bin.", "tokens": ["weil", "ich", "ohn'", "mein", "Le\u00b7ben", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Wer sich einmal in den Orden", "tokens": ["Wer", "sich", "ein\u00b7mal", "in", "den", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "treuer Freundschaft hat gesetzt,", "tokens": ["treu\u00b7er", "Freund\u00b7schaft", "hat", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und ist ihm das Herz entworden,", "tokens": ["und", "ist", "ihm", "das", "Herz", "ent\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "das er \u00fcber alles sch\u00e4tzt,", "tokens": ["das", "er", "\u00fc\u00b7ber", "al\u00b7les", "sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der giebt sich zufrieden nicht,", "tokens": ["der", "giebt", "sich", "zu\u00b7frie\u00b7den", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PRF", "ADJD", "PTKNEG", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "bis auch er aus sich entbricht.", "tokens": ["bis", "auch", "er", "aus", "sich", "ent\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "APPR", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Was ich sinne, was ich denke,", "tokens": ["Was", "ich", "sin\u00b7ne", ",", "was", "ich", "den\u00b7ke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das ist ", "tokens": ["das", "ist"], "token_info": ["word", "word"], "pos": ["PDS", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Wo ich mein Gesicht' hin lenke,", "tokens": ["Wo", "ich", "mein", "Ge\u00b7sicht'", "hin", "len\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "schwebt sein Geist noch stets vor mir.", "tokens": ["schwebt", "sein", "Geist", "noch", "stets", "vor", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wach' ich, schlaf' ich, was ich tu',", "tokens": ["Wach'", "ich", ",", "schlaf'", "ich", ",", "was", "ich", "tu'", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "so d\u00fcnkt mich, er sieht mir zu.", "tokens": ["so", "d\u00fcnkt", "mich", ",", "er", "sieht", "mir", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Will mir Gott denn Keinen geben,", "tokens": ["Will", "mir", "Gott", "denn", "Kei\u00b7nen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der sich, Liebster, gleiche dir,", "tokens": ["der", "sich", ",", "Liebs\u00b7ter", ",", "glei\u00b7che", "dir", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PRF", "$,", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nun so mu\u00df ich einsam leben", "tokens": ["nun", "so", "mu\u00df", "ich", "ein\u00b7sam", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und mich immer halten mir,", "tokens": ["und", "mich", "im\u00b7mer", "hal\u00b7ten", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "[ma\u00df auch gro\u00dfe Klagewort'", "tokens": ["ma\u00df", "auch", "gro\u00b7\u00dfe", "Kla\u00b7ge\u00b7wort'"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "traurig f\u00fchren fort und fort.]", "tokens": ["trau\u00b7rig", "f\u00fch\u00b7ren", "fort", "und", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Dieses Alles wirstu h\u00f6ren", "tokens": ["Die\u00b7ses", "Al\u00b7les", "wirs\u00b7tu", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "PIS", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mich ansehn unverwandt,", "tokens": ["und", "mich", "an\u00b7sehn", "un\u00b7ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "drauf dich sehnlich zu mir kehren,", "tokens": ["drauf", "dich", "sehn\u00b7lich", "zu", "mir", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dar mir bieten deine Hand", "tokens": ["dar", "mir", "bie\u00b7ten", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKVZ", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und mit feuriger Begier", "tokens": ["und", "mit", "feu\u00b7ri\u00b7ger", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "diese Worte sagen mir:", "tokens": ["die\u00b7se", "Wor\u00b7te", "sa\u00b7gen", "mir", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "\u00bbhastu etwas vor verloren,", "tokens": ["\u00bb", "has\u00b7tu", "et\u00b7was", "vor", "ver\u00b7lo\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "APPR", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "suche selbigs nur in mir!\u00ab", "tokens": ["su\u00b7che", "sel\u00b7bigs", "nur", "in", "mir", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich, als w\u00e4r' ich neugeboren,", "tokens": ["Ich", ",", "als", "w\u00e4r'", "ich", "neu\u00b7ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOKOM", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "werde wenden mich zu dir,", "tokens": ["wer\u00b7de", "wen\u00b7den", "mich", "zu", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PRF", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sprechend: \u00bbLieber, geh' es ein!", "tokens": ["spre\u00b7chend", ":", "\u00bb", "Lie\u00b7ber", ",", "geh'", "es", "ein", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "$(", "ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du, da solst mein ", "tokens": ["Du", ",", "da", "solst", "mein"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "KOUS", "VMFIN", "PPOSAT"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.35": {"line.1": {"text": "Linde, du und ihr, ihr Wiesen,", "tokens": ["Lin\u00b7de", ",", "du", "und", "ihr", ",", "ihr", "Wie\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "KON", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihr, ihr sollet Zeugen sein,", "tokens": ["ihr", ",", "ihr", "sol\u00b7let", "Zeu\u00b7gen", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "VMFIN", "NN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich diesen Meinen, diesen", "tokens": ["da\u00df", "ich", "die\u00b7sen", "Mei\u00b7nen", ",", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "PDAT", "NN", "$,", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "gleich als meinen ", "tokens": ["gleich", "als", "mei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "KOKOM", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Ich bin deine, meine du!", "tokens": ["Ich", "bin", "dei\u00b7ne", ",", "mei\u00b7ne", "du", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ganze Gegend, h\u00f6re zu!", "tokens": ["Gan\u00b7ze", "Ge\u00b7gend", ",", "h\u00f6\u00b7re", "zu", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Denn so la\u00df uns beide schreien:", "tokens": ["Denn", "so", "la\u00df", "uns", "bei\u00b7de", "schrei\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVIMP", "PPER", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbgl\u00fcck zur neuen Br\u00fcderschaft,", "tokens": ["\u00bb", "gl\u00fcck", "zur", "neu\u00b7en", "Br\u00fc\u00b7der\u00b7schaft", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gl\u00fcck uns beiden, Gl\u00fcck uns zweien!", "tokens": ["Gl\u00fcck", "uns", "bei\u00b7den", ",", "Gl\u00fcck", "uns", "zwei\u00b7en", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "$,", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieses B\u00fcndn\u00fc\u00df habe Kraft!\u00ab", "tokens": ["Die\u00b7ses", "B\u00fcnd\u00b7n\u00fc\u00df", "ha\u00b7be", "Kraft", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "VAFIN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Echo hallt: es habe Kraft!", "tokens": ["E\u00b7cho", "hallt", ":", "es", "ha\u00b7be", "Kraft", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck zur neuen Br\u00fcderschaft!", "tokens": ["Gl\u00fcck", "zur", "neu\u00b7en", "Br\u00fc\u00b7der\u00b7schaft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Was befreundet doch das Saufen?", "tokens": ["Was", "be\u00b7freun\u00b7det", "doch", "das", "Sau\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Es ist nur des P\u00f6fels Brauch,", "tokens": ["Es", "ist", "nur", "des", "P\u00f6\u00b7fels", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "da man Br\u00fcderschaft mu\u00df kaufen", "tokens": ["da", "man", "Br\u00fc\u00b7der\u00b7schaft", "mu\u00df", "kau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um das, was nur f\u00fcllt den Bauch,", "tokens": ["um", "das", ",", "was", "nur", "f\u00fcllt", "den", "Bauch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDS", "$,", "PRELS", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die denn kaum so lange steht,", "tokens": ["die", "denn", "kaum", "so", "lan\u00b7ge", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "bis der Soff vom Leibe geht", "tokens": ["bis", "der", "Soff", "vom", "Lei\u00b7be", "geht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "N\u00fcchtern soll man sein und seine,", "tokens": ["N\u00fcch\u00b7tern", "soll", "man", "sein", "und", "sei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "VAINF", "KON", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn man seinesgleichen sucht,", "tokens": ["wenn", "man", "sei\u00b7nes\u00b7glei\u00b7chen", "sucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "weil noch sind die Sinnen reine,", "tokens": ["weil", "noch", "sind", "die", "Sin\u00b7nen", "rei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VAFIN", "ART", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "weil man Scham noch hat und Zucht.", "tokens": ["weil", "man", "Scham", "noch", "hat", "und", "Zucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "ADV", "VAFIN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was best\u00e4ndig bleiben soll,", "tokens": ["Was", "be\u00b7st\u00e4n\u00b7dig", "blei\u00b7ben", "soll", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mu\u00df man vor bedenken wol.", "tokens": ["mu\u00df", "man", "vor", "be\u00b7den\u00b7ken", "wol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Nachmals werden wir uns sehnen", "tokens": ["Nach\u00b7mals", "wer\u00b7den", "wir", "uns", "seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "um einander stets zu sein,", "tokens": ["um", "ein\u00b7an\u00b7der", "stets", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "uns allm\u00e4hlich angew\u00f6hnen,", "tokens": ["uns", "all\u00b7m\u00e4h\u00b7lich", "an\u00b7ge\u00b7w\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df wir ", "tokens": ["da\u00df", "wir"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Unser Sin wird h\u00f6her stehn", "tokens": ["Un\u00b7ser", "Sin", "wird", "h\u00f6\u00b7her", "stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "als wo nur die Feigen gehn.", "tokens": ["als", "wo", "nur", "die", "Fei\u00b7gen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Dein Verb\u00fcndn\u00fc\u00df, deine Treue", "tokens": ["Dein", "Ver\u00b7b\u00fcnd\u00b7n\u00fc\u00df", ",", "dei\u00b7ne", "Treu\u00b7e"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "macht, da\u00df ich mein Vaterland", "tokens": ["macht", ",", "da\u00df", "ich", "mein", "Va\u00b7ter\u00b7land"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "zu verlassen ganz nicht scheue.", "tokens": ["zu", "ver\u00b7las\u00b7sen", "ganz", "nicht", "scheu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das verkn\u00fcpfte Liebesband", "tokens": ["Das", "ver\u00b7kn\u00fcpf\u00b7te", "Lie\u00b7bes\u00b7band"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wird uns f\u00fchren hin und her,", "tokens": ["wird", "uns", "f\u00fch\u00b7ren", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcber Trucken, \u00fcber Meer.", "tokens": ["\u00fc\u00b7ber", "Tru\u00b7cken", ",", "\u00fc\u00b7ber", "Meer", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Weg mit dem, der stets nur lieget", "tokens": ["Weg", "mit", "dem", ",", "der", "stets", "nur", "lie\u00b7get"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "$,", "PRELS", "ADV", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bei der faulen Ofenbank!", "tokens": ["bei", "der", "fau\u00b7len", "O\u00b7fen\u00b7bank", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sich in die Fremde f\u00fcget,", "tokens": ["Wer", "sich", "in", "die", "Frem\u00b7de", "f\u00fc\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wird bekant, verdienet Dank.", "tokens": ["wird", "be\u00b7kant", ",", "ver\u00b7die\u00b7net", "Dank", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Di\u00df ist meines Lebens Ziel,", "tokens": ["Di\u00df", "ist", "mei\u00b7nes", "Le\u00b7bens", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df ich stets mehr lernen will.", "tokens": ["da\u00df", "ich", "stets", "mehr", "ler\u00b7nen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Drauf so gehn wir neuen Br\u00fcder", "tokens": ["Drauf", "so", "gehn", "wir", "neu\u00b7en", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf das nahe ", "tokens": ["auf", "das", "na\u00b7he"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "da denn auch nichts mangelt wieder,", "tokens": ["da", "denn", "auch", "nichts", "man\u00b7gelt", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PIS", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was ergetzet unsern Sin.", "tokens": ["was", "er\u00b7get\u00b7zet", "un\u00b7sern", "Sin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Heint ist gleich die andre Nacht,", "tokens": ["Heint", "ist", "gleich", "die", "and\u00b7re", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df man Hochzeit da gemacht.", "tokens": ["da\u00df", "man", "Hoch\u00b7zeit", "da", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "an die hei\u00dfe Brust gedruckt;", "tokens": ["an", "die", "hei\u00b7\u00dfe", "Brust", "ge\u00b7druckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "was ihr wol tut, wie sies juckt;", "tokens": ["was", "ihr", "wol", "tut", ",", "wie", "sies", "juckt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Andre, die zugegen sein,", "tokens": ["And\u00b7re", ",", "die", "zu\u00b7ge\u00b7gen", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "f\u00fchren einen Bauerrei'n.", "tokens": ["f\u00fch\u00b7ren", "ei\u00b7nen", "Bau\u00b7er\u00b7rei'", "n."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["VVFIN", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "um ihr braunes Haar und steht,", "tokens": ["um", "ihr", "brau\u00b7nes", "Haar", "und", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "bis sie holet ab ihr Freier", "tokens": ["bis", "sie", "ho\u00b7let", "ab", "ihr", "Frei\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und mit ihr zu Platze geht,", "tokens": ["und", "mit", "ihr", "zu", "Plat\u00b7ze", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da sie denn um einen Tanz", "tokens": ["da", "sie", "denn", "um", "ei\u00b7nen", "Tanz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ihm vertauschet ihren Kranz.", "tokens": ["ihm", "ver\u00b7tau\u00b7schet", "ih\u00b7ren", "Kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Sind wir denn des Zusehns m\u00fcde,", "tokens": ["Sind", "wir", "denn", "des", "Zu\u00b7sehns", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gut! so machen wir uns fort,", "tokens": ["gut", "!", "so", "ma\u00b7chen", "wir", "uns", "fort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "lachen \u00fcber manchem Liede,", "tokens": ["la\u00b7chen", "\u00fc\u00b7ber", "man\u00b7chem", "Lie\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bis wir kommen an den Ort,", "tokens": ["bis", "wir", "kom\u00b7men", "an", "den", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "in den Hof, der uns wol kennt", "tokens": ["in", "den", "Hof", ",", "der", "uns", "wol", "kennt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und oft seine G\u00e4ste nennt.", "tokens": ["und", "oft", "sei\u00b7ne", "G\u00e4s\u00b7te", "nennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.46": {"line.1": {"text": "Zwar wir k\u00f6nten uns auch wenden", "tokens": ["Zwar", "wir", "k\u00f6n\u00b7ten", "uns", "auch", "wen\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf das sch\u00f6ne ", "tokens": ["auf", "das", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "und den Knaben vor uns senden,", "tokens": ["und", "den", "Kna\u00b7ben", "vor", "uns", "sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "der uns Alles wol bestellt,", "tokens": ["der", "uns", "Al\u00b7les", "wol", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "doch wie ", "tokens": ["doch", "wie"], "token_info": ["word", "word"], "pos": ["ADV", "KOKOM"], "meter": "-+", "measure": "iambic.single"}}, "stanza.47": {"line.1": {"text": "hier ist Lust in gutem Kauf,", "tokens": ["hier", "ist", "Lust", "in", "gu\u00b7tem", "Kauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "hier kan man dem Trauren wehren,", "tokens": ["hier", "kan", "man", "dem", "Trau\u00b7ren", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "hier tr\u00e4gt man vollauf uns auf.", "tokens": ["hier", "tr\u00e4gt", "man", "vol\u00b7lauf", "uns", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Was man w\u00fcndscht nur und begehrt,", "tokens": ["Was", "man", "w\u00fcnd\u00b7scht", "nur", "und", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "ADV", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dessen wird man hier gew\u00e4hrt.", "tokens": ["des\u00b7sen", "wird", "man", "hier", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Auf dem schattenreichen Rasen", "tokens": ["Auf", "dem", "schat\u00b7ten\u00b7rei\u00b7chen", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "dieses dicken Apfelbaums", "tokens": ["die\u00b7ses", "di\u00b7cken", "Ap\u00b7fel\u00b7baums"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "oder dort, wo jene grasen,", "tokens": ["o\u00b7der", "dort", ",", "wo", "je\u00b7ne", "gra\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "PDS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ist der Platz sehr gutes Raums.", "tokens": ["ist", "der", "Platz", "sehr", "gu\u00b7tes", "Raums", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oder liebt die\u00df Lusthaus ba\u00df,", "tokens": ["O\u00b7der", "liebt", "die\u00df", "Lust\u00b7haus", "ba\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da ich oft vor diesem sa\u00df?", "tokens": ["da", "ich", "oft", "vor", "die\u00b7sem", "sa\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PDAT", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Ich und jene lieben Dreie,", "tokens": ["Ich", "und", "je\u00b7ne", "lie\u00b7ben", "Drei\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "derer Einer nun ist hin, \u2013", "tokens": ["de\u00b7rer", "Ei\u00b7ner", "nun", "ist", "hin", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PIS", "ADV", "VAFIN", "ADV", "$,", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "itzt die \u00fcberbliebnen Zweie", "tokens": ["itzt", "die", "\u00fc\u00b7berb\u00b7lieb\u00b7nen", "Zwei\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ungesegnet von mir ziehn, \u2013", "tokens": ["un\u00b7ge\u00b7seg\u00b7net", "von", "mir", "ziehn", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ich alleine bin noch hier,", "tokens": ["ich", "al\u00b7lei\u00b7ne", "bin", "noch", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der ich wei\u00df um die Revier.", "tokens": ["der", "ich", "wei\u00df", "um", "die", "Re\u00b7vier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "L\u00fcstet dich nach einem Fische,", "tokens": ["L\u00fcs\u00b7tet", "dich", "nach", "ei\u00b7nem", "Fi\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "den die ", "tokens": ["den", "die"], "token_info": ["word", "word"], "pos": ["ART", "ART"], "meter": "--", "measure": "unknown.measure.zero"}, "line.3": {"text": "er soll bald stehn auf dem Tische.", "tokens": ["er", "soll", "bald", "stehn", "auf", "dem", "Ti\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Liebet dir ein feister Hahn,", "tokens": ["Lie\u00b7bet", "dir", "ein", "feis\u00b7ter", "Hahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der im Hof' ist worden jung,", "tokens": ["der", "im", "Hof'", "ist", "wor\u00b7den", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VAFIN", "VAPP", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "hier giebts solches Viehs genung.", "tokens": ["hier", "giebts", "sol\u00b7ches", "Viehs", "ge\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "ADV", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.51": {"line.1": {"text": "Haben wir denn Lust zu Weine,", "tokens": ["Ha\u00b7ben", "wir", "denn", "Lust", "zu", "Wei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die den besten Trunk vom Rheine,", "tokens": ["die", "den", "bes\u00b7ten", "Trunk", "vom", "Rhei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPRART", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die den s\u00fc\u00df'sten Alakant", "tokens": ["die", "den", "s\u00fc\u00df'\u00b7sten", "A\u00b7la\u00b7kant"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und was lieber noch kan sein", "tokens": ["und", "was", "lie\u00b7ber", "noch", "kan", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "ADV", "VMFIN", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "auf der Post uns liefert ein.", "tokens": ["auf", "der", "Post", "uns", "lie\u00b7fert", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "W\u00fcndschest da nach einer Sch\u00fcssel,", "tokens": ["W\u00fcnd\u00b7schest", "da", "nach", "ei\u00b7ner", "Sch\u00fcs\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so mit s\u00fc\u00dfer Milch gef\u00fcllt?", "tokens": ["so", "mit", "s\u00fc\u00b7\u00dfer", "Milch", "ge\u00b7f\u00fcllt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schau, dort ist der Kellerschl\u00fcssel!", "tokens": ["Schau", ",", "dort", "ist", "der", "Kel\u00b7ler\u00b7schl\u00fcs\u00b7sel", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nim dir, so am meisten gilt!", "tokens": ["Nim", "dir", ",", "so", "am", "meis\u00b7ten", "gilt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "ADV", "PTKA", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier sind Semmeln, L\u00f6ffel hier.", "tokens": ["Hier", "sind", "Sem\u00b7meln", ",", "L\u00f6f\u00b7fel", "hier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "I\u00df, so viel beliebet dir!", "tokens": ["I\u00df", ",", "so", "viel", "be\u00b7lie\u00b7bet", "dir", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Wollen wir zu Wasser fahren?", "tokens": ["Wol\u00b7len", "wir", "zu", "Was\u00b7ser", "fah\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dorte steht ein neuer Kahn.", "tokens": ["Dor\u00b7te", "steht", "ein", "neu\u00b7er", "Kahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Heute wird man nichts nicht sparen.", "tokens": ["Heu\u00b7te", "wird", "man", "nichts", "nicht", "spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PIS", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Knecht, greif frisch die Ruder an!", "tokens": ["Knecht", ",", "greif", "frisch", "die", "Ru\u00b7der", "an", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "mit der ", "tokens": ["mit", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.54": {"line.1": {"text": "Gleichsfals mangelts nicht an Spielen.", "tokens": ["Gleichs\u00b7fals", "man\u00b7gelts", "nicht", "an", "Spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vor uns steht das Interim,", "tokens": ["Vor", "uns", "steht", "das", "In\u00b7te\u00b7rim", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da die Peilke, hier sind M\u00fchlen,", "tokens": ["da", "die", "Peil\u00b7ke", ",", "hier", "sind", "M\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADV", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und wornach du dich siehst um,", "tokens": ["und", "wor\u00b7nach", "du", "dich", "siehst", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wol! es gilt auf gleichen Sieg,", "tokens": ["Wol", "!", "es", "gilt", "auf", "glei\u00b7chen", "Sieg", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "einen Treppel, einen Pick!", "tokens": ["ei\u00b7nen", "Trep\u00b7pel", ",", "ei\u00b7nen", "Pick", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Wilst du lortschen, wilst du dammen,", "tokens": ["Wilst", "du", "lort\u00b7schen", ",", "wilst", "du", "dam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wilst da ziehen in dem Schach'?", "tokens": ["wilst", "da", "zie\u00b7hen", "in", "dem", "Schach'", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Her, wir wagen uns zusammen!", "tokens": ["Her", ",", "wir", "wa\u00b7gen", "uns", "zu\u00b7sam\u00b7men", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df uns sehn, wers beste mach'!", "tokens": ["La\u00df", "uns", "sehn", ",", "wers", "bes\u00b7te", "mach'", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "ADV", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oder solls im Brete sein?", "tokens": ["O\u00b7der", "solls", "im", "Bre\u00b7te", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gut! es gilt ein Stiebchen Wein!", "tokens": ["Gut", "!", "es", "gilt", "ein", "Stieb\u00b7chen", "Wein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Dorte liegen auch die Kegel.", "tokens": ["Dor\u00b7te", "lie\u00b7gen", "auch", "die", "Ke\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebt dirs, nim es an mit mir!", "tokens": ["Liebt", "dirs", ",", "nim", "es", "an", "mit", "mir", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "VVIMP", "PPER", "APPR", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Inde\u00df bringt der Knecht das Legel,", "tokens": ["In\u00b7de\u00df", "bringt", "der", "Knecht", "das", "Le\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "angef\u00fcllt mit kaltem Bier,", "tokens": ["an\u00b7ge\u00b7f\u00fcllt", "mit", "kal\u00b7tem", "Bier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und das soll uns lieber sein", "tokens": ["und", "das", "soll", "uns", "lie\u00b7ber", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VMFIN", "PPER", "ADV", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "als Madrill, dein bester Wein.", "tokens": ["als", "Mad\u00b7rill", ",", "dein", "bes\u00b7ter", "Wein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.57": {"line.1": {"text": "Wenn die Sonn' am h\u00f6chsten stehet,", "tokens": ["Wenn", "die", "Sonn'", "am", "h\u00f6chs\u00b7ten", "ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPRART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doppelt ihre wilde Glut", "tokens": ["dop\u00b7pelt", "ih\u00b7re", "wil\u00b7de", "Glut"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und kein linder West nicht wehet,", "tokens": ["und", "kein", "lin\u00b7der", "West", "nicht", "we\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da verraucht uns Kraft und Mut,", "tokens": ["da", "ver\u00b7raucht", "uns", "Kraft", "und", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "bis ein frischer Trunk ersetzt", "tokens": ["bis", "ein", "fri\u00b7scher", "Trunk", "er\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "das, was in uns war verletzt.", "tokens": ["das", ",", "was", "in", "uns", "war", "ver\u00b7letzt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "\u00dcber, unter, um und neben,", "tokens": ["\u00dc\u00b7ber", ",", "un\u00b7ter", ",", "um", "und", "ne\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "$,", "KOUI", "KON", "APPR", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "vor und hinter uns ist Lust.", "tokens": ["vor", "und", "hin\u00b7ter", "uns", "ist", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "KON", "APPR", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da ist lauter liebes Leben,", "tokens": ["Da", "ist", "lau\u00b7ter", "lie\u00b7bes", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wo wir wenden hin die Brust.", "tokens": ["wo", "wir", "wen\u00b7den", "hin", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo wir liegen, wo wir stehn,", "tokens": ["Wo", "wir", "lie\u00b7gen", ",", "wo", "wir", "stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "sehn wir Freude mit uns gehn.", "tokens": ["sehn", "wir", "Freu\u00b7de", "mit", "uns", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "Doch was k\u00f6nnen wir alleine", "tokens": ["Doch", "was", "k\u00f6n\u00b7nen", "wir", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VMFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mit einander lustig sein?", "tokens": ["mit", "ein\u00b7an\u00b7der", "lus\u00b7tig", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df hieher auch bitten Deine,", "tokens": ["La\u00df", "hie\u00b7her", "auch", "bit\u00b7ten", "Dei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PAV", "ADV", "VVFIN", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die nichts minder auch sind mein,", "tokens": ["die", "nichts", "min\u00b7der", "auch", "sind", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "VAFIN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "als die gleichsfals itzt, wie ich,", "tokens": ["als", "die", "gleichs\u00b7fals", "itzt", ",", "wie", "ich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ADV", "$,", "PWAV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "so bem\u00fchet sein auf dich!", "tokens": ["so", "be\u00b7m\u00fc\u00b7het", "sein", "auf", "dich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Hola, Junger, hole Jene,", "tokens": ["Ho\u00b7la", ",", "Jun\u00b7ger", ",", "ho\u00b7le", "Je\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "$,", "VVFIN", "PDS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jene, die du kennest wol!", "tokens": ["Je\u00b7ne", ",", "die", "du", "ken\u00b7nest", "wol", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hei\u00df sie kommen und erw\u00e4hne,", "tokens": ["Hei\u00df", "sie", "kom\u00b7men", "und", "er\u00b7w\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df wir schon sind zimlich voll!", "tokens": ["da\u00df", "wir", "schon", "sind", "zim\u00b7lich", "voll", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hei\u00df sie da sein ohn' Verzug,", "tokens": ["Hei\u00df", "sie", "da", "sein", "ohn'", "Ver\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "APPR", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "weil noch w\u00e4hrt der dritte Krug!", "tokens": ["weil", "noch", "w\u00e4hrt", "der", "drit\u00b7te", "Krug", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Und so wollen wir uns freuen,", "tokens": ["Und", "so", "wol\u00b7len", "wir", "uns", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bis da\u00df Ph\u00f6bus Urlaub nimmt,", "tokens": ["bis", "da\u00df", "Ph\u00f6\u00b7bus", "Ur\u00b7laub", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "bis mit ihren lichten Reien", "tokens": ["bis", "mit", "ih\u00b7ren", "lich\u00b7ten", "Rei\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Luna an ihr Zimmer k\u00f6mmt;", "tokens": ["Lu\u00b7na", "an", "ihr", "Zim\u00b7mer", "k\u00f6mmt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "bis der Tag bricht wieder ein,", "tokens": ["bis", "der", "Tag", "bricht", "wie\u00b7der", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen wir so lustig sein!", "tokens": ["wol\u00b7len", "wir", "so", "lus\u00b7tig", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Sind wir itzt nicht in dem Maien,", "tokens": ["Sind", "wir", "itzt", "nicht", "in", "dem", "Mai\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "in der besten Jahreszeit,", "tokens": ["in", "der", "bes\u00b7ten", "Jah\u00b7res\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da man Alles sich sieht freuen,", "tokens": ["da", "man", "Al\u00b7les", "sich", "sieht", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "PRF", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was sich reget weit und breit,", "tokens": ["was", "sich", "re\u00b7get", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "da die stolze Welt sich putzt", "tokens": ["da", "die", "stol\u00b7ze", "Welt", "sich", "putzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und in jungem Schmucke stutzt?", "tokens": ["und", "in", "jun\u00b7gem", "Schmu\u00b7cke", "stutzt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Du nur wilst dich nicht bequemen", "tokens": ["Du", "nur", "wilst", "dich", "nicht", "be\u00b7que\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "PTKNEG", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "zu der s\u00fc\u00dfen Liebligkeit", "tokens": ["zu", "der", "s\u00fc\u00b7\u00dfen", "Lieb\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und die Freude mitte nehmen,", "tokens": ["und", "die", "Freu\u00b7de", "mit\u00b7te", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so sich giebet dieser Zeit?", "tokens": ["so", "sich", "gie\u00b7bet", "die\u00b7ser", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du nur tust nicht, kleine Welt,", "tokens": ["Du", "nur", "tust", "nicht", ",", "klei\u00b7ne", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "was der gro\u00dfen so gef\u00e4llt?", "tokens": ["was", "der", "gro\u00b7\u00dfen", "so", "ge\u00b7f\u00e4llt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Gib den m\u00fcden B\u00fcchern Feier!", "tokens": ["Gib", "den", "m\u00fc\u00b7den", "B\u00fc\u00b7chern", "Fei\u00b7er", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tu die matte Feder hin!", "tokens": ["Tu", "die", "mat\u00b7te", "Fe\u00b7der", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was du hast erlebet heuer,", "tokens": ["Was", "du", "hast", "er\u00b7le\u00b7bet", "heu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wird dirs \u00fcbers Jahr nachziehn?", "tokens": ["wird", "dirs", "\u00fc\u00b7bers", "Jahr", "nach\u00b7ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ists, dem du dich verbannst", "tokens": ["Was", "ists", ",", "dem", "du", "dich", "ver\u00b7bannst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "PPER", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und in ein solch Joch dich spannst?", "tokens": ["und", "in", "ein", "solch", "Joch", "dich", "spannst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Was der von Stagyr geschrieben,", "tokens": ["Was", "der", "von", "Sta\u00b7gyr", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Plato, was du hast erdacht,", "tokens": ["Pla\u00b7to", ",", "was", "du", "hast", "er\u00b7dacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "das ist Alles nach euch blieben;", "tokens": ["das", "ist", "Al\u00b7les", "nach", "euch", "blie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ihr nur gabet gute Nacht.", "tokens": ["ihr", "nur", "ga\u00b7bet", "gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist denn di\u00df die gro\u00dfe Frucht,", "tokens": ["Ist", "denn", "di\u00df", "die", "gro\u00b7\u00dfe", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "die man in dem Schreiben sucht?", "tokens": ["die", "man", "in", "dem", "Schrei\u00b7ben", "sucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "Mein! Was hilft es doch dem Dichter,", "tokens": ["Mein", "!", "Was", "hilft", "es", "doch", "dem", "Dich\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df sein Flei\u00df ihn \u00fcberlebt?", "tokens": ["da\u00df", "sein", "Flei\u00df", "ihn", "\u00fc\u00b7ber\u00b7lebt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwar ein Ieder ist hier Richter,", "tokens": ["Zwar", "ein", "Ie\u00b7der", "ist", "hier", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df er hat auf Ruhm gestrebt.", "tokens": ["da\u00df", "er", "hat", "auf", "Ruhm", "ge\u00b7strebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber was geneu\u00dfts der Man,", "tokens": ["A\u00b7ber", "was", "ge\u00b7neu\u00dfts", "der", "Man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "ART", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der schon l\u00e4ngst ist beigetan?", "tokens": ["der", "schon", "l\u00e4ngst", "ist", "bei\u00b7ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.67": {"line.1": {"text": "Eh' man etwas T\u00fcchtigs schreibet,", "tokens": ["Eh'", "man", "et\u00b7was", "T\u00fcch\u00b7tigs", "schrei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lauft f\u00fcrwar viel Zeit vorbei.", "tokens": ["lauft", "f\u00fcr\u00b7war", "viel", "Zeit", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was ists, das nach uns bleibet?", "tokens": ["Und", "was", "ists", ",", "das", "nach", "uns", "blei\u00b7bet", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein vergebliches Geschrei,", "tokens": ["Ein", "ver\u00b7geb\u00b7li\u00b7ches", "Ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "das derselbe doch nicht h\u00f6ret,", "tokens": ["das", "der\u00b7sel\u00b7be", "doch", "nicht", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PDAT", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der darmitte wird geehret.", "tokens": ["der", "dar\u00b7mit\u00b7te", "wird", "ge\u00b7eh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Geben dir die G\u00f6tter Gaben", "tokens": ["Ge\u00b7ben", "dir", "die", "G\u00f6t\u00b7ter", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und verehren dich mit Kunst,", "tokens": ["und", "ver\u00b7eh\u00b7ren", "dich", "mit", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df du des kanst Ehre haben", "tokens": ["da\u00df", "du", "des", "kanst", "Eh\u00b7re", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und verdienen Vieler Gunst,", "tokens": ["und", "ver\u00b7die\u00b7nen", "Vie\u00b7ler", "Gunst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "so gedenk doch auch darbei,", "tokens": ["so", "ge\u00b7denk", "doch", "auch", "dar\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wie ein eitel Ding das sei!", "tokens": ["wie", "ein", "ei\u00b7tel", "Ding", "das", "sei", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PDS", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "Wo sind Perianders Schriften,", "tokens": ["Wo", "sind", "Pe\u00b7ri\u00b7an\u00b7ders", "Schrif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Chilon, Thales, Pittakus?", "tokens": ["Chi\u00b7lon", ",", "Tha\u00b7les", ",", "Pit\u00b7ta\u00b7kus", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ihr Flei\u00df flog nach den L\u00fcften,", "tokens": ["Weil", "ihr", "Flei\u00df", "flog", "nach", "den", "L\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sind die Namen auch Verdru\u00df.", "tokens": ["sind", "die", "Na\u00b7men", "auch", "Ver\u00b7dru\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie viel hundert Andre sein", "tokens": ["Wie", "viel", "hun\u00b7dert", "And\u00b7re", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "CARD", "PIS", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mit dem Namen gangen ein!", "tokens": ["mit", "dem", "Na\u00b7men", "gan\u00b7gen", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Haben sie bei ihrer M\u00fche", "tokens": ["Ha\u00b7ben", "sie", "bei", "ih\u00b7rer", "M\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "nicht Ergetzligkeit gehabt", "tokens": ["nicht", "Er\u00b7getz\u00b7lig\u00b7keit", "ge\u00b7habt"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "NN", "VAPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und sich, wenns die Zeit verliehe,", "tokens": ["und", "sich", ",", "wenns", "die", "Zeit", "ver\u00b7lie\u00b7he", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht mit lieber Lust erlabt,", "tokens": ["nicht", "mit", "lie\u00b7ber", "Lust", "er\u00b7labt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "was denn wird wol ihre sein,", "tokens": ["was", "denn", "wird", "wol", "ih\u00b7re", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "PPOSAT", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "nun auch nicht mehr ist ihr Schein?", "tokens": ["nun", "auch", "nicht", "mehr", "ist", "ihr", "Schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Lebe, weil du bist im Leben,", "tokens": ["Le\u00b7be", ",", "weil", "du", "bist", "im", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und gebrauche deiner Lust;", "tokens": ["und", "ge\u00b7brau\u00b7che", "dei\u00b7ner", "Lust", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "doch sei nicht zu sehr ergeben", "tokens": ["doch", "sei", "nicht", "zu", "sehr", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PTKNEG", "PTKA", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dem, das du bald meiden mu\u00dft!", "tokens": ["dem", ",", "das", "du", "bald", "mei\u00b7den", "mu\u00dft", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denke, da\u00df du auch einmal", "tokens": ["Den\u00b7ke", ",", "da\u00df", "du", "auch", "ein\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wol berechnest deine Zahl!", "tokens": ["wol", "be\u00b7rech\u00b7nest", "dei\u00b7ne", "Zahl", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "Gott verwehrt uns keine Freuden,", "tokens": ["Gott", "ver\u00b7wehrt", "uns", "kei\u00b7ne", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wann sie Freuden bleiben nur,", "tokens": ["wann", "sie", "Freu\u00b7den", "blei\u00b7ben", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn wir hierbei nur vermeiden,", "tokens": ["wenn", "wir", "hier\u00b7bei", "nur", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was lockt auf der Wollust Spur.", "tokens": ["was", "lockt", "auf", "der", "Wol\u00b7lust", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und wie kan di\u00df Freude sein,", "tokens": ["Und", "wie", "kan", "di\u00df", "Freu\u00b7de", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PDS", "NN", "VAINF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "was sie nur ist auf den Schein?", "tokens": ["was", "sie", "nur", "ist", "auf", "den", "Schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.73": {"line.1": {"text": "Was hilft das zu Tode-Saufen,", "tokens": ["Was", "hilft", "das", "zu", "To\u00b7de\u00b7\u00b7Sau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDS", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "das Verleihen seinen Leib,", "tokens": ["das", "Ver\u00b7lei\u00b7hen", "sei\u00b7nen", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "das um Wollust Reue-Kaufen,", "tokens": ["das", "um", "Wol\u00b7lust", "Reu\u00b7e\u00b7Kau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Borgen eines Andern Weib?", "tokens": ["Bor\u00b7gen", "ei\u00b7nes", "An\u00b7dern", "Weib", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist das Freude, hei\u00dft das Lust,", "tokens": ["Ist", "das", "Freu\u00b7de", ",", "hei\u00dft", "das", "Lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df du Schande haben mu\u00dft?", "tokens": ["da\u00df", "du", "Schan\u00b7de", "ha\u00b7ben", "mu\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.74": {"line.1": {"text": "Was f\u00fcr Freuden mir behagen,", "tokens": ["Was", "f\u00fcr", "Freu\u00b7den", "mir", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sind von schn\u00f6den L\u00fcsten weit.", "tokens": ["sind", "von", "schn\u00f6\u00b7den", "L\u00fcs\u00b7ten", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Worzu mich die Sinnen tragen,", "tokens": ["Wor\u00b7zu", "mich", "die", "Sin\u00b7nen", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ist verg\u00f6nnte Fr\u00f6ligkeit.", "tokens": ["ist", "ver\u00b7g\u00f6nn\u00b7te", "Fr\u00f6\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ist ehrbar, was ger\u00fchmt,", "tokens": ["Was", "ist", "ehr\u00b7bar", ",", "was", "ge\u00b7r\u00fchmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "$,", "PRELS", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "was bedachte Weisen ziemt,", "tokens": ["was", "be\u00b7dach\u00b7te", "Wei\u00b7sen", "ziemt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "was die m\u00fcde Seele speiset", "tokens": ["was", "die", "m\u00fc\u00b7de", "See\u00b7le", "spei\u00b7set"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und den lassen Leib ergetzt,", "tokens": ["und", "den", "las\u00b7sen", "Leib", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "was zum h\u00f6chsten Gut uns weiset", "tokens": ["was", "zum", "h\u00f6chs\u00b7ten", "Gut", "uns", "wei\u00b7set"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPRART", "ADJA", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und in sanften Wolstand setzt:", "tokens": ["und", "in", "sanf\u00b7ten", "Wol\u00b7stand", "setzt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ich, du, der und alle wir", "tokens": ["ich", ",", "du", ",", "der", "und", "al\u00b7le", "wir"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PPER", "$,", "PRELS", "KON", "PIS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "sind von dessen wegen hier.", "tokens": ["sind", "von", "des\u00b7sen", "we\u00b7gen", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDS", "APPR", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.76": {"line.1": {"text": "Itzund la\u00df dich von mir f\u00fchren", "tokens": ["It\u00b7zund", "la\u00df", "dich", "von", "mir", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in der feuchten ", "tokens": ["in", "der", "feuch\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "da\u00df wir sehn die Flora zieren", "tokens": ["da\u00df", "wir", "sehn", "die", "Flo\u00b7ra", "zie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ihrer langen Wiesen Saal,", "tokens": ["ih\u00b7rer", "lan\u00b7gen", "Wie\u00b7sen", "Saal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wie sie um die B\u00e4ume tanzt", "tokens": ["wie", "sie", "um", "die", "B\u00e4u\u00b7me", "tanzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "und manch sch\u00f6nes Bl\u00fcmlein pflanzt!", "tokens": ["und", "manch", "sch\u00f6\u00b7nes", "Bl\u00fcm\u00b7lein", "pflanzt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.77": {"line.1": {"text": "Ist schon hier nichts aus Idumen", "tokens": ["Ist", "schon", "hier", "nichts", "aus", "I\u00b7du\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und was her k\u00f6mmt \u00fcber See,", "tokens": ["und", "was", "her", "k\u00f6mmt", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APZR", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ei, so sind doch Maienblumen,", "tokens": ["ei", ",", "so", "sind", "doch", "Mai\u00b7en\u00b7blu\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "feister Schmergel, dicker Klee.", "tokens": ["feis\u00b7ter", "Schmer\u00b7gel", ",", "di\u00b7cker", "Klee", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Haben wir schon Fremdes nicht,", "tokens": ["Ha\u00b7ben", "wir", "schon", "Frem\u00b7des", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "doch an Lust drum nichts gebricht.", "tokens": ["doch", "an", "Lust", "drum", "nichts", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PAV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.78": {"line.1": {"text": "Der gesunde Tau sinkt nieder,", "tokens": ["Der", "ge\u00b7sun\u00b7de", "Tau", "sinkt", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das gezogne Kind der Nacht,", "tokens": ["das", "ge\u00b7zog\u00b7ne", "Kind", "der", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der der matten Kr\u00e4uter Glieder", "tokens": ["der", "der", "mat\u00b7ten", "Kr\u00e4u\u00b7ter", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wieder steif und saftig macht,", "tokens": ["wie\u00b7der", "steif", "und", "saf\u00b7tig", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der die welken Blumen tr\u00e4nkt", "tokens": ["der", "die", "wel\u00b7ken", "Blu\u00b7men", "tr\u00e4nkt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und in ihre Scho\u00df sich senkt.", "tokens": ["und", "in", "ih\u00b7re", "Scho\u00df", "sich", "senkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.79": {"line.1": {"text": "Zynthius streckt her von oben", "tokens": ["Zynt\u00b7hi\u00b7us", "streckt", "her", "von", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ADV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "seines Goldes reinen Schein,", "tokens": ["sei\u00b7nes", "Gol\u00b7des", "rei\u00b7nen", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn er itzt sein H\u00e4upt erhoben", "tokens": ["wenn", "er", "itzt", "sein", "H\u00e4upt", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und f\u00e4ngt munter an zu sein,", "tokens": ["und", "f\u00e4ngt", "mun\u00b7ter", "an", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wenn er seine Glut aufsteckt", "tokens": ["wenn", "er", "sei\u00b7ne", "Glut", "auf\u00b7steckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und die faule Welt erweckt.", "tokens": ["und", "die", "fau\u00b7le", "Welt", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.80": {"line.1": {"text": "Vor ihm her k\u00f6mt hergegangen", "tokens": ["Vor", "ihm", "her", "k\u00f6mt", "her\u00b7ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "APZR", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die Zertreiberin der Nacht", "tokens": ["die", "Zer\u00b7trei\u00b7be\u00b7rin", "der", "Nacht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "in den purpurbraunen Wangen,", "tokens": ["in", "den", "pur\u00b7pur\u00b7brau\u00b7nen", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der Anemonen Tracht,", "tokens": ["in", "der", "A\u00b7ne\u00b7mo\u00b7nen", "Tracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die denn balde, wenn er k\u00f6mmt,", "tokens": ["die", "denn", "bal\u00b7de", ",", "wenn", "er", "k\u00f6mmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "schamrot ihren Abschied nimmt.", "tokens": ["scham\u00b7rot", "ih\u00b7ren", "Ab\u00b7schied", "nimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.81": {"line.1": {"text": "Und itzt ist vor zweien Stunden,", "tokens": ["Und", "itzt", "ist", "vor", "zwei\u00b7en", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "APPR", "CARD", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "als es noch war tiefe Nacht,", "tokens": ["als", "es", "noch", "war", "tie\u00b7fe", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "eh' es Iemand hat empfunden,", "tokens": ["eh'", "es", "Ie\u00b7mand", "hat", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schon die Nachtigal erwacht,", "tokens": ["schon", "die", "Nach\u00b7ti\u00b7gal", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "welche denn verf\u00fchret schon", "tokens": ["wel\u00b7che", "denn", "ver\u00b7f\u00fch\u00b7ret", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["PRELS", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "manchen lieben s\u00fc\u00dfen Ton.", "tokens": ["man\u00b7chen", "lie\u00b7ben", "s\u00fc\u00b7\u00dfen", "Ton", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.82": {"line.1": {"text": "Nun begr\u00fc\u00dfen auch die Andern,", "tokens": ["Nun", "be\u00b7gr\u00fc\u00b7\u00dfen", "auch", "die", "An\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die kein Nest mehr halten mag", "tokens": ["die", "kein", "Nest", "mehr", "hal\u00b7ten", "mag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "ADV", "VVINF", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und durch freie L\u00fcfte wandern,", "tokens": ["und", "durch", "frei\u00b7e", "L\u00fcf\u00b7te", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "durch ihr Lied den jungen Tag.", "tokens": ["durch", "ihr", "Lied", "den", "jun\u00b7gen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Keines will vom Andern ein", "tokens": ["Kei\u00b7nes", "will", "vom", "An\u00b7dern", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPRART", "ADJA", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "in der Kunst getrieben sein.", "tokens": ["in", "der", "Kunst", "ge\u00b7trie\u00b7ben", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.83": {"line.1": {"text": "Siehst du, wie sich lieblich gatten", "tokens": ["Siehst", "du", ",", "wie", "sich", "lieb\u00b7lich", "gat\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "PRF", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hier ein P\u00e4rlein, dort ein Paar", "tokens": ["hier", "ein", "P\u00e4r\u00b7lein", ",", "dort", "ein", "Paar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "in der jungen Bl\u00e4tter Schatten?", "tokens": ["in", "der", "jun\u00b7gen", "Bl\u00e4t\u00b7ter", "Schat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie die stumme Wasserschaar", "tokens": ["Wie", "die", "stum\u00b7me", "Was\u00b7ser\u00b7schaar"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "an den sanften Ufern ringet", "tokens": ["an", "den", "sanf\u00b7ten", "U\u00b7fern", "rin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und sich um die Bulschaft dringet?", "tokens": ["und", "sich", "um", "die", "Bul\u00b7schaft", "drin\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.84": {"line.1": {"text": "Und die ausversch\u00e4mten Fr\u00f6sche", "tokens": ["Und", "die", "aus\u00b7ver\u00b7sch\u00e4m\u00b7ten", "Fr\u00f6\u00b7sche"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "haben Hochzeit schon gemacht,", "tokens": ["ha\u00b7ben", "Hoch\u00b7zeit", "schon", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "treiben ihr Koaxgew\u00e4sche", "tokens": ["trei\u00b7ben", "ihr", "Ko\u00b7ax\u00b7ge\u00b7w\u00e4\u00b7sche"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "von fr\u00fch' an bis in die Nacht;", "tokens": ["von", "fr\u00fch'", "an", "bis", "in", "die", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "APPR", "KON", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "von der Nacht bis wieder fr\u00fch'", "tokens": ["von", "der", "Nacht", "bis", "wie\u00b7der", "fr\u00fch'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "h\u00f6ret man sie schweigen nie.", "tokens": ["h\u00f6\u00b7ret", "man", "sie", "schwei\u00b7gen", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.85": {"line.1": {"text": "Hier la\u00df uns ein wenig schauen,", "tokens": ["Hier", "la\u00df", "uns", "ein", "we\u00b7nig", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ART", "PIS", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wie der Fischer Reusen legt,", "tokens": ["wie", "der", "Fi\u00b7scher", "Reu\u00b7sen", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wie der Feldman baut die Auen,", "tokens": ["wie", "der", "Feld\u00b7man", "baut", "die", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie der G\u00e4rtner B\u00e4ume hegt,", "tokens": ["wie", "der", "G\u00e4rt\u00b7ner", "B\u00e4u\u00b7me", "hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "oder wie die dicke Saat", "tokens": ["o\u00b7der", "wie", "die", "di\u00b7cke", "Saat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "halb schon gleich vorschosset hat!", "tokens": ["halb", "schon", "gleich", "vor\u00b7schos\u00b7set", "hat", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.86": {"line.1": {"text": "Dorte stehen feiste Rinder", "tokens": ["Dor\u00b7te", "ste\u00b7hen", "feis\u00b7te", "Rin\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in der Weide bis an Bauch.", "tokens": ["in", "der", "Wei\u00b7de", "bis", "an", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier sind Ziegen, so nichts minder", "tokens": ["Hier", "sind", "Zie\u00b7gen", ",", "so", "nichts", "min\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "$,", "ADV", "PIS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "blaten um den fetten Strauch.", "tokens": ["bla\u00b7ten", "um", "den", "fet\u00b7ten", "Strauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier gehn L\u00e4mmer, so f\u00fcr Lust", "tokens": ["Hier", "gehn", "L\u00e4m\u00b7mer", ",", "so", "f\u00fcr", "Lust"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "scherzen bei gesunder Kost.", "tokens": ["scher\u00b7zen", "bei", "ge\u00b7sun\u00b7der", "Kost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.87": {"line.1": {"text": "Hast du der Lust satt gepflogen,", "tokens": ["Hast", "du", "der", "Lust", "satt", "ge\u00b7pflo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wol! so lege dich mit mir", "tokens": ["wol", "!", "so", "le\u00b7ge", "dich", "mit", "mir"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "VVFIN", "PRF", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "unter den gew\u00f6lbten Bogen", "tokens": ["un\u00b7ter", "den", "ge\u00b7w\u00f6lb\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dieser hohen Linden hier,", "tokens": ["die\u00b7ser", "ho\u00b7hen", "Lin\u00b7den", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NE", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da denn solche sanfte Rast", "tokens": ["da", "denn", "sol\u00b7che", "sanf\u00b7te", "Rast"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "uns benimmt der Glieder Last!", "tokens": ["uns", "be\u00b7nimmt", "der", "Glie\u00b7der", "Last", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.88": {"line.1": {"text": "Was die V\u00f6gel tiriliren,", "tokens": ["Was", "die", "V\u00f6\u00b7gel", "ti\u00b7ri\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das hallt wider durch die Kluft;", "tokens": ["das", "hallt", "wi\u00b7der", "durch", "die", "Kluft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "was wir hier f\u00fcr Reden f\u00fchren,", "tokens": ["was", "wir", "hier", "f\u00fcr", "Re\u00b7den", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das verschweigt die stille Luft.", "tokens": ["das", "ver\u00b7schweigt", "die", "stil\u00b7le", "Luft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und da werd' ich melden viel,", "tokens": ["Und", "da", "werd'", "ich", "mel\u00b7den", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "das ich itzt nur denken will.", "tokens": ["das", "ich", "itzt", "nur", "den\u00b7ken", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.89": {"line.1": {"text": "und was er mir macht f\u00fcr Plagen,", "tokens": ["und", "was", "er", "mir", "macht", "f\u00fcr", "Pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "seit er mir entrissen sich.", "tokens": ["seit", "er", "mir", "ent\u00b7ris\u00b7sen", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seit er sich von mir gewandt,", "tokens": ["Seit", "er", "sich", "von", "mir", "ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "bin ich selbst mir unbekant.", "tokens": ["bin", "ich", "selbst", "mir", "un\u00b7be\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.90": {"line.1": {"text": "Achtmal hat nun, als ich z\u00e4hle,", "tokens": ["Acht\u00b7mal", "hat", "nun", ",", "als", "ich", "z\u00e4h\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ph\u00f6be volle H\u00f6rner kriegt,", "tokens": ["Ph\u00f6\u00b7be", "vol\u00b7le", "H\u00f6r\u00b7ner", "kriegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df zoh' hin die fromme Seele,", "tokens": ["da\u00df", "zoh'", "hin", "die", "from\u00b7me", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df der liebe Leib erliegt,", "tokens": ["da\u00df", "der", "lie\u00b7be", "Leib", "er\u00b7liegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und so lange sterb' ich hin,", "tokens": ["und", "so", "lan\u00b7ge", "sterb'", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "weil ich ohn' mein Leben bin.", "tokens": ["weil", "ich", "ohn'", "mein", "Le\u00b7ben", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.91": {"line.1": {"text": "Wer sich einmal in den Orden", "tokens": ["Wer", "sich", "ein\u00b7mal", "in", "den", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "treuer Freundschaft hat gesetzt,", "tokens": ["treu\u00b7er", "Freund\u00b7schaft", "hat", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und ist ihm das Herz entworden,", "tokens": ["und", "ist", "ihm", "das", "Herz", "ent\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "das er \u00fcber alles sch\u00e4tzt,", "tokens": ["das", "er", "\u00fc\u00b7ber", "al\u00b7les", "sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der giebt sich zufrieden nicht,", "tokens": ["der", "giebt", "sich", "zu\u00b7frie\u00b7den", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PRF", "ADJD", "PTKNEG", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "bis auch er aus sich entbricht.", "tokens": ["bis", "auch", "er", "aus", "sich", "ent\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "APPR", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.92": {"line.1": {"text": "Was ich sinne, was ich denke,", "tokens": ["Was", "ich", "sin\u00b7ne", ",", "was", "ich", "den\u00b7ke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das ist ", "tokens": ["das", "ist"], "token_info": ["word", "word"], "pos": ["PDS", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Wo ich mein Gesicht' hin lenke,", "tokens": ["Wo", "ich", "mein", "Ge\u00b7sicht'", "hin", "len\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "schwebt sein Geist noch stets vor mir.", "tokens": ["schwebt", "sein", "Geist", "noch", "stets", "vor", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wach' ich, schlaf' ich, was ich tu',", "tokens": ["Wach'", "ich", ",", "schlaf'", "ich", ",", "was", "ich", "tu'", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "so d\u00fcnkt mich, er sieht mir zu.", "tokens": ["so", "d\u00fcnkt", "mich", ",", "er", "sieht", "mir", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.93": {"line.1": {"text": "Will mir Gott denn Keinen geben,", "tokens": ["Will", "mir", "Gott", "denn", "Kei\u00b7nen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der sich, Liebster, gleiche dir,", "tokens": ["der", "sich", ",", "Liebs\u00b7ter", ",", "glei\u00b7che", "dir", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PRF", "$,", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nun so mu\u00df ich einsam leben", "tokens": ["nun", "so", "mu\u00df", "ich", "ein\u00b7sam", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und mich immer halten mir,", "tokens": ["und", "mich", "im\u00b7mer", "hal\u00b7ten", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "[ma\u00df auch gro\u00dfe Klagewort'", "tokens": ["ma\u00df", "auch", "gro\u00b7\u00dfe", "Kla\u00b7ge\u00b7wort'"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "traurig f\u00fchren fort und fort.]", "tokens": ["trau\u00b7rig", "f\u00fch\u00b7ren", "fort", "und", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.94": {"line.1": {"text": "Dieses Alles wirstu h\u00f6ren", "tokens": ["Die\u00b7ses", "Al\u00b7les", "wirs\u00b7tu", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "PIS", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mich ansehn unverwandt,", "tokens": ["und", "mich", "an\u00b7sehn", "un\u00b7ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "drauf dich sehnlich zu mir kehren,", "tokens": ["drauf", "dich", "sehn\u00b7lich", "zu", "mir", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dar mir bieten deine Hand", "tokens": ["dar", "mir", "bie\u00b7ten", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKVZ", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und mit feuriger Begier", "tokens": ["und", "mit", "feu\u00b7ri\u00b7ger", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "diese Worte sagen mir:", "tokens": ["die\u00b7se", "Wor\u00b7te", "sa\u00b7gen", "mir", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.95": {"line.1": {"text": "\u00bbhastu etwas vor verloren,", "tokens": ["\u00bb", "has\u00b7tu", "et\u00b7was", "vor", "ver\u00b7lo\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "APPR", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "suche selbigs nur in mir!\u00ab", "tokens": ["su\u00b7che", "sel\u00b7bigs", "nur", "in", "mir", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich, als w\u00e4r' ich neugeboren,", "tokens": ["Ich", ",", "als", "w\u00e4r'", "ich", "neu\u00b7ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOKOM", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "werde wenden mich zu dir,", "tokens": ["wer\u00b7de", "wen\u00b7den", "mich", "zu", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PRF", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sprechend: \u00bbLieber, geh' es ein!", "tokens": ["spre\u00b7chend", ":", "\u00bb", "Lie\u00b7ber", ",", "geh'", "es", "ein", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "$(", "ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du, da solst mein ", "tokens": ["Du", ",", "da", "solst", "mein"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "KOUS", "VMFIN", "PPOSAT"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.96": {"line.1": {"text": "Linde, du und ihr, ihr Wiesen,", "tokens": ["Lin\u00b7de", ",", "du", "und", "ihr", ",", "ihr", "Wie\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "KON", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihr, ihr sollet Zeugen sein,", "tokens": ["ihr", ",", "ihr", "sol\u00b7let", "Zeu\u00b7gen", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "VMFIN", "NN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich diesen Meinen, diesen", "tokens": ["da\u00df", "ich", "die\u00b7sen", "Mei\u00b7nen", ",", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "PDAT", "NN", "$,", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "gleich als meinen ", "tokens": ["gleich", "als", "mei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "KOKOM", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Ich bin deine, meine du!", "tokens": ["Ich", "bin", "dei\u00b7ne", ",", "mei\u00b7ne", "du", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ganze Gegend, h\u00f6re zu!", "tokens": ["Gan\u00b7ze", "Ge\u00b7gend", ",", "h\u00f6\u00b7re", "zu", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.97": {"line.1": {"text": "Denn so la\u00df uns beide schreien:", "tokens": ["Denn", "so", "la\u00df", "uns", "bei\u00b7de", "schrei\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVIMP", "PPER", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbgl\u00fcck zur neuen Br\u00fcderschaft,", "tokens": ["\u00bb", "gl\u00fcck", "zur", "neu\u00b7en", "Br\u00fc\u00b7der\u00b7schaft", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gl\u00fcck uns beiden, Gl\u00fcck uns zweien!", "tokens": ["Gl\u00fcck", "uns", "bei\u00b7den", ",", "Gl\u00fcck", "uns", "zwei\u00b7en", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "$,", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieses B\u00fcndn\u00fc\u00df habe Kraft!\u00ab", "tokens": ["Die\u00b7ses", "B\u00fcnd\u00b7n\u00fc\u00df", "ha\u00b7be", "Kraft", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "VAFIN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Echo hallt: es habe Kraft!", "tokens": ["E\u00b7cho", "hallt", ":", "es", "ha\u00b7be", "Kraft", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck zur neuen Br\u00fcderschaft!", "tokens": ["Gl\u00fcck", "zur", "neu\u00b7en", "Br\u00fc\u00b7der\u00b7schaft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.98": {"line.1": {"text": "Was befreundet doch das Saufen?", "tokens": ["Was", "be\u00b7freun\u00b7det", "doch", "das", "Sau\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Es ist nur des P\u00f6fels Brauch,", "tokens": ["Es", "ist", "nur", "des", "P\u00f6\u00b7fels", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "da man Br\u00fcderschaft mu\u00df kaufen", "tokens": ["da", "man", "Br\u00fc\u00b7der\u00b7schaft", "mu\u00df", "kau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um das, was nur f\u00fcllt den Bauch,", "tokens": ["um", "das", ",", "was", "nur", "f\u00fcllt", "den", "Bauch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDS", "$,", "PRELS", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die denn kaum so lange steht,", "tokens": ["die", "denn", "kaum", "so", "lan\u00b7ge", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "bis der Soff vom Leibe geht", "tokens": ["bis", "der", "Soff", "vom", "Lei\u00b7be", "geht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.99": {"line.1": {"text": "N\u00fcchtern soll man sein und seine,", "tokens": ["N\u00fcch\u00b7tern", "soll", "man", "sein", "und", "sei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "VAINF", "KON", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn man seinesgleichen sucht,", "tokens": ["wenn", "man", "sei\u00b7nes\u00b7glei\u00b7chen", "sucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "weil noch sind die Sinnen reine,", "tokens": ["weil", "noch", "sind", "die", "Sin\u00b7nen", "rei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VAFIN", "ART", "NN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "weil man Scham noch hat und Zucht.", "tokens": ["weil", "man", "Scham", "noch", "hat", "und", "Zucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "ADV", "VAFIN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was best\u00e4ndig bleiben soll,", "tokens": ["Was", "be\u00b7st\u00e4n\u00b7dig", "blei\u00b7ben", "soll", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mu\u00df man vor bedenken wol.", "tokens": ["mu\u00df", "man", "vor", "be\u00b7den\u00b7ken", "wol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.100": {"line.1": {"text": "Nachmals werden wir uns sehnen", "tokens": ["Nach\u00b7mals", "wer\u00b7den", "wir", "uns", "seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "um einander stets zu sein,", "tokens": ["um", "ein\u00b7an\u00b7der", "stets", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "uns allm\u00e4hlich angew\u00f6hnen,", "tokens": ["uns", "all\u00b7m\u00e4h\u00b7lich", "an\u00b7ge\u00b7w\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df wir ", "tokens": ["da\u00df", "wir"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Unser Sin wird h\u00f6her stehn", "tokens": ["Un\u00b7ser", "Sin", "wird", "h\u00f6\u00b7her", "stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "als wo nur die Feigen gehn.", "tokens": ["als", "wo", "nur", "die", "Fei\u00b7gen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.101": {"line.1": {"text": "Dein Verb\u00fcndn\u00fc\u00df, deine Treue", "tokens": ["Dein", "Ver\u00b7b\u00fcnd\u00b7n\u00fc\u00df", ",", "dei\u00b7ne", "Treu\u00b7e"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "macht, da\u00df ich mein Vaterland", "tokens": ["macht", ",", "da\u00df", "ich", "mein", "Va\u00b7ter\u00b7land"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "zu verlassen ganz nicht scheue.", "tokens": ["zu", "ver\u00b7las\u00b7sen", "ganz", "nicht", "scheu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das verkn\u00fcpfte Liebesband", "tokens": ["Das", "ver\u00b7kn\u00fcpf\u00b7te", "Lie\u00b7bes\u00b7band"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wird uns f\u00fchren hin und her,", "tokens": ["wird", "uns", "f\u00fch\u00b7ren", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcber Trucken, \u00fcber Meer.", "tokens": ["\u00fc\u00b7ber", "Tru\u00b7cken", ",", "\u00fc\u00b7ber", "Meer", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.102": {"line.1": {"text": "Weg mit dem, der stets nur lieget", "tokens": ["Weg", "mit", "dem", ",", "der", "stets", "nur", "lie\u00b7get"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "$,", "PRELS", "ADV", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bei der faulen Ofenbank!", "tokens": ["bei", "der", "fau\u00b7len", "O\u00b7fen\u00b7bank", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sich in die Fremde f\u00fcget,", "tokens": ["Wer", "sich", "in", "die", "Frem\u00b7de", "f\u00fc\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wird bekant, verdienet Dank.", "tokens": ["wird", "be\u00b7kant", ",", "ver\u00b7die\u00b7net", "Dank", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Di\u00df ist meines Lebens Ziel,", "tokens": ["Di\u00df", "ist", "mei\u00b7nes", "Le\u00b7bens", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df ich stets mehr lernen will.", "tokens": ["da\u00df", "ich", "stets", "mehr", "ler\u00b7nen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.103": {"line.1": {"text": "Drauf so gehn wir neuen Br\u00fcder", "tokens": ["Drauf", "so", "gehn", "wir", "neu\u00b7en", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf das nahe ", "tokens": ["auf", "das", "na\u00b7he"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "da denn auch nichts mangelt wieder,", "tokens": ["da", "denn", "auch", "nichts", "man\u00b7gelt", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PIS", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was ergetzet unsern Sin.", "tokens": ["was", "er\u00b7get\u00b7zet", "un\u00b7sern", "Sin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Heint ist gleich die andre Nacht,", "tokens": ["Heint", "ist", "gleich", "die", "and\u00b7re", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df man Hochzeit da gemacht.", "tokens": ["da\u00df", "man", "Hoch\u00b7zeit", "da", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.104": {"line.1": {"text": "an die hei\u00dfe Brust gedruckt;", "tokens": ["an", "die", "hei\u00b7\u00dfe", "Brust", "ge\u00b7druckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "was ihr wol tut, wie sies juckt;", "tokens": ["was", "ihr", "wol", "tut", ",", "wie", "sies", "juckt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Andre, die zugegen sein,", "tokens": ["And\u00b7re", ",", "die", "zu\u00b7ge\u00b7gen", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "f\u00fchren einen Bauerrei'n.", "tokens": ["f\u00fch\u00b7ren", "ei\u00b7nen", "Bau\u00b7er\u00b7rei'", "n."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["VVFIN", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.105": {"line.1": {"text": "um ihr braunes Haar und steht,", "tokens": ["um", "ihr", "brau\u00b7nes", "Haar", "und", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "bis sie holet ab ihr Freier", "tokens": ["bis", "sie", "ho\u00b7let", "ab", "ihr", "Frei\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und mit ihr zu Platze geht,", "tokens": ["und", "mit", "ihr", "zu", "Plat\u00b7ze", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da sie denn um einen Tanz", "tokens": ["da", "sie", "denn", "um", "ei\u00b7nen", "Tanz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ihm vertauschet ihren Kranz.", "tokens": ["ihm", "ver\u00b7tau\u00b7schet", "ih\u00b7ren", "Kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.106": {"line.1": {"text": "Sind wir denn des Zusehns m\u00fcde,", "tokens": ["Sind", "wir", "denn", "des", "Zu\u00b7sehns", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gut! so machen wir uns fort,", "tokens": ["gut", "!", "so", "ma\u00b7chen", "wir", "uns", "fort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "lachen \u00fcber manchem Liede,", "tokens": ["la\u00b7chen", "\u00fc\u00b7ber", "man\u00b7chem", "Lie\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bis wir kommen an den Ort,", "tokens": ["bis", "wir", "kom\u00b7men", "an", "den", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "in den Hof, der uns wol kennt", "tokens": ["in", "den", "Hof", ",", "der", "uns", "wol", "kennt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und oft seine G\u00e4ste nennt.", "tokens": ["und", "oft", "sei\u00b7ne", "G\u00e4s\u00b7te", "nennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.107": {"line.1": {"text": "Zwar wir k\u00f6nten uns auch wenden", "tokens": ["Zwar", "wir", "k\u00f6n\u00b7ten", "uns", "auch", "wen\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf das sch\u00f6ne ", "tokens": ["auf", "das", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "und den Knaben vor uns senden,", "tokens": ["und", "den", "Kna\u00b7ben", "vor", "uns", "sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "der uns Alles wol bestellt,", "tokens": ["der", "uns", "Al\u00b7les", "wol", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "doch wie ", "tokens": ["doch", "wie"], "token_info": ["word", "word"], "pos": ["ADV", "KOKOM"], "meter": "-+", "measure": "iambic.single"}}, "stanza.108": {"line.1": {"text": "hier ist Lust in gutem Kauf,", "tokens": ["hier", "ist", "Lust", "in", "gu\u00b7tem", "Kauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "hier kan man dem Trauren wehren,", "tokens": ["hier", "kan", "man", "dem", "Trau\u00b7ren", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "hier tr\u00e4gt man vollauf uns auf.", "tokens": ["hier", "tr\u00e4gt", "man", "vol\u00b7lauf", "uns", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Was man w\u00fcndscht nur und begehrt,", "tokens": ["Was", "man", "w\u00fcnd\u00b7scht", "nur", "und", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "ADV", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dessen wird man hier gew\u00e4hrt.", "tokens": ["des\u00b7sen", "wird", "man", "hier", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.109": {"line.1": {"text": "Auf dem schattenreichen Rasen", "tokens": ["Auf", "dem", "schat\u00b7ten\u00b7rei\u00b7chen", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "dieses dicken Apfelbaums", "tokens": ["die\u00b7ses", "di\u00b7cken", "Ap\u00b7fel\u00b7baums"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "oder dort, wo jene grasen,", "tokens": ["o\u00b7der", "dort", ",", "wo", "je\u00b7ne", "gra\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "PDS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ist der Platz sehr gutes Raums.", "tokens": ["ist", "der", "Platz", "sehr", "gu\u00b7tes", "Raums", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oder liebt die\u00df Lusthaus ba\u00df,", "tokens": ["O\u00b7der", "liebt", "die\u00df", "Lust\u00b7haus", "ba\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da ich oft vor diesem sa\u00df?", "tokens": ["da", "ich", "oft", "vor", "die\u00b7sem", "sa\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PDAT", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.110": {"line.1": {"text": "Ich und jene lieben Dreie,", "tokens": ["Ich", "und", "je\u00b7ne", "lie\u00b7ben", "Drei\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "derer Einer nun ist hin, \u2013", "tokens": ["de\u00b7rer", "Ei\u00b7ner", "nun", "ist", "hin", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PIS", "ADV", "VAFIN", "ADV", "$,", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "itzt die \u00fcberbliebnen Zweie", "tokens": ["itzt", "die", "\u00fc\u00b7berb\u00b7lieb\u00b7nen", "Zwei\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ungesegnet von mir ziehn, \u2013", "tokens": ["un\u00b7ge\u00b7seg\u00b7net", "von", "mir", "ziehn", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ich alleine bin noch hier,", "tokens": ["ich", "al\u00b7lei\u00b7ne", "bin", "noch", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der ich wei\u00df um die Revier.", "tokens": ["der", "ich", "wei\u00df", "um", "die", "Re\u00b7vier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.111": {"line.1": {"text": "L\u00fcstet dich nach einem Fische,", "tokens": ["L\u00fcs\u00b7tet", "dich", "nach", "ei\u00b7nem", "Fi\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "den die ", "tokens": ["den", "die"], "token_info": ["word", "word"], "pos": ["ART", "ART"], "meter": "--", "measure": "unknown.measure.zero"}, "line.3": {"text": "er soll bald stehn auf dem Tische.", "tokens": ["er", "soll", "bald", "stehn", "auf", "dem", "Ti\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Liebet dir ein feister Hahn,", "tokens": ["Lie\u00b7bet", "dir", "ein", "feis\u00b7ter", "Hahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der im Hof' ist worden jung,", "tokens": ["der", "im", "Hof'", "ist", "wor\u00b7den", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VAFIN", "VAPP", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "hier giebts solches Viehs genung.", "tokens": ["hier", "giebts", "sol\u00b7ches", "Viehs", "ge\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "ADV", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.112": {"line.1": {"text": "Haben wir denn Lust zu Weine,", "tokens": ["Ha\u00b7ben", "wir", "denn", "Lust", "zu", "Wei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die den besten Trunk vom Rheine,", "tokens": ["die", "den", "bes\u00b7ten", "Trunk", "vom", "Rhei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPRART", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die den s\u00fc\u00df'sten Alakant", "tokens": ["die", "den", "s\u00fc\u00df'\u00b7sten", "A\u00b7la\u00b7kant"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und was lieber noch kan sein", "tokens": ["und", "was", "lie\u00b7ber", "noch", "kan", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "ADV", "VMFIN", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "auf der Post uns liefert ein.", "tokens": ["auf", "der", "Post", "uns", "lie\u00b7fert", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.113": {"line.1": {"text": "W\u00fcndschest da nach einer Sch\u00fcssel,", "tokens": ["W\u00fcnd\u00b7schest", "da", "nach", "ei\u00b7ner", "Sch\u00fcs\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so mit s\u00fc\u00dfer Milch gef\u00fcllt?", "tokens": ["so", "mit", "s\u00fc\u00b7\u00dfer", "Milch", "ge\u00b7f\u00fcllt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schau, dort ist der Kellerschl\u00fcssel!", "tokens": ["Schau", ",", "dort", "ist", "der", "Kel\u00b7ler\u00b7schl\u00fcs\u00b7sel", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nim dir, so am meisten gilt!", "tokens": ["Nim", "dir", ",", "so", "am", "meis\u00b7ten", "gilt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "ADV", "PTKA", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier sind Semmeln, L\u00f6ffel hier.", "tokens": ["Hier", "sind", "Sem\u00b7meln", ",", "L\u00f6f\u00b7fel", "hier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "I\u00df, so viel beliebet dir!", "tokens": ["I\u00df", ",", "so", "viel", "be\u00b7lie\u00b7bet", "dir", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADV", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.114": {"line.1": {"text": "Wollen wir zu Wasser fahren?", "tokens": ["Wol\u00b7len", "wir", "zu", "Was\u00b7ser", "fah\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dorte steht ein neuer Kahn.", "tokens": ["Dor\u00b7te", "steht", "ein", "neu\u00b7er", "Kahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Heute wird man nichts nicht sparen.", "tokens": ["Heu\u00b7te", "wird", "man", "nichts", "nicht", "spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PIS", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Knecht, greif frisch die Ruder an!", "tokens": ["Knecht", ",", "greif", "frisch", "die", "Ru\u00b7der", "an", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "mit der ", "tokens": ["mit", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.115": {"line.1": {"text": "Gleichsfals mangelts nicht an Spielen.", "tokens": ["Gleichs\u00b7fals", "man\u00b7gelts", "nicht", "an", "Spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vor uns steht das Interim,", "tokens": ["Vor", "uns", "steht", "das", "In\u00b7te\u00b7rim", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da die Peilke, hier sind M\u00fchlen,", "tokens": ["da", "die", "Peil\u00b7ke", ",", "hier", "sind", "M\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADV", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und wornach du dich siehst um,", "tokens": ["und", "wor\u00b7nach", "du", "dich", "siehst", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wol! es gilt auf gleichen Sieg,", "tokens": ["Wol", "!", "es", "gilt", "auf", "glei\u00b7chen", "Sieg", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "einen Treppel, einen Pick!", "tokens": ["ei\u00b7nen", "Trep\u00b7pel", ",", "ei\u00b7nen", "Pick", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.116": {"line.1": {"text": "Wilst du lortschen, wilst du dammen,", "tokens": ["Wilst", "du", "lort\u00b7schen", ",", "wilst", "du", "dam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wilst da ziehen in dem Schach'?", "tokens": ["wilst", "da", "zie\u00b7hen", "in", "dem", "Schach'", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Her, wir wagen uns zusammen!", "tokens": ["Her", ",", "wir", "wa\u00b7gen", "uns", "zu\u00b7sam\u00b7men", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df uns sehn, wers beste mach'!", "tokens": ["La\u00df", "uns", "sehn", ",", "wers", "bes\u00b7te", "mach'", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "ADV", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oder solls im Brete sein?", "tokens": ["O\u00b7der", "solls", "im", "Bre\u00b7te", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gut! es gilt ein Stiebchen Wein!", "tokens": ["Gut", "!", "es", "gilt", "ein", "Stieb\u00b7chen", "Wein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.117": {"line.1": {"text": "Dorte liegen auch die Kegel.", "tokens": ["Dor\u00b7te", "lie\u00b7gen", "auch", "die", "Ke\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebt dirs, nim es an mit mir!", "tokens": ["Liebt", "dirs", ",", "nim", "es", "an", "mit", "mir", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "VVIMP", "PPER", "APPR", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Inde\u00df bringt der Knecht das Legel,", "tokens": ["In\u00b7de\u00df", "bringt", "der", "Knecht", "das", "Le\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "angef\u00fcllt mit kaltem Bier,", "tokens": ["an\u00b7ge\u00b7f\u00fcllt", "mit", "kal\u00b7tem", "Bier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und das soll uns lieber sein", "tokens": ["und", "das", "soll", "uns", "lie\u00b7ber", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VMFIN", "PPER", "ADV", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "als Madrill, dein bester Wein.", "tokens": ["als", "Mad\u00b7rill", ",", "dein", "bes\u00b7ter", "Wein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.118": {"line.1": {"text": "Wenn die Sonn' am h\u00f6chsten stehet,", "tokens": ["Wenn", "die", "Sonn'", "am", "h\u00f6chs\u00b7ten", "ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPRART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doppelt ihre wilde Glut", "tokens": ["dop\u00b7pelt", "ih\u00b7re", "wil\u00b7de", "Glut"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und kein linder West nicht wehet,", "tokens": ["und", "kein", "lin\u00b7der", "West", "nicht", "we\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da verraucht uns Kraft und Mut,", "tokens": ["da", "ver\u00b7raucht", "uns", "Kraft", "und", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "bis ein frischer Trunk ersetzt", "tokens": ["bis", "ein", "fri\u00b7scher", "Trunk", "er\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "das, was in uns war verletzt.", "tokens": ["das", ",", "was", "in", "uns", "war", "ver\u00b7letzt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.119": {"line.1": {"text": "\u00dcber, unter, um und neben,", "tokens": ["\u00dc\u00b7ber", ",", "un\u00b7ter", ",", "um", "und", "ne\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "$,", "KOUI", "KON", "APPR", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "vor und hinter uns ist Lust.", "tokens": ["vor", "und", "hin\u00b7ter", "uns", "ist", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "KON", "APPR", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da ist lauter liebes Leben,", "tokens": ["Da", "ist", "lau\u00b7ter", "lie\u00b7bes", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wo wir wenden hin die Brust.", "tokens": ["wo", "wir", "wen\u00b7den", "hin", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo wir liegen, wo wir stehn,", "tokens": ["Wo", "wir", "lie\u00b7gen", ",", "wo", "wir", "stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "sehn wir Freude mit uns gehn.", "tokens": ["sehn", "wir", "Freu\u00b7de", "mit", "uns", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.120": {"line.1": {"text": "Doch was k\u00f6nnen wir alleine", "tokens": ["Doch", "was", "k\u00f6n\u00b7nen", "wir", "al\u00b7lei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VMFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mit einander lustig sein?", "tokens": ["mit", "ein\u00b7an\u00b7der", "lus\u00b7tig", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df hieher auch bitten Deine,", "tokens": ["La\u00df", "hie\u00b7her", "auch", "bit\u00b7ten", "Dei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PAV", "ADV", "VVFIN", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die nichts minder auch sind mein,", "tokens": ["die", "nichts", "min\u00b7der", "auch", "sind", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "VAFIN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "als die gleichsfals itzt, wie ich,", "tokens": ["als", "die", "gleichs\u00b7fals", "itzt", ",", "wie", "ich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ADV", "$,", "PWAV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "so bem\u00fchet sein auf dich!", "tokens": ["so", "be\u00b7m\u00fc\u00b7het", "sein", "auf", "dich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.121": {"line.1": {"text": "Hola, Junger, hole Jene,", "tokens": ["Ho\u00b7la", ",", "Jun\u00b7ger", ",", "ho\u00b7le", "Je\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "$,", "VVFIN", "PDS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jene, die du kennest wol!", "tokens": ["Je\u00b7ne", ",", "die", "du", "ken\u00b7nest", "wol", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hei\u00df sie kommen und erw\u00e4hne,", "tokens": ["Hei\u00df", "sie", "kom\u00b7men", "und", "er\u00b7w\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df wir schon sind zimlich voll!", "tokens": ["da\u00df", "wir", "schon", "sind", "zim\u00b7lich", "voll", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hei\u00df sie da sein ohn' Verzug,", "tokens": ["Hei\u00df", "sie", "da", "sein", "ohn'", "Ver\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "APPR", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "weil noch w\u00e4hrt der dritte Krug!", "tokens": ["weil", "noch", "w\u00e4hrt", "der", "drit\u00b7te", "Krug", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.122": {"line.1": {"text": "Und so wollen wir uns freuen,", "tokens": ["Und", "so", "wol\u00b7len", "wir", "uns", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bis da\u00df Ph\u00f6bus Urlaub nimmt,", "tokens": ["bis", "da\u00df", "Ph\u00f6\u00b7bus", "Ur\u00b7laub", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "bis mit ihren lichten Reien", "tokens": ["bis", "mit", "ih\u00b7ren", "lich\u00b7ten", "Rei\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Luna an ihr Zimmer k\u00f6mmt;", "tokens": ["Lu\u00b7na", "an", "ihr", "Zim\u00b7mer", "k\u00f6mmt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "bis der Tag bricht wieder ein,", "tokens": ["bis", "der", "Tag", "bricht", "wie\u00b7der", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen wir so lustig sein!", "tokens": ["wol\u00b7len", "wir", "so", "lus\u00b7tig", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}