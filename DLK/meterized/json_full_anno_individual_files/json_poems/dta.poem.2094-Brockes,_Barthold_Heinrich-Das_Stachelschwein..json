{"dta.poem.2094": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Das Stachelschwein.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1748", "urn": "urn:nbn:de:kobv:b4-200905198553", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Noch zeigt uns die Natur ein Thier, das einem Jgel", "tokens": ["Noch", "zeigt", "uns", "die", "Na\u00b7tur", "ein", "Thier", ",", "das", "ei\u00b7nem", "Jgel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "ziemlich gleich,", "tokens": ["ziem\u00b7lich", "gleich", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADV", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und das nicht weniger als jener an spitzen Stacheln", "tokens": ["Und", "das", "nicht", "we\u00b7ni\u00b7ger", "als", "je\u00b7ner", "an", "spit\u00b7zen", "Sta\u00b7cheln"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "PTKNEG", "PIS", "KOKOM", "PDS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "wunderreich,", "tokens": ["wun\u00b7der\u00b7reich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ja fast annoch betr\u00e4chtlicher, indem es mit den l\u00e4ngern", "tokens": ["Ja", "fast", "an\u00b7noch", "be\u00b7tr\u00e4cht\u00b7li\u00b7cher", ",", "in\u00b7dem", "es", "mit", "den", "l\u00e4n\u00b7gern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Spitzen", "tokens": ["Spit\u00b7zen"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Nicht nur noch mehr geschickt und f\u00e4hig, sich selbst zu", "tokens": ["Nicht", "nur", "noch", "mehr", "ge\u00b7schickt", "und", "f\u00e4\u00b7hig", ",", "sich", "selbst", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ADV", "ADV", "VVPP", "KON", "ADJD", "$,", "PRF", "ADV", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "decken und zu sch\u00fctzen,", "tokens": ["de\u00b7cken", "und", "zu", "sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Nein, sich so gar von weitem wehren und seinem Gegner", "tokens": ["Nein", ",", "sich", "so", "gar", "von", "wei\u00b7tem", "weh\u00b7ren", "und", "sei\u00b7nem", "Geg\u00b7ner"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PRF", "ADV", "ADV", "APPR", "PIS", "VVINF", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "schaden kann.", "tokens": ["scha\u00b7den", "kann", "."], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VMFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "Es f\u00e4llt mit selben seinen Feind, recht als mit spitzen", "tokens": ["Es", "f\u00e4llt", "mit", "sel\u00b7ben", "sei\u00b7nen", "Feind", ",", "recht", "als", "mit", "spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "PPOSAT", "NN", "$,", "ADJD", "KOKOM", "APPR", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Pfeilen, an,", "tokens": ["Pfei\u00b7len", ",", "an", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Und sucht von weitem ihm zu schaden. Die Art, wie", "tokens": ["Und", "sucht", "von", "wei\u00b7tem", "ihm", "zu", "scha\u00b7den", ".", "Die", "Art", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "PPER", "PTKZU", "VVINF", "$.", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "er aus seinem Fleisch", "tokens": ["er", "aus", "sei\u00b7nem", "Fleisch"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.15": {"text": "Sie so geschwinde schnellen kann, ist wunderlich. Ein", "tokens": ["Sie", "so", "ge\u00b7schwin\u00b7de", "schnel\u00b7len", "kann", ",", "ist", "wun\u00b7der\u00b7lich", ".", "Ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "ADV", "ADJA", "VVINF", "VMFIN", "$,", "VAFIN", "ADJD", "$.", "ART"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.16": {"text": "stark Ger\u00e4usch", "tokens": ["stark", "Ge\u00b7r\u00e4usch"], "token_info": ["word", "word"], "pos": ["ADJD", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "Erreget es, wenn es erz\u00fcrnt. Die Stacheln selbst sind", "tokens": ["Er\u00b7re\u00b7get", "es", ",", "wenn", "es", "er\u00b7z\u00fcrnt", ".", "Die", "Sta\u00b7cheln", "selbst", "sind"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "VVPP", "$.", "ART", "NN", "ADV", "VAFIN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "glatt und sch\u00f6n,", "tokens": ["glatt", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.19": {"text": "Wie Ebenholz und Elfenbein, ja noch fast sch\u00f6ner, an-", "tokens": ["Wie", "E\u00b7ben\u00b7holz", "und", "El\u00b7fen\u00b7bein", ",", "ja", "noch", "fast", "sch\u00f6\u00b7ner", ",", "an"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "NN", "KON", "NN", "$,", "ADV", "ADV", "ADV", "ADJD", "$,", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.20": {"text": "zusehn.", "tokens": ["zu\u00b7sehn", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "-+", "measure": "iambic.single"}, "line.21": {"text": "Sie sind oft einer Ellen lang, mit schwarzen und mit", "tokens": ["Sie", "sind", "oft", "ei\u00b7ner", "El\u00b7len", "lang", ",", "mit", "schwar\u00b7zen", "und", "mit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADJD", "$,", "APPR", "ADJA", "KON", "APPR"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.22": {"text": "wei\u00dfen Flecken,", "tokens": ["wei\u00b7\u00dfen", "Fle\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.23": {"text": "Die wir in Ordnung, eins ums andre, nicht ohne Lust", "tokens": ["Die", "wir", "in", "Ord\u00b7nung", ",", "eins", "ums", "and\u00b7re", ",", "nicht", "oh\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "$,", "PIS", "APPRART", "ADJA", "$,", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "darauf entdecken.", "tokens": ["da\u00b7rauf", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.25": {"text": "Man braucht sie bey den Schildern viel, zu auserlesnen", "tokens": ["Man", "braucht", "sie", "bey", "den", "Schil\u00b7dern", "viel", ",", "zu", "au\u00b7ser\u00b7les\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Pinselst\u00f6cken.", "tokens": ["Pin\u00b7sel\u00b7st\u00f6\u00b7cken", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.27": {"text": "Man i\u00dft ihr Fleisch, man hat auch ihrer zu heilen und", "tokens": ["Man", "i\u00dft", "ihr", "Fleisch", ",", "man", "hat", "auch", "ih\u00b7rer", "zu", "hei\u00b7len", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$,", "PIS", "VAFIN", "ADV", "PPOSAT", "PTKZU", "VVINF", "KON"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "in Arzeneyen", "tokens": ["in", "Ar\u00b7ze\u00b7ne\u00b7yen"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.29": {"text": "Sich eben auf dieselbe Weise, als wie des Jgels, zu er-", "tokens": ["Sich", "e\u00b7ben", "auf", "die\u00b7sel\u00b7be", "Wei\u00b7se", ",", "als", "wie", "des", "Jgels", ",", "zu", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PRF", "ADV", "APPR", "PDAT", "NN", "$,", "KOUS", "KOKOM", "ART", "NN", "$,", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-+--", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "freuen.", "tokens": ["freu\u00b7en", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}}}}