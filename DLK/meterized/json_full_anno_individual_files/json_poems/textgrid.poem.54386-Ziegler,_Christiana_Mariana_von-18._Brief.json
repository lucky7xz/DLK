{"textgrid.poem.54386": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "18. Brief", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Apollens werthe Braut nennt mich dein Dichterkiel!", "tokens": ["A\u00b7pol\u00b7lens", "wert\u00b7he", "Braut", "nennt", "mich", "dein", "Dich\u00b7ter\u00b7kiel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Galante \u2013 \u2013 \u2013 du denkst und schreibst zu viel;", "tokens": ["Ga\u00b7lan\u00b7te", "\u2013", "\u2013", "\u2013", "du", "denkst", "und", "schreibst", "zu", "viel", ";"], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "$(", "$(", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "PIS", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ach es erfordert mehr zum rechten Zweck zu kommen,", "tokens": ["Ach", "es", "er\u00b7for\u00b7dert", "mehr", "zum", "rech\u00b7ten", "Zweck", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und das was ich gethan, hei\u00dft noch nichts unternommen.", "tokens": ["Und", "das", "was", "ich", "ge\u00b7than", ",", "hei\u00dft", "noch", "nichts", "un\u00b7ter\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PRELS", "PPER", "VVPP", "$,", "VVFIN", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Reim zehlt uns nicht gleich zu den Poeten mit,", "tokens": ["Ein", "Reim", "zehlt", "uns", "nicht", "gleich", "zu", "den", "Po\u00b7et\u00b7en", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn man auch noch so schnell zum Musenh\u00fcgel tritt.", "tokens": ["Wenn", "man", "auch", "noch", "so", "schnell", "zum", "Mu\u00b7sen\u00b7h\u00fc\u00b7gel", "tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Hippocrenen Flu\u00df dient auch zu St\u00fcmpereyen;", "tokens": ["Der", "Hip\u00b7po\u00b7cre\u00b7nen", "Flu\u00df", "dient", "auch", "zu", "St\u00fcm\u00b7pe\u00b7rey\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Drum wirst du, Freundinn, mir vor diesesmal verzeyhen,", "tokens": ["Drum", "wirst", "du", ",", "Freun\u00b7dinn", ",", "mir", "vor", "die\u00b7ses\u00b7mal", "ver\u00b7zey\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "$,", "NN", "$,", "PPER", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich schreibe deutsch heraus, so wie das Herze denkt;", "tokens": ["Ich", "schrei\u00b7be", "deutsch", "he\u00b7raus", ",", "so", "wie", "das", "Her\u00b7ze", "denkt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$,", "ADV", "KOKOM", "PDS", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und da dein Schreiben mir so viele Neigung schenkt,", "tokens": ["Und", "da", "dein", "Schrei\u00b7ben", "mir", "so", "vie\u00b7le", "Nei\u00b7gung", "schenkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So offenbar ich dir, wie mir es sonst gegangen,", "tokens": ["So", "of\u00b7fen\u00b7bar", "ich", "dir", ",", "wie", "mir", "es", "sonst", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit was vergebner M\u00fch ich manches angefangen.", "tokens": ["Mit", "was", "ver\u00b7geb\u00b7ner", "M\u00fch", "ich", "man\u00b7ches", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJA", "NN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein Dichter soll und mu\u00df dazu gebohren seyn,", "tokens": ["Ein", "Dich\u00b7ter", "soll", "und", "mu\u00df", "da\u00b7zu", "ge\u00b7boh\u00b7ren", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "KON", "VMFIN", "PAV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das lag mir in dem Kopf, ich schrieb in Tag hinein;", "tokens": ["Das", "lag", "mir", "in", "dem", "Kopf", ",", "ich", "schrieb", "in", "Tag", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bis treuer Freunde Rath mich auf den Einfall brachte,", "tokens": ["Bis", "treu\u00b7er", "Freun\u00b7de", "Rath", "mich", "auf", "den", "Ein\u00b7fall", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df ich blo\u00df die Vernunft zu meiner Richtschnur machte.", "tokens": ["Da\u00df", "ich", "blo\u00df", "die", "Ver\u00b7nunft", "zu", "mei\u00b7ner", "Richt\u00b7schnur", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die f\u00fchrte mich so gleich ganz einen andern Weg;", "tokens": ["Die", "f\u00fchr\u00b7te", "mich", "so", "gleich", "ganz", "ei\u00b7nen", "an\u00b7dern", "Weg", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Gef\u00e4llt dir mein Gesang, betritt auch diesen Steg,", "tokens": ["Ge\u00b7f\u00e4llt", "dir", "mein", "Ge\u00b7sang", ",", "be\u00b7tritt", "auch", "die\u00b7sen", "Steg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Du wirst denselbigen sodann mit Ruhm beschreiten", "tokens": ["Du", "wirst", "den\u00b7sel\u00b7bi\u00b7gen", "so\u00b7dann", "mit", "Ruhm", "be\u00b7schrei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDS", "ADV", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Daferne du dich l\u00e4\u00dft in diesen Schranken leiten.", "tokens": ["Da\u00b7fer\u00b7ne", "du", "dich", "l\u00e4\u00dft", "in", "die\u00b7sen", "Schran\u00b7ken", "lei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Geduld, Vernunft und Zeit die k\u00f6nnen uns belehren.", "tokens": ["Ge\u00b7duld", ",", "Ver\u00b7nunft", "und", "Zeit", "die", "k\u00f6n\u00b7nen", "uns", "be\u00b7leh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ART", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "An statt da\u00df M\u00e4nner stets gelehrte Redner h\u00f6ren,", "tokens": ["An", "statt", "da\u00df", "M\u00e4n\u00b7ner", "stets", "ge\u00b7lehr\u00b7te", "Red\u00b7ner", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "KOUS", "NN", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So nehmen wir ein Buch von einer klugen Hand,", "tokens": ["So", "neh\u00b7men", "wir", "ein", "Buch", "von", "ei\u00b7ner", "klu\u00b7gen", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und machen uns daraus das was uns n\u00fctzt, bekannt.", "tokens": ["Und", "ma\u00b7chen", "uns", "da\u00b7raus", "das", "was", "uns", "n\u00fctzt", ",", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PAV", "PDS", "PRELS", "PPER", "VVFIN", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Regeln mu\u00df man auch aus ihrem Grunde wissen,", "tokens": ["Die", "Re\u00b7geln", "mu\u00df", "man", "auch", "aus", "ih\u00b7rem", "Grun\u00b7de", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Es mu\u00df uns keine M\u00fch bey dieser Kunst verdriessen;", "tokens": ["Es", "mu\u00df", "uns", "kei\u00b7ne", "M\u00fch", "bey", "die\u00b7ser", "Kunst", "ver\u00b7dries\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIAT", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wenn man die S\u00e4tze nicht recht einzutheilen weis,", "tokens": ["Wenn", "man", "die", "S\u00e4t\u00b7ze", "nicht", "recht", "ein\u00b7zu\u00b7thei\u00b7len", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PTKNEG", "ADJD", "VVIZU", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So wird dem Leser kalt, bald \u00fcbel und bald hei\u00df.", "tokens": ["So", "wird", "dem", "Le\u00b7ser", "kalt", ",", "bald", "\u00fc\u00b7bel", "und", "bald", "hei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$,", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Dem Unfall in der Zeit mit Vorsicht vor zu kommen,", "tokens": ["Dem", "Un\u00b7fall", "in", "der", "Zeit", "mit", "Vor\u00b7sicht", "vor", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So hab ich manchen Rath mit Danken angekommen.", "tokens": ["So", "hab", "ich", "man\u00b7chen", "Rath", "mit", "Dan\u00b7ken", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Es k\u00f6mmt manch sch\u00f6nes Werk zu unsrer Zeit heraus,", "tokens": ["Es", "k\u00f6mmt", "manch", "sch\u00f6\u00b7nes", "Werk", "zu", "uns\u00b7rer", "Zeit", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Ich suchte mir noch letzt dergleichen B\u00fccher aus,", "tokens": ["Ich", "such\u00b7te", "mir", "noch", "letzt", "derg\u00b7lei\u00b7chen", "B\u00fc\u00b7cher", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und lese stets mit Lust was andrer Witz geschrieben,", "tokens": ["Und", "le\u00b7se", "stets", "mit", "Lust", "was", "an\u00b7drer", "Witz", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "PWS", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Denn wer das Dichten liebt, der mu\u00df auch diese lieben.", "tokens": ["Denn", "wer", "das", "Dich\u00b7ten", "liebt", ",", "der", "mu\u00df", "auch", "die\u00b7se", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,", "ART", "VMFIN", "ADV", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So fahr ich t\u00e4glich fort, und lerne was dabey;", "tokens": ["So", "fahr", "ich", "t\u00e4g\u00b7lich", "fort", ",", "und", "ler\u00b7ne", "was", "da\u00b7bey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "PIS", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Dadurch verliehret sich das wilde Waldgeschrey.", "tokens": ["Da\u00b7durch", "ver\u00b7lieh\u00b7ret", "sich", "das", "wil\u00b7de", "Wald\u00b7ge\u00b7schrey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Die Vorschrift kann ich dir aus gutem Herzen geben;", "tokens": ["Die", "Vor\u00b7schrift", "kann", "ich", "dir", "aus", "gu\u00b7tem", "Her\u00b7zen", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Doch steht dir ferner frey derselben nach zu leben.", "tokens": ["Doch", "steht", "dir", "fer\u00b7ner", "frey", "der\u00b7sel\u00b7ben", "nach", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "PDAT", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "In liegendes Gedicht stellt sich auch bey dir ein;", "tokens": ["In", "lie\u00b7gen\u00b7des", "Ge\u00b7dicht", "stellt", "sich", "auch", "bey", "dir", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PRF", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Es soll von meiner Gunst zum Schlu\u00df der Zeuge seyn;", "tokens": ["Es", "soll", "von", "mei\u00b7ner", "Gunst", "zum", "Schlu\u00df", "der", "Zeu\u00b7ge", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "APPRART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Nebst der Versicherung, du wirst mich stets so kennen,", "tokens": ["Nebst", "der", "Ver\u00b7si\u00b7che\u00b7rung", ",", "du", "wirst", "mich", "stets", "so", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.42": {"text": "Da\u00df du mich in der That kannst deine Freundinn nennen.", "tokens": ["Da\u00df", "du", "mich", "in", "der", "That", "kannst", "dei\u00b7ne", "Freun\u00b7dinn", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}}, "stanza.2": {"line.1": {"text": "Apollens werthe Braut nennt mich dein Dichterkiel!", "tokens": ["A\u00b7pol\u00b7lens", "wert\u00b7he", "Braut", "nennt", "mich", "dein", "Dich\u00b7ter\u00b7kiel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Galante \u2013 \u2013 \u2013 du denkst und schreibst zu viel;", "tokens": ["Ga\u00b7lan\u00b7te", "\u2013", "\u2013", "\u2013", "du", "denkst", "und", "schreibst", "zu", "viel", ";"], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "$(", "$(", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "PIS", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ach es erfordert mehr zum rechten Zweck zu kommen,", "tokens": ["Ach", "es", "er\u00b7for\u00b7dert", "mehr", "zum", "rech\u00b7ten", "Zweck", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und das was ich gethan, hei\u00dft noch nichts unternommen.", "tokens": ["Und", "das", "was", "ich", "ge\u00b7than", ",", "hei\u00dft", "noch", "nichts", "un\u00b7ter\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PRELS", "PPER", "VVPP", "$,", "VVFIN", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Reim zehlt uns nicht gleich zu den Poeten mit,", "tokens": ["Ein", "Reim", "zehlt", "uns", "nicht", "gleich", "zu", "den", "Po\u00b7et\u00b7en", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn man auch noch so schnell zum Musenh\u00fcgel tritt.", "tokens": ["Wenn", "man", "auch", "noch", "so", "schnell", "zum", "Mu\u00b7sen\u00b7h\u00fc\u00b7gel", "tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Hippocrenen Flu\u00df dient auch zu St\u00fcmpereyen;", "tokens": ["Der", "Hip\u00b7po\u00b7cre\u00b7nen", "Flu\u00df", "dient", "auch", "zu", "St\u00fcm\u00b7pe\u00b7rey\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Drum wirst du, Freundinn, mir vor diesesmal verzeyhen,", "tokens": ["Drum", "wirst", "du", ",", "Freun\u00b7dinn", ",", "mir", "vor", "die\u00b7ses\u00b7mal", "ver\u00b7zey\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "$,", "NN", "$,", "PPER", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich schreibe deutsch heraus, so wie das Herze denkt;", "tokens": ["Ich", "schrei\u00b7be", "deutsch", "he\u00b7raus", ",", "so", "wie", "das", "Her\u00b7ze", "denkt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$,", "ADV", "KOKOM", "PDS", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und da dein Schreiben mir so viele Neigung schenkt,", "tokens": ["Und", "da", "dein", "Schrei\u00b7ben", "mir", "so", "vie\u00b7le", "Nei\u00b7gung", "schenkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So offenbar ich dir, wie mir es sonst gegangen,", "tokens": ["So", "of\u00b7fen\u00b7bar", "ich", "dir", ",", "wie", "mir", "es", "sonst", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit was vergebner M\u00fch ich manches angefangen.", "tokens": ["Mit", "was", "ver\u00b7geb\u00b7ner", "M\u00fch", "ich", "man\u00b7ches", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJA", "NN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein Dichter soll und mu\u00df dazu gebohren seyn,", "tokens": ["Ein", "Dich\u00b7ter", "soll", "und", "mu\u00df", "da\u00b7zu", "ge\u00b7boh\u00b7ren", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "KON", "VMFIN", "PAV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das lag mir in dem Kopf, ich schrieb in Tag hinein;", "tokens": ["Das", "lag", "mir", "in", "dem", "Kopf", ",", "ich", "schrieb", "in", "Tag", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bis treuer Freunde Rath mich auf den Einfall brachte,", "tokens": ["Bis", "treu\u00b7er", "Freun\u00b7de", "Rath", "mich", "auf", "den", "Ein\u00b7fall", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df ich blo\u00df die Vernunft zu meiner Richtschnur machte.", "tokens": ["Da\u00df", "ich", "blo\u00df", "die", "Ver\u00b7nunft", "zu", "mei\u00b7ner", "Richt\u00b7schnur", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die f\u00fchrte mich so gleich ganz einen andern Weg;", "tokens": ["Die", "f\u00fchr\u00b7te", "mich", "so", "gleich", "ganz", "ei\u00b7nen", "an\u00b7dern", "Weg", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Gef\u00e4llt dir mein Gesang, betritt auch diesen Steg,", "tokens": ["Ge\u00b7f\u00e4llt", "dir", "mein", "Ge\u00b7sang", ",", "be\u00b7tritt", "auch", "die\u00b7sen", "Steg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Du wirst denselbigen sodann mit Ruhm beschreiten", "tokens": ["Du", "wirst", "den\u00b7sel\u00b7bi\u00b7gen", "so\u00b7dann", "mit", "Ruhm", "be\u00b7schrei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDS", "ADV", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Daferne du dich l\u00e4\u00dft in diesen Schranken leiten.", "tokens": ["Da\u00b7fer\u00b7ne", "du", "dich", "l\u00e4\u00dft", "in", "die\u00b7sen", "Schran\u00b7ken", "lei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Geduld, Vernunft und Zeit die k\u00f6nnen uns belehren.", "tokens": ["Ge\u00b7duld", ",", "Ver\u00b7nunft", "und", "Zeit", "die", "k\u00f6n\u00b7nen", "uns", "be\u00b7leh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ART", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "An statt da\u00df M\u00e4nner stets gelehrte Redner h\u00f6ren,", "tokens": ["An", "statt", "da\u00df", "M\u00e4n\u00b7ner", "stets", "ge\u00b7lehr\u00b7te", "Red\u00b7ner", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "KOUS", "NN", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So nehmen wir ein Buch von einer klugen Hand,", "tokens": ["So", "neh\u00b7men", "wir", "ein", "Buch", "von", "ei\u00b7ner", "klu\u00b7gen", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und machen uns daraus das was uns n\u00fctzt, bekannt.", "tokens": ["Und", "ma\u00b7chen", "uns", "da\u00b7raus", "das", "was", "uns", "n\u00fctzt", ",", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PAV", "PDS", "PRELS", "PPER", "VVFIN", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Regeln mu\u00df man auch aus ihrem Grunde wissen,", "tokens": ["Die", "Re\u00b7geln", "mu\u00df", "man", "auch", "aus", "ih\u00b7rem", "Grun\u00b7de", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Es mu\u00df uns keine M\u00fch bey dieser Kunst verdriessen;", "tokens": ["Es", "mu\u00df", "uns", "kei\u00b7ne", "M\u00fch", "bey", "die\u00b7ser", "Kunst", "ver\u00b7dries\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIAT", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wenn man die S\u00e4tze nicht recht einzutheilen weis,", "tokens": ["Wenn", "man", "die", "S\u00e4t\u00b7ze", "nicht", "recht", "ein\u00b7zu\u00b7thei\u00b7len", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PTKNEG", "ADJD", "VVIZU", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So wird dem Leser kalt, bald \u00fcbel und bald hei\u00df.", "tokens": ["So", "wird", "dem", "Le\u00b7ser", "kalt", ",", "bald", "\u00fc\u00b7bel", "und", "bald", "hei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$,", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Dem Unfall in der Zeit mit Vorsicht vor zu kommen,", "tokens": ["Dem", "Un\u00b7fall", "in", "der", "Zeit", "mit", "Vor\u00b7sicht", "vor", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So hab ich manchen Rath mit Danken angekommen.", "tokens": ["So", "hab", "ich", "man\u00b7chen", "Rath", "mit", "Dan\u00b7ken", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Es k\u00f6mmt manch sch\u00f6nes Werk zu unsrer Zeit heraus,", "tokens": ["Es", "k\u00f6mmt", "manch", "sch\u00f6\u00b7nes", "Werk", "zu", "uns\u00b7rer", "Zeit", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Ich suchte mir noch letzt dergleichen B\u00fccher aus,", "tokens": ["Ich", "such\u00b7te", "mir", "noch", "letzt", "derg\u00b7lei\u00b7chen", "B\u00fc\u00b7cher", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und lese stets mit Lust was andrer Witz geschrieben,", "tokens": ["Und", "le\u00b7se", "stets", "mit", "Lust", "was", "an\u00b7drer", "Witz", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "PWS", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Denn wer das Dichten liebt, der mu\u00df auch diese lieben.", "tokens": ["Denn", "wer", "das", "Dich\u00b7ten", "liebt", ",", "der", "mu\u00df", "auch", "die\u00b7se", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,", "ART", "VMFIN", "ADV", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So fahr ich t\u00e4glich fort, und lerne was dabey;", "tokens": ["So", "fahr", "ich", "t\u00e4g\u00b7lich", "fort", ",", "und", "ler\u00b7ne", "was", "da\u00b7bey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "PIS", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Dadurch verliehret sich das wilde Waldgeschrey.", "tokens": ["Da\u00b7durch", "ver\u00b7lieh\u00b7ret", "sich", "das", "wil\u00b7de", "Wald\u00b7ge\u00b7schrey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Die Vorschrift kann ich dir aus gutem Herzen geben;", "tokens": ["Die", "Vor\u00b7schrift", "kann", "ich", "dir", "aus", "gu\u00b7tem", "Her\u00b7zen", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Doch steht dir ferner frey derselben nach zu leben.", "tokens": ["Doch", "steht", "dir", "fer\u00b7ner", "frey", "der\u00b7sel\u00b7ben", "nach", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "PDAT", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "In liegendes Gedicht stellt sich auch bey dir ein;", "tokens": ["In", "lie\u00b7gen\u00b7des", "Ge\u00b7dicht", "stellt", "sich", "auch", "bey", "dir", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PRF", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Es soll von meiner Gunst zum Schlu\u00df der Zeuge seyn;", "tokens": ["Es", "soll", "von", "mei\u00b7ner", "Gunst", "zum", "Schlu\u00df", "der", "Zeu\u00b7ge", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "APPRART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Nebst der Versicherung, du wirst mich stets so kennen,", "tokens": ["Nebst", "der", "Ver\u00b7si\u00b7che\u00b7rung", ",", "du", "wirst", "mich", "stets", "so", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.42": {"text": "Da\u00df du mich in der That kannst deine Freundinn nennen.", "tokens": ["Da\u00df", "du", "mich", "in", "der", "That", "kannst", "dei\u00b7ne", "Freun\u00b7dinn", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}}}}}