{"textgrid.poem.46516": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[immer that ich ihren Willen]", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Immer that ich ihren Willen", "tokens": ["Im\u00b7mer", "that", "ich", "ih\u00b7ren", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner Dichtung, und sie meinen;", "tokens": ["Mei\u00b7ner", "Dich\u00b7tung", ",", "und", "sie", "mei\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Herzbed\u00fcrfnisse zu stillen,", "tokens": ["Herz\u00b7be\u00b7d\u00fcrf\u00b7nis\u00b7se", "zu", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Seh' ich immer sie erscheinen.", "tokens": ["Seh'", "ich", "im\u00b7mer", "sie", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und so kommt sie nun, zu weinen", "tokens": ["Und", "so", "kommt", "sie", "nun", ",", "zu", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$,", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit mir um zwei theure Schatten;", "tokens": ["Mit", "mir", "um", "zwei", "theu\u00b7re", "Schat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "CARD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Sollten wir's uns nicht gestatten?", "tokens": ["Soll\u00b7ten", "wir's", "uns", "nicht", "ge\u00b7stat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Die von mir das Leben hatten,", "tokens": ["Die", "von", "mir", "das", "Le\u00b7ben", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haben es zu fr\u00fch verloren;", "tokens": ["Ha\u00b7ben", "es", "zu", "fr\u00fch", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKA", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Soll die Mutter ihrem Gatten", "tokens": ["Soll", "die", "Mut\u00b7ter", "ih\u00b7rem", "Gat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Haben sie umsonst geboren?", "tokens": ["Ha\u00b7ben", "sie", "um\u00b7sonst", "ge\u00b7bo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, ich hab' es mir geschworen,", "tokens": ["Nein", ",", "ich", "hab'", "es", "mir", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Euer Leben fort zu dichten,", "tokens": ["Eu\u00b7er", "Le\u00b7ben", "fort", "zu", "dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df mir nichts es kann vernichten.", "tokens": ["Da\u00df", "mir", "nichts", "es", "kann", "ver\u00b7nich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Immer that ich ihren Willen", "tokens": ["Im\u00b7mer", "that", "ich", "ih\u00b7ren", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner Dichtung, und sie meinen;", "tokens": ["Mei\u00b7ner", "Dich\u00b7tung", ",", "und", "sie", "mei\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Herzbed\u00fcrfnisse zu stillen,", "tokens": ["Herz\u00b7be\u00b7d\u00fcrf\u00b7nis\u00b7se", "zu", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Seh' ich immer sie erscheinen.", "tokens": ["Seh'", "ich", "im\u00b7mer", "sie", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und so kommt sie nun, zu weinen", "tokens": ["Und", "so", "kommt", "sie", "nun", ",", "zu", "wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$,", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit mir um zwei theure Schatten;", "tokens": ["Mit", "mir", "um", "zwei", "theu\u00b7re", "Schat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "CARD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Sollten wir's uns nicht gestatten?", "tokens": ["Soll\u00b7ten", "wir's", "uns", "nicht", "ge\u00b7stat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Die von mir das Leben hatten,", "tokens": ["Die", "von", "mir", "das", "Le\u00b7ben", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haben es zu fr\u00fch verloren;", "tokens": ["Ha\u00b7ben", "es", "zu", "fr\u00fch", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKA", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Soll die Mutter ihrem Gatten", "tokens": ["Soll", "die", "Mut\u00b7ter", "ih\u00b7rem", "Gat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Haben sie umsonst geboren?", "tokens": ["Ha\u00b7ben", "sie", "um\u00b7sonst", "ge\u00b7bo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, ich hab' es mir geschworen,", "tokens": ["Nein", ",", "ich", "hab'", "es", "mir", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Euer Leben fort zu dichten,", "tokens": ["Eu\u00b7er", "Le\u00b7ben", "fort", "zu", "dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df mir nichts es kann vernichten.", "tokens": ["Da\u00df", "mir", "nichts", "es", "kann", "ver\u00b7nich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}