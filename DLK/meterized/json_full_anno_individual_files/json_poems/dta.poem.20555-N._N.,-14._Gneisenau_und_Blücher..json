{"dta.poem.20555": {"metadata": {"author": {"name": "N. N., ", "birth": "N.A.", "death": "N.A."}, "title": "14.  \n  Gneisenau und Bl\u00fccher.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1848", "urn": "urn:nbn:de:kobv:b4-25129-1", "language": ["de:0.99"], "booktitle": "[N. N.]: Erinnerungen eines freiwilligen reitenden J\u00e4gers aus den Kriegsjahren 1813\u20131815. Berlin, 1848."}, "poem": {"stanza.1": {"line.1": {"text": "Eu'r Excellenz, ich melde mich Jhnen;", "tokens": ["Eu'r", "Ex\u00b7cel\u00b7lenz", ",", "ich", "mel\u00b7de", "mich", "Jh\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zum Gen\u2019ralstabs-Chef ward ich heut ernannt.", "tokens": ["Zum", "Gen'\u00b7ral\u00b7stab\u00b7sChef", "ward", "ich", "heut", "er\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein weiter Kreis des Wirkens ist erschienen", "tokens": ["Ein", "wei\u00b7ter", "Kreis", "des", "Wir\u00b7kens", "ist", "er\u00b7schie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hierdurch f\u00fcr mich, wie dankbar ich erkannt.", "tokens": ["Hier\u00b7durch", "f\u00fcr", "mich", ",", "wie", "dank\u00b7bar", "ich", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "PPER", "$,", "PWAV", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Eu\u2019r Excellenz woll\u2019 nachsichtsvoll mich f\u00fchren,", "tokens": ["Eu'r", "Ex\u00b7cel\u00b7lenz", "woll'", "nach\u00b7sichts\u00b7voll", "mich", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Um unter Jhnen Taktik zu studiren.", "tokens": ["Um", "un\u00b7ter", "Jh\u00b7nen", "Tak\u00b7tik", "zu", "stu\u00b7di\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Warum man Sie mir, General, gesandt,", "tokens": ["Wa\u00b7rum", "man", "Sie", "mir", ",", "Ge\u00b7ne\u00b7ral", ",", "ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "PPER", "$,", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist mir und wahrlich ganz genau bekannt!", "tokens": ["Ist", "mir", "und", "wahr\u00b7lich", "ganz", "ge\u00b7nau", "be\u00b7kannt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es ist der Pl\u00e4ne uns\u2019rer Schlachten wegen.", "tokens": ["Es", "ist", "der", "Pl\u00e4\u00b7ne", "un\u00b7s'\u00b7rer", "Schlach\u00b7ten", "we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Statt mit der Feder, schreib\u2019 ich mit dem Degen.", "tokens": ["Statt", "mit", "der", "Fe\u00b7der", ",", "schreib'", "ich", "mit", "dem", "De\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Dies wei\u00df man gut. Sie werden Bolzen gie\u00dfen,", "tokens": ["Dies", "wei\u00df", "man", "gut", ".", "Sie", "wer\u00b7den", "Bol\u00b7zen", "gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADJD", "$.", "PPER", "VAFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Freund ", "tokens": ["Freund"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.3": {"line.1": {"text": "Wie dem auch sei, ich hei\u00dfe Sie willkommen.", "tokens": ["Wie", "dem", "auch", "sei", ",", "ich", "hei\u00b7\u00dfe", "Sie", "will\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADV", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das, was mir fehlt, Sie werden es erg\u00e4nzen!", "tokens": ["Das", ",", "was", "mir", "fehlt", ",", "Sie", "wer\u00b7den", "es", "er\u00b7g\u00e4n\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sind Eins wir Zwei, mu\u00df es dem Ganzen frommen.", "tokens": ["Sind", "Eins", "wir", "Zwei", ",", "mu\u00df", "es", "dem", "Gan\u00b7zen", "from\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PPER", "CARD", "$,", "VMFIN", "PPER", "ART", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wohlan denn, fort zu heller Waffen T\u00e4nzen!", "tokens": ["Wo\u00b7hlan", "denn", ",", "fort", "zu", "hel\u00b7ler", "Waf\u00b7fen", "T\u00e4n\u00b7zen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PTKVZ", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es gilt den K\u00f6nig und das Land zu sch\u00fctzen!", "tokens": ["Es", "gilt", "den", "K\u00f6\u00b7nig", "und", "das", "Land", "zu", "sch\u00fct\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "La\u00dft S\u00e4bel, la\u00dft die Bajonett\u2019 erblitzen!", "tokens": ["La\u00dft", "S\u00e4\u00b7bel", ",", "la\u00dft", "die", "Ba\u00b7jo\u00b7nett'", "er\u00b7blit\u00b7zen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}