{"textgrid.poem.52117": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "26.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nachdem des Himmels Reich in grimmen Schlachten gl\u00fct,", "tokens": ["Nach\u00b7dem", "des", "Him\u00b7mels", "Reich", "in", "grim\u00b7men", "Schlach\u00b7ten", "gl\u00fct", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und niemand keine Treu in deutschen Hertzen sieht:", "tokens": ["Und", "nie\u00b7mand", "kei\u00b7ne", "Treu", "in", "deut\u00b7schen", "Hert\u00b7zen", "sieht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem ein ieder l\u00e4st das allgemeine Wesen,", "tokens": ["Nach\u00b7dem", "ein", "ie\u00b7der", "l\u00e4st", "das", "all\u00b7ge\u00b7mei\u00b7ne", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus de\u00dfen Fall er ihm sein eignes wei\u00df zu lesen.", "tokens": ["Aus", "de\u00b7\u00dfen", "Fall", "er", "ihm", "sein", "eig\u00b7nes", "wei\u00df", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PPER", "PPOSAT", "ADJA", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Nachdem wir die Gesetz und alles Recht verlohrn,", "tokens": ["Nach\u00b7dem", "wir", "die", "Ge\u00b7setz", "und", "al\u00b7les", "Recht", "ver\u00b7lohrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und alle m\u00fc\u00dfen thun, was einer auserkohrn:", "tokens": ["Und", "al\u00b7le", "m\u00fc\u00b7\u00dfen", "thun", ",", "was", "ei\u00b7ner", "au\u00b7ser\u00b7kohrn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "VVINF", "$,", "PRELS", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem man hat den Hut der Freyheit abgezogen,", "tokens": ["Nach\u00b7dem", "man", "hat", "den", "Hut", "der", "Frey\u00b7heit", "ab\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und das verfluchte Joch um ihren Hals gebogen.", "tokens": ["Und", "das", "ver\u00b7fluch\u00b7te", "Joch", "um", "ih\u00b7ren", "Hals", "ge\u00b7bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nachdem der P\u00f6fel sich zu fremden G\u00f6ttern sellt,", "tokens": ["Nach\u00b7dem", "der", "P\u00f6\u00b7fel", "sich", "zu", "frem\u00b7den", "G\u00f6t\u00b7tern", "sellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nichts von Erbarkeit und guter Auffsicht h\u00e4lt:", "tokens": ["Und", "nichts", "von", "Er\u00b7bar\u00b7keit", "und", "gu\u00b7ter", "Auff\u00b7sicht", "h\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem der Deutsche Muth von gro\u00dfen Ha\u00fcsern kommen,", "tokens": ["Nach\u00b7dem", "der", "Deut\u00b7sche", "Muth", "von", "gro\u00b7\u00dfen", "Ha\u00fc\u00b7sern", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Furcht und Heucheley inde\u00dfen eingenommen.", "tokens": ["Die", "Furcht", "und", "Heu\u00b7che\u00b7ley", "in\u00b7de\u00b7\u00dfen", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Nachdem das Band der Welt der Glauben abgethan,", "tokens": ["Nach\u00b7dem", "das", "Band", "der", "Welt", "der", "Glau\u00b7ben", "ab\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Mi\u00dftreu Frieden heist, der alles st\u00fcrtzen kan:", "tokens": ["Und", "Mi\u00df\u00b7treu", "Frie\u00b7den", "heist", ",", "der", "al\u00b7les", "st\u00fcrt\u00b7zen", "kan", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVFIN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem das Vaterland zu Sturm und Grund gegangen,", "tokens": ["Nach\u00b7dem", "das", "Va\u00b7ter\u00b7land", "zu", "Sturm", "und", "Grund", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und seine letzte H\u00fclff und Oelung hat empfangen.", "tokens": ["Und", "sei\u00b7ne", "letz\u00b7te", "H\u00fclff", "und", "O\u00b7e\u00b7lung", "hat", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Nachdem der Schatten selbst des ersten Standes fleucht", "tokens": ["Nach\u00b7dem", "der", "Schat\u00b7ten", "selbst", "des", "ers\u00b7ten", "Stan\u00b7des", "fleucht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mit der Leichen sich in ihre Grufft verkreucht,", "tokens": ["Und", "mit", "der", "Lei\u00b7chen", "sich", "in", "ih\u00b7re", "Grufft", "ver\u00b7kreucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Stirbst du, o theurer Mann, wolt ihr es recht verstehen,", "tokens": ["Stirbst", "du", ",", "o", "theu\u00b7rer", "Mann", ",", "wolt", "ihr", "es", "recht", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "FM", "ADJD", "NN", "$,", "VMFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er wil zu Grabe hin mit unserm Lande gehen.", "tokens": ["Er", "wil", "zu", "Gra\u00b7be", "hin", "mit", "un\u00b7serm", "Lan\u00b7de", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Nachdem des Himmels Reich in grimmen Schlachten gl\u00fct,", "tokens": ["Nach\u00b7dem", "des", "Him\u00b7mels", "Reich", "in", "grim\u00b7men", "Schlach\u00b7ten", "gl\u00fct", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und niemand keine Treu in deutschen Hertzen sieht:", "tokens": ["Und", "nie\u00b7mand", "kei\u00b7ne", "Treu", "in", "deut\u00b7schen", "Hert\u00b7zen", "sieht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem ein ieder l\u00e4st das allgemeine Wesen,", "tokens": ["Nach\u00b7dem", "ein", "ie\u00b7der", "l\u00e4st", "das", "all\u00b7ge\u00b7mei\u00b7ne", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus de\u00dfen Fall er ihm sein eignes wei\u00df zu lesen.", "tokens": ["Aus", "de\u00b7\u00dfen", "Fall", "er", "ihm", "sein", "eig\u00b7nes", "wei\u00df", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PPER", "PPOSAT", "ADJA", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Nachdem wir die Gesetz und alles Recht verlohrn,", "tokens": ["Nach\u00b7dem", "wir", "die", "Ge\u00b7setz", "und", "al\u00b7les", "Recht", "ver\u00b7lohrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und alle m\u00fc\u00dfen thun, was einer auserkohrn:", "tokens": ["Und", "al\u00b7le", "m\u00fc\u00b7\u00dfen", "thun", ",", "was", "ei\u00b7ner", "au\u00b7ser\u00b7kohrn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "VVINF", "$,", "PRELS", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem man hat den Hut der Freyheit abgezogen,", "tokens": ["Nach\u00b7dem", "man", "hat", "den", "Hut", "der", "Frey\u00b7heit", "ab\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und das verfluchte Joch um ihren Hals gebogen.", "tokens": ["Und", "das", "ver\u00b7fluch\u00b7te", "Joch", "um", "ih\u00b7ren", "Hals", "ge\u00b7bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Nachdem der P\u00f6fel sich zu fremden G\u00f6ttern sellt,", "tokens": ["Nach\u00b7dem", "der", "P\u00f6\u00b7fel", "sich", "zu", "frem\u00b7den", "G\u00f6t\u00b7tern", "sellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nichts von Erbarkeit und guter Auffsicht h\u00e4lt:", "tokens": ["Und", "nichts", "von", "Er\u00b7bar\u00b7keit", "und", "gu\u00b7ter", "Auff\u00b7sicht", "h\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem der Deutsche Muth von gro\u00dfen Ha\u00fcsern kommen,", "tokens": ["Nach\u00b7dem", "der", "Deut\u00b7sche", "Muth", "von", "gro\u00b7\u00dfen", "Ha\u00fc\u00b7sern", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Furcht und Heucheley inde\u00dfen eingenommen.", "tokens": ["Die", "Furcht", "und", "Heu\u00b7che\u00b7ley", "in\u00b7de\u00b7\u00dfen", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Nachdem das Band der Welt der Glauben abgethan,", "tokens": ["Nach\u00b7dem", "das", "Band", "der", "Welt", "der", "Glau\u00b7ben", "ab\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Mi\u00dftreu Frieden heist, der alles st\u00fcrtzen kan:", "tokens": ["Und", "Mi\u00df\u00b7treu", "Frie\u00b7den", "heist", ",", "der", "al\u00b7les", "st\u00fcrt\u00b7zen", "kan", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVFIN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nachdem das Vaterland zu Sturm und Grund gegangen,", "tokens": ["Nach\u00b7dem", "das", "Va\u00b7ter\u00b7land", "zu", "Sturm", "und", "Grund", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und seine letzte H\u00fclff und Oelung hat empfangen.", "tokens": ["Und", "sei\u00b7ne", "letz\u00b7te", "H\u00fclff", "und", "O\u00b7e\u00b7lung", "hat", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Nachdem der Schatten selbst des ersten Standes fleucht", "tokens": ["Nach\u00b7dem", "der", "Schat\u00b7ten", "selbst", "des", "ers\u00b7ten", "Stan\u00b7des", "fleucht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mit der Leichen sich in ihre Grufft verkreucht,", "tokens": ["Und", "mit", "der", "Lei\u00b7chen", "sich", "in", "ih\u00b7re", "Grufft", "ver\u00b7kreucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Stirbst du, o theurer Mann, wolt ihr es recht verstehen,", "tokens": ["Stirbst", "du", ",", "o", "theu\u00b7rer", "Mann", ",", "wolt", "ihr", "es", "recht", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "FM", "ADJD", "NN", "$,", "VMFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er wil zu Grabe hin mit unserm Lande gehen.", "tokens": ["Er", "wil", "zu", "Gra\u00b7be", "hin", "mit", "un\u00b7serm", "Lan\u00b7de", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}