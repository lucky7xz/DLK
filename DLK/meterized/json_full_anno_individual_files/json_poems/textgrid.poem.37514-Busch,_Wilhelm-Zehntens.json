{"textgrid.poem.37514": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Zehntens", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der heilige Antonius, so wird berichtet,", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", ",", "so", "wird", "be\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat endlich ganz auf die Welt verzichtet;", "tokens": ["Hat", "end\u00b7lich", "ganz", "auf", "die", "Welt", "ver\u00b7zich\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist tief, tief hinten im Wald gesessen,", "tokens": ["Ist", "tief", ",", "tief", "hin\u00b7ten", "im", "Wald", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ADJD", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hat Tau getrunken und Moos gegessen,", "tokens": ["Hat", "Tau", "ge\u00b7trun\u00b7ken", "und", "Moos", "ge\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVPP", "KON", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und sitzt und sitzt an diesem Ort", "tokens": ["Und", "sitzt", "und", "sitzt", "an", "die\u00b7sem", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und betet, bis er schier verdorrt", "tokens": ["Und", "be\u00b7tet", ",", "bis", "er", "schier", "ver\u00b7dorrt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihm zuletzt das wilde Kraut", "tokens": ["Und", "ihm", "zu\u00b7letzt", "das", "wil\u00b7de", "Kraut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus Nase und aus Ohren schaut.", "tokens": ["Aus", "Na\u00b7se", "und", "aus", "Oh\u00b7ren", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Er sprach: \u00bbVon hier will ich nicht weichen,", "tokens": ["Er", "sprach", ":", "\u00bb", "Von", "hier", "will", "ich", "nicht", "wei\u00b7chen", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "APPR", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Es k\u00e4m' mir denn ein glaubhaft Zeichen!\u00ab", "tokens": ["Es", "k\u00e4m'", "mir", "denn", "ein", "glaub\u00b7haft", "Zei\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und siehe da! \u2013 Aus Waldes Mitten", "tokens": ["Und", "sie\u00b7he", "da", "!", "\u2013", "Aus", "Wal\u00b7des", "Mit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "ADV", "$.", "$(", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Wildschwein kommt dahergeschritten,", "tokens": ["Ein", "Wild\u00b7schwein", "kommt", "da\u00b7her\u00b7ge\u00b7schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Das w\u00fchlet emsig an der Stelle", "tokens": ["Das", "w\u00fch\u00b7let", "em\u00b7sig", "an", "der", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Br\u00fcnnlein auf, gar rein und helle,", "tokens": ["Ein", "Br\u00fcnn\u00b7lein", "auf", ",", "gar", "rein", "und", "hel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "ADJD", "KON", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fchlt mit Schnauben und mit Schn\u00fcffeln", "tokens": ["Und", "w\u00fchlt", "mit", "Schnau\u00b7ben", "und", "mit", "Schn\u00fcf\u00b7feln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dazu hervor ein H\u00e4uflein Tr\u00fcffeln. \u2013", "tokens": ["Da\u00b7zu", "her\u00b7vor", "ein", "H\u00e4uf\u00b7lein", "Tr\u00fcf\u00b7feln", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "PTKVZ", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der heilige Antonius, voll Preis und Dank,", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", ",", "voll", "Preis", "und", "Dank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "Setzte sich nieder, a\u00df und trank", "tokens": ["Setz\u00b7te", "sich", "nie\u00b7der", ",", "a\u00df", "und", "trank"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PTKVZ", "$,", "VVFIN", "KON", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Und sprach ger\u00fchrt: \u00bbDu gutes Schwein,", "tokens": ["Und", "sprach", "ge\u00b7r\u00fchrt", ":", "\u00bb", "Du", "gu\u00b7tes", "Schwein", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$.", "$(", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du sollst nun ewig bei mir sein!\u00ab", "tokens": ["Du", "sollst", "nun", "e\u00b7wig", "bei", "mir", "sein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "APPR", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "So lebten die zwei in Einigkeit", "tokens": ["So", "leb\u00b7ten", "die", "zwei", "in", "Ei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "CARD", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hienieden auf Erden noch lange Zeit,", "tokens": ["Hien\u00b7ie\u00b7den", "auf", "Er\u00b7den", "noch", "lan\u00b7ge", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und starben endlich und starben zugleich", "tokens": ["Und", "star\u00b7ben", "end\u00b7lich", "und", "star\u00b7ben", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "KON", "VVFIN", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und fuhren zusammen vors Himmelreich. \u2013", "tokens": ["Und", "fuh\u00b7ren", "zu\u00b7sam\u00b7men", "vors", "Him\u00b7mel\u00b7reich", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "\u00bbau weih geschrien! Ein Schwein, ein Schwein!\u00ab", "tokens": ["\u00bb", "au", "weih", "ge\u00b7schri\u00b7en", "!", "Ein", "Schwein", ",", "ein", "Schwein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "VVPP", "$.", "ART", "NN", "$,", "ART", "NN", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "So huben die Juden an zu schrein;", "tokens": ["So", "hu\u00b7ben", "die", "Ju\u00b7den", "an", "zu", "schrein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "PTKZU", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und auch die T\u00fcrken kamen in Scharen", "tokens": ["Und", "auch", "die", "T\u00fcr\u00b7ken", "ka\u00b7men", "in", "Scha\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und wollten sich gegen das Schwein verwahren.\u2013", "tokens": ["Und", "woll\u00b7ten", "sich", "ge\u00b7gen", "das", "Schwein", "ver\u00b7wah\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Doch siehe! \u2013 Aus des Himmels Tor", "tokens": ["Doch", "sie\u00b7he", "!", "\u2013", "Aus", "des", "Him\u00b7mels", "Tor"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "$(", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tritt unsre liebe Frau hervor.", "tokens": ["Tritt", "uns\u00b7re", "lie\u00b7be", "Frau", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den blauen Mantel h\u00e4lt die Linke,", "tokens": ["Den", "blau\u00b7en", "Man\u00b7tel", "h\u00e4lt", "die", "Lin\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Rechte sieht man sanft erhoben,", "tokens": ["Die", "Rech\u00b7te", "sieht", "man", "sanft", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Halb drohend, halb zum Gnadenwinke;", "tokens": ["Halb", "dro\u00b7hend", ",", "halb", "zum", "Gna\u00b7den\u00b7win\u00b7ke", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So steht sie da, von Glanz umwoben.", "tokens": ["So", "steht", "sie", "da", ",", "von", "Glanz", "um\u00b7wo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbwillkommen! Gehet ein in Frieden!", "tokens": ["\u00bb", "will\u00b7kom\u00b7men", "!", "Ge\u00b7het", "ein", "in", "Frie\u00b7den", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "VVFIN", "ART", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier wird kein Freund vom Freund geschieden.", "tokens": ["Hier", "wird", "kein", "Freund", "vom", "Freund", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es kommt so manches Schaf herein,", "tokens": ["Es", "kommt", "so", "man\u00b7ches", "Schaf", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum nicht auch ein braves Schwein!!\u00ab", "tokens": ["Wa\u00b7rum", "nicht", "auch", "ein", "bra\u00b7ves", "Schwein", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da grunzte das Schwein, die Englein sangen.", "tokens": ["Da", "grunz\u00b7te", "das", "Schwein", ",", "die", "En\u00b7glein", "san\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So sind sie beide hineingegangen.", "tokens": ["So", "sind", "sie", "bei\u00b7de", "hin\u00b7ein\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Der heilige Antonius, so wird berichtet,", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", ",", "so", "wird", "be\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat endlich ganz auf die Welt verzichtet;", "tokens": ["Hat", "end\u00b7lich", "ganz", "auf", "die", "Welt", "ver\u00b7zich\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist tief, tief hinten im Wald gesessen,", "tokens": ["Ist", "tief", ",", "tief", "hin\u00b7ten", "im", "Wald", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ADJD", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hat Tau getrunken und Moos gegessen,", "tokens": ["Hat", "Tau", "ge\u00b7trun\u00b7ken", "und", "Moos", "ge\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVPP", "KON", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und sitzt und sitzt an diesem Ort", "tokens": ["Und", "sitzt", "und", "sitzt", "an", "die\u00b7sem", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und betet, bis er schier verdorrt", "tokens": ["Und", "be\u00b7tet", ",", "bis", "er", "schier", "ver\u00b7dorrt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihm zuletzt das wilde Kraut", "tokens": ["Und", "ihm", "zu\u00b7letzt", "das", "wil\u00b7de", "Kraut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus Nase und aus Ohren schaut.", "tokens": ["Aus", "Na\u00b7se", "und", "aus", "Oh\u00b7ren", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Er sprach: \u00bbVon hier will ich nicht weichen,", "tokens": ["Er", "sprach", ":", "\u00bb", "Von", "hier", "will", "ich", "nicht", "wei\u00b7chen", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "APPR", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Es k\u00e4m' mir denn ein glaubhaft Zeichen!\u00ab", "tokens": ["Es", "k\u00e4m'", "mir", "denn", "ein", "glaub\u00b7haft", "Zei\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und siehe da! \u2013 Aus Waldes Mitten", "tokens": ["Und", "sie\u00b7he", "da", "!", "\u2013", "Aus", "Wal\u00b7des", "Mit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "ADV", "$.", "$(", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Wildschwein kommt dahergeschritten,", "tokens": ["Ein", "Wild\u00b7schwein", "kommt", "da\u00b7her\u00b7ge\u00b7schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Das w\u00fchlet emsig an der Stelle", "tokens": ["Das", "w\u00fch\u00b7let", "em\u00b7sig", "an", "der", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Br\u00fcnnlein auf, gar rein und helle,", "tokens": ["Ein", "Br\u00fcnn\u00b7lein", "auf", ",", "gar", "rein", "und", "hel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "ADJD", "KON", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fchlt mit Schnauben und mit Schn\u00fcffeln", "tokens": ["Und", "w\u00fchlt", "mit", "Schnau\u00b7ben", "und", "mit", "Schn\u00fcf\u00b7feln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dazu hervor ein H\u00e4uflein Tr\u00fcffeln. \u2013", "tokens": ["Da\u00b7zu", "her\u00b7vor", "ein", "H\u00e4uf\u00b7lein", "Tr\u00fcf\u00b7feln", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "PTKVZ", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der heilige Antonius, voll Preis und Dank,", "tokens": ["Der", "hei\u00b7li\u00b7ge", "An\u00b7to\u00b7ni\u00b7us", ",", "voll", "Preis", "und", "Dank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "Setzte sich nieder, a\u00df und trank", "tokens": ["Setz\u00b7te", "sich", "nie\u00b7der", ",", "a\u00df", "und", "trank"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PTKVZ", "$,", "VVFIN", "KON", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Und sprach ger\u00fchrt: \u00bbDu gutes Schwein,", "tokens": ["Und", "sprach", "ge\u00b7r\u00fchrt", ":", "\u00bb", "Du", "gu\u00b7tes", "Schwein", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$.", "$(", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du sollst nun ewig bei mir sein!\u00ab", "tokens": ["Du", "sollst", "nun", "e\u00b7wig", "bei", "mir", "sein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "APPR", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "So lebten die zwei in Einigkeit", "tokens": ["So", "leb\u00b7ten", "die", "zwei", "in", "Ei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "CARD", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hienieden auf Erden noch lange Zeit,", "tokens": ["Hien\u00b7ie\u00b7den", "auf", "Er\u00b7den", "noch", "lan\u00b7ge", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Und starben endlich und starben zugleich", "tokens": ["Und", "star\u00b7ben", "end\u00b7lich", "und", "star\u00b7ben", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "KON", "VVFIN", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und fuhren zusammen vors Himmelreich. \u2013", "tokens": ["Und", "fuh\u00b7ren", "zu\u00b7sam\u00b7men", "vors", "Him\u00b7mel\u00b7reich", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "\u00bbau weih geschrien! Ein Schwein, ein Schwein!\u00ab", "tokens": ["\u00bb", "au", "weih", "ge\u00b7schri\u00b7en", "!", "Ein", "Schwein", ",", "ein", "Schwein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "VVPP", "$.", "ART", "NN", "$,", "ART", "NN", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "So huben die Juden an zu schrein;", "tokens": ["So", "hu\u00b7ben", "die", "Ju\u00b7den", "an", "zu", "schrein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "PTKZU", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und auch die T\u00fcrken kamen in Scharen", "tokens": ["Und", "auch", "die", "T\u00fcr\u00b7ken", "ka\u00b7men", "in", "Scha\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und wollten sich gegen das Schwein verwahren.\u2013", "tokens": ["Und", "woll\u00b7ten", "sich", "ge\u00b7gen", "das", "Schwein", "ver\u00b7wah\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Doch siehe! \u2013 Aus des Himmels Tor", "tokens": ["Doch", "sie\u00b7he", "!", "\u2013", "Aus", "des", "Him\u00b7mels", "Tor"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "$(", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tritt unsre liebe Frau hervor.", "tokens": ["Tritt", "uns\u00b7re", "lie\u00b7be", "Frau", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den blauen Mantel h\u00e4lt die Linke,", "tokens": ["Den", "blau\u00b7en", "Man\u00b7tel", "h\u00e4lt", "die", "Lin\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Rechte sieht man sanft erhoben,", "tokens": ["Die", "Rech\u00b7te", "sieht", "man", "sanft", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Halb drohend, halb zum Gnadenwinke;", "tokens": ["Halb", "dro\u00b7hend", ",", "halb", "zum", "Gna\u00b7den\u00b7win\u00b7ke", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So steht sie da, von Glanz umwoben.", "tokens": ["So", "steht", "sie", "da", ",", "von", "Glanz", "um\u00b7wo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "\u00bbwillkommen! Gehet ein in Frieden!", "tokens": ["\u00bb", "will\u00b7kom\u00b7men", "!", "Ge\u00b7het", "ein", "in", "Frie\u00b7den", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "VVFIN", "ART", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier wird kein Freund vom Freund geschieden.", "tokens": ["Hier", "wird", "kein", "Freund", "vom", "Freund", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es kommt so manches Schaf herein,", "tokens": ["Es", "kommt", "so", "man\u00b7ches", "Schaf", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum nicht auch ein braves Schwein!!\u00ab", "tokens": ["Wa\u00b7rum", "nicht", "auch", "ein", "bra\u00b7ves", "Schwein", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da grunzte das Schwein, die Englein sangen.", "tokens": ["Da", "grunz\u00b7te", "das", "Schwein", ",", "die", "En\u00b7glein", "san\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So sind sie beide hineingegangen.", "tokens": ["So", "sind", "sie", "bei\u00b7de", "hin\u00b7ein\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}