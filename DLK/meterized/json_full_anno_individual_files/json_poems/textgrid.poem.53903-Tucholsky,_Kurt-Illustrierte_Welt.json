{"textgrid.poem.53903": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Illustrierte Welt", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Geh\u00f6ren Sie vielleicht zur Zeitgeschichte \u2013?", "tokens": ["Ge\u00b7h\u00f6\u00b7ren", "Sie", "viel\u00b7leicht", "zur", "Zeit\u00b7ge\u00b7schich\u00b7te", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "ADV", "APPRART", "NN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn ich Sie im Profil ver\u00f6ffentlichte,", "tokens": ["Wenn", "ich", "Sie", "im", "Pro\u00b7fil", "ver\u00b7\u00f6f\u00b7fent\u00b7lich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "geh\u00f6rt mir Ihr Gesicht.", "tokens": ["ge\u00b7h\u00f6rt", "mir", "Ihr", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Sind Sie dagegen nur ein ganz Privater,", "tokens": ["Sind", "Sie", "da\u00b7ge\u00b7gen", "nur", "ein", "ganz", "Pri\u00b7va\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "ADV", "ART", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ein armer, pensionierter Landesvater:", "tokens": ["ein", "ar\u00b7mer", ",", "pen\u00b7si\u00b7o\u00b7nier\u00b7ter", "Lan\u00b7des\u00b7va\u00b7ter", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "dann darf ich sowas nicht.", "tokens": ["dann", "darf", "ich", "so\u00b7was", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Die Prinzen, die ich niemals knipsen kann,", "tokens": ["Die", "Prin\u00b7zen", ",", "die", "ich", "nie\u00b7mals", "knip\u00b7sen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "geh\u00f6ren nicht der Zeitgeschichte an.", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "nicht", "der", "Zeit\u00b7ge\u00b7schich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Doch wer geh\u00f6rt nun so zur Zeitgeschichte?", "tokens": ["Doch", "wer", "ge\u00b7h\u00f6rt", "nun", "so", "zur", "Zeit\u00b7ge\u00b7schich\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Herr Rosner, der die Heldenliedgedichte", "tokens": ["Herr", "Ros\u00b7ner", ",", "der", "die", "Hel\u00b7den\u00b7lied\u00b7ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "von einem Reisenden in Waffen schrieb?", "tokens": ["von", "ei\u00b7nem", "Rei\u00b7sen\u00b7den", "in", "Waf\u00b7fen", "schrieb", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der selige Sternheim, Asthma deutscher Szenen?", "tokens": ["Der", "se\u00b7li\u00b7ge", "Stern\u00b7heim", ",", "Asth\u00b7ma", "deut\u00b7scher", "Sze\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "NE", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Die Karin Michaelis, Schmockbild aller D\u00e4nen?", "tokens": ["Die", "Ka\u00b7rin", "Mic\u00b7ha\u00b7e\u00b7lis", ",", "Schmock\u00b7bild", "al\u00b7ler", "D\u00e4\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ein Pfreudenm\u00e4dchen? ein Millionendieb?", "tokens": ["ein", "Pfreu\u00b7den\u00b7m\u00e4d\u00b7chen", "?", "ein", "Mil\u00b7li\u00b7o\u00b7nen\u00b7dieb", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Auch diese da \u2013 ich zweifle kaum daran \u2013", "tokens": ["Auch", "die\u00b7se", "da", "\u2013", "ich", "zweif\u00b7le", "kaum", "da\u00b7ran", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "ADV", "$(", "PPER", "VVFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "geh\u00f6ren nicht der Zeitgeschichte an.", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "nicht", "der", "Zeit\u00b7ge\u00b7schich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Jedoch die Richter, schwarz-rot-gold vernickelt,", "tokens": ["Je\u00b7doch", "die", "Rich\u00b7ter", ",", "schwa\u00b7rz\u00b7rot\u00b7gold", "ver\u00b7ni\u00b7ckelt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "die wie die Fotos vielfach unentwickelt,", "tokens": ["die", "wie", "die", "Fo\u00b7tos", "viel\u00b7fach", "un\u00b7ent\u00b7wi\u00b7ckelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mitunter nicht so recht belichtet sind;", "tokens": ["mi\u00b7tun\u00b7ter", "nicht", "so", "recht", "be\u00b7lich\u00b7tet", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die Richter, die den letzten Prinzen sch\u00fctzen", "tokens": ["die", "Rich\u00b7ter", ",", "die", "den", "letz\u00b7ten", "Prin\u00b7zen", "sch\u00fct\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und jeden Wunsch aus Holland unterst\u00fctzen,", "tokens": ["und", "je\u00b7den", "Wunsch", "aus", "Hol\u00b7land", "un\u00b7ter\u00b7st\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "f\u00fcr neun Jahr Zeitaufnahme g\u00e4nzlich blind \u2013:", "tokens": ["f\u00fcr", "neun", "Jahr", "Zeit\u00b7auf\u00b7nah\u00b7me", "g\u00e4nz\u00b7lich", "blind", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "CARD", "NN", "NN", "ADJD", "ADJD", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ja, diese Richter \u2013 das sieht jedermann \u2013", "tokens": ["Ja", ",", "die\u00b7se", "Rich\u00b7ter", "\u2013", "das", "sieht", "je\u00b7der\u00b7mann", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDAT", "NN", "$(", "PDS", "VVFIN", "PIS", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "geh\u00f6ren \u2013", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "\u2013"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "wie sie gebacken und gebraten sind \u2013", "tokens": ["wie", "sie", "ge\u00b7ba\u00b7cken", "und", "ge\u00b7bra\u00b7ten", "sind", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "KON", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Im Namen des Volkes!", "tokens": ["Im", "Na\u00b7men", "des", "Vol\u00b7kes", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "geh\u00f6ren unsrer Zeitgeschichte an.", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "uns\u00b7rer", "Zeit\u00b7ge\u00b7schich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Geh\u00f6ren Sie vielleicht zur Zeitgeschichte \u2013?", "tokens": ["Ge\u00b7h\u00f6\u00b7ren", "Sie", "viel\u00b7leicht", "zur", "Zeit\u00b7ge\u00b7schich\u00b7te", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "ADV", "APPRART", "NN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn ich Sie im Profil ver\u00f6ffentlichte,", "tokens": ["Wenn", "ich", "Sie", "im", "Pro\u00b7fil", "ver\u00b7\u00f6f\u00b7fent\u00b7lich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "geh\u00f6rt mir Ihr Gesicht.", "tokens": ["ge\u00b7h\u00f6rt", "mir", "Ihr", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Sind Sie dagegen nur ein ganz Privater,", "tokens": ["Sind", "Sie", "da\u00b7ge\u00b7gen", "nur", "ein", "ganz", "Pri\u00b7va\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "ADV", "ART", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ein armer, pensionierter Landesvater:", "tokens": ["ein", "ar\u00b7mer", ",", "pen\u00b7si\u00b7o\u00b7nier\u00b7ter", "Lan\u00b7des\u00b7va\u00b7ter", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "dann darf ich sowas nicht.", "tokens": ["dann", "darf", "ich", "so\u00b7was", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Die Prinzen, die ich niemals knipsen kann,", "tokens": ["Die", "Prin\u00b7zen", ",", "die", "ich", "nie\u00b7mals", "knip\u00b7sen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "geh\u00f6ren nicht der Zeitgeschichte an.", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "nicht", "der", "Zeit\u00b7ge\u00b7schich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Doch wer geh\u00f6rt nun so zur Zeitgeschichte?", "tokens": ["Doch", "wer", "ge\u00b7h\u00f6rt", "nun", "so", "zur", "Zeit\u00b7ge\u00b7schich\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Herr Rosner, der die Heldenliedgedichte", "tokens": ["Herr", "Ros\u00b7ner", ",", "der", "die", "Hel\u00b7den\u00b7lied\u00b7ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "von einem Reisenden in Waffen schrieb?", "tokens": ["von", "ei\u00b7nem", "Rei\u00b7sen\u00b7den", "in", "Waf\u00b7fen", "schrieb", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der selige Sternheim, Asthma deutscher Szenen?", "tokens": ["Der", "se\u00b7li\u00b7ge", "Stern\u00b7heim", ",", "Asth\u00b7ma", "deut\u00b7scher", "Sze\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "NE", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Die Karin Michaelis, Schmockbild aller D\u00e4nen?", "tokens": ["Die", "Ka\u00b7rin", "Mic\u00b7ha\u00b7e\u00b7lis", ",", "Schmock\u00b7bild", "al\u00b7ler", "D\u00e4\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ein Pfreudenm\u00e4dchen? ein Millionendieb?", "tokens": ["ein", "Pfreu\u00b7den\u00b7m\u00e4d\u00b7chen", "?", "ein", "Mil\u00b7li\u00b7o\u00b7nen\u00b7dieb", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Auch diese da \u2013 ich zweifle kaum daran \u2013", "tokens": ["Auch", "die\u00b7se", "da", "\u2013", "ich", "zweif\u00b7le", "kaum", "da\u00b7ran", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "ADV", "$(", "PPER", "VVFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "geh\u00f6ren nicht der Zeitgeschichte an.", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "nicht", "der", "Zeit\u00b7ge\u00b7schich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Jedoch die Richter, schwarz-rot-gold vernickelt,", "tokens": ["Je\u00b7doch", "die", "Rich\u00b7ter", ",", "schwa\u00b7rz\u00b7rot\u00b7gold", "ver\u00b7ni\u00b7ckelt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "die wie die Fotos vielfach unentwickelt,", "tokens": ["die", "wie", "die", "Fo\u00b7tos", "viel\u00b7fach", "un\u00b7ent\u00b7wi\u00b7ckelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mitunter nicht so recht belichtet sind;", "tokens": ["mi\u00b7tun\u00b7ter", "nicht", "so", "recht", "be\u00b7lich\u00b7tet", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die Richter, die den letzten Prinzen sch\u00fctzen", "tokens": ["die", "Rich\u00b7ter", ",", "die", "den", "letz\u00b7ten", "Prin\u00b7zen", "sch\u00fct\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und jeden Wunsch aus Holland unterst\u00fctzen,", "tokens": ["und", "je\u00b7den", "Wunsch", "aus", "Hol\u00b7land", "un\u00b7ter\u00b7st\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "f\u00fcr neun Jahr Zeitaufnahme g\u00e4nzlich blind \u2013:", "tokens": ["f\u00fcr", "neun", "Jahr", "Zeit\u00b7auf\u00b7nah\u00b7me", "g\u00e4nz\u00b7lich", "blind", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "CARD", "NN", "NN", "ADJD", "ADJD", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ja, diese Richter \u2013 das sieht jedermann \u2013", "tokens": ["Ja", ",", "die\u00b7se", "Rich\u00b7ter", "\u2013", "das", "sieht", "je\u00b7der\u00b7mann", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDAT", "NN", "$(", "PDS", "VVFIN", "PIS", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "geh\u00f6ren \u2013", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "\u2013"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "wie sie gebacken und gebraten sind \u2013", "tokens": ["wie", "sie", "ge\u00b7ba\u00b7cken", "und", "ge\u00b7bra\u00b7ten", "sind", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "KON", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Im Namen des Volkes!", "tokens": ["Im", "Na\u00b7men", "des", "Vol\u00b7kes", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "geh\u00f6ren unsrer Zeitgeschichte an.", "tokens": ["ge\u00b7h\u00f6\u00b7ren", "uns\u00b7rer", "Zeit\u00b7ge\u00b7schich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}