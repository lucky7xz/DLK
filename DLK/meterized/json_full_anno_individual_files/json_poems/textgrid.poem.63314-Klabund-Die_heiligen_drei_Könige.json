{"textgrid.poem.63314": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Die heiligen drei K\u00f6nige", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir sind die drei Weisen aus dem Morgenland,", "tokens": ["Wir", "sind", "die", "drei", "Wei\u00b7sen", "aus", "dem", "Mor\u00b7gen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Die Sonne, die hat uns so schwarz gebrannt.", "tokens": ["Die", "Son\u00b7ne", ",", "die", "hat", "uns", "so", "schwarz", "ge\u00b7brannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Unsere Haut ist schwarz, unsere Seel ist klar,", "tokens": ["Un\u00b7se\u00b7re", "Haut", "ist", "schwarz", ",", "un\u00b7se\u00b7re", "Seel", "ist", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "+--+-+---+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Doch unser Hemd ist besch... ganz und gar.", "tokens": ["Doch", "un\u00b7ser", "Hemd", "ist", "besch.", "..", "ganz", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "abbreviation", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Der erste, der tr\u00e4gt eine lederne Hos',", "tokens": ["Der", "ers\u00b7te", ",", "der", "tr\u00e4gt", "ei\u00b7ne", "le\u00b7der\u00b7ne", "Hos'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Der zweite ist gar am A... blo\u00df,", "tokens": ["Der", "zwei\u00b7te", "ist", "gar", "am", "A", "...", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "abbreviation", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "APPRART", "NE", "$(", "ADV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der dritte hat einen spitzigen Hut,", "tokens": ["Der", "drit\u00b7te", "hat", "ei\u00b7nen", "spit\u00b7zi\u00b7gen", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf dem ein Stern sich drehen tut.", "tokens": ["Auf", "dem", "ein", "Stern", "sich", "dre\u00b7hen", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Der erste, der hat den Kopf voll Grind,", "tokens": ["Der", "ers\u00b7te", ",", "der", "hat", "den", "Kopf", "voll", "Grind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "VAFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der zweite ist ein unehlich' Kind.", "tokens": ["Der", "zwei\u00b7te", "ist", "ein", "un\u00b7eh\u00b7lich'", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der dritte nicht Vater, nicht Mutter preist,", "tokens": ["Der", "drit\u00b7te", "nicht", "Va\u00b7ter", ",", "nicht", "Mut\u00b7ter", "preist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKNEG", "NN", "$,", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Ihn zeugte h\u00f6chstselbst der heilige Geist.", "tokens": ["Ihn", "zeug\u00b7te", "h\u00f6chst\u00b7selbst", "der", "hei\u00b7li\u00b7ge", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "Der erste hat einen Pfennig gespart,", "tokens": ["Der", "ers\u00b7te", "hat", "ei\u00b7nen", "Pfen\u00b7nig", "ge\u00b7spart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der zweite hat L\u00e4use in seinem Bart,", "tokens": ["Der", "zwei\u00b7te", "hat", "L\u00e4u\u00b7se", "in", "sei\u00b7nem", "Bart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der dritte hat noch weniger als nichts,", "tokens": ["Der", "drit\u00b7te", "hat", "noch", "we\u00b7ni\u00b7ger", "als", "nichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "PIS", "KOKOM", "PIS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er steht im Strahl des g\u00f6ttlichen Lichts.", "tokens": ["Er", "steht", "im", "Strahl", "des", "g\u00f6tt\u00b7li\u00b7chen", "Lichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Wir sind die heiligen drei K\u00f6nige,", "tokens": ["Wir", "sind", "die", "hei\u00b7li\u00b7gen", "drei", "K\u00f6\u00b7ni\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wir haben W\u00fcnsche nicht wenige.", "tokens": ["Wir", "ha\u00b7ben", "W\u00fcn\u00b7sche", "nicht", "we\u00b7ni\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "PTKNEG", "PIS", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den ersten hungert, den zweiten d\u00fcrst',", "tokens": ["Den", "ers\u00b7ten", "hun\u00b7gert", ",", "den", "zwei\u00b7ten", "d\u00fcr\u00b7st'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$,", "ART", "ADJA", "VMFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der dritte w\u00fcnscht sich gebratene W\u00fcrst.", "tokens": ["Der", "drit\u00b7te", "w\u00fcnscht", "sich", "ge\u00b7bra\u00b7te\u00b7ne", "W\u00fcrst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Ach, schenkt den armen drei K\u00f6nigen was.", "tokens": ["Ach", ",", "schenkt", "den", "ar\u00b7men", "drei", "K\u00f6\u00b7ni\u00b7gen", "was", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "ART", "ADJA", "CARD", "NN", "PWS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Sch\u00f6pfl\u00f6ffel aus dem Heringsfa\u00df \u2013", "tokens": ["Ein", "Sch\u00f6pf\u00b7l\u00f6f\u00b7fel", "aus", "dem", "He\u00b7rings\u00b7fa\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Verschimmelt Brot, verfaulter Fisch,", "tokens": ["Ver\u00b7schim\u00b7melt", "Brot", ",", "ver\u00b7faul\u00b7ter", "Fisch", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da setzen sie sich noch fr\u00f6hlich zu Tisch.", "tokens": ["Da", "set\u00b7zen", "sie", "sich", "noch", "fr\u00f6h\u00b7lich", "zu", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.7": {"line.1": {"text": "Wir singen einen s\u00fc\u00dfen Gesang", "tokens": ["Wir", "sin\u00b7gen", "ei\u00b7nen", "s\u00fc\u00b7\u00dfen", "Ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Den Weibern auf der Ofenbank.", "tokens": ["Den", "Wei\u00b7bern", "auf", "der", "O\u00b7fen\u00b7bank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir lassen an einem jeglichen Ort", "tokens": ["Wir", "las\u00b7sen", "an", "ei\u00b7nem", "jeg\u00b7li\u00b7chen", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "PIAT", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einen kleinen heiligen K\u00f6nig zum Andenken dort.", "tokens": ["Ei\u00b7nen", "klei\u00b7nen", "hei\u00b7li\u00b7gen", "K\u00f6\u00b7nig", "zum", "An\u00b7den\u00b7ken", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "APPRART", "NN", "ADV", "$."], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.8": {"line.1": {"text": "Wir geben euch unseren Segen drein,", "tokens": ["Wir", "ge\u00b7ben", "euch", "un\u00b7se\u00b7ren", "Se\u00b7gen", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Gemischt aus Kuhdreck und Rosmarein.", "tokens": ["Ge\u00b7mischt", "aus", "Kuh\u00b7dreck", "und", "Ros\u00b7ma\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir danken f\u00fcr Schnaps, wir danken f\u00fcr Bier.", "tokens": ["Wir", "dan\u00b7ken", "f\u00fcr", "Schnaps", ",", "wir", "dan\u00b7ken", "f\u00fcr", "Bier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Anders Jahr um die Zeit sind wir wieder hier.", "tokens": ["An\u00b7ders", "Jahr", "um", "die", "Zeit", "sind", "wir", "wie\u00b7der", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.9": {"line.1": {"text": "Wir sind die drei Weisen aus dem Morgenland,", "tokens": ["Wir", "sind", "die", "drei", "Wei\u00b7sen", "aus", "dem", "Mor\u00b7gen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Die Sonne, die hat uns so schwarz gebrannt.", "tokens": ["Die", "Son\u00b7ne", ",", "die", "hat", "uns", "so", "schwarz", "ge\u00b7brannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Unsere Haut ist schwarz, unsere Seel ist klar,", "tokens": ["Un\u00b7se\u00b7re", "Haut", "ist", "schwarz", ",", "un\u00b7se\u00b7re", "Seel", "ist", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "+--+-+---+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Doch unser Hemd ist besch... ganz und gar.", "tokens": ["Doch", "un\u00b7ser", "Hemd", "ist", "besch.", "..", "ganz", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "abbreviation", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.10": {"line.1": {"text": "Der erste, der tr\u00e4gt eine lederne Hos',", "tokens": ["Der", "ers\u00b7te", ",", "der", "tr\u00e4gt", "ei\u00b7ne", "le\u00b7der\u00b7ne", "Hos'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Der zweite ist gar am A... blo\u00df,", "tokens": ["Der", "zwei\u00b7te", "ist", "gar", "am", "A", "...", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "abbreviation", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "APPRART", "NE", "$(", "ADV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der dritte hat einen spitzigen Hut,", "tokens": ["Der", "drit\u00b7te", "hat", "ei\u00b7nen", "spit\u00b7zi\u00b7gen", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf dem ein Stern sich drehen tut.", "tokens": ["Auf", "dem", "ein", "Stern", "sich", "dre\u00b7hen", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.11": {"line.1": {"text": "Der erste, der hat den Kopf voll Grind,", "tokens": ["Der", "ers\u00b7te", ",", "der", "hat", "den", "Kopf", "voll", "Grind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "VAFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der zweite ist ein unehlich' Kind.", "tokens": ["Der", "zwei\u00b7te", "ist", "ein", "un\u00b7eh\u00b7lich'", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der dritte nicht Vater, nicht Mutter preist,", "tokens": ["Der", "drit\u00b7te", "nicht", "Va\u00b7ter", ",", "nicht", "Mut\u00b7ter", "preist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKNEG", "NN", "$,", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Ihn zeugte h\u00f6chstselbst der heilige Geist.", "tokens": ["Ihn", "zeug\u00b7te", "h\u00f6chst\u00b7selbst", "der", "hei\u00b7li\u00b7ge", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.12": {"line.1": {"text": "Der erste hat einen Pfennig gespart,", "tokens": ["Der", "ers\u00b7te", "hat", "ei\u00b7nen", "Pfen\u00b7nig", "ge\u00b7spart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der zweite hat L\u00e4use in seinem Bart,", "tokens": ["Der", "zwei\u00b7te", "hat", "L\u00e4u\u00b7se", "in", "sei\u00b7nem", "Bart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der dritte hat noch weniger als nichts,", "tokens": ["Der", "drit\u00b7te", "hat", "noch", "we\u00b7ni\u00b7ger", "als", "nichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "PIS", "KOKOM", "PIS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er steht im Strahl des g\u00f6ttlichen Lichts.", "tokens": ["Er", "steht", "im", "Strahl", "des", "g\u00f6tt\u00b7li\u00b7chen", "Lichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.13": {"line.1": {"text": "Wir sind die heiligen drei K\u00f6nige,", "tokens": ["Wir", "sind", "die", "hei\u00b7li\u00b7gen", "drei", "K\u00f6\u00b7ni\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wir haben W\u00fcnsche nicht wenige.", "tokens": ["Wir", "ha\u00b7ben", "W\u00fcn\u00b7sche", "nicht", "we\u00b7ni\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "PTKNEG", "PIS", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den ersten hungert, den zweiten d\u00fcrst',", "tokens": ["Den", "ers\u00b7ten", "hun\u00b7gert", ",", "den", "zwei\u00b7ten", "d\u00fcr\u00b7st'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$,", "ART", "ADJA", "VMFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der dritte w\u00fcnscht sich gebratene W\u00fcrst.", "tokens": ["Der", "drit\u00b7te", "w\u00fcnscht", "sich", "ge\u00b7bra\u00b7te\u00b7ne", "W\u00fcrst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.14": {"line.1": {"text": "Ach, schenkt den armen drei K\u00f6nigen was.", "tokens": ["Ach", ",", "schenkt", "den", "ar\u00b7men", "drei", "K\u00f6\u00b7ni\u00b7gen", "was", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "ART", "ADJA", "CARD", "NN", "PWS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Sch\u00f6pfl\u00f6ffel aus dem Heringsfa\u00df \u2013", "tokens": ["Ein", "Sch\u00f6pf\u00b7l\u00f6f\u00b7fel", "aus", "dem", "He\u00b7rings\u00b7fa\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Verschimmelt Brot, verfaulter Fisch,", "tokens": ["Ver\u00b7schim\u00b7melt", "Brot", ",", "ver\u00b7faul\u00b7ter", "Fisch", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da setzen sie sich noch fr\u00f6hlich zu Tisch.", "tokens": ["Da", "set\u00b7zen", "sie", "sich", "noch", "fr\u00f6h\u00b7lich", "zu", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.15": {"line.1": {"text": "Wir singen einen s\u00fc\u00dfen Gesang", "tokens": ["Wir", "sin\u00b7gen", "ei\u00b7nen", "s\u00fc\u00b7\u00dfen", "Ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Den Weibern auf der Ofenbank.", "tokens": ["Den", "Wei\u00b7bern", "auf", "der", "O\u00b7fen\u00b7bank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir lassen an einem jeglichen Ort", "tokens": ["Wir", "las\u00b7sen", "an", "ei\u00b7nem", "jeg\u00b7li\u00b7chen", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "PIAT", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einen kleinen heiligen K\u00f6nig zum Andenken dort.", "tokens": ["Ei\u00b7nen", "klei\u00b7nen", "hei\u00b7li\u00b7gen", "K\u00f6\u00b7nig", "zum", "An\u00b7den\u00b7ken", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "APPRART", "NN", "ADV", "$."], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.16": {"line.1": {"text": "Wir geben euch unseren Segen drein,", "tokens": ["Wir", "ge\u00b7ben", "euch", "un\u00b7se\u00b7ren", "Se\u00b7gen", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Gemischt aus Kuhdreck und Rosmarein.", "tokens": ["Ge\u00b7mischt", "aus", "Kuh\u00b7dreck", "und", "Ros\u00b7ma\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir danken f\u00fcr Schnaps, wir danken f\u00fcr Bier.", "tokens": ["Wir", "dan\u00b7ken", "f\u00fcr", "Schnaps", ",", "wir", "dan\u00b7ken", "f\u00fcr", "Bier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Anders Jahr um die Zeit sind wir wieder hier.", "tokens": ["An\u00b7ders", "Jahr", "um", "die", "Zeit", "sind", "wir", "wie\u00b7der", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Kyrieeleis.", "tokens": ["Ky\u00b7ri\u00b7ee\u00b7leis", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}}}}