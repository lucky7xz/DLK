{"textgrid.poem.61976": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es stand ein zierlicher J\u00fcngling", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es stand ein zierlicher J\u00fcngling", "tokens": ["Es", "stand", "ein", "zier\u00b7li\u00b7cher", "J\u00fcng\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Auf einem H\u00fcgel von Stein,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel", "von", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u00bbo d\u00fcrfte ich\u00ab, \u2013 rief er, \u00bbhin\u00fcber,", "tokens": ["\u00bb", "o", "d\u00fcrf\u00b7te", "ich", "\u00ab", ",", "\u2013", "rief", "er", ",", "\u00bb", "hin\u00b7\u00fc\u00b7ber", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "FM", "VMFIN", "PPER", "$(", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "ADV", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Hin\u00fcber bis \u00fcber den Rhein!\u00ab", "tokens": ["Hin\u00b7\u00fc\u00b7ber", "bis", "\u00fc\u00b7ber", "den", "Rhein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NE", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.2": {"line.1": {"text": "Die Welle zu meinen F\u00fc\u00dfen,", "tokens": ["Die", "Wel\u00b7le", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da dr\u00fcben den deutschen Grund!", "tokens": ["Da", "dr\u00fc\u00b7ben", "den", "deut\u00b7schen", "Grund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So steh' ich, mich sehnend am Ufer", "tokens": ["So", "steh'", "ich", ",", "mich", "seh\u00b7nend", "am", "U\u00b7fer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVPP", "APPRART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Tagt\u00e4glich zu jeder Stund'!", "tokens": ["Tag\u00b7t\u00e4g\u00b7lich", "zu", "je\u00b7der", "Stund'", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Ich bin der echteste Deutsche,", "tokens": ["Ich", "bin", "der", "ech\u00b7tes\u00b7te", "Deut\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Verbannet, doch ohne Grund,", "tokens": ["Ver\u00b7ban\u00b7net", ",", "doch", "oh\u00b7ne", "Grund", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ein Deutscher schon tausend Jahre! \u2013", "tokens": ["Ein", "Deut\u00b7scher", "schon", "tau\u00b7send", "Jah\u00b7re", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "CARD", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und sp\u00f6ttisch l\u00e4chelt sein Mund.", "tokens": ["Und", "sp\u00f6t\u00b7tisch", "l\u00e4\u00b7chelt", "sein", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Ein Deutscher, trotz brauner Locken,", "tokens": ["Ein", "Deut\u00b7scher", ",", "trotz", "brau\u00b7ner", "Lo\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der Falte inmitten der Stirn,", "tokens": ["Der", "Fal\u00b7te", "in\u00b7mit\u00b7ten", "der", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Dem tr\u00fcben und bleichen Antlitz,", "tokens": ["Dem", "tr\u00fc\u00b7ben", "und", "blei\u00b7chen", "Ant\u00b7litz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und meinem so gl\u00fchenden Hirn.", "tokens": ["Und", "mei\u00b7nem", "so", "gl\u00fc\u00b7hen\u00b7den", "Hirn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "Wer war's, der sich so sinnig", "tokens": ["Wer", "wa\u00b7r's", ",", "der", "sich", "so", "sin\u00b7nig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "PRF", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An jenen Felsen gelehnt,", "tokens": ["An", "je\u00b7nen", "Fel\u00b7sen", "ge\u00b7lehnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "So wahrhaft sich und innig", "tokens": ["So", "wahr\u00b7haft", "sich", "und", "in\u00b7nig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PRF", "KON", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nach Deutschland hat gesehnt?", "tokens": ["Nach", "Deutschland", "hat", "ge\u00b7sehnt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Er war's, der wackre B\u00f6rne,", "tokens": ["Er", "wa\u00b7r's", ",", "der", "wack\u00b7re", "B\u00f6r\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "VVFIN", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der Meister vom Rechtsgef\u00fchl \u2013", "tokens": ["Der", "Meis\u00b7ter", "vom", "Rechts\u00b7ge\u00b7f\u00fchl", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Deutschland ernsthaft liebte", "tokens": ["Der", "Deutschland", "ernst\u00b7haft", "lieb\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Mit hei\u00dfestem Pflichtgef\u00fchl!", "tokens": ["Mit", "hei\u00b7\u00dfes\u00b7tem", "Pflicht\u00b7ge\u00b7f\u00fchl", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Den Deutschland einstens versto\u00dfen,", "tokens": ["Den", "Deutschland", "eins\u00b7tens", "ver\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "In Deutschland einstens verp\u00f6nt,", "tokens": ["In", "Deutschland", "eins\u00b7tens", "ver\u00b7p\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und der sich drum nicht minder", "tokens": ["Und", "der", "sich", "drum", "nicht", "min\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PRF", "PAV", "PTKNEG", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nach Deutschland hat gesehnt.", "tokens": ["Nach", "Deutschland", "hat", "ge\u00b7sehnt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Es stand ein zierlicher J\u00fcngling", "tokens": ["Es", "stand", "ein", "zier\u00b7li\u00b7cher", "J\u00fcng\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Auf einem H\u00fcgel von Stein,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel", "von", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u00bbo d\u00fcrfte ich\u00ab, \u2013 rief er, \u00bbhin\u00fcber,", "tokens": ["\u00bb", "o", "d\u00fcrf\u00b7te", "ich", "\u00ab", ",", "\u2013", "rief", "er", ",", "\u00bb", "hin\u00b7\u00fc\u00b7ber", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "FM", "VMFIN", "PPER", "$(", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "ADV", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Hin\u00fcber bis \u00fcber den Rhein!\u00ab", "tokens": ["Hin\u00b7\u00fc\u00b7ber", "bis", "\u00fc\u00b7ber", "den", "Rhein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NE", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.9": {"line.1": {"text": "Die Welle zu meinen F\u00fc\u00dfen,", "tokens": ["Die", "Wel\u00b7le", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da dr\u00fcben den deutschen Grund!", "tokens": ["Da", "dr\u00fc\u00b7ben", "den", "deut\u00b7schen", "Grund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So steh' ich, mich sehnend am Ufer", "tokens": ["So", "steh'", "ich", ",", "mich", "seh\u00b7nend", "am", "U\u00b7fer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVPP", "APPRART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Tagt\u00e4glich zu jeder Stund'!", "tokens": ["Tag\u00b7t\u00e4g\u00b7lich", "zu", "je\u00b7der", "Stund'", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Ich bin der echteste Deutsche,", "tokens": ["Ich", "bin", "der", "ech\u00b7tes\u00b7te", "Deut\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Verbannet, doch ohne Grund,", "tokens": ["Ver\u00b7ban\u00b7net", ",", "doch", "oh\u00b7ne", "Grund", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ein Deutscher schon tausend Jahre! \u2013", "tokens": ["Ein", "Deut\u00b7scher", "schon", "tau\u00b7send", "Jah\u00b7re", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "CARD", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und sp\u00f6ttisch l\u00e4chelt sein Mund.", "tokens": ["Und", "sp\u00f6t\u00b7tisch", "l\u00e4\u00b7chelt", "sein", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "Ein Deutscher, trotz brauner Locken,", "tokens": ["Ein", "Deut\u00b7scher", ",", "trotz", "brau\u00b7ner", "Lo\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der Falte inmitten der Stirn,", "tokens": ["Der", "Fal\u00b7te", "in\u00b7mit\u00b7ten", "der", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Dem tr\u00fcben und bleichen Antlitz,", "tokens": ["Dem", "tr\u00fc\u00b7ben", "und", "blei\u00b7chen", "Ant\u00b7litz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und meinem so gl\u00fchenden Hirn.", "tokens": ["Und", "mei\u00b7nem", "so", "gl\u00fc\u00b7hen\u00b7den", "Hirn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.12": {"line.1": {"text": "Wer war's, der sich so sinnig", "tokens": ["Wer", "wa\u00b7r's", ",", "der", "sich", "so", "sin\u00b7nig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "PRF", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An jenen Felsen gelehnt,", "tokens": ["An", "je\u00b7nen", "Fel\u00b7sen", "ge\u00b7lehnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "So wahrhaft sich und innig", "tokens": ["So", "wahr\u00b7haft", "sich", "und", "in\u00b7nig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PRF", "KON", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nach Deutschland hat gesehnt?", "tokens": ["Nach", "Deutschland", "hat", "ge\u00b7sehnt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Er war's, der wackre B\u00f6rne,", "tokens": ["Er", "wa\u00b7r's", ",", "der", "wack\u00b7re", "B\u00f6r\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "VVFIN", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der Meister vom Rechtsgef\u00fchl \u2013", "tokens": ["Der", "Meis\u00b7ter", "vom", "Rechts\u00b7ge\u00b7f\u00fchl", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Deutschland ernsthaft liebte", "tokens": ["Der", "Deutschland", "ernst\u00b7haft", "lieb\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Mit hei\u00dfestem Pflichtgef\u00fchl!", "tokens": ["Mit", "hei\u00b7\u00dfes\u00b7tem", "Pflicht\u00b7ge\u00b7f\u00fchl", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Den Deutschland einstens versto\u00dfen,", "tokens": ["Den", "Deutschland", "eins\u00b7tens", "ver\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "In Deutschland einstens verp\u00f6nt,", "tokens": ["In", "Deutschland", "eins\u00b7tens", "ver\u00b7p\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und der sich drum nicht minder", "tokens": ["Und", "der", "sich", "drum", "nicht", "min\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PRF", "PAV", "PTKNEG", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nach Deutschland hat gesehnt.", "tokens": ["Nach", "Deutschland", "hat", "ge\u00b7sehnt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}