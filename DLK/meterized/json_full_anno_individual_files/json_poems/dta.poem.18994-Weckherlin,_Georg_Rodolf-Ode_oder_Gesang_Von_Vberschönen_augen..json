{"dta.poem.18994": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Ode oder Gesang/  \n Von Vbersch\u00f6nen augen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Oder Lieb wahrer hort vnd port/", "tokens": ["O\u00b7der", "Lieb", "wah\u00b7rer", "hort", "vnd", "port", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "KON", "NE", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Jhr meiner sch\u00f6nen Myrten augen/", "tokens": ["Ihr", "mei\u00b7ner", "sch\u00f6\u00b7nen", "Myr\u00b7ten", "au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wan anderst ein so schlechtes wort", "tokens": ["Wan", "an\u00b7derst", "ein", "so", "schlech\u00b7tes", "wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan euch zu nennen gnugsam taugen!", "tokens": ["Kan", "euch", "zu", "nen\u00b7nen", "gnug\u00b7sam", "tau\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKZU", "VVINF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zwar augen kan man euch/ weil jhrem angesicht", "tokens": ["Zwar", "au\u00b7gen", "kan", "man", "euch", "/", "weil", "jhrem", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVINF", "VMFIN", "PIS", "PPER", "$(", "KOUS", "PPOSAT", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Jhr klare augen seit/ zu sein verl\u00e4ugnen nicht:", "tokens": ["Ihr", "kla\u00b7re", "au\u00b7gen", "seit", "/", "zu", "sein", "ver\u00b7l\u00e4ug\u00b7nen", "nicht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "$(", "PTKZU", "VAINF", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch darff man euch kaum augen nennen/", "tokens": ["Doch", "darff", "man", "euch", "kaum", "au\u00b7gen", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "PPER", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil jhr so sch\u00f6n vnd tugenthafft/", "tokens": ["Weil", "jhr", "so", "sch\u00f6n", "vnd", "tu\u00b7gent\u00b7hafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sondern von wegen ewrer krafft", "tokens": ["Son\u00b7dern", "von", "we\u00b7gen", "ew\u00b7rer", "krafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Mu\u00df man euch himmelisch bekennen.", "tokens": ["Mu\u00df", "man", "euch", "him\u00b7me\u00b7lisch", "be\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Zwar mit so wunderreichem pracht/", "tokens": ["Zwar", "mit", "so", "wun\u00b7der\u00b7rei\u00b7chem", "pracht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Damit sich diese augen zieren/", "tokens": ["Da\u00b7mit", "sich", "die\u00b7se", "au\u00b7gen", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kan (es sey gleich tag oder nacht)", "tokens": ["Kan", "(", "es", "sey", "gleich", "tag", "o\u00b7der", "nacht", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$(", "PPER", "VAFIN", "ADV", "NN", "KON", "NN", "$("], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Der himmel selbs niemahls prachtieren:", "tokens": ["Der", "him\u00b7mel", "selbs", "nie\u00b7mahls", "prach\u00b7tie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Wan schon dem himmel gleich jhr haitter glatte stirn", "tokens": ["Wan", "schon", "dem", "him\u00b7mel", "gleich", "jhr", "hait\u00b7ter", "glat\u00b7te", "stirn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Erleuchtet dise welt durch Euch/ als ein gestirn:", "tokens": ["Er\u00b7leuch\u00b7tet", "di\u00b7se", "welt", "durch", "Euch", "/", "als", "ein", "ge\u00b7stirn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPER", "$(", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So ist jedoch in euch vermischet", "tokens": ["So", "ist", "je\u00b7doch", "in", "euch", "ver\u00b7mi\u00b7schet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das braun vnd liecht mit solchem schein/", "tokens": ["Das", "braun", "vnd", "liecht", "mit", "sol\u00b7chem", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "KON", "VVFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df es ja mu\u00df ein wunder sein/", "tokens": ["Da\u00df", "es", "ja", "mu\u00df", "ein", "wun\u00b7der", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wie jhrer jedes Vns erfrischet.", "tokens": ["Wie", "jhrer", "je\u00b7des", "Vns", "er\u00b7fri\u00b7schet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "So darff auch mein warhaffter mund", "tokens": ["So", "darff", "auch", "mein", "war\u00b7haff\u00b7ter", "mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Euch mit der Sonnen nicht vergleichen/", "tokens": ["Euch", "mit", "der", "Son\u00b7nen", "nicht", "ver\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Weil jhr glantz (wie dem Vmbkrai\u00df kund)", "tokens": ["Weil", "jhr", "glantz", "(", "wie", "dem", "Vmb\u00b7krai\u00df", "kund", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$(", "KOKOM", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df ewerm glantz vnd w\u00fcrckung weichen:", "tokens": ["Mu\u00df", "e\u00b7werm", "glantz", "vnd", "w\u00fcr\u00b7ckung", "wei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd zwayer Sonnen schein bedeutet krieg vnd layd/", "tokens": ["Vnd", "zway\u00b7er", "Son\u00b7nen", "schein", "be\u00b7deu\u00b7tet", "krieg", "vnd", "layd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJD", "VVFIN", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da ewer Zwilling liecht erw\u00f6cket frid vnd frayd;", "tokens": ["Da", "e\u00b7wer", "Zwil\u00b7ling", "liecht", "er\u00b7w\u00f6\u00b7cket", "frid", "vnd", "frayd", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "VVFIN", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Sonn durch jhre brunst beschweret/", "tokens": ["Die", "Sonn", "durch", "jhre", "brunst", "be\u00b7schwe\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Die sie anschawen/ mit verdru\u00df:", "tokens": ["Die", "sie", "an\u00b7scha\u00b7wen", "/", "mit", "ver\u00b7dru\u00df", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$(", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "Da jhr mit s\u00fcssem lusts eingu\u00df", "tokens": ["Da", "jhr", "mit", "s\u00fcs\u00b7sem", "lusts", "ein\u00b7gu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Durch das gesicht das hertz versehret.", "tokens": ["Durch", "das", "ge\u00b7sicht", "das", "hertz", "ver\u00b7seh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer sich (glickseelig) kan in Euch", "tokens": ["Wer", "sich", "(", "glick\u00b7see\u00b7lig", ")", "kan", "in", "Euch"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PRF", "$(", "ADJD", "$(", "VMFIN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Besehen/ wirt reichlich gesegnet/", "tokens": ["Be\u00b7se\u00b7hen", "/", "wirt", "reich\u00b7lich", "ge\u00b7seg\u00b7net", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dan jhr gantz wunderlich liebreich", "tokens": ["Dan", "jhr", "gantz", "wun\u00b7der\u00b7lich", "lieb\u00b7reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "ADJD", "ADJD"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sein hertz mit frewden vberregnet.", "tokens": ["Sein", "hertz", "mit", "frew\u00b7den", "vber\u00b7reg\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die strahlen ewers liechts/ vnd ewers anblicks glantz", "tokens": ["Die", "strah\u00b7len", "e\u00b7wers", "liechts", "/", "vnd", "e\u00b7wers", "an\u00b7blicks", "glantz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Seind zugleich der Lieb pfeil/ vnd auch der keuschheit", "tokens": ["Seind", "zu\u00b7gleich", "der", "Lieb", "pfeil", "/", "vnd", "auch", "der", "keuschheit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "$(", "KON", "ADV", "ART", "NN"], "meter": "+-+-++-+-+", "measure": "unknown.measure.hexa"}, "line.7": {"text": "schantz; ", "tokens": ["schantz", ";"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Dan Sie mit lieb vnd lust entleben/", "tokens": ["Dan", "Sie", "mit", "lieb", "vnd", "lust", "ent\u00b7le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "ADJD", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Vnd dan mit s\u00fcsser forcht vnd ehr", "tokens": ["Vnd", "dan", "mit", "s\u00fcs\u00b7ser", "forcht", "vnd", "ehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Widrumb belebend/ Vns die lehr/", "tokens": ["Wid\u00b7rumb", "be\u00b7le\u00b7bend", "/", "Vns", "die", "lehr", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "$(", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Den Engeln gleich zu leben/ geben.", "tokens": ["Den", "En\u00b7geln", "gleich", "zu", "le\u00b7ben", "/", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$(", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Daher/ O augen braun vnd klar/", "tokens": ["Da\u00b7her", "/", "O", "au\u00b7gen", "braun", "vnd", "klar", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "NE", "NN", "VVINF", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schwartzlecht vnd hell/ wie plitz vnd dunder;", "tokens": ["Schwartz\u00b7lecht", "vnd", "hell", "/", "wie", "plitz", "vnd", "dun\u00b7der", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$(", "KOKOM", "NE", "KON", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Sch\u00f6nheit vnd Lieb wieg vnd bahr/", "tokens": ["Der", "Sch\u00f6n\u00b7heit", "vnd", "Lieb", "wieg", "vnd", "bahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Der Natur schatz vnd gr\u00f6stes wunder/", "tokens": ["Der", "Na\u00b7tur", "schatz", "vnd", "gr\u00f6s\u00b7tes", "wun\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gantz vbermenschlich sch\u00f6n mu\u00df ich mit layd vnd", "tokens": ["Gantz", "vber\u00b7menschlich", "sch\u00f6n", "mu\u00df", "ich", "mit", "layd", "vnd"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADJD", "VMFIN", "PPER", "APPR", "NN", "KON"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "wohn", "tokens": ["wohn"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Bekennen Euch zugleich der G\u00f6tter straff vnd lohn:", "tokens": ["Be\u00b7ken\u00b7nen", "Euch", "zu\u00b7gleich", "der", "G\u00f6t\u00b7ter", "straff", "vnd", "lohn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dan jhr k\u00f6nt ja mit ewern blicken", "tokens": ["Dan", "jhr", "k\u00f6nt", "ja", "mit", "e\u00b7wern", "bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "(der Sch\u00f6nheit/ Lieb vnd Tugent sitz)", "tokens": ["(", "der", "Sch\u00f6n\u00b7heit", "/", "Lieb", "vnd", "Tu\u00b7gent", "sitz", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "NN", "KON", "NN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wie durch gesch\u00fctz/ hitz/ spitz vnd plitz", "tokens": ["Wie", "durch", "ge\u00b7sch\u00fctz", "/", "hitz", "/", "spitz", "vnd", "plitz"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "NE", "$(", "NE", "$(", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Das hertz zerst\u00fccken vnd erquicken.", "tokens": ["Das", "hertz", "zer\u00b7st\u00fc\u00b7cken", "vnd", "er\u00b7qui\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}