{"dta.poem.9259": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das Erste Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ach wenn ich doch mein k\u00fcnfftig weib", "tokens": ["Ach", "wenn", "ich", "doch", "mein", "k\u00fcnff\u00b7tig", "weib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "KOUS", "PPER", "ADV", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jm spiegel sehen solte/", "tokens": ["Jm", "spie\u00b7gel", "se\u00b7hen", "sol\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ob mir das gl\u00fccke vor dem leib", "tokens": ["Ob", "mir", "das", "gl\u00fc\u00b7cke", "vor", "dem", "leib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was gutes g\u00f6nnen wolte/", "tokens": ["Was", "gu\u00b7tes", "g\u00f6n\u00b7nen", "wol\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ob ich eine leichte b\u00fcrde", "tokens": ["Und", "ob", "ich", "ei\u00b7ne", "leich\u00b7te", "b\u00fcr\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In meiner heyrath finden w\u00fcrde.", "tokens": ["In", "mei\u00b7ner", "hey\u00b7rath", "fin\u00b7den", "w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Es kan wohl seyn in kurtzer frist/", "tokens": ["Es", "kan", "wohl", "seyn", "in", "kurt\u00b7zer", "frist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VAINF", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich ein kind erwische/", "tokens": ["Da\u00df", "ich", "ein", "kind", "er\u00b7wi\u00b7sche", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das in dem bett\u2019 ein t\u00e4ubgen ist/", "tokens": ["Das", "in", "dem", "bett'", "ein", "t\u00e4ub\u00b7gen", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "VVFIN", "ART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein engel an dem tische/", "tokens": ["Ein", "en\u00b7gel", "an", "dem", "ti\u00b7sche", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "$("], "meter": "-+-++--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Und das mit ihren zarten lachen", "tokens": ["Und", "das", "mit", "ih\u00b7ren", "zar\u00b7ten", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "APPR", "PPOSAT", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sich allzeit kan belieblich machen.", "tokens": ["Sich", "all\u00b7zeit", "kan", "be\u00b7lieb\u00b7lich", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Drumb schau ich stets die jugend an/", "tokens": ["Drumb", "schau", "ich", "stets", "die", "ju\u00b7gend", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da such ich mein ergetzen:", "tokens": ["Da", "such", "ich", "mein", "er\u00b7get\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jedoch die schlaue bo\u00dfheit kan", "tokens": ["Je\u00b7doch", "die", "schlau\u00b7e", "bo\u00df\u00b7heit", "kan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das alter offt ersetzen/", "tokens": ["Das", "al\u00b7ter", "offt", "er\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df wir ein kind an leibes-gaben/", "tokens": ["Da\u00df", "wir", "ein", "kind", "an", "lei\u00b7bes\u00b7ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "An sitten alte weiber haben.", "tokens": ["An", "sit\u00b7ten", "al\u00b7te", "wei\u00b7ber", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Zwar dieses ist wohl eh geschehn/", "tokens": ["Zwar", "die\u00b7ses", "ist", "wohl", "eh", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "ADV", "KOUS", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wir zu unserm frommen/", "tokens": ["Da\u00df", "wir", "zu", "un\u00b7serm", "from\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die m\u00e4nner gerne sterben sehn/", "tokens": ["Die", "m\u00e4n\u00b7ner", "ger\u00b7ne", "ster\u00b7ben", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df wir die frau bekommen/", "tokens": ["Da\u00df", "wir", "die", "frau", "be\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ob sie gleich im kalten bette/", "tokens": ["Und", "ob", "sie", "gleich", "im", "kal\u00b7ten", "bet\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nichts mehr als haut und knochen h\u00e4tte.", "tokens": ["Nichts", "mehr", "als", "haut", "und", "kno\u00b7chen", "h\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "KOKOM", "VVFIN", "KON", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Wo wir nur halbicht unterhalt", "tokens": ["Wo", "wir", "nur", "hal\u00b7bicht", "un\u00b7ter\u00b7halt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gute mittel finden/", "tokens": ["Und", "gu\u00b7te", "mit\u00b7tel", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da lassen wir uns alsobald", "tokens": ["Da", "las\u00b7sen", "wir", "uns", "al\u00b7so\u00b7bald"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit sehnden augen binden/", "tokens": ["Mit", "sehn\u00b7den", "au\u00b7gen", "bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und machen guter tage wegen/", "tokens": ["Und", "ma\u00b7chen", "gu\u00b7ter", "ta\u00b7ge", "we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "ADJA", "NN", "APPR", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Uns einen sauren abendsegen.", "tokens": ["Uns", "ei\u00b7nen", "sau\u00b7ren", "a\u00b7bend\u00b7se\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Da gehn wir um die mutter rumm", "tokens": ["Da", "gehn", "wir", "um", "die", "mut\u00b7ter", "rumm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und klopffen sie in nacken/", "tokens": ["Und", "klopf\u00b7fen", "sie", "in", "na\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wolten gern ihr eigenthum", "tokens": ["Und", "wol\u00b7ten", "gern", "ihr", "ei\u00b7gen\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bald hier/ bald dort bezwacken/", "tokens": ["Bald", "hier", "/", "bald", "dort", "be\u00b7zwa\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da soll sie uns die besten sachen", "tokens": ["Da", "soll", "sie", "uns", "die", "bes\u00b7ten", "sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jm testament allein vermachen.", "tokens": ["Jm", "tes\u00b7ta\u00b7ment", "al\u00b7lein", "ver\u00b7ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "7. Und also f\u00e4llt ein junger mann", "tokens": ["Und", "al\u00b7so", "f\u00e4llt", "ein", "jun\u00b7ger", "mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Allm\u00e4hlich ins verderben/", "tokens": ["All\u00b7m\u00e4h\u00b7lich", "ins", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er blickt zwar manches m\u00e4dgen an/", "tokens": ["Er", "blickt", "zwar", "man\u00b7ches", "m\u00e4d\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch diese will nicht sterben/", "tokens": ["Doch", "die\u00b7se", "will", "nicht", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und stirbt sie gleich in zwantzig jahren/", "tokens": ["Und", "stirbt", "sie", "gleich", "in", "zwant\u00b7zig", "jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So ist die zeit auch weggefahren.", "tokens": ["So", "ist", "die", "zeit", "auch", "weg\u00b7ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "8. Wer wei\u00df wie mir mein gl\u00fccke bl\u00fcht/", "tokens": ["Wer", "wei\u00df", "wie", "mir", "mein", "gl\u00fc\u00b7cke", "bl\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KOKOM", "PPER", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jtzt hilfft mich doch kein sorgen/", "tokens": ["Jtzt", "hilfft", "mich", "doch", "kein", "sor\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich will dem himmel/ der es sieht/", "tokens": ["Ich", "will", "dem", "him\u00b7mel", "/", "der", "es", "sieht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein theil so lange borgen.", "tokens": ["Mein", "theil", "so", "lan\u00b7ge", "bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich mag mich gut und b\u00f6se paaren/", "tokens": ["Ich", "mag", "mich", "gut", "und", "b\u00f6\u00b7se", "paa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADJD", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So werd ichs zeit genung erfahren.", "tokens": ["So", "werd", "ichs", "zeit", "ge\u00b7nung", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}