{"textgrid.poem.40738": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "Herr Abb\u00e9", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sprach der alte Prinz zum Sohn:", "tokens": ["Sprach", "der", "al\u00b7te", "Prinz", "zum", "Sohn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbkind, ich dien' um Frankreichs Lohn,", "tokens": ["\u00bb", "kind", ",", "ich", "dien'", "um", "Fran\u00b7kreichs", "Lohn", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$,", "PPER", "VVFIN", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin an Kindern reich,", "tokens": ["Bin", "an", "Kin\u00b7dern", "reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Nicht an G\u00fctern gleich;", "tokens": ["Nicht", "an", "G\u00fc\u00b7tern", "gleich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Taugst zu anderm nicht auf Erden,", "tokens": ["Taugst", "zu", "an\u00b7derm", "nicht", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIS", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Magst mir ein Pr\u00e4late werden.\u00ab", "tokens": ["Magst", "mir", "ein", "Pr\u00e4\u00b7la\u00b7te", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "H\u00fcbsch in Notredame stehn,", "tokens": ["H\u00fcbsch", "in", "Not\u00b7re\u00b7da\u00b7me", "stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Psalmen singen soll Eugen;", "tokens": ["Psal\u00b7men", "sin\u00b7gen", "soll", "Eu\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VMFIN", "NE", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Seltsamer Abb\u00e9,", "tokens": ["Selt\u00b7sa\u00b7mer", "Ab\u00b7b\u00e9", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Flieht des M\u00fcnsters N\u00e4h',", "tokens": ["Flieht", "des", "M\u00fcns\u00b7ters", "N\u00e4h'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Tr\u00e4gt Gesporn statt seidner Socken,", "tokens": ["Tr\u00e4gt", "Ge\u00b7sporn", "statt", "seid\u00b7ner", "So\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schwingt Rappiere statt der Glocken!", "tokens": ["Schwingt", "Rap\u00b7pie\u00b7re", "statt", "der", "Glo\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "H\u00e4lt nicht sehr auf Kleiderpracht,", "tokens": ["H\u00e4lt", "nicht", "sehr", "auf", "Klei\u00b7der\u00b7pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist der Dose mehr bedacht,", "tokens": ["Ist", "der", "Do\u00b7se", "mehr", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Abb\u00e9 zum Gl\u00fcck", "tokens": ["Ein", "Ab\u00b7b\u00e9", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Nur in diesem St\u00fcck;", "tokens": ["Nur", "in", "die\u00b7sem", "St\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Aber klopft er drauf, so schallt es", "tokens": ["A\u00b7ber", "klopft", "er", "drauf", ",", "so", "schallt", "es"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie ein Schu\u00df, von Pulver wallt es!", "tokens": ["Wie", "ein", "Schu\u00df", ",", "von", "Pul\u00b7ver", "wallt", "es", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "APPR", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "M\u00e4dchen l\u00e4\u00dft er ungeneckt,", "tokens": ["M\u00e4d\u00b7chen", "l\u00e4\u00dft", "er", "un\u00b7ge\u00b7neckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tag und Nacht im Buch er steckt;", "tokens": ["Tag", "und", "Nacht", "im", "Buch", "er", "steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Grad in diesem St\u00fcck", "tokens": ["Grad", "in", "die\u00b7sem", "St\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PDAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Kein Abb\u00e9 zum Gl\u00fcck!", "tokens": ["Kein", "Ab\u00b7b\u00e9", "zum", "Gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Sein Brevier ist's, m\u00f6gt ihr rathen,", "tokens": ["Sein", "Bre\u00b7vier", "ist's", ",", "m\u00f6gt", "ihr", "ra\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nein, doch Alexanders Thaten!", "tokens": ["Nein", ",", "doch", "A\u00b7lex\u00b7an\u00b7ders", "Tha\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "NE", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Gl\u00fchend steigt es ihm zu Haupt;", "tokens": ["Gl\u00fc\u00b7hend", "steigt", "es", "ihm", "zu", "Haupt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unfrisirt, tabakbestaubt", "tokens": ["Un\u00b7fri\u00b7sirt", ",", "ta\u00b7bak\u00b7be\u00b7staubt"], "token_info": ["word", "punct", "word"], "pos": ["VVPP", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fliegt er in das Schlo\u00df:", "tokens": ["Fliegt", "er", "in", "das", "Schlo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "\u00bbherrscher, k\u00fchn und gro\u00df,", "tokens": ["\u00bb", "herr\u00b7scher", ",", "k\u00fchn", "und", "gro\u00df", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Gib mir Rang in Frankreichs Heere", "tokens": ["Gib", "mir", "Rang", "in", "Fran\u00b7kreichs", "Hee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "NN", "APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ich's f\u00fchr' in Sieg und Ehre.\u00ab", "tokens": ["Da\u00df", "ich's", "f\u00fchr'", "in", "Sieg", "und", "Eh\u00b7re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "K\u00f6nig Louis ihn scharf beschaut:", "tokens": ["K\u00f6\u00b7nig", "Lou\u00b7is", "ihn", "scharf", "be\u00b7schaut", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "ADJD", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "\u00bbseid mit Pulver zwar vertraut,", "tokens": ["\u00bb", "seid", "mit", "Pul\u00b7ver", "zwar", "ver\u00b7traut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch, mein Herr Abb\u00e9,", "tokens": ["Doch", ",", "mein", "Herr", "Ab\u00b7b\u00e9", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Bleibt nur beim Rap\u00e9,", "tokens": ["Bleibt", "nur", "beim", "Rap\u00e9", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Das Rapier doch m\u00f6gt Ihr lassen,", "tokens": ["Das", "Ra\u00b7pier", "doch", "m\u00f6gt", "Ihr", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Einst den Bischofsstab zu fassen.\u00ab", "tokens": ["Einst", "den", "Bi\u00b7schofs\u00b7stab", "zu", "fas\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Sch\u00f6nes Frankreich, nun Ade!", "tokens": ["Sch\u00f6\u00b7nes", "Fran\u00b7kreich", ",", "nun", "A\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADV", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Gegen Wien trabt dein Abb\u00e9;", "tokens": ["Ge\u00b7gen", "Wi\u00b7en", "trabt", "dein", "Ab\u00b7b\u00e9", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kaiser Leopold,", "tokens": ["Kai\u00b7ser", "Leo\u00b7pold", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Jedem Schwarzrock hold,", "tokens": ["Je\u00b7dem", "Schwarz\u00b7rock", "hold", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Hei\u00dft in Oestreich ihn willkommen:", "tokens": ["Hei\u00dft", "in", "O\u00b7e\u00b7streich", "ihn", "will\u00b7kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bboffen steht mein Reich den Frommen.\u00ab", "tokens": ["\u00bb", "of\u00b7fen", "steht", "mein", "Reich", "den", "From\u00b7men", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbist im lieben Portugall", "tokens": ["\u00bb", "ist", "im", "lie\u00b7ben", "Por\u00b7tu\u00b7gall"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sanct Antonius Feldmarschall,", "tokens": ["Sanct", "An\u00b7to\u00b7ni\u00b7us", "Feld\u00b7mar\u00b7schall", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Taugt wohl ein Abb\u00e9", "tokens": ["Taugt", "wohl", "ein", "Ab\u00b7b\u00e9"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Mir in T\u00fcrkenn\u00e4h';", "tokens": ["Mir", "in", "T\u00fcr\u00b7ken\u00b7n\u00e4h'", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Beten hilft so gut wie Raufen,", "tokens": ["Be\u00b7ten", "hilft", "so", "gut", "wie", "Rau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADJD", "KOKOM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und ein Sieg auch ist das Taufen.\u00ab", "tokens": ["Und", "ein", "Sieg", "auch", "ist", "das", "Tau\u00b7fen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VAFIN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Die Dragoner, schlachtgereiht,", "tokens": ["Die", "Dra\u00b7go\u00b7ner", ",", "schlacht\u00b7ge\u00b7reiht", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehn das kuttenbraune Kleid,", "tokens": ["Sehn", "das", "kut\u00b7ten\u00b7brau\u00b7ne", "Kleid", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lachen durch die Reihn:", "tokens": ["La\u00b7chen", "durch", "die", "Reihn", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "\u00bbkapuzinerlein,", "tokens": ["\u00bb", "ka\u00b7pu\u00b7zi\u00b7ner\u00b7lein", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Lies uns Messe, weih' die Fahne,", "tokens": ["Lies", "uns", "Mes\u00b7se", ",", "weih'", "die", "Fah\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Pred'ge, neuer Kapistrane!\u00ab", "tokens": ["Pre\u00b7d'\u00b7ge", ",", "neu\u00b7er", "Ka\u00b7pis\u00b7tra\u00b7ne", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$.", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.10": {"line.1": {"text": "Und das Pf\u00e4fflein fr\u00fch und spat", "tokens": ["Und", "das", "Pf\u00e4f\u00b7flein", "fr\u00fch", "und", "spat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Predigt gut in Feld und Rath;", "tokens": ["Pre\u00b7digt", "gut", "in", "Feld", "und", "Rath", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Springt einst rasch vom Pferd,", "tokens": ["Springt", "einst", "rasch", "vom", "Pferd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00e4lt im Mund sein Schwert,", "tokens": ["H\u00e4lt", "im", "Mund", "sein", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Klimmt empor zum T\u00fcrkenwalle;", "tokens": ["Klimmt", "em\u00b7por", "zum", "T\u00fcr\u00b7ken\u00b7wal\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Diese Predigt lobten Alle.", "tokens": ["Die\u00b7se", "Pre\u00b7digt", "lob\u00b7ten", "Al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Und vor Belgrad auf der Schanz'", "tokens": ["Und", "vor", "Bel\u00b7grad", "auf", "der", "Schanz'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Betet er den Rosenkranz.", "tokens": ["Be\u00b7tet", "er", "den", "Ro\u00b7sen\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ri\u00df vielleicht die Schnur?", "tokens": ["Ri\u00df", "viel\u00b7leicht", "die", "Schnur", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df auf Stadt und Flur", "tokens": ["Da\u00df", "auf", "Stadt", "und", "Flur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "KON", "NN"], "meter": "--+-+", "measure": "anapaest.init"}, "line.5": {"text": "Schwarz und dicht die Betkorallen", "tokens": ["Schwarz", "und", "dicht", "die", "Bet\u00b7ko\u00b7ral\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "ADJD", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aus dem Paternoster fallen!", "tokens": ["Aus", "dem", "Pa\u00b7ter\u00b7nos\u00b7ter", "fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Dann in W\u00e4lschland und am Rhein", "tokens": ["Dann", "in", "W\u00e4l\u00b7schland", "und", "am", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "APPRART", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "R\u00e4uchert er den Franzmann ein;", "tokens": ["R\u00e4u\u00b7chert", "er", "den", "Franz\u00b7mann", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser Weihrauch doch", "tokens": ["Die\u00b7ser", "Weih\u00b7rauch", "doch"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "NN", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Nicht nach Amber roch,", "tokens": ["Nicht", "nach", "Am\u00b7ber", "roch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Rauchfa\u00df auch und heil'ge Kerze", "tokens": ["Rauch\u00b7fa\u00df", "auch", "und", "heil'\u00b7ge", "Ker\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "War von etwas grobem Erze.", "tokens": ["War", "von", "et\u00b7was", "gro\u00b7bem", "Er\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "In Cremona holt vom Bett", "tokens": ["In", "Cre\u00b7mo\u00b7na", "holt", "vom", "Bett"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "APPRART", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Er den Feind zur fr\u00fchen Mett';", "tokens": ["Er", "den", "Feind", "zur", "fr\u00fc\u00b7hen", "Mett'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Marschall Villeroi", "tokens": ["Mar\u00b7schall", "Vil\u00b7le\u00b7roi"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Stand im Schlafrock da,", "tokens": ["Stand", "im", "Schla\u00b7frock", "da", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Frierend auf des Lagers Wiese,", "tokens": ["Frie\u00b7rend", "auf", "des", "La\u00b7gers", "Wie\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eugens beste Morgenprise!", "tokens": ["Eu\u00b7gens", "bes\u00b7te", "Mor\u00b7gen\u00b7pri\u00b7se", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Da\u00df solch frommes Thun geehrt,", "tokens": ["Da\u00df", "solch", "from\u00b7mes", "Thun", "ge\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weiht der Pabst ihm Hut und Schwert,", "tokens": ["Weiht", "der", "Pabst", "ihm", "Hut", "und", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deutschlands Kaiser gab", "tokens": ["Deutschlands", "Kai\u00b7ser", "gab"], "token_info": ["word", "word", "word"], "pos": ["NE", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Ihm den Marschallstab,", "tokens": ["Ihm", "den", "Mar\u00b7schall\u00b7stab", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "H\u00e4ngt ihm selbst des Vlie\u00dfes Orden", "tokens": ["H\u00e4ngt", "ihm", "selbst", "des", "Vlie\u00b7\u00dfes", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uebers Kleid mit goldnen Borden.", "tokens": ["Ue\u00b7bers", "Kleid", "mit", "gold\u00b7nen", "Bor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Brittenschiffe schm\u00fcckt sein Nam',", "tokens": ["Brit\u00b7ten\u00b7schif\u00b7fe", "schm\u00fcckt", "sein", "Nam'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch ein Bot' aus Frankreich kam:", "tokens": ["Auch", "ein", "Bot'", "aus", "Fran\u00b7kreich", "kam", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbk\u00f6nig Louis Euch beut,", "tokens": ["\u00bb", "k\u00f6\u00b7nig", "Lou\u00b7is", "Euch", "beut", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "NE", "PPER", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Eures Ruhms erfreut,", "tokens": ["Eu\u00b7res", "Ruhms", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Gru\u00df und Rang in Frankreichs Heere,", "tokens": ["Gru\u00df", "und", "Rang", "in", "Fran\u00b7kreichs", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df Ihr's f\u00fchrt zu Sieg und Ehre.\u00ab", "tokens": ["Da\u00df", "Ih\u00b7r's", "f\u00fchrt", "zu", "Sieg", "und", "Eh\u00b7re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Prinz Eugenius sinnt nicht lang:", "tokens": ["Prinz", "Eu\u00b7ge\u00b7nius", "sinnt", "nicht", "lang", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "++-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbeurem K\u00f6nig sch\u00f6nen Dank!", "tokens": ["\u00bb", "eu\u00b7rem", "K\u00f6\u00b7nig", "sch\u00f6\u00b7nen", "Dank", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Folgsam seiner Lehr'", "tokens": ["Folg\u00b7sam", "sei\u00b7ner", "Lehr'"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Ward ich Mission\u00e4r,", "tokens": ["Ward", "ich", "Mis\u00b7si\u00b7o\u00b7n\u00e4r", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Hab' in Oestreich eine Sendung,", "tokens": ["Hab'", "in", "O\u00b7e\u00b7streich", "ei\u00b7ne", "Sen\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fchrte gern sie zur Vollendung!", "tokens": ["F\u00fchr\u00b7te", "gern", "sie", "zur", "Vol\u00b7len\u00b7dung", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "APPRART", "NN", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Auch den Bischofsstab ich fand", "tokens": ["Auch", "den", "Bi\u00b7schofs\u00b7stab", "ich", "fand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Freilich nicht in seinem Land;", "tokens": ["Frei\u00b7lich", "nicht", "in", "sei\u00b7nem", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch von Zeit zu Zeit,", "tokens": ["Doch", "von", "Zeit", "zu", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "APPR", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Da die Grenz' unweit,", "tokens": ["Da", "die", "Grenz'", "un\u00b7weit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Komm' ich, will der Herr mich schirmen,", "tokens": ["Komm'", "ich", ",", "will", "der", "Herr", "mich", "schir\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VMFIN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gern auch in sein Kirchspiel firmen.\u00ab", "tokens": ["Gern", "auch", "in", "sein", "Kirch\u00b7spiel", "fir\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.18": {"line.1": {"text": "Also ehrten Land und See", "tokens": ["Al\u00b7so", "ehr\u00b7ten", "Land", "und", "See"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Oestreichs kleinen Herrn Abb\u00e9.", "tokens": ["O\u00b7e\u00b7streichs", "klei\u00b7nen", "Herrn", "Ab\u00b7b\u00e9", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Seiner Priesterhand", "tokens": ["Sei\u00b7ner", "Pries\u00b7ter\u00b7hand"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Segen str\u00f6mt aufs Land;", "tokens": ["Se\u00b7gen", "str\u00f6mt", "aufs", "Land", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Einig schw\u00f6ren's Pfaff und Laien:", "tokens": ["Ei\u00b7nig", "schw\u00f6\u00b7ren's", "Pfaff", "und", "Lai\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00bbja, das sind die heil'gen Weihen!\u00ab", "tokens": ["\u00bb", "ja", ",", "das", "sind", "die", "heil'\u00b7gen", "Wei\u00b7hen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Sprach der alte Prinz zum Sohn:", "tokens": ["Sprach", "der", "al\u00b7te", "Prinz", "zum", "Sohn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbkind, ich dien' um Frankreichs Lohn,", "tokens": ["\u00bb", "kind", ",", "ich", "dien'", "um", "Fran\u00b7kreichs", "Lohn", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$,", "PPER", "VVFIN", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin an Kindern reich,", "tokens": ["Bin", "an", "Kin\u00b7dern", "reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Nicht an G\u00fctern gleich;", "tokens": ["Nicht", "an", "G\u00fc\u00b7tern", "gleich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Taugst zu anderm nicht auf Erden,", "tokens": ["Taugst", "zu", "an\u00b7derm", "nicht", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIS", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Magst mir ein Pr\u00e4late werden.\u00ab", "tokens": ["Magst", "mir", "ein", "Pr\u00e4\u00b7la\u00b7te", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "H\u00fcbsch in Notredame stehn,", "tokens": ["H\u00fcbsch", "in", "Not\u00b7re\u00b7da\u00b7me", "stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Psalmen singen soll Eugen;", "tokens": ["Psal\u00b7men", "sin\u00b7gen", "soll", "Eu\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VMFIN", "NE", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Seltsamer Abb\u00e9,", "tokens": ["Selt\u00b7sa\u00b7mer", "Ab\u00b7b\u00e9", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Flieht des M\u00fcnsters N\u00e4h',", "tokens": ["Flieht", "des", "M\u00fcns\u00b7ters", "N\u00e4h'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Tr\u00e4gt Gesporn statt seidner Socken,", "tokens": ["Tr\u00e4gt", "Ge\u00b7sporn", "statt", "seid\u00b7ner", "So\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schwingt Rappiere statt der Glocken!", "tokens": ["Schwingt", "Rap\u00b7pie\u00b7re", "statt", "der", "Glo\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "H\u00e4lt nicht sehr auf Kleiderpracht,", "tokens": ["H\u00e4lt", "nicht", "sehr", "auf", "Klei\u00b7der\u00b7pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist der Dose mehr bedacht,", "tokens": ["Ist", "der", "Do\u00b7se", "mehr", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Abb\u00e9 zum Gl\u00fcck", "tokens": ["Ein", "Ab\u00b7b\u00e9", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Nur in diesem St\u00fcck;", "tokens": ["Nur", "in", "die\u00b7sem", "St\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Aber klopft er drauf, so schallt es", "tokens": ["A\u00b7ber", "klopft", "er", "drauf", ",", "so", "schallt", "es"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie ein Schu\u00df, von Pulver wallt es!", "tokens": ["Wie", "ein", "Schu\u00df", ",", "von", "Pul\u00b7ver", "wallt", "es", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "APPR", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "M\u00e4dchen l\u00e4\u00dft er ungeneckt,", "tokens": ["M\u00e4d\u00b7chen", "l\u00e4\u00dft", "er", "un\u00b7ge\u00b7neckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tag und Nacht im Buch er steckt;", "tokens": ["Tag", "und", "Nacht", "im", "Buch", "er", "steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Grad in diesem St\u00fcck", "tokens": ["Grad", "in", "die\u00b7sem", "St\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PDAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Kein Abb\u00e9 zum Gl\u00fcck!", "tokens": ["Kein", "Ab\u00b7b\u00e9", "zum", "Gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Sein Brevier ist's, m\u00f6gt ihr rathen,", "tokens": ["Sein", "Bre\u00b7vier", "ist's", ",", "m\u00f6gt", "ihr", "ra\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nein, doch Alexanders Thaten!", "tokens": ["Nein", ",", "doch", "A\u00b7lex\u00b7an\u00b7ders", "Tha\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "NE", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Gl\u00fchend steigt es ihm zu Haupt;", "tokens": ["Gl\u00fc\u00b7hend", "steigt", "es", "ihm", "zu", "Haupt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unfrisirt, tabakbestaubt", "tokens": ["Un\u00b7fri\u00b7sirt", ",", "ta\u00b7bak\u00b7be\u00b7staubt"], "token_info": ["word", "punct", "word"], "pos": ["VVPP", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fliegt er in das Schlo\u00df:", "tokens": ["Fliegt", "er", "in", "das", "Schlo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "\u00bbherrscher, k\u00fchn und gro\u00df,", "tokens": ["\u00bb", "herr\u00b7scher", ",", "k\u00fchn", "und", "gro\u00df", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Gib mir Rang in Frankreichs Heere", "tokens": ["Gib", "mir", "Rang", "in", "Fran\u00b7kreichs", "Hee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "NN", "APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ich's f\u00fchr' in Sieg und Ehre.\u00ab", "tokens": ["Da\u00df", "ich's", "f\u00fchr'", "in", "Sieg", "und", "Eh\u00b7re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "K\u00f6nig Louis ihn scharf beschaut:", "tokens": ["K\u00f6\u00b7nig", "Lou\u00b7is", "ihn", "scharf", "be\u00b7schaut", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "ADJD", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "\u00bbseid mit Pulver zwar vertraut,", "tokens": ["\u00bb", "seid", "mit", "Pul\u00b7ver", "zwar", "ver\u00b7traut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch, mein Herr Abb\u00e9,", "tokens": ["Doch", ",", "mein", "Herr", "Ab\u00b7b\u00e9", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Bleibt nur beim Rap\u00e9,", "tokens": ["Bleibt", "nur", "beim", "Rap\u00e9", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Das Rapier doch m\u00f6gt Ihr lassen,", "tokens": ["Das", "Ra\u00b7pier", "doch", "m\u00f6gt", "Ihr", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Einst den Bischofsstab zu fassen.\u00ab", "tokens": ["Einst", "den", "Bi\u00b7schofs\u00b7stab", "zu", "fas\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Sch\u00f6nes Frankreich, nun Ade!", "tokens": ["Sch\u00f6\u00b7nes", "Fran\u00b7kreich", ",", "nun", "A\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADV", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Gegen Wien trabt dein Abb\u00e9;", "tokens": ["Ge\u00b7gen", "Wi\u00b7en", "trabt", "dein", "Ab\u00b7b\u00e9", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kaiser Leopold,", "tokens": ["Kai\u00b7ser", "Leo\u00b7pold", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Jedem Schwarzrock hold,", "tokens": ["Je\u00b7dem", "Schwarz\u00b7rock", "hold", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Hei\u00dft in Oestreich ihn willkommen:", "tokens": ["Hei\u00dft", "in", "O\u00b7e\u00b7streich", "ihn", "will\u00b7kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bboffen steht mein Reich den Frommen.\u00ab", "tokens": ["\u00bb", "of\u00b7fen", "steht", "mein", "Reich", "den", "From\u00b7men", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "\u00bbist im lieben Portugall", "tokens": ["\u00bb", "ist", "im", "lie\u00b7ben", "Por\u00b7tu\u00b7gall"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sanct Antonius Feldmarschall,", "tokens": ["Sanct", "An\u00b7to\u00b7ni\u00b7us", "Feld\u00b7mar\u00b7schall", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Taugt wohl ein Abb\u00e9", "tokens": ["Taugt", "wohl", "ein", "Ab\u00b7b\u00e9"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Mir in T\u00fcrkenn\u00e4h';", "tokens": ["Mir", "in", "T\u00fcr\u00b7ken\u00b7n\u00e4h'", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Beten hilft so gut wie Raufen,", "tokens": ["Be\u00b7ten", "hilft", "so", "gut", "wie", "Rau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADJD", "KOKOM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und ein Sieg auch ist das Taufen.\u00ab", "tokens": ["Und", "ein", "Sieg", "auch", "ist", "das", "Tau\u00b7fen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VAFIN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Die Dragoner, schlachtgereiht,", "tokens": ["Die", "Dra\u00b7go\u00b7ner", ",", "schlacht\u00b7ge\u00b7reiht", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehn das kuttenbraune Kleid,", "tokens": ["Sehn", "das", "kut\u00b7ten\u00b7brau\u00b7ne", "Kleid", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lachen durch die Reihn:", "tokens": ["La\u00b7chen", "durch", "die", "Reihn", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "\u00bbkapuzinerlein,", "tokens": ["\u00bb", "ka\u00b7pu\u00b7zi\u00b7ner\u00b7lein", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Lies uns Messe, weih' die Fahne,", "tokens": ["Lies", "uns", "Mes\u00b7se", ",", "weih'", "die", "Fah\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Pred'ge, neuer Kapistrane!\u00ab", "tokens": ["Pre\u00b7d'\u00b7ge", ",", "neu\u00b7er", "Ka\u00b7pis\u00b7tra\u00b7ne", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$.", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.28": {"line.1": {"text": "Und das Pf\u00e4fflein fr\u00fch und spat", "tokens": ["Und", "das", "Pf\u00e4f\u00b7flein", "fr\u00fch", "und", "spat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Predigt gut in Feld und Rath;", "tokens": ["Pre\u00b7digt", "gut", "in", "Feld", "und", "Rath", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Springt einst rasch vom Pferd,", "tokens": ["Springt", "einst", "rasch", "vom", "Pferd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00e4lt im Mund sein Schwert,", "tokens": ["H\u00e4lt", "im", "Mund", "sein", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Klimmt empor zum T\u00fcrkenwalle;", "tokens": ["Klimmt", "em\u00b7por", "zum", "T\u00fcr\u00b7ken\u00b7wal\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Diese Predigt lobten Alle.", "tokens": ["Die\u00b7se", "Pre\u00b7digt", "lob\u00b7ten", "Al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Und vor Belgrad auf der Schanz'", "tokens": ["Und", "vor", "Bel\u00b7grad", "auf", "der", "Schanz'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Betet er den Rosenkranz.", "tokens": ["Be\u00b7tet", "er", "den", "Ro\u00b7sen\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ri\u00df vielleicht die Schnur?", "tokens": ["Ri\u00df", "viel\u00b7leicht", "die", "Schnur", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df auf Stadt und Flur", "tokens": ["Da\u00df", "auf", "Stadt", "und", "Flur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "KON", "NN"], "meter": "--+-+", "measure": "anapaest.init"}, "line.5": {"text": "Schwarz und dicht die Betkorallen", "tokens": ["Schwarz", "und", "dicht", "die", "Bet\u00b7ko\u00b7ral\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "ADJD", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aus dem Paternoster fallen!", "tokens": ["Aus", "dem", "Pa\u00b7ter\u00b7nos\u00b7ter", "fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Dann in W\u00e4lschland und am Rhein", "tokens": ["Dann", "in", "W\u00e4l\u00b7schland", "und", "am", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "APPRART", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "R\u00e4uchert er den Franzmann ein;", "tokens": ["R\u00e4u\u00b7chert", "er", "den", "Franz\u00b7mann", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser Weihrauch doch", "tokens": ["Die\u00b7ser", "Weih\u00b7rauch", "doch"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "NN", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Nicht nach Amber roch,", "tokens": ["Nicht", "nach", "Am\u00b7ber", "roch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Rauchfa\u00df auch und heil'ge Kerze", "tokens": ["Rauch\u00b7fa\u00df", "auch", "und", "heil'\u00b7ge", "Ker\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "War von etwas grobem Erze.", "tokens": ["War", "von", "et\u00b7was", "gro\u00b7bem", "Er\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "In Cremona holt vom Bett", "tokens": ["In", "Cre\u00b7mo\u00b7na", "holt", "vom", "Bett"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "APPRART", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Er den Feind zur fr\u00fchen Mett';", "tokens": ["Er", "den", "Feind", "zur", "fr\u00fc\u00b7hen", "Mett'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Marschall Villeroi", "tokens": ["Mar\u00b7schall", "Vil\u00b7le\u00b7roi"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Stand im Schlafrock da,", "tokens": ["Stand", "im", "Schla\u00b7frock", "da", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Frierend auf des Lagers Wiese,", "tokens": ["Frie\u00b7rend", "auf", "des", "La\u00b7gers", "Wie\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eugens beste Morgenprise!", "tokens": ["Eu\u00b7gens", "bes\u00b7te", "Mor\u00b7gen\u00b7pri\u00b7se", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Da\u00df solch frommes Thun geehrt,", "tokens": ["Da\u00df", "solch", "from\u00b7mes", "Thun", "ge\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weiht der Pabst ihm Hut und Schwert,", "tokens": ["Weiht", "der", "Pabst", "ihm", "Hut", "und", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deutschlands Kaiser gab", "tokens": ["Deutschlands", "Kai\u00b7ser", "gab"], "token_info": ["word", "word", "word"], "pos": ["NE", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Ihm den Marschallstab,", "tokens": ["Ihm", "den", "Mar\u00b7schall\u00b7stab", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "H\u00e4ngt ihm selbst des Vlie\u00dfes Orden", "tokens": ["H\u00e4ngt", "ihm", "selbst", "des", "Vlie\u00b7\u00dfes", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uebers Kleid mit goldnen Borden.", "tokens": ["Ue\u00b7bers", "Kleid", "mit", "gold\u00b7nen", "Bor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Brittenschiffe schm\u00fcckt sein Nam',", "tokens": ["Brit\u00b7ten\u00b7schif\u00b7fe", "schm\u00fcckt", "sein", "Nam'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch ein Bot' aus Frankreich kam:", "tokens": ["Auch", "ein", "Bot'", "aus", "Fran\u00b7kreich", "kam", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbk\u00f6nig Louis Euch beut,", "tokens": ["\u00bb", "k\u00f6\u00b7nig", "Lou\u00b7is", "Euch", "beut", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "NE", "PPER", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Eures Ruhms erfreut,", "tokens": ["Eu\u00b7res", "Ruhms", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Gru\u00df und Rang in Frankreichs Heere,", "tokens": ["Gru\u00df", "und", "Rang", "in", "Fran\u00b7kreichs", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df Ihr's f\u00fchrt zu Sieg und Ehre.\u00ab", "tokens": ["Da\u00df", "Ih\u00b7r's", "f\u00fchrt", "zu", "Sieg", "und", "Eh\u00b7re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Prinz Eugenius sinnt nicht lang:", "tokens": ["Prinz", "Eu\u00b7ge\u00b7nius", "sinnt", "nicht", "lang", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "++-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbeurem K\u00f6nig sch\u00f6nen Dank!", "tokens": ["\u00bb", "eu\u00b7rem", "K\u00f6\u00b7nig", "sch\u00f6\u00b7nen", "Dank", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Folgsam seiner Lehr'", "tokens": ["Folg\u00b7sam", "sei\u00b7ner", "Lehr'"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Ward ich Mission\u00e4r,", "tokens": ["Ward", "ich", "Mis\u00b7si\u00b7o\u00b7n\u00e4r", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Hab' in Oestreich eine Sendung,", "tokens": ["Hab'", "in", "O\u00b7e\u00b7streich", "ei\u00b7ne", "Sen\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fchrte gern sie zur Vollendung!", "tokens": ["F\u00fchr\u00b7te", "gern", "sie", "zur", "Vol\u00b7len\u00b7dung", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "APPRART", "NN", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}, "stanza.35": {"line.1": {"text": "Auch den Bischofsstab ich fand", "tokens": ["Auch", "den", "Bi\u00b7schofs\u00b7stab", "ich", "fand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Freilich nicht in seinem Land;", "tokens": ["Frei\u00b7lich", "nicht", "in", "sei\u00b7nem", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch von Zeit zu Zeit,", "tokens": ["Doch", "von", "Zeit", "zu", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "APPR", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Da die Grenz' unweit,", "tokens": ["Da", "die", "Grenz'", "un\u00b7weit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Komm' ich, will der Herr mich schirmen,", "tokens": ["Komm'", "ich", ",", "will", "der", "Herr", "mich", "schir\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VMFIN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gern auch in sein Kirchspiel firmen.\u00ab", "tokens": ["Gern", "auch", "in", "sein", "Kirch\u00b7spiel", "fir\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.36": {"line.1": {"text": "Also ehrten Land und See", "tokens": ["Al\u00b7so", "ehr\u00b7ten", "Land", "und", "See"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Oestreichs kleinen Herrn Abb\u00e9.", "tokens": ["O\u00b7e\u00b7streichs", "klei\u00b7nen", "Herrn", "Ab\u00b7b\u00e9", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Seiner Priesterhand", "tokens": ["Sei\u00b7ner", "Pries\u00b7ter\u00b7hand"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Segen str\u00f6mt aufs Land;", "tokens": ["Se\u00b7gen", "str\u00f6mt", "aufs", "Land", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Einig schw\u00f6ren's Pfaff und Laien:", "tokens": ["Ei\u00b7nig", "schw\u00f6\u00b7ren's", "Pfaff", "und", "Lai\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00bbja, das sind die heil'gen Weihen!\u00ab", "tokens": ["\u00bb", "ja", ",", "das", "sind", "die", "heil'\u00b7gen", "Wei\u00b7hen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}