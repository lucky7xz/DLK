{"textgrid.poem.54079": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der Neurotiker", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Er sitzt wie hinter Glas, das arme Luder,", "tokens": ["Er", "sitzt", "wie", "hin\u00b7ter", "Glas", ",", "das", "ar\u00b7me", "Lu\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und trippelt \u00e4ngstlich an des Lebens Rand.", "tokens": ["und", "trip\u00b7pelt", "\u00e4ngst\u00b7lich", "an", "des", "Le\u00b7bens", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er flieht und sucht und flieht den Menschenbruder", "tokens": ["Er", "flieht", "und", "sucht", "und", "flieht", "den", "Men\u00b7schen\u00b7bru\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und hat den Nebenmenschen nie gekannt.", "tokens": ["und", "hat", "den", "Ne\u00b7ben\u00b7men\u00b7schen", "nie", "ge\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er strahlte, wenn er grollte,", "tokens": ["Er", "strahl\u00b7te", ",", "wenn", "er", "groll\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "nur Flucht ist sein Verzicht . . .", "tokens": ["nur", "Flucht", "ist", "sein", "Ver\u00b7zicht", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Er k\u00f6nnte, m\u00fc\u00dfte, sollte \u2013", "tokens": ["Er", "k\u00f6nn\u00b7te", ",", "m\u00fc\u00df\u00b7te", ",", "soll\u00b7te", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VMFIN", "$,", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "und kann doch nicht.", "tokens": ["und", "kann", "doch", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Er d\u00fcnkt sich klein. Wie eitel ist der Knabe!", "tokens": ["Er", "d\u00fcnkt", "sich", "klein", ".", "Wie", "ei\u00b7tel", "ist", "der", "Kna\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$.", "PWAV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er d\u00fcnkt sich klein. Doch keiner ist ihm gro\u00df.", "tokens": ["Er", "d\u00fcnkt", "sich", "klein", ".", "Doch", "kei\u00b7ner", "ist", "ihm", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$.", "KON", "PIS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sein starres Ich ist seine ganze Habe;", "tokens": ["Sein", "star\u00b7res", "Ich", "ist", "sei\u00b7ne", "gan\u00b7ze", "Ha\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "er will kein Schicksal \u2013 nur das gro\u00dfe Los.", "tokens": ["er", "will", "kein", "Schick\u00b7sal", "\u2013", "nur", "das", "gro\u00b7\u00dfe", "Los", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "$(", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ja, wenn er wollen wollte . . . !", "tokens": ["Ja", ",", "wenn", "er", "wol\u00b7len", "woll\u00b7te", ".", ".", ".", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "VMFIN", "VMFIN", "$.", "$.", "$.", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Er hat kein Gleichgewicht.", "tokens": ["Er", "hat", "kein", "Gleich\u00b7ge\u00b7wicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Er k\u00f6nnte, m\u00fc\u00dfte, sollte \u2013", "tokens": ["Er", "k\u00f6nn\u00b7te", ",", "m\u00fc\u00df\u00b7te", ",", "soll\u00b7te", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VMFIN", "$,", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "und kann doch nicht.", "tokens": ["und", "kann", "doch", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Er meint: die b\u00f6se Welt mu\u00df an ihm schuld sein;", "tokens": ["Er", "meint", ":", "die", "b\u00f6\u00b7se", "Welt", "mu\u00df", "an", "ihm", "schuld", "sein", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "ADJA", "NN", "VMFIN", "APPR", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "er projiziert auf sie sein d\u00fcnnes Weh.", "tokens": ["er", "pro\u00b7ji\u00b7ziert", "auf", "sie", "sein", "d\u00fcn\u00b7nes", "Weh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er m\u00f6chte ganz allein und im Tumult sein:", "tokens": ["Er", "m\u00f6ch\u00b7te", "ganz", "al\u00b7lein", "und", "im", "Tu\u00b7mult", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "KON", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "vorn Leipziger Stra\u00dfe \u2013 hinten Comer See.", "tokens": ["vorn", "Leip\u00b7zi\u00b7ger", "Stra\u00b7\u00dfe", "\u2013", "hin\u00b7ten", "Co\u00b7mer", "See", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$(", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Er sp\u00fcrt, wie in ihm sausend", "tokens": ["Er", "sp\u00fcrt", ",", "wie", "in", "ihm", "sau\u00b7send"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "APPR", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "die kranken Nerven schrein.", "tokens": ["die", "kran\u00b7ken", "Ner\u00b7ven", "schrein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "So gibt es hunderttausend \u2013", "tokens": ["So", "gibt", "es", "hun\u00b7dert\u00b7tau\u00b7send", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "und jeder ist allein.", "tokens": ["und", "je\u00b7der", "ist", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und kann man \u2013 kann man solche Knaben heilen?", "tokens": ["Und", "kann", "man", "\u2013", "kann", "man", "sol\u00b7che", "Kna\u00b7ben", "hei\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "$(", "VMFIN", "PIS", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man: nein. Sie: ja. Gesund wird nur, wer will.", "tokens": ["Man", ":", "nein", ".", "Sie", ":", "ja", ".", "Ge\u00b7sund", "wird", "nur", ",", "wer", "will", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "$.", "PTKANT", "$.", "PPER", "$.", "ADV", "$.", "NN", "VAFIN", "ADV", "$,", "PWS", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man kann ihn l\u00f6sen, lockern, spalten, heilen \u2013", "tokens": ["Man", "kann", "ihn", "l\u00f6\u00b7sen", ",", "lo\u00b7ckern", ",", "spal\u00b7ten", ",", "hei\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und dann zu sich verhelfen, fest und still.", "tokens": ["und", "dann", "zu", "sich", "ver\u00b7hel\u00b7fen", ",", "fest", "und", "still", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PRF", "VVINF", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er ist, vor Faulheit flei\u00dfig,", "tokens": ["Er", "ist", ",", "vor", "Faul\u00b7heit", "flei\u00b7\u00dfig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "der echte Exponent", "tokens": ["der", "ech\u00b7te", "Ex\u00b7po\u00b7nent"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "von 1930,", "tokens": ["von", "19\u00b730", ","], "token_info": ["word", "number", "punct"], "pos": ["APPR", "CARD", "$,"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "das solche Nummern kennt.", "tokens": ["das", "sol\u00b7che", "Num\u00b7mern", "kennt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Wie mancher davon verz\u00fcckt ist . . . !", "tokens": ["Wie", "man\u00b7cher", "da\u00b7von", "ver\u00b7z\u00fcckt", "ist", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PWAV", "PIS", "PAV", "VVPP", "VAFIN", "$.", "$.", "$.", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Lerne bei Vater Jung:", "tokens": ["Ler\u00b7ne", "bei", "Va\u00b7ter", "Jung", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.11": {"text": "Es fragt sich, wer verr\u00fcckt ist.", "tokens": ["Es", "fragt", "sich", ",", "wer", "ver\u00b7r\u00fcckt", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "PWS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und dann gute Besserung \u2013!", "tokens": ["Und", "dann", "gu\u00b7te", "Bes\u00b7se\u00b7rung", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$(", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.5": {"line.1": {"text": "Er sitzt wie hinter Glas, das arme Luder,", "tokens": ["Er", "sitzt", "wie", "hin\u00b7ter", "Glas", ",", "das", "ar\u00b7me", "Lu\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und trippelt \u00e4ngstlich an des Lebens Rand.", "tokens": ["und", "trip\u00b7pelt", "\u00e4ngst\u00b7lich", "an", "des", "Le\u00b7bens", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er flieht und sucht und flieht den Menschenbruder", "tokens": ["Er", "flieht", "und", "sucht", "und", "flieht", "den", "Men\u00b7schen\u00b7bru\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und hat den Nebenmenschen nie gekannt.", "tokens": ["und", "hat", "den", "Ne\u00b7ben\u00b7men\u00b7schen", "nie", "ge\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er strahlte, wenn er grollte,", "tokens": ["Er", "strahl\u00b7te", ",", "wenn", "er", "groll\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "nur Flucht ist sein Verzicht . . .", "tokens": ["nur", "Flucht", "ist", "sein", "Ver\u00b7zicht", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Er k\u00f6nnte, m\u00fc\u00dfte, sollte \u2013", "tokens": ["Er", "k\u00f6nn\u00b7te", ",", "m\u00fc\u00df\u00b7te", ",", "soll\u00b7te", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VMFIN", "$,", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "und kann doch nicht.", "tokens": ["und", "kann", "doch", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Er d\u00fcnkt sich klein. Wie eitel ist der Knabe!", "tokens": ["Er", "d\u00fcnkt", "sich", "klein", ".", "Wie", "ei\u00b7tel", "ist", "der", "Kna\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$.", "PWAV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er d\u00fcnkt sich klein. Doch keiner ist ihm gro\u00df.", "tokens": ["Er", "d\u00fcnkt", "sich", "klein", ".", "Doch", "kei\u00b7ner", "ist", "ihm", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$.", "KON", "PIS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sein starres Ich ist seine ganze Habe;", "tokens": ["Sein", "star\u00b7res", "Ich", "ist", "sei\u00b7ne", "gan\u00b7ze", "Ha\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "er will kein Schicksal \u2013 nur das gro\u00dfe Los.", "tokens": ["er", "will", "kein", "Schick\u00b7sal", "\u2013", "nur", "das", "gro\u00b7\u00dfe", "Los", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "$(", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ja, wenn er wollen wollte . . . !", "tokens": ["Ja", ",", "wenn", "er", "wol\u00b7len", "woll\u00b7te", ".", ".", ".", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "VMFIN", "VMFIN", "$.", "$.", "$.", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Er hat kein Gleichgewicht.", "tokens": ["Er", "hat", "kein", "Gleich\u00b7ge\u00b7wicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Er k\u00f6nnte, m\u00fc\u00dfte, sollte \u2013", "tokens": ["Er", "k\u00f6nn\u00b7te", ",", "m\u00fc\u00df\u00b7te", ",", "soll\u00b7te", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VMFIN", "$,", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "und kann doch nicht.", "tokens": ["und", "kann", "doch", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Er meint: die b\u00f6se Welt mu\u00df an ihm schuld sein;", "tokens": ["Er", "meint", ":", "die", "b\u00f6\u00b7se", "Welt", "mu\u00df", "an", "ihm", "schuld", "sein", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "ADJA", "NN", "VMFIN", "APPR", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "er projiziert auf sie sein d\u00fcnnes Weh.", "tokens": ["er", "pro\u00b7ji\u00b7ziert", "auf", "sie", "sein", "d\u00fcn\u00b7nes", "Weh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er m\u00f6chte ganz allein und im Tumult sein:", "tokens": ["Er", "m\u00f6ch\u00b7te", "ganz", "al\u00b7lein", "und", "im", "Tu\u00b7mult", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "KON", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "vorn Leipziger Stra\u00dfe \u2013 hinten Comer See.", "tokens": ["vorn", "Leip\u00b7zi\u00b7ger", "Stra\u00b7\u00dfe", "\u2013", "hin\u00b7ten", "Co\u00b7mer", "See", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$(", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Er sp\u00fcrt, wie in ihm sausend", "tokens": ["Er", "sp\u00fcrt", ",", "wie", "in", "ihm", "sau\u00b7send"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "APPR", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "die kranken Nerven schrein.", "tokens": ["die", "kran\u00b7ken", "Ner\u00b7ven", "schrein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "So gibt es hunderttausend \u2013", "tokens": ["So", "gibt", "es", "hun\u00b7dert\u00b7tau\u00b7send", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "und jeder ist allein.", "tokens": ["und", "je\u00b7der", "ist", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und kann man \u2013 kann man solche Knaben heilen?", "tokens": ["Und", "kann", "man", "\u2013", "kann", "man", "sol\u00b7che", "Kna\u00b7ben", "hei\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "$(", "VMFIN", "PIS", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Man: nein. Sie: ja. Gesund wird nur, wer will.", "tokens": ["Man", ":", "nein", ".", "Sie", ":", "ja", ".", "Ge\u00b7sund", "wird", "nur", ",", "wer", "will", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "$.", "PTKANT", "$.", "PPER", "$.", "ADV", "$.", "NN", "VAFIN", "ADV", "$,", "PWS", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man kann ihn l\u00f6sen, lockern, spalten, heilen \u2013", "tokens": ["Man", "kann", "ihn", "l\u00f6\u00b7sen", ",", "lo\u00b7ckern", ",", "spal\u00b7ten", ",", "hei\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und dann zu sich verhelfen, fest und still.", "tokens": ["und", "dann", "zu", "sich", "ver\u00b7hel\u00b7fen", ",", "fest", "und", "still", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PRF", "VVINF", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er ist, vor Faulheit flei\u00dfig,", "tokens": ["Er", "ist", ",", "vor", "Faul\u00b7heit", "flei\u00b7\u00dfig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "der echte Exponent", "tokens": ["der", "ech\u00b7te", "Ex\u00b7po\u00b7nent"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "von 1930,", "tokens": ["von", "19\u00b730", ","], "token_info": ["word", "number", "punct"], "pos": ["APPR", "CARD", "$,"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "das solche Nummern kennt.", "tokens": ["das", "sol\u00b7che", "Num\u00b7mern", "kennt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Wie mancher davon verz\u00fcckt ist . . . !", "tokens": ["Wie", "man\u00b7cher", "da\u00b7von", "ver\u00b7z\u00fcckt", "ist", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PWAV", "PIS", "PAV", "VVPP", "VAFIN", "$.", "$.", "$.", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Lerne bei Vater Jung:", "tokens": ["Ler\u00b7ne", "bei", "Va\u00b7ter", "Jung", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.11": {"text": "Es fragt sich, wer verr\u00fcckt ist.", "tokens": ["Es", "fragt", "sich", ",", "wer", "ver\u00b7r\u00fcckt", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "PWS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und dann gute Besserung \u2013!", "tokens": ["Und", "dann", "gu\u00b7te", "Bes\u00b7se\u00b7rung", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$(", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}}}}