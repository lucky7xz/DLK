{"textgrid.poem.38112": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Kloster Trebnitz", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der edel Herzog Heinrich zu Pferd", "tokens": ["Der", "e\u00b7del", "Her\u00b7zog", "Hein\u00b7rich", "zu", "Pferd"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "NE", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "St\u00fcrzt in den Sumpf gar tief, tief, tief.", "tokens": ["St\u00fcrzt", "in", "den", "Sumpf", "gar", "tief", ",", "tief", ",", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Seines Lebens er sich schier verwehrt,", "tokens": ["Sei\u00b7nes", "Le\u00b7bens", "er", "sich", "schier", "ver\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "PRF", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Als Gott sein Engel rief, rief, rief.", "tokens": ["Als", "Gott", "sein", "En\u00b7gel", "rief", ",", "rief", ",", "rief", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Engel nahm ein K\u00f6hlertracht,", "tokens": ["Der", "En\u00b7gel", "nahm", "ein", "K\u00f6h\u00b7ler\u00b7tracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und trat zum Sumpf hinan, an, an.", "tokens": ["Und", "trat", "zum", "Sumpf", "hi\u00b7nan", ",", "an", ",", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "PTKVZ", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schnell dem Herrn ein Aestlein bracht:", "tokens": ["Und", "schnell", "dem", "Herrn", "ein", "A\u00b7est\u00b7lein", "bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "\u00bbda halt der Herr sich dran, dran, dran.\u00ab", "tokens": ["\u00bb", "da", "halt", "der", "Herr", "sich", "dran", ",", "dran", ",", "dran", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "PRF", "PAV", "$,", "PAV", "$,", "PAV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und als der Herzog g'rettet war,", "tokens": ["Und", "als", "der", "Her\u00b7zog", "g'\u00b7ret\u00b7tet", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da kniet er freudig hin, hin, hin.", "tokens": ["Da", "kniet", "er", "freu\u00b7dig", "hin", ",", "hin", ",", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PTKVZ", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbo Herr wie ist es wunderbar,", "tokens": ["\u00bb", "o", "Herr", "wie", "ist", "es", "wun\u00b7der\u00b7bar", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "KOKOM", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich gerettet bin, bin, bin.", "tokens": ["Da\u00df", "ich", "ge\u00b7ret\u00b7tet", "bin", ",", "bin", ",", "bin", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,", "VAFIN", "$,", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und bin ich denn gerettet nun,", "tokens": ["Und", "bin", "ich", "denn", "ge\u00b7ret\u00b7tet", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bau ich ein Kloster dir, dir, dir,", "tokens": ["Bau", "ich", "ein", "Klos\u00b7ter", "dir", ",", "dir", ",", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "PPER", "$,", "PPER", "$,", "PPER", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Da\u00df man dir dien in Fried und Ruh,", "tokens": ["Da\u00df", "man", "dir", "di\u00b7en", "in", "Fried", "und", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Auf diesem Flecklein hier, hier, hier.\u00ab", "tokens": ["Auf", "die\u00b7sem", "Flec\u00b7klein", "hier", ",", "hier", ",", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "$,", "ADV", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Das Kloster war gar sch\u00f6n gebaut,", "tokens": ["Das", "Klos\u00b7ter", "war", "gar", "sch\u00f6n", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des freut sich wer es sah, sah, sah.", "tokens": ["Des", "freut", "sich", "wer", "es", "sah", ",", "sah", ",", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "VVFIN", "PRF", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und manche fromme Gottesbraut,", "tokens": ["Und", "man\u00b7che", "from\u00b7me", "Got\u00b7tes\u00b7braut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kam hin von fern und nah, nah, nah.", "tokens": ["Kam", "hin", "von", "fern", "und", "nah", ",", "nah", ",", "nah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ADJD", "KON", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbwas begehrt ihr edle Jungfrauen mehr?\u00ab", "tokens": ["\u00bb", "was", "be\u00b7gehrt", "ihr", "ed\u00b7le", "Jung\u00b7frau\u00b7en", "mehr", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPOSAT", "ADJA", "NN", "ADV", "$.", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Der Herzog fragt sie dann, dann, dann.", "tokens": ["Der", "Her\u00b7zog", "fragt", "sie", "dann", ",", "dann", ",", "dann", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "ADV", "$,", "ADV", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwir b'd\u00fcrfen nichts und nimmermehr", "tokens": ["\u00bb", "wir", "d\u00fcr\u00b7fe", "nichts", "und", "nim\u00b7mer\u00b7mehr"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PIS", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dieweil wir alles han, han, han.\u00ab", "tokens": ["Die\u00b7weil", "wir", "al\u00b7les", "han", ",", "han", ",", "han", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PIS", "VAFIN", "$,", "VAFIN", "$,", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbund weil euch denn nichts noth mehr ist,", "tokens": ["\u00bb", "und", "weil", "euch", "denn", "nichts", "noth", "mehr", "ist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "ADV", "PIAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sey denn dieser Nam, Nam, Nam,", "tokens": ["So", "sey", "denn", "die\u00b7ser", "Nam", ",", "Nam", ",", "Nam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDAT", "NN", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Trebnitz, das hie\u00df, wir b'd\u00fcrfen nichts.\u00ab", "tokens": ["Treb\u00b7nitz", ",", "das", "hie\u00df", ",", "wir", "d\u00fcr\u00b7fe", "nichts", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "PDS", "VVFIN", "$,", "PPER", "VVFIN", "PIS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Namen es bekam, kam, kam.", "tokens": ["Den", "Na\u00b7men", "es", "be\u00b7kam", ",", "kam", ",", "kam", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der edel Herzog Heinrich zu Pferd", "tokens": ["Der", "e\u00b7del", "Her\u00b7zog", "Hein\u00b7rich", "zu", "Pferd"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "NE", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "St\u00fcrzt in den Sumpf gar tief, tief, tief.", "tokens": ["St\u00fcrzt", "in", "den", "Sumpf", "gar", "tief", ",", "tief", ",", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Seines Lebens er sich schier verwehrt,", "tokens": ["Sei\u00b7nes", "Le\u00b7bens", "er", "sich", "schier", "ver\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "PRF", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Als Gott sein Engel rief, rief, rief.", "tokens": ["Als", "Gott", "sein", "En\u00b7gel", "rief", ",", "rief", ",", "rief", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der Engel nahm ein K\u00f6hlertracht,", "tokens": ["Der", "En\u00b7gel", "nahm", "ein", "K\u00f6h\u00b7ler\u00b7tracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und trat zum Sumpf hinan, an, an.", "tokens": ["Und", "trat", "zum", "Sumpf", "hi\u00b7nan", ",", "an", ",", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "PTKVZ", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schnell dem Herrn ein Aestlein bracht:", "tokens": ["Und", "schnell", "dem", "Herrn", "ein", "A\u00b7est\u00b7lein", "bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "\u00bbda halt der Herr sich dran, dran, dran.\u00ab", "tokens": ["\u00bb", "da", "halt", "der", "Herr", "sich", "dran", ",", "dran", ",", "dran", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "PRF", "PAV", "$,", "PAV", "$,", "PAV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Und als der Herzog g'rettet war,", "tokens": ["Und", "als", "der", "Her\u00b7zog", "g'\u00b7ret\u00b7tet", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da kniet er freudig hin, hin, hin.", "tokens": ["Da", "kniet", "er", "freu\u00b7dig", "hin", ",", "hin", ",", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PTKVZ", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbo Herr wie ist es wunderbar,", "tokens": ["\u00bb", "o", "Herr", "wie", "ist", "es", "wun\u00b7der\u00b7bar", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "KOKOM", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich gerettet bin, bin, bin.", "tokens": ["Da\u00df", "ich", "ge\u00b7ret\u00b7tet", "bin", ",", "bin", ",", "bin", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,", "VAFIN", "$,", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und bin ich denn gerettet nun,", "tokens": ["Und", "bin", "ich", "denn", "ge\u00b7ret\u00b7tet", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bau ich ein Kloster dir, dir, dir,", "tokens": ["Bau", "ich", "ein", "Klos\u00b7ter", "dir", ",", "dir", ",", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "PPER", "$,", "PPER", "$,", "PPER", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Da\u00df man dir dien in Fried und Ruh,", "tokens": ["Da\u00df", "man", "dir", "di\u00b7en", "in", "Fried", "und", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Auf diesem Flecklein hier, hier, hier.\u00ab", "tokens": ["Auf", "die\u00b7sem", "Flec\u00b7klein", "hier", ",", "hier", ",", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "$,", "ADV", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Das Kloster war gar sch\u00f6n gebaut,", "tokens": ["Das", "Klos\u00b7ter", "war", "gar", "sch\u00f6n", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des freut sich wer es sah, sah, sah.", "tokens": ["Des", "freut", "sich", "wer", "es", "sah", ",", "sah", ",", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "VVFIN", "PRF", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und manche fromme Gottesbraut,", "tokens": ["Und", "man\u00b7che", "from\u00b7me", "Got\u00b7tes\u00b7braut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kam hin von fern und nah, nah, nah.", "tokens": ["Kam", "hin", "von", "fern", "und", "nah", ",", "nah", ",", "nah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ADJD", "KON", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "\u00bbwas begehrt ihr edle Jungfrauen mehr?\u00ab", "tokens": ["\u00bb", "was", "be\u00b7gehrt", "ihr", "ed\u00b7le", "Jung\u00b7frau\u00b7en", "mehr", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPOSAT", "ADJA", "NN", "ADV", "$.", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Der Herzog fragt sie dann, dann, dann.", "tokens": ["Der", "Her\u00b7zog", "fragt", "sie", "dann", ",", "dann", ",", "dann", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "ADV", "$,", "ADV", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwir b'd\u00fcrfen nichts und nimmermehr", "tokens": ["\u00bb", "wir", "d\u00fcr\u00b7fe", "nichts", "und", "nim\u00b7mer\u00b7mehr"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PIS", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dieweil wir alles han, han, han.\u00ab", "tokens": ["Die\u00b7weil", "wir", "al\u00b7les", "han", ",", "han", ",", "han", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PIS", "VAFIN", "$,", "VAFIN", "$,", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "\u00bbund weil euch denn nichts noth mehr ist,", "tokens": ["\u00bb", "und", "weil", "euch", "denn", "nichts", "noth", "mehr", "ist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "ADV", "PIAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sey denn dieser Nam, Nam, Nam,", "tokens": ["So", "sey", "denn", "die\u00b7ser", "Nam", ",", "Nam", ",", "Nam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDAT", "NN", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Trebnitz, das hie\u00df, wir b'd\u00fcrfen nichts.\u00ab", "tokens": ["Treb\u00b7nitz", ",", "das", "hie\u00df", ",", "wir", "d\u00fcr\u00b7fe", "nichts", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "PDS", "VVFIN", "$,", "PPER", "VVFIN", "PIS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Namen es bekam, kam, kam.", "tokens": ["Den", "Na\u00b7men", "es", "be\u00b7kam", ",", "kam", ",", "kam", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}