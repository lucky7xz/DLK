{"textgrid.poem.53642": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Literatur-Walzer", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn Mutter abends zu Bette geht", "tokens": ["Wenn", "Mut\u00b7ter", "a\u00b7bends", "zu", "Bet\u00b7te", "geht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADV", "APPR", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und Papa in den (blonden) Verein,", "tokens": ["und", "Pa\u00b7pa", "in", "den", "(", "blon\u00b7den", ")", "Ver\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "$(", "ADJA", "$(", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "liest Lieschen noch bei der Kerze sp\u00e4t", "tokens": ["liest", "Lie\u00b7schen", "noch", "bei", "der", "Ker\u00b7ze", "sp\u00e4t"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "ADV", "APPR", "ART", "NN", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "von Ewers Schweinigelein.", "tokens": ["von", "E\u00b7wers", "Schwei\u00b7ni\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Der Autor ersetzt einem anst\u00e4ndigen Kind", "tokens": ["Der", "Au\u00b7tor", "er\u00b7setzt", "ei\u00b7nem", "an\u00b7st\u00e4n\u00b7di\u00b7gen", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "das erotische A-B-C.", "tokens": ["das", "e\u00b7ro\u00b7ti\u00b7sche", "A\u00b7\u00b7B", "C."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["ART", "ADJA", "TRUNC", "NE"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.7": {"text": "Ein Teufelsj\u00e4ger! Er kitzelt so lind \u2013", "tokens": ["Ein", "Teu\u00b7fels\u00b7j\u00e4\u00b7ger", "!", "Er", "kit\u00b7zelt", "so", "lind", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VVFIN", "ADV", "ADJD", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ein lebendiger Gaudemich\u00e9.", "tokens": ["ein", "le\u00b7ben\u00b7di\u00b7ger", "Gau\u00b7de\u00b7mich\u00e9", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "Er kam jetzt aus Amerika", "tokens": ["Er", "kam", "jetzt", "aus", "A\u00b7me\u00b7ri\u00b7ka"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "mit einem neuen Band \u2013", "tokens": ["mit", "ei\u00b7nem", "neu\u00b7en", "Band", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Was steht darin?", "tokens": ["Was", "steht", "da\u00b7rin", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Was weht darin?", "tokens": ["Was", "weht", "da\u00b7rin", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Die Weise ist bekannt . . .", "tokens": ["Die", "Wei\u00b7se", "ist", "be\u00b7kannt", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Das hat kein Goethe g'schrieben, das hat ka Schiller dicht \u2013", "tokens": ["Das", "hat", "kein", "Goe\u00b7the", "g'\u00b7schrie\u00b7ben", ",", "das", "hat", "ka", "Schil\u00b7ler", "dicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "VVINF", "$,", "PDS", "VAFIN", "NE", "NE", "ADJD", "$("], "meter": "-+-+-+---+-+-+", "measure": "unknown.measure.hexa"}, "line.15": {"text": "das is a Tantiemensadiste, der zu den Backfischen spricht!", "tokens": ["das", "is", "a", "Tan\u00b7tie\u00b7men\u00b7sa\u00b7dis\u00b7te", ",", "der", "zu", "den", "Back\u00b7fi\u00b7schen", "spricht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "FM", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-++--+--+--+-+", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "Das is von ka Klassiehker \u2013 das is von kein Genie \u2013", "tokens": ["Das", "is", "von", "ka", "Klas\u00b7sieh\u00b7ker", "\u2013", "das", "is", "von", "kein", "Ge\u00b7nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "APPR", "NE", "NN", "$(", "ART", "FM", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Und 's klingt doch, halten zu Gnaden, so voller Poesie \u2013!", "tokens": ["Und", "'s", "klingt", "doch", ",", "hal\u00b7ten", "zu", "Gna\u00b7den", ",", "so", "vol\u00b7ler", "Poe\u00b7sie", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,", "VVFIN", "APPR", "NN", "$,", "ADV", "ADJA", "NN", "$(", "$."], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}}, "stanza.2": {"line.1": {"text": "Der Kriegsgewinnler, der auf sich h\u00e4lt,", "tokens": ["Der", "Kriegs\u00b7ge\u00b7winn\u00b7ler", ",", "der", "auf", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "macht hin in die dicken Premieren.", "tokens": ["macht", "hin", "in", "die", "di\u00b7cken", "Pre\u00b7mie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da sitzt die literarische Welt", "tokens": ["Da", "sitzt", "die", "li\u00b7te\u00b7ra\u00b7ri\u00b7sche", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Walter Hasenclever zu Ehren.", "tokens": ["Wal\u00b7ter", "Ha\u00b7sen\u00b7cle\u00b7ver", "zu", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Und k\u00fcrzer wird immer der S\u00e4tze Bau", "tokens": ["Und", "k\u00fcr\u00b7zer", "wird", "im\u00b7mer", "der", "S\u00e4t\u00b7ze", "Bau"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und dunkler, o Herr, der Sinn . . .", "tokens": ["und", "dunk\u00b7ler", ",", "o", "Herr", ",", "der", "Sinn", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADJA", "$,", "FM", "NN", "$,", "ART", "NN", "$.", "$.", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "\u00bbwat hat er jesacht?\u00ab Man wei\u00df nicht genau.", "tokens": ["\u00bb", "wat", "hat", "er", "je\u00b7sacht", "?", "\u00ab", "Man", "wei\u00df", "nicht", "ge\u00b7nau", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "ADV", "$.", "$(", "PIS", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Da steckt Metaphysike drin!", "tokens": ["Da", "steckt", "Me\u00b7ta\u00b7phy\u00b7si\u00b7ke", "drin", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.9": {"text": "Wenn dir nur der Artikel fehlt,", "tokens": ["Wenn", "dir", "nur", "der", "Ar\u00b7ti\u00b7kel", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "das andre machen schon", "tokens": ["das", "and\u00b7re", "ma\u00b7chen", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "die Wallungen,", "tokens": ["die", "Wal\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-++-", "measure": "unknown.measure.di"}, "line.12": {"text": "die Ballungen", "tokens": ["die", "Bal\u00b7lun\u00b7gen"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.13": {"text": "\u2013 o ungeratener \u203aSohn\u2039!", "tokens": ["\u2013", "o", "un\u00b7ge\u00b7ra\u00b7te\u00b7ner", "\u203a", "Sohn", "\u2039", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "FM", "ADJA", "ADJA", "NN", "$(", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.14": {"text": "Das hat kein Goethe g'schrieben, ka junger Schiller dicht \u2013", "tokens": ["Das", "hat", "kein", "Goe\u00b7the", "g'\u00b7schrie\u00b7ben", ",", "ka", "jun\u00b7ger", "Schil\u00b7ler", "dicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "VVINF", "$,", "NE", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+---+-+-+", "measure": "unknown.measure.hexa"}, "line.15": {"text": "das is a lyrischer Reporter, der zu den Logen spricht!", "tokens": ["das", "is", "a", "ly\u00b7ri\u00b7scher", "Re\u00b7por\u00b7ter", ",", "der", "zu", "den", "Lo\u00b7gen", "spricht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+---+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Das is von ka Klassiehker \u2013 das is von kein Genie \u2013", "tokens": ["Das", "is", "von", "ka", "Klas\u00b7sieh\u00b7ker", "\u2013", "das", "is", "von", "kein", "Ge\u00b7nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "APPR", "NE", "NN", "$(", "ART", "FM", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Und 's klingt doch, halten zu Gnaden, so voller Poesie \u2013!", "tokens": ["Und", "'s", "klingt", "doch", ",", "hal\u00b7ten", "zu", "Gna\u00b7den", ",", "so", "vol\u00b7ler", "Poe\u00b7sie", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,", "VVFIN", "APPR", "NN", "$,", "ADV", "ADJA", "NN", "$(", "$."], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}}, "stanza.3": {"line.1": {"text": "Und es schreiben Edschmid und Otto Ernst", "tokens": ["Und", "es", "schrei\u00b7ben", "E\u00b7dschmid", "und", "Ot\u00b7to", "Ernst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJA", "NN", "KON", "NE", "NE"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "(in jeder Beziehung Schmidt) \u2013", "tokens": ["(", "in", "je\u00b7der", "Be\u00b7zie\u00b7hung", "Schmidt", ")", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "NE", "$(", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Pa\u00df auf, mein Lieber, da\u00df du was lernst,", "tokens": ["Pa\u00df", "auf", ",", "mein", "Lie\u00b7ber", ",", "da\u00df", "du", "was", "lernst", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "und geh mit den Str\u00f6mungen mit!", "tokens": ["und", "geh", "mit", "den", "Str\u00f6\u00b7mun\u00b7gen", "mit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Auch du mu\u00dft dichten mehr als genug.", "tokens": ["Auch", "du", "mu\u00dft", "dich\u00b7ten", "mehr", "als", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "ADJA", "PIAT", "KOKOM", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u00dcb dich beizeiten, mein Sohn!", "tokens": ["\u00dcb", "dich", "bei\u00b7zei\u00b7ten", ",", "mein", "Sohn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.7": {"text": "Es kommt die Stunde, da schreibst du im Druck", "tokens": ["Es", "kommt", "die", "Stun\u00b7de", ",", "da", "schreibst", "du", "im", "Druck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "deine Steuerdeklaration.", "tokens": ["dei\u00b7ne", "Steu\u00b7er\u00b7de\u00b7kla\u00b7ra\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Verschieb, solang du schieben kannst,", "tokens": ["Ver\u00b7schieb", ",", "so\u00b7lang", "du", "schie\u00b7ben", "kannst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "gib nur ein Viertel an.", "tokens": ["gib", "nur", "ein", "Vier\u00b7tel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Dicht in Finanz", "tokens": ["Dicht", "in", "Fi\u00b7nanz"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.12": {"text": "wie M\u00fcllers Hans \u2013", "tokens": ["wie", "M\u00fcl\u00b7lers", "Hans", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "und l\u00e4chelnd summst du dann:", "tokens": ["und", "l\u00e4\u00b7chelnd", "summst", "du", "dann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "\u00bbdas hat kein Goethe g'schriebn \u2013 das hat ka Schiller dicht \u2013", "tokens": ["\u00bb", "das", "hat", "kein", "Goe\u00b7the", "g'\u00b7schriebn", "\u2013", "das", "hat", "ka", "Schil\u00b7ler", "dicht", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PIAT", "NE", "NE", "$(", "PDS", "VAFIN", "NE", "NE", "ADJD", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Das is a armer Preu\u00dfe, der zum Finanzamt spricht.", "tokens": ["Das", "is", "a", "ar\u00b7mer", "Preu\u00b7\u00dfe", ",", "der", "zum", "Fi\u00b7nanz\u00b7amt", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.16": {"text": "Das is von ka Klassiehker \u2013 das is von an Genie!", "tokens": ["Das", "is", "von", "ka", "Klas\u00b7sieh\u00b7ker", "\u2013", "das", "is", "von", "an", "Ge\u00b7nie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "APPR", "NE", "NN", "$(", "ART", "FM", "APPR", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Drum klingts auch \u2013 halten zu Gnaden \u2013 so voller Poesie \u2013!\u00ab", "tokens": ["Drum", "klingts", "auch", "\u2013", "hal\u00b7ten", "zu", "Gna\u00b7den", "\u2013", "so", "vol\u00b7ler", "Poe\u00b7sie", "\u2013", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PAV", "VVFIN", "ADV", "$(", "VVFIN", "APPR", "NN", "$(", "ADV", "ADJA", "NN", "$(", "$.", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Wenn Mutter abends zu Bette geht", "tokens": ["Wenn", "Mut\u00b7ter", "a\u00b7bends", "zu", "Bet\u00b7te", "geht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADV", "APPR", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und Papa in den (blonden) Verein,", "tokens": ["und", "Pa\u00b7pa", "in", "den", "(", "blon\u00b7den", ")", "Ver\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "$(", "ADJA", "$(", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "liest Lieschen noch bei der Kerze sp\u00e4t", "tokens": ["liest", "Lie\u00b7schen", "noch", "bei", "der", "Ker\u00b7ze", "sp\u00e4t"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "ADV", "APPR", "ART", "NN", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "von Ewers Schweinigelein.", "tokens": ["von", "E\u00b7wers", "Schwei\u00b7ni\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Der Autor ersetzt einem anst\u00e4ndigen Kind", "tokens": ["Der", "Au\u00b7tor", "er\u00b7setzt", "ei\u00b7nem", "an\u00b7st\u00e4n\u00b7di\u00b7gen", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "das erotische A-B-C.", "tokens": ["das", "e\u00b7ro\u00b7ti\u00b7sche", "A\u00b7\u00b7B", "C."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["ART", "ADJA", "TRUNC", "NE"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.7": {"text": "Ein Teufelsj\u00e4ger! Er kitzelt so lind \u2013", "tokens": ["Ein", "Teu\u00b7fels\u00b7j\u00e4\u00b7ger", "!", "Er", "kit\u00b7zelt", "so", "lind", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VVFIN", "ADV", "ADJD", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ein lebendiger Gaudemich\u00e9.", "tokens": ["ein", "le\u00b7ben\u00b7di\u00b7ger", "Gau\u00b7de\u00b7mich\u00e9", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "Er kam jetzt aus Amerika", "tokens": ["Er", "kam", "jetzt", "aus", "A\u00b7me\u00b7ri\u00b7ka"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "mit einem neuen Band \u2013", "tokens": ["mit", "ei\u00b7nem", "neu\u00b7en", "Band", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Was steht darin?", "tokens": ["Was", "steht", "da\u00b7rin", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Was weht darin?", "tokens": ["Was", "weht", "da\u00b7rin", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Die Weise ist bekannt . . .", "tokens": ["Die", "Wei\u00b7se", "ist", "be\u00b7kannt", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Das hat kein Goethe g'schrieben, das hat ka Schiller dicht \u2013", "tokens": ["Das", "hat", "kein", "Goe\u00b7the", "g'\u00b7schrie\u00b7ben", ",", "das", "hat", "ka", "Schil\u00b7ler", "dicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "VVINF", "$,", "PDS", "VAFIN", "NE", "NE", "ADJD", "$("], "meter": "-+-+-+---+-+-+", "measure": "unknown.measure.hexa"}, "line.15": {"text": "das is a Tantiemensadiste, der zu den Backfischen spricht!", "tokens": ["das", "is", "a", "Tan\u00b7tie\u00b7men\u00b7sa\u00b7dis\u00b7te", ",", "der", "zu", "den", "Back\u00b7fi\u00b7schen", "spricht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "FM", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-++--+--+--+-+", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "Das is von ka Klassiehker \u2013 das is von kein Genie \u2013", "tokens": ["Das", "is", "von", "ka", "Klas\u00b7sieh\u00b7ker", "\u2013", "das", "is", "von", "kein", "Ge\u00b7nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "APPR", "NE", "NN", "$(", "ART", "FM", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Und 's klingt doch, halten zu Gnaden, so voller Poesie \u2013!", "tokens": ["Und", "'s", "klingt", "doch", ",", "hal\u00b7ten", "zu", "Gna\u00b7den", ",", "so", "vol\u00b7ler", "Poe\u00b7sie", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,", "VVFIN", "APPR", "NN", "$,", "ADV", "ADJA", "NN", "$(", "$."], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}}, "stanza.5": {"line.1": {"text": "Der Kriegsgewinnler, der auf sich h\u00e4lt,", "tokens": ["Der", "Kriegs\u00b7ge\u00b7winn\u00b7ler", ",", "der", "auf", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "macht hin in die dicken Premieren.", "tokens": ["macht", "hin", "in", "die", "di\u00b7cken", "Pre\u00b7mie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da sitzt die literarische Welt", "tokens": ["Da", "sitzt", "die", "li\u00b7te\u00b7ra\u00b7ri\u00b7sche", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Walter Hasenclever zu Ehren.", "tokens": ["Wal\u00b7ter", "Ha\u00b7sen\u00b7cle\u00b7ver", "zu", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Und k\u00fcrzer wird immer der S\u00e4tze Bau", "tokens": ["Und", "k\u00fcr\u00b7zer", "wird", "im\u00b7mer", "der", "S\u00e4t\u00b7ze", "Bau"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und dunkler, o Herr, der Sinn . . .", "tokens": ["und", "dunk\u00b7ler", ",", "o", "Herr", ",", "der", "Sinn", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADJA", "$,", "FM", "NN", "$,", "ART", "NN", "$.", "$.", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "\u00bbwat hat er jesacht?\u00ab Man wei\u00df nicht genau.", "tokens": ["\u00bb", "wat", "hat", "er", "je\u00b7sacht", "?", "\u00ab", "Man", "wei\u00df", "nicht", "ge\u00b7nau", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "ADV", "$.", "$(", "PIS", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Da steckt Metaphysike drin!", "tokens": ["Da", "steckt", "Me\u00b7ta\u00b7phy\u00b7si\u00b7ke", "drin", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.9": {"text": "Wenn dir nur der Artikel fehlt,", "tokens": ["Wenn", "dir", "nur", "der", "Ar\u00b7ti\u00b7kel", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "das andre machen schon", "tokens": ["das", "and\u00b7re", "ma\u00b7chen", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "die Wallungen,", "tokens": ["die", "Wal\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-++-", "measure": "unknown.measure.di"}, "line.12": {"text": "die Ballungen", "tokens": ["die", "Bal\u00b7lun\u00b7gen"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.13": {"text": "\u2013 o ungeratener \u203aSohn\u2039!", "tokens": ["\u2013", "o", "un\u00b7ge\u00b7ra\u00b7te\u00b7ner", "\u203a", "Sohn", "\u2039", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "FM", "ADJA", "ADJA", "NN", "$(", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.14": {"text": "Das hat kein Goethe g'schrieben, ka junger Schiller dicht \u2013", "tokens": ["Das", "hat", "kein", "Goe\u00b7the", "g'\u00b7schrie\u00b7ben", ",", "ka", "jun\u00b7ger", "Schil\u00b7ler", "dicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "VVINF", "$,", "NE", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+---+-+-+", "measure": "unknown.measure.hexa"}, "line.15": {"text": "das is a lyrischer Reporter, der zu den Logen spricht!", "tokens": ["das", "is", "a", "ly\u00b7ri\u00b7scher", "Re\u00b7por\u00b7ter", ",", "der", "zu", "den", "Lo\u00b7gen", "spricht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+---+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Das is von ka Klassiehker \u2013 das is von kein Genie \u2013", "tokens": ["Das", "is", "von", "ka", "Klas\u00b7sieh\u00b7ker", "\u2013", "das", "is", "von", "kein", "Ge\u00b7nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "APPR", "NE", "NN", "$(", "ART", "FM", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Und 's klingt doch, halten zu Gnaden, so voller Poesie \u2013!", "tokens": ["Und", "'s", "klingt", "doch", ",", "hal\u00b7ten", "zu", "Gna\u00b7den", ",", "so", "vol\u00b7ler", "Poe\u00b7sie", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,", "VVFIN", "APPR", "NN", "$,", "ADV", "ADJA", "NN", "$(", "$."], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}}, "stanza.6": {"line.1": {"text": "Und es schreiben Edschmid und Otto Ernst", "tokens": ["Und", "es", "schrei\u00b7ben", "E\u00b7dschmid", "und", "Ot\u00b7to", "Ernst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJA", "NN", "KON", "NE", "NE"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "(in jeder Beziehung Schmidt) \u2013", "tokens": ["(", "in", "je\u00b7der", "Be\u00b7zie\u00b7hung", "Schmidt", ")", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "NE", "$(", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Pa\u00df auf, mein Lieber, da\u00df du was lernst,", "tokens": ["Pa\u00df", "auf", ",", "mein", "Lie\u00b7ber", ",", "da\u00df", "du", "was", "lernst", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "und geh mit den Str\u00f6mungen mit!", "tokens": ["und", "geh", "mit", "den", "Str\u00f6\u00b7mun\u00b7gen", "mit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Auch du mu\u00dft dichten mehr als genug.", "tokens": ["Auch", "du", "mu\u00dft", "dich\u00b7ten", "mehr", "als", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "ADJA", "PIAT", "KOKOM", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u00dcb dich beizeiten, mein Sohn!", "tokens": ["\u00dcb", "dich", "bei\u00b7zei\u00b7ten", ",", "mein", "Sohn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.7": {"text": "Es kommt die Stunde, da schreibst du im Druck", "tokens": ["Es", "kommt", "die", "Stun\u00b7de", ",", "da", "schreibst", "du", "im", "Druck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "deine Steuerdeklaration.", "tokens": ["dei\u00b7ne", "Steu\u00b7er\u00b7de\u00b7kla\u00b7ra\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Verschieb, solang du schieben kannst,", "tokens": ["Ver\u00b7schieb", ",", "so\u00b7lang", "du", "schie\u00b7ben", "kannst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "gib nur ein Viertel an.", "tokens": ["gib", "nur", "ein", "Vier\u00b7tel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Dicht in Finanz", "tokens": ["Dicht", "in", "Fi\u00b7nanz"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.12": {"text": "wie M\u00fcllers Hans \u2013", "tokens": ["wie", "M\u00fcl\u00b7lers", "Hans", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "und l\u00e4chelnd summst du dann:", "tokens": ["und", "l\u00e4\u00b7chelnd", "summst", "du", "dann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "\u00bbdas hat kein Goethe g'schriebn \u2013 das hat ka Schiller dicht \u2013", "tokens": ["\u00bb", "das", "hat", "kein", "Goe\u00b7the", "g'\u00b7schriebn", "\u2013", "das", "hat", "ka", "Schil\u00b7ler", "dicht", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PIAT", "NE", "NE", "$(", "PDS", "VAFIN", "NE", "NE", "ADJD", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Das is a armer Preu\u00dfe, der zum Finanzamt spricht.", "tokens": ["Das", "is", "a", "ar\u00b7mer", "Preu\u00b7\u00dfe", ",", "der", "zum", "Fi\u00b7nanz\u00b7amt", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.16": {"text": "Das is von ka Klassiehker \u2013 das is von an Genie!", "tokens": ["Das", "is", "von", "ka", "Klas\u00b7sieh\u00b7ker", "\u2013", "das", "is", "von", "an", "Ge\u00b7nie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "APPR", "NE", "NN", "$(", "ART", "FM", "APPR", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Drum klingts auch \u2013 halten zu Gnaden \u2013 so voller Poesie \u2013!\u00ab", "tokens": ["Drum", "klingts", "auch", "\u2013", "hal\u00b7ten", "zu", "Gna\u00b7den", "\u2013", "so", "vol\u00b7ler", "Poe\u00b7sie", "\u2013", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PAV", "VVFIN", "ADV", "$(", "VVFIN", "APPR", "NN", "$(", "ADV", "ADJA", "NN", "$(", "$.", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}}}}