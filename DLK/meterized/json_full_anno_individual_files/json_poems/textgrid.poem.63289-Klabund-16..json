{"textgrid.poem.63289": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "16.", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich springe aus einem fremden Bett", "tokens": ["Ich", "sprin\u00b7ge", "aus", "ei\u00b7nem", "frem\u00b7den", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Schweinebraten heute war ziemlich fett", "tokens": ["Der", "Schwei\u00b7ne\u00b7bra\u00b7ten", "heu\u00b7te", "war", "ziem\u00b7lich", "fett"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Es rumort im Darm", "tokens": ["Es", "ru\u00b7mort", "im", "Darm"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Ich muss gehn", "tokens": ["Ich", "muss", "gehn"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ich glaube ich hielt den Mond im Arm", "tokens": ["Ich", "glau\u00b7be", "ich", "hielt", "den", "Mond", "im", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Er zelebrierte eine Hyazinthe im Maul", "tokens": ["Er", "ze\u00b7leb\u00b7rier\u00b7te", "ei\u00b7ne", "Hy\u00b7a\u00b7zin\u00b7the", "im", "Maul"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "---+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Bleib doch noch, Paul \u2013", "tokens": ["Bleib", "doch", "noch", ",", "Paul", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ADV", "ADV", "$,", "NE", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Auf Wiedersehn.", "tokens": ["Auf", "Wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Was soll werden?", "tokens": ["Was", "soll", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "VAINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Weisst du das?", "tokens": ["Weisst", "du", "das", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Friede auf Erden", "tokens": ["Frie\u00b7de", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Gl\u00fcck und Glas", "tokens": ["Gl\u00fcck", "und", "Glas"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Die letzte Untergrundbahn hab ich vers\u00e4umt", "tokens": ["Die", "letz\u00b7te", "Un\u00b7ter\u00b7grund\u00b7bahn", "hab", "ich", "ver\u00b7s\u00e4umt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Eine Autohaltestelle ist auch nicht in der N\u00e4he", "tokens": ["Ei\u00b7ne", "Au\u00b7to\u00b7hal\u00b7te\u00b7stel\u00b7le", "ist", "auch", "nicht", "in", "der", "N\u00e4\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Auf der N\u00fcrnbergerstrasse wandeln zwei Rehe", "tokens": ["Auf", "der", "N\u00fcrn\u00b7ber\u00b7ger\u00b7stras\u00b7se", "wan\u00b7deln", "zwei", "Re\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "CARD", "NN"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Eine Droschke tr\u00e4umt", "tokens": ["Ei\u00b7ne", "Droschke", "tr\u00e4umt"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Von sich", "tokens": ["Von", "sich"], "token_info": ["word", "word"], "pos": ["APPR", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Sie fuhr \u00fcbern Strich", "tokens": ["Sie", "fuhr", "\u00fc\u00b7bern", "Strich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Dann untern Strich", "tokens": ["Dann", "un\u00b7tern", "Strich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Kobolz", "tokens": ["Ko\u00b7bolz"], "token_info": ["word"], "pos": ["NN"], "meter": "--", "measure": "unknown.measure.zero"}, "line.13": {"text": "Ins Feuilleton", "tokens": ["Ins", "Feu\u00b7il\u00b7le\u00b7ton"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Bon", "tokens": ["Bon"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.15": {"text": "Das Pferd ist aus Holz", "tokens": ["Das", "Pferd", "ist", "aus", "Holz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.16": {"text": "Der Mann aus Stein", "tokens": ["Der", "Mann", "aus", "Stein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Bald wird es morgen sein.", "tokens": ["Bald", "wird", "es", "mor\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Olga", "tokens": ["Ol\u00b7ga"], "token_info": ["word"], "pos": ["NE"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Und Wolga", "tokens": ["Und", "Wol\u00b7ga"], "token_info": ["word", "word"], "pos": ["KON", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Reimt sich", "tokens": ["Reimt", "sich"], "token_info": ["word", "word"], "pos": ["VVFIN", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Erster Kuss", "tokens": ["Ers\u00b7ter", "Kuss"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Letzter Kuss", "tokens": ["Letz\u00b7ter", "Kuss"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Ebenfalls.", "tokens": ["E\u00b7ben\u00b7falls", "."], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Man brach in der Loge zu den drei Weltkugeln einigen Flaschen den Hals", "tokens": ["Man", "brach", "in", "der", "Lo\u00b7ge", "zu", "den", "drei", "Welt\u00b7ku\u00b7geln", "ei\u00b7ni\u00b7gen", "Fla\u00b7schen", "den", "Hals"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "CARD", "NN", "PIAT", "NN", "ART", "NN"], "meter": "-+--+-+---+-+--+--+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Und einer Dame im Nerz", "tokens": ["Und", "ei\u00b7ner", "Da\u00b7me", "im", "Nerz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPRART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Das Gipsherz", "tokens": ["Das", "Gips\u00b7herz"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "--+", "measure": "anapaest.init"}, "line.10": {"text": "(gegen Blut empfand sie ein gewisses Odium)", "tokens": ["(", "ge\u00b7gen", "Blut", "emp\u00b7fand", "sie", "ein", "ge\u00b7wis\u00b7ses", "O\u00b7dium", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NE", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Ich rezitierte auf einem Podium", "tokens": ["Ich", "re\u00b7zi\u00b7tier\u00b7te", "auf", "ei\u00b7nem", "Po\u00b7di\u00b7um"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Auf dem eine Guillotine stand:", "tokens": ["Auf", "dem", "ei\u00b7ne", "Guil\u00b7lo\u00b7ti\u00b7ne", "stand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.13": {"text": "Was ist des Deutschen Vaterland?", "tokens": ["Was", "ist", "des", "Deut\u00b7schen", "Va\u00b7ter\u00b7land", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Aus einer benachbarten Kaschemme", "tokens": ["Aus", "ei\u00b7ner", "be\u00b7nach\u00b7bar\u00b7ten", "Ka\u00b7schem\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Holte der Meister vom Stuhl mir pers\u00f6nlich eine Bemme.", "tokens": ["Hol\u00b7te", "der", "Meis\u00b7ter", "vom", "Stuhl", "mir", "per\u00b7s\u00f6n\u00b7lich", "ei\u00b7ne", "Bem\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "+--+--+--+-+-+-", "measure": "elegiambus"}, "line.16": {"text": "Da sage einer noch, dass der B\u00fcrger seine Dichter hungern l\u00e4sst", "tokens": ["Da", "sa\u00b7ge", "ei\u00b7ner", "noch", ",", "dass", "der", "B\u00fcr\u00b7ger", "sei\u00b7ne", "Dich\u00b7ter", "hun\u00b7gern", "l\u00e4sst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADV", "$,", "KOUS", "ART", "NN", "PPOSAT", "NN", "VVFIN", "VVFIN"], "meter": "-+-+--+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.17": {"text": "Es war ein ph\u00e4nomenales Fest.", "tokens": ["Es", "war", "ein", "ph\u00e4\u00b7no\u00b7me\u00b7na\u00b7les", "Fest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Man hat mir am Wittenbergplatz", "tokens": ["Man", "hat", "mir", "am", "Wit\u00b7ten\u00b7berg\u00b7platz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Meinen Wintermantel gestohlen (Applaus)", "tokens": ["Mei\u00b7nen", "Win\u00b7ter\u00b7man\u00b7tel", "ge\u00b7stoh\u00b7len", "(", "Ap\u00b7plaus", ")"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$(", "NE", "$("], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Dazu einen Kinderlatz", "tokens": ["Da\u00b7zu", "ei\u00b7nen", "Kin\u00b7der\u00b7latz"], "token_info": ["word", "word", "word"], "pos": ["PAV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und meine Brille.", "tokens": ["Und", "mei\u00b7ne", "Bril\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Was immer geschieht: es geschieht Gottes Wille.", "tokens": ["Was", "im\u00b7mer", "ge\u00b7schieht", ":", "es", "ge\u00b7schieht", "Got\u00b7tes", "Wil\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "NN", "NN", "$."], "meter": "-+--+--++-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Durch meine Brille sieht die Welt wie ein frisch gebornes Ferkel so rosig aus.", "tokens": ["Durch", "mei\u00b7ne", "Bril\u00b7le", "sieht", "die", "Welt", "wie", "ein", "frisch", "ge\u00b7bor\u00b7nes", "Fer\u00b7kel", "so", "ro\u00b7sig", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "KOKOM", "ART", "ADJD", "ADJA", "NN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+-+--+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.6": {"line.1": {"text": "Der ersten Strassenbahn Gebimmel.", "tokens": ["Der", "ers\u00b7ten", "Stras\u00b7sen\u00b7bahn", "Ge\u00b7bim\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Himmel", "tokens": ["Der", "Him\u00b7mel"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Gl\u00e4nzt wie ein Rasierspiegel", "tokens": ["Gl\u00e4nzt", "wie", "ein", "Ra\u00b7sier\u00b7spie\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Herrgott hab ich Stoppeln am Kinn", "tokens": ["Herr\u00b7gott", "hab", "ich", "Stop\u00b7peln", "am", "Kinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "NN", "APPRART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Und wie widerlich ich im grossen ganzen bin", "tokens": ["Und", "wie", "wi\u00b7der\u00b7lich", "ich", "im", "gros\u00b7sen", "gan\u00b7zen", "bin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADJD", "PPER", "APPRART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Selbsterkenntnis ist der erste Schritt \u2013", "tokens": ["Selbs\u00b7ter\u00b7kennt\u00b7nis", "ist", "der", "ers\u00b7te", "Schritt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Na Kleener, kommste mit?", "tokens": ["Na", "Klee\u00b7ner", ",", "komms\u00b7te", "mit", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Die Sterne fallen wie Schnee", "tokens": ["Die", "Ster\u00b7ne", "fal\u00b7len", "wie", "Schnee"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "KOKOM", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Der Stern dort mein Herz zuckt r\u00f6tlich", "tokens": ["Der", "Stern", "dort", "mein", "Herz", "zuckt", "r\u00f6t\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Und jener: mein Nabel?", "tokens": ["Und", "je\u00b7ner", ":", "mein", "Na\u00b7bel", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PDS", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Fabel-", "tokens": ["Fa\u00b7bel"], "token_info": ["word"], "pos": ["TRUNC"], "meter": "+-", "measure": "trochaic.single"}, "line.12": {"text": "haft \u2013 oder ists die grosse Zeh?", "tokens": ["haft", "\u2013", "o\u00b7der", "ists", "die", "gros\u00b7se", "Zeh", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "KON", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ich langweile mich t\u00f6dlich", "tokens": ["Ich", "lang\u00b7wei\u00b7le", "mich", "t\u00f6d\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Getreu bis zum Grab", "tokens": ["Ge\u00b7treu", "bis", "zum", "Grab"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Schieb ab, kleine Dirne,", "tokens": ["Schieb", "ab", ",", "klei\u00b7ne", "Dir\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.16": {"text": "Es leuchten die Firne", "tokens": ["Es", "leuch\u00b7ten", "die", "Fir\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.17": {"text": "Schieb ab, schieb ab \u2013", "tokens": ["Schieb", "ab", ",", "schieb", "ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.18": {"text": "Die Kinder wie Ratten in den feuchten Kellern krepieren", "tokens": ["Die", "Kin\u00b7der", "wie", "Rat\u00b7ten", "in", "den", "feuch\u00b7ten", "Kel\u00b7lern", "kre\u00b7pie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOKOM", "NN", "APPR", "ART", "ADJA", "NN", "VVINF"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Die M\u00fctter in ihren d\u00fcnnen Hemden frieren", "tokens": ["Die", "M\u00fct\u00b7ter", "in", "ih\u00b7ren", "d\u00fcn\u00b7nen", "Hem\u00b7den", "frie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Keine Kohle", "tokens": ["Kei\u00b7ne", "Koh\u00b7le"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.21": {"text": "Kein Brot", "tokens": ["Kein", "Brot"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.22": {"text": "Keine Sohle", "tokens": ["Kei\u00b7ne", "Soh\u00b7le"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.23": {"text": "Kein Tod", "tokens": ["Kein", "Tod"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "Ein halbes Leben", "tokens": ["Ein", "hal\u00b7bes", "Le\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Ein halbes Sterben", "tokens": ["Ein", "hal\u00b7bes", "Ster\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Gott im Himmel ich kann nicht vergeben \u2013", "tokens": ["Gott", "im", "Him\u00b7mel", "ich", "kann", "nicht", "ver\u00b7ge\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PPER", "VMFIN", "PTKNEG", "VVPP", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Rachitische Braut", "tokens": ["Ra\u00b7chi\u00b7ti\u00b7sche", "Braut"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Aus deiner ledernen Haut", "tokens": ["Aus", "dei\u00b7ner", "le\u00b7der\u00b7nen", "Haut"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wollen wir dir deine Hochzeitsschuhe gerben", "tokens": ["Wol\u00b7len", "wir", "dir", "dei\u00b7ne", "Hoch\u00b7zeits\u00b7schu\u00b7he", "ger\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Denn deine letzten Pantinen", "tokens": ["Denn", "dei\u00b7ne", "letz\u00b7ten", "Pan\u00b7ti\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+----", "measure": "unknown.measure.di"}, "line.8": {"text": "Hat dir mit heitersten Mienen", "tokens": ["Hat", "dir", "mit", "hei\u00b7ters\u00b7ten", "Mie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Dein zweiter Kerl geklaut.", "tokens": ["Dein", "zwei\u00b7ter", "Kerl", "ge\u00b7klaut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Es ist scheusslich kalt", "tokens": ["Es", "ist", "scheuss\u00b7lich", "kalt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD"], "meter": "--+-+", "measure": "anapaest.init"}, "line.2": {"text": "In der Passage ist eine alte Frau erfroren", "tokens": ["In", "der", "Pas\u00b7sa\u00b7ge", "ist", "ei\u00b7ne", "al\u00b7te", "Frau", "er\u00b7fro\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Sie hat auf die Steinfliesen ein blindes Kind geboren", "tokens": ["Sie", "hat", "auf", "die", "Stein\u00b7flie\u00b7sen", "ein", "blin\u00b7des", "Kind", "ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVPP"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Sitte nahm es mit: Kleines Biest", "tokens": ["Die", "Sit\u00b7te", "nahm", "es", "mit", ":", "Klei\u00b7nes", "Biest"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sei froh dass du die Friedrichstrasse nicht siehst", "tokens": ["Sei", "froh", "dass", "du", "die", "Fried\u00b7rich\u00b7stras\u00b7se", "nicht", "siehst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Wie ein Vogel hat sich das Kind an den Schutzmann gekrallt", "tokens": ["Wie", "ein", "Vo\u00b7gel", "hat", "sich", "das", "Kind", "an", "den", "Schutz\u00b7mann", "ge\u00b7krallt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "VAFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVPP"], "meter": "--+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Aber der liebe Gott geht in einem angew\u00e4rmten Schafpelz durch den Wald.", "tokens": ["A\u00b7ber", "der", "lie\u00b7be", "Gott", "geht", "in", "ei\u00b7nem", "an\u00b7ge\u00b7w\u00e4rm\u00b7ten", "Schaf\u00b7pelz", "durch", "den", "Wald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+--+-+-+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Er ist der liebe gute alte Mann", "tokens": ["Er", "ist", "der", "lie\u00b7be", "gu\u00b7te", "al\u00b7te", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Dem man nicht b\u00f6se werden kann", "tokens": ["Dem", "man", "nicht", "b\u00f6\u00b7se", "wer\u00b7den", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "PTKNEG", "ADJD", "VAINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Er kommt wie der lahme", "tokens": ["Er", "kommt", "wie", "der", "lah\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Revierf\u00f6rster angesackt", "tokens": ["Re\u00b7vier\u00b7f\u00f6rs\u00b7ter", "an\u00b7ge\u00b7sackt"], "token_info": ["word", "word"], "pos": ["NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Achtung: Grossaufnahme", "tokens": ["Ach\u00b7tung", ":", "Gros\u00b7sauf\u00b7nah\u00b7me"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$.", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Letzter Akt", "tokens": ["Letz\u00b7ter", "Akt"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.14": {"text": "Monumentalfilm: Die Sch\u00f6pfung (Die Schr\u00f6pfung)", "tokens": ["Mo\u00b7nu\u00b7men\u00b7tal\u00b7film", ":", "Die", "Sch\u00f6p\u00b7fung", "(", "Die", "Schr\u00f6p\u00b7fung", ")"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Titel: Gelobt sei dein Namen", "tokens": ["Ti\u00b7tel", ":", "Ge\u00b7lobt", "sei", "dein", "Na\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "VVPP", "VAFIN", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.16": {"text": "In Ewigkeit Amen.", "tokens": ["In", "E\u00b7wig\u00b7keit", "A\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.9": {"line.1": {"text": "Ich springe aus einem fremden Bett", "tokens": ["Ich", "sprin\u00b7ge", "aus", "ei\u00b7nem", "frem\u00b7den", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Schweinebraten heute war ziemlich fett", "tokens": ["Der", "Schwei\u00b7ne\u00b7bra\u00b7ten", "heu\u00b7te", "war", "ziem\u00b7lich", "fett"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Es rumort im Darm", "tokens": ["Es", "ru\u00b7mort", "im", "Darm"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Ich muss gehn", "tokens": ["Ich", "muss", "gehn"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ich glaube ich hielt den Mond im Arm", "tokens": ["Ich", "glau\u00b7be", "ich", "hielt", "den", "Mond", "im", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Er zelebrierte eine Hyazinthe im Maul", "tokens": ["Er", "ze\u00b7leb\u00b7rier\u00b7te", "ei\u00b7ne", "Hy\u00b7a\u00b7zin\u00b7the", "im", "Maul"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "---+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Bleib doch noch, Paul \u2013", "tokens": ["Bleib", "doch", "noch", ",", "Paul", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ADV", "ADV", "$,", "NE", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Auf Wiedersehn.", "tokens": ["Auf", "Wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Was soll werden?", "tokens": ["Was", "soll", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "VAINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Weisst du das?", "tokens": ["Weisst", "du", "das", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Friede auf Erden", "tokens": ["Frie\u00b7de", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Gl\u00fcck und Glas", "tokens": ["Gl\u00fcck", "und", "Glas"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Die letzte Untergrundbahn hab ich vers\u00e4umt", "tokens": ["Die", "letz\u00b7te", "Un\u00b7ter\u00b7grund\u00b7bahn", "hab", "ich", "ver\u00b7s\u00e4umt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Eine Autohaltestelle ist auch nicht in der N\u00e4he", "tokens": ["Ei\u00b7ne", "Au\u00b7to\u00b7hal\u00b7te\u00b7stel\u00b7le", "ist", "auch", "nicht", "in", "der", "N\u00e4\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Auf der N\u00fcrnbergerstrasse wandeln zwei Rehe", "tokens": ["Auf", "der", "N\u00fcrn\u00b7ber\u00b7ger\u00b7stras\u00b7se", "wan\u00b7deln", "zwei", "Re\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "CARD", "NN"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Eine Droschke tr\u00e4umt", "tokens": ["Ei\u00b7ne", "Droschke", "tr\u00e4umt"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Von sich", "tokens": ["Von", "sich"], "token_info": ["word", "word"], "pos": ["APPR", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Sie fuhr \u00fcbern Strich", "tokens": ["Sie", "fuhr", "\u00fc\u00b7bern", "Strich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Dann untern Strich", "tokens": ["Dann", "un\u00b7tern", "Strich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Kobolz", "tokens": ["Ko\u00b7bolz"], "token_info": ["word"], "pos": ["NN"], "meter": "--", "measure": "unknown.measure.zero"}, "line.13": {"text": "Ins Feuilleton", "tokens": ["Ins", "Feu\u00b7il\u00b7le\u00b7ton"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Bon", "tokens": ["Bon"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.15": {"text": "Das Pferd ist aus Holz", "tokens": ["Das", "Pferd", "ist", "aus", "Holz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.16": {"text": "Der Mann aus Stein", "tokens": ["Der", "Mann", "aus", "Stein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Bald wird es morgen sein.", "tokens": ["Bald", "wird", "es", "mor\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Olga", "tokens": ["Ol\u00b7ga"], "token_info": ["word"], "pos": ["NE"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Und Wolga", "tokens": ["Und", "Wol\u00b7ga"], "token_info": ["word", "word"], "pos": ["KON", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Reimt sich", "tokens": ["Reimt", "sich"], "token_info": ["word", "word"], "pos": ["VVFIN", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Erster Kuss", "tokens": ["Ers\u00b7ter", "Kuss"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Letzter Kuss", "tokens": ["Letz\u00b7ter", "Kuss"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Ebenfalls.", "tokens": ["E\u00b7ben\u00b7falls", "."], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Man brach in der Loge zu den drei Weltkugeln einigen Flaschen den Hals", "tokens": ["Man", "brach", "in", "der", "Lo\u00b7ge", "zu", "den", "drei", "Welt\u00b7ku\u00b7geln", "ei\u00b7ni\u00b7gen", "Fla\u00b7schen", "den", "Hals"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "CARD", "NN", "PIAT", "NN", "ART", "NN"], "meter": "-+--+-+---+-+--+--+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Und einer Dame im Nerz", "tokens": ["Und", "ei\u00b7ner", "Da\u00b7me", "im", "Nerz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPRART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Das Gipsherz", "tokens": ["Das", "Gips\u00b7herz"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "--+", "measure": "anapaest.init"}, "line.10": {"text": "(gegen Blut empfand sie ein gewisses Odium)", "tokens": ["(", "ge\u00b7gen", "Blut", "emp\u00b7fand", "sie", "ein", "ge\u00b7wis\u00b7ses", "O\u00b7dium", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NE", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Ich rezitierte auf einem Podium", "tokens": ["Ich", "re\u00b7zi\u00b7tier\u00b7te", "auf", "ei\u00b7nem", "Po\u00b7di\u00b7um"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Auf dem eine Guillotine stand:", "tokens": ["Auf", "dem", "ei\u00b7ne", "Guil\u00b7lo\u00b7ti\u00b7ne", "stand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.13": {"text": "Was ist des Deutschen Vaterland?", "tokens": ["Was", "ist", "des", "Deut\u00b7schen", "Va\u00b7ter\u00b7land", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Aus einer benachbarten Kaschemme", "tokens": ["Aus", "ei\u00b7ner", "be\u00b7nach\u00b7bar\u00b7ten", "Ka\u00b7schem\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Holte der Meister vom Stuhl mir pers\u00f6nlich eine Bemme.", "tokens": ["Hol\u00b7te", "der", "Meis\u00b7ter", "vom", "Stuhl", "mir", "per\u00b7s\u00f6n\u00b7lich", "ei\u00b7ne", "Bem\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "+--+--+--+-+-+-", "measure": "elegiambus"}, "line.16": {"text": "Da sage einer noch, dass der B\u00fcrger seine Dichter hungern l\u00e4sst", "tokens": ["Da", "sa\u00b7ge", "ei\u00b7ner", "noch", ",", "dass", "der", "B\u00fcr\u00b7ger", "sei\u00b7ne", "Dich\u00b7ter", "hun\u00b7gern", "l\u00e4sst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADV", "$,", "KOUS", "ART", "NN", "PPOSAT", "NN", "VVFIN", "VVFIN"], "meter": "-+-+--+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.17": {"text": "Es war ein ph\u00e4nomenales Fest.", "tokens": ["Es", "war", "ein", "ph\u00e4\u00b7no\u00b7me\u00b7na\u00b7les", "Fest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Man hat mir am Wittenbergplatz", "tokens": ["Man", "hat", "mir", "am", "Wit\u00b7ten\u00b7berg\u00b7platz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Meinen Wintermantel gestohlen (Applaus)", "tokens": ["Mei\u00b7nen", "Win\u00b7ter\u00b7man\u00b7tel", "ge\u00b7stoh\u00b7len", "(", "Ap\u00b7plaus", ")"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$(", "NE", "$("], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Dazu einen Kinderlatz", "tokens": ["Da\u00b7zu", "ei\u00b7nen", "Kin\u00b7der\u00b7latz"], "token_info": ["word", "word", "word"], "pos": ["PAV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und meine Brille.", "tokens": ["Und", "mei\u00b7ne", "Bril\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Was immer geschieht: es geschieht Gottes Wille.", "tokens": ["Was", "im\u00b7mer", "ge\u00b7schieht", ":", "es", "ge\u00b7schieht", "Got\u00b7tes", "Wil\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "NN", "NN", "$."], "meter": "-+--+--++-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Durch meine Brille sieht die Welt wie ein frisch gebornes Ferkel so rosig aus.", "tokens": ["Durch", "mei\u00b7ne", "Bril\u00b7le", "sieht", "die", "Welt", "wie", "ein", "frisch", "ge\u00b7bor\u00b7nes", "Fer\u00b7kel", "so", "ro\u00b7sig", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "KOKOM", "ART", "ADJD", "ADJA", "NN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+-+--+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.14": {"line.1": {"text": "Der ersten Strassenbahn Gebimmel.", "tokens": ["Der", "ers\u00b7ten", "Stras\u00b7sen\u00b7bahn", "Ge\u00b7bim\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Himmel", "tokens": ["Der", "Him\u00b7mel"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Gl\u00e4nzt wie ein Rasierspiegel", "tokens": ["Gl\u00e4nzt", "wie", "ein", "Ra\u00b7sier\u00b7spie\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Herrgott hab ich Stoppeln am Kinn", "tokens": ["Herr\u00b7gott", "hab", "ich", "Stop\u00b7peln", "am", "Kinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "NN", "APPRART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Und wie widerlich ich im grossen ganzen bin", "tokens": ["Und", "wie", "wi\u00b7der\u00b7lich", "ich", "im", "gros\u00b7sen", "gan\u00b7zen", "bin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADJD", "PPER", "APPRART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Selbsterkenntnis ist der erste Schritt \u2013", "tokens": ["Selbs\u00b7ter\u00b7kennt\u00b7nis", "ist", "der", "ers\u00b7te", "Schritt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Na Kleener, kommste mit?", "tokens": ["Na", "Klee\u00b7ner", ",", "komms\u00b7te", "mit", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Die Sterne fallen wie Schnee", "tokens": ["Die", "Ster\u00b7ne", "fal\u00b7len", "wie", "Schnee"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "KOKOM", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Der Stern dort mein Herz zuckt r\u00f6tlich", "tokens": ["Der", "Stern", "dort", "mein", "Herz", "zuckt", "r\u00f6t\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Und jener: mein Nabel?", "tokens": ["Und", "je\u00b7ner", ":", "mein", "Na\u00b7bel", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PDS", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Fabel-", "tokens": ["Fa\u00b7bel"], "token_info": ["word"], "pos": ["TRUNC"], "meter": "+-", "measure": "trochaic.single"}, "line.12": {"text": "haft \u2013 oder ists die grosse Zeh?", "tokens": ["haft", "\u2013", "o\u00b7der", "ists", "die", "gros\u00b7se", "Zeh", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "KON", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ich langweile mich t\u00f6dlich", "tokens": ["Ich", "lang\u00b7wei\u00b7le", "mich", "t\u00f6d\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Getreu bis zum Grab", "tokens": ["Ge\u00b7treu", "bis", "zum", "Grab"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Schieb ab, kleine Dirne,", "tokens": ["Schieb", "ab", ",", "klei\u00b7ne", "Dir\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.16": {"text": "Es leuchten die Firne", "tokens": ["Es", "leuch\u00b7ten", "die", "Fir\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.17": {"text": "Schieb ab, schieb ab \u2013", "tokens": ["Schieb", "ab", ",", "schieb", "ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.18": {"text": "Die Kinder wie Ratten in den feuchten Kellern krepieren", "tokens": ["Die", "Kin\u00b7der", "wie", "Rat\u00b7ten", "in", "den", "feuch\u00b7ten", "Kel\u00b7lern", "kre\u00b7pie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOKOM", "NN", "APPR", "ART", "ADJA", "NN", "VVINF"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Die M\u00fctter in ihren d\u00fcnnen Hemden frieren", "tokens": ["Die", "M\u00fct\u00b7ter", "in", "ih\u00b7ren", "d\u00fcn\u00b7nen", "Hem\u00b7den", "frie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Keine Kohle", "tokens": ["Kei\u00b7ne", "Koh\u00b7le"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.21": {"text": "Kein Brot", "tokens": ["Kein", "Brot"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.22": {"text": "Keine Sohle", "tokens": ["Kei\u00b7ne", "Soh\u00b7le"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.23": {"text": "Kein Tod", "tokens": ["Kein", "Tod"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.15": {"line.1": {"text": "Ein halbes Leben", "tokens": ["Ein", "hal\u00b7bes", "Le\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Ein halbes Sterben", "tokens": ["Ein", "hal\u00b7bes", "Ster\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Gott im Himmel ich kann nicht vergeben \u2013", "tokens": ["Gott", "im", "Him\u00b7mel", "ich", "kann", "nicht", "ver\u00b7ge\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PPER", "VMFIN", "PTKNEG", "VVPP", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Rachitische Braut", "tokens": ["Ra\u00b7chi\u00b7ti\u00b7sche", "Braut"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Aus deiner ledernen Haut", "tokens": ["Aus", "dei\u00b7ner", "le\u00b7der\u00b7nen", "Haut"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wollen wir dir deine Hochzeitsschuhe gerben", "tokens": ["Wol\u00b7len", "wir", "dir", "dei\u00b7ne", "Hoch\u00b7zeits\u00b7schu\u00b7he", "ger\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Denn deine letzten Pantinen", "tokens": ["Denn", "dei\u00b7ne", "letz\u00b7ten", "Pan\u00b7ti\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+----", "measure": "unknown.measure.di"}, "line.8": {"text": "Hat dir mit heitersten Mienen", "tokens": ["Hat", "dir", "mit", "hei\u00b7ters\u00b7ten", "Mie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Dein zweiter Kerl geklaut.", "tokens": ["Dein", "zwei\u00b7ter", "Kerl", "ge\u00b7klaut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Es ist scheusslich kalt", "tokens": ["Es", "ist", "scheuss\u00b7lich", "kalt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD"], "meter": "--+-+", "measure": "anapaest.init"}, "line.2": {"text": "In der Passage ist eine alte Frau erfroren", "tokens": ["In", "der", "Pas\u00b7sa\u00b7ge", "ist", "ei\u00b7ne", "al\u00b7te", "Frau", "er\u00b7fro\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Sie hat auf die Steinfliesen ein blindes Kind geboren", "tokens": ["Sie", "hat", "auf", "die", "Stein\u00b7flie\u00b7sen", "ein", "blin\u00b7des", "Kind", "ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVPP"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Sitte nahm es mit: Kleines Biest", "tokens": ["Die", "Sit\u00b7te", "nahm", "es", "mit", ":", "Klei\u00b7nes", "Biest"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sei froh dass du die Friedrichstrasse nicht siehst", "tokens": ["Sei", "froh", "dass", "du", "die", "Fried\u00b7rich\u00b7stras\u00b7se", "nicht", "siehst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Wie ein Vogel hat sich das Kind an den Schutzmann gekrallt", "tokens": ["Wie", "ein", "Vo\u00b7gel", "hat", "sich", "das", "Kind", "an", "den", "Schutz\u00b7mann", "ge\u00b7krallt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "VAFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVPP"], "meter": "--+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Aber der liebe Gott geht in einem angew\u00e4rmten Schafpelz durch den Wald.", "tokens": ["A\u00b7ber", "der", "lie\u00b7be", "Gott", "geht", "in", "ei\u00b7nem", "an\u00b7ge\u00b7w\u00e4rm\u00b7ten", "Schaf\u00b7pelz", "durch", "den", "Wald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+--+-+-+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Er ist der liebe gute alte Mann", "tokens": ["Er", "ist", "der", "lie\u00b7be", "gu\u00b7te", "al\u00b7te", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Dem man nicht b\u00f6se werden kann", "tokens": ["Dem", "man", "nicht", "b\u00f6\u00b7se", "wer\u00b7den", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "PTKNEG", "ADJD", "VAINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Er kommt wie der lahme", "tokens": ["Er", "kommt", "wie", "der", "lah\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Revierf\u00f6rster angesackt", "tokens": ["Re\u00b7vier\u00b7f\u00f6rs\u00b7ter", "an\u00b7ge\u00b7sackt"], "token_info": ["word", "word"], "pos": ["NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Achtung: Grossaufnahme", "tokens": ["Ach\u00b7tung", ":", "Gros\u00b7sauf\u00b7nah\u00b7me"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$.", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Letzter Akt", "tokens": ["Letz\u00b7ter", "Akt"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.14": {"text": "Monumentalfilm: Die Sch\u00f6pfung (Die Schr\u00f6pfung)", "tokens": ["Mo\u00b7nu\u00b7men\u00b7tal\u00b7film", ":", "Die", "Sch\u00f6p\u00b7fung", "(", "Die", "Schr\u00f6p\u00b7fung", ")"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Titel: Gelobt sei dein Namen", "tokens": ["Ti\u00b7tel", ":", "Ge\u00b7lobt", "sei", "dein", "Na\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "VVPP", "VAFIN", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.16": {"text": "In Ewigkeit Amen.", "tokens": ["In", "E\u00b7wig\u00b7keit", "A\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}