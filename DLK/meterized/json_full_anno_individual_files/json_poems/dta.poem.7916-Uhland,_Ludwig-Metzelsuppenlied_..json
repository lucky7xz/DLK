{"dta.poem.7916": {"metadata": {"author": {"name": "Uhland, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Metzelsuppenlied .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1815", "urn": "urn:nbn:de:kobv:b4-200905196438", "language": ["de:0.99"], "booktitle": "Uhland, Ludwig: Gedichte. Stuttgart u. a., 1815."}, "poem": {"stanza.1": {"line.1": {"text": "Wir haben heut nach altem Brauch", "tokens": ["Wir", "ha\u00b7ben", "heut", "nach", "al\u00b7tem", "Brauch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Schweinchen abgeschlachtet;", "tokens": ["Ein", "Schwein\u00b7chen", "ab\u00b7ge\u00b7schlach\u00b7tet", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der ist ein j\u00fcdisch eckler Gauch,", "tokens": ["Der", "ist", "ein", "j\u00fc\u00b7disch", "eck\u00b7ler", "Gauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer solch ein Fleisch verachtet.", "tokens": ["Wer", "solch", "ein", "Fleisch", "ver\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es lebe zahm und wildes Schwein!", "tokens": ["Es", "le\u00b7be", "zahm", "und", "wil\u00b7des", "Schwein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie leben alle, gro\u00df und klein,", "tokens": ["Sie", "le\u00b7ben", "al\u00b7le", ",", "gro\u00df", "und", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die blonden und die braunen!", "tokens": ["Die", "blon\u00b7den", "und", "die", "brau\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "So s\u00e4umet denn, ihr Freunde, nicht,", "tokens": ["So", "s\u00e4u\u00b7met", "denn", ",", "ihr", "Freun\u00b7de", ",", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PPOSAT", "NN", "$,", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die W\u00fcrste zu verspeisen,", "tokens": ["Die", "W\u00fcrs\u00b7te", "zu", "ver\u00b7spei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und la\u00dft zum w\u00fcrzigen Gericht", "tokens": ["Und", "la\u00dft", "zum", "w\u00fcr\u00b7zi\u00b7gen", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Becher flei\u00dfig kreisen!", "tokens": ["Die", "Be\u00b7cher", "flei\u00b7\u00dfig", "krei\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es reimt sich trefflich: ", "tokens": ["Es", "reimt", "sich", "treff\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und pa\u00dft sich k\u00f6stlich: ", "tokens": ["Und", "pa\u00dft", "sich", "k\u00f6st\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Bei ", "tokens": ["Bei"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.3": {"line.1": {"text": "Auch unser edles Sauerkraut,", "tokens": ["Auch", "un\u00b7ser", "ed\u00b7les", "Sau\u00b7er\u00b7kraut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sollen\u2019s nicht vergessen;", "tokens": ["Wir", "sol\u00b7len's", "nicht", "ver\u00b7ges\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Deutscher hat\u2019s zuerst gebaut,", "tokens": ["Ein", "Deut\u00b7scher", "hat's", "zu\u00b7erst", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Drum ist\u2019s ein deutsches Essen.", "tokens": ["Drum", "ist's", "ein", "deut\u00b7sches", "Es\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn solch ein Fleischchen, wei\u00df und mild,", "tokens": ["Wenn", "solch", "ein", "Flei\u00b7schchen", ",", "wei\u00df", "und", "mild", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "NN", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im Kraute liegt, das ist ein Bild", "tokens": ["Im", "Krau\u00b7te", "liegt", ",", "das", "ist", "ein", "Bild"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PDS", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie Venus in den Rosen.", "tokens": ["Wie", "Ve\u00b7nus", "in", "den", "Ro\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und wird von sch\u00f6nen H\u00e4nden dann", "tokens": ["Und", "wird", "von", "sch\u00f6\u00b7nen", "H\u00e4n\u00b7den", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sch\u00f6ne Fleisch zerleget,", "tokens": ["Das", "sch\u00f6\u00b7ne", "Fleisch", "zer\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das ist, was einem deutschen Mann", "tokens": ["Das", "ist", ",", "was", "ei\u00b7nem", "deut\u00b7schen", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar s\u00fc\u00df das Herz beweget.", "tokens": ["Gar", "s\u00fc\u00df", "das", "Herz", "be\u00b7we\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gott Amor naht und l\u00e4chelt still,", "tokens": ["Gott", "A\u00b7mor", "naht", "und", "l\u00e4\u00b7chelt", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und denkt: nur da\u00df, wer k\u00fcssen will,", "tokens": ["Und", "denkt", ":", "nur", "da\u00df", ",", "wer", "k\u00fcs\u00b7sen", "will", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ADV", "KOUS", "$,", "PWS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zuvor den Mund sich wische!", "tokens": ["Zu\u00b7vor", "den", "Mund", "sich", "wi\u00b7sche", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ihr Freunde, tadle Keiner mich,", "tokens": ["Ihr", "Freun\u00b7de", ",", "tad\u00b7le", "Kei\u00b7ner", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PIS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich von Schweinen singe!", "tokens": ["Da\u00df", "ich", "von", "Schwei\u00b7nen", "sin\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es kn\u00fcpfen Kraftgedanken sich", "tokens": ["Es", "kn\u00fcp\u00b7fen", "Kraft\u00b7ge\u00b7dan\u00b7ken", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Oft an geringe Dinge.", "tokens": ["Oft", "an", "ge\u00b7rin\u00b7ge", "Din\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ihr kennet jenes alte Wort,", "tokens": ["Ihr", "ken\u00b7net", "je\u00b7nes", "al\u00b7te", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr wi\u00dft: es findet hier und dort", "tokens": ["Ihr", "wi\u00dft", ":", "es", "fin\u00b7det", "hier", "und", "dort"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Schwein auch eine Perle.", "tokens": ["Ein", "Schwein", "auch", "ei\u00b7ne", "Per\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}