{"textgrid.poem.53048": {"metadata": {"author": {"name": "Lohenstein, Daniel Casper von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Flammen steigen stets dem ersten Quelle zu;", "genre": "verse", "period": "N.A.", "pub_year": 1659, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Flammen steigen stets dem ersten Quelle zu;", "tokens": ["Die", "Flam\u00b7men", "stei\u00b7gen", "stets", "dem", "ers\u00b7ten", "Quel\u00b7le", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Wolken regnen hin, wo sie zuerst entspringen;", "tokens": ["Die", "Wol\u00b7ken", "reg\u00b7nen", "hin", ",", "wo", "sie", "zu\u00b7erst", "ent\u00b7sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "PWAV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es suchet der Magnet beim Angelsterne Ruh';", "tokens": ["Es", "su\u00b7chet", "der", "Mag\u00b7net", "beim", "An\u00b7gels\u00b7ter\u00b7ne", "Ruh'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "NN", "$."], "meter": "-+--+--++--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Man sieht des Meeres Salz zu seinen Brunnen dringen;", "tokens": ["Man", "sieht", "des", "Mee\u00b7res", "Salz", "zu", "sei\u00b7nen", "Brun\u00b7nen", "drin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jedweden Morgen kehrt dahin der Sonne Rad,", "tokens": ["Jed\u00b7we\u00b7den", "Mor\u00b7gen", "kehrt", "da\u00b7hin", "der", "Son\u00b7ne", "Rad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PAV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo Memnon's Mutter sie vorher geboren hat;", "tokens": ["Wo", "Mem\u00b7non's", "Mut\u00b7ter", "sie", "vor\u00b7her", "ge\u00b7bo\u00b7ren", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So, weil der morsche Mensch zur Mutter hat die Erden,", "tokens": ["So", ",", "weil", "der", "mor\u00b7sche", "Mensch", "zur", "Mut\u00b7ter", "hat", "die", "Er\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mu\u00df, was die Wiege war, ihm auch sein Leichstein werden.", "tokens": ["Mu\u00df", ",", "was", "die", "Wie\u00b7ge", "war", ",", "ihm", "auch", "sein", "Leichs\u00b7tein", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PRELS", "ART", "NN", "VAFIN", "$,", "PPER", "ADV", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie aber? schleu\u00dft dies Grab sein ganzes Wesen ein?", "tokens": ["Wie", "a\u00b7ber", "?", "schleu\u00dft", "dies", "Grab", "sein", "gan\u00b7zes", "We\u00b7sen", "ein", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$.", "VVFIN", "PDS", "NN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll in des Lebens Kreis', im Zirkel unsrer Jahre", "tokens": ["Soll", "in", "des", "Le\u00b7bens", "Kreis'", ",", "im", "Zir\u00b7kel", "uns\u00b7rer", "Jah\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "NN", "$,", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Nichts der Mittelpunkt, das Ende Sterben sein?", "tokens": ["Ein", "Nichts", "der", "Mit\u00b7tel\u00b7punkt", ",", "das", "En\u00b7de", "Ster\u00b7ben", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "$,", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sucht doch die Fledermaus im Lichte Tod und Bahre,", "tokens": ["Sucht", "doch", "die", "Fle\u00b7der\u00b7maus", "im", "Lich\u00b7te", "Tod", "und", "Bah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ob sie des Tages Glanz gleich nicht vertragen kann!", "tokens": ["Ob", "sie", "des", "Ta\u00b7ges", "Glanz", "gleich", "nicht", "ver\u00b7tra\u00b7gen", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Gluth nimmt hellern Glanz bei dem Verl\u00f6schen an.", "tokens": ["Die", "Gluth", "nimmt", "hel\u00b7lern", "Glanz", "bei", "dem", "Ver\u00b7l\u00f6\u00b7schen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nein! auch der weise Mensch pflegt, mu\u00df er schon erblassen,", "tokens": ["Nein", "!", "auch", "der", "wei\u00b7se", "Mensch", "pflegt", ",", "mu\u00df", "er", "schon", "er\u00b7blas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Zweck der Ewigkeit auch sterbend zu umfassen.", "tokens": ["Den", "Zweck", "der", "E\u00b7wig\u00b7keit", "auch", "ster\u00b7bend", "zu", "um\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Hat Vielen, die gleich nicht der Seele Schatz gekannt,", "tokens": ["Hat", "Vie\u00b7len", ",", "die", "gleich", "nicht", "der", "See\u00b7le", "Schatz", "ge\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "PRELS", "ADV", "PTKNEG", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Kern und Geist gesucht in K\u00f6rpers Schal' und Aschen,", "tokens": ["Die", "Kern", "und", "Geist", "ge\u00b7sucht", "in", "K\u00f6r\u00b7pers", "Schal'", "und", "A\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "APPR", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch nach der Ewigkeit ihr dumpfer Geist gebrannt,", "tokens": ["Doch", "nach", "der", "E\u00b7wig\u00b7keit", "ihr", "dum\u00b7pfer", "Geist", "ge\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn sie mit Cedersaft die Leichen abgewaschen,", "tokens": ["Wenn", "sie", "mit", "Ce\u00b7der\u00b7saft", "die", "Lei\u00b7chen", "ab\u00b7ge\u00b7wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit Oel und Aloe gesalbet Leib und Haupt!", "tokens": ["Mit", "O\u00b7el", "und", "A\u00b7loe", "ge\u00b7sal\u00b7bet", "Leib", "und", "Haupt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "NN", "KON", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Weil aber endlich Zeit und F\u00e4ule Beides raubt,", "tokens": ["Weil", "a\u00b7ber", "end\u00b7lich", "Zeit", "und", "F\u00e4u\u00b7le", "Bei\u00b7des", "raubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "NN", "KON", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Balsam Moder wird, die Myrrhen W\u00fcrmer s\u00e4men,", "tokens": ["Der", "Bal\u00b7sam", "Mo\u00b7der", "wird", ",", "die", "Myr\u00b7rhen", "W\u00fcr\u00b7mer", "s\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mu\u00df man zur Ewigkeit wohl bessern Zunder nehmen.", "tokens": ["Mu\u00df", "man", "zur", "E\u00b7wig\u00b7keit", "wohl", "bes\u00b7sern", "Zun\u00b7der", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPRART", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Des Namens Ewigkeit und gro\u00dfer Thaten Ruhm", "tokens": ["Des", "Na\u00b7mens", "E\u00b7wig\u00b7keit", "und", "gro\u00b7\u00dfer", "Tha\u00b7ten", "Ruhm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Besteht auf festerm Fu\u00df und etwas l\u00e4ngerm Wesen;", "tokens": ["Be\u00b7steht", "auf", "fes\u00b7term", "Fu\u00df", "und", "et\u00b7was", "l\u00e4n\u00b7germ", "We\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch ist der Name selbst erborgtes Eigenthum.", "tokens": ["Doch", "ist", "der", "Na\u00b7me", "selbst", "er\u00b7borg\u00b7tes", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man kann gelehrtes Lob zwar in den B\u00fcchern lesen;", "tokens": ["Man", "kann", "ge\u00b7lehr\u00b7tes", "Lob", "zwar", "in", "den", "B\u00fc\u00b7chern", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch wie mag's glaublich sein, da\u00df man unsterblich ist", "tokens": ["Doch", "wie", "mag's", "glaub\u00b7lich", "sein", ",", "da\u00df", "man", "uns\u00b7terb\u00b7lich", "ist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIS", "ADJD", "VAINF", "$,", "KOUS", "PIS", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auf Leder und Papier, das selbst die Motte fri\u00dft?", "tokens": ["Auf", "Le\u00b7der", "und", "Pa\u00b7pier", ",", "das", "selbst", "die", "Mot\u00b7te", "fri\u00dft", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der deutschen Helden Preis, den Plinius geschrieben,", "tokens": ["Der", "deut\u00b7schen", "Hel\u00b7den", "Preis", ",", "den", "Pli\u00b7nius", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "NE", "VVPP", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Ist mit den B\u00fcchern selbst vom Zufall aufgerieben.", "tokens": ["Ist", "mit", "den", "B\u00fc\u00b7chern", "selbst", "vom", "Zu\u00b7fall", "auf\u00b7ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Man suchet Rom in Rom, Griechen in Griechenland,", "tokens": ["Man", "su\u00b7chet", "Rom", "in", "Rom", ",", "Grie\u00b7chen", "in", "Grie\u00b7chen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NE", "APPR", "NE", "$,", "NN", "APPR", "NE", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "In dem die Marmel mehr, als Menschen, Griechisch sprechen.", "tokens": ["In", "dem", "die", "Mar\u00b7mel", "mehr", ",", "als", "Men\u00b7schen", ",", "Grie\u00b7chisch", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "ADV", "$,", "KOUS", "NN", "$,", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Cephisus hat nicht Fluth, Pactol nicht g\u00fcldnen Sand;", "tokens": ["Ce\u00b7phi\u00b7sus", "hat", "nicht", "Fluth", ",", "Pac\u00b7tol", "nicht", "g\u00fcld\u00b7nen", "Sand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "NN", "$,", "NN", "PTKNEG", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Das reiche Sardes ist f\u00fcr arm und Nichts zu rechnen;", "tokens": ["Das", "rei\u00b7che", "Sar\u00b7des", "ist", "f\u00fcr", "arm", "und", "Nichts", "zu", "rech\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ADJD", "KON", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Sch\u00e4fer h\u00fcten Vieh, wo einst Miletus war,", "tokens": ["Die", "Sch\u00e4\u00b7fer", "h\u00fc\u00b7ten", "Vieh", ",", "wo", "einst", "Mi\u00b7le\u00b7tus", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PWAV", "ADV", "NE", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ja, wir vermi\u00dften es, wie seine Hirten, gar,", "tokens": ["Ja", ",", "wir", "ver\u00b7mi\u00df\u00b7ten", "es", ",", "wie", "sei\u00b7ne", "Hir\u00b7ten", ",", "gar", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "$,", "PWAV", "PPOSAT", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn nicht ein stummer Stein mit seiner Schrift entdeckte,", "tokens": ["Wenn", "nicht", "ein", "stum\u00b7mer", "Stein", "mit", "sei\u00b7ner", "Schrift", "ent\u00b7deck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df Thales' Vaterland daselbst vergraben steckte.", "tokens": ["Da\u00df", "Tha\u00b7les'", "Va\u00b7ter\u00b7land", "da\u00b7selbst", "ver\u00b7gra\u00b7ben", "steck\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "PAV", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ob auch die Seelen gleich Ged\u00e4chtni\u00dftempel sind,", "tokens": ["Ob", "auch", "die", "See\u00b7len", "gleich", "Ge\u00b7d\u00e4cht\u00b7ni\u00df\u00b7tem\u00b7pel", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "In denen Tugend uns zum Abgott hat erhoben;", "tokens": ["In", "de\u00b7nen", "Tu\u00b7gend", "uns", "zum", "Ab\u00b7gott", "hat", "er\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "PPER", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Sonnenschein wird nicht zur Wolke so geschwind,", "tokens": ["Der", "Son\u00b7nen\u00b7schein", "wird", "nicht", "zur", "Wol\u00b7ke", "so", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als man verfluchen wird das, was wir heute loben.", "tokens": ["Als", "man", "ver\u00b7flu\u00b7chen", "wird", "das", ",", "was", "wir", "heu\u00b7te", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "VAFIN", "PDS", "$,", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Jener Wohlthat hei\u00dft, schilt Dieser Missethat;", "tokens": ["Was", "Je\u00b7ner", "Wohlt\u00b7hat", "hei\u00dft", ",", "schilt", "Die\u00b7ser", "Mis\u00b7se\u00b7that", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man legt zu h\u00f6chstem Schimpf' auf Holzst\u00f6\u00df' und auf's Rad", "tokens": ["Man", "legt", "zu", "h\u00f6chs\u00b7tem", "Schimpf'", "auf", "Holz\u00b7st\u00f6\u00df'", "und", "auf's", "Rad"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ADJA", "NN", "APPR", "NE", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das, was vor kurzer Zeit wir eingebalsamt haben,", "tokens": ["Das", ",", "was", "vor", "kur\u00b7zer", "Zeit", "wir", "ein\u00b7ge\u00b7bal\u00b7samt", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "APPR", "ADJA", "NN", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was unter dem Altar noch gestern lag begraben.", "tokens": ["Was", "un\u00b7ter", "dem", "Al\u00b7tar", "noch", "ge\u00b7stern", "lag", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADV", "ADV", "VVFIN", "VVPP", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Zudem sch\u00e4tzt Tugenden f\u00fcr ein unsterblich Ding;", "tokens": ["Zu\u00b7dem", "sch\u00e4tzt", "Tu\u00b7gen\u00b7den", "f\u00fcr", "ein", "uns\u00b7terb\u00b7lich", "Ding", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "APPR", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "La\u00dft gro\u00dfer Thaten Ruhm so lange Zeit bekleiben,", "tokens": ["La\u00dft", "gro\u00b7\u00dfer", "Tha\u00b7ten", "Ruhm", "so", "lan\u00b7ge", "Zeit", "be\u00b7klei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "NN", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als aller Jahre Lauf umzirket ihren Ring;", "tokens": ["Als", "al\u00b7ler", "Jah\u00b7re", "Lauf", "um\u00b7zir\u00b7ket", "ih\u00b7ren", "Ring", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "La\u00dft an de Mondes Rand gar eure Namen schreiben!", "tokens": ["La\u00dft", "an", "de", "Mon\u00b7des", "Rand", "gar", "eu\u00b7re", "Na\u00b7men", "schrei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "NE", "NE", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wird von der Ewigkeit ein Schimmer \u00fcbrig sein,", "tokens": ["Wird", "von", "der", "E\u00b7wig\u00b7keit", "ein", "Schim\u00b7mer", "\u00fcb\u00b7rig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn Alles h\u00f6ret auf, der Himmel schrumpfet ein?", "tokens": ["Wenn", "Al\u00b7les", "h\u00f6\u00b7ret", "auf", ",", "der", "Him\u00b7mel", "schrump\u00b7fet", "ein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo werden bleiben stehn die G\u00f6tter dieser Erden,", "tokens": ["Wo", "wer\u00b7den", "blei\u00b7ben", "stehn", "die", "G\u00f6t\u00b7ter", "die\u00b7ser", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "VVINF", "VVFIN", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wann Erd' und Welt wird Graus, die Sterne Asche werden? \u2013", "tokens": ["Wann", "Erd'", "und", "Welt", "wird", "Graus", ",", "die", "Ster\u00b7ne", "A\u00b7sche", "wer\u00b7den", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VAFIN", "NN", "$,", "ART", "NN", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Welch' andrer Pfad weist denn zur Ewigkeit den Weg,", "tokens": ["Welch'", "an\u00b7drer", "Pfad", "weist", "denn", "zur", "E\u00b7wig\u00b7keit", "den", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die keiner Zeiten Zeit ist m\u00e4chtig zu vergraben?", "tokens": ["Die", "kei\u00b7ner", "Zei\u00b7ten", "Zeit", "ist", "m\u00e4ch\u00b7tig", "zu", "ver\u00b7gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NN", "VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Brunn der Ewigkeit will Oel ohn' allen Fleck", "tokens": ["Der", "Brunn", "der", "E\u00b7wig\u00b7keit", "will", "O\u00b7el", "ohn'", "al\u00b7len", "Fleck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VMFIN", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und Ampeln nicht von Thon in seinem Tempel haben.", "tokens": ["Und", "Am\u00b7peln", "nicht", "von", "Thon", "in", "sei\u00b7nem", "Tem\u00b7pel", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKNEG", "APPR", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die ihre reine Seel' anz\u00fcnden ihrem Gott", "tokens": ["Die", "ih\u00b7re", "rei\u00b7ne", "Seel'", "an\u00b7z\u00fcn\u00b7den", "ih\u00b7rem", "Gott"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VVIZU", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ihm Glauben, werden nicht vom Sterben haben Noth;", "tokens": ["Ihm", "Glau\u00b7ben", ",", "wer\u00b7den", "nicht", "vom", "Ster\u00b7ben", "ha\u00b7ben", "Noth", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VAFIN", "PTKNEG", "APPRART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die zur Gerechtigkeit den Weg hier lebend zeigen,", "tokens": ["Die", "zur", "Ge\u00b7rech\u00b7tig\u00b7keit", "den", "Weg", "hier", "le\u00b7bend", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Derselben Glanz wird selbst die Sterne \u00fcbersteigen!", "tokens": ["Der\u00b7sel\u00b7ben", "Glanz", "wird", "selbst", "die", "Ster\u00b7ne", "\u00fc\u00b7bers\u00b7tei\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Die Flammen steigen stets dem ersten Quelle zu;", "tokens": ["Die", "Flam\u00b7men", "stei\u00b7gen", "stets", "dem", "ers\u00b7ten", "Quel\u00b7le", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Wolken regnen hin, wo sie zuerst entspringen;", "tokens": ["Die", "Wol\u00b7ken", "reg\u00b7nen", "hin", ",", "wo", "sie", "zu\u00b7erst", "ent\u00b7sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "PWAV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es suchet der Magnet beim Angelsterne Ruh';", "tokens": ["Es", "su\u00b7chet", "der", "Mag\u00b7net", "beim", "An\u00b7gels\u00b7ter\u00b7ne", "Ruh'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "NN", "$."], "meter": "-+--+--++--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Man sieht des Meeres Salz zu seinen Brunnen dringen;", "tokens": ["Man", "sieht", "des", "Mee\u00b7res", "Salz", "zu", "sei\u00b7nen", "Brun\u00b7nen", "drin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jedweden Morgen kehrt dahin der Sonne Rad,", "tokens": ["Jed\u00b7we\u00b7den", "Mor\u00b7gen", "kehrt", "da\u00b7hin", "der", "Son\u00b7ne", "Rad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PAV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo Memnon's Mutter sie vorher geboren hat;", "tokens": ["Wo", "Mem\u00b7non's", "Mut\u00b7ter", "sie", "vor\u00b7her", "ge\u00b7bo\u00b7ren", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So, weil der morsche Mensch zur Mutter hat die Erden,", "tokens": ["So", ",", "weil", "der", "mor\u00b7sche", "Mensch", "zur", "Mut\u00b7ter", "hat", "die", "Er\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mu\u00df, was die Wiege war, ihm auch sein Leichstein werden.", "tokens": ["Mu\u00df", ",", "was", "die", "Wie\u00b7ge", "war", ",", "ihm", "auch", "sein", "Leichs\u00b7tein", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PRELS", "ART", "NN", "VAFIN", "$,", "PPER", "ADV", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wie aber? schleu\u00dft dies Grab sein ganzes Wesen ein?", "tokens": ["Wie", "a\u00b7ber", "?", "schleu\u00dft", "dies", "Grab", "sein", "gan\u00b7zes", "We\u00b7sen", "ein", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$.", "VVFIN", "PDS", "NN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll in des Lebens Kreis', im Zirkel unsrer Jahre", "tokens": ["Soll", "in", "des", "Le\u00b7bens", "Kreis'", ",", "im", "Zir\u00b7kel", "uns\u00b7rer", "Jah\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "NN", "$,", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Nichts der Mittelpunkt, das Ende Sterben sein?", "tokens": ["Ein", "Nichts", "der", "Mit\u00b7tel\u00b7punkt", ",", "das", "En\u00b7de", "Ster\u00b7ben", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "$,", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sucht doch die Fledermaus im Lichte Tod und Bahre,", "tokens": ["Sucht", "doch", "die", "Fle\u00b7der\u00b7maus", "im", "Lich\u00b7te", "Tod", "und", "Bah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ob sie des Tages Glanz gleich nicht vertragen kann!", "tokens": ["Ob", "sie", "des", "Ta\u00b7ges", "Glanz", "gleich", "nicht", "ver\u00b7tra\u00b7gen", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Gluth nimmt hellern Glanz bei dem Verl\u00f6schen an.", "tokens": ["Die", "Gluth", "nimmt", "hel\u00b7lern", "Glanz", "bei", "dem", "Ver\u00b7l\u00f6\u00b7schen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nein! auch der weise Mensch pflegt, mu\u00df er schon erblassen,", "tokens": ["Nein", "!", "auch", "der", "wei\u00b7se", "Mensch", "pflegt", ",", "mu\u00df", "er", "schon", "er\u00b7blas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Zweck der Ewigkeit auch sterbend zu umfassen.", "tokens": ["Den", "Zweck", "der", "E\u00b7wig\u00b7keit", "auch", "ster\u00b7bend", "zu", "um\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Hat Vielen, die gleich nicht der Seele Schatz gekannt,", "tokens": ["Hat", "Vie\u00b7len", ",", "die", "gleich", "nicht", "der", "See\u00b7le", "Schatz", "ge\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "PRELS", "ADV", "PTKNEG", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Kern und Geist gesucht in K\u00f6rpers Schal' und Aschen,", "tokens": ["Die", "Kern", "und", "Geist", "ge\u00b7sucht", "in", "K\u00f6r\u00b7pers", "Schal'", "und", "A\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "APPR", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch nach der Ewigkeit ihr dumpfer Geist gebrannt,", "tokens": ["Doch", "nach", "der", "E\u00b7wig\u00b7keit", "ihr", "dum\u00b7pfer", "Geist", "ge\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn sie mit Cedersaft die Leichen abgewaschen,", "tokens": ["Wenn", "sie", "mit", "Ce\u00b7der\u00b7saft", "die", "Lei\u00b7chen", "ab\u00b7ge\u00b7wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit Oel und Aloe gesalbet Leib und Haupt!", "tokens": ["Mit", "O\u00b7el", "und", "A\u00b7loe", "ge\u00b7sal\u00b7bet", "Leib", "und", "Haupt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "NN", "KON", "NN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Weil aber endlich Zeit und F\u00e4ule Beides raubt,", "tokens": ["Weil", "a\u00b7ber", "end\u00b7lich", "Zeit", "und", "F\u00e4u\u00b7le", "Bei\u00b7des", "raubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "NN", "KON", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Balsam Moder wird, die Myrrhen W\u00fcrmer s\u00e4men,", "tokens": ["Der", "Bal\u00b7sam", "Mo\u00b7der", "wird", ",", "die", "Myr\u00b7rhen", "W\u00fcr\u00b7mer", "s\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mu\u00df man zur Ewigkeit wohl bessern Zunder nehmen.", "tokens": ["Mu\u00df", "man", "zur", "E\u00b7wig\u00b7keit", "wohl", "bes\u00b7sern", "Zun\u00b7der", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPRART", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Des Namens Ewigkeit und gro\u00dfer Thaten Ruhm", "tokens": ["Des", "Na\u00b7mens", "E\u00b7wig\u00b7keit", "und", "gro\u00b7\u00dfer", "Tha\u00b7ten", "Ruhm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Besteht auf festerm Fu\u00df und etwas l\u00e4ngerm Wesen;", "tokens": ["Be\u00b7steht", "auf", "fes\u00b7term", "Fu\u00df", "und", "et\u00b7was", "l\u00e4n\u00b7germ", "We\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch ist der Name selbst erborgtes Eigenthum.", "tokens": ["Doch", "ist", "der", "Na\u00b7me", "selbst", "er\u00b7borg\u00b7tes", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man kann gelehrtes Lob zwar in den B\u00fcchern lesen;", "tokens": ["Man", "kann", "ge\u00b7lehr\u00b7tes", "Lob", "zwar", "in", "den", "B\u00fc\u00b7chern", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch wie mag's glaublich sein, da\u00df man unsterblich ist", "tokens": ["Doch", "wie", "mag's", "glaub\u00b7lich", "sein", ",", "da\u00df", "man", "uns\u00b7terb\u00b7lich", "ist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIS", "ADJD", "VAINF", "$,", "KOUS", "PIS", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auf Leder und Papier, das selbst die Motte fri\u00dft?", "tokens": ["Auf", "Le\u00b7der", "und", "Pa\u00b7pier", ",", "das", "selbst", "die", "Mot\u00b7te", "fri\u00dft", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der deutschen Helden Preis, den Plinius geschrieben,", "tokens": ["Der", "deut\u00b7schen", "Hel\u00b7den", "Preis", ",", "den", "Pli\u00b7nius", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "NE", "VVPP", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Ist mit den B\u00fcchern selbst vom Zufall aufgerieben.", "tokens": ["Ist", "mit", "den", "B\u00fc\u00b7chern", "selbst", "vom", "Zu\u00b7fall", "auf\u00b7ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Man suchet Rom in Rom, Griechen in Griechenland,", "tokens": ["Man", "su\u00b7chet", "Rom", "in", "Rom", ",", "Grie\u00b7chen", "in", "Grie\u00b7chen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NE", "APPR", "NE", "$,", "NN", "APPR", "NE", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "In dem die Marmel mehr, als Menschen, Griechisch sprechen.", "tokens": ["In", "dem", "die", "Mar\u00b7mel", "mehr", ",", "als", "Men\u00b7schen", ",", "Grie\u00b7chisch", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "ADV", "$,", "KOUS", "NN", "$,", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Cephisus hat nicht Fluth, Pactol nicht g\u00fcldnen Sand;", "tokens": ["Ce\u00b7phi\u00b7sus", "hat", "nicht", "Fluth", ",", "Pac\u00b7tol", "nicht", "g\u00fcld\u00b7nen", "Sand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "NN", "$,", "NN", "PTKNEG", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Das reiche Sardes ist f\u00fcr arm und Nichts zu rechnen;", "tokens": ["Das", "rei\u00b7che", "Sar\u00b7des", "ist", "f\u00fcr", "arm", "und", "Nichts", "zu", "rech\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ADJD", "KON", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Sch\u00e4fer h\u00fcten Vieh, wo einst Miletus war,", "tokens": ["Die", "Sch\u00e4\u00b7fer", "h\u00fc\u00b7ten", "Vieh", ",", "wo", "einst", "Mi\u00b7le\u00b7tus", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PWAV", "ADV", "NE", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ja, wir vermi\u00dften es, wie seine Hirten, gar,", "tokens": ["Ja", ",", "wir", "ver\u00b7mi\u00df\u00b7ten", "es", ",", "wie", "sei\u00b7ne", "Hir\u00b7ten", ",", "gar", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "$,", "PWAV", "PPOSAT", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn nicht ein stummer Stein mit seiner Schrift entdeckte,", "tokens": ["Wenn", "nicht", "ein", "stum\u00b7mer", "Stein", "mit", "sei\u00b7ner", "Schrift", "ent\u00b7deck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df Thales' Vaterland daselbst vergraben steckte.", "tokens": ["Da\u00df", "Tha\u00b7les'", "Va\u00b7ter\u00b7land", "da\u00b7selbst", "ver\u00b7gra\u00b7ben", "steck\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "PAV", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ob auch die Seelen gleich Ged\u00e4chtni\u00dftempel sind,", "tokens": ["Ob", "auch", "die", "See\u00b7len", "gleich", "Ge\u00b7d\u00e4cht\u00b7ni\u00df\u00b7tem\u00b7pel", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "In denen Tugend uns zum Abgott hat erhoben;", "tokens": ["In", "de\u00b7nen", "Tu\u00b7gend", "uns", "zum", "Ab\u00b7gott", "hat", "er\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "PPER", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Sonnenschein wird nicht zur Wolke so geschwind,", "tokens": ["Der", "Son\u00b7nen\u00b7schein", "wird", "nicht", "zur", "Wol\u00b7ke", "so", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als man verfluchen wird das, was wir heute loben.", "tokens": ["Als", "man", "ver\u00b7flu\u00b7chen", "wird", "das", ",", "was", "wir", "heu\u00b7te", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "VAFIN", "PDS", "$,", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Jener Wohlthat hei\u00dft, schilt Dieser Missethat;", "tokens": ["Was", "Je\u00b7ner", "Wohlt\u00b7hat", "hei\u00dft", ",", "schilt", "Die\u00b7ser", "Mis\u00b7se\u00b7that", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man legt zu h\u00f6chstem Schimpf' auf Holzst\u00f6\u00df' und auf's Rad", "tokens": ["Man", "legt", "zu", "h\u00f6chs\u00b7tem", "Schimpf'", "auf", "Holz\u00b7st\u00f6\u00df'", "und", "auf's", "Rad"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ADJA", "NN", "APPR", "NE", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das, was vor kurzer Zeit wir eingebalsamt haben,", "tokens": ["Das", ",", "was", "vor", "kur\u00b7zer", "Zeit", "wir", "ein\u00b7ge\u00b7bal\u00b7samt", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "APPR", "ADJA", "NN", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was unter dem Altar noch gestern lag begraben.", "tokens": ["Was", "un\u00b7ter", "dem", "Al\u00b7tar", "noch", "ge\u00b7stern", "lag", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADV", "ADV", "VVFIN", "VVPP", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Zudem sch\u00e4tzt Tugenden f\u00fcr ein unsterblich Ding;", "tokens": ["Zu\u00b7dem", "sch\u00e4tzt", "Tu\u00b7gen\u00b7den", "f\u00fcr", "ein", "uns\u00b7terb\u00b7lich", "Ding", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "APPR", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "La\u00dft gro\u00dfer Thaten Ruhm so lange Zeit bekleiben,", "tokens": ["La\u00dft", "gro\u00b7\u00dfer", "Tha\u00b7ten", "Ruhm", "so", "lan\u00b7ge", "Zeit", "be\u00b7klei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "NN", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als aller Jahre Lauf umzirket ihren Ring;", "tokens": ["Als", "al\u00b7ler", "Jah\u00b7re", "Lauf", "um\u00b7zir\u00b7ket", "ih\u00b7ren", "Ring", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "La\u00dft an de Mondes Rand gar eure Namen schreiben!", "tokens": ["La\u00dft", "an", "de", "Mon\u00b7des", "Rand", "gar", "eu\u00b7re", "Na\u00b7men", "schrei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "NE", "NE", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wird von der Ewigkeit ein Schimmer \u00fcbrig sein,", "tokens": ["Wird", "von", "der", "E\u00b7wig\u00b7keit", "ein", "Schim\u00b7mer", "\u00fcb\u00b7rig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn Alles h\u00f6ret auf, der Himmel schrumpfet ein?", "tokens": ["Wenn", "Al\u00b7les", "h\u00f6\u00b7ret", "auf", ",", "der", "Him\u00b7mel", "schrump\u00b7fet", "ein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo werden bleiben stehn die G\u00f6tter dieser Erden,", "tokens": ["Wo", "wer\u00b7den", "blei\u00b7ben", "stehn", "die", "G\u00f6t\u00b7ter", "die\u00b7ser", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "VVINF", "VVFIN", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wann Erd' und Welt wird Graus, die Sterne Asche werden? \u2013", "tokens": ["Wann", "Erd'", "und", "Welt", "wird", "Graus", ",", "die", "Ster\u00b7ne", "A\u00b7sche", "wer\u00b7den", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VAFIN", "NN", "$,", "ART", "NN", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Welch' andrer Pfad weist denn zur Ewigkeit den Weg,", "tokens": ["Welch'", "an\u00b7drer", "Pfad", "weist", "denn", "zur", "E\u00b7wig\u00b7keit", "den", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die keiner Zeiten Zeit ist m\u00e4chtig zu vergraben?", "tokens": ["Die", "kei\u00b7ner", "Zei\u00b7ten", "Zeit", "ist", "m\u00e4ch\u00b7tig", "zu", "ver\u00b7gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NN", "VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Brunn der Ewigkeit will Oel ohn' allen Fleck", "tokens": ["Der", "Brunn", "der", "E\u00b7wig\u00b7keit", "will", "O\u00b7el", "ohn'", "al\u00b7len", "Fleck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VMFIN", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und Ampeln nicht von Thon in seinem Tempel haben.", "tokens": ["Und", "Am\u00b7peln", "nicht", "von", "Thon", "in", "sei\u00b7nem", "Tem\u00b7pel", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKNEG", "APPR", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die ihre reine Seel' anz\u00fcnden ihrem Gott", "tokens": ["Die", "ih\u00b7re", "rei\u00b7ne", "Seel'", "an\u00b7z\u00fcn\u00b7den", "ih\u00b7rem", "Gott"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VVIZU", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ihm Glauben, werden nicht vom Sterben haben Noth;", "tokens": ["Ihm", "Glau\u00b7ben", ",", "wer\u00b7den", "nicht", "vom", "Ster\u00b7ben", "ha\u00b7ben", "Noth", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VAFIN", "PTKNEG", "APPRART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die zur Gerechtigkeit den Weg hier lebend zeigen,", "tokens": ["Die", "zur", "Ge\u00b7rech\u00b7tig\u00b7keit", "den", "Weg", "hier", "le\u00b7bend", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Derselben Glanz wird selbst die Sterne \u00fcbersteigen!", "tokens": ["Der\u00b7sel\u00b7ben", "Glanz", "wird", "selbst", "die", "Ster\u00b7ne", "\u00fc\u00b7bers\u00b7tei\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}