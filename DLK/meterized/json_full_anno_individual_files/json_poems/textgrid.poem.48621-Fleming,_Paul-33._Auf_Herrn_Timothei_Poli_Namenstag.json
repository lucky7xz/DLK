{"textgrid.poem.48621": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "33. Auf Herrn Timothei Poli Namenstag", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja, er hat es weit gebracht,", "tokens": ["Ja", ",", "er", "hat", "es", "weit", "ge\u00b7bracht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "unsrer Sprache werter Meister!", "tokens": ["uns\u00b7rer", "Spra\u00b7che", "wer\u00b7ter", "Meis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch den Witz der klugen Geister", "tokens": ["Durch", "den", "Witz", "der", "klu\u00b7gen", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "hat er uns den Weg gemacht,", "tokens": ["hat", "er", "uns", "den", "Weg", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df wir nun die h\u00f6chsten Sinnen", "tokens": ["da\u00df", "wir", "nun", "die", "h\u00f6chs\u00b7ten", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "vieler V\u00f6lker trutzen k\u00f6nnen.", "tokens": ["vie\u00b7ler", "V\u00f6l\u00b7ker", "trut\u00b7zen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Unser wird, was Andern war.", "tokens": ["Un\u00b7ser", "wird", ",", "was", "An\u00b7dern", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "PWS", "ADJA", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsern Deutschen mag nicht gleichen", "tokens": ["Un\u00b7sern", "Deut\u00b7schen", "mag", "nicht", "glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "so will ganz nichts Fremdes klingen.", "tokens": ["so", "will", "ganz", "nichts", "Frem\u00b7des", "klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PIS", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Auch das Alte wird verj\u00fcngt.", "tokens": ["Auch", "das", "Al\u00b7te", "wird", "ver\u00b7j\u00fcngt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Pelasger sch\u00f6nes Wesen", "tokens": ["Der", "Pe\u00b7las\u00b7ger", "sch\u00f6\u00b7nes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und was Rom zuvor gelesen", "tokens": ["und", "was", "Rom", "zu\u00b7vor", "ge\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "NE", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "h\u00f6rt man, wie mans bei uns singt.", "tokens": ["h\u00f6rt", "man", ",", "wie", "mans", "bei", "uns", "singt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWAV", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Venus und ihr ganzer Orden", "tokens": ["Ve\u00b7nus", "und", "ihr", "gan\u00b7zer", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.6": {"text": "ist nun kurz auch hochdeutsch worden.", "tokens": ["ist", "nun", "kurz", "auch", "hoch\u00b7deutsch", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Du durchrennst des Lobes Bahn,", "tokens": ["Du", "durch\u00b7rennst", "des", "Lo\u00b7bes", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Freund, mit abgescho\u00dfnem Z\u00fcgel!", "tokens": ["Freund", ",", "mit", "ab\u00b7ge\u00b7scho\u00df\u00b7nem", "Z\u00fc\u00b7gel", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich auch setz' in vollem B\u00fcgel", "tokens": ["Ich", "auch", "setz'", "in", "vol\u00b7lem", "B\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "auf das sch\u00f6ne Wesen an,", "tokens": ["auf", "das", "sch\u00f6\u00b7ne", "We\u00b7sen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "von dem Dafnes edle Sprossen", "tokens": ["von", "dem", "Daf\u00b7nes", "ed\u00b7le", "Spros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "um mein braunes Haar geschossen.", "tokens": ["um", "mein", "brau\u00b7nes", "Haar", "ge\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Kastalis, dein teurer Flu\u00df", "tokens": ["Kas\u00b7ta\u00b7lis", ",", "dein", "teu\u00b7rer", "Flu\u00df"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "soll durch mich auch sich ergie\u00dfen", "tokens": ["soll", "durch", "mich", "auch", "sich", "er\u00b7gie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "PPER", "ADV", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und mit v\u00f6llern Ufern flie\u00dfen", "tokens": ["und", "mit", "v\u00f6l\u00b7lern", "U\u00b7fern", "flie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um Cytherons gr\u00fcnen Fu\u00df!", "tokens": ["um", "Cy\u00b7the\u00b7rons", "gr\u00fc\u00b7nen", "Fu\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Cyrrha soll mir Anla\u00df geben,", "tokens": ["Cyrr\u00b7ha", "soll", "mir", "An\u00b7la\u00df", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "was mein ", "tokens": ["was", "mein"], "token_info": ["word", "word"], "pos": ["PWS", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}}, "stanza.6": {"line.1": {"text": "Heute la\u00df uns unser sein!", "tokens": ["Heu\u00b7te", "la\u00df", "uns", "un\u00b7ser", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PPOSAT", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Tag, dein Tag, der so sch\u00f6ne,", "tokens": ["Der", "Tag", ",", "dein", "Tag", ",", "der", "so", "sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ADJA", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "ruft uns treue Musens\u00f6hne", "tokens": ["ruft", "uns", "treu\u00b7e", "Mu\u00b7sen\u00b7s\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "von uns aus und zu dir ein.", "tokens": ["von", "uns", "aus", "und", "zu", "dir", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "KON", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der Tag, dein Tag, den wir ehren,", "tokens": ["Der", "Tag", ",", "dein", "Tag", ",", "den", "wir", "eh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "soll uns neue Freude lehren.", "tokens": ["soll", "uns", "neu\u00b7e", "Freu\u00b7de", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Dann so la\u00df uns alles Leid,", "tokens": ["Dann", "so", "la\u00df", "uns", "al\u00b7les", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIMP", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "allen Kummer in die Gaben", "tokens": ["al\u00b7len", "Kum\u00b7mer", "in", "die", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "des gesunden Evans graben!", "tokens": ["des", "ge\u00b7sun\u00b7den", "E\u00b7vans", "gra\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dann gedenk an keinen Neid,", "tokens": ["Dann", "ge\u00b7denk", "an", "kei\u00b7nen", "Neid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der, indem er uns verletzet,", "tokens": ["der", ",", "in\u00b7dem", "er", "uns", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "auf sich selbst sein Messer wetzet!", "tokens": ["auf", "sich", "selbst", "sein", "Mes\u00b7ser", "wet\u00b7zet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Was bek\u00fcmmert dich ein Maul,", "tokens": ["Was", "be\u00b7k\u00fcm\u00b7mert", "dich", "ein", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "das nichts anders kan als klaffen", "tokens": ["das", "nichts", "an\u00b7ders", "kan", "als", "klaf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "ADV", "VMFIN", "KOKOM", "VVFIN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "und aus Gutem B\u00f6ses schaffen,", "tokens": ["und", "aus", "Gu\u00b7tem", "B\u00f6\u00b7ses", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schnell' auf Schmach, auf Loben faul?", "tokens": ["schnell'", "auf", "Schmach", ",", "auf", "Lo\u00b7ben", "faul", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "APPR", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df sie sagen, was sie wollen,", "tokens": ["La\u00df", "sie", "sa\u00b7gen", ",", "was", "sie", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "PRELS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wenn nur wir tun, was wir sollen!", "tokens": ["wenn", "nur", "wir", "tun", ",", "was", "wir", "sol\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVINF", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.9": {"line.1": {"text": "Wenn der Reben g\u00fcldner Saft", "tokens": ["Wenn", "der", "Re\u00b7ben", "g\u00fcld\u00b7ner", "Saft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "in den lichten R\u00f6mern springet,", "tokens": ["in", "den", "lich\u00b7ten", "R\u00f6\u00b7mern", "sprin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und uns in die Stirne dringet", "tokens": ["und", "uns", "in", "die", "Stir\u00b7ne", "drin\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "seiner St\u00e4rke hei\u00dfe Kraft,", "tokens": ["sei\u00b7ner", "St\u00e4r\u00b7ke", "hei\u00b7\u00dfe", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da vergessen wir der Sachen,", "tokens": ["da", "ver\u00b7ges\u00b7sen", "wir", "der", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die die Herzen irdisch machen.", "tokens": ["die", "die", "Her\u00b7zen", "ir\u00b7disch", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Das ist unser Pegasus,", "tokens": ["Das", "ist", "un\u00b7ser", "Pe\u00b7ga\u00b7sus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "der uns von dem schweren Volke", "tokens": ["der", "uns", "von", "dem", "schwe\u00b7ren", "Vol\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "hoch setzt \u00fcber eine Wolke,", "tokens": ["hoch", "setzt", "\u00fc\u00b7ber", "ei\u00b7ne", "Wol\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da uns Niemand schaden mu\u00df.", "tokens": ["da", "uns", "Nie\u00b7mand", "scha\u00b7den", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ehren uns Thymbr\u00e4us Schwestern,", "tokens": ["Eh\u00b7ren", "uns", "Thym\u00b7br\u00e4us", "Schwes\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NE", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "so la\u00df jene sicher l\u00e4stern!", "tokens": ["so", "la\u00df", "je\u00b7ne", "si\u00b7cher", "l\u00e4s\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PDS", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Recht so, ", "tokens": ["Recht", "so", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Her die Hand, dieweil ich trinke!", "tokens": ["Her", "die", "Hand", ",", "die\u00b7weil", "ich", "trin\u00b7ke", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch von Herzen geht die Linke,", "tokens": ["Doch", "von", "Her\u00b7zen", "geht", "die", "Lin\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie man itzt will sein getraut.", "tokens": ["wie", "man", "itzt", "will", "sein", "ge\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VMFIN", "PPOSAT", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer uns heute wird betr\u00fcben,", "tokens": ["Wer", "uns", "heu\u00b7te", "wird", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "den soll Ph\u00f6bus nimmer lieben!", "tokens": ["den", "soll", "Ph\u00f6\u00b7bus", "nim\u00b7mer", "lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "der ihm um das Schorsteinfeuer", "tokens": ["der", "ihm", "um", "das", "Schor\u00b7stein\u00b7feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wol l\u00e4\u00dft schmecken deinen Wein.", "tokens": ["wol", "l\u00e4\u00dft", "schme\u00b7cken", "dei\u00b7nen", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was du schenkest deinen G\u00e4sten,", "tokens": ["Was", "du", "schen\u00b7kest", "dei\u00b7nen", "G\u00e4s\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "das k\u00f6mmt dennoch dir zum Besten!", "tokens": ["das", "k\u00f6mmt", "den\u00b7noch", "dir", "zum", "Bes\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Sind der Freunde mehr noch hier,", "tokens": ["Sind", "der", "Freun\u00b7de", "mehr", "noch", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wol! so la\u00df sie alle kommen!", "tokens": ["wol", "!", "so", "la\u00df", "sie", "al\u00b7le", "kom\u00b7men", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVIMP", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner mu\u00df sein ausgenommen,", "tokens": ["Kei\u00b7ner", "mu\u00df", "sein", "aus\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPOSAT", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der dich ehrt und liebt wie wir.", "tokens": ["der", "dich", "ehrt", "und", "liebt", "wie", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "VVFIN", "KOKOM", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du und er und ich und Alle", "tokens": ["Du", "und", "er", "und", "ich", "und", "Al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "KON", "PPER", "KON", "PPER", "KON", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen fr\u00f6lich sein mit Schalle.", "tokens": ["wol\u00b7len", "fr\u00f6\u00b7lich", "sein", "mit", "Schal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VAINF", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Sa, ihr Freunde, machts wie ich!", "tokens": ["Sa", ",", "ihr", "Freun\u00b7de", ",", "machts", "wie", "ich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "KOKOM", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leeret die gef\u00fcllten Schaalen!", "tokens": ["Lee\u00b7ret", "die", "ge\u00b7f\u00fcll\u00b7ten", "Schaa\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sa, ihr Br\u00fcder, seht auf mich!", "tokens": ["Sa", ",", "ihr", "Br\u00fc\u00b7der", ",", "seht", "auf", "mich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tut mirs nach, wie ichs euch weise:", "tokens": ["Tut", "mirs", "nach", ",", "wie", "ichs", "euch", "wei\u00b7se", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PTKVZ", "$,", "PWAV", "PIS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "auf die Wolfart unsrer Reise!", "tokens": ["auf", "die", "Wol\u00b7fart", "uns\u00b7rer", "Rei\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Ja, er hat es weit gebracht,", "tokens": ["Ja", ",", "er", "hat", "es", "weit", "ge\u00b7bracht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "unsrer Sprache werter Meister!", "tokens": ["uns\u00b7rer", "Spra\u00b7che", "wer\u00b7ter", "Meis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch den Witz der klugen Geister", "tokens": ["Durch", "den", "Witz", "der", "klu\u00b7gen", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "hat er uns den Weg gemacht,", "tokens": ["hat", "er", "uns", "den", "Weg", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df wir nun die h\u00f6chsten Sinnen", "tokens": ["da\u00df", "wir", "nun", "die", "h\u00f6chs\u00b7ten", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "vieler V\u00f6lker trutzen k\u00f6nnen.", "tokens": ["vie\u00b7ler", "V\u00f6l\u00b7ker", "trut\u00b7zen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Unser wird, was Andern war.", "tokens": ["Un\u00b7ser", "wird", ",", "was", "An\u00b7dern", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "PWS", "ADJA", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsern Deutschen mag nicht gleichen", "tokens": ["Un\u00b7sern", "Deut\u00b7schen", "mag", "nicht", "glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "so will ganz nichts Fremdes klingen.", "tokens": ["so", "will", "ganz", "nichts", "Frem\u00b7des", "klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PIS", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Auch das Alte wird verj\u00fcngt.", "tokens": ["Auch", "das", "Al\u00b7te", "wird", "ver\u00b7j\u00fcngt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Pelasger sch\u00f6nes Wesen", "tokens": ["Der", "Pe\u00b7las\u00b7ger", "sch\u00f6\u00b7nes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und was Rom zuvor gelesen", "tokens": ["und", "was", "Rom", "zu\u00b7vor", "ge\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "NE", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "h\u00f6rt man, wie mans bei uns singt.", "tokens": ["h\u00f6rt", "man", ",", "wie", "mans", "bei", "uns", "singt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWAV", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Venus und ihr ganzer Orden", "tokens": ["Ve\u00b7nus", "und", "ihr", "gan\u00b7zer", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.6": {"text": "ist nun kurz auch hochdeutsch worden.", "tokens": ["ist", "nun", "kurz", "auch", "hoch\u00b7deutsch", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Du durchrennst des Lobes Bahn,", "tokens": ["Du", "durch\u00b7rennst", "des", "Lo\u00b7bes", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Freund, mit abgescho\u00dfnem Z\u00fcgel!", "tokens": ["Freund", ",", "mit", "ab\u00b7ge\u00b7scho\u00df\u00b7nem", "Z\u00fc\u00b7gel", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich auch setz' in vollem B\u00fcgel", "tokens": ["Ich", "auch", "setz'", "in", "vol\u00b7lem", "B\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "auf das sch\u00f6ne Wesen an,", "tokens": ["auf", "das", "sch\u00f6\u00b7ne", "We\u00b7sen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "von dem Dafnes edle Sprossen", "tokens": ["von", "dem", "Daf\u00b7nes", "ed\u00b7le", "Spros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "um mein braunes Haar geschossen.", "tokens": ["um", "mein", "brau\u00b7nes", "Haar", "ge\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Kastalis, dein teurer Flu\u00df", "tokens": ["Kas\u00b7ta\u00b7lis", ",", "dein", "teu\u00b7rer", "Flu\u00df"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "soll durch mich auch sich ergie\u00dfen", "tokens": ["soll", "durch", "mich", "auch", "sich", "er\u00b7gie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "PPER", "ADV", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und mit v\u00f6llern Ufern flie\u00dfen", "tokens": ["und", "mit", "v\u00f6l\u00b7lern", "U\u00b7fern", "flie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "um Cytherons gr\u00fcnen Fu\u00df!", "tokens": ["um", "Cy\u00b7the\u00b7rons", "gr\u00fc\u00b7nen", "Fu\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Cyrrha soll mir Anla\u00df geben,", "tokens": ["Cyrr\u00b7ha", "soll", "mir", "An\u00b7la\u00df", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "was mein ", "tokens": ["was", "mein"], "token_info": ["word", "word"], "pos": ["PWS", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}}, "stanza.20": {"line.1": {"text": "Heute la\u00df uns unser sein!", "tokens": ["Heu\u00b7te", "la\u00df", "uns", "un\u00b7ser", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PPOSAT", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Tag, dein Tag, der so sch\u00f6ne,", "tokens": ["Der", "Tag", ",", "dein", "Tag", ",", "der", "so", "sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ADJA", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "ruft uns treue Musens\u00f6hne", "tokens": ["ruft", "uns", "treu\u00b7e", "Mu\u00b7sen\u00b7s\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "von uns aus und zu dir ein.", "tokens": ["von", "uns", "aus", "und", "zu", "dir", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "KON", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der Tag, dein Tag, den wir ehren,", "tokens": ["Der", "Tag", ",", "dein", "Tag", ",", "den", "wir", "eh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "soll uns neue Freude lehren.", "tokens": ["soll", "uns", "neu\u00b7e", "Freu\u00b7de", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Dann so la\u00df uns alles Leid,", "tokens": ["Dann", "so", "la\u00df", "uns", "al\u00b7les", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIMP", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "allen Kummer in die Gaben", "tokens": ["al\u00b7len", "Kum\u00b7mer", "in", "die", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "des gesunden Evans graben!", "tokens": ["des", "ge\u00b7sun\u00b7den", "E\u00b7vans", "gra\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dann gedenk an keinen Neid,", "tokens": ["Dann", "ge\u00b7denk", "an", "kei\u00b7nen", "Neid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der, indem er uns verletzet,", "tokens": ["der", ",", "in\u00b7dem", "er", "uns", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "auf sich selbst sein Messer wetzet!", "tokens": ["auf", "sich", "selbst", "sein", "Mes\u00b7ser", "wet\u00b7zet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Was bek\u00fcmmert dich ein Maul,", "tokens": ["Was", "be\u00b7k\u00fcm\u00b7mert", "dich", "ein", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "das nichts anders kan als klaffen", "tokens": ["das", "nichts", "an\u00b7ders", "kan", "als", "klaf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "ADV", "VMFIN", "KOKOM", "VVFIN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "und aus Gutem B\u00f6ses schaffen,", "tokens": ["und", "aus", "Gu\u00b7tem", "B\u00f6\u00b7ses", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schnell' auf Schmach, auf Loben faul?", "tokens": ["schnell'", "auf", "Schmach", ",", "auf", "Lo\u00b7ben", "faul", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "APPR", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df sie sagen, was sie wollen,", "tokens": ["La\u00df", "sie", "sa\u00b7gen", ",", "was", "sie", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "PRELS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wenn nur wir tun, was wir sollen!", "tokens": ["wenn", "nur", "wir", "tun", ",", "was", "wir", "sol\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVINF", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.23": {"line.1": {"text": "Wenn der Reben g\u00fcldner Saft", "tokens": ["Wenn", "der", "Re\u00b7ben", "g\u00fcld\u00b7ner", "Saft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "in den lichten R\u00f6mern springet,", "tokens": ["in", "den", "lich\u00b7ten", "R\u00f6\u00b7mern", "sprin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und uns in die Stirne dringet", "tokens": ["und", "uns", "in", "die", "Stir\u00b7ne", "drin\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "seiner St\u00e4rke hei\u00dfe Kraft,", "tokens": ["sei\u00b7ner", "St\u00e4r\u00b7ke", "hei\u00b7\u00dfe", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da vergessen wir der Sachen,", "tokens": ["da", "ver\u00b7ges\u00b7sen", "wir", "der", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die die Herzen irdisch machen.", "tokens": ["die", "die", "Her\u00b7zen", "ir\u00b7disch", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Das ist unser Pegasus,", "tokens": ["Das", "ist", "un\u00b7ser", "Pe\u00b7ga\u00b7sus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "der uns von dem schweren Volke", "tokens": ["der", "uns", "von", "dem", "schwe\u00b7ren", "Vol\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "hoch setzt \u00fcber eine Wolke,", "tokens": ["hoch", "setzt", "\u00fc\u00b7ber", "ei\u00b7ne", "Wol\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da uns Niemand schaden mu\u00df.", "tokens": ["da", "uns", "Nie\u00b7mand", "scha\u00b7den", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ehren uns Thymbr\u00e4us Schwestern,", "tokens": ["Eh\u00b7ren", "uns", "Thym\u00b7br\u00e4us", "Schwes\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NE", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "so la\u00df jene sicher l\u00e4stern!", "tokens": ["so", "la\u00df", "je\u00b7ne", "si\u00b7cher", "l\u00e4s\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PDS", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Recht so, ", "tokens": ["Recht", "so", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Her die Hand, dieweil ich trinke!", "tokens": ["Her", "die", "Hand", ",", "die\u00b7weil", "ich", "trin\u00b7ke", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch von Herzen geht die Linke,", "tokens": ["Doch", "von", "Her\u00b7zen", "geht", "die", "Lin\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie man itzt will sein getraut.", "tokens": ["wie", "man", "itzt", "will", "sein", "ge\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VMFIN", "PPOSAT", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer uns heute wird betr\u00fcben,", "tokens": ["Wer", "uns", "heu\u00b7te", "wird", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "den soll Ph\u00f6bus nimmer lieben!", "tokens": ["den", "soll", "Ph\u00f6\u00b7bus", "nim\u00b7mer", "lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "der ihm um das Schorsteinfeuer", "tokens": ["der", "ihm", "um", "das", "Schor\u00b7stein\u00b7feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wol l\u00e4\u00dft schmecken deinen Wein.", "tokens": ["wol", "l\u00e4\u00dft", "schme\u00b7cken", "dei\u00b7nen", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was du schenkest deinen G\u00e4sten,", "tokens": ["Was", "du", "schen\u00b7kest", "dei\u00b7nen", "G\u00e4s\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "das k\u00f6mmt dennoch dir zum Besten!", "tokens": ["das", "k\u00f6mmt", "den\u00b7noch", "dir", "zum", "Bes\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.27": {"line.1": {"text": "Sind der Freunde mehr noch hier,", "tokens": ["Sind", "der", "Freun\u00b7de", "mehr", "noch", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wol! so la\u00df sie alle kommen!", "tokens": ["wol", "!", "so", "la\u00df", "sie", "al\u00b7le", "kom\u00b7men", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVIMP", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner mu\u00df sein ausgenommen,", "tokens": ["Kei\u00b7ner", "mu\u00df", "sein", "aus\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPOSAT", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der dich ehrt und liebt wie wir.", "tokens": ["der", "dich", "ehrt", "und", "liebt", "wie", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "VVFIN", "KOKOM", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du und er und ich und Alle", "tokens": ["Du", "und", "er", "und", "ich", "und", "Al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "KON", "PPER", "KON", "PPER", "KON", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen fr\u00f6lich sein mit Schalle.", "tokens": ["wol\u00b7len", "fr\u00f6\u00b7lich", "sein", "mit", "Schal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VAINF", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Sa, ihr Freunde, machts wie ich!", "tokens": ["Sa", ",", "ihr", "Freun\u00b7de", ",", "machts", "wie", "ich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "KOKOM", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leeret die gef\u00fcllten Schaalen!", "tokens": ["Lee\u00b7ret", "die", "ge\u00b7f\u00fcll\u00b7ten", "Schaa\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sa, ihr Br\u00fcder, seht auf mich!", "tokens": ["Sa", ",", "ihr", "Br\u00fc\u00b7der", ",", "seht", "auf", "mich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tut mirs nach, wie ichs euch weise:", "tokens": ["Tut", "mirs", "nach", ",", "wie", "ichs", "euch", "wei\u00b7se", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PTKVZ", "$,", "PWAV", "PIS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "auf die Wolfart unsrer Reise!", "tokens": ["auf", "die", "Wol\u00b7fart", "uns\u00b7rer", "Rei\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}