{"textgrid.poem.40058": {"metadata": {"author": {"name": "Hoyers, Anna Ovena", "birth": "N.A.", "death": "N.A."}, "title": "Capvt 2", "genre": "verse", "period": "N.A.", "pub_year": 1619, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es war ein Mann/ vernehmet recht/", "tokens": ["Es", "war", "ein", "Mann", "/", "ver\u00b7neh\u00b7met", "recht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tapffer und reich von G\u00fcter/", "tokens": ["Tapf\u00b7fer", "und", "reich", "von", "G\u00fc\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPR", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Eli Melechs freund von geschlecht/", "tokens": ["E\u00b7li", "Me\u00b7lechs", "freund", "von", "ge\u00b7schlecht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "APPR", "VVPP", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Auch ein Bethlehemiter.", "tokens": ["Auch", "ein", "Beth\u00b7le\u00b7he\u00b7mi\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Ein feiner Mann Boas genandt/", "tokens": ["Ein", "fei\u00b7ner", "Mann", "Boas", "ge\u00b7nandt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VVPP", "$("], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Der lie\u00df auch Gersten schneiden;", "tokens": ["Der", "lie\u00df", "auch", "Gers\u00b7ten", "schnei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Naemi war er wol bekandt/", "tokens": ["Nae\u00b7mi", "war", "er", "wol", "be\u00b7kandt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Die mit Ruth sa\u00df in leiden/", "tokens": ["Die", "mit", "Ruth", "sa\u00df", "in", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVFIN", "APPR", "VVINF", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.9": {"text": "Einsam/ und beyde nehrten sich", "tokens": ["Ein\u00b7sam", "/", "und", "bey\u00b7de", "nehr\u00b7ten", "sich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$(", "KON", "PIS", "VVFIN", "PRF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Durch das werck ihrer h\u00e4nde/", "tokens": ["Durch", "das", "werck", "ih\u00b7rer", "h\u00e4n\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "ADJA", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "Wie arme Witwen k\u00fcmmerlich/", "tokens": ["Wie", "ar\u00b7me", "Wit\u00b7wen", "k\u00fcm\u00b7mer\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Pflegen in ihrm Elende.", "tokens": ["Pfle\u00b7gen", "in", "ihrm", "E\u00b7len\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.13": {"text": "Es war gering ihr beyder sach/", "tokens": ["Es", "war", "ge\u00b7ring", "ihr", "bey\u00b7der", "sach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Vormals besser gewesen/", "tokens": ["Vor\u00b7mals", "bes\u00b7ser", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAPP", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.15": {"text": "Darumb Ruth zu Naemi sprach:", "tokens": ["Da\u00b7rumb", "Ruth", "zu", "Nae\u00b7mi", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.16": {"text": "Last mich gehn und aufflesen", "tokens": ["Last", "mich", "gehn", "und", "auf\u00b7fle\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "VVINF", "KON", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.17": {"text": "\u00c4hern auffs feld dem nach/ f\u00fcr dem", "tokens": ["\u00c4\u00b7hern", "auffs", "feld", "dem", "nach", "/", "f\u00fcr", "dem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPRART", "NN", "ART", "APPR", "$(", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Ich gnad und gunst itzt finde/", "tokens": ["Ich", "gnad", "und", "gunst", "itzt", "fin\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Vnd da ich seyn werd angenehm/", "tokens": ["Vnd", "da", "ich", "seyn", "werd", "an\u00b7ge\u00b7nehm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAINF", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Im feld bey dem Gesinde.", "tokens": ["Im", "feld", "bey", "dem", "Ge\u00b7sin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Geh hin mein Tochter/ antwort sie/", "tokens": ["Geh", "hin", "mein", "Toch\u00b7ter", "/", "ant\u00b7wort", "sie", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "$(", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Ich will es dir nicht wehren/", "tokens": ["Ich", "will", "es", "dir", "nicht", "weh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Bring was zu hau\u00df da\u00df wir uns hie", "tokens": ["Bring", "was", "zu", "hau\u00df", "da\u00df", "wir", "uns", "hie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "NN", "KOUS", "PPER", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "M\u00f6gen davon ernehren.", "tokens": ["M\u00f6\u00b7gen", "da\u00b7von", "er\u00b7neh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PAV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.25": {"text": "Sie ging hin/ merckt doch was geschicht/", "tokens": ["Sie", "ging", "hin", "/", "merckt", "doch", "was", "ge\u00b7schicht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$(", "VVFIN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Vnd kam auff Boas Acker/", "tokens": ["Vnd", "kam", "auff", "Boas", "A\u00b7cker", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.27": {"text": "Jedoch den Mann sie kante nicht/", "tokens": ["Je\u00b7doch", "den", "Mann", "sie", "kan\u00b7te", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "VMFIN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Sie la\u00df die \u00e4hern wacker", "tokens": ["Sie", "la\u00df", "die", "\u00e4\u00b7hern", "wa\u00b7cker"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Den Schnittern nach. Boas der Mann", "tokens": ["Den", "Schnit\u00b7tern", "nach", ".", "Boas", "der", "Mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "NE", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.30": {"text": "Von Bethlehem kam gangen/", "tokens": ["Von", "Beth\u00b7le\u00b7hem", "kam", "gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "Er sprach die Schnitter also an:", "tokens": ["Er", "sprach", "die", "Schnit\u00b7ter", "al\u00b7so", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Was ihr habt angefangen/", "tokens": ["Was", "ihr", "habt", "an\u00b7ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.33": {"text": "Das geh in Gottes Namen fort/", "tokens": ["Das", "geh", "in", "Got\u00b7tes", "Na\u00b7men", "fort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Der sey mit euch im wercke.", "tokens": ["Der", "sey", "mit", "euch", "im", "wer\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "Danck habt/ war wider jhr antwort/", "tokens": ["Danck", "habt", "/", "war", "wi\u00b7der", "jhr", "ant\u00b7wort", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$(", "VAFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Der Herr sey ewer st\u00e4rcke.", "tokens": ["Der", "Herr", "sey", "e\u00b7wer", "st\u00e4r\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.37": {"text": "Boas sah Ruth auch da im Feld/", "tokens": ["Boas", "sah", "Ruth", "auch", "da", "im", "Feld", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "ADV", "ADV", "APPRART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.38": {"text": "Vnd sprach zu seinem Knaben", "tokens": ["Vnd", "sprach", "zu", "sei\u00b7nem", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.39": {"text": "Der ubr die Schnitter war gestellt:", "tokens": ["Der", "ubr", "die", "Schnit\u00b7ter", "war", "ge\u00b7stellt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Was will die Dirne haben?", "tokens": ["Was", "will", "die", "Dir\u00b7ne", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.41": {"text": "Wes ist sie? Der Knab gab bescheit:", "tokens": ["Wes", "ist", "sie", "?", "Der", "Knab", "gab", "be\u00b7scheit", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "$.", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.42": {"text": "Sie ist/ hab ich vernommen/", "tokens": ["Sie", "ist", "/", "hab", "ich", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.43": {"text": "Die von Moab vor wenig zeit", "tokens": ["Die", "von", "Mo\u00b7ab", "vor", "we\u00b7nig", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Ist mit Naemi kommen.", "tokens": ["Ist", "mit", "Nae\u00b7mi", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NE", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.45": {"text": "Ferner der Knab zu Boas sprach:", "tokens": ["Fer\u00b7ner", "der", "Knab", "zu", "Boas", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.46": {"text": "Sie ist hie heut gewesen", "tokens": ["Sie", "ist", "hie", "heut", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VAPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.47": {"text": "Bey uns im Feld den gantzen Tag.", "tokens": ["Bey", "uns", "im", "Feld", "den", "gant\u00b7zen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Die \u00e4hern auffzulesen", "tokens": ["Die", "\u00e4\u00b7hern", "auff\u00b7zu\u00b7le\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Den schnittern nach; dieweil sie mich", "tokens": ["Den", "schnit\u00b7tern", "nach", ";", "die\u00b7weil", "sie", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "PTKVZ", "$.", "KOUS", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Drumb bath ihr di\u00df zu g\u00fcnnen/", "tokens": ["Drumb", "ba\u00b7th", "ihr", "di\u00df", "zu", "g\u00fcn\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PDS", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.51": {"text": "Solch ihre bitt an mich hab ich", "tokens": ["Solch", "ih\u00b7re", "bitt", "an", "mich", "hab", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "PPOSAT", "ADV", "APPR", "PPER", "VAFIN", "PPER"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.52": {"text": "Ihr nicht abschlagen k\u00f6nnen.", "tokens": ["Ihr", "nicht", "ab\u00b7schla\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.53": {"text": "Flei\u00dfig ist sie gewesen heut", "tokens": ["Flei\u00b7\u00dfig", "ist", "sie", "ge\u00b7we\u00b7sen", "heut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "VAPP", "ADV"], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.54": {"text": "Es geht ihr wol von handen/", "tokens": ["Es", "geht", "ihr", "wol", "von", "han\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.55": {"text": "Von morgen bi\u00df auff diese zeit", "tokens": ["Von", "mor\u00b7gen", "bi\u00df", "auff", "die\u00b7se", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "Ist sie bey uns gestanden.", "tokens": ["Ist", "sie", "bey", "uns", "ge\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.57": {"text": "Da ging Boas selbst hin zu ihr/", "tokens": ["Da", "ging", "Boas", "selbst", "hin", "zu", "ihr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ADV", "ADV", "APPR", "PPOSAT", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.58": {"text": "Sprach mit freundtlichen worten:", "tokens": ["Sprach", "mit", "freundt\u00b7li\u00b7chen", "wor\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.59": {"text": "Meine Tochter gehorche mir", "tokens": ["Mei\u00b7ne", "Toch\u00b7ter", "ge\u00b7hor\u00b7che", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.60": {"text": "Vnd bleib an diesen Orten/", "tokens": ["Vnd", "bleib", "an", "die\u00b7sen", "Or\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.61": {"text": "Es soll dir nichts zu leid geschehn/", "tokens": ["Es", "soll", "dir", "nichts", "zu", "leid", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "PTKA", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Darumb geh' nicht von hinnen/", "tokens": ["Da\u00b7rumb", "geh'", "nicht", "von", "hin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PTKNEG", "APPR", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.63": {"text": "Mit meinen Dirnen soltu gehn/", "tokens": ["Mit", "mei\u00b7nen", "Dir\u00b7nen", "sol\u00b7tu", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Die dich anleiten k\u00f6nnen/", "tokens": ["Die", "dich", "an\u00b7lei\u00b7ten", "k\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.65": {"text": "Da sie schneiden/ geh' jhnen nach/", "tokens": ["Da", "sie", "schnei\u00b7den", "/", "geh'", "jh\u00b7nen", "nach", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$(", "VVFIN", "PPER", "APPR", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.66": {"text": "Dem Volck hab ich gebotten", "tokens": ["Dem", "Volck", "hab", "ich", "ge\u00b7bot\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.67": {"text": "Da\u00df keiner dich antast/ er sprach/", "tokens": ["Da\u00df", "kei\u00b7ner", "dich", "an\u00b7tast", "/", "er", "sprach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.68": {"text": "Oder sonst soll verspotten.", "tokens": ["O\u00b7der", "sonst", "soll", "ver\u00b7spot\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.69": {"text": "Vnd so dich durst/ geh hin zum krug/", "tokens": ["Vnd", "so", "dich", "durst", "/", "geh", "hin", "zum", "krug", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "ADV", "$(", "VVFIN", "ADV", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Vnd trinck mit meinen Knaben/", "tokens": ["Vnd", "trinck", "mit", "mei\u00b7nen", "Kna\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.71": {"text": "Es wird f\u00fcr dir auch seyn genug/", "tokens": ["Es", "wird", "f\u00fcr", "dir", "auch", "seyn", "ge\u00b7nug", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "PPOSAT", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "Dein hertz damit zu laben.", "tokens": ["Dein", "hertz", "da\u00b7mit", "zu", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.73": {"text": "Da fiel sie auff ihr angesicht/", "tokens": ["Da", "fiel", "sie", "auff", "ihr", "an\u00b7ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "Dem\u00fctig sie ihn ehret/", "tokens": ["De\u00b7m\u00fc\u00b7tig", "sie", "ihn", "eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.75": {"text": "Sprach: Ich hab je verdienet nicht", "tokens": ["Sprach", ":", "Ich", "hab", "je", "ver\u00b7die\u00b7net", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "VAFIN", "ADV", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.76": {"text": "Das mir itzt widerf\u00e4hret/", "tokens": ["Das", "mir", "itzt", "wi\u00b7der\u00b7f\u00e4h\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.77": {"text": "Ich wei\u00df auch nicht in meinem sinn", "tokens": ["Ich", "wei\u00df", "auch", "nicht", "in", "mei\u00b7nem", "sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Womit ich gnad bekommen/", "tokens": ["Wo\u00b7mit", "ich", "gnad", "be\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.79": {"text": "Die ich doch hie ein Frembde bin.", "tokens": ["Die", "ich", "doch", "hie", "ein", "Fremb\u00b7de", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "Er sprach ich hab vernommen/", "tokens": ["Er", "sprach", "ich", "hab", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.81": {"text": "Da\u00df du nach deines Mannes todt/", "tokens": ["Da\u00df", "du", "nach", "dei\u00b7nes", "Man\u00b7nes", "todt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "Hast wollen nicht verlassen", "tokens": ["Hast", "wol\u00b7len", "nicht", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.83": {"text": "Dein Schwieger Mutter in der noth/", "tokens": ["Dein", "Schwie\u00b7ger", "Mut\u00b7ter", "in", "der", "noth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.84": {"text": "Sondern mit jhr die strassen", "tokens": ["Son\u00b7dern", "mit", "jhr", "die", "stras\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.85": {"text": "Gezogen bist im frembden Landt/", "tokens": ["Ge\u00b7zo\u00b7gen", "bist", "im", "fremb\u00b7den", "Landt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.86": {"text": "Hast ihr viel guts erzeiget;", "tokens": ["Hast", "ihr", "viel", "guts", "er\u00b7zei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.87": {"text": "Bey einem Volck dir unbekant", "tokens": ["Bey", "ei\u00b7nem", "Volck", "dir", "un\u00b7be\u00b7kant"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.88": {"text": "Zu bleiben bist geneiget.", "tokens": ["Zu", "blei\u00b7ben", "bist", "ge\u00b7nei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.89": {"text": "Der Herr vergelt dir deine that/", "tokens": ["Der", "Herr", "ver\u00b7gelt", "dir", "dei\u00b7ne", "that", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "Vnd mach dein lohn vollkommen:", "tokens": ["Vnd", "mach", "dein", "lohn", "voll\u00b7kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.91": {"text": "Der zu dem Herren Zuflucht hat", "tokens": ["Der", "zu", "dem", "Her\u00b7ren", "Zu\u00b7flucht", "hat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "Wird von jhm angenommen.", "tokens": ["Wird", "von", "jhm", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.93": {"text": "Israels Gott sey immer zu", "tokens": ["Is\u00b7raels", "Gott", "sey", "im\u00b7mer", "zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NN", "VAFIN", "ADV", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.94": {"text": "Dein H\u00fclff und Trost im leben;", "tokens": ["Dein", "H\u00fclff", "und", "Trost", "im", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.95": {"text": "Vnter des fl\u00fcgeln jtzund du", "tokens": ["Vn\u00b7ter", "des", "fl\u00fc\u00b7geln", "jt\u00b7zund", "du"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVINF", "KON", "PPER"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.96": {"text": "Dich hast zu wohnen geben.", "tokens": ["Dich", "hast", "zu", "woh\u00b7nen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.97": {"text": "Ruth sich der wort erfrewen thet/", "tokens": ["Ruth", "sich", "der", "wort", "er\u00b7fre\u00b7wen", "thet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "ART", "NN", "VVINF", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.98": {"text": "Vnd antwort jhm dem\u00fctig:", "tokens": ["Vnd", "ant\u00b7wort", "jhm", "de\u00b7m\u00fc\u00b7tig", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.99": {"text": "Wie freundlich hat mein Herr geredt/", "tokens": ["Wie", "freund\u00b7lich", "hat", "mein", "Herr", "ge\u00b7redt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.100": {"text": "Vnd ist mir doch so g\u00fctig.", "tokens": ["Vnd", "ist", "mir", "doch", "so", "g\u00fc\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.101": {"text": "Nun ich f\u00fcr ewren augen gunst", "tokens": ["Nun", "ich", "f\u00fcr", "ew\u00b7ren", "au\u00b7gen", "gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "Vnd gnade hab gefunden/", "tokens": ["Vnd", "gna\u00b7de", "hab", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.103": {"text": "Wird von mir nichts begehret sonst/", "tokens": ["Wird", "von", "mir", "nichts", "be\u00b7ge\u00b7hret", "sonst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "PIS", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "Mein Leid ist mir verschwunden.", "tokens": ["Mein", "Leid", "ist", "mir", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.105": {"text": "Was solt ich doch begehren mehr", "tokens": ["Was", "solt", "ich", "doch", "be\u00b7geh\u00b7ren", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.106": {"text": "Denn ewer Gunst alleine?", "tokens": ["Denn", "e\u00b7wer", "Gunst", "al\u00b7lei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.107": {"text": "Weil ich geringer bin/ mein Herr/", "tokens": ["Weil", "ich", "ge\u00b7rin\u00b7ger", "bin", "/", "mein", "Herr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.108": {"text": "Als ewer M\u00e4gde eine.", "tokens": ["Als", "e\u00b7wer", "M\u00e4g\u00b7de", "ei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.109": {"text": "Er sprach zu jhr: Wenns essen zeit", "tokens": ["Er", "sprach", "zu", "jhr", ":", "Wenns", "es\u00b7sen", "zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "$.", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "Ist/ solt dich auch hernahen/", "tokens": ["Ist", "/", "solt", "dich", "auch", "her\u00b7na\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.111": {"text": "Vnd bey dem Volck nach der arbeit/", "tokens": ["Vnd", "bey", "dem", "Volck", "nach", "der", "ar\u00b7beit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.112": {"text": "Dein speise mit empfahen;", "tokens": ["Dein", "spei\u00b7se", "mit", "em\u00b7pfa\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.113": {"text": "Ihrer freyheit dich mit gebrauch/", "tokens": ["Ih\u00b7rer", "frey\u00b7heit", "dich", "mit", "ge\u00b7brauch", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "APPR", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.114": {"text": "Vnd tuncke deinen bissen", "tokens": ["Vnd", "tun\u00b7cke", "dei\u00b7nen", "bis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.115": {"text": "In essig wie die andern auch/", "tokens": ["In", "es\u00b7sig", "wie", "die", "an\u00b7dern", "auch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KOKOM", "ART", "ADJA", "ADV", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.116": {"text": "So spei\u00df einnehmen m\u00fcssen.", "tokens": ["So", "spei\u00df", "ein\u00b7neh\u00b7men", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.117": {"text": "Sie nam di\u00df an mit danckbarkeit/", "tokens": ["Sie", "nam", "di\u00df", "an", "mit", "dan\u00b7ck\u00b7bar\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "APPR", "APPR", "NN", "$("], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.118": {"text": "Dar\u00fcber sich ergetzte/", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "sich", "er\u00b7getz\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "PRF", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.119": {"text": "Vnd da es war zu essen zeit/", "tokens": ["Vnd", "da", "es", "war", "zu", "es\u00b7sen", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.120": {"text": "Sie sich mit nieder setzte.", "tokens": ["Sie", "sich", "mit", "nie\u00b7der", "setz\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPR", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.121": {"text": "Boas legt selbst zu essen f\u00fcr/", "tokens": ["Boas", "legt", "selbst", "zu", "es\u00b7sen", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKZU", "VVINF", "APPR", "$("], "meter": "+---+-+", "measure": "dactylic.init"}, "line.122": {"text": "Sie a\u00df/ er lie\u00df jhm langen", "tokens": ["Sie", "a\u00df", "/", "er", "lie\u00df", "jhm", "lan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.123": {"text": "Ged\u00f6rte \u00e4hern gab er jhr/", "tokens": ["Ge\u00b7d\u00f6r\u00b7te", "\u00e4\u00b7hern", "gab", "er", "jhr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVFIN", "PPER", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.124": {"text": "Die man sonst nennet Sangen:", "tokens": ["Die", "man", "sonst", "nen\u00b7net", "San\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.125": {"text": "Sie a\u00df sich mit den andern satt/", "tokens": ["Sie", "a\u00df", "sich", "mit", "den", "an\u00b7dern", "satt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "ADJA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.126": {"text": "Stund wieder auff zu lesen/", "tokens": ["Stund", "wie\u00b7der", "auff", "zu", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.127": {"text": "Von Sangen sie noch uber hatt/", "tokens": ["Von", "San\u00b7gen", "sie", "noch", "u\u00b7ber", "hatt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "ADV", "ADV", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.128": {"text": "Die zur mahlzeit gewesen.", "tokens": ["Die", "zur", "mahl\u00b7zeit", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.129": {"text": "Boas zu seinem knaben sprach:", "tokens": ["Boas", "zu", "sei\u00b7nem", "kna\u00b7ben", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.130": {"text": "Ihr solt sie nicht besch\u00e4men", "tokens": ["Ihr", "solt", "sie", "nicht", "be\u00b7sch\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.131": {"text": "Sondern lasset was bleiben nach/", "tokens": ["Son\u00b7dern", "las\u00b7set", "was", "blei\u00b7ben", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "VVINF", "APPR", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.132": {"text": "Davon sie m\u00f6g auffnemen;", "tokens": ["Da\u00b7von", "sie", "m\u00f6g", "auff\u00b7ne\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.133": {"text": "Auch von dem hauffen ligen last/", "tokens": ["Auch", "von", "dem", "hauf\u00b7fen", "li\u00b7gen", "last", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.134": {"text": "Als ob jhr es nicht achtet;", "tokens": ["Als", "ob", "jhr", "es", "nicht", "ach\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.135": {"text": "Sie ist bey uns frembd wie ein Gast/", "tokens": ["Sie", "ist", "bey", "uns", "frembd", "wie", "ein", "Gast", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADJD", "KOKOM", "ART", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.136": {"text": "Ihr noth bey euch betrachtet.", "tokens": ["Ihr", "noth", "bey", "euch", "be\u00b7trach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.137": {"text": "Also lase sie fleissig auff/", "tokens": ["Al\u00b7so", "la\u00b7se", "sie", "fleis\u00b7sig", "auff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.138": {"text": "Vnd war dasmal zum ersten/", "tokens": ["Vnd", "war", "das\u00b7mal", "zum", "ers\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPRART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.139": {"text": "So sie gesamlet hatt zu hauff/", "tokens": ["So", "sie", "ge\u00b7sam\u00b7let", "hatt", "zu", "hauff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "VAFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.140": {"text": "Bey einem Epha gersten;", "tokens": ["Bey", "ei\u00b7nem", "E\u00b7pha", "gers\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.141": {"text": "Da sie es hatt geschlagen au\u00df/", "tokens": ["Da", "sie", "es", "hatt", "ge\u00b7schla\u00b7gen", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VVPP", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.142": {"text": "Sie hub es auff zu tragen/", "tokens": ["Sie", "hub", "es", "auff", "zu", "tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.143": {"text": "Kam damit in die Statt zu hau\u00df:", "tokens": ["Kam", "da\u00b7mit", "in", "die", "Statt", "zu", "hau\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.144": {"text": "Naemi sprach mit fragen/", "tokens": ["Nae\u00b7mi", "sprach", "mit", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.145": {"text": "Da sie di\u00df all's gesehen hatt", "tokens": ["Da", "sie", "di\u00df", "all's", "ge\u00b7se\u00b7hen", "hatt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "PIS", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.146": {"text": "Vnd von der Ruth empfangen", "tokens": ["Vnd", "von", "der", "Ruth", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.147": {"text": "Das/ davon sie war g'worden satt/", "tokens": ["Das", "/", "da\u00b7von", "sie", "war", "g'\u00b7wor\u00b7den", "satt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PAV", "PPER", "VAFIN", "ADJD", "ADJD", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.148": {"text": "Auch g'blieben nach von Sangen:", "tokens": ["Auch", "g'\u00b7blie\u00b7ben", "nach", "von", "San\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.149": {"text": "Mein Tochter wo bist g'wesen heut", "tokens": ["Mein", "Toch\u00b7ter", "wo", "bist", "g'\u00b7we\u00b7sen", "heut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PWAV", "VAFIN", "ADJD", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.150": {"text": "Vnd wo bistu herkommen?", "tokens": ["Vnd", "wo", "bis\u00b7tu", "her\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.151": {"text": "Es m\u00fcssen g'wi\u00df seyn gute Leut", "tokens": ["Es", "m\u00fcs\u00b7sen", "g'\u00b7wi\u00df", "seyn", "gu\u00b7te", "Leut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.152": {"text": "Die dich hab'n angenommen.", "tokens": ["Die", "dich", "hab'n", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.153": {"text": "Sie gab es zuerkennen ihr/", "tokens": ["Sie", "gab", "es", "zu\u00b7er\u00b7ken\u00b7nen", "ihr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.154": {"text": "Sprach: da ich hab gelesen", "tokens": ["Sprach", ":", "da", "ich", "hab", "ge\u00b7le\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "KOUS", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.155": {"text": "Vnd der di\u00df all's hat geben mir", "tokens": ["Vnd", "der", "di\u00df", "all's", "hat", "ge\u00b7ben", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PDS", "PIS", "VAFIN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.156": {"text": "Ist der Boas gewesen.", "tokens": ["Ist", "der", "Boas", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VAPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.157": {"text": "Naemi sprach zu ihrer Schnur/", "tokens": ["Nae\u00b7mi", "sprach", "zu", "ih\u00b7rer", "Schnur", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.158": {"text": "Der Mann ist mein bekanter/", "tokens": ["Der", "Mann", "ist", "mein", "be\u00b7kan\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.159": {"text": "Mein Tochter sey zu frieden nur/", "tokens": ["Mein", "Toch\u00b7ter", "sey", "zu", "frie\u00b7den", "nur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.160": {"text": "Er ist meins Manns Verwanter/", "tokens": ["Er", "ist", "meins", "Manns", "Ver\u00b7wan\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.161": {"text": "Vnd Erb/ ein solcher frommer Mann/", "tokens": ["Vnd", "Erb", "/", "ein", "sol\u00b7cher", "from\u00b7mer", "Mann", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "ART", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "Der nicht hat unterlassen", "tokens": ["Der", "nicht", "hat", "un\u00b7ter\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "VAFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.163": {"text": "Sein G\u00fctigkeit zu zeigen an", "tokens": ["Sein", "G\u00fc\u00b7tig\u00b7keit", "zu", "zei\u00b7gen", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.164": {"text": "Thut unser sich anmassen.", "tokens": ["Thut", "un\u00b7ser", "sich", "an\u00b7mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.165": {"text": "An den Todten und Vns hat er", "tokens": ["An", "den", "Tod\u00b7ten", "und", "Vns", "hat", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "PPER", "VAFIN", "PPER"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.166": {"text": "Barmhertzigkeit beweiset;", "tokens": ["Barm\u00b7hert\u00b7zig\u00b7keit", "be\u00b7wei\u00b7set", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.167": {"text": "Geseg'n ihn daf\u00fcr Gott der Herr/", "tokens": ["Ge\u00b7seg'n", "ihn", "da\u00b7f\u00fcr", "Gott", "der", "Herr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PAV", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.168": {"text": "Den er mit gutthat preiset.", "tokens": ["Den", "er", "mit", "gut\u00b7that", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.169": {"text": "Ruth wieder zu Naemi sprach/", "tokens": ["Ruth", "wie\u00b7der", "zu", "Nae\u00b7mi", "sprach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NE", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.170": {"text": "Der Mann sagt mir imgleichen/", "tokens": ["Der", "Mann", "sagt", "mir", "im\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.171": {"text": "Ich solt sein'n Dirnen folgen nach/", "tokens": ["Ich", "solt", "sein'n", "Dir\u00b7nen", "fol\u00b7gen", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVFIN", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.172": {"text": "Vnd nicht von ihnen weichen/", "tokens": ["Vnd", "nicht", "von", "ih\u00b7nen", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.173": {"text": "Bi\u00df alles Korn zu hau\u00df gebracht/", "tokens": ["Bi\u00df", "al\u00b7les", "Korn", "zu", "hau\u00df", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.174": {"text": "Solt auch mit jhnen essen/", "tokens": ["Solt", "auch", "mit", "jh\u00b7nen", "es\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.175": {"text": "Solch wort hat er zu mir gesagt/", "tokens": ["Solch", "wort", "hat", "er", "zu", "mir", "ge\u00b7sagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.176": {"text": "Die ich nicht kan vergessen.", "tokens": ["Die", "ich", "nicht", "kan", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VMFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.177": {"text": "Naemi sprach ja/ das ist gut/", "tokens": ["Nae\u00b7mi", "sprach", "ja", "/", "das", "ist", "gut", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$(", "PDS", "VAFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.178": {"text": "Da\u00df du mit jhnen gehest;", "tokens": ["Da\u00df", "du", "mit", "jh\u00b7nen", "ge\u00b7hest", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.179": {"text": "Niemand dir da einreden thut/", "tokens": ["Nie\u00b7mand", "dir", "da", "ein\u00b7re\u00b7den", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "ADV", "VVINF", "VVFIN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.180": {"text": "Wie du di\u00df wol verstehest.", "tokens": ["Wie", "du", "di\u00df", "wol", "ver\u00b7ste\u00b7hest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.181": {"text": "Also die Ruth zu ihnen sich", "tokens": ["Al\u00b7so", "die", "Ruth", "zu", "ih\u00b7nen", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "PPER", "PRF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.182": {"text": "Bald widerumb gesellte/", "tokens": ["Bald", "wi\u00b7de\u00b7rumb", "ge\u00b7sell\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.183": {"text": "Vnd la\u00df/ wie vor geredet ich/", "tokens": ["Vnd", "la\u00df", "/", "wie", "vor", "ge\u00b7re\u00b7det", "ich", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$(", "KOKOM", "APPR", "VVPP", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.184": {"text": "Da \u00e4hren auff im Felde/", "tokens": ["Da", "\u00e4h\u00b7ren", "auff", "im", "Fel\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.185": {"text": "Bey Boas Volck: wolt zu der zeit", "tokens": ["Bey", "Boas", "Volck", ":", "wolt", "zu", "der", "zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "$.", "VMFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.186": {"text": "Auff ander Feld nicht gehen/", "tokens": ["Auff", "an\u00b7der", "Feld", "nicht", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.187": {"text": "Bi\u00df da\u00df an Gerst und Weitzen beid", "tokens": ["Bi\u00df", "da\u00df", "an", "Gerst", "und", "Weit\u00b7zen", "beid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "APPR", "NN", "KON", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.188": {"text": "Die Ernd da war geschehen.", "tokens": ["Die", "Ernd", "da", "war", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.189": {"text": "Darnach sie zu Hau\u00df wider kehrt/", "tokens": ["Dar\u00b7nach", "sie", "zu", "Hau\u00df", "wi\u00b7der", "kehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "NN", "PTKVZ", "VVFIN", "$("], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.190": {"text": "Naemi zu ernehren/", "tokens": ["Nae\u00b7mi", "zu", "er\u00b7neh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PTKZU", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.191": {"text": "Die sie als jhre Mutter ehrt/", "tokens": ["Die", "sie", "als", "jhre", "Mut\u00b7ter", "ehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.192": {"text": "Wolt nicht mehr au\u00df begehren.", "tokens": ["Wolt", "nicht", "mehr", "au\u00df", "be\u00b7geh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "APPR", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Es war ein Mann/ vernehmet recht/", "tokens": ["Es", "war", "ein", "Mann", "/", "ver\u00b7neh\u00b7met", "recht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tapffer und reich von G\u00fcter/", "tokens": ["Tapf\u00b7fer", "und", "reich", "von", "G\u00fc\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPR", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Eli Melechs freund von geschlecht/", "tokens": ["E\u00b7li", "Me\u00b7lechs", "freund", "von", "ge\u00b7schlecht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "APPR", "VVPP", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Auch ein Bethlehemiter.", "tokens": ["Auch", "ein", "Beth\u00b7le\u00b7he\u00b7mi\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Ein feiner Mann Boas genandt/", "tokens": ["Ein", "fei\u00b7ner", "Mann", "Boas", "ge\u00b7nandt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VVPP", "$("], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Der lie\u00df auch Gersten schneiden;", "tokens": ["Der", "lie\u00df", "auch", "Gers\u00b7ten", "schnei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Naemi war er wol bekandt/", "tokens": ["Nae\u00b7mi", "war", "er", "wol", "be\u00b7kandt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Die mit Ruth sa\u00df in leiden/", "tokens": ["Die", "mit", "Ruth", "sa\u00df", "in", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVFIN", "APPR", "VVINF", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.9": {"text": "Einsam/ und beyde nehrten sich", "tokens": ["Ein\u00b7sam", "/", "und", "bey\u00b7de", "nehr\u00b7ten", "sich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$(", "KON", "PIS", "VVFIN", "PRF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Durch das werck ihrer h\u00e4nde/", "tokens": ["Durch", "das", "werck", "ih\u00b7rer", "h\u00e4n\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "ADJA", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "Wie arme Witwen k\u00fcmmerlich/", "tokens": ["Wie", "ar\u00b7me", "Wit\u00b7wen", "k\u00fcm\u00b7mer\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Pflegen in ihrm Elende.", "tokens": ["Pfle\u00b7gen", "in", "ihrm", "E\u00b7len\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.13": {"text": "Es war gering ihr beyder sach/", "tokens": ["Es", "war", "ge\u00b7ring", "ihr", "bey\u00b7der", "sach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Vormals besser gewesen/", "tokens": ["Vor\u00b7mals", "bes\u00b7ser", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAPP", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.15": {"text": "Darumb Ruth zu Naemi sprach:", "tokens": ["Da\u00b7rumb", "Ruth", "zu", "Nae\u00b7mi", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.16": {"text": "Last mich gehn und aufflesen", "tokens": ["Last", "mich", "gehn", "und", "auf\u00b7fle\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "VVINF", "KON", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.17": {"text": "\u00c4hern auffs feld dem nach/ f\u00fcr dem", "tokens": ["\u00c4\u00b7hern", "auffs", "feld", "dem", "nach", "/", "f\u00fcr", "dem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPRART", "NN", "ART", "APPR", "$(", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Ich gnad und gunst itzt finde/", "tokens": ["Ich", "gnad", "und", "gunst", "itzt", "fin\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Vnd da ich seyn werd angenehm/", "tokens": ["Vnd", "da", "ich", "seyn", "werd", "an\u00b7ge\u00b7nehm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAINF", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Im feld bey dem Gesinde.", "tokens": ["Im", "feld", "bey", "dem", "Ge\u00b7sin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Geh hin mein Tochter/ antwort sie/", "tokens": ["Geh", "hin", "mein", "Toch\u00b7ter", "/", "ant\u00b7wort", "sie", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "$(", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Ich will es dir nicht wehren/", "tokens": ["Ich", "will", "es", "dir", "nicht", "weh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Bring was zu hau\u00df da\u00df wir uns hie", "tokens": ["Bring", "was", "zu", "hau\u00df", "da\u00df", "wir", "uns", "hie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "NN", "KOUS", "PPER", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "M\u00f6gen davon ernehren.", "tokens": ["M\u00f6\u00b7gen", "da\u00b7von", "er\u00b7neh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PAV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.25": {"text": "Sie ging hin/ merckt doch was geschicht/", "tokens": ["Sie", "ging", "hin", "/", "merckt", "doch", "was", "ge\u00b7schicht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$(", "VVFIN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Vnd kam auff Boas Acker/", "tokens": ["Vnd", "kam", "auff", "Boas", "A\u00b7cker", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.27": {"text": "Jedoch den Mann sie kante nicht/", "tokens": ["Je\u00b7doch", "den", "Mann", "sie", "kan\u00b7te", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "VMFIN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Sie la\u00df die \u00e4hern wacker", "tokens": ["Sie", "la\u00df", "die", "\u00e4\u00b7hern", "wa\u00b7cker"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Den Schnittern nach. Boas der Mann", "tokens": ["Den", "Schnit\u00b7tern", "nach", ".", "Boas", "der", "Mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "NE", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.30": {"text": "Von Bethlehem kam gangen/", "tokens": ["Von", "Beth\u00b7le\u00b7hem", "kam", "gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "Er sprach die Schnitter also an:", "tokens": ["Er", "sprach", "die", "Schnit\u00b7ter", "al\u00b7so", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Was ihr habt angefangen/", "tokens": ["Was", "ihr", "habt", "an\u00b7ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.33": {"text": "Das geh in Gottes Namen fort/", "tokens": ["Das", "geh", "in", "Got\u00b7tes", "Na\u00b7men", "fort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Der sey mit euch im wercke.", "tokens": ["Der", "sey", "mit", "euch", "im", "wer\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "Danck habt/ war wider jhr antwort/", "tokens": ["Danck", "habt", "/", "war", "wi\u00b7der", "jhr", "ant\u00b7wort", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$(", "VAFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Der Herr sey ewer st\u00e4rcke.", "tokens": ["Der", "Herr", "sey", "e\u00b7wer", "st\u00e4r\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.37": {"text": "Boas sah Ruth auch da im Feld/", "tokens": ["Boas", "sah", "Ruth", "auch", "da", "im", "Feld", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "ADV", "ADV", "APPRART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.38": {"text": "Vnd sprach zu seinem Knaben", "tokens": ["Vnd", "sprach", "zu", "sei\u00b7nem", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.39": {"text": "Der ubr die Schnitter war gestellt:", "tokens": ["Der", "ubr", "die", "Schnit\u00b7ter", "war", "ge\u00b7stellt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Was will die Dirne haben?", "tokens": ["Was", "will", "die", "Dir\u00b7ne", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.41": {"text": "Wes ist sie? Der Knab gab bescheit:", "tokens": ["Wes", "ist", "sie", "?", "Der", "Knab", "gab", "be\u00b7scheit", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "$.", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.42": {"text": "Sie ist/ hab ich vernommen/", "tokens": ["Sie", "ist", "/", "hab", "ich", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.43": {"text": "Die von Moab vor wenig zeit", "tokens": ["Die", "von", "Mo\u00b7ab", "vor", "we\u00b7nig", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Ist mit Naemi kommen.", "tokens": ["Ist", "mit", "Nae\u00b7mi", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NE", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.45": {"text": "Ferner der Knab zu Boas sprach:", "tokens": ["Fer\u00b7ner", "der", "Knab", "zu", "Boas", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.46": {"text": "Sie ist hie heut gewesen", "tokens": ["Sie", "ist", "hie", "heut", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VAPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.47": {"text": "Bey uns im Feld den gantzen Tag.", "tokens": ["Bey", "uns", "im", "Feld", "den", "gant\u00b7zen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Die \u00e4hern auffzulesen", "tokens": ["Die", "\u00e4\u00b7hern", "auff\u00b7zu\u00b7le\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Den schnittern nach; dieweil sie mich", "tokens": ["Den", "schnit\u00b7tern", "nach", ";", "die\u00b7weil", "sie", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "PTKVZ", "$.", "KOUS", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Drumb bath ihr di\u00df zu g\u00fcnnen/", "tokens": ["Drumb", "ba\u00b7th", "ihr", "di\u00df", "zu", "g\u00fcn\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PDS", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.51": {"text": "Solch ihre bitt an mich hab ich", "tokens": ["Solch", "ih\u00b7re", "bitt", "an", "mich", "hab", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "PPOSAT", "ADV", "APPR", "PPER", "VAFIN", "PPER"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.52": {"text": "Ihr nicht abschlagen k\u00f6nnen.", "tokens": ["Ihr", "nicht", "ab\u00b7schla\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.53": {"text": "Flei\u00dfig ist sie gewesen heut", "tokens": ["Flei\u00b7\u00dfig", "ist", "sie", "ge\u00b7we\u00b7sen", "heut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "VAPP", "ADV"], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.54": {"text": "Es geht ihr wol von handen/", "tokens": ["Es", "geht", "ihr", "wol", "von", "han\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.55": {"text": "Von morgen bi\u00df auff diese zeit", "tokens": ["Von", "mor\u00b7gen", "bi\u00df", "auff", "die\u00b7se", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "Ist sie bey uns gestanden.", "tokens": ["Ist", "sie", "bey", "uns", "ge\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.57": {"text": "Da ging Boas selbst hin zu ihr/", "tokens": ["Da", "ging", "Boas", "selbst", "hin", "zu", "ihr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ADV", "ADV", "APPR", "PPOSAT", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.58": {"text": "Sprach mit freundtlichen worten:", "tokens": ["Sprach", "mit", "freundt\u00b7li\u00b7chen", "wor\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.59": {"text": "Meine Tochter gehorche mir", "tokens": ["Mei\u00b7ne", "Toch\u00b7ter", "ge\u00b7hor\u00b7che", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.60": {"text": "Vnd bleib an diesen Orten/", "tokens": ["Vnd", "bleib", "an", "die\u00b7sen", "Or\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.61": {"text": "Es soll dir nichts zu leid geschehn/", "tokens": ["Es", "soll", "dir", "nichts", "zu", "leid", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "PTKA", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Darumb geh' nicht von hinnen/", "tokens": ["Da\u00b7rumb", "geh'", "nicht", "von", "hin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PTKNEG", "APPR", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.63": {"text": "Mit meinen Dirnen soltu gehn/", "tokens": ["Mit", "mei\u00b7nen", "Dir\u00b7nen", "sol\u00b7tu", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Die dich anleiten k\u00f6nnen/", "tokens": ["Die", "dich", "an\u00b7lei\u00b7ten", "k\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.65": {"text": "Da sie schneiden/ geh' jhnen nach/", "tokens": ["Da", "sie", "schnei\u00b7den", "/", "geh'", "jh\u00b7nen", "nach", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$(", "VVFIN", "PPER", "APPR", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.66": {"text": "Dem Volck hab ich gebotten", "tokens": ["Dem", "Volck", "hab", "ich", "ge\u00b7bot\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.67": {"text": "Da\u00df keiner dich antast/ er sprach/", "tokens": ["Da\u00df", "kei\u00b7ner", "dich", "an\u00b7tast", "/", "er", "sprach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.68": {"text": "Oder sonst soll verspotten.", "tokens": ["O\u00b7der", "sonst", "soll", "ver\u00b7spot\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.69": {"text": "Vnd so dich durst/ geh hin zum krug/", "tokens": ["Vnd", "so", "dich", "durst", "/", "geh", "hin", "zum", "krug", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "ADV", "$(", "VVFIN", "ADV", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Vnd trinck mit meinen Knaben/", "tokens": ["Vnd", "trinck", "mit", "mei\u00b7nen", "Kna\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.71": {"text": "Es wird f\u00fcr dir auch seyn genug/", "tokens": ["Es", "wird", "f\u00fcr", "dir", "auch", "seyn", "ge\u00b7nug", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "PPOSAT", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "Dein hertz damit zu laben.", "tokens": ["Dein", "hertz", "da\u00b7mit", "zu", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.73": {"text": "Da fiel sie auff ihr angesicht/", "tokens": ["Da", "fiel", "sie", "auff", "ihr", "an\u00b7ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "Dem\u00fctig sie ihn ehret/", "tokens": ["De\u00b7m\u00fc\u00b7tig", "sie", "ihn", "eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.75": {"text": "Sprach: Ich hab je verdienet nicht", "tokens": ["Sprach", ":", "Ich", "hab", "je", "ver\u00b7die\u00b7net", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "VAFIN", "ADV", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.76": {"text": "Das mir itzt widerf\u00e4hret/", "tokens": ["Das", "mir", "itzt", "wi\u00b7der\u00b7f\u00e4h\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.77": {"text": "Ich wei\u00df auch nicht in meinem sinn", "tokens": ["Ich", "wei\u00df", "auch", "nicht", "in", "mei\u00b7nem", "sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Womit ich gnad bekommen/", "tokens": ["Wo\u00b7mit", "ich", "gnad", "be\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.79": {"text": "Die ich doch hie ein Frembde bin.", "tokens": ["Die", "ich", "doch", "hie", "ein", "Fremb\u00b7de", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "Er sprach ich hab vernommen/", "tokens": ["Er", "sprach", "ich", "hab", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.81": {"text": "Da\u00df du nach deines Mannes todt/", "tokens": ["Da\u00df", "du", "nach", "dei\u00b7nes", "Man\u00b7nes", "todt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "Hast wollen nicht verlassen", "tokens": ["Hast", "wol\u00b7len", "nicht", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.83": {"text": "Dein Schwieger Mutter in der noth/", "tokens": ["Dein", "Schwie\u00b7ger", "Mut\u00b7ter", "in", "der", "noth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.84": {"text": "Sondern mit jhr die strassen", "tokens": ["Son\u00b7dern", "mit", "jhr", "die", "stras\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.85": {"text": "Gezogen bist im frembden Landt/", "tokens": ["Ge\u00b7zo\u00b7gen", "bist", "im", "fremb\u00b7den", "Landt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.86": {"text": "Hast ihr viel guts erzeiget;", "tokens": ["Hast", "ihr", "viel", "guts", "er\u00b7zei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.87": {"text": "Bey einem Volck dir unbekant", "tokens": ["Bey", "ei\u00b7nem", "Volck", "dir", "un\u00b7be\u00b7kant"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.88": {"text": "Zu bleiben bist geneiget.", "tokens": ["Zu", "blei\u00b7ben", "bist", "ge\u00b7nei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.89": {"text": "Der Herr vergelt dir deine that/", "tokens": ["Der", "Herr", "ver\u00b7gelt", "dir", "dei\u00b7ne", "that", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "Vnd mach dein lohn vollkommen:", "tokens": ["Vnd", "mach", "dein", "lohn", "voll\u00b7kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.91": {"text": "Der zu dem Herren Zuflucht hat", "tokens": ["Der", "zu", "dem", "Her\u00b7ren", "Zu\u00b7flucht", "hat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "Wird von jhm angenommen.", "tokens": ["Wird", "von", "jhm", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.93": {"text": "Israels Gott sey immer zu", "tokens": ["Is\u00b7raels", "Gott", "sey", "im\u00b7mer", "zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NN", "VAFIN", "ADV", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.94": {"text": "Dein H\u00fclff und Trost im leben;", "tokens": ["Dein", "H\u00fclff", "und", "Trost", "im", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.95": {"text": "Vnter des fl\u00fcgeln jtzund du", "tokens": ["Vn\u00b7ter", "des", "fl\u00fc\u00b7geln", "jt\u00b7zund", "du"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVINF", "KON", "PPER"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.96": {"text": "Dich hast zu wohnen geben.", "tokens": ["Dich", "hast", "zu", "woh\u00b7nen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.97": {"text": "Ruth sich der wort erfrewen thet/", "tokens": ["Ruth", "sich", "der", "wort", "er\u00b7fre\u00b7wen", "thet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "ART", "NN", "VVINF", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.98": {"text": "Vnd antwort jhm dem\u00fctig:", "tokens": ["Vnd", "ant\u00b7wort", "jhm", "de\u00b7m\u00fc\u00b7tig", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.99": {"text": "Wie freundlich hat mein Herr geredt/", "tokens": ["Wie", "freund\u00b7lich", "hat", "mein", "Herr", "ge\u00b7redt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.100": {"text": "Vnd ist mir doch so g\u00fctig.", "tokens": ["Vnd", "ist", "mir", "doch", "so", "g\u00fc\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.101": {"text": "Nun ich f\u00fcr ewren augen gunst", "tokens": ["Nun", "ich", "f\u00fcr", "ew\u00b7ren", "au\u00b7gen", "gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "Vnd gnade hab gefunden/", "tokens": ["Vnd", "gna\u00b7de", "hab", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.103": {"text": "Wird von mir nichts begehret sonst/", "tokens": ["Wird", "von", "mir", "nichts", "be\u00b7ge\u00b7hret", "sonst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "PIS", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "Mein Leid ist mir verschwunden.", "tokens": ["Mein", "Leid", "ist", "mir", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.105": {"text": "Was solt ich doch begehren mehr", "tokens": ["Was", "solt", "ich", "doch", "be\u00b7geh\u00b7ren", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.106": {"text": "Denn ewer Gunst alleine?", "tokens": ["Denn", "e\u00b7wer", "Gunst", "al\u00b7lei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.107": {"text": "Weil ich geringer bin/ mein Herr/", "tokens": ["Weil", "ich", "ge\u00b7rin\u00b7ger", "bin", "/", "mein", "Herr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.108": {"text": "Als ewer M\u00e4gde eine.", "tokens": ["Als", "e\u00b7wer", "M\u00e4g\u00b7de", "ei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.109": {"text": "Er sprach zu jhr: Wenns essen zeit", "tokens": ["Er", "sprach", "zu", "jhr", ":", "Wenns", "es\u00b7sen", "zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "$.", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "Ist/ solt dich auch hernahen/", "tokens": ["Ist", "/", "solt", "dich", "auch", "her\u00b7na\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.111": {"text": "Vnd bey dem Volck nach der arbeit/", "tokens": ["Vnd", "bey", "dem", "Volck", "nach", "der", "ar\u00b7beit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.112": {"text": "Dein speise mit empfahen;", "tokens": ["Dein", "spei\u00b7se", "mit", "em\u00b7pfa\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.113": {"text": "Ihrer freyheit dich mit gebrauch/", "tokens": ["Ih\u00b7rer", "frey\u00b7heit", "dich", "mit", "ge\u00b7brauch", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "APPR", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.114": {"text": "Vnd tuncke deinen bissen", "tokens": ["Vnd", "tun\u00b7cke", "dei\u00b7nen", "bis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.115": {"text": "In essig wie die andern auch/", "tokens": ["In", "es\u00b7sig", "wie", "die", "an\u00b7dern", "auch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KOKOM", "ART", "ADJA", "ADV", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.116": {"text": "So spei\u00df einnehmen m\u00fcssen.", "tokens": ["So", "spei\u00df", "ein\u00b7neh\u00b7men", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.117": {"text": "Sie nam di\u00df an mit danckbarkeit/", "tokens": ["Sie", "nam", "di\u00df", "an", "mit", "dan\u00b7ck\u00b7bar\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "APPR", "APPR", "NN", "$("], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.118": {"text": "Dar\u00fcber sich ergetzte/", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "sich", "er\u00b7getz\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "PRF", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.119": {"text": "Vnd da es war zu essen zeit/", "tokens": ["Vnd", "da", "es", "war", "zu", "es\u00b7sen", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.120": {"text": "Sie sich mit nieder setzte.", "tokens": ["Sie", "sich", "mit", "nie\u00b7der", "setz\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPR", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.121": {"text": "Boas legt selbst zu essen f\u00fcr/", "tokens": ["Boas", "legt", "selbst", "zu", "es\u00b7sen", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKZU", "VVINF", "APPR", "$("], "meter": "+---+-+", "measure": "dactylic.init"}, "line.122": {"text": "Sie a\u00df/ er lie\u00df jhm langen", "tokens": ["Sie", "a\u00df", "/", "er", "lie\u00df", "jhm", "lan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.123": {"text": "Ged\u00f6rte \u00e4hern gab er jhr/", "tokens": ["Ge\u00b7d\u00f6r\u00b7te", "\u00e4\u00b7hern", "gab", "er", "jhr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVFIN", "PPER", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.124": {"text": "Die man sonst nennet Sangen:", "tokens": ["Die", "man", "sonst", "nen\u00b7net", "San\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.125": {"text": "Sie a\u00df sich mit den andern satt/", "tokens": ["Sie", "a\u00df", "sich", "mit", "den", "an\u00b7dern", "satt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "ADJA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.126": {"text": "Stund wieder auff zu lesen/", "tokens": ["Stund", "wie\u00b7der", "auff", "zu", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.127": {"text": "Von Sangen sie noch uber hatt/", "tokens": ["Von", "San\u00b7gen", "sie", "noch", "u\u00b7ber", "hatt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "ADV", "ADV", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.128": {"text": "Die zur mahlzeit gewesen.", "tokens": ["Die", "zur", "mahl\u00b7zeit", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.129": {"text": "Boas zu seinem knaben sprach:", "tokens": ["Boas", "zu", "sei\u00b7nem", "kna\u00b7ben", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.130": {"text": "Ihr solt sie nicht besch\u00e4men", "tokens": ["Ihr", "solt", "sie", "nicht", "be\u00b7sch\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.131": {"text": "Sondern lasset was bleiben nach/", "tokens": ["Son\u00b7dern", "las\u00b7set", "was", "blei\u00b7ben", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "VVINF", "APPR", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.132": {"text": "Davon sie m\u00f6g auffnemen;", "tokens": ["Da\u00b7von", "sie", "m\u00f6g", "auff\u00b7ne\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.133": {"text": "Auch von dem hauffen ligen last/", "tokens": ["Auch", "von", "dem", "hauf\u00b7fen", "li\u00b7gen", "last", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.134": {"text": "Als ob jhr es nicht achtet;", "tokens": ["Als", "ob", "jhr", "es", "nicht", "ach\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.135": {"text": "Sie ist bey uns frembd wie ein Gast/", "tokens": ["Sie", "ist", "bey", "uns", "frembd", "wie", "ein", "Gast", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADJD", "KOKOM", "ART", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.136": {"text": "Ihr noth bey euch betrachtet.", "tokens": ["Ihr", "noth", "bey", "euch", "be\u00b7trach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.137": {"text": "Also lase sie fleissig auff/", "tokens": ["Al\u00b7so", "la\u00b7se", "sie", "fleis\u00b7sig", "auff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.138": {"text": "Vnd war dasmal zum ersten/", "tokens": ["Vnd", "war", "das\u00b7mal", "zum", "ers\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPRART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.139": {"text": "So sie gesamlet hatt zu hauff/", "tokens": ["So", "sie", "ge\u00b7sam\u00b7let", "hatt", "zu", "hauff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "VAFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.140": {"text": "Bey einem Epha gersten;", "tokens": ["Bey", "ei\u00b7nem", "E\u00b7pha", "gers\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.141": {"text": "Da sie es hatt geschlagen au\u00df/", "tokens": ["Da", "sie", "es", "hatt", "ge\u00b7schla\u00b7gen", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VVPP", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.142": {"text": "Sie hub es auff zu tragen/", "tokens": ["Sie", "hub", "es", "auff", "zu", "tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.143": {"text": "Kam damit in die Statt zu hau\u00df:", "tokens": ["Kam", "da\u00b7mit", "in", "die", "Statt", "zu", "hau\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.144": {"text": "Naemi sprach mit fragen/", "tokens": ["Nae\u00b7mi", "sprach", "mit", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.145": {"text": "Da sie di\u00df all's gesehen hatt", "tokens": ["Da", "sie", "di\u00df", "all's", "ge\u00b7se\u00b7hen", "hatt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "PIS", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.146": {"text": "Vnd von der Ruth empfangen", "tokens": ["Vnd", "von", "der", "Ruth", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.147": {"text": "Das/ davon sie war g'worden satt/", "tokens": ["Das", "/", "da\u00b7von", "sie", "war", "g'\u00b7wor\u00b7den", "satt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PAV", "PPER", "VAFIN", "ADJD", "ADJD", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.148": {"text": "Auch g'blieben nach von Sangen:", "tokens": ["Auch", "g'\u00b7blie\u00b7ben", "nach", "von", "San\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.149": {"text": "Mein Tochter wo bist g'wesen heut", "tokens": ["Mein", "Toch\u00b7ter", "wo", "bist", "g'\u00b7we\u00b7sen", "heut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PWAV", "VAFIN", "ADJD", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.150": {"text": "Vnd wo bistu herkommen?", "tokens": ["Vnd", "wo", "bis\u00b7tu", "her\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.151": {"text": "Es m\u00fcssen g'wi\u00df seyn gute Leut", "tokens": ["Es", "m\u00fcs\u00b7sen", "g'\u00b7wi\u00df", "seyn", "gu\u00b7te", "Leut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.152": {"text": "Die dich hab'n angenommen.", "tokens": ["Die", "dich", "hab'n", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.153": {"text": "Sie gab es zuerkennen ihr/", "tokens": ["Sie", "gab", "es", "zu\u00b7er\u00b7ken\u00b7nen", "ihr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.154": {"text": "Sprach: da ich hab gelesen", "tokens": ["Sprach", ":", "da", "ich", "hab", "ge\u00b7le\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "KOUS", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.155": {"text": "Vnd der di\u00df all's hat geben mir", "tokens": ["Vnd", "der", "di\u00df", "all's", "hat", "ge\u00b7ben", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PDS", "PIS", "VAFIN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.156": {"text": "Ist der Boas gewesen.", "tokens": ["Ist", "der", "Boas", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VAPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.157": {"text": "Naemi sprach zu ihrer Schnur/", "tokens": ["Nae\u00b7mi", "sprach", "zu", "ih\u00b7rer", "Schnur", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.158": {"text": "Der Mann ist mein bekanter/", "tokens": ["Der", "Mann", "ist", "mein", "be\u00b7kan\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.159": {"text": "Mein Tochter sey zu frieden nur/", "tokens": ["Mein", "Toch\u00b7ter", "sey", "zu", "frie\u00b7den", "nur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.160": {"text": "Er ist meins Manns Verwanter/", "tokens": ["Er", "ist", "meins", "Manns", "Ver\u00b7wan\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.161": {"text": "Vnd Erb/ ein solcher frommer Mann/", "tokens": ["Vnd", "Erb", "/", "ein", "sol\u00b7cher", "from\u00b7mer", "Mann", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "ART", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "Der nicht hat unterlassen", "tokens": ["Der", "nicht", "hat", "un\u00b7ter\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "VAFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.163": {"text": "Sein G\u00fctigkeit zu zeigen an", "tokens": ["Sein", "G\u00fc\u00b7tig\u00b7keit", "zu", "zei\u00b7gen", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.164": {"text": "Thut unser sich anmassen.", "tokens": ["Thut", "un\u00b7ser", "sich", "an\u00b7mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.165": {"text": "An den Todten und Vns hat er", "tokens": ["An", "den", "Tod\u00b7ten", "und", "Vns", "hat", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "PPER", "VAFIN", "PPER"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.166": {"text": "Barmhertzigkeit beweiset;", "tokens": ["Barm\u00b7hert\u00b7zig\u00b7keit", "be\u00b7wei\u00b7set", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.167": {"text": "Geseg'n ihn daf\u00fcr Gott der Herr/", "tokens": ["Ge\u00b7seg'n", "ihn", "da\u00b7f\u00fcr", "Gott", "der", "Herr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PAV", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.168": {"text": "Den er mit gutthat preiset.", "tokens": ["Den", "er", "mit", "gut\u00b7that", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.169": {"text": "Ruth wieder zu Naemi sprach/", "tokens": ["Ruth", "wie\u00b7der", "zu", "Nae\u00b7mi", "sprach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NE", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.170": {"text": "Der Mann sagt mir imgleichen/", "tokens": ["Der", "Mann", "sagt", "mir", "im\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.171": {"text": "Ich solt sein'n Dirnen folgen nach/", "tokens": ["Ich", "solt", "sein'n", "Dir\u00b7nen", "fol\u00b7gen", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVFIN", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.172": {"text": "Vnd nicht von ihnen weichen/", "tokens": ["Vnd", "nicht", "von", "ih\u00b7nen", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.173": {"text": "Bi\u00df alles Korn zu hau\u00df gebracht/", "tokens": ["Bi\u00df", "al\u00b7les", "Korn", "zu", "hau\u00df", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.174": {"text": "Solt auch mit jhnen essen/", "tokens": ["Solt", "auch", "mit", "jh\u00b7nen", "es\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.175": {"text": "Solch wort hat er zu mir gesagt/", "tokens": ["Solch", "wort", "hat", "er", "zu", "mir", "ge\u00b7sagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.176": {"text": "Die ich nicht kan vergessen.", "tokens": ["Die", "ich", "nicht", "kan", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VMFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.177": {"text": "Naemi sprach ja/ das ist gut/", "tokens": ["Nae\u00b7mi", "sprach", "ja", "/", "das", "ist", "gut", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$(", "PDS", "VAFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.178": {"text": "Da\u00df du mit jhnen gehest;", "tokens": ["Da\u00df", "du", "mit", "jh\u00b7nen", "ge\u00b7hest", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.179": {"text": "Niemand dir da einreden thut/", "tokens": ["Nie\u00b7mand", "dir", "da", "ein\u00b7re\u00b7den", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "ADV", "VVINF", "VVFIN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.180": {"text": "Wie du di\u00df wol verstehest.", "tokens": ["Wie", "du", "di\u00df", "wol", "ver\u00b7ste\u00b7hest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.181": {"text": "Also die Ruth zu ihnen sich", "tokens": ["Al\u00b7so", "die", "Ruth", "zu", "ih\u00b7nen", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "PPER", "PRF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.182": {"text": "Bald widerumb gesellte/", "tokens": ["Bald", "wi\u00b7de\u00b7rumb", "ge\u00b7sell\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.183": {"text": "Vnd la\u00df/ wie vor geredet ich/", "tokens": ["Vnd", "la\u00df", "/", "wie", "vor", "ge\u00b7re\u00b7det", "ich", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$(", "KOKOM", "APPR", "VVPP", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.184": {"text": "Da \u00e4hren auff im Felde/", "tokens": ["Da", "\u00e4h\u00b7ren", "auff", "im", "Fel\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.185": {"text": "Bey Boas Volck: wolt zu der zeit", "tokens": ["Bey", "Boas", "Volck", ":", "wolt", "zu", "der", "zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "$.", "VMFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.186": {"text": "Auff ander Feld nicht gehen/", "tokens": ["Auff", "an\u00b7der", "Feld", "nicht", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.187": {"text": "Bi\u00df da\u00df an Gerst und Weitzen beid", "tokens": ["Bi\u00df", "da\u00df", "an", "Gerst", "und", "Weit\u00b7zen", "beid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "APPR", "NN", "KON", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.188": {"text": "Die Ernd da war geschehen.", "tokens": ["Die", "Ernd", "da", "war", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.189": {"text": "Darnach sie zu Hau\u00df wider kehrt/", "tokens": ["Dar\u00b7nach", "sie", "zu", "Hau\u00df", "wi\u00b7der", "kehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "NN", "PTKVZ", "VVFIN", "$("], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.190": {"text": "Naemi zu ernehren/", "tokens": ["Nae\u00b7mi", "zu", "er\u00b7neh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PTKZU", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.191": {"text": "Die sie als jhre Mutter ehrt/", "tokens": ["Die", "sie", "als", "jhre", "Mut\u00b7ter", "ehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.192": {"text": "Wolt nicht mehr au\u00df begehren.", "tokens": ["Wolt", "nicht", "mehr", "au\u00df", "be\u00b7geh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "APPR", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}