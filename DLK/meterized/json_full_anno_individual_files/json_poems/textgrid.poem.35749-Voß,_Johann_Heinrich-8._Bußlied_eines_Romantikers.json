{"textgrid.poem.35749": {"metadata": {"author": {"name": "Vo\u00df, Johann Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "8. Bu\u00dflied eines Romantikers", "genre": "verse", "period": "N.A.", "pub_year": 1801, "urn": "N.A.", "language": ["de:0.85", "nl:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Alles, was mit Qual und Zoren", "tokens": ["Al\u00b7les", ",", "was", "mit", "Qual", "und", "Zo\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir gedudelt, geht verloren;", "tokens": ["Wir", "ge\u00b7du\u00b7delt", ",", "geht", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat's auch kein Prophet beschworen.", "tokens": ["Hat's", "auch", "kein", "Pro\u00b7phet", "be\u00b7schwo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Welch ein Graun wird sein und Zagen,", "tokens": ["Welch", "ein", "Graun", "wird", "sein", "und", "Za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VAFIN", "PPOSAT", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Pr\u00fcft der Richter ernst mit Fragen", "tokens": ["Pr\u00fcft", "der", "Rich\u00b7ter", "ernst", "mit", "Fra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kleine so wie gro\u00dfe Klagen!", "tokens": ["Klei\u00b7ne", "so", "wie", "gro\u00b7\u00dfe", "Kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADV", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Hinposaunt mit Schreckentone,", "tokens": ["Hin\u00b7po\u00b7saunt", "mit", "Schre\u00b7cken\u00b7to\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gehen wir zum Richterthrone,", "tokens": ["Ge\u00b7hen", "wir", "zum", "Rich\u00b7ter\u00b7thro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer mit Geist gereimt, und ohne.", "tokens": ["Wer", "mit", "Geist", "ge\u00b7reimt", ",", "und", "oh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVPP", "$,", "KON", "KOUI", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auch mich Armen wird man sehen", "tokens": ["Auch", "mich", "Ar\u00b7men", "wird", "man", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "NN", "VAFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den S\u00fcndern auferstehen,", "tokens": ["Mit", "den", "S\u00fcn\u00b7dern", "auf\u00b7er\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zur Verantwortung zu gehen.", "tokens": ["Zur", "Ver\u00b7ant\u00b7wor\u00b7tung", "zu", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}}, "stanza.5": {"line.1": {"text": "Manches B\u00fcchlein wird entfalten,", "tokens": ["Man\u00b7ches", "B\u00fcch\u00b7lein", "wird", "ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie wir, feind den hohen Alten,", "tokens": ["Wie", "wir", ",", "feind", "den", "ho\u00b7hen", "Al\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier modern-romantisch lallten.", "tokens": ["Hier", "mo\u00b7dern\u00b7ro\u00b7man\u00b7tisch", "lall\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Ohn' Erbarmen wird gerichtet,", "tokens": ["Ohn'", "Er\u00b7bar\u00b7men", "wird", "ge\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was wir, gleich als w\u00e4r's gedichtet,", "tokens": ["Was", "wir", ",", "gleich", "als", "w\u00e4r's", "ge\u00b7dich\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "$,", "ADV", "KOKOM", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Firlefanzisch aufgeschichtet.", "tokens": ["Fir\u00b7le\u00b7fan\u00b7zisch", "auf\u00b7ge\u00b7schich\u00b7tet", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ach, was werd' ich Armer sagen,", "tokens": ["Ach", ",", "was", "werd'", "ich", "Ar\u00b7mer", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wann der Kunst Geweihte klagen,", "tokens": ["Wann", "der", "Kunst", "Ge\u00b7weih\u00b7te", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wir S\u00fcd-Kunstmacher zagen?", "tokens": ["Und", "wir", "S\u00fcd\u00b7Kunst\u00b7ma\u00b7cher", "za\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Gnade, ruf' ich, Herr, mir Knaben!", "tokens": ["Gna\u00b7de", ",", "ruf'", "ich", ",", "Herr", ",", "mir", "Kna\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "NN", "$,", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frei ja gabst du deine Gaben;", "tokens": ["Frei", "ja", "gabst", "du", "dei\u00b7ne", "Ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Konntest du mich auch nicht laben?", "tokens": ["Konn\u00b7test", "du", "mich", "auch", "nicht", "la\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Thatst du (woll' es, Herr, erw\u00e4gen!)", "tokens": ["Thatst", "du", "(", "woll'", "es", ",", "Herr", ",", "er\u00b7w\u00e4\u00b7gen", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$(", "VMFIN", "PPER", "$,", "NN", "$,", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Je ein Wunder meinetwegen,", "tokens": ["Je", "ein", "Wun\u00b7der", "mei\u00b7net\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein Gem\u00fct mit Kraft zu pflegen?", "tokens": ["Mein", "Ge\u00b7m\u00fct", "mit", "Kraft", "zu", "pfle\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Trotz dem Angstschwei\u00df meines Strebens,", "tokens": ["Trotz", "dem", "A\u00b7ngstschwei\u00df", "mei\u00b7nes", "Stre\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nachzu\u00e4ffen Geist des Lebens;", "tokens": ["Nach\u00b7zu\u00b7\u00e4f\u00b7fen", "Geist", "des", "Le\u00b7bens", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle M\u00fche war vergebens!", "tokens": ["Al\u00b7le", "M\u00fc\u00b7he", "war", "ver\u00b7ge\u00b7bens", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Richter der gerechten Rache,", "tokens": ["Rich\u00b7ter", "der", "ge\u00b7rech\u00b7ten", "Ra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nachsicht \u00fcb' in meiner Sache,", "tokens": ["Nach\u00b7sicht", "\u00fcb'", "in", "mei\u00b7ner", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ich, wie ich kann, es mache.", "tokens": ["Wenn", "ich", ",", "wie", "ich", "kann", ",", "es", "ma\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Scham und Reue mu\u00df ich dulden;", "tokens": ["Scham", "und", "Reu\u00b7e", "mu\u00df", "ich", "dul\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tief err\u00f6t' ich ob den Schulden,", "tokens": ["Tief", "er\u00b7r\u00f6t'", "ich", "ob", "den", "Schul\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "KOUS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Kreuzer unter Gulden.", "tokens": ["Wie", "ein", "Kreu\u00b7zer", "un\u00b7ter", "Gul\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Hab' ich reimend mich verschrieen,", "tokens": ["Hab'", "ich", "rei\u00b7mend", "mich", "ver\u00b7schri\u00b7een", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du, der Sch\u00e4chern selbst verziehen,", "tokens": ["Du", ",", "der", "Sch\u00e4\u00b7chern", "selbst", "ver\u00b7zie\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df es gehn f\u00fcr Melodieen!", "tokens": ["La\u00df", "es", "gehn", "f\u00fcr", "Me\u00b7lo\u00b7di\u00b7e\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Achte nicht mein Schrei'n so teuer,", "tokens": ["Ach\u00b7te", "nicht", "mein", "Schrei'n", "so", "teu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich darum, o du Treuer,", "tokens": ["Da\u00df", "ich", "da\u00b7rum", ",", "o", "du", "Treu\u00b7er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "$,", "FM", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Brennen sollt' in ewgem Feuer.", "tokens": ["Bren\u00b7nen", "sollt'", "in", "ew\u00b7gem", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Zu den Schafen la\u00df mich kommen,", "tokens": ["Zu", "den", "Scha\u00b7fen", "la\u00df", "mich", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den st\u00f6\u00dfigen, nicht frommen,", "tokens": ["Von", "den", "st\u00f6\u00b7\u00dfi\u00b7gen", ",", "nicht", "from\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "PTKNEG", "ADJA", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Bundesb\u00f6cken ausgenommen.", "tokens": ["Bun\u00b7des\u00b7b\u00f6\u00b7cken", "aus\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Wird auch Feuer ohne Schonung", "tokens": ["Wird", "auch", "Feu\u00b7er", "oh\u00b7ne", "Scho\u00b7nung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinen Reimen zur Belohnung,", "tokens": ["Mei\u00b7nen", "Rei\u00b7men", "zur", "Be\u00b7loh\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nimm doch mich in deine Wohnung.", "tokens": ["Nimm", "doch", "mich", "in", "dei\u00b7ne", "Woh\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Herz, zerknirscht im tiefsten Grunde,", "tokens": ["Herz", ",", "zer\u00b7knirscht", "im", "tiefs\u00b7ten", "Grun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruf' Ade dem Schw\u00e4rmerbunde,", "tokens": ["Ruf'", "A\u00b7de", "dem", "Schw\u00e4r\u00b7mer\u00b7bun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df ich zu Vernunft gesunde!", "tokens": ["Da\u00df", "ich", "zu", "Ver\u00b7nunft", "ge\u00b7sun\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Wer ges\u00fcndigt hat mit Zoren,", "tokens": ["Wer", "ge\u00b7s\u00fcn\u00b7digt", "hat", "mit", "Zo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df dort ewig, ewig schmoren.", "tokens": ["Mu\u00df", "dort", "e\u00b7wig", ",", "e\u00b7wig", "schmo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "$,", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber mich, trotz meinen Schulden,", "tokens": ["A\u00b7ber", "mich", ",", "trotz", "mei\u00b7nen", "Schul\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimm ins Paradies mit Hulden.", "tokens": ["Nimm", "ins", "Pa\u00b7ra\u00b7dies", "mit", "Hul\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gieb mir Armen ewge Ruh,", "tokens": ["Gieb", "mir", "Ar\u00b7men", "ew\u00b7ge", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sei es auch \u2013 mit Kotzebu!", "tokens": ["Sei", "es", "auch", "\u2013", "mit", "Kot\u00b7ze\u00b7bu", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$(", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Alles, was mit Qual und Zoren", "tokens": ["Al\u00b7les", ",", "was", "mit", "Qual", "und", "Zo\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir gedudelt, geht verloren;", "tokens": ["Wir", "ge\u00b7du\u00b7delt", ",", "geht", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat's auch kein Prophet beschworen.", "tokens": ["Hat's", "auch", "kein", "Pro\u00b7phet", "be\u00b7schwo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Welch ein Graun wird sein und Zagen,", "tokens": ["Welch", "ein", "Graun", "wird", "sein", "und", "Za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VAFIN", "PPOSAT", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Pr\u00fcft der Richter ernst mit Fragen", "tokens": ["Pr\u00fcft", "der", "Rich\u00b7ter", "ernst", "mit", "Fra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kleine so wie gro\u00dfe Klagen!", "tokens": ["Klei\u00b7ne", "so", "wie", "gro\u00b7\u00dfe", "Kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADV", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Hinposaunt mit Schreckentone,", "tokens": ["Hin\u00b7po\u00b7saunt", "mit", "Schre\u00b7cken\u00b7to\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gehen wir zum Richterthrone,", "tokens": ["Ge\u00b7hen", "wir", "zum", "Rich\u00b7ter\u00b7thro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer mit Geist gereimt, und ohne.", "tokens": ["Wer", "mit", "Geist", "ge\u00b7reimt", ",", "und", "oh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVPP", "$,", "KON", "KOUI", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Auch mich Armen wird man sehen", "tokens": ["Auch", "mich", "Ar\u00b7men", "wird", "man", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "NN", "VAFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den S\u00fcndern auferstehen,", "tokens": ["Mit", "den", "S\u00fcn\u00b7dern", "auf\u00b7er\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zur Verantwortung zu gehen.", "tokens": ["Zur", "Ver\u00b7ant\u00b7wor\u00b7tung", "zu", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}}, "stanza.23": {"line.1": {"text": "Manches B\u00fcchlein wird entfalten,", "tokens": ["Man\u00b7ches", "B\u00fcch\u00b7lein", "wird", "ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie wir, feind den hohen Alten,", "tokens": ["Wie", "wir", ",", "feind", "den", "ho\u00b7hen", "Al\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier modern-romantisch lallten.", "tokens": ["Hier", "mo\u00b7dern\u00b7ro\u00b7man\u00b7tisch", "lall\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "Ohn' Erbarmen wird gerichtet,", "tokens": ["Ohn'", "Er\u00b7bar\u00b7men", "wird", "ge\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was wir, gleich als w\u00e4r's gedichtet,", "tokens": ["Was", "wir", ",", "gleich", "als", "w\u00e4r's", "ge\u00b7dich\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "$,", "ADV", "KOKOM", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Firlefanzisch aufgeschichtet.", "tokens": ["Fir\u00b7le\u00b7fan\u00b7zisch", "auf\u00b7ge\u00b7schich\u00b7tet", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Ach, was werd' ich Armer sagen,", "tokens": ["Ach", ",", "was", "werd'", "ich", "Ar\u00b7mer", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wann der Kunst Geweihte klagen,", "tokens": ["Wann", "der", "Kunst", "Ge\u00b7weih\u00b7te", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wir S\u00fcd-Kunstmacher zagen?", "tokens": ["Und", "wir", "S\u00fcd\u00b7Kunst\u00b7ma\u00b7cher", "za\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Gnade, ruf' ich, Herr, mir Knaben!", "tokens": ["Gna\u00b7de", ",", "ruf'", "ich", ",", "Herr", ",", "mir", "Kna\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "NN", "$,", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frei ja gabst du deine Gaben;", "tokens": ["Frei", "ja", "gabst", "du", "dei\u00b7ne", "Ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Konntest du mich auch nicht laben?", "tokens": ["Konn\u00b7test", "du", "mich", "auch", "nicht", "la\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Thatst du (woll' es, Herr, erw\u00e4gen!)", "tokens": ["Thatst", "du", "(", "woll'", "es", ",", "Herr", ",", "er\u00b7w\u00e4\u00b7gen", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$(", "VMFIN", "PPER", "$,", "NN", "$,", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Je ein Wunder meinetwegen,", "tokens": ["Je", "ein", "Wun\u00b7der", "mei\u00b7net\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein Gem\u00fct mit Kraft zu pflegen?", "tokens": ["Mein", "Ge\u00b7m\u00fct", "mit", "Kraft", "zu", "pfle\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Trotz dem Angstschwei\u00df meines Strebens,", "tokens": ["Trotz", "dem", "A\u00b7ngstschwei\u00df", "mei\u00b7nes", "Stre\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nachzu\u00e4ffen Geist des Lebens;", "tokens": ["Nach\u00b7zu\u00b7\u00e4f\u00b7fen", "Geist", "des", "Le\u00b7bens", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle M\u00fche war vergebens!", "tokens": ["Al\u00b7le", "M\u00fc\u00b7he", "war", "ver\u00b7ge\u00b7bens", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Richter der gerechten Rache,", "tokens": ["Rich\u00b7ter", "der", "ge\u00b7rech\u00b7ten", "Ra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nachsicht \u00fcb' in meiner Sache,", "tokens": ["Nach\u00b7sicht", "\u00fcb'", "in", "mei\u00b7ner", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ich, wie ich kann, es mache.", "tokens": ["Wenn", "ich", ",", "wie", "ich", "kann", ",", "es", "ma\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Scham und Reue mu\u00df ich dulden;", "tokens": ["Scham", "und", "Reu\u00b7e", "mu\u00df", "ich", "dul\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tief err\u00f6t' ich ob den Schulden,", "tokens": ["Tief", "er\u00b7r\u00f6t'", "ich", "ob", "den", "Schul\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "KOUS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Kreuzer unter Gulden.", "tokens": ["Wie", "ein", "Kreu\u00b7zer", "un\u00b7ter", "Gul\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Hab' ich reimend mich verschrieen,", "tokens": ["Hab'", "ich", "rei\u00b7mend", "mich", "ver\u00b7schri\u00b7een", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du, der Sch\u00e4chern selbst verziehen,", "tokens": ["Du", ",", "der", "Sch\u00e4\u00b7chern", "selbst", "ver\u00b7zie\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df es gehn f\u00fcr Melodieen!", "tokens": ["La\u00df", "es", "gehn", "f\u00fcr", "Me\u00b7lo\u00b7di\u00b7e\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Achte nicht mein Schrei'n so teuer,", "tokens": ["Ach\u00b7te", "nicht", "mein", "Schrei'n", "so", "teu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich darum, o du Treuer,", "tokens": ["Da\u00df", "ich", "da\u00b7rum", ",", "o", "du", "Treu\u00b7er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "$,", "FM", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Brennen sollt' in ewgem Feuer.", "tokens": ["Bren\u00b7nen", "sollt'", "in", "ew\u00b7gem", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Zu den Schafen la\u00df mich kommen,", "tokens": ["Zu", "den", "Scha\u00b7fen", "la\u00df", "mich", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den st\u00f6\u00dfigen, nicht frommen,", "tokens": ["Von", "den", "st\u00f6\u00b7\u00dfi\u00b7gen", ",", "nicht", "from\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "PTKNEG", "ADJA", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Bundesb\u00f6cken ausgenommen.", "tokens": ["Bun\u00b7des\u00b7b\u00f6\u00b7cken", "aus\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Wird auch Feuer ohne Schonung", "tokens": ["Wird", "auch", "Feu\u00b7er", "oh\u00b7ne", "Scho\u00b7nung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinen Reimen zur Belohnung,", "tokens": ["Mei\u00b7nen", "Rei\u00b7men", "zur", "Be\u00b7loh\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nimm doch mich in deine Wohnung.", "tokens": ["Nimm", "doch", "mich", "in", "dei\u00b7ne", "Woh\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Herz, zerknirscht im tiefsten Grunde,", "tokens": ["Herz", ",", "zer\u00b7knirscht", "im", "tiefs\u00b7ten", "Grun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruf' Ade dem Schw\u00e4rmerbunde,", "tokens": ["Ruf'", "A\u00b7de", "dem", "Schw\u00e4r\u00b7mer\u00b7bun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df ich zu Vernunft gesunde!", "tokens": ["Da\u00df", "ich", "zu", "Ver\u00b7nunft", "ge\u00b7sun\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Wer ges\u00fcndigt hat mit Zoren,", "tokens": ["Wer", "ge\u00b7s\u00fcn\u00b7digt", "hat", "mit", "Zo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df dort ewig, ewig schmoren.", "tokens": ["Mu\u00df", "dort", "e\u00b7wig", ",", "e\u00b7wig", "schmo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "$,", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber mich, trotz meinen Schulden,", "tokens": ["A\u00b7ber", "mich", ",", "trotz", "mei\u00b7nen", "Schul\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimm ins Paradies mit Hulden.", "tokens": ["Nimm", "ins", "Pa\u00b7ra\u00b7dies", "mit", "Hul\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gieb mir Armen ewge Ruh,", "tokens": ["Gieb", "mir", "Ar\u00b7men", "ew\u00b7ge", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sei es auch \u2013 mit Kotzebu!", "tokens": ["Sei", "es", "auch", "\u2013", "mit", "Kot\u00b7ze\u00b7bu", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$(", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}