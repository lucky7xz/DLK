{"textgrid.poem.55419": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Zahme Xenien", "genre": "verse", "period": "N.A.", "pub_year": 1825, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lasset walten, lasset gelten,", "tokens": ["Las\u00b7set", "wal\u00b7ten", ",", "las\u00b7set", "gel\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVINF", "$,", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ich wunderlich verk\u00fcndigt!", "tokens": ["Was", "ich", "wun\u00b7der\u00b7lich", "ver\u00b7k\u00fcn\u00b7digt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "D\u00fcrftet ihr den Guten schelten,", "tokens": ["D\u00fcrf\u00b7tet", "ihr", "den", "Gu\u00b7ten", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der mit seiner Zeit ges\u00fcndigt?", "tokens": ["Der", "mit", "sei\u00b7ner", "Zeit", "ge\u00b7s\u00fcn\u00b7digt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Nichts wird rechts und links mich kr\u00e4nken,", "tokens": ["Nichts", "wird", "rechts", "und", "links", "mich", "kr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "KON", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Folg ich k\u00fchn dem raschen Flug;", "tokens": ["Folg", "ich", "k\u00fchn", "dem", "ra\u00b7schen", "Flug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollte jemand anders denken,", "tokens": ["Woll\u00b7te", "je\u00b7mand", "an\u00b7ders", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist der Weg ja breit genug.", "tokens": ["Ist", "der", "Weg", "ja", "breit", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Schw\u00e4rmt ihr doch zu ganzen Scharen", "tokens": ["Schw\u00e4rmt", "ihr", "doch", "zu", "gan\u00b7zen", "Scha\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lieber als in wenig Paaren,", "tokens": ["Lie\u00b7ber", "als", "in", "we\u00b7nig", "Paa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00dft mir keine Seite leer!", "tokens": ["La\u00dft", "mir", "kei\u00b7ne", "Sei\u00b7te", "leer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sumst umher, es wird euch gl\u00fccken!", "tokens": ["Sumst", "um\u00b7her", ",", "es", "wird", "euch", "gl\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Einzeln stechen auch die M\u00fccken,", "tokens": ["Ein\u00b7zeln", "ste\u00b7chen", "auch", "die", "M\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Braucht nicht gleich ein ganzes Heer.", "tokens": ["Braucht", "nicht", "gleich", "ein", "gan\u00b7zes", "Heer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Da ich viel allein verbleibe,", "tokens": ["Da", "ich", "viel", "al\u00b7lein", "ver\u00b7blei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Pflege weniges zu sagen;", "tokens": ["Pfle\u00b7ge", "we\u00b7ni\u00b7ges", "zu", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da ich aber gerne schreibe,", "tokens": ["Da", "ich", "a\u00b7ber", "ger\u00b7ne", "schrei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00f6gen's meine Leser tragen!", "tokens": ["M\u00f6\u00b7gen's", "mei\u00b7ne", "Le\u00b7ser", "tra\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sollte hei\u00dfen: gern diktiere,", "tokens": ["Soll\u00b7te", "hei\u00b7\u00dfen", ":", "gern", "dik\u00b7tie\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$.", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und das ist doch auch ein Sprechen,", "tokens": ["Und", "das", "ist", "doch", "auch", "ein", "Spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wo ich keine Zeit verliere;", "tokens": ["Wo", "ich", "kei\u00b7ne", "Zeit", "ver\u00b7lie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Niemand wird mich unterbrechen.", "tokens": ["Nie\u00b7mand", "wird", "mich", "un\u00b7ter\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie im Auge mit fliegenden M\u00fccken,", "tokens": ["Wie", "im", "Au\u00b7ge", "mit", "flie\u00b7gen\u00b7den", "M\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "So ist's mit Sorgen ganz genau;", "tokens": ["So", "ist's", "mit", "Sor\u00b7gen", "ganz", "ge\u00b7nau", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn wir in die sch\u00f6ne Welt hineinblicken,", "tokens": ["Wenn", "wir", "in", "die", "sch\u00f6\u00b7ne", "Welt", "hin\u00b7ein\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da schwebt ein Spinnewebengrau;", "tokens": ["Da", "schwebt", "ein", "Spin\u00b7ne\u00b7we\u00b7ben\u00b7grau", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es \u00fcberzieht nicht, es zieht nur vor\u00fcber,", "tokens": ["Es", "\u00fc\u00b7berz\u00b7ieht", "nicht", ",", "es", "zieht", "nur", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das Bild ist gest\u00f6rt, wenn nur nicht tr\u00fcber;", "tokens": ["Das", "Bild", "ist", "ge\u00b7st\u00f6rt", ",", "wenn", "nur", "nicht", "tr\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "KOUS", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Die klare Welt bleibt klare Welt:", "tokens": ["Die", "kla\u00b7re", "Welt", "bleibt", "kla\u00b7re", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Im Auge nur ist's schlecht bestellt.", "tokens": ["Im", "Au\u00b7ge", "nur", "ist's", "schlecht", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Trage dein \u00dcbel, wie du magst,", "tokens": ["Tra\u00b7ge", "dein", "\u00dc\u00b7bel", ",", "wie", "du", "magst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Klage niemand dein Mi\u00dfgeschick;", "tokens": ["Kla\u00b7ge", "nie\u00b7mand", "dein", "Mi\u00df\u00b7ge\u00b7schick", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Wie du dem Freunde ", "tokens": ["Wie", "du", "dem", "Freun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Gibt er dir gleich ein Dutzend zur\u00fcck!", "tokens": ["Gibt", "er", "dir", "gleich", "ein", "Dut\u00b7zend", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "In keiner Gilde kann man sein,", "tokens": ["In", "kei\u00b7ner", "Gil\u00b7de", "kann", "man", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "PIS", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man wisse denn zu schultern fein;", "tokens": ["Man", "wis\u00b7se", "denn", "zu", "schul\u00b7tern", "fein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PTKZU", "VVINF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das, was sie lieben, was sie hassen,", "tokens": ["Das", ",", "was", "sie", "lie\u00b7ben", ",", "was", "sie", "has\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "VVINF", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das mu\u00df man eben geschehen lassen;", "tokens": ["Das", "mu\u00df", "man", "e\u00b7ben", "ge\u00b7sche\u00b7hen", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Das, was sie wissen, l\u00e4\u00dft man gelten,", "tokens": ["Das", ",", "was", "sie", "wis\u00b7sen", ",", "l\u00e4\u00dft", "man", "gel\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "VVINF", "$,", "VVFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was sie nicht wissen, mu\u00df man schelten,", "tokens": ["Was", "sie", "nicht", "wis\u00b7sen", ",", "mu\u00df", "man", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VVINF", "$,", "VMFIN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Althergebrachtes weiterf\u00fchren,", "tokens": ["Al\u00b7ther\u00b7ge\u00b7brach\u00b7tes", "wei\u00b7ter\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Das Neue kl\u00fcglich retardieren;", "tokens": ["Das", "Neu\u00b7e", "kl\u00fcg\u00b7lich", "re\u00b7tar\u00b7die\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Dann werden sie dir zugestehn,", "tokens": ["Dann", "wer\u00b7den", "sie", "dir", "zu\u00b7ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Auch nebenher deinen Weg zu gehn.", "tokens": ["Auch", "ne\u00b7ben\u00b7her", "dei\u00b7nen", "Weg", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Doch w\u00fcrden sie, k\u00f6nnt es gelingen,", "tokens": ["Doch", "w\u00fcr\u00b7den", "sie", ",", "k\u00f6nnt", "es", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$,", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Zum Widerruf dich pf\u00e4ffisch zwingen.", "tokens": ["Zum", "Wi\u00b7der\u00b7ruf", "dich", "pf\u00e4f\u00b7fisch", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Hemmet ihr verschm\u00e4hten Freier", "tokens": ["Hem\u00b7met", "ihr", "ver\u00b7schm\u00e4h\u00b7ten", "Frei\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht die schlechtgestimmte Leier,", "tokens": ["Nicht", "die", "schlecht\u00b7ge\u00b7stimm\u00b7te", "Lei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So verzweifl' ich ganz und gar;", "tokens": ["So", "ver\u00b7zweifl'", "ich", "ganz", "und", "gar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Isis zeigt sich ohne Schleier,", "tokens": ["I\u00b7sis", "zeigt", "sich", "oh\u00b7ne", "Schlei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch der Mensch, er hat den Star.", "tokens": ["Doch", "der", "Mensch", ",", "er", "hat", "den", "Star", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Die geschichtlichen Symbole \u2013", "tokens": ["Die", "ge\u00b7schicht\u00b7li\u00b7chen", "Sym\u00b7bo\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00f6rig, wer sie wichtig h\u00e4lt;", "tokens": ["T\u00f6\u00b7rig", ",", "wer", "sie", "wich\u00b7tig", "h\u00e4lt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWS", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Immer forschet er ins Hohle", "tokens": ["Im\u00b7mer", "for\u00b7schet", "er", "ins", "Hoh\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vers\u00e4umt die reiche Welt.", "tokens": ["Und", "ver\u00b7s\u00e4umt", "die", "rei\u00b7che", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Suche nicht verborgne Weihe!", "tokens": ["Su\u00b7che", "nicht", "ver\u00b7borg\u00b7ne", "Wei\u00b7he", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unterm Schleier la\u00df das Starre!", "tokens": ["Un\u00b7term", "Schlei\u00b7er", "la\u00df", "das", "Star\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Willst du leben, guter Narre,", "tokens": ["Willst", "du", "le\u00b7ben", ",", "gu\u00b7ter", "Nar\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sieh nur hinter dich ins Freie.", "tokens": ["Sieh", "nur", "hin\u00b7ter", "dich", "ins", "Frei\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Einheit ewigen Lichts zu spalten,", "tokens": ["Ein\u00b7heit", "e\u00b7wi\u00b7gen", "Lichts", "zu", "spal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "M\u00fcssen wir f\u00fcr t\u00f6rig halten,", "tokens": ["M\u00fcs\u00b7sen", "wir", "f\u00fcr", "t\u00f6\u00b7rig", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn euch Irrtum schon gen\u00fcgt.", "tokens": ["Wenn", "euch", "Irr\u00b7tum", "schon", "ge\u00b7n\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hell und Dunkel, Licht und Schatten,", "tokens": ["Hell", "und", "Dun\u00b7kel", ",", "Licht", "und", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wei\u00df man kl\u00fcglich sie zu gatten,", "tokens": ["Wei\u00df", "man", "kl\u00fcg\u00b7lich", "sie", "zu", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist das Farbenreich besiegt.", "tokens": ["Ist", "das", "Far\u00b7ben\u00b7reich", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Die beiden lieben sich gar fein,", "tokens": ["Die", "bei\u00b7den", "lie\u00b7ben", "sich", "gar", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "M\u00f6gen nicht ohne einander sein.", "tokens": ["M\u00f6\u00b7gen", "nicht", "oh\u00b7ne", "ein\u00b7an\u00b7der", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "PRF", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wie eins im andern sich verliert,", "tokens": ["Wie", "eins", "im", "an\u00b7dern", "sich", "ver\u00b7liert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPRART", "ADJA", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Manch buntes Kind sich ausgebiert,", "tokens": ["Manch", "bun\u00b7tes", "Kind", "sich", "aus\u00b7ge\u00b7biert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im eignen Auge schaue mit Lust,", "tokens": ["Im", "eig\u00b7nen", "Au\u00b7ge", "schau\u00b7e", "mit", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Was Plato von Anbeginn gewu\u00dft;", "tokens": ["Was", "Pla\u00b7to", "von", "An\u00b7be\u00b7ginn", "ge\u00b7wu\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Denn das ist der Natur Gehalt,", "tokens": ["Denn", "das", "ist", "der", "Na\u00b7tur", "Ge\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Da\u00df au\u00dfen gilt, was innen galt.", "tokens": ["Da\u00df", "au\u00b7\u00dfen", "gilt", ",", "was", "in\u00b7nen", "galt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Freunde, flieht die dunkle Kammer,", "tokens": ["Freun\u00b7de", ",", "flieht", "die", "dunk\u00b7le", "Kam\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo man euch das Licht verzwickt", "tokens": ["Wo", "man", "euch", "das", "Licht", "ver\u00b7zwickt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit k\u00fcmmerlichstem Jammer", "tokens": ["Und", "mit", "k\u00fcm\u00b7mer\u00b7lichs\u00b7tem", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich verschrobnen Bildern b\u00fcckt.", "tokens": ["Sich", "ver\u00b7schrob\u00b7nen", "Bil\u00b7dern", "b\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Abergl\u00e4ubische Verehrer", "tokens": ["A\u00b7berg\u00b7l\u00e4u\u00b7bi\u00b7sche", "Ver\u00b7eh\u00b7rer"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gab's die Jahre her genug,", "tokens": ["Gab's", "die", "Jah\u00b7re", "her", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APZR", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "In den K\u00f6pfen eurer Lehrer La\u00dft", "tokens": ["In", "den", "K\u00f6p\u00b7fen", "eu\u00b7rer", "Leh\u00b7rer", "La\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Gespenst und Wahn und Trug.", "tokens": ["Ge\u00b7spenst", "und", "Wahn", "und", "Trug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wenn der Blick an heitern Tagen", "tokens": ["Wenn", "der", "Blick", "an", "hei\u00b7tern", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich zur Himmelsbl\u00e4ue lenkt,", "tokens": ["Sich", "zur", "Him\u00b7mels\u00b7bl\u00e4u\u00b7e", "lenkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Beim Sirok der Sonnenwagen", "tokens": ["Beim", "Si\u00b7rok", "der", "Son\u00b7nen\u00b7wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Purpurrot sich niedersenkt,", "tokens": ["Pur\u00b7pur\u00b7rot", "sich", "nie\u00b7der\u00b7senkt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da gebt der Natur die Ehre,", "tokens": ["Da", "gebt", "der", "Na\u00b7tur", "die", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Froh, an Aug und Herz gesund,", "tokens": ["Froh", ",", "an", "Aug", "und", "Herz", "ge\u00b7sund", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und erkennt der Farbenlehre", "tokens": ["Und", "er\u00b7kennt", "der", "Far\u00b7ben\u00b7leh\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Allgemeinen, ewigen Grund.", "tokens": ["All\u00b7ge\u00b7mei\u00b7nen", ",", "e\u00b7wi\u00b7gen", "Grund", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.16": {"line.1": {"text": "Das wirst du sie nicht \u00fcberreden,", "tokens": ["Das", "wirst", "du", "sie", "nicht", "\u00fc\u00b7berr\u00b7e\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie rechnen dich ja zu den Bl\u00f6den,", "tokens": ["Sie", "rech\u00b7nen", "dich", "ja", "zu", "den", "Bl\u00f6\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von bl\u00f6den Augen, bl\u00f6den Sinnen;", "tokens": ["Von", "bl\u00f6\u00b7den", "Au\u00b7gen", ",", "bl\u00f6\u00b7den", "Sin\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Finsternis im Lichte drinnen,", "tokens": ["Die", "Fins\u00b7ter\u00b7nis", "im", "Lich\u00b7te", "drin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die kannst du ewig nicht erfassen;", "tokens": ["Die", "kannst", "du", "e\u00b7wig", "nicht", "er\u00b7fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mu\u00dft das den Herren \u00fcberlassen,", "tokens": ["Mu\u00dft", "das", "den", "Her\u00b7ren", "\u00fc\u00b7ber\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die's zu beweisen sind erb\u00f6tig.", "tokens": ["Die's", "zu", "be\u00b7wei\u00b7sen", "sind", "er\u00b7b\u00f6\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKZU", "VVINF", "VAFIN", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Gott sei den guten Sch\u00fclern gn\u00e4dig!", "tokens": ["Gott", "sei", "den", "gu\u00b7ten", "Sch\u00fc\u00b7lern", "gn\u00e4\u00b7dig", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Mit Widerlegen, Bedingen, Begrimmen", "tokens": ["Mit", "Wi\u00b7der\u00b7le\u00b7gen", ",", "Be\u00b7din\u00b7gen", ",", "Be\u00b7grim\u00b7men"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bem\u00fcht und br\u00fcstet mancher sich;", "tokens": ["Be\u00b7m\u00fcht", "und", "br\u00fcs\u00b7tet", "man\u00b7cher", "sich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "PIS", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich kann daraus nichts weiter gewinnen,", "tokens": ["Ich", "kann", "da\u00b7raus", "nichts", "wei\u00b7ter", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als da\u00df er anders denkt wie ich.", "tokens": ["Als", "da\u00df", "er", "an\u00b7ders", "denkt", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "VVFIN", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Wie man die K\u00f6nige verletzt,", "tokens": ["Wie", "man", "die", "K\u00f6\u00b7ni\u00b7ge", "ver\u00b7letzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird der Granit auch abgesetzt;", "tokens": ["Wird", "der", "Gra\u00b7nit", "auch", "ab\u00b7ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und Gneis, der Sohn, ist nun Papa!", "tokens": ["Und", "Gneis", ",", "der", "Sohn", ",", "ist", "nun", "Pa\u00b7pa", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "NN", "$,", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch dessen Untergang ist nah:", "tokens": ["Auch", "des\u00b7sen", "Un\u00b7ter\u00b7gang", "ist", "nah", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn Plutos Gabel drohet schon", "tokens": ["Denn", "Plu\u00b7tos", "Ga\u00b7bel", "dro\u00b7het", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Urgrund Revolution;", "tokens": ["Dem", "Ur\u00b7grund", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Basalt, der schwarze Teufelsmohr,", "tokens": ["Ba\u00b7salt", ",", "der", "schwar\u00b7ze", "Teu\u00b7fels\u00b7mohr", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus tiefster H\u00f6lle bricht hervor,", "tokens": ["Aus", "tiefs\u00b7ter", "H\u00f6l\u00b7le", "bricht", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zerspaltet Fels, Gestein und Erden,", "tokens": ["Zer\u00b7spal\u00b7tet", "Fels", ",", "Ge\u00b7stein", "und", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Omega mu\u00df zum Alpha werden.", "tokens": ["O\u00b7me\u00b7ga", "mu\u00df", "zum", "Al\u00b7pha", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "APPRART", "NN", "VAINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Und so w\u00e4re denn die liebe Welt", "tokens": ["Und", "so", "w\u00e4\u00b7re", "denn", "die", "lie\u00b7be", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Geognostisch auch auf den Kopf gestellt.", "tokens": ["Ge\u00b7og\u00b7nos\u00b7tisch", "auch", "auf", "den", "Kopf", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Kaum wendet der edle Werner den R\u00fccken,", "tokens": ["Kaum", "wen\u00b7det", "der", "ed\u00b7le", "Wer\u00b7ner", "den", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zerst\u00f6rt man das Poseidaonische Reich;", "tokens": ["Zer\u00b7st\u00f6rt", "man", "das", "Po\u00b7sei\u00b7dao\u00b7nisc\u00b7he", "Reich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn alle sich vor Heph\u00e4stos b\u00fccken,", "tokens": ["Wenn", "al\u00b7le", "sich", "vor", "He\u00b7ph\u00e4s\u00b7tos", "b\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich kann es nicht sogleich;", "tokens": ["Ich", "kann", "es", "nicht", "sog\u00b7leich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich wei\u00df nur in der Folge zu sch\u00e4tzen.", "tokens": ["Ich", "wei\u00df", "nur", "in", "der", "Fol\u00b7ge", "zu", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Schon hab ich manches Credo verpa\u00dft;", "tokens": ["Schon", "hab", "ich", "man\u00b7ches", "Cre\u00b7do", "ver\u00b7pa\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Mir sind sie alle gleich verha\u00dft,", "tokens": ["Mir", "sind", "sie", "al\u00b7le", "gleich", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Neue G\u00f6tter und G\u00f6tzen.", "tokens": ["Neu\u00b7e", "G\u00f6t\u00b7ter", "und", "G\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.20": {"line.1": {"text": "Urspr\u00fcnglich eignen Sinn", "tokens": ["Ur\u00b7spr\u00fcng\u00b7lich", "eig\u00b7nen", "Sinn"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "La\u00df dir nicht rauben!", "tokens": ["La\u00df", "dir", "nicht", "rau\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Woran die Menge glaubt,", "tokens": ["Wo\u00b7ran", "die", "Men\u00b7ge", "glaubt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist leicht zu glauben.", "tokens": ["Ist", "leicht", "zu", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.21": {"line.1": {"text": "Nat\u00fcrlich mit Verstand", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "mit", "Ver\u00b7stand"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sei du beflissen;", "tokens": ["Sei", "du", "be\u00b7flis\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "$."], "meter": "---+-", "measure": "unknown.measure.single"}, "line.3": {"text": "Was der Gescheite wei\u00df,", "tokens": ["Was", "der", "Ge\u00b7schei\u00b7te", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist schwer zu wissen.", "tokens": ["Ist", "schwer", "zu", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.22": {"line.1": {"text": "Je mehr man kennt, je mehr man wei\u00df,", "tokens": ["Je", "mehr", "man", "kennt", ",", "je", "mehr", "man", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVFIN", "$,", "ADV", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erkennt man: alles dreht im Kreis;", "tokens": ["Er\u00b7kennt", "man", ":", "al\u00b7les", "dreht", "im", "Kreis", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$.", "PIS", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erst lehrt man jenes, lehrt man dies,", "tokens": ["Erst", "lehrt", "man", "je\u00b7nes", ",", "lehrt", "man", "dies", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PDS", "$,", "VVFIN", "PIS", "PDS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun aber waltet ganz gewi\u00df", "tokens": ["Nun", "a\u00b7ber", "wal\u00b7tet", "ganz", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im innern Erdenspatium", "tokens": ["Im", "in\u00b7nern", "Er\u00b7den\u00b7spa\u00b7ti\u00b7um"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Pyro-Hydrophylacium,", "tokens": ["Py\u00b7ro\u00b7Hy\u00b7dro\u00b7phyla\u00b7ci\u00b7um", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Damit's der Erden Oberfl\u00e4che", "tokens": ["Da\u00b7mit's", "der", "Er\u00b7den", "O\u00b7berf\u00b7l\u00e4\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "An Feuer und Wasser nicht gebreche.", "tokens": ["An", "Feu\u00b7er", "und", "Was\u00b7ser", "nicht", "ge\u00b7bre\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKNEG", "ADJA", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wo k\u00e4me denn ein Ding sonst her,", "tokens": ["Wo", "k\u00e4\u00b7me", "denn", "ein", "Ding", "sonst", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wenn es nicht l\u00e4ngst schon fertig w\u00e4r?", "tokens": ["Wenn", "es", "nicht", "l\u00e4ngst", "schon", "fer\u00b7tig", "w\u00e4r", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "So ist denn, eh man sich's versah,", "tokens": ["So", "ist", "denn", ",", "eh", "man", "sich's", "ver\u00b7sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der Pater Kircher wieder da.", "tokens": ["Der", "Pa\u00b7ter", "Kir\u00b7cher", "wie\u00b7der", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Will mich jedoch des Worts nicht sch\u00e4men:", "tokens": ["Will", "mich", "je\u00b7doch", "des", "Worts", "nicht", "sch\u00e4\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.14": {"text": "Wir tasten ewig an Problemen.", "tokens": ["Wir", "tas\u00b7ten", "e\u00b7wig", "an", "Prob\u00b7le\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Keine Gluten, keine Meere", "tokens": ["Kei\u00b7ne", "Glu\u00b7ten", ",", "kei\u00b7ne", "Mee\u00b7re"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Geb ich in dem Innern zu;", "tokens": ["Geb", "ich", "in", "dem", "In\u00b7nern", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch allherrschend waltet Schwere,", "tokens": ["Doch", "all\u00b7herr\u00b7schend", "wal\u00b7tet", "Schwe\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Nicht verdammt zu Tod und Ruh.", "tokens": ["Nicht", "ver\u00b7dammt", "zu", "Tod", "und", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vom lebendigen Gott lebendig,", "tokens": ["Vom", "le\u00b7ben\u00b7di\u00b7gen", "Gott", "le\u00b7ben\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch den Geist, der alles regt,", "tokens": ["Durch", "den", "Geist", ",", "der", "al\u00b7les", "regt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wechselt sie, nicht unbest\u00e4ndig,", "tokens": ["Wech\u00b7selt", "sie", ",", "nicht", "un\u00b7be\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Immer in sich selbst bewegt.", "tokens": ["Im\u00b7mer", "in", "sich", "selbst", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Seht nur hin! Ihr werdet's fassen!", "tokens": ["Seht", "nur", "hin", "!", "Ihr", "wer\u00b7det's", "fas\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$.", "PPER", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn Merkur sich hebt und neigt,", "tokens": ["Wenn", "Mer\u00b7kur", "sich", "hebt", "und", "neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Wird im Anziehn, im Entlassen", "tokens": ["Wird", "im", "An\u00b7ziehn", ",", "im", "Ent\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "APPRART", "NN", "$,", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Atmosph\u00e4re schwer und leicht.", "tokens": ["At\u00b7mo\u00b7sph\u00e4\u00b7re", "schwer", "und", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Mir gen\u00fcgt nicht eure Lehre:", "tokens": ["Mir", "ge\u00b7n\u00fcgt", "nicht", "eu\u00b7re", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ebb und Flut der Atmosph\u00e4re \u2013", "tokens": ["Ebb", "und", "Flut", "der", "At\u00b7mo\u00b7sph\u00e4\u00b7re", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denk sich's jeder, wie er kann!", "tokens": ["Denk", "sich's", "je\u00b7der", ",", "wie", "er", "kann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "PIS", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Will mich nur an Hermes halten;", "tokens": ["Will", "mich", "nur", "an", "Her\u00b7mes", "hal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn des Barometers Walten", "tokens": ["Denn", "des", "Ba\u00b7ro\u00b7me\u00b7ters", "Wal\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Ist der Witterung Tyrann.", "tokens": ["Ist", "der", "Wit\u00b7te\u00b7rung", "Ty\u00b7rann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Westen mag die Luft regieren,", "tokens": ["Wes\u00b7ten", "mag", "die", "Luft", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sturm und Flut nach Osten f\u00fchren,", "tokens": ["Sturm", "und", "Flut", "nach", "Os\u00b7ten", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn Merkur sich schl\u00e4frig zeigt;", "tokens": ["Wenn", "Mer\u00b7kur", "sich", "schl\u00e4f\u00b7rig", "zeigt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Aller Elemente Toben,", "tokens": ["Al\u00b7ler", "E\u00b7le\u00b7men\u00b7te", "To\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Osther ist es aufgehoben,", "tokens": ["Ost\u00b7her", "ist", "es", "auf\u00b7ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn er aus dem Schlummer steigt.", "tokens": ["Wenn", "er", "aus", "dem", "Schlum\u00b7mer", "steigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Das Leben wohnt in jedem Sterne:", "tokens": ["Das", "Le\u00b7ben", "wohnt", "in", "je\u00b7dem", "Ster\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er wandelt mit den andern gerne", "tokens": ["Er", "wan\u00b7delt", "mit", "den", "an\u00b7dern", "ger\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die selbsterw\u00e4hlte reine Bahn;", "tokens": ["Die", "selbs\u00b7ter\u00b7w\u00e4hl\u00b7te", "rei\u00b7ne", "Bahn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im innern Erdenball pulsieren", "tokens": ["Im", "in\u00b7nern", "Er\u00b7den\u00b7ball", "pul\u00b7sie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Kr\u00e4fte, die zur Nacht uns f\u00fchren", "tokens": ["Die", "Kr\u00e4f\u00b7te", ",", "die", "zur", "Nacht", "uns", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und wieder zu dem Tag heran.", "tokens": ["Und", "wie\u00b7der", "zu", "dem", "Tag", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Wenn im Unendlichen dasselbe", "tokens": ["Wenn", "im", "Un\u00b7end\u00b7li\u00b7chen", "das\u00b7sel\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "PDAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich wiederholend ewig flie\u00dft,", "tokens": ["Sich", "wie\u00b7der\u00b7ho\u00b7lend", "e\u00b7wig", "flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das tausendf\u00e4ltige Gew\u00f6lbe", "tokens": ["Das", "tau\u00b7send\u00b7f\u00e4l\u00b7ti\u00b7ge", "Ge\u00b7w\u00f6l\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich kr\u00e4ftig ineinander schlie\u00dft,", "tokens": ["Sich", "kr\u00e4f\u00b7tig", "in\u00b7ein\u00b7an\u00b7der", "schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Str\u00f6mt Lebenslust aus allen Dingen,", "tokens": ["Str\u00f6mt", "Le\u00b7bens\u00b7lust", "aus", "al\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dem kleinsten wie dem gr\u00f6\u00dften Stern", "tokens": ["Dem", "kleins\u00b7ten", "wie", "dem", "gr\u00f6\u00df\u00b7ten", "Stern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und alles Dr\u00e4ngen, alles Ringen", "tokens": ["Und", "al\u00b7les", "Dr\u00e4n\u00b7gen", ",", "al\u00b7les", "Rin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIAT", "NN", "$,", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist ewige Ruh in Gott dem Herrn.", "tokens": ["Ist", "e\u00b7wi\u00b7ge", "Ruh", "in", "Gott", "dem", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "Nachts, wann gute Geister schweifen,", "tokens": ["Nachts", ",", "wann", "gu\u00b7te", "Geis\u00b7ter", "schwei\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schlaf dir von der Stirne streifen,", "tokens": ["Schlaf", "dir", "von", "der", "Stir\u00b7ne", "strei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mondenlicht und Sternenflimmern", "tokens": ["Mon\u00b7den\u00b7licht", "und", "Ster\u00b7nen\u00b7flim\u00b7mern"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dich mit ewigem All umschimmern,", "tokens": ["Dich", "mit", "e\u00b7wi\u00b7gem", "All", "um\u00b7schim\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Scheinst du dir entk\u00f6rpert schon,", "tokens": ["Scheinst", "du", "dir", "ent\u00b7k\u00f6r\u00b7pert", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wagest dich an Gottes Thron.", "tokens": ["Wa\u00b7gest", "dich", "an", "Got\u00b7tes", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Aber wenn der Tag die Welt", "tokens": ["A\u00b7ber", "wenn", "der", "Tag", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wieder auf die F\u00fc\u00dfe stellt,", "tokens": ["Wie\u00b7der", "auf", "die", "F\u00fc\u00b7\u00dfe", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwerlich m\u00f6cht er dir's erf\u00fcllen", "tokens": ["Schwer\u00b7lich", "m\u00f6cht", "er", "dir's", "er\u00b7f\u00fcl\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit der Fr\u00fche bestem Willen;", "tokens": ["Mit", "der", "Fr\u00fc\u00b7he", "bes\u00b7tem", "Wil\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zu Mittag schon wandelt sich", "tokens": ["Zu", "Mit\u00b7tag", "schon", "wan\u00b7delt", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "VVFIN", "PRF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Morgentraum gar wunderlich.", "tokens": ["Mor\u00b7gen\u00b7traum", "gar", "wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Sei du im Leben wie im Wissen", "tokens": ["Sei", "du", "im", "Le\u00b7ben", "wie", "im", "Wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "KOKOM", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durchaus der reinen Fahrt beflissen;", "tokens": ["Durc\u00b7haus", "der", "rei\u00b7nen", "Fahrt", "be\u00b7flis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Sturm und Str\u00f6mung sto\u00dfen, zerrn,", "tokens": ["Wenn", "Sturm", "und", "Str\u00f6\u00b7mung", "sto\u00b7\u00dfen", ",", "zerrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie werden doch nicht deine Herrn;", "tokens": ["Sie", "wer\u00b7den", "doch", "nicht", "dei\u00b7ne", "Herrn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kompa\u00df und Pol-Stern, Zeitenmesser", "tokens": ["Kom\u00b7pa\u00df", "und", "Pol\u00b7S\u00b7tern", ",", "Zei\u00b7ten\u00b7mes\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["VVIMP", "KON", "NN", "$,", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Sonn und Mond verstehst du besser,", "tokens": ["Und", "Sonn", "und", "Mond", "ver\u00b7stehst", "du", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vollendest so nach deiner Art", "tokens": ["Voll\u00b7en\u00b7dest", "so", "nach", "dei\u00b7ner", "Art"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit stillen Freuden deine Fahrt.", "tokens": ["Mit", "stil\u00b7len", "Freu\u00b7den", "dei\u00b7ne", "Fahrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Besonders, wenn dich's nicht verdrie\u00dft,", "tokens": ["Be\u00b7son\u00b7ders", ",", "wenn", "dich's", "nicht", "ver\u00b7drie\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wo sich der Weg im Kreise schlie\u00dft;", "tokens": ["Wo", "sich", "der", "Weg", "im", "Krei\u00b7se", "schlie\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der Weltumsegler freudig trifft", "tokens": ["Der", "Welt\u00b7um\u00b7seg\u00b7ler", "freu\u00b7dig", "trifft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Den Hafen, wo er ausgeschifft.", "tokens": ["Den", "Ha\u00b7fen", ",", "wo", "er", "aus\u00b7ge\u00b7schifft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Wie fruchtbar ist der kleinste Kreis,", "tokens": ["Wie", "frucht\u00b7bar", "ist", "der", "kleins\u00b7te", "Kreis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn man ihn wohl zu pflegen wei\u00df.", "tokens": ["Wenn", "man", "ihn", "wohl", "zu", "pfle\u00b7gen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Wenn Kindesblick begierig schaut,", "tokens": ["Wenn", "Kin\u00b7des\u00b7blick", "be\u00b7gie\u00b7rig", "schaut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er findet des Vaters Haus gebaut;", "tokens": ["Er", "fin\u00b7det", "des", "Va\u00b7ters", "Haus", "ge\u00b7baut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wenn das Ohr sich erst vertraut,", "tokens": ["Und", "wenn", "das", "Ohr", "sich", "erst", "ver\u00b7traut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm t\u00f6nt der Muttersprache Laut;", "tokens": ["Ihm", "t\u00f6nt", "der", "Mut\u00b7ter\u00b7spra\u00b7che", "Laut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gewahrt es dies und jenes nah,", "tokens": ["Ge\u00b7wahrt", "es", "dies", "und", "je\u00b7nes", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "KON", "PDS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man fabelt ihm, was fern geschah,", "tokens": ["Man", "fa\u00b7belt", "ihm", ",", "was", "fern", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Umsittigt ihn, w\u00e4chst er heran;", "tokens": ["Um\u00b7sit\u00b7tigt", "ihn", ",", "w\u00e4chst", "er", "he\u00b7ran", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Er findet eben alles getan.", "tokens": ["Er", "fin\u00b7det", "e\u00b7ben", "al\u00b7les", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Man r\u00fchmt ihm dies, man preist ihm das:", "tokens": ["Man", "r\u00fchmt", "ihm", "dies", ",", "man", "preist", "ihm", "das", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PDS", "$,", "PIS", "VVFIN", "PPER", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Er w\u00e4re gar gern auch etwas;", "tokens": ["Er", "w\u00e4\u00b7re", "gar", "gern", "auch", "et\u00b7was", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wie er soll wirken, schaffen, lieben,", "tokens": ["Wie", "er", "soll", "wir\u00b7ken", ",", "schaf\u00b7fen", ",", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Das steht ja alles schon geschrieben", "tokens": ["Das", "steht", "ja", "al\u00b7les", "schon", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PIS", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und, was noch schlimmer ist, gedruckt;", "tokens": ["Und", ",", "was", "noch", "schlim\u00b7mer", "ist", ",", "ge\u00b7druckt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Da steht der junge Mensch verduckt,", "tokens": ["Da", "steht", "der", "jun\u00b7ge", "Mensch", "ver\u00b7duckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und endlich wird ihm offenbar:", "tokens": ["Und", "end\u00b7lich", "wird", "ihm", "of\u00b7fen\u00b7bar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Er sei nur, was ein andrer war.", "tokens": ["Er", "sei", "nur", ",", "was", "ein", "an\u00b7drer", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PRELS", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Gern w\u00e4r ich \u00dcberliefrung los", "tokens": ["Gern", "w\u00e4r", "ich", "\u00dc\u00b7berl\u00b7ief\u00b7rung", "los"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ganz original;", "tokens": ["Und", "ganz", "o\u00b7rig\u00b7i\u00b7nal", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch ist das Unternehmen gro\u00df", "tokens": ["Doch", "ist", "das", "Un\u00b7ter\u00b7neh\u00b7men", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und f\u00fchrt in manche Qual.", "tokens": ["Und", "f\u00fchrt", "in", "man\u00b7che", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Als Autochthone rechnet ich", "tokens": ["Als", "Au\u00b7toch\u00b7tho\u00b7ne", "rech\u00b7net", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es mir zur h\u00f6chsten Ehre,", "tokens": ["Es", "mir", "zur", "h\u00f6chs\u00b7ten", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wenn ich nicht gar zu wunderlich", "tokens": ["Wenn", "ich", "nicht", "gar", "zu", "wun\u00b7der\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Selbst \u00dcberliefrung w\u00e4re.", "tokens": ["Selbst", "\u00dc\u00b7berl\u00b7ief\u00b7rung", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Vom Vater hab ich die Statur,", "tokens": ["Vom", "Va\u00b7ter", "hab", "ich", "die", "Sta\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Lebens ernstes F\u00fchren,", "tokens": ["Des", "Le\u00b7bens", "erns\u00b7tes", "F\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von M\u00fctterchen die Frohnatur", "tokens": ["Von", "M\u00fct\u00b7ter\u00b7chen", "die", "Froh\u00b7na\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Lust zu fabulieren.", "tokens": ["Und", "Lust", "zu", "fa\u00b7bu\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Urahnherr war der Sch\u00f6nsten hold,", "tokens": ["Ur\u00b7ah\u00b7nherr", "war", "der", "Sch\u00f6ns\u00b7ten", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das spukt so hin und wieder,", "tokens": ["Das", "spukt", "so", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKVZ", "KON", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Urahnfrau liebte Schmuck und Gold,", "tokens": ["U\u00b7rahn\u00b7frau", "lieb\u00b7te", "Schmuck", "und", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Das zuckt wohl durch die Glieder.", "tokens": ["Das", "zuckt", "wohl", "durch", "die", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Sind nun die Elemente nicht", "tokens": ["Sind", "nun", "die", "E\u00b7le\u00b7men\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Aus dem Komplex zu trennen,", "tokens": ["Aus", "dem", "Kom\u00b7plex", "zu", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Was ist denn an dem ganzen Wicht", "tokens": ["Was", "ist", "denn", "an", "dem", "gan\u00b7zen", "Wicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Original zu nennen?", "tokens": ["O\u00b7rig\u00b7i\u00b7nal", "zu", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+----", "measure": "unknown.measure.di"}}, "stanza.36": {"line.1": {"text": "Teilen kann ich nicht das Leben,", "tokens": ["Tei\u00b7len", "kann", "ich", "nicht", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht das Innen noch das Au\u00dfen,", "tokens": ["Nicht", "das", "In\u00b7nen", "noch", "das", "Au\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Allen mu\u00df das Ganze geben,", "tokens": ["Al\u00b7len", "mu\u00df", "das", "Gan\u00b7ze", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um mit euch und mir zu hausen.", "tokens": ["Um", "mit", "euch", "und", "mir", "zu", "hau\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "PPER", "KON", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Immer hab ich nur geschrieben,", "tokens": ["Im\u00b7mer", "hab", "ich", "nur", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie ich f\u00fchle, wie ich's meine,", "tokens": ["Wie", "ich", "f\u00fch\u00b7le", ",", "wie", "ich's", "mei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und so spalt ich mich, ihr Lieben,", "tokens": ["Und", "so", "spalt", "ich", "mich", ",", "ihr", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$,", "PPOSAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und bin immerfort der ", "tokens": ["Und", "bin", "im\u00b7mer\u00b7fort", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.37": {"line.1": {"text": "Lasset walten, lasset gelten,", "tokens": ["Las\u00b7set", "wal\u00b7ten", ",", "las\u00b7set", "gel\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVINF", "$,", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ich wunderlich verk\u00fcndigt!", "tokens": ["Was", "ich", "wun\u00b7der\u00b7lich", "ver\u00b7k\u00fcn\u00b7digt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "D\u00fcrftet ihr den Guten schelten,", "tokens": ["D\u00fcrf\u00b7tet", "ihr", "den", "Gu\u00b7ten", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der mit seiner Zeit ges\u00fcndigt?", "tokens": ["Der", "mit", "sei\u00b7ner", "Zeit", "ge\u00b7s\u00fcn\u00b7digt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Nichts wird rechts und links mich kr\u00e4nken,", "tokens": ["Nichts", "wird", "rechts", "und", "links", "mich", "kr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "KON", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Folg ich k\u00fchn dem raschen Flug;", "tokens": ["Folg", "ich", "k\u00fchn", "dem", "ra\u00b7schen", "Flug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollte jemand anders denken,", "tokens": ["Woll\u00b7te", "je\u00b7mand", "an\u00b7ders", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist der Weg ja breit genug.", "tokens": ["Ist", "der", "Weg", "ja", "breit", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Schw\u00e4rmt ihr doch zu ganzen Scharen", "tokens": ["Schw\u00e4rmt", "ihr", "doch", "zu", "gan\u00b7zen", "Scha\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lieber als in wenig Paaren,", "tokens": ["Lie\u00b7ber", "als", "in", "we\u00b7nig", "Paa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00dft mir keine Seite leer!", "tokens": ["La\u00dft", "mir", "kei\u00b7ne", "Sei\u00b7te", "leer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sumst umher, es wird euch gl\u00fccken!", "tokens": ["Sumst", "um\u00b7her", ",", "es", "wird", "euch", "gl\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Einzeln stechen auch die M\u00fccken,", "tokens": ["Ein\u00b7zeln", "ste\u00b7chen", "auch", "die", "M\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Braucht nicht gleich ein ganzes Heer.", "tokens": ["Braucht", "nicht", "gleich", "ein", "gan\u00b7zes", "Heer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Da ich viel allein verbleibe,", "tokens": ["Da", "ich", "viel", "al\u00b7lein", "ver\u00b7blei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Pflege weniges zu sagen;", "tokens": ["Pfle\u00b7ge", "we\u00b7ni\u00b7ges", "zu", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da ich aber gerne schreibe,", "tokens": ["Da", "ich", "a\u00b7ber", "ger\u00b7ne", "schrei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00f6gen's meine Leser tragen!", "tokens": ["M\u00f6\u00b7gen's", "mei\u00b7ne", "Le\u00b7ser", "tra\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sollte hei\u00dfen: gern diktiere,", "tokens": ["Soll\u00b7te", "hei\u00b7\u00dfen", ":", "gern", "dik\u00b7tie\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$.", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und das ist doch auch ein Sprechen,", "tokens": ["Und", "das", "ist", "doch", "auch", "ein", "Spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wo ich keine Zeit verliere;", "tokens": ["Wo", "ich", "kei\u00b7ne", "Zeit", "ver\u00b7lie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Niemand wird mich unterbrechen.", "tokens": ["Nie\u00b7mand", "wird", "mich", "un\u00b7ter\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Wie im Auge mit fliegenden M\u00fccken,", "tokens": ["Wie", "im", "Au\u00b7ge", "mit", "flie\u00b7gen\u00b7den", "M\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "So ist's mit Sorgen ganz genau;", "tokens": ["So", "ist's", "mit", "Sor\u00b7gen", "ganz", "ge\u00b7nau", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn wir in die sch\u00f6ne Welt hineinblicken,", "tokens": ["Wenn", "wir", "in", "die", "sch\u00f6\u00b7ne", "Welt", "hin\u00b7ein\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da schwebt ein Spinnewebengrau;", "tokens": ["Da", "schwebt", "ein", "Spin\u00b7ne\u00b7we\u00b7ben\u00b7grau", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es \u00fcberzieht nicht, es zieht nur vor\u00fcber,", "tokens": ["Es", "\u00fc\u00b7berz\u00b7ieht", "nicht", ",", "es", "zieht", "nur", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das Bild ist gest\u00f6rt, wenn nur nicht tr\u00fcber;", "tokens": ["Das", "Bild", "ist", "ge\u00b7st\u00f6rt", ",", "wenn", "nur", "nicht", "tr\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "KOUS", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Die klare Welt bleibt klare Welt:", "tokens": ["Die", "kla\u00b7re", "Welt", "bleibt", "kla\u00b7re", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Im Auge nur ist's schlecht bestellt.", "tokens": ["Im", "Au\u00b7ge", "nur", "ist's", "schlecht", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Trage dein \u00dcbel, wie du magst,", "tokens": ["Tra\u00b7ge", "dein", "\u00dc\u00b7bel", ",", "wie", "du", "magst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Klage niemand dein Mi\u00dfgeschick;", "tokens": ["Kla\u00b7ge", "nie\u00b7mand", "dein", "Mi\u00df\u00b7ge\u00b7schick", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Wie du dem Freunde ", "tokens": ["Wie", "du", "dem", "Freun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Gibt er dir gleich ein Dutzend zur\u00fcck!", "tokens": ["Gibt", "er", "dir", "gleich", "ein", "Dut\u00b7zend", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.43": {"line.1": {"text": "In keiner Gilde kann man sein,", "tokens": ["In", "kei\u00b7ner", "Gil\u00b7de", "kann", "man", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "PIS", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man wisse denn zu schultern fein;", "tokens": ["Man", "wis\u00b7se", "denn", "zu", "schul\u00b7tern", "fein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PTKZU", "VVINF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das, was sie lieben, was sie hassen,", "tokens": ["Das", ",", "was", "sie", "lie\u00b7ben", ",", "was", "sie", "has\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "VVINF", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das mu\u00df man eben geschehen lassen;", "tokens": ["Das", "mu\u00df", "man", "e\u00b7ben", "ge\u00b7sche\u00b7hen", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Das, was sie wissen, l\u00e4\u00dft man gelten,", "tokens": ["Das", ",", "was", "sie", "wis\u00b7sen", ",", "l\u00e4\u00dft", "man", "gel\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "VVINF", "$,", "VVFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was sie nicht wissen, mu\u00df man schelten,", "tokens": ["Was", "sie", "nicht", "wis\u00b7sen", ",", "mu\u00df", "man", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VVINF", "$,", "VMFIN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Althergebrachtes weiterf\u00fchren,", "tokens": ["Al\u00b7ther\u00b7ge\u00b7brach\u00b7tes", "wei\u00b7ter\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Das Neue kl\u00fcglich retardieren;", "tokens": ["Das", "Neu\u00b7e", "kl\u00fcg\u00b7lich", "re\u00b7tar\u00b7die\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Dann werden sie dir zugestehn,", "tokens": ["Dann", "wer\u00b7den", "sie", "dir", "zu\u00b7ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Auch nebenher deinen Weg zu gehn.", "tokens": ["Auch", "ne\u00b7ben\u00b7her", "dei\u00b7nen", "Weg", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.44": {"line.1": {"text": "Doch w\u00fcrden sie, k\u00f6nnt es gelingen,", "tokens": ["Doch", "w\u00fcr\u00b7den", "sie", ",", "k\u00f6nnt", "es", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$,", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Zum Widerruf dich pf\u00e4ffisch zwingen.", "tokens": ["Zum", "Wi\u00b7der\u00b7ruf", "dich", "pf\u00e4f\u00b7fisch", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Hemmet ihr verschm\u00e4hten Freier", "tokens": ["Hem\u00b7met", "ihr", "ver\u00b7schm\u00e4h\u00b7ten", "Frei\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht die schlechtgestimmte Leier,", "tokens": ["Nicht", "die", "schlecht\u00b7ge\u00b7stimm\u00b7te", "Lei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So verzweifl' ich ganz und gar;", "tokens": ["So", "ver\u00b7zweifl'", "ich", "ganz", "und", "gar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Isis zeigt sich ohne Schleier,", "tokens": ["I\u00b7sis", "zeigt", "sich", "oh\u00b7ne", "Schlei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch der Mensch, er hat den Star.", "tokens": ["Doch", "der", "Mensch", ",", "er", "hat", "den", "Star", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Die geschichtlichen Symbole \u2013", "tokens": ["Die", "ge\u00b7schicht\u00b7li\u00b7chen", "Sym\u00b7bo\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00f6rig, wer sie wichtig h\u00e4lt;", "tokens": ["T\u00f6\u00b7rig", ",", "wer", "sie", "wich\u00b7tig", "h\u00e4lt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWS", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Immer forschet er ins Hohle", "tokens": ["Im\u00b7mer", "for\u00b7schet", "er", "ins", "Hoh\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vers\u00e4umt die reiche Welt.", "tokens": ["Und", "ver\u00b7s\u00e4umt", "die", "rei\u00b7che", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Suche nicht verborgne Weihe!", "tokens": ["Su\u00b7che", "nicht", "ver\u00b7borg\u00b7ne", "Wei\u00b7he", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unterm Schleier la\u00df das Starre!", "tokens": ["Un\u00b7term", "Schlei\u00b7er", "la\u00df", "das", "Star\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Willst du leben, guter Narre,", "tokens": ["Willst", "du", "le\u00b7ben", ",", "gu\u00b7ter", "Nar\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sieh nur hinter dich ins Freie.", "tokens": ["Sieh", "nur", "hin\u00b7ter", "dich", "ins", "Frei\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Einheit ewigen Lichts zu spalten,", "tokens": ["Ein\u00b7heit", "e\u00b7wi\u00b7gen", "Lichts", "zu", "spal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "M\u00fcssen wir f\u00fcr t\u00f6rig halten,", "tokens": ["M\u00fcs\u00b7sen", "wir", "f\u00fcr", "t\u00f6\u00b7rig", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn euch Irrtum schon gen\u00fcgt.", "tokens": ["Wenn", "euch", "Irr\u00b7tum", "schon", "ge\u00b7n\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hell und Dunkel, Licht und Schatten,", "tokens": ["Hell", "und", "Dun\u00b7kel", ",", "Licht", "und", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wei\u00df man kl\u00fcglich sie zu gatten,", "tokens": ["Wei\u00df", "man", "kl\u00fcg\u00b7lich", "sie", "zu", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist das Farbenreich besiegt.", "tokens": ["Ist", "das", "Far\u00b7ben\u00b7reich", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Die beiden lieben sich gar fein,", "tokens": ["Die", "bei\u00b7den", "lie\u00b7ben", "sich", "gar", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "M\u00f6gen nicht ohne einander sein.", "tokens": ["M\u00f6\u00b7gen", "nicht", "oh\u00b7ne", "ein\u00b7an\u00b7der", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "PRF", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wie eins im andern sich verliert,", "tokens": ["Wie", "eins", "im", "an\u00b7dern", "sich", "ver\u00b7liert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPRART", "ADJA", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Manch buntes Kind sich ausgebiert,", "tokens": ["Manch", "bun\u00b7tes", "Kind", "sich", "aus\u00b7ge\u00b7biert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im eignen Auge schaue mit Lust,", "tokens": ["Im", "eig\u00b7nen", "Au\u00b7ge", "schau\u00b7e", "mit", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Was Plato von Anbeginn gewu\u00dft;", "tokens": ["Was", "Pla\u00b7to", "von", "An\u00b7be\u00b7ginn", "ge\u00b7wu\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Denn das ist der Natur Gehalt,", "tokens": ["Denn", "das", "ist", "der", "Na\u00b7tur", "Ge\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Da\u00df au\u00dfen gilt, was innen galt.", "tokens": ["Da\u00df", "au\u00b7\u00dfen", "gilt", ",", "was", "in\u00b7nen", "galt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Freunde, flieht die dunkle Kammer,", "tokens": ["Freun\u00b7de", ",", "flieht", "die", "dunk\u00b7le", "Kam\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo man euch das Licht verzwickt", "tokens": ["Wo", "man", "euch", "das", "Licht", "ver\u00b7zwickt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit k\u00fcmmerlichstem Jammer", "tokens": ["Und", "mit", "k\u00fcm\u00b7mer\u00b7lichs\u00b7tem", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich verschrobnen Bildern b\u00fcckt.", "tokens": ["Sich", "ver\u00b7schrob\u00b7nen", "Bil\u00b7dern", "b\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Abergl\u00e4ubische Verehrer", "tokens": ["A\u00b7berg\u00b7l\u00e4u\u00b7bi\u00b7sche", "Ver\u00b7eh\u00b7rer"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gab's die Jahre her genug,", "tokens": ["Gab's", "die", "Jah\u00b7re", "her", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APZR", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "In den K\u00f6pfen eurer Lehrer La\u00dft", "tokens": ["In", "den", "K\u00f6p\u00b7fen", "eu\u00b7rer", "Leh\u00b7rer", "La\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Gespenst und Wahn und Trug.", "tokens": ["Ge\u00b7spenst", "und", "Wahn", "und", "Trug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "Wenn der Blick an heitern Tagen", "tokens": ["Wenn", "der", "Blick", "an", "hei\u00b7tern", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich zur Himmelsbl\u00e4ue lenkt,", "tokens": ["Sich", "zur", "Him\u00b7mels\u00b7bl\u00e4u\u00b7e", "lenkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Beim Sirok der Sonnenwagen", "tokens": ["Beim", "Si\u00b7rok", "der", "Son\u00b7nen\u00b7wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Purpurrot sich niedersenkt,", "tokens": ["Pur\u00b7pur\u00b7rot", "sich", "nie\u00b7der\u00b7senkt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da gebt der Natur die Ehre,", "tokens": ["Da", "gebt", "der", "Na\u00b7tur", "die", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Froh, an Aug und Herz gesund,", "tokens": ["Froh", ",", "an", "Aug", "und", "Herz", "ge\u00b7sund", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und erkennt der Farbenlehre", "tokens": ["Und", "er\u00b7kennt", "der", "Far\u00b7ben\u00b7leh\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Allgemeinen, ewigen Grund.", "tokens": ["All\u00b7ge\u00b7mei\u00b7nen", ",", "e\u00b7wi\u00b7gen", "Grund", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.52": {"line.1": {"text": "Das wirst du sie nicht \u00fcberreden,", "tokens": ["Das", "wirst", "du", "sie", "nicht", "\u00fc\u00b7berr\u00b7e\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie rechnen dich ja zu den Bl\u00f6den,", "tokens": ["Sie", "rech\u00b7nen", "dich", "ja", "zu", "den", "Bl\u00f6\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von bl\u00f6den Augen, bl\u00f6den Sinnen;", "tokens": ["Von", "bl\u00f6\u00b7den", "Au\u00b7gen", ",", "bl\u00f6\u00b7den", "Sin\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Finsternis im Lichte drinnen,", "tokens": ["Die", "Fins\u00b7ter\u00b7nis", "im", "Lich\u00b7te", "drin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die kannst du ewig nicht erfassen;", "tokens": ["Die", "kannst", "du", "e\u00b7wig", "nicht", "er\u00b7fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mu\u00dft das den Herren \u00fcberlassen,", "tokens": ["Mu\u00dft", "das", "den", "Her\u00b7ren", "\u00fc\u00b7ber\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die's zu beweisen sind erb\u00f6tig.", "tokens": ["Die's", "zu", "be\u00b7wei\u00b7sen", "sind", "er\u00b7b\u00f6\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKZU", "VVINF", "VAFIN", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Gott sei den guten Sch\u00fclern gn\u00e4dig!", "tokens": ["Gott", "sei", "den", "gu\u00b7ten", "Sch\u00fc\u00b7lern", "gn\u00e4\u00b7dig", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Mit Widerlegen, Bedingen, Begrimmen", "tokens": ["Mit", "Wi\u00b7der\u00b7le\u00b7gen", ",", "Be\u00b7din\u00b7gen", ",", "Be\u00b7grim\u00b7men"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bem\u00fcht und br\u00fcstet mancher sich;", "tokens": ["Be\u00b7m\u00fcht", "und", "br\u00fcs\u00b7tet", "man\u00b7cher", "sich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "PIS", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich kann daraus nichts weiter gewinnen,", "tokens": ["Ich", "kann", "da\u00b7raus", "nichts", "wei\u00b7ter", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als da\u00df er anders denkt wie ich.", "tokens": ["Als", "da\u00df", "er", "an\u00b7ders", "denkt", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "VVFIN", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Wie man die K\u00f6nige verletzt,", "tokens": ["Wie", "man", "die", "K\u00f6\u00b7ni\u00b7ge", "ver\u00b7letzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird der Granit auch abgesetzt;", "tokens": ["Wird", "der", "Gra\u00b7nit", "auch", "ab\u00b7ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und Gneis, der Sohn, ist nun Papa!", "tokens": ["Und", "Gneis", ",", "der", "Sohn", ",", "ist", "nun", "Pa\u00b7pa", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "NN", "$,", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch dessen Untergang ist nah:", "tokens": ["Auch", "des\u00b7sen", "Un\u00b7ter\u00b7gang", "ist", "nah", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn Plutos Gabel drohet schon", "tokens": ["Denn", "Plu\u00b7tos", "Ga\u00b7bel", "dro\u00b7het", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Urgrund Revolution;", "tokens": ["Dem", "Ur\u00b7grund", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Basalt, der schwarze Teufelsmohr,", "tokens": ["Ba\u00b7salt", ",", "der", "schwar\u00b7ze", "Teu\u00b7fels\u00b7mohr", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus tiefster H\u00f6lle bricht hervor,", "tokens": ["Aus", "tiefs\u00b7ter", "H\u00f6l\u00b7le", "bricht", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zerspaltet Fels, Gestein und Erden,", "tokens": ["Zer\u00b7spal\u00b7tet", "Fels", ",", "Ge\u00b7stein", "und", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Omega mu\u00df zum Alpha werden.", "tokens": ["O\u00b7me\u00b7ga", "mu\u00df", "zum", "Al\u00b7pha", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "APPRART", "NN", "VAINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Und so w\u00e4re denn die liebe Welt", "tokens": ["Und", "so", "w\u00e4\u00b7re", "denn", "die", "lie\u00b7be", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Geognostisch auch auf den Kopf gestellt.", "tokens": ["Ge\u00b7og\u00b7nos\u00b7tisch", "auch", "auf", "den", "Kopf", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Kaum wendet der edle Werner den R\u00fccken,", "tokens": ["Kaum", "wen\u00b7det", "der", "ed\u00b7le", "Wer\u00b7ner", "den", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zerst\u00f6rt man das Poseidaonische Reich;", "tokens": ["Zer\u00b7st\u00f6rt", "man", "das", "Po\u00b7sei\u00b7dao\u00b7nisc\u00b7he", "Reich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn alle sich vor Heph\u00e4stos b\u00fccken,", "tokens": ["Wenn", "al\u00b7le", "sich", "vor", "He\u00b7ph\u00e4s\u00b7tos", "b\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich kann es nicht sogleich;", "tokens": ["Ich", "kann", "es", "nicht", "sog\u00b7leich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich wei\u00df nur in der Folge zu sch\u00e4tzen.", "tokens": ["Ich", "wei\u00df", "nur", "in", "der", "Fol\u00b7ge", "zu", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Schon hab ich manches Credo verpa\u00dft;", "tokens": ["Schon", "hab", "ich", "man\u00b7ches", "Cre\u00b7do", "ver\u00b7pa\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Mir sind sie alle gleich verha\u00dft,", "tokens": ["Mir", "sind", "sie", "al\u00b7le", "gleich", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Neue G\u00f6tter und G\u00f6tzen.", "tokens": ["Neu\u00b7e", "G\u00f6t\u00b7ter", "und", "G\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.56": {"line.1": {"text": "Urspr\u00fcnglich eignen Sinn", "tokens": ["Ur\u00b7spr\u00fcng\u00b7lich", "eig\u00b7nen", "Sinn"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "La\u00df dir nicht rauben!", "tokens": ["La\u00df", "dir", "nicht", "rau\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Woran die Menge glaubt,", "tokens": ["Wo\u00b7ran", "die", "Men\u00b7ge", "glaubt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist leicht zu glauben.", "tokens": ["Ist", "leicht", "zu", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.57": {"line.1": {"text": "Nat\u00fcrlich mit Verstand", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "mit", "Ver\u00b7stand"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sei du beflissen;", "tokens": ["Sei", "du", "be\u00b7flis\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "$."], "meter": "---+-", "measure": "unknown.measure.single"}, "line.3": {"text": "Was der Gescheite wei\u00df,", "tokens": ["Was", "der", "Ge\u00b7schei\u00b7te", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist schwer zu wissen.", "tokens": ["Ist", "schwer", "zu", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.58": {"line.1": {"text": "Je mehr man kennt, je mehr man wei\u00df,", "tokens": ["Je", "mehr", "man", "kennt", ",", "je", "mehr", "man", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVFIN", "$,", "ADV", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erkennt man: alles dreht im Kreis;", "tokens": ["Er\u00b7kennt", "man", ":", "al\u00b7les", "dreht", "im", "Kreis", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$.", "PIS", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erst lehrt man jenes, lehrt man dies,", "tokens": ["Erst", "lehrt", "man", "je\u00b7nes", ",", "lehrt", "man", "dies", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PDS", "$,", "VVFIN", "PIS", "PDS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun aber waltet ganz gewi\u00df", "tokens": ["Nun", "a\u00b7ber", "wal\u00b7tet", "ganz", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im innern Erdenspatium", "tokens": ["Im", "in\u00b7nern", "Er\u00b7den\u00b7spa\u00b7ti\u00b7um"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Pyro-Hydrophylacium,", "tokens": ["Py\u00b7ro\u00b7Hy\u00b7dro\u00b7phyla\u00b7ci\u00b7um", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Damit's der Erden Oberfl\u00e4che", "tokens": ["Da\u00b7mit's", "der", "Er\u00b7den", "O\u00b7berf\u00b7l\u00e4\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "An Feuer und Wasser nicht gebreche.", "tokens": ["An", "Feu\u00b7er", "und", "Was\u00b7ser", "nicht", "ge\u00b7bre\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKNEG", "ADJA", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wo k\u00e4me denn ein Ding sonst her,", "tokens": ["Wo", "k\u00e4\u00b7me", "denn", "ein", "Ding", "sonst", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wenn es nicht l\u00e4ngst schon fertig w\u00e4r?", "tokens": ["Wenn", "es", "nicht", "l\u00e4ngst", "schon", "fer\u00b7tig", "w\u00e4r", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "So ist denn, eh man sich's versah,", "tokens": ["So", "ist", "denn", ",", "eh", "man", "sich's", "ver\u00b7sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der Pater Kircher wieder da.", "tokens": ["Der", "Pa\u00b7ter", "Kir\u00b7cher", "wie\u00b7der", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Will mich jedoch des Worts nicht sch\u00e4men:", "tokens": ["Will", "mich", "je\u00b7doch", "des", "Worts", "nicht", "sch\u00e4\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.14": {"text": "Wir tasten ewig an Problemen.", "tokens": ["Wir", "tas\u00b7ten", "e\u00b7wig", "an", "Prob\u00b7le\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Keine Gluten, keine Meere", "tokens": ["Kei\u00b7ne", "Glu\u00b7ten", ",", "kei\u00b7ne", "Mee\u00b7re"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Geb ich in dem Innern zu;", "tokens": ["Geb", "ich", "in", "dem", "In\u00b7nern", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch allherrschend waltet Schwere,", "tokens": ["Doch", "all\u00b7herr\u00b7schend", "wal\u00b7tet", "Schwe\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Nicht verdammt zu Tod und Ruh.", "tokens": ["Nicht", "ver\u00b7dammt", "zu", "Tod", "und", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vom lebendigen Gott lebendig,", "tokens": ["Vom", "le\u00b7ben\u00b7di\u00b7gen", "Gott", "le\u00b7ben\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch den Geist, der alles regt,", "tokens": ["Durch", "den", "Geist", ",", "der", "al\u00b7les", "regt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wechselt sie, nicht unbest\u00e4ndig,", "tokens": ["Wech\u00b7selt", "sie", ",", "nicht", "un\u00b7be\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Immer in sich selbst bewegt.", "tokens": ["Im\u00b7mer", "in", "sich", "selbst", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Seht nur hin! Ihr werdet's fassen!", "tokens": ["Seht", "nur", "hin", "!", "Ihr", "wer\u00b7det's", "fas\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$.", "PPER", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn Merkur sich hebt und neigt,", "tokens": ["Wenn", "Mer\u00b7kur", "sich", "hebt", "und", "neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Wird im Anziehn, im Entlassen", "tokens": ["Wird", "im", "An\u00b7ziehn", ",", "im", "Ent\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "APPRART", "NN", "$,", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Atmosph\u00e4re schwer und leicht.", "tokens": ["At\u00b7mo\u00b7sph\u00e4\u00b7re", "schwer", "und", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Mir gen\u00fcgt nicht eure Lehre:", "tokens": ["Mir", "ge\u00b7n\u00fcgt", "nicht", "eu\u00b7re", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ebb und Flut der Atmosph\u00e4re \u2013", "tokens": ["Ebb", "und", "Flut", "der", "At\u00b7mo\u00b7sph\u00e4\u00b7re", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denk sich's jeder, wie er kann!", "tokens": ["Denk", "sich's", "je\u00b7der", ",", "wie", "er", "kann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "PIS", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Will mich nur an Hermes halten;", "tokens": ["Will", "mich", "nur", "an", "Her\u00b7mes", "hal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn des Barometers Walten", "tokens": ["Denn", "des", "Ba\u00b7ro\u00b7me\u00b7ters", "Wal\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Ist der Witterung Tyrann.", "tokens": ["Ist", "der", "Wit\u00b7te\u00b7rung", "Ty\u00b7rann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Westen mag die Luft regieren,", "tokens": ["Wes\u00b7ten", "mag", "die", "Luft", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sturm und Flut nach Osten f\u00fchren,", "tokens": ["Sturm", "und", "Flut", "nach", "Os\u00b7ten", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn Merkur sich schl\u00e4frig zeigt;", "tokens": ["Wenn", "Mer\u00b7kur", "sich", "schl\u00e4f\u00b7rig", "zeigt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Aller Elemente Toben,", "tokens": ["Al\u00b7ler", "E\u00b7le\u00b7men\u00b7te", "To\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Osther ist es aufgehoben,", "tokens": ["Ost\u00b7her", "ist", "es", "auf\u00b7ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn er aus dem Schlummer steigt.", "tokens": ["Wenn", "er", "aus", "dem", "Schlum\u00b7mer", "steigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Das Leben wohnt in jedem Sterne:", "tokens": ["Das", "Le\u00b7ben", "wohnt", "in", "je\u00b7dem", "Ster\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er wandelt mit den andern gerne", "tokens": ["Er", "wan\u00b7delt", "mit", "den", "an\u00b7dern", "ger\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die selbsterw\u00e4hlte reine Bahn;", "tokens": ["Die", "selbs\u00b7ter\u00b7w\u00e4hl\u00b7te", "rei\u00b7ne", "Bahn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im innern Erdenball pulsieren", "tokens": ["Im", "in\u00b7nern", "Er\u00b7den\u00b7ball", "pul\u00b7sie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Kr\u00e4fte, die zur Nacht uns f\u00fchren", "tokens": ["Die", "Kr\u00e4f\u00b7te", ",", "die", "zur", "Nacht", "uns", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und wieder zu dem Tag heran.", "tokens": ["Und", "wie\u00b7der", "zu", "dem", "Tag", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Wenn im Unendlichen dasselbe", "tokens": ["Wenn", "im", "Un\u00b7end\u00b7li\u00b7chen", "das\u00b7sel\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "PDAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich wiederholend ewig flie\u00dft,", "tokens": ["Sich", "wie\u00b7der\u00b7ho\u00b7lend", "e\u00b7wig", "flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das tausendf\u00e4ltige Gew\u00f6lbe", "tokens": ["Das", "tau\u00b7send\u00b7f\u00e4l\u00b7ti\u00b7ge", "Ge\u00b7w\u00f6l\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich kr\u00e4ftig ineinander schlie\u00dft,", "tokens": ["Sich", "kr\u00e4f\u00b7tig", "in\u00b7ein\u00b7an\u00b7der", "schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Str\u00f6mt Lebenslust aus allen Dingen,", "tokens": ["Str\u00f6mt", "Le\u00b7bens\u00b7lust", "aus", "al\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dem kleinsten wie dem gr\u00f6\u00dften Stern", "tokens": ["Dem", "kleins\u00b7ten", "wie", "dem", "gr\u00f6\u00df\u00b7ten", "Stern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und alles Dr\u00e4ngen, alles Ringen", "tokens": ["Und", "al\u00b7les", "Dr\u00e4n\u00b7gen", ",", "al\u00b7les", "Rin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIAT", "NN", "$,", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist ewige Ruh in Gott dem Herrn.", "tokens": ["Ist", "e\u00b7wi\u00b7ge", "Ruh", "in", "Gott", "dem", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.65": {"line.1": {"text": "Nachts, wann gute Geister schweifen,", "tokens": ["Nachts", ",", "wann", "gu\u00b7te", "Geis\u00b7ter", "schwei\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schlaf dir von der Stirne streifen,", "tokens": ["Schlaf", "dir", "von", "der", "Stir\u00b7ne", "strei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mondenlicht und Sternenflimmern", "tokens": ["Mon\u00b7den\u00b7licht", "und", "Ster\u00b7nen\u00b7flim\u00b7mern"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dich mit ewigem All umschimmern,", "tokens": ["Dich", "mit", "e\u00b7wi\u00b7gem", "All", "um\u00b7schim\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Scheinst du dir entk\u00f6rpert schon,", "tokens": ["Scheinst", "du", "dir", "ent\u00b7k\u00f6r\u00b7pert", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wagest dich an Gottes Thron.", "tokens": ["Wa\u00b7gest", "dich", "an", "Got\u00b7tes", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "Aber wenn der Tag die Welt", "tokens": ["A\u00b7ber", "wenn", "der", "Tag", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wieder auf die F\u00fc\u00dfe stellt,", "tokens": ["Wie\u00b7der", "auf", "die", "F\u00fc\u00b7\u00dfe", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwerlich m\u00f6cht er dir's erf\u00fcllen", "tokens": ["Schwer\u00b7lich", "m\u00f6cht", "er", "dir's", "er\u00b7f\u00fcl\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit der Fr\u00fche bestem Willen;", "tokens": ["Mit", "der", "Fr\u00fc\u00b7he", "bes\u00b7tem", "Wil\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zu Mittag schon wandelt sich", "tokens": ["Zu", "Mit\u00b7tag", "schon", "wan\u00b7delt", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "VVFIN", "PRF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Morgentraum gar wunderlich.", "tokens": ["Mor\u00b7gen\u00b7traum", "gar", "wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.67": {"line.1": {"text": "Sei du im Leben wie im Wissen", "tokens": ["Sei", "du", "im", "Le\u00b7ben", "wie", "im", "Wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "KOKOM", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durchaus der reinen Fahrt beflissen;", "tokens": ["Durc\u00b7haus", "der", "rei\u00b7nen", "Fahrt", "be\u00b7flis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Sturm und Str\u00f6mung sto\u00dfen, zerrn,", "tokens": ["Wenn", "Sturm", "und", "Str\u00f6\u00b7mung", "sto\u00b7\u00dfen", ",", "zerrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie werden doch nicht deine Herrn;", "tokens": ["Sie", "wer\u00b7den", "doch", "nicht", "dei\u00b7ne", "Herrn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kompa\u00df und Pol-Stern, Zeitenmesser", "tokens": ["Kom\u00b7pa\u00df", "und", "Pol\u00b7S\u00b7tern", ",", "Zei\u00b7ten\u00b7mes\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["VVIMP", "KON", "NN", "$,", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Sonn und Mond verstehst du besser,", "tokens": ["Und", "Sonn", "und", "Mond", "ver\u00b7stehst", "du", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vollendest so nach deiner Art", "tokens": ["Voll\u00b7en\u00b7dest", "so", "nach", "dei\u00b7ner", "Art"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit stillen Freuden deine Fahrt.", "tokens": ["Mit", "stil\u00b7len", "Freu\u00b7den", "dei\u00b7ne", "Fahrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Besonders, wenn dich's nicht verdrie\u00dft,", "tokens": ["Be\u00b7son\u00b7ders", ",", "wenn", "dich's", "nicht", "ver\u00b7drie\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wo sich der Weg im Kreise schlie\u00dft;", "tokens": ["Wo", "sich", "der", "Weg", "im", "Krei\u00b7se", "schlie\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der Weltumsegler freudig trifft", "tokens": ["Der", "Welt\u00b7um\u00b7seg\u00b7ler", "freu\u00b7dig", "trifft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Den Hafen, wo er ausgeschifft.", "tokens": ["Den", "Ha\u00b7fen", ",", "wo", "er", "aus\u00b7ge\u00b7schifft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Wie fruchtbar ist der kleinste Kreis,", "tokens": ["Wie", "frucht\u00b7bar", "ist", "der", "kleins\u00b7te", "Kreis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn man ihn wohl zu pflegen wei\u00df.", "tokens": ["Wenn", "man", "ihn", "wohl", "zu", "pfle\u00b7gen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Wenn Kindesblick begierig schaut,", "tokens": ["Wenn", "Kin\u00b7des\u00b7blick", "be\u00b7gie\u00b7rig", "schaut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er findet des Vaters Haus gebaut;", "tokens": ["Er", "fin\u00b7det", "des", "Va\u00b7ters", "Haus", "ge\u00b7baut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wenn das Ohr sich erst vertraut,", "tokens": ["Und", "wenn", "das", "Ohr", "sich", "erst", "ver\u00b7traut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm t\u00f6nt der Muttersprache Laut;", "tokens": ["Ihm", "t\u00f6nt", "der", "Mut\u00b7ter\u00b7spra\u00b7che", "Laut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gewahrt es dies und jenes nah,", "tokens": ["Ge\u00b7wahrt", "es", "dies", "und", "je\u00b7nes", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "KON", "PDS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man fabelt ihm, was fern geschah,", "tokens": ["Man", "fa\u00b7belt", "ihm", ",", "was", "fern", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Umsittigt ihn, w\u00e4chst er heran;", "tokens": ["Um\u00b7sit\u00b7tigt", "ihn", ",", "w\u00e4chst", "er", "he\u00b7ran", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Er findet eben alles getan.", "tokens": ["Er", "fin\u00b7det", "e\u00b7ben", "al\u00b7les", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Man r\u00fchmt ihm dies, man preist ihm das:", "tokens": ["Man", "r\u00fchmt", "ihm", "dies", ",", "man", "preist", "ihm", "das", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PDS", "$,", "PIS", "VVFIN", "PPER", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Er w\u00e4re gar gern auch etwas;", "tokens": ["Er", "w\u00e4\u00b7re", "gar", "gern", "auch", "et\u00b7was", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wie er soll wirken, schaffen, lieben,", "tokens": ["Wie", "er", "soll", "wir\u00b7ken", ",", "schaf\u00b7fen", ",", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Das steht ja alles schon geschrieben", "tokens": ["Das", "steht", "ja", "al\u00b7les", "schon", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PIS", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und, was noch schlimmer ist, gedruckt;", "tokens": ["Und", ",", "was", "noch", "schlim\u00b7mer", "ist", ",", "ge\u00b7druckt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Da steht der junge Mensch verduckt,", "tokens": ["Da", "steht", "der", "jun\u00b7ge", "Mensch", "ver\u00b7duckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und endlich wird ihm offenbar:", "tokens": ["Und", "end\u00b7lich", "wird", "ihm", "of\u00b7fen\u00b7bar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Er sei nur, was ein andrer war.", "tokens": ["Er", "sei", "nur", ",", "was", "ein", "an\u00b7drer", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PRELS", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Gern w\u00e4r ich \u00dcberliefrung los", "tokens": ["Gern", "w\u00e4r", "ich", "\u00dc\u00b7berl\u00b7ief\u00b7rung", "los"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ganz original;", "tokens": ["Und", "ganz", "o\u00b7rig\u00b7i\u00b7nal", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch ist das Unternehmen gro\u00df", "tokens": ["Doch", "ist", "das", "Un\u00b7ter\u00b7neh\u00b7men", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und f\u00fchrt in manche Qual.", "tokens": ["Und", "f\u00fchrt", "in", "man\u00b7che", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Als Autochthone rechnet ich", "tokens": ["Als", "Au\u00b7toch\u00b7tho\u00b7ne", "rech\u00b7net", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es mir zur h\u00f6chsten Ehre,", "tokens": ["Es", "mir", "zur", "h\u00f6chs\u00b7ten", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wenn ich nicht gar zu wunderlich", "tokens": ["Wenn", "ich", "nicht", "gar", "zu", "wun\u00b7der\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Selbst \u00dcberliefrung w\u00e4re.", "tokens": ["Selbst", "\u00dc\u00b7berl\u00b7ief\u00b7rung", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "Vom Vater hab ich die Statur,", "tokens": ["Vom", "Va\u00b7ter", "hab", "ich", "die", "Sta\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Lebens ernstes F\u00fchren,", "tokens": ["Des", "Le\u00b7bens", "erns\u00b7tes", "F\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von M\u00fctterchen die Frohnatur", "tokens": ["Von", "M\u00fct\u00b7ter\u00b7chen", "die", "Froh\u00b7na\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Lust zu fabulieren.", "tokens": ["Und", "Lust", "zu", "fa\u00b7bu\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Urahnherr war der Sch\u00f6nsten hold,", "tokens": ["Ur\u00b7ah\u00b7nherr", "war", "der", "Sch\u00f6ns\u00b7ten", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das spukt so hin und wieder,", "tokens": ["Das", "spukt", "so", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKVZ", "KON", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Urahnfrau liebte Schmuck und Gold,", "tokens": ["U\u00b7rahn\u00b7frau", "lieb\u00b7te", "Schmuck", "und", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Das zuckt wohl durch die Glieder.", "tokens": ["Das", "zuckt", "wohl", "durch", "die", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Sind nun die Elemente nicht", "tokens": ["Sind", "nun", "die", "E\u00b7le\u00b7men\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Aus dem Komplex zu trennen,", "tokens": ["Aus", "dem", "Kom\u00b7plex", "zu", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Was ist denn an dem ganzen Wicht", "tokens": ["Was", "ist", "denn", "an", "dem", "gan\u00b7zen", "Wicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Original zu nennen?", "tokens": ["O\u00b7rig\u00b7i\u00b7nal", "zu", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+----", "measure": "unknown.measure.di"}}, "stanza.72": {"line.1": {"text": "Teilen kann ich nicht das Leben,", "tokens": ["Tei\u00b7len", "kann", "ich", "nicht", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht das Innen noch das Au\u00dfen,", "tokens": ["Nicht", "das", "In\u00b7nen", "noch", "das", "Au\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Allen mu\u00df das Ganze geben,", "tokens": ["Al\u00b7len", "mu\u00df", "das", "Gan\u00b7ze", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um mit euch und mir zu hausen.", "tokens": ["Um", "mit", "euch", "und", "mir", "zu", "hau\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "PPER", "KON", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Immer hab ich nur geschrieben,", "tokens": ["Im\u00b7mer", "hab", "ich", "nur", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie ich f\u00fchle, wie ich's meine,", "tokens": ["Wie", "ich", "f\u00fch\u00b7le", ",", "wie", "ich's", "mei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und so spalt ich mich, ihr Lieben,", "tokens": ["Und", "so", "spalt", "ich", "mich", ",", "ihr", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$,", "PPOSAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und bin immerfort der ", "tokens": ["Und", "bin", "im\u00b7mer\u00b7fort", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}