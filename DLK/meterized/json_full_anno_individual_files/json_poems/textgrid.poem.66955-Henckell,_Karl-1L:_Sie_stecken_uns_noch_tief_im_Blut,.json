{"textgrid.poem.66955": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sie stecken uns noch tief im Blut,", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie stecken uns noch tief im Blut,", "tokens": ["Sie", "ste\u00b7cken", "uns", "noch", "tief", "im", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die rohen Henkerskniffe,", "tokens": ["Die", "ro\u00b7hen", "Hen\u00b7kers\u00b7knif\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Richtergeist von B\u00f6s und Gut,", "tokens": ["Der", "Rich\u00b7ter\u00b7geist", "von", "B\u00f6s", "und", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die groben Grenzbegriffe.", "tokens": ["Die", "gro\u00b7ben", "Grenz\u00b7be\u00b7grif\u00b7fe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wir sprechen skrupellos von Schuld", "tokens": ["Wir", "spre\u00b7chen", "skru\u00b7pel\u00b7los", "von", "Schuld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und S\u00fchne der Verbrechen,", "tokens": ["Und", "S\u00fch\u00b7ne", "der", "Ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie wir von Gottes Gnadenhuld", "tokens": ["Wie", "wir", "von", "Got\u00b7tes", "Gna\u00b7den\u00b7huld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Strafe Gottes sprechen.", "tokens": ["Und", "Stra\u00b7fe", "Got\u00b7tes", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich aber bin vielleicht durch Nichts", "tokens": ["Ich", "a\u00b7ber", "bin", "viel\u00b7leicht", "durch", "Nichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom M\u00f6rder unterschieden", "tokens": ["Vom", "M\u00f6r\u00b7der", "un\u00b7ter\u00b7schie\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als durch die Sch\u00f6pfung des Gedichts", "tokens": ["Als", "durch", "die", "Sch\u00f6p\u00b7fung", "des", "Ge\u00b7dichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und freiern Seelenfrieden.", "tokens": ["Und", "frei\u00b7ern", "See\u00b7len\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Sie stecken uns noch tief im Blut,", "tokens": ["Sie", "ste\u00b7cken", "uns", "noch", "tief", "im", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die rohen Henkerskniffe,", "tokens": ["Die", "ro\u00b7hen", "Hen\u00b7kers\u00b7knif\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Richtergeist von B\u00f6s und Gut,", "tokens": ["Der", "Rich\u00b7ter\u00b7geist", "von", "B\u00f6s", "und", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die groben Grenzbegriffe.", "tokens": ["Die", "gro\u00b7ben", "Grenz\u00b7be\u00b7grif\u00b7fe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wir sprechen skrupellos von Schuld", "tokens": ["Wir", "spre\u00b7chen", "skru\u00b7pel\u00b7los", "von", "Schuld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und S\u00fchne der Verbrechen,", "tokens": ["Und", "S\u00fch\u00b7ne", "der", "Ver\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie wir von Gottes Gnadenhuld", "tokens": ["Wie", "wir", "von", "Got\u00b7tes", "Gna\u00b7den\u00b7huld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Strafe Gottes sprechen.", "tokens": ["Und", "Stra\u00b7fe", "Got\u00b7tes", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ich aber bin vielleicht durch Nichts", "tokens": ["Ich", "a\u00b7ber", "bin", "viel\u00b7leicht", "durch", "Nichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom M\u00f6rder unterschieden", "tokens": ["Vom", "M\u00f6r\u00b7der", "un\u00b7ter\u00b7schie\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als durch die Sch\u00f6pfung des Gedichts", "tokens": ["Als", "durch", "die", "Sch\u00f6p\u00b7fung", "des", "Ge\u00b7dichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und freiern Seelenfrieden.", "tokens": ["Und", "frei\u00b7ern", "See\u00b7len\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}