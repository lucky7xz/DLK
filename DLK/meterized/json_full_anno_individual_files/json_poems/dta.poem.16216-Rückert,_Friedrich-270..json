{"dta.poem.16216": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "270.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195088", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein Sohn, wenn du dich hast vergangen, b\u00fc\u00df' es gleich;", "tokens": ["Mein", "Sohn", ",", "wenn", "du", "dich", "hast", "ver\u00b7gan\u00b7gen", ",", "b\u00fc\u00df'", "es", "gleich", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn des Vergehens harrt fr\u00fch oder sp\u00e4t der Streich.", "tokens": ["Denn", "des", "Ver\u00b7ge\u00b7hens", "harrt", "fr\u00fch", "o\u00b7der", "sp\u00e4t", "der", "Streich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "KON", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie aber b\u00fc\u00dfest du's? Dadurch, da\u00df du bereuest,", "tokens": ["Wie", "a\u00b7ber", "b\u00fc\u00b7\u00dfest", "du's", "?", "Da\u00b7durch", ",", "da\u00df", "du", "be\u00b7re\u00b7u\u00b7est", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PIS", "$.", "PAV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Und dich des sicheren Gef\u00fchls der Be\u00dfrung freuest.", "tokens": ["Und", "dich", "des", "si\u00b7che\u00b7ren", "Ge\u00b7f\u00fchls", "der", "Be\u00df\u00b7rung", "freu\u00b7est", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Mein Sohn, sei \u00fcberzeugt, es gibt noch Herzensk\u00fcnder,", "tokens": ["Mein", "Sohn", ",", "sei", "\u00fc\u00b7berz\u00b7eugt", ",", "es", "gibt", "noch", "Her\u00b7zen\u00b7sk\u00fcn\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Gott allein nicht sieht ins Innre jedem S\u00fcnder.", "tokens": ["Und", "Gott", "al\u00b7lein", "nicht", "sieht", "ins", "Inn\u00b7re", "je\u00b7dem", "S\u00fcn\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "PTKNEG", "VVFIN", "APPRART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ins Innre siehet auch dir jeder, dem getr\u00fcbt", "tokens": ["Ins", "Inn\u00b7re", "sie\u00b7het", "auch", "dir", "je\u00b7der", ",", "dem", "ge\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "PPER", "PIS", "$,", "PRELS", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Geistes Sehkraft selbst nicht ist, noch unge\u00fcbt.", "tokens": ["Des", "Geis\u00b7tes", "Seh\u00b7kraft", "selbst", "nicht", "ist", ",", "noch", "un\u00b7ge\u00b7\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "PTKNEG", "VAFIN", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Und welchem Blicke du begegnest, mu\u00dft du bangen,", "tokens": ["Und", "wel\u00b7chem", "Bli\u00b7cke", "du", "be\u00b7geg\u00b7nest", ",", "mu\u00dft", "du", "ban\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "PPER", "VVFIN", "$,", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df er von Gott die Kraft, dich zu durchschaun, empfangen.", "tokens": ["Da\u00df", "er", "von", "Gott", "die", "Kraft", ",", "dich", "zu", "durch\u00b7schaun", ",", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "An deiner Stirne steht's, dort wird er es entdecken;", "tokens": ["An", "dei\u00b7ner", "Stir\u00b7ne", "steht's", ",", "dort", "wird", "er", "es", "ent\u00b7de\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wegwischen kannst du's nicht, du kannst es nicht verstecken.", "tokens": ["Weg\u00b7wi\u00b7schen", "kannst", "du's", "nicht", ",", "du", "kannst", "es", "nicht", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "PTKNEG", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Drum wenn dort B\u00f6ses steht geschrieben, schreibe du", "tokens": ["Drum", "wenn", "dort", "B\u00f6\u00b7ses", "steht", "ge\u00b7schrie\u00b7ben", ",", "schrei\u00b7be", "du"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "KOUS", "ADV", "NN", "VVFIN", "VVPP", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In leserlicher Schrift die Be\u00dfrung auch dazu.", "tokens": ["In", "le\u00b7ser\u00b7li\u00b7cher", "Schrift", "die", "Be\u00df\u00b7rung", "auch", "da\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "ADV", "PAV", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Nicht ungeschrieben zwar wird, was ist ausgestrichen,", "tokens": ["Nicht", "un\u00b7ge\u00b7schrie\u00b7ben", "zwar", "wird", ",", "was", "ist", "aus\u00b7ge\u00b7stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "VAFIN", "$,", "PWS", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Doch f\u00fcr den Rechnerblick die Rechnung ausgeglichen.", "tokens": ["Doch", "f\u00fcr", "den", "Rech\u00b7ner\u00b7blick", "die", "Rech\u00b7nung", "aus\u00b7ge\u00b7gli\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Mein Sohn, nicht darin such' hier Gottes Strafgericht,", "tokens": ["Mein", "Sohn", ",", "nicht", "da\u00b7rin", "such'", "hier", "Got\u00b7tes", "Straf\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PTKNEG", "PAV", "VVFIN", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df jedem S\u00fcnder man die Strafe sichtbar spricht;", "tokens": ["Da\u00df", "je\u00b7dem", "S\u00fcn\u00b7der", "man", "die", "Stra\u00b7fe", "sicht\u00b7bar", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PIS", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Darin, da\u00df keiner hier ges\u00fcndigt und verbrochen,", "tokens": ["Da\u00b7rin", ",", "da\u00df", "kei\u00b7ner", "hier", "ge\u00b7s\u00fcn\u00b7digt", "und", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PIS", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nicht sich selber hat sein Strafurteil gesprochen.", "tokens": ["Der", "nicht", "sich", "sel\u00b7ber", "hat", "sein", "Stra\u00b7fur\u00b7teil", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "PRF", "ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Straf' ist ihm das Gef\u00fchl, da\u00df er strafw\u00fcrdig sei,", "tokens": ["Straf'", "ist", "ihm", "das", "Ge\u00b7f\u00fchl", ",", "da\u00df", "er", "straf\u00b7w\u00fcr\u00b7dig", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mehr noch Strafe dis, da\u00df er von Straf' ist frei.", "tokens": ["Und", "mehr", "noch", "Stra\u00b7fe", "dis", ",", "da\u00df", "er", "von", "Straf'", "ist", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "NN", "PDS", "$,", "KOUS", "PPER", "APPR", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Denn denken mu\u00df er, wenn sie hier ihn nicht ereilt,", "tokens": ["Denn", "den\u00b7ken", "mu\u00df", "er", ",", "wenn", "sie", "hier", "ihn", "nicht", "er\u00b7eilt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Entgegen eil' er ihr dort wo sie ewig weilt.", "tokens": ["Ent\u00b7ge\u00b7gen", "eil'", "er", "ihr", "dort", "wo", "sie", "e\u00b7wig", "weilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ADV", "PWAV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Und dis Geschw\u00fcr, das er doch pochen f\u00fchlt und kochen,", "tokens": ["Und", "dis", "Ge\u00b7schw\u00fcr", ",", "das", "er", "doch", "po\u00b7chen", "f\u00fchlt", "und", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch besser w\u00e4r' es aufgebrochen, aufgestochen.", "tokens": ["Noch", "bes\u00b7ser", "w\u00e4r'", "es", "auf\u00b7ge\u00b7bro\u00b7chen", ",", "auf\u00b7ge\u00b7sto\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "VVPP", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ja besser w\u00e4r' es dir, du heiltest hier dich aus,", "tokens": ["Ja", "bes\u00b7ser", "w\u00e4r'", "es", "dir", ",", "du", "heil\u00b7test", "hier", "dich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADJD", "VAFIN", "PPER", "PPER", "$,", "PPER", "VVFIN", "ADV", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und k\u00e4mest dort gesund in deines Vaters Haus.", "tokens": ["Und", "k\u00e4\u00b7mest", "dort", "ge\u00b7sund", "in", "dei\u00b7nes", "Va\u00b7ters", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}