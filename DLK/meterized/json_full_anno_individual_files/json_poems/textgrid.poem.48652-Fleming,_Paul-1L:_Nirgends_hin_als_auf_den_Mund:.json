{"textgrid.poem.48652": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nirgends hin als auf den Mund:", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nirgends hin als auf den Mund:", "tokens": ["Nir\u00b7gends", "hin", "als", "auf", "den", "Mund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "da sinkts in des Herzen Grund;", "tokens": ["da", "sinkts", "in", "des", "Her\u00b7zen", "Grund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "nicht zu frei, nicht zu gezwungen,", "tokens": ["nicht", "zu", "frei", ",", "nicht", "zu", "ge\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "$,", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht mit gar zu fauler Zungen.", "tokens": ["nicht", "mit", "gar", "zu", "fau\u00b7ler", "Zun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Nicht zu wenig, nicht zu viel:", "tokens": ["Nicht", "zu", "we\u00b7nig", ",", "nicht", "zu", "viel", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "PIS", "$,", "PTKNEG", "PTKA", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "beides wird sonst Kinderspiel.", "tokens": ["bei\u00b7des", "wird", "sonst", "Kin\u00b7der\u00b7spiel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu laut und nicht zu leise:", "tokens": ["Nicht", "zu", "laut", "und", "nicht", "zu", "lei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "KON", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bei der Ma\u00df' ist rechte Weise.", "tokens": ["bei", "der", "Ma\u00df'", "ist", "rech\u00b7te", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Nicht zu nahe, nicht zu weit:", "tokens": ["Nicht", "zu", "na\u00b7he", ",", "nicht", "zu", "weit", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "$,", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "di\u00df macht Kummer, jenes Leid.", "tokens": ["di\u00df", "macht", "Kum\u00b7mer", ",", "je\u00b7nes", "Leid", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "$,", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu trucken, nicht zu feuchte,", "tokens": ["Nicht", "zu", "tru\u00b7cken", ",", "nicht", "zu", "feuch\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVINF", "$,", "PTKNEG", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie Adonis Venus reichte.", "tokens": ["wie", "A\u00b7do\u00b7nis", "Ve\u00b7nus", "reich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Nicht zu harte, nicht zu weich,", "tokens": ["Nicht", "zu", "har\u00b7te", ",", "nicht", "zu", "weich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVFIN", "$,", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "bald zugleich, bald nicht zugleich.", "tokens": ["bald", "zu\u00b7gleich", ",", "bald", "nicht", "zu\u00b7gleich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu langsam, nicht zu schnelle,", "tokens": ["Nicht", "zu", "lang\u00b7sam", ",", "nicht", "zu", "schnel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "$,", "PTKNEG", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht ohn' Unterscheid der Stelle.", "tokens": ["nicht", "ohn'", "Un\u00b7ter\u00b7scheid", "der", "Stel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Halb gebissen, halb gehaucht,", "tokens": ["Halb", "ge\u00b7bis\u00b7sen", ",", "halb", "ge\u00b7haucht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "halb die Lippen eingetaucht,", "tokens": ["halb", "die", "Lip\u00b7pen", "ein\u00b7ge\u00b7taucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nicht ohn' Unterscheid der Zeiten,", "tokens": ["nicht", "ohn'", "Un\u00b7ter\u00b7scheid", "der", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mehr alleine denn bei Leuten.", "tokens": ["mehr", "al\u00b7lei\u00b7ne", "denn", "bei", "Leu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "K\u00fcsse nun ein Iederman,", "tokens": ["K\u00fcs\u00b7se", "nun", "ein", "Ie\u00b7der\u00b7man", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wie er wei\u00df, will, soll und kan!", "tokens": ["wie", "er", "wei\u00df", ",", "will", ",", "soll", "und", "kan", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VMFIN", "$,", "VMFIN", "KON", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich nur und die Liebste wissen,", "tokens": ["Ich", "nur", "und", "die", "Liebs\u00b7te", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "wie wir uns recht sollen k\u00fcssen.", "tokens": ["wie", "wir", "uns", "recht", "sol\u00b7len", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Nirgends hin als auf den Mund:", "tokens": ["Nir\u00b7gends", "hin", "als", "auf", "den", "Mund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "da sinkts in des Herzen Grund;", "tokens": ["da", "sinkts", "in", "des", "Her\u00b7zen", "Grund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "nicht zu frei, nicht zu gezwungen,", "tokens": ["nicht", "zu", "frei", ",", "nicht", "zu", "ge\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "$,", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht mit gar zu fauler Zungen.", "tokens": ["nicht", "mit", "gar", "zu", "fau\u00b7ler", "Zun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nicht zu wenig, nicht zu viel:", "tokens": ["Nicht", "zu", "we\u00b7nig", ",", "nicht", "zu", "viel", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "PIS", "$,", "PTKNEG", "PTKA", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "beides wird sonst Kinderspiel.", "tokens": ["bei\u00b7des", "wird", "sonst", "Kin\u00b7der\u00b7spiel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu laut und nicht zu leise:", "tokens": ["Nicht", "zu", "laut", "und", "nicht", "zu", "lei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "KON", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bei der Ma\u00df' ist rechte Weise.", "tokens": ["bei", "der", "Ma\u00df'", "ist", "rech\u00b7te", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nicht zu nahe, nicht zu weit:", "tokens": ["Nicht", "zu", "na\u00b7he", ",", "nicht", "zu", "weit", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "$,", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "di\u00df macht Kummer, jenes Leid.", "tokens": ["di\u00df", "macht", "Kum\u00b7mer", ",", "je\u00b7nes", "Leid", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "$,", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu trucken, nicht zu feuchte,", "tokens": ["Nicht", "zu", "tru\u00b7cken", ",", "nicht", "zu", "feuch\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVINF", "$,", "PTKNEG", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie Adonis Venus reichte.", "tokens": ["wie", "A\u00b7do\u00b7nis", "Ve\u00b7nus", "reich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Nicht zu harte, nicht zu weich,", "tokens": ["Nicht", "zu", "har\u00b7te", ",", "nicht", "zu", "weich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVFIN", "$,", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "bald zugleich, bald nicht zugleich.", "tokens": ["bald", "zu\u00b7gleich", ",", "bald", "nicht", "zu\u00b7gleich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht zu langsam, nicht zu schnelle,", "tokens": ["Nicht", "zu", "lang\u00b7sam", ",", "nicht", "zu", "schnel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "$,", "PTKNEG", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht ohn' Unterscheid der Stelle.", "tokens": ["nicht", "ohn'", "Un\u00b7ter\u00b7scheid", "der", "Stel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Halb gebissen, halb gehaucht,", "tokens": ["Halb", "ge\u00b7bis\u00b7sen", ",", "halb", "ge\u00b7haucht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "halb die Lippen eingetaucht,", "tokens": ["halb", "die", "Lip\u00b7pen", "ein\u00b7ge\u00b7taucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nicht ohn' Unterscheid der Zeiten,", "tokens": ["nicht", "ohn'", "Un\u00b7ter\u00b7scheid", "der", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mehr alleine denn bei Leuten.", "tokens": ["mehr", "al\u00b7lei\u00b7ne", "denn", "bei", "Leu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "K\u00fcsse nun ein Iederman,", "tokens": ["K\u00fcs\u00b7se", "nun", "ein", "Ie\u00b7der\u00b7man", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wie er wei\u00df, will, soll und kan!", "tokens": ["wie", "er", "wei\u00df", ",", "will", ",", "soll", "und", "kan", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VMFIN", "$,", "VMFIN", "KON", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich nur und die Liebste wissen,", "tokens": ["Ich", "nur", "und", "die", "Liebs\u00b7te", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "wie wir uns recht sollen k\u00fcssen.", "tokens": ["wie", "wir", "uns", "recht", "sol\u00b7len", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}