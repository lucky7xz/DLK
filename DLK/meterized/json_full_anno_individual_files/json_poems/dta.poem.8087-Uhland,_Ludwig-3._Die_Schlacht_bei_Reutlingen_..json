{"dta.poem.8087": {"metadata": {"author": {"name": "Uhland, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "3.  Die Schlacht bei Reutlingen .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1815", "urn": "urn:nbn:de:kobv:b4-200905196438", "language": ["de:0.99"], "booktitle": "Uhland, Ludwig: Gedichte. Stuttgart u. a., 1815."}, "poem": {"stanza.1": {"line.1": {"text": "Zu Achalm auf dem Felsen, da haust manch k\u00fchner Aar,", "tokens": ["Zu", "A\u00b7chalm", "auf", "dem", "Fel\u00b7sen", ",", "da", "haust", "manch", "k\u00fch\u00b7ner", "Aar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Graf Ulrich, Sohn des Greiners, mit seiner Ritterschaar;", "tokens": ["Graf", "Ul\u00b7rich", ",", "Sohn", "des", "Grei\u00b7ners", ",", "mit", "sei\u00b7ner", "Rit\u00b7ter\u00b7schaar", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NN", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wild rauschen ihre Fl\u00fcge um Reutlingen die Stadt,", "tokens": ["Wild", "rau\u00b7schen", "ih\u00b7re", "Fl\u00fc\u00b7ge", "um", "Reut\u00b7lin\u00b7gen", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--++--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Bald scheint sie zu erliegen, vom hei\u00dfen Drange matt.\u201c", "tokens": ["Bald", "scheint", "sie", "zu", "er\u00b7lie\u00b7gen", ",", "vom", "hei\u00b7\u00dfen", "Dran\u00b7ge", "matt", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$,", "APPRART", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Doch pl\u00f6tzlich einst erheben die St\u00e4dter sich zu Nacht,", "tokens": ["Doch", "pl\u00f6tz\u00b7lich", "einst", "er\u00b7he\u00b7ben", "die", "St\u00e4d\u00b7ter", "sich", "zu", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VVFIN", "ART", "NN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "In\u2019s Urachthal hin\u00fcber sind sie mit gro\u00dfer Macht,", "tokens": ["In's", "U\u00b7racht\u00b7hal", "hin\u00b7\u00fc\u00b7ber", "sind", "sie", "mit", "gro\u00b7\u00dfer", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Bald steigt von Dorf und M\u00fchle die Flamme blutig roth,", "tokens": ["Bald", "steigt", "von", "Dorf", "und", "M\u00fch\u00b7le", "die", "Flam\u00b7me", "blu\u00b7tig", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Herden weggetrieben, die Hirten liegen todt.", "tokens": ["Die", "Her\u00b7den", "weg\u00b7ge\u00b7trie\u00b7ben", ",", "die", "Hir\u00b7ten", "lie\u00b7gen", "todt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Herr Ulrich hat\u2019s vernommen, er ruft im grimmen Zorn:", "tokens": ["Herr", "Ul\u00b7rich", "hat's", "ver\u00b7nom\u00b7men", ",", "er", "ruft", "im", "grim\u00b7men", "Zorn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u201ein eure Stadt soll kommen kein Huf und auch kein Horn!\u201c", "tokens": ["\u201e", "in", "eu\u00b7re", "Stadt", "soll", "kom\u00b7men", "kein", "Huf", "und", "auch", "kein", "Horn", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "PIAT", "NN", "KON", "ADV", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da sputen sich die Ritter, sie wappnen sich in Stahl,", "tokens": ["Da", "spu\u00b7ten", "sich", "die", "Rit\u00b7ter", ",", "sie", "wapp\u00b7nen", "sich", "in", "Stahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sie heischen ihre Rosse, sie reiten stracks zuthal.", "tokens": ["Sie", "hei\u00b7schen", "ih\u00b7re", "Ros\u00b7se", ",", "sie", "rei\u00b7ten", "stracks", "zut\u00b7hal", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Ein Kirchlein stehet drunten, Sankt Leonhard geweiht,", "tokens": ["Ein", "Kirch\u00b7lein", "ste\u00b7het", "drun\u00b7ten", ",", "Sankt", "Le\u00b7on\u00b7hard", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "VVFIN", "NE", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dabei ein gr\u00fcner Anger, der scheint bequem zum Streit.", "tokens": ["Da\u00b7bei", "ein", "gr\u00fc\u00b7ner", "An\u00b7ger", ",", "der", "scheint", "be\u00b7quem", "zum", "Streit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie springen von den Pferden, sie ziehen stolze Reihn,", "tokens": ["Sie", "sprin\u00b7gen", "von", "den", "Pfer\u00b7den", ",", "sie", "zie\u00b7hen", "stol\u00b7ze", "Reihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die langen Spie\u00dfe starren, wohlauf! wer wagt sich drein?", "tokens": ["Die", "lan\u00b7gen", "Spie\u00b7\u00dfe", "star\u00b7ren", ",", "wohl\u00b7auf", "!", "wer", "wagt", "sich", "drein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "$.", "PWS", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Schon ziehn vom Urachthale die St\u00e4dter fern herbei,", "tokens": ["Schon", "ziehn", "vom", "U\u00b7racht\u00b7ha\u00b7le", "die", "St\u00e4d\u00b7ter", "fern", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Man h\u00f6rt der M\u00e4nner Jauchzen, der Herden wild Geschrei,", "tokens": ["Man", "h\u00f6rt", "der", "M\u00e4n\u00b7ner", "Jauch\u00b7zen", ",", "der", "Her\u00b7den", "wild", "Ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$,", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Man sieht sie f\u00fcrder schreiten, ein wohlger\u00fcstet Heer;", "tokens": ["Man", "sieht", "sie", "f\u00fcr\u00b7der", "schrei\u00b7ten", ",", "ein", "wohl\u00b7ge\u00b7r\u00fcs\u00b7tet", "Heer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "VVFIN", "$,", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wie flattern stolz die Banner! wie blitzen Schwerdt und Speer!", "tokens": ["Wie", "flat\u00b7tern", "stolz", "die", "Ban\u00b7ner", "!", "wie", "blit\u00b7zen", "Schwerdt", "und", "Speer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADJD", "ART", "NN", "$.", "PWAV", "VVFIN", "NE", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Nun schlie\u00df dich fest zusammen, du ritterliche Schaar!", "tokens": ["Nun", "schlie\u00df", "dich", "fest", "zu\u00b7sam\u00b7men", ",", "du", "rit\u00b7ter\u00b7li\u00b7che", "Schaar", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wohl hast du nicht geahnet so dr\u00e4uende Gefahr.", "tokens": ["Wohl", "hast", "du", "nicht", "ge\u00b7ah\u00b7net", "so", "dr\u00e4u\u00b7en\u00b7de", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "VVPP", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die \u00fcberm\u00e4cht\u2019gen Rotten, sie st\u00fcrmen an mit Schwall,", "tokens": ["Die", "\u00fc\u00b7ber\u00b7m\u00e4cht'\u00b7gen", "Rot\u00b7ten", ",", "sie", "st\u00fcr\u00b7men", "an", "mit", "Schwall", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Ritter stehn und starren wie Fels und Mauerwall.", "tokens": ["Die", "Rit\u00b7ter", "stehn", "und", "star\u00b7ren", "wie", "Fels", "und", "Mau\u00b7er\u00b7wall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "VVFIN", "KOKOM", "NE", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Zu Reutlingen am Zwinger, da ist ein altes Thor,", "tokens": ["Zu", "Reut\u00b7lin\u00b7gen", "am", "Zwin\u00b7ger", ",", "da", "ist", "ein", "al\u00b7tes", "Thor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "NN", "$,", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "L\u00e4ngst wob mit dichten Ranken der Epheu sich davor,", "tokens": ["L\u00e4ngst", "wob", "mit", "dich\u00b7ten", "Ran\u00b7ken", "der", "E\u00b7pheu", "sich", "da\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "ART", "NN", "PRF", "PAV", "$,"], "meter": "-+-+-+---+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Man hat es schier vergessen, nun kracht\u2019s mit einmal auf,", "tokens": ["Man", "hat", "es", "schier", "ver\u00b7ges\u00b7sen", ",", "nun", "kracht's", "mit", "ein\u00b7mal", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADJD", "VVPP", "$,", "ADV", "VVFIN", "APPR", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und aus dem Zwinger st\u00fcrzet, gedr\u00e4ngt, ein B\u00fcrgerhauf\u2019.", "tokens": ["Und", "aus", "dem", "Zwin\u00b7ger", "st\u00fcr\u00b7zet", ",", "ge\u00b7dr\u00e4ngt", ",", "ein", "B\u00fcr\u00b7ger\u00b7hauf'", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "VVPP", "$,", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Den Rittern in den R\u00fccken f\u00e4llt er mit grauser Wuth,", "tokens": ["Den", "Rit\u00b7tern", "in", "den", "R\u00fc\u00b7cken", "f\u00e4llt", "er", "mit", "grau\u00b7ser", "Wuth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Heut will der St\u00e4dter baden im hei\u00dfen Ritterblut.", "tokens": ["Heut", "will", "der", "St\u00e4d\u00b7ter", "ba\u00b7den", "im", "hei\u00b7\u00dfen", "Rit\u00b7ter\u00b7blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Wie haben da die Gerber so meisterlich gegerbt!", "tokens": ["Wie", "ha\u00b7ben", "da", "die", "Ger\u00b7ber", "so", "meis\u00b7ter\u00b7lich", "ge\u00b7gerbt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wie haben da die F\u00e4rber so purpurroth gef\u00e4rbt!", "tokens": ["Wie", "ha\u00b7ben", "da", "die", "F\u00e4r\u00b7ber", "so", "pur\u00b7pur\u00b7roth", "ge\u00b7f\u00e4rbt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Heut nimmt man nicht gefangen, heut geht es auf den Tod,", "tokens": ["Heut", "nimmt", "man", "nicht", "ge\u00b7fan\u00b7gen", ",", "heut", "geht", "es", "auf", "den", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKNEG", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Heut spr\u00fctzt das Blut wie Regen, der Anger bl\u00fchet roth.", "tokens": ["Heut", "spr\u00fctzt", "das", "Blut", "wie", "Re\u00b7gen", ",", "der", "An\u00b7ger", "bl\u00fc\u00b7het", "roth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KOKOM", "NN", "$,", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Stets dr\u00e4ngender umschlossen und w\u00fcthender best\u00fcrmt,", "tokens": ["Stets", "dr\u00e4n\u00b7gen\u00b7der", "um\u00b7schlos\u00b7sen", "und", "w\u00fct\u00b7hen\u00b7der", "be\u00b7st\u00fcrmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ist rings von Bruderleichen die Ritterschaar umth\u00fcrmt.", "tokens": ["Ist", "rings", "von", "Bru\u00b7der\u00b7lei\u00b7chen", "die", "Rit\u00b7ter\u00b7schaar", "umt\u00b7h\u00fcrmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Das F\u00e4hnlein ist verloren, Herr Ulrich blutet stark,", "tokens": ["Das", "F\u00e4hn\u00b7lein", "ist", "ver\u00b7lo\u00b7ren", ",", "Herr", "Ul\u00b7rich", "blu\u00b7tet", "stark", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "NN", "NE", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Die noch am Leben blieben, sind m\u00fcde bis in\u2019s Mark.", "tokens": ["Die", "noch", "am", "Le\u00b7ben", "blie\u00b7ben", ",", "sind", "m\u00fc\u00b7de", "bis", "in's", "Mark", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da haschen sie nach Rossen und schwingen sich darauf,", "tokens": ["Da", "ha\u00b7schen", "sie", "nach", "Ros\u00b7sen", "und", "schwin\u00b7gen", "sich", "da\u00b7rauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "KON", "VVFIN", "PRF", "PAV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sie hauen durch, sie kommen zur festen Burg hinauf.", "tokens": ["Sie", "hau\u00b7en", "durch", ",", "sie", "kom\u00b7men", "zur", "fes\u00b7ten", "Burg", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "\u201each Allm\u2014\u201c st\u00f6hnt\u2019 einst ein Ritter, ihn traf des M\u00f6rders", "tokens": ["\u201e", "ach", "Allm", "\u201c", "st\u00f6hnt'", "einst", "ein", "Rit\u00b7ter", ",", "ihn", "traf", "des", "M\u00f6r\u00b7ders"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "XY", "XY", "$(", "$(", "VVFIN", "ADV", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sto\u00df \u2014", "tokens": ["Sto\u00df"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Allm\u00e4cht\u2019ger! wollt\u2019 er rufen \u2014 man hie\u00df davon das Schlo\u00df.", "tokens": ["All\u00b7m\u00e4cht'\u00b7ger", "!", "wollt'", "er", "ru\u00b7fen", "man", "hie\u00df", "da\u00b7von", "das", "Schlo\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "VMFIN", "PPER", "VVINF", "$(", "PIS", "VVFIN", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Herr Ulrich sinkt vom Sattel, halbtodt, voll Blut und Qualm,", "tokens": ["Herr", "Ul\u00b7rich", "sinkt", "vom", "Sat\u00b7tel", ",", "halb\u00b7todt", ",", "voll", "Blut", "und", "Qualm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPRART", "NN", "$,", "ADJD", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "H\u00e4tt\u2019 nicht das Schlo\u00df den Namen, man hie\u00df\u2019 es jetzt: ", "tokens": ["H\u00e4tt'", "nicht", "das", "Schlo\u00df", "den", "Na\u00b7men", ",", "man", "hie\u00df'", "es", "jetzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "ART", "NN", "$,", "PIS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.12": {"line.1": {"text": "Wohl k\u00f6mmt am andern Morgen zu Reutlingen an\u2019s Thor", "tokens": ["Wohl", "k\u00f6mmt", "am", "an\u00b7dern", "Mor\u00b7gen", "zu", "Reut\u00b7lin\u00b7gen", "an's", "Thor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN", "APPR", "NE", "APPRART", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Manch trauervoller Knappe, der seinen Herrn verlor.", "tokens": ["Manch", "trau\u00b7er\u00b7vol\u00b7ler", "Knap\u00b7pe", ",", "der", "sei\u00b7nen", "Herrn", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dort auf dem Rathhaus liegen die Todten all gereiht,", "tokens": ["Dort", "auf", "dem", "Rath\u00b7haus", "lie\u00b7gen", "die", "Tod\u00b7ten", "all", "ge\u00b7reiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "PIAT", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Man f\u00fchrt dahin die Knechte mir sicherem Geleit.", "tokens": ["Man", "f\u00fchrt", "da\u00b7hin", "die", "Knech\u00b7te", "mir", "si\u00b7che\u00b7rem", "Ge\u00b7leit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PAV", "ART", "NN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}}, "stanza.13": {"line.1": {"text": "Dort liegen mehr denn sechszig, so blutig und so bleich,", "tokens": ["Dort", "lie\u00b7gen", "mehr", "denn", "sechs\u00b7zig", ",", "so", "blu\u00b7tig", "und", "so", "bleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "CARD", "$,", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nicht jeder Knapp\u2019 erkennet den todten Herrn sogleich.", "tokens": ["Nicht", "je\u00b7der", "Knapp'", "er\u00b7ken\u00b7net", "den", "tod\u00b7ten", "Herrn", "sog\u00b7leich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dann wird ein jeder Leichnam von treuen Dieners Hand", "tokens": ["Dann", "wird", "ein", "je\u00b7der", "Leich\u00b7nam", "von", "treu\u00b7en", "Die\u00b7ners", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "PIAT", "NN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Gewaschen und gekleidet in weisses Grabgewand.", "tokens": ["Ge\u00b7wa\u00b7schen", "und", "ge\u00b7klei\u00b7det", "in", "weis\u00b7ses", "Grab\u00b7ge\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "Auf Bahren und auf Wagen getragen und gef\u00fchrt,", "tokens": ["Auf", "Bah\u00b7ren", "und", "auf", "Wa\u00b7gen", "ge\u00b7tra\u00b7gen", "und", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit Eichenlaub bekr\u00e4nzet, wie\u2019s Helden wohl geb\u00fchrt,", "tokens": ["Mit", "Ei\u00b7chen\u00b7laub", "be\u00b7kr\u00e4n\u00b7zet", ",", "wie's", "Hel\u00b7den", "wohl", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So geht es nach dem Thore, die alte Stadt entlang,", "tokens": ["So", "geht", "es", "nach", "dem", "Tho\u00b7re", ",", "die", "al\u00b7te", "Stadt", "ent\u00b7lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Dumpf t\u00f6net von den Th\u00fcrmen der Todtenglocken Klang.", "tokens": ["Dumpf", "t\u00f6\u00b7net", "von", "den", "Th\u00fcr\u00b7men", "der", "Tod\u00b7ten\u00b7glo\u00b7cken", "Klang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "G\u00f6tz Weissenheim er\u00f6ffnet den langen Leichenzug,", "tokens": ["G\u00f6tz", "Weis\u00b7sen\u00b7heim", "er\u00b7\u00f6ff\u00b7net", "den", "lan\u00b7gen", "Lei\u00b7chen\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er war es, der im Streite des Grafen Banner trug,", "tokens": ["Er", "war", "es", ",", "der", "im", "Strei\u00b7te", "des", "Gra\u00b7fen", "Ban\u00b7ner", "trug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "APPRART", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er hatt\u2019 es nicht gelassen, bis er erschlagen war,", "tokens": ["Er", "hatt'", "es", "nicht", "ge\u00b7las\u00b7sen", ",", "bis", "er", "er\u00b7schla\u00b7gen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Drum mag er w\u00fcrdig f\u00fchren auch noch die todte Schaar.", "tokens": ["Drum", "mag", "er", "w\u00fcr\u00b7dig", "f\u00fch\u00b7ren", "auch", "noch", "die", "tod\u00b7te", "Schaar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADJD", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "Drei edle Grafen folgen, bew\u00e4hrt in Schildesamt,", "tokens": ["Drei", "ed\u00b7le", "Gra\u00b7fen", "fol\u00b7gen", ",", "be\u00b7w\u00e4hrt", "in", "Schil\u00b7des\u00b7amt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVINF", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von T\u00fcbingen, von Zollern, von Schwarzenberg entstammt.", "tokens": ["Von", "T\u00fc\u00b7bin\u00b7gen", ",", "von", "Zol\u00b7lern", ",", "von", "Schwar\u00b7zen\u00b7berg", "ent\u00b7stammt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "O Zollern! deine Leiche umschwebt ein lichter Kranz:", "tokens": ["O", "Zol\u00b7lern", "!", "dei\u00b7ne", "Lei\u00b7che", "um\u00b7schwebt", "ein", "lich\u00b7ter", "Kranz", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sahst du vielleicht noch sterbend dein Haus im k\u00fcnft\u2019gen Glanz?", "tokens": ["Sahst", "du", "viel\u00b7leicht", "noch", "ster\u00b7bend", "dein", "Haus", "im", "k\u00fcnft'\u00b7gen", "Glanz", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.17": {"line.1": {"text": "Von Sachsenheim zween Ritter, der Vater und der Sohn,", "tokens": ["Von", "Sach\u00b7sen\u00b7heim", "zween", "Rit\u00b7ter", ",", "der", "Va\u00b7ter", "und", "der", "Sohn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die liegen still beisammen in Lilien und in Mohn,", "tokens": ["Die", "lie\u00b7gen", "still", "bei\u00b7sam\u00b7men", "in", "Li\u00b7li\u00b7en", "und", "in", "Mohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "VVFIN", "APPR", "NE", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Auf ihrer Stammburg wandelt von Alters her ein Geist,", "tokens": ["Auf", "ih\u00b7rer", "Stamm\u00b7burg", "wan\u00b7delt", "von", "Al\u00b7ters", "her", "ein", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "APPR", "NN", "APZR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der l\u00e4ngst mit Klaggeb\u00e4rden auf schweres Unheil weist.", "tokens": ["Der", "l\u00e4ngst", "mit", "Klag\u00b7ge\u00b7b\u00e4r\u00b7den", "auf", "schwe\u00b7res", "Un\u00b7heil", "weist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Einst war ein Herr von Lustnau vom Scheintod auferwacht,", "tokens": ["Einst", "war", "ein", "Herr", "von", "Lust\u00b7nau", "vom", "Schein\u00b7tod", "au\u00b7fer\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NE", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er kehrt\u2019 im Leichentuche zu seiner Frau bei Nacht,", "tokens": ["Er", "kehrt'", "im", "Lei\u00b7chen\u00b7tu\u00b7che", "zu", "sei\u00b7ner", "Frau", "bei", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Davon man sein Geschlechte ", "tokens": ["Da\u00b7von", "man", "sein", "Ge\u00b7schlech\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hier bringt man ihrer einen, den traf der Tod in\u2019s Herz.", "tokens": ["Hier", "bringt", "man", "ih\u00b7rer", "ei\u00b7nen", ",", "den", "traf", "der", "Tod", "in's", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPOSAT", "ART", "$,", "ART", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Das Lied, es folgt nicht weiter, des Jammers ist genug,", "tokens": ["Das", "Lied", ",", "es", "folgt", "nicht", "wei\u00b7ter", ",", "des", "Jam\u00b7mers", "ist", "ge\u00b7nug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Will Jemand Alle wissen, die man von dannen trug:", "tokens": ["Will", "Je\u00b7mand", "Al\u00b7le", "wis\u00b7sen", ",", "die", "man", "von", "dan\u00b7nen", "trug", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PIS", "VVINF", "$,", "PRELS", "PIS", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dort auf den Rathhausfenstern, in Farben bunt und klar,", "tokens": ["Dort", "auf", "den", "Rath\u00b7haus\u00b7fens\u00b7tern", ",", "in", "Far\u00b7ben", "bunt", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "APPR", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Stellt jeden Ritters Name und Wappenschild sich dar.", "tokens": ["Stellt", "je\u00b7den", "Rit\u00b7ters", "Na\u00b7me", "und", "Wap\u00b7pen\u00b7schild", "sich", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NN", "KON", "NN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "Als nun von seinen Wunden Graf Ulrich ausgeheilt,", "tokens": ["Als", "nun", "von", "sei\u00b7nen", "Wun\u00b7den", "Graf", "Ul\u00b7rich", "aus\u00b7ge\u00b7heilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "NE", "NE", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da reitet er nach Stuttgart, er hat nicht sehr geeilt;", "tokens": ["Da", "rei\u00b7tet", "er", "nach", "Stutt\u00b7gart", ",", "er", "hat", "nicht", "sehr", "ge\u00b7eilt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "$,", "PPER", "VAFIN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er trifft den alten Vater allein am Mittagsmahl,", "tokens": ["Er", "trifft", "den", "al\u00b7ten", "Va\u00b7ter", "al\u00b7lein", "am", "Mit\u00b7tags\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein frostiger Willkommen! kein Wort ert\u00f6nt im Saal.", "tokens": ["Ein", "fros\u00b7ti\u00b7ger", "Will\u00b7kom\u00b7men", "!", "kein", "Wort", "er\u00b7t\u00f6nt", "im", "Saal", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PIAT", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.21": {"line.1": {"text": "Dem Vater gegen\u00fcber sitzt Ulrich an den Tisch,", "tokens": ["Dem", "Va\u00b7ter", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "sitzt", "Ul\u00b7rich", "an", "den", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPO", "VVFIN", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Er schl\u00e4gt die Augen nieder, man bringt ihm Wein und Fisch;", "tokens": ["Er", "schl\u00e4gt", "die", "Au\u00b7gen", "nie\u00b7der", ",", "man", "bringt", "ihm", "Wein", "und", "Fisch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PIS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da fa\u00dft der Greis ein Messer, und spricht kein Wort dabei,", "tokens": ["Da", "fa\u00dft", "der", "Greis", "ein", "Mes\u00b7ser", ",", "und", "spricht", "kein", "Wort", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,", "KON", "VVFIN", "PIAT", "NN", "PAV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und schneidet zwischen Beiden das Tafeltuch entzwei.", "tokens": ["Und", "schnei\u00b7det", "zwi\u00b7schen", "Bei\u00b7den", "das", "Ta\u00b7fel\u00b7tuch", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIS", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}}}}