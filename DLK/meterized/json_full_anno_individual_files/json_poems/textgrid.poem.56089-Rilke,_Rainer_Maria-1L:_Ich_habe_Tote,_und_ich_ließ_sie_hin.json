{"textgrid.poem.56089": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich habe Tote, und ich lie\u00df sie hin", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe Tote, und ich lie\u00df sie hin", "tokens": ["Ich", "ha\u00b7be", "To\u00b7te", ",", "und", "ich", "lie\u00df", "sie", "hin"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und war erstaunt, sie so getrost zu sehn,", "tokens": ["und", "war", "er\u00b7staunt", ",", "sie", "so", "ge\u00b7trost", "zu", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$,", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so rasch zuhaus im Totsein, so gerecht,", "tokens": ["so", "rasch", "zu\u00b7haus", "im", "Tot\u00b7sein", ",", "so", "ge\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "APPRART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "so anders als ihr Ruf. Nur du, du kehrst", "tokens": ["so", "an\u00b7ders", "als", "ihr", "Ruf", ".", "Nur", "du", ",", "du", "kehrst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "KOKOM", "PPOSAT", "NN", "$.", "ADV", "PPER", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "zur\u00fcck; du streifst mich, du gehst um, du willst", "tokens": ["zu\u00b7r\u00fcck", ";", "du", "streifst", "mich", ",", "du", "gehst", "um", ",", "du", "willst"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKVZ", "$.", "PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "an etwas sto\u00dfen, da\u00df es klingt von dir", "tokens": ["an", "et\u00b7was", "sto\u00b7\u00dfen", ",", "da\u00df", "es", "klingt", "von", "dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und dich verr\u00e4t. O nimm mir nicht, was ich", "tokens": ["und", "dich", "ver\u00b7r\u00e4t", ".", "O", "nimm", "mir", "nicht", ",", "was", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "NE", "VVFIN", "PPER", "PTKNEG", "$,", "PWS", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "langsam erlern. Ich habe recht; du irrst", "tokens": ["lang\u00b7sam", "er\u00b7lern", ".", "Ich", "ha\u00b7be", "recht", ";", "du", "irrst"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVINF", "$.", "PPER", "VAFIN", "ADJD", "$.", "PPER", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "wenn du ger\u00fchrt zu irgend einem Ding", "tokens": ["wenn", "du", "ge\u00b7r\u00fchrt", "zu", "ir\u00b7gend", "ei\u00b7nem", "Ding"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "APPR", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "ein Heimweh hast. Wir wandeln dieses um;", "tokens": ["ein", "Heim\u00b7weh", "hast", ".", "Wir", "wan\u00b7deln", "die\u00b7ses", "um", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "PPER", "VVFIN", "PDAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "es ist nicht hier, wir spiegeln es herein", "tokens": ["es", "ist", "nicht", "hier", ",", "wir", "spie\u00b7geln", "es", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "aus unserm Sein, sobald wir es erkennen.", "tokens": ["aus", "un\u00b7serm", "Sein", ",", "so\u00b7bald", "wir", "es", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich glaubte dich viel weiter. Mich verwirrts,", "tokens": ["Ich", "glaub\u00b7te", "dich", "viel", "wei\u00b7ter", ".", "Mich", "ver\u00b7wirrts", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df ", "tokens": ["da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "verwandelt hat als irgend eine Frau.", "tokens": ["ver\u00b7wan\u00b7delt", "hat", "als", "ir\u00b7gend", "ei\u00b7ne", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KOKOM", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df wir erschraken, da du starbst, nein, da\u00df", "tokens": ["Da\u00df", "wir", "er\u00b7schra\u00b7ken", ",", "da", "du", "starbst", ",", "nein", ",", "da\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "$,", "PTKANT", "$,", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "dein starker Tod uns dunkel unterbrach,", "tokens": ["dein", "star\u00b7ker", "Tod", "uns", "dun\u00b7kel", "un\u00b7ter\u00b7brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "das Bisdahin abrei\u00dfend vom Seither:", "tokens": ["das", "Bis\u00b7da\u00b7hin", "ab\u00b7rei\u00b7\u00dfend", "vom", "Sei\u00b7ther", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPRART", "NN", "$."], "meter": "-+--++--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "das geht uns an; das einzuordnen wird", "tokens": ["das", "geht", "uns", "an", ";", "das", "ein\u00b7zu\u00b7ord\u00b7nen", "wird"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$.", "PDS", "VVINF", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "die Arbeit sein, die wir mit allem tun.", "tokens": ["die", "Ar\u00b7beit", "sein", ",", "die", "wir", "mit", "al\u00b7lem", "tun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "$,", "PRELS", "PPER", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Doch da\u00df du selbst erschrakst und auch noch jetzt", "tokens": ["Doch", "da\u00df", "du", "selbst", "er\u00b7schrakst", "und", "auch", "noch", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "KON", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "den Schrecken hast, wo Schrecken nicht mehr gilt;", "tokens": ["den", "Schre\u00b7cken", "hast", ",", "wo", "Schre\u00b7cken", "nicht", "mehr", "gilt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "da\u00df du von deiner Ewigkeit ein St\u00fcck", "tokens": ["da\u00df", "du", "von", "dei\u00b7ner", "E\u00b7wig\u00b7keit", "ein", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "verlierst und hier hereintrittst, Freundin, hier,", "tokens": ["ver\u00b7lierst", "und", "hier", "her\u00b7ein\u00b7trittst", ",", "Freun\u00b7din", ",", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "KON", "ADV", "VVFIN", "$,", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "wo alles noch nicht ", "tokens": ["wo", "al\u00b7les", "noch", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "PTKNEG"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "zum ersten Mal im All zerstreut und halb,", "tokens": ["zum", "ers\u00b7ten", "Mal", "im", "All", "zer\u00b7streut", "und", "halb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "NN", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "den Aufgang der unendlichen Naturen", "tokens": ["den", "Auf\u00b7gang", "der", "un\u00b7end\u00b7li\u00b7chen", "Na\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "nicht so ergriffst wie hier ein jedes Ding;", "tokens": ["nicht", "so", "er\u00b7griffst", "wie", "hier", "ein", "je\u00b7des", "Ding", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "KOKOM", "ADV", "ART", "PIAT", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.17": {"text": "da\u00df aus dem Kreislauf, der dich schon empfing,", "tokens": ["da\u00df", "aus", "dem", "Kreis\u00b7lauf", ",", "der", "dich", "schon", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "die stumme Schwerkraft irgend einer Unruh", "tokens": ["die", "stum\u00b7me", "Schwer\u00b7kraft", "ir\u00b7gend", "ei\u00b7ner", "Un\u00b7ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "dich niederzieht zur abgez\u00e4hlten Zeit \u2013:", "tokens": ["dich", "nie\u00b7der\u00b7zieht", "zur", "ab\u00b7ge\u00b7z\u00e4hl\u00b7ten", "Zeit", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "dies weckt mich nachts oft wie ein Dieb, der einbricht.", "tokens": ["dies", "weckt", "mich", "nachts", "oft", "wie", "ein", "Dieb", ",", "der", "ein\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "KOKOM", "ART", "NN", "$,", "PRELS", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.21": {"text": "Und d\u00fcrft ich sagen, da\u00df du nur geruhst,", "tokens": ["Und", "d\u00fcrft", "ich", "sa\u00b7gen", ",", "da\u00df", "du", "nur", "ge\u00b7ruhst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,", "KOUS", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "da\u00df du aus Gro\u00dfmut kommst, aus \u00dcberf\u00fclle,", "tokens": ["da\u00df", "du", "aus", "Gro\u00df\u00b7mut", "kommst", ",", "aus", "\u00dc\u00b7berf\u00b7\u00fcl\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "weil du so sicher bist, so in dir selbst,", "tokens": ["weil", "du", "so", "si\u00b7cher", "bist", ",", "so", "in", "dir", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "da\u00df du herumgehst wie ein Kind, nicht bange", "tokens": ["da\u00df", "du", "her\u00b7um\u00b7gehst", "wie", "ein", "Kind", ",", "nicht", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,", "PTKNEG", "ADV"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "vor \u00d6rtern, wo man einem etwas tut \u2013:", "tokens": ["vor", "\u00d6r\u00b7tern", ",", "wo", "man", "ei\u00b7nem", "et\u00b7was", "tut", "\u2013", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "PIS", "ART", "ADV", "ADJD", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "doch nein: du bittest. Dieses geht mir so", "tokens": ["doch", "nein", ":", "du", "bit\u00b7test", ".", "Die\u00b7ses", "geht", "mir", "so"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PTKANT", "$.", "PPER", "VVFIN", "$.", "PDS", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "bis ins Gebein und querrt wie eine S\u00e4ge.", "tokens": ["bis", "ins", "Ge\u00b7bein", "und", "querrt", "wie", "ei\u00b7ne", "S\u00e4\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Ein Vorwurf, den du tr\u00fcgest als Gespenst,", "tokens": ["Ein", "Vor\u00b7wurf", ",", "den", "du", "tr\u00fc\u00b7gest", "als", "Ge\u00b7spenst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "nachtr\u00fcgest mir, wenn ich mich nachts zur\u00fcckzieh", "tokens": ["nach\u00b7tr\u00fc\u00b7gest", "mir", ",", "wenn", "ich", "mich", "nachts", "zu\u00b7r\u00fcck\u00b7zieh"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "ADV", "VVFIN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.30": {"text": "in meine Lunge, in die Eingeweide,", "tokens": ["in", "mei\u00b7ne", "Lun\u00b7ge", ",", "in", "die", "Ein\u00b7ge\u00b7wei\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "in meines Herzens letzte \u00e4rmste Kammer, \u2013", "tokens": ["in", "mei\u00b7nes", "Her\u00b7zens", "letz\u00b7te", "\u00e4rms\u00b7te", "Kam\u00b7mer", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "ein solcher Vorwurf w\u00e4re nicht so grausam,", "tokens": ["ein", "sol\u00b7cher", "Vor\u00b7wurf", "w\u00e4\u00b7re", "nicht", "so", "grau\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "wie dieses Bitten ist. Was bittest du?", "tokens": ["wie", "die\u00b7ses", "Bit\u00b7ten", "ist", ".", "Was", "bit\u00b7test", "du", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "VAFIN", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sag, soll ich reisen? Hast du irgendwo", "tokens": ["Sag", ",", "soll", "ich", "rei\u00b7sen", "?", "Hast", "du", "ir\u00b7gend\u00b7wo"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VMFIN", "PPER", "VVINF", "$.", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ein Ding zur\u00fcckgelassen, das sich qu\u00e4lt", "tokens": ["ein", "Ding", "zu\u00b7r\u00fcck\u00b7ge\u00b7las\u00b7sen", ",", "das", "sich", "qu\u00e4lt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "PRELS", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und das dir nachwill? Soll ich in ein Land,", "tokens": ["und", "das", "dir", "nach\u00b7will", "?", "Soll", "ich", "in", "ein", "Land", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PPER", "PTKVZ", "$.", "VMFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "das du nicht sahst, obwohl es dir verwandt", "tokens": ["das", "du", "nicht", "sahst", ",", "ob\u00b7wohl", "es", "dir", "ver\u00b7wandt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PTKNEG", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "war wie die andre H\u00e4lfte deiner Sinne?", "tokens": ["war", "wie", "die", "and\u00b7re", "H\u00e4lf\u00b7te", "dei\u00b7ner", "Sin\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich will auf seinen Fl\u00fcssen fahren, will", "tokens": ["Ich", "will", "auf", "sei\u00b7nen", "Fl\u00fcs\u00b7sen", "fah\u00b7ren", ",", "will"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "an Land gehn und nach alten Sitten fragen,", "tokens": ["an", "Land", "gehn", "und", "nach", "al\u00b7ten", "Sit\u00b7ten", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "KON", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "will mit den Frauen in den T\u00fcren sprechen", "tokens": ["will", "mit", "den", "Frau\u00b7en", "in", "den", "T\u00fc\u00b7ren", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "und zusehn, wenn sie ihre Kinder rufen.", "tokens": ["und", "zu\u00b7sehn", ",", "wenn", "sie", "ih\u00b7re", "Kin\u00b7der", "ru\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Ich will mir merken, wie sie dort die Landschaft", "tokens": ["Ich", "will", "mir", "mer\u00b7ken", ",", "wie", "sie", "dort", "die", "Land\u00b7schaft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,", "PWAV", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "umnehmen drau\u00dfen bei der alten Arbeit", "tokens": ["um\u00b7neh\u00b7men", "drau\u00b7\u00dfen", "bei", "der", "al\u00b7ten", "Ar\u00b7beit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "der Wiesen und der Felder; will begehren,", "tokens": ["der", "Wie\u00b7sen", "und", "der", "Fel\u00b7der", ";", "will", "be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "vor ihren K\u00f6nig hingef\u00fchrt zu sein,", "tokens": ["vor", "ih\u00b7ren", "K\u00f6\u00b7nig", "hin\u00b7ge\u00b7f\u00fchrt", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "und will die Priester durch Bestechung reizen,", "tokens": ["und", "will", "die", "Pries\u00b7ter", "durch", "Be\u00b7ste\u00b7chung", "rei\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "da\u00df sie mich legen vor das st\u00e4rkste Standbild", "tokens": ["da\u00df", "sie", "mich", "le\u00b7gen", "vor", "das", "st\u00e4rks\u00b7te", "Stand\u00b7bild"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und fortgehn und die Tempeltore schlie\u00dfen.", "tokens": ["und", "fort\u00b7gehn", "und", "die", "Tem\u00b7pel\u00b7to\u00b7re", "schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dann aber will ich, wenn ich vieles wei\u00df,", "tokens": ["Dann", "a\u00b7ber", "will", "ich", ",", "wenn", "ich", "vie\u00b7les", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "einfach die Tiere anschaun, da\u00df ein Etwas", "tokens": ["ein\u00b7fach", "die", "Tie\u00b7re", "an\u00b7schaun", ",", "da\u00df", "ein", "Et\u00b7was"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "von ihrer Wendung mir in die Gelenke", "tokens": ["von", "ih\u00b7rer", "Wen\u00b7dung", "mir", "in", "die", "Ge\u00b7len\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "her\u00fcbergleitet; will ein kurzes Dasein", "tokens": ["her\u00b7\u00fc\u00b7berg\u00b7lei\u00b7tet", ";", "will", "ein", "kur\u00b7zes", "Da\u00b7sein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$.", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "in ihren Augen haben, die mich halten", "tokens": ["in", "ih\u00b7ren", "Au\u00b7gen", "ha\u00b7ben", ",", "die", "mich", "hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,", "PRELS", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "und langsam lassen, ruhig, ohne Urteil.", "tokens": ["und", "lang\u00b7sam", "las\u00b7sen", ",", "ru\u00b7hig", ",", "oh\u00b7ne", "Ur\u00b7teil", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$,", "ADJD", "$,", "KOUI", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Ich will mir von den G\u00e4rtnern viele Blumen", "tokens": ["Ich", "will", "mir", "von", "den", "G\u00e4rt\u00b7nern", "vie\u00b7le", "Blu\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "hersagen lassen, da\u00df ich in den Scherben", "tokens": ["her\u00b7sa\u00b7gen", "las\u00b7sen", ",", "da\u00df", "ich", "in", "den", "Scher\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVINF", "VVINF", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.20": {"text": "der sch\u00f6nen Eigennamen einen Rest", "tokens": ["der", "sch\u00f6\u00b7nen", "Ei\u00b7gen\u00b7na\u00b7men", "ei\u00b7nen", "Rest"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "her\u00fcberbringe von den hundert D\u00fcften.", "tokens": ["her\u00b7\u00fc\u00b7berb\u00b7rin\u00b7ge", "von", "den", "hun\u00b7dert", "D\u00fcf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Und Fr\u00fcchte will ich kaufen, Fr\u00fcchte, drin", "tokens": ["Und", "Fr\u00fcch\u00b7te", "will", "ich", "kau\u00b7fen", ",", "Fr\u00fcch\u00b7te", ",", "drin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "NN", "VMFIN", "PPER", "VVINF", "$,", "NN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "das Land noch einmal ist, bis an den Himmel.", "tokens": ["das", "Land", "noch", "ein\u00b7mal", "ist", ",", "bis", "an", "den", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VAFIN", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Denn Das verstandest du: die vollen Fr\u00fcchte.", "tokens": ["Denn", "Das", "ver\u00b7stan\u00b7dest", "du", ":", "die", "vol\u00b7len", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die legtest du auf Schalen vor dich hin", "tokens": ["Die", "leg\u00b7test", "du", "auf", "Scha\u00b7len", "vor", "dich", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "APPR", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wogst mit Farben ihre Schwere auf.", "tokens": ["und", "wogst", "mit", "Far\u00b7ben", "ih\u00b7re", "Schwe\u00b7re", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und so wie Fr\u00fcchte sahst du auch die Fraun", "tokens": ["Und", "so", "wie", "Fr\u00fcch\u00b7te", "sahst", "du", "auch", "die", "Fraun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KOKOM", "NN", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und sahst die Kinder so, von innen her", "tokens": ["und", "sahst", "die", "Kin\u00b7der", "so", ",", "von", "in\u00b7nen", "her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "$,", "APPR", "ADV", "APZR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "getrieben in die Formen ihres Daseins.", "tokens": ["ge\u00b7trie\u00b7ben", "in", "die", "For\u00b7men", "ih\u00b7res", "Da\u00b7seins", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und sahst dich selbst zuletzt wie eine Frucht,", "tokens": ["Und", "sahst", "dich", "selbst", "zu\u00b7letzt", "wie", "ei\u00b7ne", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "nahmst dich heraus aus deinen Kleidern, trugst", "tokens": ["nahmst", "dich", "he\u00b7raus", "aus", "dei\u00b7nen", "Klei\u00b7dern", ",", "trugst"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "APPR", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "dich vor den Spiegel, lie\u00dfest dich hinein", "tokens": ["dich", "vor", "den", "Spie\u00b7gel", ",", "lie\u00b7\u00dfest", "dich", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "NN", "$,", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "bis auf dein Schauen; das blieb gro\u00df davor", "tokens": ["bis", "auf", "dein", "Schau\u00b7en", ";", "das", "blieb", "gro\u00df", "da\u00b7vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$.", "PDS", "VVFIN", "ADJD", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "und sagte nicht: das bin ich; nein: dies ist.", "tokens": ["und", "sag\u00b7te", "nicht", ":", "das", "bin", "ich", ";", "nein", ":", "dies", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$.", "PDS", "VAFIN", "PPER", "$.", "PTKANT", "$.", "PDS", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "So ohne Neugier war zuletzt dein Schaun", "tokens": ["So", "oh\u00b7ne", "Neu\u00b7gier", "war", "zu\u00b7letzt", "dein", "Schaun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "und so besitzlos, von so wahrer Armut,", "tokens": ["und", "so", "be\u00b7sitz\u00b7los", ",", "von", "so", "wah\u00b7rer", "Ar\u00b7mut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "da\u00df es dich selbst nicht mehr begehrte: heilig.", "tokens": ["da\u00df", "es", "dich", "selbst", "nicht", "mehr", "be\u00b7gehr\u00b7te", ":", "hei\u00b7lig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "ADV", "ADJA", "$.", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "So will ich dich behalten, wie du dich", "tokens": ["So", "will", "ich", "dich", "be\u00b7hal\u00b7ten", ",", "wie", "du", "dich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,", "PWAV", "PPER", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "hinstelltest in den Spiegel, tief hinein", "tokens": ["hin\u00b7stell\u00b7test", "in", "den", "Spie\u00b7gel", ",", "tief", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "und fort von allem. Warum kommst du anders?", "tokens": ["und", "fort", "von", "al\u00b7lem", ".", "Wa\u00b7rum", "kommst", "du", "an\u00b7ders", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "APPR", "PIS", "$.", "PWAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Was widerrufst du dich? Was willst du mir", "tokens": ["Was", "wi\u00b7der\u00b7rufst", "du", "dich", "?", "Was", "willst", "du", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "$.", "PWS", "VMFIN", "PPER", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "einreden, da\u00df in jenen Bernsteinkugeln", "tokens": ["ein\u00b7re\u00b7den", ",", "da\u00df", "in", "je\u00b7nen", "Bern\u00b7stein\u00b7ku\u00b7geln"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "um deinen Hals noch etwas Schwere war", "tokens": ["um", "dei\u00b7nen", "Hals", "noch", "et\u00b7was", "Schwe\u00b7re", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "von jener Schwere, wie sie nie im Jenseits", "tokens": ["von", "je\u00b7ner", "Schwe\u00b7re", ",", "wie", "sie", "nie", "im", "Jen\u00b7seits"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "PWAV", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "beruhigter Bilder ist; was zeigst du mir", "tokens": ["be\u00b7ru\u00b7hig\u00b7ter", "Bil\u00b7der", "ist", ";", "was", "zeigst", "du", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "$.", "PWS", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.23": {"text": "in deiner Haltung eine b\u00f6se Ahnung;", "tokens": ["in", "dei\u00b7ner", "Hal\u00b7tung", "ei\u00b7ne", "b\u00f6\u00b7se", "Ah\u00b7nung", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "was hei\u00dft dich die Konturen deines Leibes", "tokens": ["was", "hei\u00dft", "dich", "die", "Kon\u00b7tu\u00b7ren", "dei\u00b7nes", "Lei\u00b7bes"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "auslegen wie die Linien einer Hand,", "tokens": ["aus\u00b7le\u00b7gen", "wie", "die", "Li\u00b7ni\u00b7en", "ei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOKOM", "ART", "NN", "ART", "NN", "$,"], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "da\u00df ich sie nicht mehr sehn kann ohne Schicksal?", "tokens": ["da\u00df", "ich", "sie", "nicht", "mehr", "sehn", "kann", "oh\u00b7ne", "Schick\u00b7sal", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "ADV", "VVINF", "VMFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.6": {"line.1": {"text": "Komm her ins Kerzenlicht. Ich bin nicht bang,", "tokens": ["Komm", "her", "ins", "Ker\u00b7zen\u00b7licht", ".", "Ich", "bin", "nicht", "bang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "$.", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die Toten anzuschauen. Wenn sie kommen,", "tokens": ["die", "To\u00b7ten", "an\u00b7zu\u00b7schau\u00b7en", ".", "Wenn", "sie", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$.", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "so haben sie ein Recht, in unserm Blick", "tokens": ["so", "ha\u00b7ben", "sie", "ein", "Recht", ",", "in", "un\u00b7serm", "Blick"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "sich aufzuhalten, wie die andern Dinge.", "tokens": ["sich", "auf\u00b7zu\u00b7hal\u00b7ten", ",", "wie", "die", "an\u00b7dern", "Din\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVIZU", "$,", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Komm her; wir wollen eine Weile still sein.", "tokens": ["Komm", "her", ";", "wir", "wol\u00b7len", "ei\u00b7ne", "Wei\u00b7le", "still", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "PPER", "VMFIN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sieh diese Rose an auf meinem Schreibtisch;", "tokens": ["Sieh", "die\u00b7se", "Ro\u00b7se", "an", "auf", "mei\u00b7nem", "Schreib\u00b7tisch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ist nicht das Licht um sie genau so zaghaft", "tokens": ["ist", "nicht", "das", "Licht", "um", "sie", "ge\u00b7nau", "so", "zag\u00b7haft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "ADJD", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wie \u00fcber dir: sie d\u00fcrfte auch nicht hier sein.", "tokens": ["wie", "\u00fc\u00b7ber", "dir", ":", "sie", "d\u00fcrf\u00b7te", "auch", "nicht", "hier", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPER", "$.", "PPER", "VMFIN", "ADV", "PTKNEG", "ADV", "VAINF", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Im Garten drau\u00dfen, unvermischt mit mir,", "tokens": ["Im", "Gar\u00b7ten", "drau\u00b7\u00dfen", ",", "un\u00b7ver\u00b7mischt", "mit", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "h\u00e4tte sie bleiben m\u00fcssen oder hingehn, \u2013", "tokens": ["h\u00e4t\u00b7te", "sie", "blei\u00b7ben", "m\u00fcs\u00b7sen", "o\u00b7der", "hin\u00b7gehn", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "VMFIN", "KON", "VVINF", "$,", "$("], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.7": {"text": "nun w\u00e4hrt sie so: was ist ihr mein Bewu\u00dftsein?", "tokens": ["nun", "w\u00e4hrt", "sie", "so", ":", "was", "ist", "ihr", "mein", "Be\u00b7wu\u00df\u00b7tsein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PWS", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Erschrick nicht, wenn ich jetzt begreife, ach,", "tokens": ["Er\u00b7schrick", "nicht", ",", "wenn", "ich", "jetzt", "be\u00b7grei\u00b7fe", ",", "ach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "ITJ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da steigt es in mir auf: ich kann nicht anders,", "tokens": ["da", "steigt", "es", "in", "mir", "auf", ":", "ich", "kann", "nicht", "an\u00b7ders", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$.", "PPER", "VMFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ich mu\u00df begreifen, und wenn ich dran st\u00fcrbe.", "tokens": ["ich", "mu\u00df", "be\u00b7grei\u00b7fen", ",", "und", "wenn", "ich", "dran", "st\u00fcr\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KON", "KOUS", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Begreifen, da\u00df du hier bist. Ich begreife.", "tokens": ["Be\u00b7grei\u00b7fen", ",", "da\u00df", "du", "hier", "bist", ".", "Ich", "be\u00b7grei\u00b7fe", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ganz wie ein Blinder rings ein Ding begreift,", "tokens": ["Ganz", "wie", "ein", "Blin\u00b7der", "rings", "ein", "Ding", "be\u00b7greift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "f\u00fchl ich dein Los und wei\u00df ihm keinen Namen.", "tokens": ["f\u00fchl", "ich", "dein", "Los", "und", "wei\u00df", "ihm", "kei\u00b7nen", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "La\u00df uns zusammen klagen, da\u00df dich einer", "tokens": ["La\u00df", "uns", "zu\u00b7sam\u00b7men", "kla\u00b7gen", ",", "da\u00df", "dich", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$,", "KOUS", "PPER", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "aus deinem Spiegel nahm. Kannst du noch weinen?", "tokens": ["aus", "dei\u00b7nem", "Spie\u00b7gel", "nahm", ".", "Kannst", "du", "noch", "wei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Du kannst nicht. Deiner Tr\u00e4nen Kraft und Andrang", "tokens": ["Du", "kannst", "nicht", ".", "Dei\u00b7ner", "Tr\u00e4\u00b7nen", "Kraft", "und", "An\u00b7drang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "$.", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "hast du verwandelt in dein reifes Anschaun", "tokens": ["hast", "du", "ver\u00b7wan\u00b7delt", "in", "dein", "rei\u00b7fes", "An\u00b7schaun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und warst dabei, jeglichen Saft in dir", "tokens": ["und", "warst", "da\u00b7bei", ",", "jeg\u00b7li\u00b7chen", "Saft", "in", "dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PAV", "$,", "PIAT", "NN", "APPR", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "so umzusetzen in ein starkes Dasein,", "tokens": ["so", "um\u00b7zu\u00b7set\u00b7zen", "in", "ein", "star\u00b7kes", "Da\u00b7sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIZU", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "das steigt und kreist, im Gleichgewicht und blindlings.", "tokens": ["das", "steigt", "und", "kreist", ",", "im", "Gleich\u00b7ge\u00b7wicht", "und", "blind\u00b7lings", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$,", "APPRART", "NN", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Da ri\u00df ein Zufall dich, dein letzter Zufall", "tokens": ["Da", "ri\u00df", "ein", "Zu\u00b7fall", "dich", ",", "dein", "letz\u00b7ter", "Zu\u00b7fall"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "ri\u00df dich zur\u00fcck aus deinem fernsten Fortschritt", "tokens": ["ri\u00df", "dich", "zu\u00b7r\u00fcck", "aus", "dei\u00b7nem", "ferns\u00b7ten", "Fort\u00b7schritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.16": {"text": "in eine Welt zur\u00fcck, wo S\u00e4fte ", "tokens": ["in", "ei\u00b7ne", "Welt", "zu\u00b7r\u00fcck", ",", "wo", "S\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Ri\u00df dich nicht ganz; ri\u00df nur ein St\u00fcck zuerst,", "tokens": ["Ri\u00df", "dich", "nicht", "ganz", ";", "ri\u00df", "nur", "ein", "St\u00fcck", "zu\u00b7erst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ADV", "$.", "VVFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+--++--+-+", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "doch als um dieses St\u00fcck von Tag zu Tag", "tokens": ["doch", "als", "um", "die\u00b7ses", "St\u00fcck", "von", "Tag", "zu", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "PDAT", "NN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "die Wirklichkeit so zunahm, da\u00df es schwer ward,", "tokens": ["die", "Wirk\u00b7lich\u00b7keit", "so", "zu\u00b7nahm", ",", "da\u00df", "es", "schwer", "ward", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "da brauchtest du dich ganz: da gingst du hin", "tokens": ["da", "brauch\u00b7test", "du", "dich", "ganz", ":", "da", "gingst", "du", "hin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "$.", "ADV", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "und brachst in Brocken dich aus dem Gesetz", "tokens": ["und", "brachst", "in", "Bro\u00b7cken", "dich", "aus", "dem", "Ge\u00b7setz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "m\u00fchsam heraus, weil du dich brauchtest.", "tokens": ["m\u00fch\u00b7sam", "he\u00b7raus", ",", "weil", "du", "dich", "brauch\u00b7test", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.23": {"text": "Da trugst du dich ab und grubst aus deines Herzens", "tokens": ["Da", "trugst", "du", "dich", "ab", "und", "grubst", "aus", "dei\u00b7nes", "Her\u00b7zens"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "nachtwarmem Erdreich die noch gr\u00fcnen Samen,", "tokens": ["nacht\u00b7war\u00b7mem", "Er\u00b7dreich", "die", "noch", "gr\u00fc\u00b7nen", "Sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "daraus dein Tod aufkeimen sollte: deiner,", "tokens": ["da\u00b7raus", "dein", "Tod", "auf\u00b7kei\u00b7men", "soll\u00b7te", ":", "dei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "VVINF", "VMFIN", "$.", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "dein eigner Tod zu deinem eignen Leben.", "tokens": ["dein", "eig\u00b7ner", "Tod", "zu", "dei\u00b7nem", "eig\u00b7nen", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Und a\u00dfest sie, die K\u00f6rner deines Todes,", "tokens": ["Und", "a\u00b7\u00dfest", "sie", ",", "die", "K\u00f6r\u00b7ner", "dei\u00b7nes", "To\u00b7des", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "wie alle andern, a\u00dfest seine K\u00f6rner,", "tokens": ["wie", "al\u00b7le", "an\u00b7dern", ",", "a\u00b7\u00dfest", "sei\u00b7ne", "K\u00f6r\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJA", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "und hattest Nachgeschmack in dir von S\u00fc\u00dfe,", "tokens": ["und", "hat\u00b7test", "Nach\u00b7ge\u00b7schmack", "in", "dir", "von", "S\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "APPR", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "die du nicht meintest, hattest s\u00fc\u00dfe Lippen,", "tokens": ["die", "du", "nicht", "mein\u00b7test", ",", "hat\u00b7test", "s\u00fc\u00b7\u00dfe", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVFIN", "$,", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "du: die schon innen in den Sinnen s\u00fc\u00df war.", "tokens": ["du", ":", "die", "schon", "in\u00b7nen", "in", "den", "Sin\u00b7nen", "s\u00fc\u00df", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "ADV", "ADV", "APPR", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "O la\u00df uns klagen. Wei\u00dft du, wie dein Blut", "tokens": ["O", "la\u00df", "uns", "kla\u00b7gen", ".", "Wei\u00dft", "du", ",", "wie", "dein", "Blut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "VVINF", "$.", "VVFIN", "PPER", "$,", "PWAV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aus einem Kreisen ohnegleichen z\u00f6gernd", "tokens": ["aus", "ei\u00b7nem", "Krei\u00b7sen", "oh\u00b7ne\u00b7glei\u00b7chen", "z\u00f6\u00b7gernd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "und ungern wiederkam, da du es abriefst?", "tokens": ["und", "un\u00b7gern", "wie\u00b7der\u00b7kam", ",", "da", "du", "es", "ab\u00b7riefst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie es verwirrt des Leibes kleinen Kreislauf", "tokens": ["Wie", "es", "ver\u00b7wirrt", "des", "Lei\u00b7bes", "klei\u00b7nen", "Kreis\u00b7lauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADJD", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "noch einmal aufnahm; wie es voller Mi\u00dftraun", "tokens": ["noch", "ein\u00b7mal", "auf\u00b7nahm", ";", "wie", "es", "vol\u00b7ler", "Mi\u00df\u00b7traun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "$.", "PWAV", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "und Staunen eintrat in den Mutterkuchen", "tokens": ["und", "Stau\u00b7nen", "ein\u00b7trat", "in", "den", "Mut\u00b7ter\u00b7ku\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und von dem weiten R\u00fcckweg pl\u00f6tzlich m\u00fcd war.", "tokens": ["und", "von", "dem", "wei\u00b7ten", "R\u00fcck\u00b7weg", "pl\u00f6tz\u00b7lich", "m\u00fcd", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADJD", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Du triebst es an, du stie\u00dfest es nach vorn,", "tokens": ["Du", "triebst", "es", "an", ",", "du", "stie\u00b7\u00dfest", "es", "nach", "vorn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "du zerrtest es zur Feuerstelle, wie", "tokens": ["du", "zerr\u00b7test", "es", "zur", "Feu\u00b7er\u00b7stel\u00b7le", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "man eine Herde Tiere zerrt zum Opfer;", "tokens": ["man", "ei\u00b7ne", "Her\u00b7de", "Tie\u00b7re", "zerrt", "zum", "Op\u00b7fer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und wolltest noch, es sollte dabei froh sein.", "tokens": ["und", "woll\u00b7test", "noch", ",", "es", "soll\u00b7te", "da\u00b7bei", "froh", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "$,", "PPER", "VMFIN", "PAV", "ADJD", "VAINF", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Und du erzwangst es schlie\u00dflich: es war froh", "tokens": ["Und", "du", "er\u00b7zwangst", "es", "schlie\u00df\u00b7lich", ":", "es", "war", "froh"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "und lief herbei und gab sich hin. Dir schien,", "tokens": ["und", "lief", "her\u00b7bei", "und", "gab", "sich", "hin", ".", "Dir", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "VVFIN", "PRF", "PTKVZ", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "weil du gewohnt warst an die andern Ma\u00dfe,", "tokens": ["weil", "du", "ge\u00b7wohnt", "warst", "an", "die", "an\u00b7dern", "Ma\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "es w\u00e4re nur f\u00fcr eine Weile; aber", "tokens": ["es", "w\u00e4\u00b7re", "nur", "f\u00fcr", "ei\u00b7ne", "Wei\u00b7le", ";", "a\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "nun warst du in der Zeit, und Zeit ist lang.", "tokens": ["nun", "warst", "du", "in", "der", "Zeit", ",", "und", "Zeit", "ist", "lang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "$,", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Und Zeit geht hin, und Zeit nimmt zu, und Zeit", "tokens": ["Und", "Zeit", "geht", "hin", ",", "und", "Zeit", "nimmt", "zu", ",", "und", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PTKVZ", "$,", "KON", "NN", "VVFIN", "PTKVZ", "$,", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "ist wie ein R\u00fcckfall einer langen Krankheit.", "tokens": ["ist", "wie", "ein", "R\u00fcck\u00b7fall", "ei\u00b7ner", "lan\u00b7gen", "Krank\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wie war dein Leben kurz, wenn du's vergleichst", "tokens": ["Wie", "war", "dein", "Le\u00b7ben", "kurz", ",", "wenn", "du's", "ver\u00b7gleichst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADJD", "$,", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit jenen Stunden, da du sa\u00dfest und", "tokens": ["mit", "je\u00b7nen", "Stun\u00b7den", ",", "da", "du", "sa\u00b7\u00dfest", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "die vielen Kr\u00e4fte deiner vielen Zukunft", "tokens": ["die", "vie\u00b7len", "Kr\u00e4f\u00b7te", "dei\u00b7ner", "vie\u00b7len", "Zu\u00b7kunft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "schweigend herabbogst zu dem neuen Kindkeim,", "tokens": ["schwei\u00b7gend", "her\u00b7ab\u00b7bogst", "zu", "dem", "neu\u00b7en", "Kind\u00b7keim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "der wieder Schicksal war. O wehe Arbeit.", "tokens": ["der", "wie\u00b7der", "Schick\u00b7sal", "war", ".", "O", "we\u00b7he", "Ar\u00b7beit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VAFIN", "$.", "NE", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "O Arbeit \u00fcber alle Kraft. Du tatest", "tokens": ["O", "Ar\u00b7beit", "\u00fc\u00b7ber", "al\u00b7le", "Kraft", ".", "Du", "ta\u00b7test"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "APPR", "PIAT", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "sie Tag f\u00fcr Tag, du schlepptest dich zu ihr", "tokens": ["sie", "Tag", "f\u00fcr", "Tag", ",", "du", "schlepp\u00b7test", "dich", "zu", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "APPR", "NN", "$,", "PPER", "VVFIN", "PRF", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und zogst den sch\u00f6nen Einschlag aus dem Webstuhl", "tokens": ["und", "zogst", "den", "sch\u00f6\u00b7nen", "Ein\u00b7schlag", "aus", "dem", "Web\u00b7stuhl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "und brauchtest alle deine F\u00e4den anders.", "tokens": ["und", "brauch\u00b7test", "al\u00b7le", "dei\u00b7ne", "F\u00e4\u00b7den", "an\u00b7ders", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und endlich hattest du noch Mut zum Fest.", "tokens": ["Und", "end\u00b7lich", "hat\u00b7test", "du", "noch", "Mut", "zum", "Fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Denn da's getan war, wolltest du belohnt sein,", "tokens": ["Denn", "da's", "ge\u00b7tan", "war", ",", "woll\u00b7test", "du", "be\u00b7lohnt", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVPP", "VAFIN", "$,", "VMFIN", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wie Kinder, wenn sie bitters\u00fc\u00dfen Tee", "tokens": ["wie", "Kin\u00b7der", ",", "wenn", "sie", "bit\u00b7ter\u00b7s\u00fc\u00b7\u00dfen", "Tee"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "KOUS", "PPER", "ADV", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "getrunken haben, der vielleicht gesund macht.", "tokens": ["ge\u00b7trun\u00b7ken", "ha\u00b7ben", ",", "der", "viel\u00b7leicht", "ge\u00b7sund", "macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So lohntest du dich: denn von jedem andern", "tokens": ["So", "lohn\u00b7test", "du", "dich", ":", "denn", "von", "je\u00b7dem", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$.", "ADV", "APPR", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "warst du zu weit, auch jetzt noch; keiner h\u00e4tte", "tokens": ["warst", "du", "zu", "weit", ",", "auch", "jetzt", "noch", ";", "kei\u00b7ner", "h\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "PTKA", "ADJD", "$,", "ADV", "ADV", "ADV", "$.", "PIS", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ausdenken k\u00f6nnen, welcher Lohn dir wohltut.", "tokens": ["aus\u00b7den\u00b7ken", "k\u00f6n\u00b7nen", ",", "wel\u00b7cher", "Lohn", "dir", "wohl\u00b7tut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVINF", "VMINF", "$,", "PWAT", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Du wu\u00dftest es. Du sa\u00dfest auf im Kindbett,", "tokens": ["Du", "wu\u00df\u00b7test", "es", ".", "Du", "sa\u00b7\u00dfest", "auf", "im", "Kind\u00b7bett", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und vor dir stand ein Spiegel, der dir alles", "tokens": ["und", "vor", "dir", "stand", "ein", "Spie\u00b7gel", ",", "der", "dir", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "ganz wiedergab. Nun war das alles ", "tokens": ["ganz", "wie\u00b7der\u00b7gab", ".", "Nun", "war", "das", "al\u00b7les"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$.", "ADV", "VAFIN", "ART", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und ganz ", "tokens": ["und", "ganz"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "die sch\u00f6ne T\u00e4uschung jeder Frau, die gern", "tokens": ["die", "sch\u00f6\u00b7ne", "T\u00e4u\u00b7schung", "je\u00b7der", "Frau", ",", "die", "gern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Schmuck umnimmt und das Haar k\u00e4mmt und ver\u00e4ndert.", "tokens": ["Schmuck", "um\u00b7nimmt", "und", "das", "Haar", "k\u00e4mmt", "und", "ver\u00b7\u00e4n\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.12": {"line.1": {"text": "So starbst du, wie die Frauen fr\u00fcher starben,", "tokens": ["So", "starbst", "du", ",", "wie", "die", "Frau\u00b7en", "fr\u00fc\u00b7her", "star\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "altmodisch starbst du in dem warmen Hause", "tokens": ["alt\u00b7mo\u00b7disch", "starbst", "du", "in", "dem", "war\u00b7men", "Hau\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Tod der W\u00f6chnerinnen, welche wieder", "tokens": ["den", "Tod", "der", "W\u00f6ch\u00b7ne\u00b7rin\u00b7nen", ",", "wel\u00b7che", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sich schlie\u00dfen wollen und es nicht mehr k\u00f6nnen,", "tokens": ["sich", "schlie\u00b7\u00dfen", "wol\u00b7len", "und", "es", "nicht", "mehr", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "VMFIN", "KON", "PPER", "PTKNEG", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "weil jenes Dunkel, das sie mitgebaren,", "tokens": ["weil", "je\u00b7nes", "Dun\u00b7kel", ",", "das", "sie", "mit\u00b7ge\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "noch einmal wiederkommt und dr\u00e4ngt und eintritt.", "tokens": ["noch", "ein\u00b7mal", "wie\u00b7der\u00b7kommt", "und", "dr\u00e4ngt", "und", "ein\u00b7tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.13": {"line.1": {"text": "Ob man nicht dennoch h\u00e4tte Klagefrauen", "tokens": ["Ob", "man", "nicht", "den\u00b7noch", "h\u00e4t\u00b7te", "Kla\u00b7ge\u00b7frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "VAFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "auftreiben m\u00fcssen? Weiber, welche weinen", "tokens": ["auf\u00b7trei\u00b7ben", "m\u00fcs\u00b7sen", "?", "Wei\u00b7ber", ",", "wel\u00b7che", "wei\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVINF", "VMINF", "$.", "NN", "$,", "PRELS", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "f\u00fcr Geld, und die man so bezahlen kann,", "tokens": ["f\u00fcr", "Geld", ",", "und", "die", "man", "so", "be\u00b7zah\u00b7len", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KON", "ART", "PIS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df sie die Nacht durch heulen, wenn es still wird.", "tokens": ["da\u00df", "sie", "die", "Nacht", "durch", "heu\u00b7len", ",", "wenn", "es", "still", "wird", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "VVINF", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Gebr\u00e4uche her! wir haben nicht genug", "tokens": ["Ge\u00b7br\u00e4u\u00b7che", "her", "!", "wir", "ha\u00b7ben", "nicht", "ge\u00b7nug"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$.", "PPER", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Gebr\u00e4uche. Alles geht und wird verredet.", "tokens": ["Ge\u00b7br\u00e4u\u00b7che", ".", "Al\u00b7les", "geht", "und", "wird", "ver\u00b7re\u00b7det", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VVFIN", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So mu\u00dft du kommen, tot, und hier mit mir", "tokens": ["So", "mu\u00dft", "du", "kom\u00b7men", ",", "tot", ",", "und", "hier", "mit", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "ADJD", "$,", "KON", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Klagen nachholen. H\u00f6rst du, da\u00df ich klage?", "tokens": ["Kla\u00b7gen", "nach\u00b7ho\u00b7len", ".", "H\u00f6rst", "du", ",", "da\u00df", "ich", "kla\u00b7ge", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$.", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "Ich m\u00f6chte meine Stimme wie ein Tuch", "tokens": ["Ich", "m\u00f6ch\u00b7te", "mei\u00b7ne", "Stim\u00b7me", "wie", "ein", "Tuch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "hinwerfen \u00fcber deines Todes Scherben", "tokens": ["hin\u00b7wer\u00b7fen", "\u00fc\u00b7ber", "dei\u00b7nes", "To\u00b7des", "Scher\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und zerrn an ihr, bis sie in Fetzen geht,", "tokens": ["und", "zerrn", "an", "ihr", ",", "bis", "sie", "in", "Fet\u00b7zen", "geht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "und alles, was ich sage, m\u00fc\u00dfte so", "tokens": ["und", "al\u00b7les", ",", "was", "ich", "sa\u00b7ge", ",", "m\u00fc\u00df\u00b7te", "so"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VMFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "zerlumpt in dieser Stimme gehn und frieren;", "tokens": ["zer\u00b7lumpt", "in", "die\u00b7ser", "Stim\u00b7me", "gehn", "und", "frie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDAT", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "blieb es beim Klagen. Doch jetzt klag ich an:", "tokens": ["blieb", "es", "beim", "Kla\u00b7gen", ".", "Doch", "jetzt", "klag", "ich", "an", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$.", "KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "den Einen nicht, der dich aus dir zur\u00fcckzog,", "tokens": ["den", "Ei\u00b7nen", "nicht", ",", "der", "dich", "aus", "dir", "zu\u00b7r\u00fcck\u00b7zog", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "PTKNEG", "$,", "PRELS", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "(ich find ihn nicht heraus, er ist wie alle)", "tokens": ["(", "ich", "find", "ihn", "nicht", "he\u00b7raus", ",", "er", "ist", "wie", "al\u00b7le", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "PPER", "VAFIN", "KOKOM", "PIAT", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "doch alle klag ich in ihm an: den Mann.", "tokens": ["doch", "al\u00b7le", "klag", "ich", "in", "ihm", "an", ":", "den", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Wenn irgendwo ein Kindgewesensein", "tokens": ["Wenn", "ir\u00b7gend\u00b7wo", "ein", "Kind\u00b7ge\u00b7we\u00b7sen\u00b7sein"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "tief in mir aufsteigt, das ich noch nicht kenne,", "tokens": ["tief", "in", "mir", "auf\u00b7steigt", ",", "das", "ich", "noch", "nicht", "ken\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVPP", "$,", "PRELS", "PPER", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+---+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "vielleicht das reinste Kindsein meiner Kindheit:", "tokens": ["viel\u00b7leicht", "das", "reins\u00b7te", "Kinds\u00b7ein", "mei\u00b7ner", "Kind\u00b7heit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ich wills nicht wissen. Einen Engel will", "tokens": ["ich", "wills", "nicht", "wis\u00b7sen", ".", "Ei\u00b7nen", "En\u00b7gel", "will"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$.", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "ich daraus bilden ohne hinzusehn", "tokens": ["ich", "da\u00b7raus", "bil\u00b7den", "oh\u00b7ne", "hin\u00b7zu\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PAV", "VVFIN", "APPR", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und will ihn werfen in die erste Reihe", "tokens": ["und", "will", "ihn", "wer\u00b7fen", "in", "die", "ers\u00b7te", "Rei\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "schreiender Engel, welche Gott erinnern.", "tokens": ["schrei\u00b7en\u00b7der", "En\u00b7gel", ",", "wel\u00b7che", "Gott", "e\u00b7rin\u00b7nern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAT", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.15": {"line.1": {"text": "Denn dieses Leiden dauert schon zu lang,", "tokens": ["Denn", "die\u00b7ses", "Lei\u00b7den", "dau\u00b7ert", "schon", "zu", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und keiner kanns; es ist zu schwer f\u00fcr uns,", "tokens": ["und", "kei\u00b7ner", "kanns", ";", "es", "ist", "zu", "schwer", "f\u00fcr", "uns", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "$.", "PPER", "VAFIN", "PTKA", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "das wirre Leiden von der falschen Liebe,", "tokens": ["das", "wir\u00b7re", "Lei\u00b7den", "von", "der", "fal\u00b7schen", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die, bauend auf Verj\u00e4hrung wie Gewohnheit,", "tokens": ["die", ",", "bau\u00b7end", "auf", "Ver\u00b7j\u00e4h\u00b7rung", "wie", "Ge\u00b7wohn\u00b7heit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "APPR", "NN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ein Recht sich nennt und wuchert aus dem Unrecht.", "tokens": ["ein", "Recht", "sich", "nennt", "und", "wu\u00b7chert", "aus", "dem", "Un\u00b7recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wo ist ein Mann, der Recht hat auf Besitz?", "tokens": ["Wo", "ist", "ein", "Mann", ",", "der", "Recht", "hat", "auf", "Be\u00b7sitz", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "ART", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wer kann besitzen, was sich selbst nicht h\u00e4lt,", "tokens": ["Wer", "kann", "be\u00b7sit\u00b7zen", ",", "was", "sich", "selbst", "nicht", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "VVINF", "$,", "PRELS", "PRF", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "was sich von Zeit zu Zeit nur selig auff\u00e4ngt", "tokens": ["was", "sich", "von", "Zeit", "zu", "Zeit", "nur", "se\u00b7lig", "auf\u00b7f\u00e4ngt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPR", "NN", "APPR", "NN", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.9": {"text": "und wieder hinwirft wie ein Kind den Ball.", "tokens": ["und", "wie\u00b7der", "hin\u00b7wirft", "wie", "ein", "Kind", "den", "Ball", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "KOKOM", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sowenig wie der Feldherr eine Nike", "tokens": ["So\u00b7we\u00b7nig", "wie", "der", "Feld\u00b7herr", "ei\u00b7ne", "Ni\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "festhalten kann am Vorderbug des Schiffes,", "tokens": ["fest\u00b7hal\u00b7ten", "kann", "am", "Vor\u00b7der\u00b7bug", "des", "Schif\u00b7fes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVINF", "VMFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "wenn das geheime Leichtsein ihrer Gottheit", "tokens": ["wenn", "das", "ge\u00b7hei\u00b7me", "Leich\u00b7tsein", "ih\u00b7rer", "Got\u00b7theit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "sie pl\u00f6tzlich weghebt in den hellen Meerwind:", "tokens": ["sie", "pl\u00f6tz\u00b7lich", "weg\u00b7hebt", "in", "den", "hel\u00b7len", "Meer\u00b7wind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "so wenig kann einer von uns die Frau", "tokens": ["so", "we\u00b7nig", "kann", "ei\u00b7ner", "von", "uns", "die", "Frau"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VMFIN", "PIS", "APPR", "PPER", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "anrufen, die uns nicht mehr sieht und die", "tokens": ["an\u00b7ru\u00b7fen", ",", "die", "uns", "nicht", "mehr", "sieht", "und", "die"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PRELS", "PPER", "PTKNEG", "ADV", "VVFIN", "KON", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "auf einem schmalen Streifen ihres Daseins", "tokens": ["auf", "ei\u00b7nem", "schma\u00b7len", "Strei\u00b7fen", "ih\u00b7res", "Da\u00b7seins"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "wie durch ein Wunder fortgeht, ohne Unfall:", "tokens": ["wie", "durch", "ein", "Wun\u00b7der", "fort\u00b7geht", ",", "oh\u00b7ne", "Un\u00b7fall", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "VVFIN", "$,", "KOUI", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "er h\u00e4tte denn Beruf und Lust zur Schuld.", "tokens": ["er", "h\u00e4t\u00b7te", "denn", "Be\u00b7ruf", "und", "Lust", "zur", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "die Freiheit eines Lieben nicht vermehren", "tokens": ["die", "Frei\u00b7heit", "ei\u00b7nes", "Lie\u00b7ben", "nicht", "ver\u00b7meh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "um alle Freiheit, die man in sich aufbringt.", "tokens": ["um", "al\u00b7le", "Frei\u00b7heit", ",", "die", "man", "in", "sich", "auf\u00b7bringt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "PIS", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir haben, wo wir lieben, ja nur dies:", "tokens": ["Wir", "ha\u00b7ben", ",", "wo", "wir", "lie\u00b7ben", ",", "ja", "nur", "dies", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "ADV", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "einander lassen; denn da\u00df wir uns halten,", "tokens": ["ein\u00b7an\u00b7der", "las\u00b7sen", ";", "denn", "da\u00df", "wir", "uns", "hal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$.", "KON", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "das f\u00e4llt uns leicht und ist nicht erst zu lernen.", "tokens": ["das", "f\u00e4llt", "uns", "leicht", "und", "ist", "nicht", "erst", "zu", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "KON", "VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Bist du noch da? In welcher Ecke bist du? \u2013", "tokens": ["Bist", "du", "noch", "da", "?", "In", "wel\u00b7cher", "E\u00b7cke", "bist", "du", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "$.", "APPR", "PWAT", "NN", "VAFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Du hast so viel gewu\u00dft von alledem", "tokens": ["Du", "hast", "so", "viel", "ge\u00b7wu\u00dft", "von", "al\u00b7le\u00b7dem"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "APPR", "PIS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und hast so viel gekonnt, da du so hingingst", "tokens": ["und", "hast", "so", "viel", "ge\u00b7konnt", ",", "da", "du", "so", "hin\u00b7gingst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "f\u00fcr alles offen, wie ein Tag, der anbricht.", "tokens": ["f\u00fcr", "al\u00b7les", "of\u00b7fen", ",", "wie", "ein", "Tag", ",", "der", "an\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADJD", "$,", "PWAV", "ART", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Die Frauen leiden: lieben hei\u00dft allein sein,", "tokens": ["Die", "Frau\u00b7en", "lei\u00b7den", ":", "lie\u00b7ben", "hei\u00dft", "al\u00b7lein", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "VVINF", "VVFIN", "ADV", "VAINF", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "und K\u00fcnstler ahnen manchmal in der Arbeit,", "tokens": ["und", "K\u00fcnst\u00b7ler", "ah\u00b7nen", "manch\u00b7mal", "in", "der", "Ar\u00b7beit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "da\u00df sie verwandeln m\u00fcssen, wo sie lieben.", "tokens": ["da\u00df", "sie", "ver\u00b7wan\u00b7deln", "m\u00fcs\u00b7sen", ",", "wo", "sie", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMINF", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Beides begannst du; beides ist in Dem,", "tokens": ["Bei\u00b7des", "be\u00b7gannst", "du", ";", "bei\u00b7des", "ist", "in", "Dem", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$.", "PIS", "VAFIN", "APPR", "PDS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "was jetzt ein Ruhm entstellt, der es dir fortnimmt.", "tokens": ["was", "jetzt", "ein", "Ruhm", "ent\u00b7stellt", ",", "der", "es", "dir", "fort\u00b7nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,", "PRELS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Ach du warst weit von jedem Ruhm. Du warst", "tokens": ["Ach", "du", "warst", "weit", "von", "je\u00b7dem", "Ruhm", ".", "Du", "warst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "PPER", "VAFIN", "ADJD", "APPR", "PIAT", "NN", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "unscheinbar; hattest leise deine Sch\u00f6nheit", "tokens": ["un\u00b7schein\u00b7bar", ";", "hat\u00b7test", "lei\u00b7se", "dei\u00b7ne", "Sch\u00f6n\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "VAFIN", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "hineingenommen, wie man eine Fahne", "tokens": ["hin\u00b7ein\u00b7ge\u00b7nom\u00b7men", ",", "wie", "man", "ei\u00b7ne", "Fah\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "PWAV", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "einzieht am grauen Morgen eines Werktags,", "tokens": ["ein\u00b7zieht", "am", "grau\u00b7en", "Mor\u00b7gen", "ei\u00b7nes", "Werk\u00b7tags", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "und wolltest nichts, als eine lange Arbeit, \u2013", "tokens": ["und", "woll\u00b7test", "nichts", ",", "als", "ei\u00b7ne", "lan\u00b7ge", "Ar\u00b7beit", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PIS", "$,", "KOUS", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "die nicht getan ist: dennoch nicht getan.", "tokens": ["die", "nicht", "ge\u00b7tan", "ist", ":", "den\u00b7noch", "nicht", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "VVPP", "VAFIN", "$.", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Wenn du noch da bist, wenn in diesem Dunkel", "tokens": ["Wenn", "du", "noch", "da", "bist", ",", "wenn", "in", "die\u00b7sem", "Dun\u00b7kel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VAFIN", "$,", "KOUS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "noch eine Stelle ist, an der dein Geist", "tokens": ["noch", "ei\u00b7ne", "Stel\u00b7le", "ist", ",", "an", "der", "dein", "Geist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VAFIN", "$,", "APPR", "ART", "PPOSAT", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "empfindlich mitschwingt auf den flachen Schallwelln,", "tokens": ["emp\u00b7find\u00b7lich", "mit\u00b7schwingt", "auf", "den", "fla\u00b7chen", "Schall\u00b7welln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die eine Stimme, einsam in der Nacht,", "tokens": ["die", "ei\u00b7ne", "Stim\u00b7me", ",", "ein\u00b7sam", "in", "der", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "aufregt in eines hohen Zimmers Str\u00f6mung:", "tokens": ["auf\u00b7regt", "in", "ei\u00b7nes", "ho\u00b7hen", "Zim\u00b7mers", "Str\u00f6\u00b7mung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So h\u00f6r mich: Hilf mir. Sieh, wir gleiten so,", "tokens": ["So", "h\u00f6r", "mich", ":", "Hilf", "mir", ".", "Sieh", ",", "wir", "glei\u00b7ten", "so", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NE", "PPER", "$.", "NE", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "nicht wissend wann, zur\u00fcck aus unserm Fortschritt", "tokens": ["nicht", "wis\u00b7send", "wann", ",", "zu\u00b7r\u00fcck", "aus", "un\u00b7serm", "Fort\u00b7schritt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "PWAV", "$,", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "in irgendwas, was wir nicht meinen; drin", "tokens": ["in", "ir\u00b7gend\u00b7was", ",", "was", "wir", "nicht", "mei\u00b7nen", ";", "drin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PIS", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "$.", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "wir uns verfangen wie in einem Traum", "tokens": ["wir", "uns", "ver\u00b7fan\u00b7gen", "wie", "in", "ei\u00b7nem", "Traum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PRF", "VVINF", "KOKOM", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "und drin wir sterben, ohne zu erwachen.", "tokens": ["und", "drin", "wir", "ster\u00b7ben", ",", "oh\u00b7ne", "zu", "er\u00b7wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "$,", "KOUI", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Keiner ist weiter. Jedem, der sein Blut", "tokens": ["Kei\u00b7ner", "ist", "wei\u00b7ter", ".", "Je\u00b7dem", ",", "der", "sein", "Blut"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "$.", "PIAT", "$,", "PRELS", "PPOSAT", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "hinaufhob in ein Werk, das lange wird,", "tokens": ["hin\u00b7auf\u00b7hob", "in", "ein", "Werk", ",", "das", "lan\u00b7ge", "wird", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "kann es geschehen, da\u00df ers nicht mehr hochh\u00e4lt", "tokens": ["kann", "es", "ge\u00b7sche\u00b7hen", ",", "da\u00df", "ers", "nicht", "mehr", "hoch\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VVPP", "$,", "KOUS", "PIS", "PTKNEG", "ADV", "VVFIN"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.14": {"text": "und da\u00df es geht nach seiner Schwere, wertlos.", "tokens": ["und", "da\u00df", "es", "geht", "nach", "sei\u00b7ner", "Schwe\u00b7re", ",", "wert\u00b7los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.15": {"text": "Denn irgendwo ist eine alte Feindschaft", "tokens": ["Denn", "ir\u00b7gend\u00b7wo", "ist", "ei\u00b7ne", "al\u00b7te", "Feind\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "zwischen dem Leben und der gro\u00dfen Arbeit.", "tokens": ["zwi\u00b7schen", "dem", "Le\u00b7ben", "und", "der", "gro\u00b7\u00dfen", "Ar\u00b7beit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Da\u00df ich sie einseh und sie sage: hilf mir.", "tokens": ["Da\u00df", "ich", "sie", "ein\u00b7seh", "und", "sie", "sa\u00b7ge", ":", "hilf", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "KON", "PPER", "VVFIN", "$.", "VVIMP", "PPER", "$."], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "Komm nicht zur\u00fcck. Wenn du's ertr\u00e4gst, so sei", "tokens": ["Komm", "nicht", "zu\u00b7r\u00fcck", ".", "Wenn", "du's", "er\u00b7tr\u00e4gst", ",", "so", "sei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKNEG", "PTKVZ", "$.", "KOUS", "PIS", "VVFIN", "$,", "ADV", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "tot bei den Toten. Tote sind besch\u00e4ftigt.", "tokens": ["tot", "bei", "den", "To\u00b7ten", ".", "To\u00b7te", "sind", "be\u00b7sch\u00e4f\u00b7tigt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$.", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch hilf mir so, da\u00df es dich nicht zerstreut,", "tokens": ["Doch", "hilf", "mir", "so", ",", "da\u00df", "es", "dich", "nicht", "zer\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "VVPP", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.4": {"text": "wie mir das Fernste manchmal hilft: in mir.", "tokens": ["wie", "mir", "das", "Ferns\u00b7te", "manch\u00b7mal", "hilft", ":", "in", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "ADV", "VVFIN", "$.", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Ich habe Tote, und ich lie\u00df sie hin", "tokens": ["Ich", "ha\u00b7be", "To\u00b7te", ",", "und", "ich", "lie\u00df", "sie", "hin"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und war erstaunt, sie so getrost zu sehn,", "tokens": ["und", "war", "er\u00b7staunt", ",", "sie", "so", "ge\u00b7trost", "zu", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$,", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so rasch zuhaus im Totsein, so gerecht,", "tokens": ["so", "rasch", "zu\u00b7haus", "im", "Tot\u00b7sein", ",", "so", "ge\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "APPRART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "so anders als ihr Ruf. Nur du, du kehrst", "tokens": ["so", "an\u00b7ders", "als", "ihr", "Ruf", ".", "Nur", "du", ",", "du", "kehrst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "KOKOM", "PPOSAT", "NN", "$.", "ADV", "PPER", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "zur\u00fcck; du streifst mich, du gehst um, du willst", "tokens": ["zu\u00b7r\u00fcck", ";", "du", "streifst", "mich", ",", "du", "gehst", "um", ",", "du", "willst"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKVZ", "$.", "PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "an etwas sto\u00dfen, da\u00df es klingt von dir", "tokens": ["an", "et\u00b7was", "sto\u00b7\u00dfen", ",", "da\u00df", "es", "klingt", "von", "dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und dich verr\u00e4t. O nimm mir nicht, was ich", "tokens": ["und", "dich", "ver\u00b7r\u00e4t", ".", "O", "nimm", "mir", "nicht", ",", "was", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "NE", "VVFIN", "PPER", "PTKNEG", "$,", "PWS", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "langsam erlern. Ich habe recht; du irrst", "tokens": ["lang\u00b7sam", "er\u00b7lern", ".", "Ich", "ha\u00b7be", "recht", ";", "du", "irrst"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVINF", "$.", "PPER", "VAFIN", "ADJD", "$.", "PPER", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "wenn du ger\u00fchrt zu irgend einem Ding", "tokens": ["wenn", "du", "ge\u00b7r\u00fchrt", "zu", "ir\u00b7gend", "ei\u00b7nem", "Ding"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "APPR", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "ein Heimweh hast. Wir wandeln dieses um;", "tokens": ["ein", "Heim\u00b7weh", "hast", ".", "Wir", "wan\u00b7deln", "die\u00b7ses", "um", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "PPER", "VVFIN", "PDAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "es ist nicht hier, wir spiegeln es herein", "tokens": ["es", "ist", "nicht", "hier", ",", "wir", "spie\u00b7geln", "es", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "aus unserm Sein, sobald wir es erkennen.", "tokens": ["aus", "un\u00b7serm", "Sein", ",", "so\u00b7bald", "wir", "es", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Ich glaubte dich viel weiter. Mich verwirrts,", "tokens": ["Ich", "glaub\u00b7te", "dich", "viel", "wei\u00b7ter", ".", "Mich", "ver\u00b7wirrts", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df ", "tokens": ["da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "verwandelt hat als irgend eine Frau.", "tokens": ["ver\u00b7wan\u00b7delt", "hat", "als", "ir\u00b7gend", "ei\u00b7ne", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KOKOM", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df wir erschraken, da du starbst, nein, da\u00df", "tokens": ["Da\u00df", "wir", "er\u00b7schra\u00b7ken", ",", "da", "du", "starbst", ",", "nein", ",", "da\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "$,", "PTKANT", "$,", "KOUS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "dein starker Tod uns dunkel unterbrach,", "tokens": ["dein", "star\u00b7ker", "Tod", "uns", "dun\u00b7kel", "un\u00b7ter\u00b7brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "das Bisdahin abrei\u00dfend vom Seither:", "tokens": ["das", "Bis\u00b7da\u00b7hin", "ab\u00b7rei\u00b7\u00dfend", "vom", "Sei\u00b7ther", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPRART", "NN", "$."], "meter": "-+--++--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "das geht uns an; das einzuordnen wird", "tokens": ["das", "geht", "uns", "an", ";", "das", "ein\u00b7zu\u00b7ord\u00b7nen", "wird"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$.", "PDS", "VVINF", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "die Arbeit sein, die wir mit allem tun.", "tokens": ["die", "Ar\u00b7beit", "sein", ",", "die", "wir", "mit", "al\u00b7lem", "tun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "$,", "PRELS", "PPER", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Doch da\u00df du selbst erschrakst und auch noch jetzt", "tokens": ["Doch", "da\u00df", "du", "selbst", "er\u00b7schrakst", "und", "auch", "noch", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "KON", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "den Schrecken hast, wo Schrecken nicht mehr gilt;", "tokens": ["den", "Schre\u00b7cken", "hast", ",", "wo", "Schre\u00b7cken", "nicht", "mehr", "gilt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "da\u00df du von deiner Ewigkeit ein St\u00fcck", "tokens": ["da\u00df", "du", "von", "dei\u00b7ner", "E\u00b7wig\u00b7keit", "ein", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "verlierst und hier hereintrittst, Freundin, hier,", "tokens": ["ver\u00b7lierst", "und", "hier", "her\u00b7ein\u00b7trittst", ",", "Freun\u00b7din", ",", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "KON", "ADV", "VVFIN", "$,", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "wo alles noch nicht ", "tokens": ["wo", "al\u00b7les", "noch", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "PTKNEG"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "zum ersten Mal im All zerstreut und halb,", "tokens": ["zum", "ers\u00b7ten", "Mal", "im", "All", "zer\u00b7streut", "und", "halb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "NN", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "den Aufgang der unendlichen Naturen", "tokens": ["den", "Auf\u00b7gang", "der", "un\u00b7end\u00b7li\u00b7chen", "Na\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "nicht so ergriffst wie hier ein jedes Ding;", "tokens": ["nicht", "so", "er\u00b7griffst", "wie", "hier", "ein", "je\u00b7des", "Ding", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "KOKOM", "ADV", "ART", "PIAT", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.17": {"text": "da\u00df aus dem Kreislauf, der dich schon empfing,", "tokens": ["da\u00df", "aus", "dem", "Kreis\u00b7lauf", ",", "der", "dich", "schon", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "die stumme Schwerkraft irgend einer Unruh", "tokens": ["die", "stum\u00b7me", "Schwer\u00b7kraft", "ir\u00b7gend", "ei\u00b7ner", "Un\u00b7ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "dich niederzieht zur abgez\u00e4hlten Zeit \u2013:", "tokens": ["dich", "nie\u00b7der\u00b7zieht", "zur", "ab\u00b7ge\u00b7z\u00e4hl\u00b7ten", "Zeit", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "dies weckt mich nachts oft wie ein Dieb, der einbricht.", "tokens": ["dies", "weckt", "mich", "nachts", "oft", "wie", "ein", "Dieb", ",", "der", "ein\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "KOKOM", "ART", "NN", "$,", "PRELS", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.21": {"text": "Und d\u00fcrft ich sagen, da\u00df du nur geruhst,", "tokens": ["Und", "d\u00fcrft", "ich", "sa\u00b7gen", ",", "da\u00df", "du", "nur", "ge\u00b7ruhst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,", "KOUS", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "da\u00df du aus Gro\u00dfmut kommst, aus \u00dcberf\u00fclle,", "tokens": ["da\u00df", "du", "aus", "Gro\u00df\u00b7mut", "kommst", ",", "aus", "\u00dc\u00b7berf\u00b7\u00fcl\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "weil du so sicher bist, so in dir selbst,", "tokens": ["weil", "du", "so", "si\u00b7cher", "bist", ",", "so", "in", "dir", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "da\u00df du herumgehst wie ein Kind, nicht bange", "tokens": ["da\u00df", "du", "her\u00b7um\u00b7gehst", "wie", "ein", "Kind", ",", "nicht", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,", "PTKNEG", "ADV"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "vor \u00d6rtern, wo man einem etwas tut \u2013:", "tokens": ["vor", "\u00d6r\u00b7tern", ",", "wo", "man", "ei\u00b7nem", "et\u00b7was", "tut", "\u2013", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "PIS", "ART", "ADV", "ADJD", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "doch nein: du bittest. Dieses geht mir so", "tokens": ["doch", "nein", ":", "du", "bit\u00b7test", ".", "Die\u00b7ses", "geht", "mir", "so"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PTKANT", "$.", "PPER", "VVFIN", "$.", "PDS", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "bis ins Gebein und querrt wie eine S\u00e4ge.", "tokens": ["bis", "ins", "Ge\u00b7bein", "und", "querrt", "wie", "ei\u00b7ne", "S\u00e4\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Ein Vorwurf, den du tr\u00fcgest als Gespenst,", "tokens": ["Ein", "Vor\u00b7wurf", ",", "den", "du", "tr\u00fc\u00b7gest", "als", "Ge\u00b7spenst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "nachtr\u00fcgest mir, wenn ich mich nachts zur\u00fcckzieh", "tokens": ["nach\u00b7tr\u00fc\u00b7gest", "mir", ",", "wenn", "ich", "mich", "nachts", "zu\u00b7r\u00fcck\u00b7zieh"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "ADV", "VVFIN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.30": {"text": "in meine Lunge, in die Eingeweide,", "tokens": ["in", "mei\u00b7ne", "Lun\u00b7ge", ",", "in", "die", "Ein\u00b7ge\u00b7wei\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "in meines Herzens letzte \u00e4rmste Kammer, \u2013", "tokens": ["in", "mei\u00b7nes", "Her\u00b7zens", "letz\u00b7te", "\u00e4rms\u00b7te", "Kam\u00b7mer", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "ein solcher Vorwurf w\u00e4re nicht so grausam,", "tokens": ["ein", "sol\u00b7cher", "Vor\u00b7wurf", "w\u00e4\u00b7re", "nicht", "so", "grau\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "wie dieses Bitten ist. Was bittest du?", "tokens": ["wie", "die\u00b7ses", "Bit\u00b7ten", "ist", ".", "Was", "bit\u00b7test", "du", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "VAFIN", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Sag, soll ich reisen? Hast du irgendwo", "tokens": ["Sag", ",", "soll", "ich", "rei\u00b7sen", "?", "Hast", "du", "ir\u00b7gend\u00b7wo"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VMFIN", "PPER", "VVINF", "$.", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ein Ding zur\u00fcckgelassen, das sich qu\u00e4lt", "tokens": ["ein", "Ding", "zu\u00b7r\u00fcck\u00b7ge\u00b7las\u00b7sen", ",", "das", "sich", "qu\u00e4lt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "PRELS", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und das dir nachwill? Soll ich in ein Land,", "tokens": ["und", "das", "dir", "nach\u00b7will", "?", "Soll", "ich", "in", "ein", "Land", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PPER", "PTKVZ", "$.", "VMFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "das du nicht sahst, obwohl es dir verwandt", "tokens": ["das", "du", "nicht", "sahst", ",", "ob\u00b7wohl", "es", "dir", "ver\u00b7wandt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PTKNEG", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "war wie die andre H\u00e4lfte deiner Sinne?", "tokens": ["war", "wie", "die", "and\u00b7re", "H\u00e4lf\u00b7te", "dei\u00b7ner", "Sin\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Ich will auf seinen Fl\u00fcssen fahren, will", "tokens": ["Ich", "will", "auf", "sei\u00b7nen", "Fl\u00fcs\u00b7sen", "fah\u00b7ren", ",", "will"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "an Land gehn und nach alten Sitten fragen,", "tokens": ["an", "Land", "gehn", "und", "nach", "al\u00b7ten", "Sit\u00b7ten", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "KON", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "will mit den Frauen in den T\u00fcren sprechen", "tokens": ["will", "mit", "den", "Frau\u00b7en", "in", "den", "T\u00fc\u00b7ren", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "und zusehn, wenn sie ihre Kinder rufen.", "tokens": ["und", "zu\u00b7sehn", ",", "wenn", "sie", "ih\u00b7re", "Kin\u00b7der", "ru\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Ich will mir merken, wie sie dort die Landschaft", "tokens": ["Ich", "will", "mir", "mer\u00b7ken", ",", "wie", "sie", "dort", "die", "Land\u00b7schaft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,", "PWAV", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "umnehmen drau\u00dfen bei der alten Arbeit", "tokens": ["um\u00b7neh\u00b7men", "drau\u00b7\u00dfen", "bei", "der", "al\u00b7ten", "Ar\u00b7beit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "der Wiesen und der Felder; will begehren,", "tokens": ["der", "Wie\u00b7sen", "und", "der", "Fel\u00b7der", ";", "will", "be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "vor ihren K\u00f6nig hingef\u00fchrt zu sein,", "tokens": ["vor", "ih\u00b7ren", "K\u00f6\u00b7nig", "hin\u00b7ge\u00b7f\u00fchrt", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "und will die Priester durch Bestechung reizen,", "tokens": ["und", "will", "die", "Pries\u00b7ter", "durch", "Be\u00b7ste\u00b7chung", "rei\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "da\u00df sie mich legen vor das st\u00e4rkste Standbild", "tokens": ["da\u00df", "sie", "mich", "le\u00b7gen", "vor", "das", "st\u00e4rks\u00b7te", "Stand\u00b7bild"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und fortgehn und die Tempeltore schlie\u00dfen.", "tokens": ["und", "fort\u00b7gehn", "und", "die", "Tem\u00b7pel\u00b7to\u00b7re", "schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dann aber will ich, wenn ich vieles wei\u00df,", "tokens": ["Dann", "a\u00b7ber", "will", "ich", ",", "wenn", "ich", "vie\u00b7les", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "einfach die Tiere anschaun, da\u00df ein Etwas", "tokens": ["ein\u00b7fach", "die", "Tie\u00b7re", "an\u00b7schaun", ",", "da\u00df", "ein", "Et\u00b7was"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "von ihrer Wendung mir in die Gelenke", "tokens": ["von", "ih\u00b7rer", "Wen\u00b7dung", "mir", "in", "die", "Ge\u00b7len\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "her\u00fcbergleitet; will ein kurzes Dasein", "tokens": ["her\u00b7\u00fc\u00b7berg\u00b7lei\u00b7tet", ";", "will", "ein", "kur\u00b7zes", "Da\u00b7sein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$.", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "in ihren Augen haben, die mich halten", "tokens": ["in", "ih\u00b7ren", "Au\u00b7gen", "ha\u00b7ben", ",", "die", "mich", "hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,", "PRELS", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "und langsam lassen, ruhig, ohne Urteil.", "tokens": ["und", "lang\u00b7sam", "las\u00b7sen", ",", "ru\u00b7hig", ",", "oh\u00b7ne", "Ur\u00b7teil", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$,", "ADJD", "$,", "KOUI", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Ich will mir von den G\u00e4rtnern viele Blumen", "tokens": ["Ich", "will", "mir", "von", "den", "G\u00e4rt\u00b7nern", "vie\u00b7le", "Blu\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "hersagen lassen, da\u00df ich in den Scherben", "tokens": ["her\u00b7sa\u00b7gen", "las\u00b7sen", ",", "da\u00df", "ich", "in", "den", "Scher\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVINF", "VVINF", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.20": {"text": "der sch\u00f6nen Eigennamen einen Rest", "tokens": ["der", "sch\u00f6\u00b7nen", "Ei\u00b7gen\u00b7na\u00b7men", "ei\u00b7nen", "Rest"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "her\u00fcberbringe von den hundert D\u00fcften.", "tokens": ["her\u00b7\u00fc\u00b7berb\u00b7rin\u00b7ge", "von", "den", "hun\u00b7dert", "D\u00fcf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Und Fr\u00fcchte will ich kaufen, Fr\u00fcchte, drin", "tokens": ["Und", "Fr\u00fcch\u00b7te", "will", "ich", "kau\u00b7fen", ",", "Fr\u00fcch\u00b7te", ",", "drin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "NN", "VMFIN", "PPER", "VVINF", "$,", "NN", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "das Land noch einmal ist, bis an den Himmel.", "tokens": ["das", "Land", "noch", "ein\u00b7mal", "ist", ",", "bis", "an", "den", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VAFIN", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Denn Das verstandest du: die vollen Fr\u00fcchte.", "tokens": ["Denn", "Das", "ver\u00b7stan\u00b7dest", "du", ":", "die", "vol\u00b7len", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die legtest du auf Schalen vor dich hin", "tokens": ["Die", "leg\u00b7test", "du", "auf", "Scha\u00b7len", "vor", "dich", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "APPR", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wogst mit Farben ihre Schwere auf.", "tokens": ["und", "wogst", "mit", "Far\u00b7ben", "ih\u00b7re", "Schwe\u00b7re", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und so wie Fr\u00fcchte sahst du auch die Fraun", "tokens": ["Und", "so", "wie", "Fr\u00fcch\u00b7te", "sahst", "du", "auch", "die", "Fraun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KOKOM", "NN", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und sahst die Kinder so, von innen her", "tokens": ["und", "sahst", "die", "Kin\u00b7der", "so", ",", "von", "in\u00b7nen", "her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "$,", "APPR", "ADV", "APZR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "getrieben in die Formen ihres Daseins.", "tokens": ["ge\u00b7trie\u00b7ben", "in", "die", "For\u00b7men", "ih\u00b7res", "Da\u00b7seins", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und sahst dich selbst zuletzt wie eine Frucht,", "tokens": ["Und", "sahst", "dich", "selbst", "zu\u00b7letzt", "wie", "ei\u00b7ne", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "nahmst dich heraus aus deinen Kleidern, trugst", "tokens": ["nahmst", "dich", "he\u00b7raus", "aus", "dei\u00b7nen", "Klei\u00b7dern", ",", "trugst"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "APPR", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "dich vor den Spiegel, lie\u00dfest dich hinein", "tokens": ["dich", "vor", "den", "Spie\u00b7gel", ",", "lie\u00b7\u00dfest", "dich", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "NN", "$,", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "bis auf dein Schauen; das blieb gro\u00df davor", "tokens": ["bis", "auf", "dein", "Schau\u00b7en", ";", "das", "blieb", "gro\u00df", "da\u00b7vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$.", "PDS", "VVFIN", "ADJD", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "und sagte nicht: das bin ich; nein: dies ist.", "tokens": ["und", "sag\u00b7te", "nicht", ":", "das", "bin", "ich", ";", "nein", ":", "dies", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$.", "PDS", "VAFIN", "PPER", "$.", "PTKANT", "$.", "PDS", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "So ohne Neugier war zuletzt dein Schaun", "tokens": ["So", "oh\u00b7ne", "Neu\u00b7gier", "war", "zu\u00b7letzt", "dein", "Schaun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "und so besitzlos, von so wahrer Armut,", "tokens": ["und", "so", "be\u00b7sitz\u00b7los", ",", "von", "so", "wah\u00b7rer", "Ar\u00b7mut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "da\u00df es dich selbst nicht mehr begehrte: heilig.", "tokens": ["da\u00df", "es", "dich", "selbst", "nicht", "mehr", "be\u00b7gehr\u00b7te", ":", "hei\u00b7lig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "ADV", "ADJA", "$.", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "So will ich dich behalten, wie du dich", "tokens": ["So", "will", "ich", "dich", "be\u00b7hal\u00b7ten", ",", "wie", "du", "dich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,", "PWAV", "PPER", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "hinstelltest in den Spiegel, tief hinein", "tokens": ["hin\u00b7stell\u00b7test", "in", "den", "Spie\u00b7gel", ",", "tief", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "und fort von allem. Warum kommst du anders?", "tokens": ["und", "fort", "von", "al\u00b7lem", ".", "Wa\u00b7rum", "kommst", "du", "an\u00b7ders", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "APPR", "PIS", "$.", "PWAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Was widerrufst du dich? Was willst du mir", "tokens": ["Was", "wi\u00b7der\u00b7rufst", "du", "dich", "?", "Was", "willst", "du", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "$.", "PWS", "VMFIN", "PPER", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "einreden, da\u00df in jenen Bernsteinkugeln", "tokens": ["ein\u00b7re\u00b7den", ",", "da\u00df", "in", "je\u00b7nen", "Bern\u00b7stein\u00b7ku\u00b7geln"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "um deinen Hals noch etwas Schwere war", "tokens": ["um", "dei\u00b7nen", "Hals", "noch", "et\u00b7was", "Schwe\u00b7re", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "von jener Schwere, wie sie nie im Jenseits", "tokens": ["von", "je\u00b7ner", "Schwe\u00b7re", ",", "wie", "sie", "nie", "im", "Jen\u00b7seits"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "PWAV", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "beruhigter Bilder ist; was zeigst du mir", "tokens": ["be\u00b7ru\u00b7hig\u00b7ter", "Bil\u00b7der", "ist", ";", "was", "zeigst", "du", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "$.", "PWS", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.23": {"text": "in deiner Haltung eine b\u00f6se Ahnung;", "tokens": ["in", "dei\u00b7ner", "Hal\u00b7tung", "ei\u00b7ne", "b\u00f6\u00b7se", "Ah\u00b7nung", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "was hei\u00dft dich die Konturen deines Leibes", "tokens": ["was", "hei\u00dft", "dich", "die", "Kon\u00b7tu\u00b7ren", "dei\u00b7nes", "Lei\u00b7bes"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "auslegen wie die Linien einer Hand,", "tokens": ["aus\u00b7le\u00b7gen", "wie", "die", "Li\u00b7ni\u00b7en", "ei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOKOM", "ART", "NN", "ART", "NN", "$,"], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "da\u00df ich sie nicht mehr sehn kann ohne Schicksal?", "tokens": ["da\u00df", "ich", "sie", "nicht", "mehr", "sehn", "kann", "oh\u00b7ne", "Schick\u00b7sal", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "ADV", "VVINF", "VMFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.25": {"line.1": {"text": "Komm her ins Kerzenlicht. Ich bin nicht bang,", "tokens": ["Komm", "her", "ins", "Ker\u00b7zen\u00b7licht", ".", "Ich", "bin", "nicht", "bang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "$.", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die Toten anzuschauen. Wenn sie kommen,", "tokens": ["die", "To\u00b7ten", "an\u00b7zu\u00b7schau\u00b7en", ".", "Wenn", "sie", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$.", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "so haben sie ein Recht, in unserm Blick", "tokens": ["so", "ha\u00b7ben", "sie", "ein", "Recht", ",", "in", "un\u00b7serm", "Blick"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "sich aufzuhalten, wie die andern Dinge.", "tokens": ["sich", "auf\u00b7zu\u00b7hal\u00b7ten", ",", "wie", "die", "an\u00b7dern", "Din\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVIZU", "$,", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Komm her; wir wollen eine Weile still sein.", "tokens": ["Komm", "her", ";", "wir", "wol\u00b7len", "ei\u00b7ne", "Wei\u00b7le", "still", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "PPER", "VMFIN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sieh diese Rose an auf meinem Schreibtisch;", "tokens": ["Sieh", "die\u00b7se", "Ro\u00b7se", "an", "auf", "mei\u00b7nem", "Schreib\u00b7tisch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ist nicht das Licht um sie genau so zaghaft", "tokens": ["ist", "nicht", "das", "Licht", "um", "sie", "ge\u00b7nau", "so", "zag\u00b7haft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "ADJD", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wie \u00fcber dir: sie d\u00fcrfte auch nicht hier sein.", "tokens": ["wie", "\u00fc\u00b7ber", "dir", ":", "sie", "d\u00fcrf\u00b7te", "auch", "nicht", "hier", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPER", "$.", "PPER", "VMFIN", "ADV", "PTKNEG", "ADV", "VAINF", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Im Garten drau\u00dfen, unvermischt mit mir,", "tokens": ["Im", "Gar\u00b7ten", "drau\u00b7\u00dfen", ",", "un\u00b7ver\u00b7mischt", "mit", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "h\u00e4tte sie bleiben m\u00fcssen oder hingehn, \u2013", "tokens": ["h\u00e4t\u00b7te", "sie", "blei\u00b7ben", "m\u00fcs\u00b7sen", "o\u00b7der", "hin\u00b7gehn", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "VMFIN", "KON", "VVINF", "$,", "$("], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.7": {"text": "nun w\u00e4hrt sie so: was ist ihr mein Bewu\u00dftsein?", "tokens": ["nun", "w\u00e4hrt", "sie", "so", ":", "was", "ist", "ihr", "mein", "Be\u00b7wu\u00df\u00b7tsein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PWS", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Erschrick nicht, wenn ich jetzt begreife, ach,", "tokens": ["Er\u00b7schrick", "nicht", ",", "wenn", "ich", "jetzt", "be\u00b7grei\u00b7fe", ",", "ach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "ITJ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da steigt es in mir auf: ich kann nicht anders,", "tokens": ["da", "steigt", "es", "in", "mir", "auf", ":", "ich", "kann", "nicht", "an\u00b7ders", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$.", "PPER", "VMFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ich mu\u00df begreifen, und wenn ich dran st\u00fcrbe.", "tokens": ["ich", "mu\u00df", "be\u00b7grei\u00b7fen", ",", "und", "wenn", "ich", "dran", "st\u00fcr\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KON", "KOUS", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Begreifen, da\u00df du hier bist. Ich begreife.", "tokens": ["Be\u00b7grei\u00b7fen", ",", "da\u00df", "du", "hier", "bist", ".", "Ich", "be\u00b7grei\u00b7fe", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ganz wie ein Blinder rings ein Ding begreift,", "tokens": ["Ganz", "wie", "ein", "Blin\u00b7der", "rings", "ein", "Ding", "be\u00b7greift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "f\u00fchl ich dein Los und wei\u00df ihm keinen Namen.", "tokens": ["f\u00fchl", "ich", "dein", "Los", "und", "wei\u00df", "ihm", "kei\u00b7nen", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "La\u00df uns zusammen klagen, da\u00df dich einer", "tokens": ["La\u00df", "uns", "zu\u00b7sam\u00b7men", "kla\u00b7gen", ",", "da\u00df", "dich", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$,", "KOUS", "PPER", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "aus deinem Spiegel nahm. Kannst du noch weinen?", "tokens": ["aus", "dei\u00b7nem", "Spie\u00b7gel", "nahm", ".", "Kannst", "du", "noch", "wei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Du kannst nicht. Deiner Tr\u00e4nen Kraft und Andrang", "tokens": ["Du", "kannst", "nicht", ".", "Dei\u00b7ner", "Tr\u00e4\u00b7nen", "Kraft", "und", "An\u00b7drang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "$.", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "hast du verwandelt in dein reifes Anschaun", "tokens": ["hast", "du", "ver\u00b7wan\u00b7delt", "in", "dein", "rei\u00b7fes", "An\u00b7schaun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und warst dabei, jeglichen Saft in dir", "tokens": ["und", "warst", "da\u00b7bei", ",", "jeg\u00b7li\u00b7chen", "Saft", "in", "dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PAV", "$,", "PIAT", "NN", "APPR", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "so umzusetzen in ein starkes Dasein,", "tokens": ["so", "um\u00b7zu\u00b7set\u00b7zen", "in", "ein", "star\u00b7kes", "Da\u00b7sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIZU", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "das steigt und kreist, im Gleichgewicht und blindlings.", "tokens": ["das", "steigt", "und", "kreist", ",", "im", "Gleich\u00b7ge\u00b7wicht", "und", "blind\u00b7lings", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$,", "APPRART", "NN", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Da ri\u00df ein Zufall dich, dein letzter Zufall", "tokens": ["Da", "ri\u00df", "ein", "Zu\u00b7fall", "dich", ",", "dein", "letz\u00b7ter", "Zu\u00b7fall"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "ri\u00df dich zur\u00fcck aus deinem fernsten Fortschritt", "tokens": ["ri\u00df", "dich", "zu\u00b7r\u00fcck", "aus", "dei\u00b7nem", "ferns\u00b7ten", "Fort\u00b7schritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.16": {"text": "in eine Welt zur\u00fcck, wo S\u00e4fte ", "tokens": ["in", "ei\u00b7ne", "Welt", "zu\u00b7r\u00fcck", ",", "wo", "S\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Ri\u00df dich nicht ganz; ri\u00df nur ein St\u00fcck zuerst,", "tokens": ["Ri\u00df", "dich", "nicht", "ganz", ";", "ri\u00df", "nur", "ein", "St\u00fcck", "zu\u00b7erst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ADV", "$.", "VVFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+--++--+-+", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "doch als um dieses St\u00fcck von Tag zu Tag", "tokens": ["doch", "als", "um", "die\u00b7ses", "St\u00fcck", "von", "Tag", "zu", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "PDAT", "NN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "die Wirklichkeit so zunahm, da\u00df es schwer ward,", "tokens": ["die", "Wirk\u00b7lich\u00b7keit", "so", "zu\u00b7nahm", ",", "da\u00df", "es", "schwer", "ward", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "da brauchtest du dich ganz: da gingst du hin", "tokens": ["da", "brauch\u00b7test", "du", "dich", "ganz", ":", "da", "gingst", "du", "hin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "$.", "ADV", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "und brachst in Brocken dich aus dem Gesetz", "tokens": ["und", "brachst", "in", "Bro\u00b7cken", "dich", "aus", "dem", "Ge\u00b7setz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "m\u00fchsam heraus, weil du dich brauchtest.", "tokens": ["m\u00fch\u00b7sam", "he\u00b7raus", ",", "weil", "du", "dich", "brauch\u00b7test", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.23": {"text": "Da trugst du dich ab und grubst aus deines Herzens", "tokens": ["Da", "trugst", "du", "dich", "ab", "und", "grubst", "aus", "dei\u00b7nes", "Her\u00b7zens"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "nachtwarmem Erdreich die noch gr\u00fcnen Samen,", "tokens": ["nacht\u00b7war\u00b7mem", "Er\u00b7dreich", "die", "noch", "gr\u00fc\u00b7nen", "Sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "daraus dein Tod aufkeimen sollte: deiner,", "tokens": ["da\u00b7raus", "dein", "Tod", "auf\u00b7kei\u00b7men", "soll\u00b7te", ":", "dei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "VVINF", "VMFIN", "$.", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "dein eigner Tod zu deinem eignen Leben.", "tokens": ["dein", "eig\u00b7ner", "Tod", "zu", "dei\u00b7nem", "eig\u00b7nen", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Und a\u00dfest sie, die K\u00f6rner deines Todes,", "tokens": ["Und", "a\u00b7\u00dfest", "sie", ",", "die", "K\u00f6r\u00b7ner", "dei\u00b7nes", "To\u00b7des", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "wie alle andern, a\u00dfest seine K\u00f6rner,", "tokens": ["wie", "al\u00b7le", "an\u00b7dern", ",", "a\u00b7\u00dfest", "sei\u00b7ne", "K\u00f6r\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJA", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "und hattest Nachgeschmack in dir von S\u00fc\u00dfe,", "tokens": ["und", "hat\u00b7test", "Nach\u00b7ge\u00b7schmack", "in", "dir", "von", "S\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "APPR", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "die du nicht meintest, hattest s\u00fc\u00dfe Lippen,", "tokens": ["die", "du", "nicht", "mein\u00b7test", ",", "hat\u00b7test", "s\u00fc\u00b7\u00dfe", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVFIN", "$,", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "du: die schon innen in den Sinnen s\u00fc\u00df war.", "tokens": ["du", ":", "die", "schon", "in\u00b7nen", "in", "den", "Sin\u00b7nen", "s\u00fc\u00df", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "ADV", "ADV", "APPR", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "O la\u00df uns klagen. Wei\u00dft du, wie dein Blut", "tokens": ["O", "la\u00df", "uns", "kla\u00b7gen", ".", "Wei\u00dft", "du", ",", "wie", "dein", "Blut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "VVINF", "$.", "VVFIN", "PPER", "$,", "PWAV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aus einem Kreisen ohnegleichen z\u00f6gernd", "tokens": ["aus", "ei\u00b7nem", "Krei\u00b7sen", "oh\u00b7ne\u00b7glei\u00b7chen", "z\u00f6\u00b7gernd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "und ungern wiederkam, da du es abriefst?", "tokens": ["und", "un\u00b7gern", "wie\u00b7der\u00b7kam", ",", "da", "du", "es", "ab\u00b7riefst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie es verwirrt des Leibes kleinen Kreislauf", "tokens": ["Wie", "es", "ver\u00b7wirrt", "des", "Lei\u00b7bes", "klei\u00b7nen", "Kreis\u00b7lauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADJD", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "noch einmal aufnahm; wie es voller Mi\u00dftraun", "tokens": ["noch", "ein\u00b7mal", "auf\u00b7nahm", ";", "wie", "es", "vol\u00b7ler", "Mi\u00df\u00b7traun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "$.", "PWAV", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "und Staunen eintrat in den Mutterkuchen", "tokens": ["und", "Stau\u00b7nen", "ein\u00b7trat", "in", "den", "Mut\u00b7ter\u00b7ku\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und von dem weiten R\u00fcckweg pl\u00f6tzlich m\u00fcd war.", "tokens": ["und", "von", "dem", "wei\u00b7ten", "R\u00fcck\u00b7weg", "pl\u00f6tz\u00b7lich", "m\u00fcd", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADJD", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Du triebst es an, du stie\u00dfest es nach vorn,", "tokens": ["Du", "triebst", "es", "an", ",", "du", "stie\u00b7\u00dfest", "es", "nach", "vorn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "du zerrtest es zur Feuerstelle, wie", "tokens": ["du", "zerr\u00b7test", "es", "zur", "Feu\u00b7er\u00b7stel\u00b7le", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "man eine Herde Tiere zerrt zum Opfer;", "tokens": ["man", "ei\u00b7ne", "Her\u00b7de", "Tie\u00b7re", "zerrt", "zum", "Op\u00b7fer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und wolltest noch, es sollte dabei froh sein.", "tokens": ["und", "woll\u00b7test", "noch", ",", "es", "soll\u00b7te", "da\u00b7bei", "froh", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "$,", "PPER", "VMFIN", "PAV", "ADJD", "VAINF", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Und du erzwangst es schlie\u00dflich: es war froh", "tokens": ["Und", "du", "er\u00b7zwangst", "es", "schlie\u00df\u00b7lich", ":", "es", "war", "froh"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "und lief herbei und gab sich hin. Dir schien,", "tokens": ["und", "lief", "her\u00b7bei", "und", "gab", "sich", "hin", ".", "Dir", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "VVFIN", "PRF", "PTKVZ", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "weil du gewohnt warst an die andern Ma\u00dfe,", "tokens": ["weil", "du", "ge\u00b7wohnt", "warst", "an", "die", "an\u00b7dern", "Ma\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "es w\u00e4re nur f\u00fcr eine Weile; aber", "tokens": ["es", "w\u00e4\u00b7re", "nur", "f\u00fcr", "ei\u00b7ne", "Wei\u00b7le", ";", "a\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "nun warst du in der Zeit, und Zeit ist lang.", "tokens": ["nun", "warst", "du", "in", "der", "Zeit", ",", "und", "Zeit", "ist", "lang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "$,", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Und Zeit geht hin, und Zeit nimmt zu, und Zeit", "tokens": ["Und", "Zeit", "geht", "hin", ",", "und", "Zeit", "nimmt", "zu", ",", "und", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PTKVZ", "$,", "KON", "NN", "VVFIN", "PTKVZ", "$,", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "ist wie ein R\u00fcckfall einer langen Krankheit.", "tokens": ["ist", "wie", "ein", "R\u00fcck\u00b7fall", "ei\u00b7ner", "lan\u00b7gen", "Krank\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Wie war dein Leben kurz, wenn du's vergleichst", "tokens": ["Wie", "war", "dein", "Le\u00b7ben", "kurz", ",", "wenn", "du's", "ver\u00b7gleichst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADJD", "$,", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit jenen Stunden, da du sa\u00dfest und", "tokens": ["mit", "je\u00b7nen", "Stun\u00b7den", ",", "da", "du", "sa\u00b7\u00dfest", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "die vielen Kr\u00e4fte deiner vielen Zukunft", "tokens": ["die", "vie\u00b7len", "Kr\u00e4f\u00b7te", "dei\u00b7ner", "vie\u00b7len", "Zu\u00b7kunft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "schweigend herabbogst zu dem neuen Kindkeim,", "tokens": ["schwei\u00b7gend", "her\u00b7ab\u00b7bogst", "zu", "dem", "neu\u00b7en", "Kind\u00b7keim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "der wieder Schicksal war. O wehe Arbeit.", "tokens": ["der", "wie\u00b7der", "Schick\u00b7sal", "war", ".", "O", "we\u00b7he", "Ar\u00b7beit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VAFIN", "$.", "NE", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "O Arbeit \u00fcber alle Kraft. Du tatest", "tokens": ["O", "Ar\u00b7beit", "\u00fc\u00b7ber", "al\u00b7le", "Kraft", ".", "Du", "ta\u00b7test"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "APPR", "PIAT", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "sie Tag f\u00fcr Tag, du schlepptest dich zu ihr", "tokens": ["sie", "Tag", "f\u00fcr", "Tag", ",", "du", "schlepp\u00b7test", "dich", "zu", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "APPR", "NN", "$,", "PPER", "VVFIN", "PRF", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und zogst den sch\u00f6nen Einschlag aus dem Webstuhl", "tokens": ["und", "zogst", "den", "sch\u00f6\u00b7nen", "Ein\u00b7schlag", "aus", "dem", "Web\u00b7stuhl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "und brauchtest alle deine F\u00e4den anders.", "tokens": ["und", "brauch\u00b7test", "al\u00b7le", "dei\u00b7ne", "F\u00e4\u00b7den", "an\u00b7ders", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und endlich hattest du noch Mut zum Fest.", "tokens": ["Und", "end\u00b7lich", "hat\u00b7test", "du", "noch", "Mut", "zum", "Fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Denn da's getan war, wolltest du belohnt sein,", "tokens": ["Denn", "da's", "ge\u00b7tan", "war", ",", "woll\u00b7test", "du", "be\u00b7lohnt", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVPP", "VAFIN", "$,", "VMFIN", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wie Kinder, wenn sie bitters\u00fc\u00dfen Tee", "tokens": ["wie", "Kin\u00b7der", ",", "wenn", "sie", "bit\u00b7ter\u00b7s\u00fc\u00b7\u00dfen", "Tee"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "KOUS", "PPER", "ADV", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "getrunken haben, der vielleicht gesund macht.", "tokens": ["ge\u00b7trun\u00b7ken", "ha\u00b7ben", ",", "der", "viel\u00b7leicht", "ge\u00b7sund", "macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So lohntest du dich: denn von jedem andern", "tokens": ["So", "lohn\u00b7test", "du", "dich", ":", "denn", "von", "je\u00b7dem", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$.", "ADV", "APPR", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "warst du zu weit, auch jetzt noch; keiner h\u00e4tte", "tokens": ["warst", "du", "zu", "weit", ",", "auch", "jetzt", "noch", ";", "kei\u00b7ner", "h\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "PTKA", "ADJD", "$,", "ADV", "ADV", "ADV", "$.", "PIS", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ausdenken k\u00f6nnen, welcher Lohn dir wohltut.", "tokens": ["aus\u00b7den\u00b7ken", "k\u00f6n\u00b7nen", ",", "wel\u00b7cher", "Lohn", "dir", "wohl\u00b7tut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVINF", "VMINF", "$,", "PWAT", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Du wu\u00dftest es. Du sa\u00dfest auf im Kindbett,", "tokens": ["Du", "wu\u00df\u00b7test", "es", ".", "Du", "sa\u00b7\u00dfest", "auf", "im", "Kind\u00b7bett", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und vor dir stand ein Spiegel, der dir alles", "tokens": ["und", "vor", "dir", "stand", "ein", "Spie\u00b7gel", ",", "der", "dir", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "ganz wiedergab. Nun war das alles ", "tokens": ["ganz", "wie\u00b7der\u00b7gab", ".", "Nun", "war", "das", "al\u00b7les"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$.", "ADV", "VAFIN", "ART", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und ganz ", "tokens": ["und", "ganz"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "die sch\u00f6ne T\u00e4uschung jeder Frau, die gern", "tokens": ["die", "sch\u00f6\u00b7ne", "T\u00e4u\u00b7schung", "je\u00b7der", "Frau", ",", "die", "gern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Schmuck umnimmt und das Haar k\u00e4mmt und ver\u00e4ndert.", "tokens": ["Schmuck", "um\u00b7nimmt", "und", "das", "Haar", "k\u00e4mmt", "und", "ver\u00b7\u00e4n\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.31": {"line.1": {"text": "So starbst du, wie die Frauen fr\u00fcher starben,", "tokens": ["So", "starbst", "du", ",", "wie", "die", "Frau\u00b7en", "fr\u00fc\u00b7her", "star\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "altmodisch starbst du in dem warmen Hause", "tokens": ["alt\u00b7mo\u00b7disch", "starbst", "du", "in", "dem", "war\u00b7men", "Hau\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Tod der W\u00f6chnerinnen, welche wieder", "tokens": ["den", "Tod", "der", "W\u00f6ch\u00b7ne\u00b7rin\u00b7nen", ",", "wel\u00b7che", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sich schlie\u00dfen wollen und es nicht mehr k\u00f6nnen,", "tokens": ["sich", "schlie\u00b7\u00dfen", "wol\u00b7len", "und", "es", "nicht", "mehr", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "VMFIN", "KON", "PPER", "PTKNEG", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "weil jenes Dunkel, das sie mitgebaren,", "tokens": ["weil", "je\u00b7nes", "Dun\u00b7kel", ",", "das", "sie", "mit\u00b7ge\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "noch einmal wiederkommt und dr\u00e4ngt und eintritt.", "tokens": ["noch", "ein\u00b7mal", "wie\u00b7der\u00b7kommt", "und", "dr\u00e4ngt", "und", "ein\u00b7tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.32": {"line.1": {"text": "Ob man nicht dennoch h\u00e4tte Klagefrauen", "tokens": ["Ob", "man", "nicht", "den\u00b7noch", "h\u00e4t\u00b7te", "Kla\u00b7ge\u00b7frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "VAFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "auftreiben m\u00fcssen? Weiber, welche weinen", "tokens": ["auf\u00b7trei\u00b7ben", "m\u00fcs\u00b7sen", "?", "Wei\u00b7ber", ",", "wel\u00b7che", "wei\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVINF", "VMINF", "$.", "NN", "$,", "PRELS", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "f\u00fcr Geld, und die man so bezahlen kann,", "tokens": ["f\u00fcr", "Geld", ",", "und", "die", "man", "so", "be\u00b7zah\u00b7len", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KON", "ART", "PIS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df sie die Nacht durch heulen, wenn es still wird.", "tokens": ["da\u00df", "sie", "die", "Nacht", "durch", "heu\u00b7len", ",", "wenn", "es", "still", "wird", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "VVINF", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Gebr\u00e4uche her! wir haben nicht genug", "tokens": ["Ge\u00b7br\u00e4u\u00b7che", "her", "!", "wir", "ha\u00b7ben", "nicht", "ge\u00b7nug"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$.", "PPER", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Gebr\u00e4uche. Alles geht und wird verredet.", "tokens": ["Ge\u00b7br\u00e4u\u00b7che", ".", "Al\u00b7les", "geht", "und", "wird", "ver\u00b7re\u00b7det", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VVFIN", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So mu\u00dft du kommen, tot, und hier mit mir", "tokens": ["So", "mu\u00dft", "du", "kom\u00b7men", ",", "tot", ",", "und", "hier", "mit", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "ADJD", "$,", "KON", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Klagen nachholen. H\u00f6rst du, da\u00df ich klage?", "tokens": ["Kla\u00b7gen", "nach\u00b7ho\u00b7len", ".", "H\u00f6rst", "du", ",", "da\u00df", "ich", "kla\u00b7ge", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$.", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "Ich m\u00f6chte meine Stimme wie ein Tuch", "tokens": ["Ich", "m\u00f6ch\u00b7te", "mei\u00b7ne", "Stim\u00b7me", "wie", "ein", "Tuch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "hinwerfen \u00fcber deines Todes Scherben", "tokens": ["hin\u00b7wer\u00b7fen", "\u00fc\u00b7ber", "dei\u00b7nes", "To\u00b7des", "Scher\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und zerrn an ihr, bis sie in Fetzen geht,", "tokens": ["und", "zerrn", "an", "ihr", ",", "bis", "sie", "in", "Fet\u00b7zen", "geht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "und alles, was ich sage, m\u00fc\u00dfte so", "tokens": ["und", "al\u00b7les", ",", "was", "ich", "sa\u00b7ge", ",", "m\u00fc\u00df\u00b7te", "so"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VMFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "zerlumpt in dieser Stimme gehn und frieren;", "tokens": ["zer\u00b7lumpt", "in", "die\u00b7ser", "Stim\u00b7me", "gehn", "und", "frie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDAT", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "blieb es beim Klagen. Doch jetzt klag ich an:", "tokens": ["blieb", "es", "beim", "Kla\u00b7gen", ".", "Doch", "jetzt", "klag", "ich", "an", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$.", "KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "den Einen nicht, der dich aus dir zur\u00fcckzog,", "tokens": ["den", "Ei\u00b7nen", "nicht", ",", "der", "dich", "aus", "dir", "zu\u00b7r\u00fcck\u00b7zog", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "PTKNEG", "$,", "PRELS", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "(ich find ihn nicht heraus, er ist wie alle)", "tokens": ["(", "ich", "find", "ihn", "nicht", "he\u00b7raus", ",", "er", "ist", "wie", "al\u00b7le", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "PPER", "VAFIN", "KOKOM", "PIAT", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "doch alle klag ich in ihm an: den Mann.", "tokens": ["doch", "al\u00b7le", "klag", "ich", "in", "ihm", "an", ":", "den", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Wenn irgendwo ein Kindgewesensein", "tokens": ["Wenn", "ir\u00b7gend\u00b7wo", "ein", "Kind\u00b7ge\u00b7we\u00b7sen\u00b7sein"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "tief in mir aufsteigt, das ich noch nicht kenne,", "tokens": ["tief", "in", "mir", "auf\u00b7steigt", ",", "das", "ich", "noch", "nicht", "ken\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVPP", "$,", "PRELS", "PPER", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+---+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "vielleicht das reinste Kindsein meiner Kindheit:", "tokens": ["viel\u00b7leicht", "das", "reins\u00b7te", "Kinds\u00b7ein", "mei\u00b7ner", "Kind\u00b7heit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ich wills nicht wissen. Einen Engel will", "tokens": ["ich", "wills", "nicht", "wis\u00b7sen", ".", "Ei\u00b7nen", "En\u00b7gel", "will"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$.", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "ich daraus bilden ohne hinzusehn", "tokens": ["ich", "da\u00b7raus", "bil\u00b7den", "oh\u00b7ne", "hin\u00b7zu\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PAV", "VVFIN", "APPR", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und will ihn werfen in die erste Reihe", "tokens": ["und", "will", "ihn", "wer\u00b7fen", "in", "die", "ers\u00b7te", "Rei\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "schreiender Engel, welche Gott erinnern.", "tokens": ["schrei\u00b7en\u00b7der", "En\u00b7gel", ",", "wel\u00b7che", "Gott", "e\u00b7rin\u00b7nern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAT", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.34": {"line.1": {"text": "Denn dieses Leiden dauert schon zu lang,", "tokens": ["Denn", "die\u00b7ses", "Lei\u00b7den", "dau\u00b7ert", "schon", "zu", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und keiner kanns; es ist zu schwer f\u00fcr uns,", "tokens": ["und", "kei\u00b7ner", "kanns", ";", "es", "ist", "zu", "schwer", "f\u00fcr", "uns", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "$.", "PPER", "VAFIN", "PTKA", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "das wirre Leiden von der falschen Liebe,", "tokens": ["das", "wir\u00b7re", "Lei\u00b7den", "von", "der", "fal\u00b7schen", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die, bauend auf Verj\u00e4hrung wie Gewohnheit,", "tokens": ["die", ",", "bau\u00b7end", "auf", "Ver\u00b7j\u00e4h\u00b7rung", "wie", "Ge\u00b7wohn\u00b7heit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "APPR", "NN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ein Recht sich nennt und wuchert aus dem Unrecht.", "tokens": ["ein", "Recht", "sich", "nennt", "und", "wu\u00b7chert", "aus", "dem", "Un\u00b7recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wo ist ein Mann, der Recht hat auf Besitz?", "tokens": ["Wo", "ist", "ein", "Mann", ",", "der", "Recht", "hat", "auf", "Be\u00b7sitz", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "ART", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wer kann besitzen, was sich selbst nicht h\u00e4lt,", "tokens": ["Wer", "kann", "be\u00b7sit\u00b7zen", ",", "was", "sich", "selbst", "nicht", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "VVINF", "$,", "PRELS", "PRF", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "was sich von Zeit zu Zeit nur selig auff\u00e4ngt", "tokens": ["was", "sich", "von", "Zeit", "zu", "Zeit", "nur", "se\u00b7lig", "auf\u00b7f\u00e4ngt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPR", "NN", "APPR", "NN", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.9": {"text": "und wieder hinwirft wie ein Kind den Ball.", "tokens": ["und", "wie\u00b7der", "hin\u00b7wirft", "wie", "ein", "Kind", "den", "Ball", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "KOKOM", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sowenig wie der Feldherr eine Nike", "tokens": ["So\u00b7we\u00b7nig", "wie", "der", "Feld\u00b7herr", "ei\u00b7ne", "Ni\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "festhalten kann am Vorderbug des Schiffes,", "tokens": ["fest\u00b7hal\u00b7ten", "kann", "am", "Vor\u00b7der\u00b7bug", "des", "Schif\u00b7fes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVINF", "VMFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "wenn das geheime Leichtsein ihrer Gottheit", "tokens": ["wenn", "das", "ge\u00b7hei\u00b7me", "Leich\u00b7tsein", "ih\u00b7rer", "Got\u00b7theit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "sie pl\u00f6tzlich weghebt in den hellen Meerwind:", "tokens": ["sie", "pl\u00f6tz\u00b7lich", "weg\u00b7hebt", "in", "den", "hel\u00b7len", "Meer\u00b7wind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "so wenig kann einer von uns die Frau", "tokens": ["so", "we\u00b7nig", "kann", "ei\u00b7ner", "von", "uns", "die", "Frau"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VMFIN", "PIS", "APPR", "PPER", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "anrufen, die uns nicht mehr sieht und die", "tokens": ["an\u00b7ru\u00b7fen", ",", "die", "uns", "nicht", "mehr", "sieht", "und", "die"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PRELS", "PPER", "PTKNEG", "ADV", "VVFIN", "KON", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "auf einem schmalen Streifen ihres Daseins", "tokens": ["auf", "ei\u00b7nem", "schma\u00b7len", "Strei\u00b7fen", "ih\u00b7res", "Da\u00b7seins"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "wie durch ein Wunder fortgeht, ohne Unfall:", "tokens": ["wie", "durch", "ein", "Wun\u00b7der", "fort\u00b7geht", ",", "oh\u00b7ne", "Un\u00b7fall", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "VVFIN", "$,", "KOUI", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "er h\u00e4tte denn Beruf und Lust zur Schuld.", "tokens": ["er", "h\u00e4t\u00b7te", "denn", "Be\u00b7ruf", "und", "Lust", "zur", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "die Freiheit eines Lieben nicht vermehren", "tokens": ["die", "Frei\u00b7heit", "ei\u00b7nes", "Lie\u00b7ben", "nicht", "ver\u00b7meh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "um alle Freiheit, die man in sich aufbringt.", "tokens": ["um", "al\u00b7le", "Frei\u00b7heit", ",", "die", "man", "in", "sich", "auf\u00b7bringt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "PIS", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir haben, wo wir lieben, ja nur dies:", "tokens": ["Wir", "ha\u00b7ben", ",", "wo", "wir", "lie\u00b7ben", ",", "ja", "nur", "dies", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "ADV", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "einander lassen; denn da\u00df wir uns halten,", "tokens": ["ein\u00b7an\u00b7der", "las\u00b7sen", ";", "denn", "da\u00df", "wir", "uns", "hal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$.", "KON", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "das f\u00e4llt uns leicht und ist nicht erst zu lernen.", "tokens": ["das", "f\u00e4llt", "uns", "leicht", "und", "ist", "nicht", "erst", "zu", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "KON", "VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "Bist du noch da? In welcher Ecke bist du? \u2013", "tokens": ["Bist", "du", "noch", "da", "?", "In", "wel\u00b7cher", "E\u00b7cke", "bist", "du", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "$.", "APPR", "PWAT", "NN", "VAFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Du hast so viel gewu\u00dft von alledem", "tokens": ["Du", "hast", "so", "viel", "ge\u00b7wu\u00dft", "von", "al\u00b7le\u00b7dem"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "APPR", "PIS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und hast so viel gekonnt, da du so hingingst", "tokens": ["und", "hast", "so", "viel", "ge\u00b7konnt", ",", "da", "du", "so", "hin\u00b7gingst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "f\u00fcr alles offen, wie ein Tag, der anbricht.", "tokens": ["f\u00fcr", "al\u00b7les", "of\u00b7fen", ",", "wie", "ein", "Tag", ",", "der", "an\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADJD", "$,", "PWAV", "ART", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Die Frauen leiden: lieben hei\u00dft allein sein,", "tokens": ["Die", "Frau\u00b7en", "lei\u00b7den", ":", "lie\u00b7ben", "hei\u00dft", "al\u00b7lein", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "VVINF", "VVFIN", "ADV", "VAINF", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "und K\u00fcnstler ahnen manchmal in der Arbeit,", "tokens": ["und", "K\u00fcnst\u00b7ler", "ah\u00b7nen", "manch\u00b7mal", "in", "der", "Ar\u00b7beit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "da\u00df sie verwandeln m\u00fcssen, wo sie lieben.", "tokens": ["da\u00df", "sie", "ver\u00b7wan\u00b7deln", "m\u00fcs\u00b7sen", ",", "wo", "sie", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMINF", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Beides begannst du; beides ist in Dem,", "tokens": ["Bei\u00b7des", "be\u00b7gannst", "du", ";", "bei\u00b7des", "ist", "in", "Dem", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$.", "PIS", "VAFIN", "APPR", "PDS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "was jetzt ein Ruhm entstellt, der es dir fortnimmt.", "tokens": ["was", "jetzt", "ein", "Ruhm", "ent\u00b7stellt", ",", "der", "es", "dir", "fort\u00b7nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,", "PRELS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Ach du warst weit von jedem Ruhm. Du warst", "tokens": ["Ach", "du", "warst", "weit", "von", "je\u00b7dem", "Ruhm", ".", "Du", "warst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "PPER", "VAFIN", "ADJD", "APPR", "PIAT", "NN", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "unscheinbar; hattest leise deine Sch\u00f6nheit", "tokens": ["un\u00b7schein\u00b7bar", ";", "hat\u00b7test", "lei\u00b7se", "dei\u00b7ne", "Sch\u00f6n\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "VAFIN", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "hineingenommen, wie man eine Fahne", "tokens": ["hin\u00b7ein\u00b7ge\u00b7nom\u00b7men", ",", "wie", "man", "ei\u00b7ne", "Fah\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "PWAV", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "einzieht am grauen Morgen eines Werktags,", "tokens": ["ein\u00b7zieht", "am", "grau\u00b7en", "Mor\u00b7gen", "ei\u00b7nes", "Werk\u00b7tags", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "und wolltest nichts, als eine lange Arbeit, \u2013", "tokens": ["und", "woll\u00b7test", "nichts", ",", "als", "ei\u00b7ne", "lan\u00b7ge", "Ar\u00b7beit", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PIS", "$,", "KOUS", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "die nicht getan ist: dennoch nicht getan.", "tokens": ["die", "nicht", "ge\u00b7tan", "ist", ":", "den\u00b7noch", "nicht", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "VVPP", "VAFIN", "$.", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Wenn du noch da bist, wenn in diesem Dunkel", "tokens": ["Wenn", "du", "noch", "da", "bist", ",", "wenn", "in", "die\u00b7sem", "Dun\u00b7kel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VAFIN", "$,", "KOUS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "noch eine Stelle ist, an der dein Geist", "tokens": ["noch", "ei\u00b7ne", "Stel\u00b7le", "ist", ",", "an", "der", "dein", "Geist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VAFIN", "$,", "APPR", "ART", "PPOSAT", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "empfindlich mitschwingt auf den flachen Schallwelln,", "tokens": ["emp\u00b7find\u00b7lich", "mit\u00b7schwingt", "auf", "den", "fla\u00b7chen", "Schall\u00b7welln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die eine Stimme, einsam in der Nacht,", "tokens": ["die", "ei\u00b7ne", "Stim\u00b7me", ",", "ein\u00b7sam", "in", "der", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "aufregt in eines hohen Zimmers Str\u00f6mung:", "tokens": ["auf\u00b7regt", "in", "ei\u00b7nes", "ho\u00b7hen", "Zim\u00b7mers", "Str\u00f6\u00b7mung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So h\u00f6r mich: Hilf mir. Sieh, wir gleiten so,", "tokens": ["So", "h\u00f6r", "mich", ":", "Hilf", "mir", ".", "Sieh", ",", "wir", "glei\u00b7ten", "so", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NE", "PPER", "$.", "NE", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "nicht wissend wann, zur\u00fcck aus unserm Fortschritt", "tokens": ["nicht", "wis\u00b7send", "wann", ",", "zu\u00b7r\u00fcck", "aus", "un\u00b7serm", "Fort\u00b7schritt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "PWAV", "$,", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "in irgendwas, was wir nicht meinen; drin", "tokens": ["in", "ir\u00b7gend\u00b7was", ",", "was", "wir", "nicht", "mei\u00b7nen", ";", "drin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PIS", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "$.", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "wir uns verfangen wie in einem Traum", "tokens": ["wir", "uns", "ver\u00b7fan\u00b7gen", "wie", "in", "ei\u00b7nem", "Traum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PRF", "VVINF", "KOKOM", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "und drin wir sterben, ohne zu erwachen.", "tokens": ["und", "drin", "wir", "ster\u00b7ben", ",", "oh\u00b7ne", "zu", "er\u00b7wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "$,", "KOUI", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Keiner ist weiter. Jedem, der sein Blut", "tokens": ["Kei\u00b7ner", "ist", "wei\u00b7ter", ".", "Je\u00b7dem", ",", "der", "sein", "Blut"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "$.", "PIAT", "$,", "PRELS", "PPOSAT", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "hinaufhob in ein Werk, das lange wird,", "tokens": ["hin\u00b7auf\u00b7hob", "in", "ein", "Werk", ",", "das", "lan\u00b7ge", "wird", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "kann es geschehen, da\u00df ers nicht mehr hochh\u00e4lt", "tokens": ["kann", "es", "ge\u00b7sche\u00b7hen", ",", "da\u00df", "ers", "nicht", "mehr", "hoch\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VVPP", "$,", "KOUS", "PIS", "PTKNEG", "ADV", "VVFIN"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.14": {"text": "und da\u00df es geht nach seiner Schwere, wertlos.", "tokens": ["und", "da\u00df", "es", "geht", "nach", "sei\u00b7ner", "Schwe\u00b7re", ",", "wert\u00b7los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.15": {"text": "Denn irgendwo ist eine alte Feindschaft", "tokens": ["Denn", "ir\u00b7gend\u00b7wo", "ist", "ei\u00b7ne", "al\u00b7te", "Feind\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "zwischen dem Leben und der gro\u00dfen Arbeit.", "tokens": ["zwi\u00b7schen", "dem", "Le\u00b7ben", "und", "der", "gro\u00b7\u00dfen", "Ar\u00b7beit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Da\u00df ich sie einseh und sie sage: hilf mir.", "tokens": ["Da\u00df", "ich", "sie", "ein\u00b7seh", "und", "sie", "sa\u00b7ge", ":", "hilf", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "KON", "PPER", "VVFIN", "$.", "VVIMP", "PPER", "$."], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.38": {"line.1": {"text": "Komm nicht zur\u00fcck. Wenn du's ertr\u00e4gst, so sei", "tokens": ["Komm", "nicht", "zu\u00b7r\u00fcck", ".", "Wenn", "du's", "er\u00b7tr\u00e4gst", ",", "so", "sei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKNEG", "PTKVZ", "$.", "KOUS", "PIS", "VVFIN", "$,", "ADV", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "tot bei den Toten. Tote sind besch\u00e4ftigt.", "tokens": ["tot", "bei", "den", "To\u00b7ten", ".", "To\u00b7te", "sind", "be\u00b7sch\u00e4f\u00b7tigt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$.", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch hilf mir so, da\u00df es dich nicht zerstreut,", "tokens": ["Doch", "hilf", "mir", "so", ",", "da\u00df", "es", "dich", "nicht", "zer\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "VVPP", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.4": {"text": "wie mir das Fernste manchmal hilft: in mir.", "tokens": ["wie", "mir", "das", "Ferns\u00b7te", "manch\u00b7mal", "hilft", ":", "in", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "ADV", "VVFIN", "$.", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}