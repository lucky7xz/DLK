{"textgrid.poem.40363": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Maik\u00f6nig kommt gefahren,", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Maik\u00f6nig kommt gefahren,", "tokens": ["Mai\u00b7k\u00f6\u00b7nig", "kommt", "ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "in seinem gr\u00fcngoldnen Wagen,", "tokens": ["in", "sei\u00b7nem", "gr\u00fcn\u00b7gold\u00b7nen", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "mit Saus und Gesinge.", "tokens": ["mit", "Saus", "und", "Ge\u00b7sin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Seine Z\u00fcgel sind Sonnenstrahlen;", "tokens": ["Sei\u00b7ne", "Z\u00fc\u00b7gel", "sind", "Son\u00b7nen\u00b7strah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "gro\u00dfe blaue Schmetterlinge", "tokens": ["gro\u00b7\u00dfe", "blau\u00b7e", "Schmet\u00b7ter\u00b7lin\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ziehn ihn \u00fcber Busch und Bach,", "tokens": ["ziehn", "ihn", "\u00fc\u00b7ber", "Busch", "und", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "da\u00df die wei\u00dfen Bl\u00fctenglocken", "tokens": ["da\u00df", "die", "wei\u00b7\u00dfen", "Bl\u00fc\u00b7ten\u00b7glo\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "in seinen Locken", "tokens": ["in", "sei\u00b7nen", "Lo\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "schwingen und springen.", "tokens": ["schwin\u00b7gen", "und", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Und Hans kuckt ihm nach", "tokens": ["Und", "Hans", "kuckt", "ihm", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "PPER", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "und h\u00f6rt sein Lied:", "tokens": ["und", "h\u00f6rt", "sein", "Lied", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "wer zieht mit? zieht mit?", "tokens": ["wer", "zieht", "mit", "?", "zieht", "mit", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKVZ", "$.", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Kommt das Maienweibchen,", "tokens": ["Kommt", "das", "Mai\u00b7en\u00b7weib\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "tr\u00e4gt ein wei\u00dfes Kleidchen,", "tokens": ["tr\u00e4gt", "ein", "wei\u00b7\u00dfes", "Kleid\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "tr\u00e4gt ein gr\u00fcnes Kr\u00e4nzchen,", "tokens": ["tr\u00e4gt", "ein", "gr\u00fc\u00b7nes", "Kr\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "sagt zu unserm H\u00e4nschen:", "tokens": ["sagt", "zu", "un\u00b7serm", "H\u00e4n\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Eia, Hans,", "tokens": ["Ei\u00b7a", ",", "Hans", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "komm zum Tanz!", "tokens": ["komm", "zum", "Tanz", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Einen Schritt Frau Nixe,", "tokens": ["Ei\u00b7nen", "Schritt", "Frau", "Ni\u00b7xe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.8": {"text": "einen Schritt Herr Nix,", "tokens": ["ei\u00b7nen", "Schritt", "Herr", "Nix", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Ringeldireih, Ringeldireih,", "tokens": ["Rin\u00b7gel\u00b7di\u00b7reih", ",", "Rin\u00b7gel\u00b7di\u00b7reih", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Dienerchen,", "tokens": ["Die\u00b7ner\u00b7chen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "Knix!", "tokens": ["Knix", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.3": {"line.1": {"text": "Lieber, \u00df\u00f6ner Hampelmann!", "tokens": ["Lie\u00b7ber", ",", "\u00df\u00f6\u00b7ner", "Ham\u00b7pel\u00b7mann", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fing die Detta wieder an;", "tokens": ["fing", "die", "Det\u00b7ta", "wie\u00b7der", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sieh doch endlich manchmal her!", "tokens": ["sieh", "doch", "end\u00b7lich", "manch\u00b7mal", "her", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "freust du dich denn garnicht sehr?", "tokens": ["freust", "du", "dich", "denn", "gar\u00b7nicht", "sehr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "du?", "tokens": ["du", "?"], "token_info": ["word", "punct"], "pos": ["PPER", "$."], "meter": "-", "measure": "single.down"}}, "stanza.4": {"line.1": {"text": "Du! mein tleiner lieber Dott!", "tokens": ["Du", "!", "mein", "tlei\u00b7ner", "lie\u00b7ber", "Dott", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "kuck doch nich so w\u00fctend fo't!", "tokens": ["kuck", "doch", "nich", "so", "w\u00fc\u00b7tend", "fo't", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00dfenkst du mir denn teinen Tu\u00df,", "tokens": ["\u00dfenkst", "du", "mir", "denn", "tei\u00b7nen", "Tu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn man so viel beten mu\u00df?", "tokens": ["wenn", "man", "so", "viel", "be\u00b7ten", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "nein? \u2013", "tokens": ["nein", "?", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["PTKANT", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.5": {"line.1": {"text": "Nein, der b\u00f6se Flitzebock", "tokens": ["Nein", ",", "der", "b\u00f6\u00b7se", "Flit\u00b7ze\u00b7bock"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sa\u00df so steif wie'n Fliegenstock,", "tokens": ["sa\u00df", "so", "steif", "wie'n", "Flie\u00b7gen\u00b7stock", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sah nur immer starr und stumm", "tokens": ["sah", "nur", "im\u00b7mer", "starr", "und", "stumm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "nach dem alten Hut sich um;", "tokens": ["nach", "dem", "al\u00b7ten", "Hut", "sich", "um", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PRF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "oh.", "tokens": ["oh", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Oh, sprach Detta, sei doch dut!", "tokens": ["Oh", ",", "sprach", "Det\u00b7ta", ",", "sei", "doch", "dut", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "NE", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "willst du einen neuen Hut?", "tokens": ["willst", "du", "ei\u00b7nen", "neu\u00b7en", "Hut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tlinglingling: wer b'ingt das Band?", "tokens": ["Tling\u00b7ling\u00b7ling", ":", "wer", "ing", "das", "Band", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nigin aus Mohrenland!", "tokens": ["K\u00f6\u00b7ni\u00b7gin", "aus", "Moh\u00b7ren\u00b7land", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "tnicks!", "tokens": ["tnicks", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-", "measure": "single.down"}}, "stanza.7": {"line.1": {"text": "Tnix, ich bin F'au T\u00f6nidin,", "tokens": ["Tnix", ",", "ich", "bin", "F'\u00b7au", "T\u00f6\u00b7ni\u00b7din", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "NE", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "hab zvei Lippen von Zutterrosin;", "tokens": ["hab", "zvei", "Lip\u00b7pen", "von", "Zut\u00b7ter\u00b7ro\u00b7sin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "APPR", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Fitzebutze, sieh mal an,", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "sieh", "mal", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ei, wie Detta tanzen tann,", "tokens": ["ei", ",", "wie", "Det\u00b7ta", "tan\u00b7zen", "tann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "NE", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "hopp\u00df!", "tokens": ["hopp\u00df", "!"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}}, "stanza.8": {"line.1": {"text": "Hop\u00dfa, hop\u00dfa, hop\u00dfassa:", "tokens": ["Hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfas\u00b7sa", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "FM.la", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "T\u00f6nigin von Af'ika!", "tokens": ["T\u00f6\u00b7ni\u00b7gin", "von", "Af'\u00b7i\u00b7ka", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flitzeputzig, Butzebein,", "tokens": ["Flit\u00b7ze\u00b7put\u00b7zig", ",", "But\u00b7ze\u00b7bein", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wann soll unse Hochzeit sein?", "tokens": ["wann", "soll", "un\u00b7se", "Hoch\u00b7zeit", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "na? \u2013", "tokens": ["na", "?", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ITJ", "$.", "$("], "meter": "O", "measure": "unknown.measure.zero"}}, "stanza.9": {"line.1": {"text": "Na, was meint ihr, was geschah?", "tokens": ["Na", ",", "was", "meint", "ihr", ",", "was", "ge\u00b7schah", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "VVFIN", "PPER", "$,", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er sa\u00df stumm wie immer da.", "tokens": ["Er", "sa\u00df", "stumm", "wie", "im\u00b7mer", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KOKOM", "ADV", "ADV", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Immer stumm auf seinem Platz", "tokens": ["Im\u00b7mer", "stumm", "auf", "sei\u00b7nem", "Platz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "sa\u00df der alte Hampelmatz,", "tokens": ["sa\u00df", "der", "al\u00b7te", "Ham\u00b7pel\u00b7matz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "huh.", "tokens": ["huh", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+", "measure": "single.up"}}, "stanza.10": {"line.1": {"text": "Huh, er hatte keinen Mut,", "tokens": ["Huh", ",", "er", "hat\u00b7te", "kei\u00b7nen", "Mut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wollte keinen neuen Hut.", "tokens": ["woll\u00b7te", "kei\u00b7nen", "neu\u00b7en", "Hut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da schmi\u00df Detta ihn vom Stuhl:", "tokens": ["Da", "schmi\u00df", "Det\u00b7ta", "ihn", "vom", "Stuhl", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PPER", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Ach, du dummer Blitzepul,", "tokens": ["Ach", ",", "du", "dum\u00b7mer", "Blit\u00b7ze\u00b7pul", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "marsch! \u2013", "tokens": ["marsch", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ADJD", "$.", "$("], "meter": "-", "measure": "single.down"}}, "stanza.11": {"line.1": {"text": "Maik\u00f6nig kommt gefahren,", "tokens": ["Mai\u00b7k\u00f6\u00b7nig", "kommt", "ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "in seinem gr\u00fcngoldnen Wagen,", "tokens": ["in", "sei\u00b7nem", "gr\u00fcn\u00b7gold\u00b7nen", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "mit Saus und Gesinge.", "tokens": ["mit", "Saus", "und", "Ge\u00b7sin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Seine Z\u00fcgel sind Sonnenstrahlen;", "tokens": ["Sei\u00b7ne", "Z\u00fc\u00b7gel", "sind", "Son\u00b7nen\u00b7strah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "gro\u00dfe blaue Schmetterlinge", "tokens": ["gro\u00b7\u00dfe", "blau\u00b7e", "Schmet\u00b7ter\u00b7lin\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ziehn ihn \u00fcber Busch und Bach,", "tokens": ["ziehn", "ihn", "\u00fc\u00b7ber", "Busch", "und", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "da\u00df die wei\u00dfen Bl\u00fctenglocken", "tokens": ["da\u00df", "die", "wei\u00b7\u00dfen", "Bl\u00fc\u00b7ten\u00b7glo\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "in seinen Locken", "tokens": ["in", "sei\u00b7nen", "Lo\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "schwingen und springen.", "tokens": ["schwin\u00b7gen", "und", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Und Hans kuckt ihm nach", "tokens": ["Und", "Hans", "kuckt", "ihm", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "PPER", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "und h\u00f6rt sein Lied:", "tokens": ["und", "h\u00f6rt", "sein", "Lied", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "wer zieht mit? zieht mit?", "tokens": ["wer", "zieht", "mit", "?", "zieht", "mit", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKVZ", "$.", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Kommt das Maienweibchen,", "tokens": ["Kommt", "das", "Mai\u00b7en\u00b7weib\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "tr\u00e4gt ein wei\u00dfes Kleidchen,", "tokens": ["tr\u00e4gt", "ein", "wei\u00b7\u00dfes", "Kleid\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "tr\u00e4gt ein gr\u00fcnes Kr\u00e4nzchen,", "tokens": ["tr\u00e4gt", "ein", "gr\u00fc\u00b7nes", "Kr\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "sagt zu unserm H\u00e4nschen:", "tokens": ["sagt", "zu", "un\u00b7serm", "H\u00e4n\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Eia, Hans,", "tokens": ["Ei\u00b7a", ",", "Hans", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "komm zum Tanz!", "tokens": ["komm", "zum", "Tanz", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Einen Schritt Frau Nixe,", "tokens": ["Ei\u00b7nen", "Schritt", "Frau", "Ni\u00b7xe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.8": {"text": "einen Schritt Herr Nix,", "tokens": ["ei\u00b7nen", "Schritt", "Herr", "Nix", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Ringeldireih, Ringeldireih,", "tokens": ["Rin\u00b7gel\u00b7di\u00b7reih", ",", "Rin\u00b7gel\u00b7di\u00b7reih", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Dienerchen,", "tokens": ["Die\u00b7ner\u00b7chen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.11": {"text": "Knix!", "tokens": ["Knix", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.13": {"line.1": {"text": "Lieber, \u00df\u00f6ner Hampelmann!", "tokens": ["Lie\u00b7ber", ",", "\u00df\u00f6\u00b7ner", "Ham\u00b7pel\u00b7mann", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fing die Detta wieder an;", "tokens": ["fing", "die", "Det\u00b7ta", "wie\u00b7der", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sieh doch endlich manchmal her!", "tokens": ["sieh", "doch", "end\u00b7lich", "manch\u00b7mal", "her", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "freust du dich denn garnicht sehr?", "tokens": ["freust", "du", "dich", "denn", "gar\u00b7nicht", "sehr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "du?", "tokens": ["du", "?"], "token_info": ["word", "punct"], "pos": ["PPER", "$."], "meter": "-", "measure": "single.down"}}, "stanza.14": {"line.1": {"text": "Du! mein tleiner lieber Dott!", "tokens": ["Du", "!", "mein", "tlei\u00b7ner", "lie\u00b7ber", "Dott", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "kuck doch nich so w\u00fctend fo't!", "tokens": ["kuck", "doch", "nich", "so", "w\u00fc\u00b7tend", "fo't", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00dfenkst du mir denn teinen Tu\u00df,", "tokens": ["\u00dfenkst", "du", "mir", "denn", "tei\u00b7nen", "Tu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn man so viel beten mu\u00df?", "tokens": ["wenn", "man", "so", "viel", "be\u00b7ten", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "nein? \u2013", "tokens": ["nein", "?", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["PTKANT", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.15": {"line.1": {"text": "Nein, der b\u00f6se Flitzebock", "tokens": ["Nein", ",", "der", "b\u00f6\u00b7se", "Flit\u00b7ze\u00b7bock"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sa\u00df so steif wie'n Fliegenstock,", "tokens": ["sa\u00df", "so", "steif", "wie'n", "Flie\u00b7gen\u00b7stock", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sah nur immer starr und stumm", "tokens": ["sah", "nur", "im\u00b7mer", "starr", "und", "stumm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "nach dem alten Hut sich um;", "tokens": ["nach", "dem", "al\u00b7ten", "Hut", "sich", "um", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PRF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "oh.", "tokens": ["oh", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+", "measure": "single.up"}}, "stanza.16": {"line.1": {"text": "Oh, sprach Detta, sei doch dut!", "tokens": ["Oh", ",", "sprach", "Det\u00b7ta", ",", "sei", "doch", "dut", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "NE", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "willst du einen neuen Hut?", "tokens": ["willst", "du", "ei\u00b7nen", "neu\u00b7en", "Hut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tlinglingling: wer b'ingt das Band?", "tokens": ["Tling\u00b7ling\u00b7ling", ":", "wer", "ing", "das", "Band", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nigin aus Mohrenland!", "tokens": ["K\u00f6\u00b7ni\u00b7gin", "aus", "Moh\u00b7ren\u00b7land", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "tnicks!", "tokens": ["tnicks", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-", "measure": "single.down"}}, "stanza.17": {"line.1": {"text": "Tnix, ich bin F'au T\u00f6nidin,", "tokens": ["Tnix", ",", "ich", "bin", "F'\u00b7au", "T\u00f6\u00b7ni\u00b7din", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "NE", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "hab zvei Lippen von Zutterrosin;", "tokens": ["hab", "zvei", "Lip\u00b7pen", "von", "Zut\u00b7ter\u00b7ro\u00b7sin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "APPR", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Fitzebutze, sieh mal an,", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "sieh", "mal", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ei, wie Detta tanzen tann,", "tokens": ["ei", ",", "wie", "Det\u00b7ta", "tan\u00b7zen", "tann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "NE", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "hopp\u00df!", "tokens": ["hopp\u00df", "!"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}}, "stanza.18": {"line.1": {"text": "Hop\u00dfa, hop\u00dfa, hop\u00dfassa:", "tokens": ["Hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfas\u00b7sa", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "FM.la", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "T\u00f6nigin von Af'ika!", "tokens": ["T\u00f6\u00b7ni\u00b7gin", "von", "Af'\u00b7i\u00b7ka", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flitzeputzig, Butzebein,", "tokens": ["Flit\u00b7ze\u00b7put\u00b7zig", ",", "But\u00b7ze\u00b7bein", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wann soll unse Hochzeit sein?", "tokens": ["wann", "soll", "un\u00b7se", "Hoch\u00b7zeit", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "na? \u2013", "tokens": ["na", "?", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ITJ", "$.", "$("], "meter": "O", "measure": "unknown.measure.zero"}}, "stanza.19": {"line.1": {"text": "Na, was meint ihr, was geschah?", "tokens": ["Na", ",", "was", "meint", "ihr", ",", "was", "ge\u00b7schah", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "VVFIN", "PPER", "$,", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er sa\u00df stumm wie immer da.", "tokens": ["Er", "sa\u00df", "stumm", "wie", "im\u00b7mer", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KOKOM", "ADV", "ADV", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Immer stumm auf seinem Platz", "tokens": ["Im\u00b7mer", "stumm", "auf", "sei\u00b7nem", "Platz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "sa\u00df der alte Hampelmatz,", "tokens": ["sa\u00df", "der", "al\u00b7te", "Ham\u00b7pel\u00b7matz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "huh.", "tokens": ["huh", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+", "measure": "single.up"}}, "stanza.20": {"line.1": {"text": "Huh, er hatte keinen Mut,", "tokens": ["Huh", ",", "er", "hat\u00b7te", "kei\u00b7nen", "Mut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wollte keinen neuen Hut.", "tokens": ["woll\u00b7te", "kei\u00b7nen", "neu\u00b7en", "Hut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da schmi\u00df Detta ihn vom Stuhl:", "tokens": ["Da", "schmi\u00df", "Det\u00b7ta", "ihn", "vom", "Stuhl", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PPER", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Ach, du dummer Blitzepul,", "tokens": ["Ach", ",", "du", "dum\u00b7mer", "Blit\u00b7ze\u00b7pul", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "marsch! \u2013", "tokens": ["marsch", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["ADJD", "$.", "$("], "meter": "-", "measure": "single.down"}}}}}