{"textgrid.poem.42976": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Abermals in Zwickau", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Rings um das Zwickauer Krankenstift", "tokens": ["Rings", "um", "das", "Zwi\u00b7ck\u00b7au\u00b7er", "Kran\u00b7ken\u00b7stift"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Torkeln im Schnee fette Raben,", "tokens": ["Tor\u00b7keln", "im", "Schnee", "fet\u00b7te", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Die wissen nicht, was Pulver und Gift", "tokens": ["Die", "wis\u00b7sen", "nicht", ",", "was", "Pul\u00b7ver", "und", "Gift"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PTKNEG", "$,", "PWS", "NN", "KON", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ist und wie gut sie es haben.", "tokens": ["Ist", "und", "wie", "gut", "sie", "es", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "PWAV", "ADJD", "PPER", "PPER", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Es geht modern und freundlich zu", "tokens": ["Es", "geht", "mo\u00b7dern", "und", "freund\u00b7lich", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "PTKZU"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In den sauberen Krankenstationen.", "tokens": ["In", "den", "sau\u00b7be\u00b7ren", "Kran\u00b7ken\u00b7sta\u00b7ti\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ich m\u00f6chte gern einmal in Ruh", "tokens": ["Ich", "m\u00f6ch\u00b7te", "gern", "ein\u00b7mal", "in", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dort ein, zwei Jahre wohnen.", "tokens": ["Dort", "ein", ",", "zwei", "Jah\u00b7re", "woh\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wenn das verdammte Kranksein nicht war,", "tokens": ["Wenn", "das", "ver\u00b7damm\u00b7te", "Krank\u00b7sein", "nicht", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKNEG", "VAFIN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Das die zum Eintritt verlangen!", "tokens": ["Das", "die", "zum", "Ein\u00b7tritt", "ver\u00b7lan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "(dann wird man zwar wie ein Teddyb\u00e4r", "tokens": ["(", "dann", "wird", "man", "zwar", "wie", "ein", "Ted\u00b7dy\u00b7b\u00e4r"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PIS", "ADV", "KOKOM", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von \u00c4rzten und Schwestern empfangen.)", "tokens": ["Von", "\u00c4rz\u00b7ten", "und", "Schwes\u00b7tern", "emp\u00b7fan\u00b7gen", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Ich denke mir: Sie sterben nie \u2013", "tokens": ["Ich", "den\u00b7ke", "mir", ":", "Sie", "ster\u00b7ben", "nie", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die au\u00dferhalb \u2013 die Raben \u2013", "tokens": ["Die", "au\u00b7\u00dfer\u00b7halb", "\u2013", "die", "Ra\u00b7ben", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "$(", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sind wohl auch nur Kr\u00e4hen, die", "tokens": ["Und", "sind", "wohl", "auch", "nur", "Kr\u00e4\u00b7hen", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADV", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was gegen Zwickau haben.", "tokens": ["Was", "ge\u00b7gen", "Zwi\u00b7ckau", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NE", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Weil sie mit ihrem gro\u00dfen Blick", "tokens": ["Weil", "sie", "mit", "ih\u00b7rem", "gro\u00b7\u00dfen", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So hell und weitaus sp\u00e4hen. \u2013", "tokens": ["So", "hell", "und", "weit\u00b7aus", "sp\u00e4\u00b7hen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein neuer Eindruck hier in Zwick.", "tokens": ["Ein", "neu\u00b7er", "Ein\u00b7druck", "hier", "in", "Zwick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Prost, \u00c4rzte! und prost, Kr\u00e4hen!", "tokens": ["Prost", ",", "\u00c4rz\u00b7te", "!", "und", "prost", ",", "Kr\u00e4\u00b7hen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "KON", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Rings um das Zwickauer Krankenstift", "tokens": ["Rings", "um", "das", "Zwi\u00b7ck\u00b7au\u00b7er", "Kran\u00b7ken\u00b7stift"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Torkeln im Schnee fette Raben,", "tokens": ["Tor\u00b7keln", "im", "Schnee", "fet\u00b7te", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Die wissen nicht, was Pulver und Gift", "tokens": ["Die", "wis\u00b7sen", "nicht", ",", "was", "Pul\u00b7ver", "und", "Gift"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PTKNEG", "$,", "PWS", "NN", "KON", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ist und wie gut sie es haben.", "tokens": ["Ist", "und", "wie", "gut", "sie", "es", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "PWAV", "ADJD", "PPER", "PPER", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Es geht modern und freundlich zu", "tokens": ["Es", "geht", "mo\u00b7dern", "und", "freund\u00b7lich", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "PTKZU"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In den sauberen Krankenstationen.", "tokens": ["In", "den", "sau\u00b7be\u00b7ren", "Kran\u00b7ken\u00b7sta\u00b7ti\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ich m\u00f6chte gern einmal in Ruh", "tokens": ["Ich", "m\u00f6ch\u00b7te", "gern", "ein\u00b7mal", "in", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dort ein, zwei Jahre wohnen.", "tokens": ["Dort", "ein", ",", "zwei", "Jah\u00b7re", "woh\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wenn das verdammte Kranksein nicht war,", "tokens": ["Wenn", "das", "ver\u00b7damm\u00b7te", "Krank\u00b7sein", "nicht", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKNEG", "VAFIN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Das die zum Eintritt verlangen!", "tokens": ["Das", "die", "zum", "Ein\u00b7tritt", "ver\u00b7lan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "(dann wird man zwar wie ein Teddyb\u00e4r", "tokens": ["(", "dann", "wird", "man", "zwar", "wie", "ein", "Ted\u00b7dy\u00b7b\u00e4r"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PIS", "ADV", "KOKOM", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von \u00c4rzten und Schwestern empfangen.)", "tokens": ["Von", "\u00c4rz\u00b7ten", "und", "Schwes\u00b7tern", "emp\u00b7fan\u00b7gen", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.9": {"line.1": {"text": "Ich denke mir: Sie sterben nie \u2013", "tokens": ["Ich", "den\u00b7ke", "mir", ":", "Sie", "ster\u00b7ben", "nie", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die au\u00dferhalb \u2013 die Raben \u2013", "tokens": ["Die", "au\u00b7\u00dfer\u00b7halb", "\u2013", "die", "Ra\u00b7ben", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "$(", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sind wohl auch nur Kr\u00e4hen, die", "tokens": ["Und", "sind", "wohl", "auch", "nur", "Kr\u00e4\u00b7hen", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADV", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was gegen Zwickau haben.", "tokens": ["Was", "ge\u00b7gen", "Zwi\u00b7ckau", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NE", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Weil sie mit ihrem gro\u00dfen Blick", "tokens": ["Weil", "sie", "mit", "ih\u00b7rem", "gro\u00b7\u00dfen", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So hell und weitaus sp\u00e4hen. \u2013", "tokens": ["So", "hell", "und", "weit\u00b7aus", "sp\u00e4\u00b7hen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein neuer Eindruck hier in Zwick.", "tokens": ["Ein", "neu\u00b7er", "Ein\u00b7druck", "hier", "in", "Zwick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Prost, \u00c4rzte! und prost, Kr\u00e4hen!", "tokens": ["Prost", ",", "\u00c4rz\u00b7te", "!", "und", "prost", ",", "Kr\u00e4\u00b7hen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "KON", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}