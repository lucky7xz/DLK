{"textgrid.poem.57721": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Erinnerung", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Heut' ist der erste Dezembertag,", "tokens": ["Heut'", "ist", "der", "ers\u00b7te", "De\u00b7zem\u00b7ber\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+--+----+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da ist das Herz uns schwer,", "tokens": ["Da", "ist", "das", "Herz", "uns", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich seh' noch, wie er vor mir lag,", "tokens": ["Ich", "seh'", "noch", ",", "wie", "er", "vor", "mir", "lag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind's auch schon Jahre her.", "tokens": ["Sin\u00b7d's", "auch", "schon", "Jah\u00b7re", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Am ersten Dezember vor sieben Jahr", "tokens": ["Am", "ers\u00b7ten", "De\u00b7zem\u00b7ber", "vor", "sie\u00b7ben", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Schien auch die Sonne so blank,", "tokens": ["Schien", "auch", "die", "Son\u00b7ne", "so", "blank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Und als der Tag zu Ende war,", "tokens": ["Und", "als", "der", "Tag", "zu", "En\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Totenglocke klang.", "tokens": ["Die", "To\u00b7ten\u00b7glo\u00b7cke", "klang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wir gingen zu Holze bei halber Nacht,", "tokens": ["Wir", "gin\u00b7gen", "zu", "Hol\u00b7ze", "bei", "hal\u00b7ber", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Schnee war hell und hart,", "tokens": ["Der", "Schnee", "war", "hell", "und", "hart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Himmel stand in Sternenpracht,", "tokens": ["Der", "Him\u00b7mel", "stand", "in", "Ster\u00b7nen\u00b7pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Uns fror der Hauch im Bart.", "tokens": ["Uns", "fror", "der", "Hauch", "im", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wir gingen nebeneinander her,", "tokens": ["Wir", "gin\u00b7gen", "ne\u00b7ben\u00b7ein\u00b7an\u00b7der", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Seine Augen waren weit fort,", "tokens": ["Sei\u00b7ne", "Au\u00b7gen", "wa\u00b7ren", "weit", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sein Atem ging so tief und schwer,", "tokens": ["Sein", "A\u00b7tem", "ging", "so", "tief", "und", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er sprach kein einziges Wort.", "tokens": ["Er", "sprach", "kein", "ein\u00b7zi\u00b7ges", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Und als wir kamen auf das Hai,", "tokens": ["Und", "als", "wir", "ka\u00b7men", "auf", "das", "Hai", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sagte er: \u00bbJohann,", "tokens": ["Da", "sag\u00b7te", "er", ":", "\u00bb", "Jo\u00b7hann", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mir ist so eigen, Junge, sei", "tokens": ["Mir", "ist", "so", "ei\u00b7gen", ",", "Jun\u00b7ge", ",", "sei"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "NN", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meiner Schwester ein guter Mann!\u00ab", "tokens": ["Mei\u00b7ner", "Schwes\u00b7ter", "ein", "gu\u00b7ter", "Mann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.6": {"line.1": {"text": "Er setzte die S\u00e4ge an den Baum,", "tokens": ["Er", "setz\u00b7te", "die", "S\u00e4\u00b7ge", "an", "den", "Baum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Am anderen Ende ich stand;", "tokens": ["Am", "an\u00b7de\u00b7ren", "En\u00b7de", "ich", "stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Seine Augen waren wie im Traum,", "tokens": ["Sei\u00b7ne", "Au\u00b7gen", "wa\u00b7ren", "wie", "im", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ich hatt' ihn noch nie so gekannt.", "tokens": ["Ich", "hatt'", "ihn", "noch", "nie", "so", "ge\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.7": {"line.1": {"text": "Sonst sah man die Z\u00e4hne in seinem Mund,", "tokens": ["Sonst", "sah", "man", "die", "Z\u00e4h\u00b7ne", "in", "sei\u00b7nem", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Den Tag, da sah man sie nicht;", "tokens": ["Den", "Tag", ",", "da", "sah", "man", "sie", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "VVFIN", "PIS", "PPER", "PTKNEG", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sonst war so fr\u00f6hlich und so rund,", "tokens": ["Sonst", "war", "so", "fr\u00f6h\u00b7lich", "und", "so", "rund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun ernst und lang sein Gesicht.", "tokens": ["Nun", "ernst", "und", "lang", "sein", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Wir nahmen die Axt, der Doppelklang", "tokens": ["Wir", "nah\u00b7men", "die", "Axt", ",", "der", "Dop\u00b7pel\u00b7klang"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schallte hell und klar;", "tokens": ["Schall\u00b7te", "hell", "und", "klar", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Das Echo aus dem Felsen sprang,", "tokens": ["Das", "E\u00b7cho", "aus", "dem", "Fel\u00b7sen", "sprang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz wie sonst es war.", "tokens": ["Ganz", "wie", "sonst", "es", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "PPER", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Es gab einen Krach und gab einen Schrei,", "tokens": ["Es", "gab", "ei\u00b7nen", "Krach", "und", "gab", "ei\u00b7nen", "Schrei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Falsch fiel der Buchenbaum;", "tokens": ["Falsch", "fiel", "der", "Bu\u00b7chen\u00b7baum", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er fiel auf ihn: \u00bbEs ist vorbei,\u00ab", "tokens": ["Er", "fiel", "auf", "ihn", ":", "\u00bb", "Es", "ist", "vor\u00b7bei", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$.", "$(", "PPER", "VAFIN", "ADV", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sprach er, den Mund voll Schaum.", "tokens": ["Sprach", "er", ",", "den", "Mund", "voll", "Schaum", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Ich sprach f\u00fcr ihn ein kurzes Gebet,", "tokens": ["Ich", "sprach", "f\u00fcr", "ihn", "ein", "kur\u00b7zes", "Ge\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df leicht ihm die Erde sei;", "tokens": ["Da\u00df", "leicht", "ihm", "die", "Er\u00b7de", "sei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Im Dorfe hat ein Hahn gekr\u00e4ht,", "tokens": ["Im", "Dor\u00b7fe", "hat", "ein", "Hahn", "ge\u00b7kr\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es war wie ein Jammerschrei.", "tokens": ["Es", "war", "wie", "ein", "Jam\u00b7mer\u00b7schrei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Der Oberholzhauer trat heran", "tokens": ["Der", "O\u00b7berh\u00b7olz\u00b7hau\u00b7er", "trat", "he\u00b7ran"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und deckte ihm zu das Gesicht,", "tokens": ["Und", "deck\u00b7te", "ihm", "zu", "das", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sprach: \u00bbNun sagt es dem F\u00f6rster an!", "tokens": ["Und", "sprach", ":", "\u00bb", "Nun", "sagt", "es", "dem", "F\u00f6rs\u00b7ter", "an", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "F\u00fcr heute machen wir Schicht.\u00ab", "tokens": ["F\u00fcr", "heu\u00b7te", "ma\u00b7chen", "wir", "Schicht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "Komm', Frau, und la\u00df die Arbeit stehn,", "tokens": ["Komm'", ",", "Frau", ",", "und", "la\u00df", "die", "Ar\u00b7beit", "stehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "KON", "VVIMP", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zieh' an dein Kirchenkleid;", "tokens": ["Zieh'", "an", "dein", "Kir\u00b7chen\u00b7kleid", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir wollen zu seinem Grabe gehn,", "tokens": ["Wir", "wol\u00b7len", "zu", "sei\u00b7nem", "Gra\u00b7be", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es ist seine Sterbezeit.", "tokens": ["Es", "ist", "sei\u00b7ne", "Ster\u00b7be\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Heut' ist der erste Dezembertag,", "tokens": ["Heut'", "ist", "der", "ers\u00b7te", "De\u00b7zem\u00b7ber\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+--+----+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da ist das Herz uns schwer,", "tokens": ["Da", "ist", "das", "Herz", "uns", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich seh' noch, wie er vor mir lag,", "tokens": ["Ich", "seh'", "noch", ",", "wie", "er", "vor", "mir", "lag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind's auch schon Jahre her.", "tokens": ["Sin\u00b7d's", "auch", "schon", "Jah\u00b7re", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Am ersten Dezember vor sieben Jahr", "tokens": ["Am", "ers\u00b7ten", "De\u00b7zem\u00b7ber", "vor", "sie\u00b7ben", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Schien auch die Sonne so blank,", "tokens": ["Schien", "auch", "die", "Son\u00b7ne", "so", "blank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Und als der Tag zu Ende war,", "tokens": ["Und", "als", "der", "Tag", "zu", "En\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Totenglocke klang.", "tokens": ["Die", "To\u00b7ten\u00b7glo\u00b7cke", "klang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wir gingen zu Holze bei halber Nacht,", "tokens": ["Wir", "gin\u00b7gen", "zu", "Hol\u00b7ze", "bei", "hal\u00b7ber", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Schnee war hell und hart,", "tokens": ["Der", "Schnee", "war", "hell", "und", "hart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Himmel stand in Sternenpracht,", "tokens": ["Der", "Him\u00b7mel", "stand", "in", "Ster\u00b7nen\u00b7pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Uns fror der Hauch im Bart.", "tokens": ["Uns", "fror", "der", "Hauch", "im", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Wir gingen nebeneinander her,", "tokens": ["Wir", "gin\u00b7gen", "ne\u00b7ben\u00b7ein\u00b7an\u00b7der", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Seine Augen waren weit fort,", "tokens": ["Sei\u00b7ne", "Au\u00b7gen", "wa\u00b7ren", "weit", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sein Atem ging so tief und schwer,", "tokens": ["Sein", "A\u00b7tem", "ging", "so", "tief", "und", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er sprach kein einziges Wort.", "tokens": ["Er", "sprach", "kein", "ein\u00b7zi\u00b7ges", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Und als wir kamen auf das Hai,", "tokens": ["Und", "als", "wir", "ka\u00b7men", "auf", "das", "Hai", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sagte er: \u00bbJohann,", "tokens": ["Da", "sag\u00b7te", "er", ":", "\u00bb", "Jo\u00b7hann", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mir ist so eigen, Junge, sei", "tokens": ["Mir", "ist", "so", "ei\u00b7gen", ",", "Jun\u00b7ge", ",", "sei"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "NN", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meiner Schwester ein guter Mann!\u00ab", "tokens": ["Mei\u00b7ner", "Schwes\u00b7ter", "ein", "gu\u00b7ter", "Mann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.18": {"line.1": {"text": "Er setzte die S\u00e4ge an den Baum,", "tokens": ["Er", "setz\u00b7te", "die", "S\u00e4\u00b7ge", "an", "den", "Baum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Am anderen Ende ich stand;", "tokens": ["Am", "an\u00b7de\u00b7ren", "En\u00b7de", "ich", "stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Seine Augen waren wie im Traum,", "tokens": ["Sei\u00b7ne", "Au\u00b7gen", "wa\u00b7ren", "wie", "im", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ich hatt' ihn noch nie so gekannt.", "tokens": ["Ich", "hatt'", "ihn", "noch", "nie", "so", "ge\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.19": {"line.1": {"text": "Sonst sah man die Z\u00e4hne in seinem Mund,", "tokens": ["Sonst", "sah", "man", "die", "Z\u00e4h\u00b7ne", "in", "sei\u00b7nem", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Den Tag, da sah man sie nicht;", "tokens": ["Den", "Tag", ",", "da", "sah", "man", "sie", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "VVFIN", "PIS", "PPER", "PTKNEG", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sonst war so fr\u00f6hlich und so rund,", "tokens": ["Sonst", "war", "so", "fr\u00f6h\u00b7lich", "und", "so", "rund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun ernst und lang sein Gesicht.", "tokens": ["Nun", "ernst", "und", "lang", "sein", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.20": {"line.1": {"text": "Wir nahmen die Axt, der Doppelklang", "tokens": ["Wir", "nah\u00b7men", "die", "Axt", ",", "der", "Dop\u00b7pel\u00b7klang"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schallte hell und klar;", "tokens": ["Schall\u00b7te", "hell", "und", "klar", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Das Echo aus dem Felsen sprang,", "tokens": ["Das", "E\u00b7cho", "aus", "dem", "Fel\u00b7sen", "sprang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz wie sonst es war.", "tokens": ["Ganz", "wie", "sonst", "es", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "PPER", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Es gab einen Krach und gab einen Schrei,", "tokens": ["Es", "gab", "ei\u00b7nen", "Krach", "und", "gab", "ei\u00b7nen", "Schrei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Falsch fiel der Buchenbaum;", "tokens": ["Falsch", "fiel", "der", "Bu\u00b7chen\u00b7baum", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er fiel auf ihn: \u00bbEs ist vorbei,\u00ab", "tokens": ["Er", "fiel", "auf", "ihn", ":", "\u00bb", "Es", "ist", "vor\u00b7bei", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$.", "$(", "PPER", "VAFIN", "ADV", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sprach er, den Mund voll Schaum.", "tokens": ["Sprach", "er", ",", "den", "Mund", "voll", "Schaum", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Ich sprach f\u00fcr ihn ein kurzes Gebet,", "tokens": ["Ich", "sprach", "f\u00fcr", "ihn", "ein", "kur\u00b7zes", "Ge\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df leicht ihm die Erde sei;", "tokens": ["Da\u00df", "leicht", "ihm", "die", "Er\u00b7de", "sei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Im Dorfe hat ein Hahn gekr\u00e4ht,", "tokens": ["Im", "Dor\u00b7fe", "hat", "ein", "Hahn", "ge\u00b7kr\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es war wie ein Jammerschrei.", "tokens": ["Es", "war", "wie", "ein", "Jam\u00b7mer\u00b7schrei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.23": {"line.1": {"text": "Der Oberholzhauer trat heran", "tokens": ["Der", "O\u00b7berh\u00b7olz\u00b7hau\u00b7er", "trat", "he\u00b7ran"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und deckte ihm zu das Gesicht,", "tokens": ["Und", "deck\u00b7te", "ihm", "zu", "das", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sprach: \u00bbNun sagt es dem F\u00f6rster an!", "tokens": ["Und", "sprach", ":", "\u00bb", "Nun", "sagt", "es", "dem", "F\u00f6rs\u00b7ter", "an", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "F\u00fcr heute machen wir Schicht.\u00ab", "tokens": ["F\u00fcr", "heu\u00b7te", "ma\u00b7chen", "wir", "Schicht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.24": {"line.1": {"text": "Komm', Frau, und la\u00df die Arbeit stehn,", "tokens": ["Komm'", ",", "Frau", ",", "und", "la\u00df", "die", "Ar\u00b7beit", "stehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "KON", "VVIMP", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zieh' an dein Kirchenkleid;", "tokens": ["Zieh'", "an", "dein", "Kir\u00b7chen\u00b7kleid", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir wollen zu seinem Grabe gehn,", "tokens": ["Wir", "wol\u00b7len", "zu", "sei\u00b7nem", "Gra\u00b7be", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es ist seine Sterbezeit.", "tokens": ["Es", "ist", "sei\u00b7ne", "Ster\u00b7be\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}