{"textgrid.poem.42345": {"metadata": {"author": {"name": "Lachmann, Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was ist's nun, was uns unser Schicksal lehrt?", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was ist's nun, was uns unser Schicksal lehrt?", "tokens": ["Was", "ist's", "nun", ",", "was", "uns", "un\u00b7ser", "Schick\u00b7sal", "lehrt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist es ein h\u00f6hrer Ernst, ein tiefrer Sinn?", "tokens": ["Ist", "es", "ein", "h\u00f6h\u00b7rer", "Ernst", ",", "ein", "tief\u00b7rer", "Sinn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist es ein vordem ungekannter Wert,", "tokens": ["Ist", "es", "ein", "vor\u00b7dem", "un\u00b7ge\u00b7kann\u00b7ter", "Wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ein neuerrungner innerer Gewinn?", "tokens": ["Ein", "neu\u00b7er\u00b7rung\u00b7ner", "in\u00b7ne\u00b7rer", "Ge\u00b7winn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ist es das Hochgef\u00fchl gest\u00e4hlter Kraft,", "tokens": ["Ist", "es", "das", "Hoch\u00b7ge\u00b7f\u00fchl", "ge\u00b7st\u00e4hl\u00b7ter", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die sich im Kampf erprobte und bemass,", "tokens": ["Die", "sich", "im", "Kampf", "er\u00b7prob\u00b7te", "und", "be\u00b7mass", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein \u00dcberquellen finstrer Leidenschaft,", "tokens": ["Ein", "\u00dc\u00b7berq\u00b7uel\u00b7len", "finst\u00b7rer", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Gezeugt in Liebe und gen\u00e4hrt an Hass?", "tokens": ["Ge\u00b7zeugt", "in", "Lie\u00b7be", "und", "ge\u00b7n\u00e4hrt", "an", "Hass", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "VVPP", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Oder \u2013 mein Gott \u2013 ist es nur fr\u00fch und sp\u00e4t", "tokens": ["O\u00b7der", "\u2013", "mein", "Gott", "\u2013", "ist", "es", "nur", "fr\u00fch", "und", "sp\u00e4t"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "PPOSAT", "NN", "$(", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Ein dumpfes Wehren gegen dumpfre Not \u2013", "tokens": ["Ein", "dum\u00b7pfes", "Weh\u00b7ren", "ge\u00b7gen", "dum\u00b7pf\u00b7re", "Not", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Auf vielen tausend Lippen das Gebet:", "tokens": ["Auf", "vie\u00b7len", "tau\u00b7send", "Lip\u00b7pen", "das", "Ge\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "CARD", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u00bbgib uns, o Vater, unser t\u00e4glich Brot!\u00ab", "tokens": ["\u00bb", "gib", "uns", ",", "o", "Va\u00b7ter", ",", "un\u00b7ser", "t\u00e4g\u00b7lich", "Brot", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "FM", "NN", "$,", "PPOSAT", "ADJD", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Was ist's nun, was uns unser Schicksal lehrt?", "tokens": ["Was", "ist's", "nun", ",", "was", "uns", "un\u00b7ser", "Schick\u00b7sal", "lehrt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist es ein h\u00f6hrer Ernst, ein tiefrer Sinn?", "tokens": ["Ist", "es", "ein", "h\u00f6h\u00b7rer", "Ernst", ",", "ein", "tief\u00b7rer", "Sinn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist es ein vordem ungekannter Wert,", "tokens": ["Ist", "es", "ein", "vor\u00b7dem", "un\u00b7ge\u00b7kann\u00b7ter", "Wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ein neuerrungner innerer Gewinn?", "tokens": ["Ein", "neu\u00b7er\u00b7rung\u00b7ner", "in\u00b7ne\u00b7rer", "Ge\u00b7winn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ist es das Hochgef\u00fchl gest\u00e4hlter Kraft,", "tokens": ["Ist", "es", "das", "Hoch\u00b7ge\u00b7f\u00fchl", "ge\u00b7st\u00e4hl\u00b7ter", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die sich im Kampf erprobte und bemass,", "tokens": ["Die", "sich", "im", "Kampf", "er\u00b7prob\u00b7te", "und", "be\u00b7mass", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein \u00dcberquellen finstrer Leidenschaft,", "tokens": ["Ein", "\u00dc\u00b7berq\u00b7uel\u00b7len", "finst\u00b7rer", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Gezeugt in Liebe und gen\u00e4hrt an Hass?", "tokens": ["Ge\u00b7zeugt", "in", "Lie\u00b7be", "und", "ge\u00b7n\u00e4hrt", "an", "Hass", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "VVPP", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Oder \u2013 mein Gott \u2013 ist es nur fr\u00fch und sp\u00e4t", "tokens": ["O\u00b7der", "\u2013", "mein", "Gott", "\u2013", "ist", "es", "nur", "fr\u00fch", "und", "sp\u00e4t"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "PPOSAT", "NN", "$(", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Ein dumpfes Wehren gegen dumpfre Not \u2013", "tokens": ["Ein", "dum\u00b7pfes", "Weh\u00b7ren", "ge\u00b7gen", "dum\u00b7pf\u00b7re", "Not", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Auf vielen tausend Lippen das Gebet:", "tokens": ["Auf", "vie\u00b7len", "tau\u00b7send", "Lip\u00b7pen", "das", "Ge\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "CARD", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u00bbgib uns, o Vater, unser t\u00e4glich Brot!\u00ab", "tokens": ["\u00bb", "gib", "uns", ",", "o", "Va\u00b7ter", ",", "un\u00b7ser", "t\u00e4g\u00b7lich", "Brot", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "FM", "NN", "$,", "PPOSAT", "ADJD", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}