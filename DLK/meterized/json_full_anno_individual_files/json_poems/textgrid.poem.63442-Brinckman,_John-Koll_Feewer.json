{"textgrid.poem.63442": {"metadata": {"author": {"name": "Brinckman, John", "birth": "N.A.", "death": "N.A."}, "title": "Koll Feewer", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du b\u00fcst denn rein so geestlich, Jung,", "tokens": ["Du", "b\u00fcst", "denn", "rein", "so", "geest\u00b7lich", ",", "Jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "ADV", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "so leg un so elenn,", "tokens": ["so", "leg", "un", "so", "e\u00b7lenn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "FM", "ADV", "ADJD", "$,"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "as wir din Kopp 'ne M\u00f6llerpung,", "tokens": ["as", "wir", "din", "Kopp", "'ne", "M\u00f6l\u00b7ler\u00b7pung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "as Gosdreck an't witt Enn.", "tokens": ["as", "Gos\u00b7dreck", "an't", "witt", "Enn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VVFIN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "As wenn dat Brot nich satt du kregst,", "tokens": ["As", "wenn", "dat", "Brot", "nich", "satt", "du", "kregst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ART", "NN", "PTKNEG", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "so pewrig b\u00fcst un k\u00fcm;", "tokens": ["so", "pew\u00b7rig", "b\u00fcst", "un", "k\u00fcm", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "FM", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "as wenn nich dr\u00f6g un natt du kregst", "tokens": ["as", "wenn", "nich", "dr\u00f6g", "un", "natt", "du", "kregst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "PTKNEG", "ADV", "FM", "FM", "PPER", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "un wu\u00dft noch ganz ut'n Lim.", "tokens": ["un", "wu\u00dft", "noch", "ganz", "ut'n", "Lim", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "ADV", "ADV", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Din Witt in't Og is quitteng\u00e4l,", "tokens": ["Din", "Witt", "in't", "Og", "is", "quit\u00b7ten\u00b7g\u00e4l", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "din Mul as 'ne Kreek so blag;", "tokens": ["din", "Mul", "as", "'ne", "Kreek", "so", "blag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "du warst so dr\u00f6g as'n Bessenst\u00e4l", "tokens": ["du", "warst", "so", "dr\u00f6g", "as'n", "Bes\u00b7sen\u00b7st\u00e4l"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "un wirst doch s\u00fcs so tag.", "tokens": ["un", "wirst", "doch", "s\u00fcs", "so", "tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VAFIN", "ADV", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Du sn\u00fcffst un qu\u00fcchst, as haddst'n Kropp,", "tokens": ["Du", "sn\u00fcffst", "un", "qu\u00fcchst", ",", "as", "haddst'n", "Kropp", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "FM", "FM", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "as \u0153wergoren Gest \u2013", "tokens": ["as", "\u0153wer\u00b7go\u00b7ren", "Gest", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "wat b\u00fcst f\u00f6r'n ollen Quesenkopp,", "tokens": ["wat", "b\u00fcst", "f\u00f6r'n", "ol\u00b7len", "Que\u00b7sen\u00b7kopp", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dat du sonn Grappen hest!", "tokens": ["dat", "du", "sonn", "Grap\u00b7pen", "hest", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Dat's nu glik an dree Mand all ran,", "tokens": ["Dat's", "nu", "glik", "an", "dree", "Mand", "all", "ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "APPR", "CARD", "NN", "PIAT", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du sl\u00e4pst di man so hen;", "tokens": ["du", "sl\u00e4pst", "di", "man", "so", "hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "un bi di sleiht rein gor nicks an,", "tokens": ["un", "bi", "di", "sleiht", "rein", "gor", "nicks", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "keen Afschrift un keen Spenn.", "tokens": ["ke\u00b7en", "Af\u00b7schrift", "un", "ke\u00b7en", "Spenn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "FM", "VVFIN", "NE", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Wat, Bengel, nimm di doch tosam!", "tokens": ["Wat", ",", "Ben\u00b7gel", ",", "nimm", "di", "doch", "to\u00b7sam", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VVIMP", "NE", "ADV", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Du sleihst jo ganz ute Ort \u2013", "tokens": ["Du", "sleihst", "jo", "ganz", "u\u00b7te", "Ort", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "s\u00fch, Jung, ick lat den Dokter kam',", "tokens": ["s\u00fch", ",", "Jung", ",", "ick", "lat", "den", "Dok\u00b7ter", "kam'", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wenn mi dat lang noch wohrt!", "tokens": ["wenn", "mi", "dat", "lang", "noch", "wohrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "ADJD", "ADV", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.7": {"line.1": {"text": "Du b\u00fcst denn rein so geestlich, Jung,", "tokens": ["Du", "b\u00fcst", "denn", "rein", "so", "geest\u00b7lich", ",", "Jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "ADV", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "so leg un so elenn,", "tokens": ["so", "leg", "un", "so", "e\u00b7lenn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "FM", "ADV", "ADJD", "$,"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "as wir din Kopp 'ne M\u00f6llerpung,", "tokens": ["as", "wir", "din", "Kopp", "'ne", "M\u00f6l\u00b7ler\u00b7pung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "as Gosdreck an't witt Enn.", "tokens": ["as", "Gos\u00b7dreck", "an't", "witt", "Enn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VVFIN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "As wenn dat Brot nich satt du kregst,", "tokens": ["As", "wenn", "dat", "Brot", "nich", "satt", "du", "kregst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ART", "NN", "PTKNEG", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "so pewrig b\u00fcst un k\u00fcm;", "tokens": ["so", "pew\u00b7rig", "b\u00fcst", "un", "k\u00fcm", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "FM", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "as wenn nich dr\u00f6g un natt du kregst", "tokens": ["as", "wenn", "nich", "dr\u00f6g", "un", "natt", "du", "kregst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "PTKNEG", "ADV", "FM", "FM", "PPER", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "un wu\u00dft noch ganz ut'n Lim.", "tokens": ["un", "wu\u00dft", "noch", "ganz", "ut'n", "Lim", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "ADV", "ADV", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Din Witt in't Og is quitteng\u00e4l,", "tokens": ["Din", "Witt", "in't", "Og", "is", "quit\u00b7ten\u00b7g\u00e4l", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "din Mul as 'ne Kreek so blag;", "tokens": ["din", "Mul", "as", "'ne", "Kreek", "so", "blag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "du warst so dr\u00f6g as'n Bessenst\u00e4l", "tokens": ["du", "warst", "so", "dr\u00f6g", "as'n", "Bes\u00b7sen\u00b7st\u00e4l"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "un wirst doch s\u00fcs so tag.", "tokens": ["un", "wirst", "doch", "s\u00fcs", "so", "tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VAFIN", "ADV", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Du sn\u00fcffst un qu\u00fcchst, as haddst'n Kropp,", "tokens": ["Du", "sn\u00fcffst", "un", "qu\u00fcchst", ",", "as", "haddst'n", "Kropp", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "FM", "FM", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "as \u0153wergoren Gest \u2013", "tokens": ["as", "\u0153wer\u00b7go\u00b7ren", "Gest", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "wat b\u00fcst f\u00f6r'n ollen Quesenkopp,", "tokens": ["wat", "b\u00fcst", "f\u00f6r'n", "ol\u00b7len", "Que\u00b7sen\u00b7kopp", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dat du sonn Grappen hest!", "tokens": ["dat", "du", "sonn", "Grap\u00b7pen", "hest", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Dat's nu glik an dree Mand all ran,", "tokens": ["Dat's", "nu", "glik", "an", "dree", "Mand", "all", "ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "APPR", "CARD", "NN", "PIAT", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du sl\u00e4pst di man so hen;", "tokens": ["du", "sl\u00e4pst", "di", "man", "so", "hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "un bi di sleiht rein gor nicks an,", "tokens": ["un", "bi", "di", "sleiht", "rein", "gor", "nicks", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "keen Afschrift un keen Spenn.", "tokens": ["ke\u00b7en", "Af\u00b7schrift", "un", "ke\u00b7en", "Spenn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "FM", "VVFIN", "NE", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "Wat, Bengel, nimm di doch tosam!", "tokens": ["Wat", ",", "Ben\u00b7gel", ",", "nimm", "di", "doch", "to\u00b7sam", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VVIMP", "NE", "ADV", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Du sleihst jo ganz ute Ort \u2013", "tokens": ["Du", "sleihst", "jo", "ganz", "u\u00b7te", "Ort", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "s\u00fch, Jung, ick lat den Dokter kam',", "tokens": ["s\u00fch", ",", "Jung", ",", "ick", "lat", "den", "Dok\u00b7ter", "kam'", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wenn mi dat lang noch wohrt!", "tokens": ["wenn", "mi", "dat", "lang", "noch", "wohrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "ADJD", "ADV", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}}}}