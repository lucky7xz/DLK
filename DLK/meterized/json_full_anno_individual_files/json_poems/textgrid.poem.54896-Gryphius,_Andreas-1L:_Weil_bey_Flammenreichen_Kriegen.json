{"textgrid.poem.54896": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "1L: Weil bey Flammenreichen Kriegen", "genre": "verse", "period": "N.A.", "pub_year": 1640, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Weil bey Flammenreichen Kriegen", "tokens": ["Weil", "bey", "Flam\u00b7men\u00b7rei\u00b7chen", "Krie\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Phabus K\u00fcnste gar erliegen/", "tokens": ["Pha\u00b7bus", "K\u00fcns\u00b7te", "gar", "er\u00b7lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat sich unser Freund bedacht", "tokens": ["Hat", "sich", "un\u00b7ser", "Freund", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und giebt B\u00fcchern gute Nacht.", "tokens": ["Und", "giebt", "B\u00fc\u00b7chern", "gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADJA", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.2": {"line.1": {"text": "Wer wolt auch wol hier studiren", "tokens": ["Wer", "wolt", "auch", "wol", "hier", "stu\u00b7di\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ADV", "ADV", "ADV", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wo man nur pflegt einzuf\u00fchren", "tokens": ["Wo", "man", "nur", "pflegt", "ein\u00b7zu\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "VVFIN", "VVIZU"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Leinwand/ Wolle/ Korn und Waltz", "tokens": ["Lein\u00b7wand", "/", "Wol\u00b7le", "/", "Korn", "und", "Waltz"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NE", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ochsen/ Gr\u00f6tzer-Bier und Saltz?", "tokens": ["Och\u00b7sen", "/", "Gr\u00f6t\u00b7zer\u00b7Bier", "und", "Saltz", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie man mir gewi\u00df wil sagen:", "tokens": ["Wie", "man", "mir", "ge\u00b7wi\u00df", "wil", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat sich noch f\u00fcr wenig Tagen/", "tokens": ["Hat", "sich", "noch", "f\u00fcr", "we\u00b7nig", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "APPR", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der uns B\u00fccher trug hervor", "tokens": ["Der", "uns", "B\u00fc\u00b7cher", "trug", "her\u00b7vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weg gemacht durchs Polnsche Thor", "tokens": ["Weg", "ge\u00b7macht", "durchs", "Poln\u00b7sche", "Thor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVPP", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Weil er nichts denn nur Donaten/", "tokens": ["Weil", "er", "nichts", "denn", "nur", "Do\u00b7na\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "B\u00fcchlein/ wie man ein soll rathen/", "tokens": ["B\u00fcch\u00b7lein", "/", "wie", "man", "ein", "soll", "ra\u00b7then", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PWAV", "PIS", "ART", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eulen-Spiegel/ A.B.C.", "tokens": ["Eu\u00b7len\u00b7Spie\u00b7gel", "/", "A.", "B.", "C."], "token_info": ["word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "$(", "APPRART", "NN", "NE"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Hat verkauffet je und eh.", "tokens": ["Hat", "ver\u00b7kauf\u00b7fet", "je", "und", "eh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "ADV", "KON", "KOUS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Warum solte denn zum Weben", "tokens": ["Wa\u00b7rum", "sol\u00b7te", "denn", "zum", "We\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich nicht unser Freund begeben?", "tokens": ["Sich", "nicht", "un\u00b7ser", "Freund", "be\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "(w\u00e4ben schafft uns Brod ins Hau\u00df", "tokens": ["(", "w\u00e4\u00b7ben", "schafft", "uns", "Brod", "ins", "Hau\u00df"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVINF", "VVFIN", "PPER", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00fccher kauffen/ tr\u00e4gt es rau\u00df.)", "tokens": ["B\u00fc\u00b7cher", "kauf\u00b7fen", "/", "tr\u00e4gt", "es", "rau\u00df", ".", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVINF", "$(", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wenn zumahl der/ der ihn lehret", "tokens": ["Wenn", "zu\u00b7mahl", "der", "/", "der", "ihn", "leh\u00b7ret"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "$(", "PRELS", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird von jederman geehret/", "tokens": ["Wird", "von", "je\u00b7der\u00b7man", "ge\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIS", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die goldne Kunst versteht", "tokens": ["Und", "die", "gold\u00b7ne", "Kunst", "ver\u00b7steht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dir da nicht nach Brodte geht.", "tokens": ["Dir", "da", "nicht", "nach", "Brod\u00b7te", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Kan es einer darzu bringen", "tokens": ["Kan", "es", "ei\u00b7ner", "dar\u00b7zu", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PIS", "PAV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er mag mit Jungfern dingen", "tokens": ["Da\u00df", "er", "mag", "mit", "Jung\u00b7fern", "din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wieviel Jahr er lernen soll/", "tokens": ["Wie\u00b7viel", "Jahr", "er", "ler\u00b7nen", "soll", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Basta der befindt sich wol.", "tokens": ["Bas\u00b7ta", "der", "be\u00b7findt", "sich", "wol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "VVFIN", "PRF", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Di\u00df Gl\u00fcck/ hab ich recht vernommen/", "tokens": ["Di\u00df", "Gl\u00fcck", "/", "hab", "ich", "recht", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$(", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist euch jetzt zu Hause kommen", "tokens": ["Ist", "euch", "jetzt", "zu", "Hau\u00b7se", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wehrter Freund/ mein ander Hertz/", "tokens": ["Wehr\u00b7ter", "Freund", "/", "mein", "an\u00b7der", "Hertz", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$(", "PPOSAT", "ADJD", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Offt mein Trost in meinem Schmertz.", "tokens": ["Offt", "mein", "Trost", "in", "mei\u00b7nem", "Schmertz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Ey greifft weil sie kommt gefahren", "tokens": ["Ey", "greifft", "weil", "sie", "kommt", "ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "KOUS", "PPER", "VVFIN", "VVPP"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Die Gelegenheit bey Haaren/", "tokens": ["Die", "Ge\u00b7le\u00b7gen\u00b7heit", "bey", "Haa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Andre m\u00f6gen m\u00fc\u00dfig stehn/", "tokens": ["And\u00b7re", "m\u00f6\u00b7gen", "m\u00fc\u00b7\u00dfig", "stehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder Gassen treten gehn.", "tokens": ["O\u00b7der", "Gas\u00b7sen", "tre\u00b7ten", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Schreckt nicht f\u00fcr den W\u00e4ber K\u00f6rben/", "tokens": ["Schreckt", "nicht", "f\u00fcr", "den", "W\u00e4\u00b7ber", "K\u00f6r\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "NN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer was redlichs wil erwerben", "tokens": ["Wer", "was", "red\u00b7lichs", "wil", "er\u00b7wer\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PWS", "VVFIN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tr\u00e4gt di\u00df offt mir K\u00f6rben ein/", "tokens": ["Tr\u00e4gt", "di\u00df", "offt", "mir", "K\u00f6r\u00b7ben", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "PPER", "NN", "ART", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was zu Fudern kan gedeyn.", "tokens": ["Was", "zu", "Fu\u00b7dern", "kan", "ge\u00b7deyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Wird/ die euch soll unterrichten", "tokens": ["Wird", "/", "die", "euch", "soll", "un\u00b7ter\u00b7rich\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "$(", "PRELS", "PPER", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnen recht die Werffte schlichten", "tokens": ["K\u00f6n\u00b7nen", "recht", "die", "Werff\u00b7te", "schlich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird die Sch\u00fctz euch l\u00e4uffig seyn", "tokens": ["Wird", "die", "Sch\u00fctz", "euch", "l\u00e4uf\u00b7fig", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PPER", "ADJD", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tragt ihr saubre Faden ein.", "tokens": ["Tragt", "ihr", "saub\u00b7re", "Fa\u00b7den", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wenn auch das Gez\u00f6h recht feste/", "tokens": ["Wenn", "auch", "das", "Ge\u00b7z\u00f6h", "recht", "fes\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "ADJA", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ey so webet ihr auffs beste", "tokens": ["Ey", "so", "we\u00b7bet", "ihr", "auffs", "bes\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VVFIN", "PPER", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bilder/ V\u00f6gel/ See und Land/", "tokens": ["Bil\u00b7der", "/", "V\u00f6\u00b7gel", "/", "See", "und", "Land", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trotz/ Gevatter Grantzes Hand.", "tokens": ["Trotz", "/", "Ge\u00b7vat\u00b7ter", "Grant\u00b7zes", "Hand", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Wolt ihr ausgelernet kriegen/", "tokens": ["Wolt", "ihr", "aus\u00b7ge\u00b7ler\u00b7net", "krie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4bt ein Kindlein in der Wiegen", "tokens": ["W\u00e4bt", "ein", "Kin\u00b7dlein", "in", "der", "Wie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine W\u00f6chnerin ins Bett", "tokens": ["Ei\u00b7ne", "W\u00f6ch\u00b7ne\u00b7rin", "ins", "Bett"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lo\u00dfgesagt geht ihr; Ich wett.", "tokens": ["Lo\u00df\u00b7ge\u00b7sagt", "geht", "ihr", ";", "Ich", "wett", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$.", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Weil bey Flammenreichen Kriegen", "tokens": ["Weil", "bey", "Flam\u00b7men\u00b7rei\u00b7chen", "Krie\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Phabus K\u00fcnste gar erliegen/", "tokens": ["Pha\u00b7bus", "K\u00fcns\u00b7te", "gar", "er\u00b7lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat sich unser Freund bedacht", "tokens": ["Hat", "sich", "un\u00b7ser", "Freund", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und giebt B\u00fcchern gute Nacht.", "tokens": ["Und", "giebt", "B\u00fc\u00b7chern", "gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADJA", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.15": {"line.1": {"text": "Wer wolt auch wol hier studiren", "tokens": ["Wer", "wolt", "auch", "wol", "hier", "stu\u00b7di\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ADV", "ADV", "ADV", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wo man nur pflegt einzuf\u00fchren", "tokens": ["Wo", "man", "nur", "pflegt", "ein\u00b7zu\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "VVFIN", "VVIZU"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Leinwand/ Wolle/ Korn und Waltz", "tokens": ["Lein\u00b7wand", "/", "Wol\u00b7le", "/", "Korn", "und", "Waltz"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NE", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ochsen/ Gr\u00f6tzer-Bier und Saltz?", "tokens": ["Och\u00b7sen", "/", "Gr\u00f6t\u00b7zer\u00b7Bier", "und", "Saltz", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Wie man mir gewi\u00df wil sagen:", "tokens": ["Wie", "man", "mir", "ge\u00b7wi\u00df", "wil", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat sich noch f\u00fcr wenig Tagen/", "tokens": ["Hat", "sich", "noch", "f\u00fcr", "we\u00b7nig", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "APPR", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der uns B\u00fccher trug hervor", "tokens": ["Der", "uns", "B\u00fc\u00b7cher", "trug", "her\u00b7vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weg gemacht durchs Polnsche Thor", "tokens": ["Weg", "ge\u00b7macht", "durchs", "Poln\u00b7sche", "Thor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVPP", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Weil er nichts denn nur Donaten/", "tokens": ["Weil", "er", "nichts", "denn", "nur", "Do\u00b7na\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "B\u00fcchlein/ wie man ein soll rathen/", "tokens": ["B\u00fcch\u00b7lein", "/", "wie", "man", "ein", "soll", "ra\u00b7then", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PWAV", "PIS", "ART", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eulen-Spiegel/ A.B.C.", "tokens": ["Eu\u00b7len\u00b7Spie\u00b7gel", "/", "A.", "B.", "C."], "token_info": ["word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "$(", "APPRART", "NN", "NE"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Hat verkauffet je und eh.", "tokens": ["Hat", "ver\u00b7kauf\u00b7fet", "je", "und", "eh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "ADV", "KON", "KOUS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Warum solte denn zum Weben", "tokens": ["Wa\u00b7rum", "sol\u00b7te", "denn", "zum", "We\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich nicht unser Freund begeben?", "tokens": ["Sich", "nicht", "un\u00b7ser", "Freund", "be\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "(w\u00e4ben schafft uns Brod ins Hau\u00df", "tokens": ["(", "w\u00e4\u00b7ben", "schafft", "uns", "Brod", "ins", "Hau\u00df"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVINF", "VVFIN", "PPER", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "B\u00fccher kauffen/ tr\u00e4gt es rau\u00df.)", "tokens": ["B\u00fc\u00b7cher", "kauf\u00b7fen", "/", "tr\u00e4gt", "es", "rau\u00df", ".", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVINF", "$(", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wenn zumahl der/ der ihn lehret", "tokens": ["Wenn", "zu\u00b7mahl", "der", "/", "der", "ihn", "leh\u00b7ret"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "$(", "PRELS", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird von jederman geehret/", "tokens": ["Wird", "von", "je\u00b7der\u00b7man", "ge\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIS", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die goldne Kunst versteht", "tokens": ["Und", "die", "gold\u00b7ne", "Kunst", "ver\u00b7steht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dir da nicht nach Brodte geht.", "tokens": ["Dir", "da", "nicht", "nach", "Brod\u00b7te", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Kan es einer darzu bringen", "tokens": ["Kan", "es", "ei\u00b7ner", "dar\u00b7zu", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PIS", "PAV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er mag mit Jungfern dingen", "tokens": ["Da\u00df", "er", "mag", "mit", "Jung\u00b7fern", "din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wieviel Jahr er lernen soll/", "tokens": ["Wie\u00b7viel", "Jahr", "er", "ler\u00b7nen", "soll", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Basta der befindt sich wol.", "tokens": ["Bas\u00b7ta", "der", "be\u00b7findt", "sich", "wol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "VVFIN", "PRF", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Di\u00df Gl\u00fcck/ hab ich recht vernommen/", "tokens": ["Di\u00df", "Gl\u00fcck", "/", "hab", "ich", "recht", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$(", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist euch jetzt zu Hause kommen", "tokens": ["Ist", "euch", "jetzt", "zu", "Hau\u00b7se", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wehrter Freund/ mein ander Hertz/", "tokens": ["Wehr\u00b7ter", "Freund", "/", "mein", "an\u00b7der", "Hertz", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$(", "PPOSAT", "ADJD", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Offt mein Trost in meinem Schmertz.", "tokens": ["Offt", "mein", "Trost", "in", "mei\u00b7nem", "Schmertz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Ey greifft weil sie kommt gefahren", "tokens": ["Ey", "greifft", "weil", "sie", "kommt", "ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "KOUS", "PPER", "VVFIN", "VVPP"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Die Gelegenheit bey Haaren/", "tokens": ["Die", "Ge\u00b7le\u00b7gen\u00b7heit", "bey", "Haa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Andre m\u00f6gen m\u00fc\u00dfig stehn/", "tokens": ["And\u00b7re", "m\u00f6\u00b7gen", "m\u00fc\u00b7\u00dfig", "stehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder Gassen treten gehn.", "tokens": ["O\u00b7der", "Gas\u00b7sen", "tre\u00b7ten", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Schreckt nicht f\u00fcr den W\u00e4ber K\u00f6rben/", "tokens": ["Schreckt", "nicht", "f\u00fcr", "den", "W\u00e4\u00b7ber", "K\u00f6r\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "NN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer was redlichs wil erwerben", "tokens": ["Wer", "was", "red\u00b7lichs", "wil", "er\u00b7wer\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PWS", "VVFIN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tr\u00e4gt di\u00df offt mir K\u00f6rben ein/", "tokens": ["Tr\u00e4gt", "di\u00df", "offt", "mir", "K\u00f6r\u00b7ben", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "PPER", "NN", "ART", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was zu Fudern kan gedeyn.", "tokens": ["Was", "zu", "Fu\u00b7dern", "kan", "ge\u00b7deyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Wird/ die euch soll unterrichten", "tokens": ["Wird", "/", "die", "euch", "soll", "un\u00b7ter\u00b7rich\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "$(", "PRELS", "PPER", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnen recht die Werffte schlichten", "tokens": ["K\u00f6n\u00b7nen", "recht", "die", "Werff\u00b7te", "schlich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird die Sch\u00fctz euch l\u00e4uffig seyn", "tokens": ["Wird", "die", "Sch\u00fctz", "euch", "l\u00e4uf\u00b7fig", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PPER", "ADJD", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tragt ihr saubre Faden ein.", "tokens": ["Tragt", "ihr", "saub\u00b7re", "Fa\u00b7den", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Wenn auch das Gez\u00f6h recht feste/", "tokens": ["Wenn", "auch", "das", "Ge\u00b7z\u00f6h", "recht", "fes\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "ADJA", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ey so webet ihr auffs beste", "tokens": ["Ey", "so", "we\u00b7bet", "ihr", "auffs", "bes\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VVFIN", "PPER", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bilder/ V\u00f6gel/ See und Land/", "tokens": ["Bil\u00b7der", "/", "V\u00f6\u00b7gel", "/", "See", "und", "Land", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trotz/ Gevatter Grantzes Hand.", "tokens": ["Trotz", "/", "Ge\u00b7vat\u00b7ter", "Grant\u00b7zes", "Hand", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Wolt ihr ausgelernet kriegen/", "tokens": ["Wolt", "ihr", "aus\u00b7ge\u00b7ler\u00b7net", "krie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4bt ein Kindlein in der Wiegen", "tokens": ["W\u00e4bt", "ein", "Kin\u00b7dlein", "in", "der", "Wie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine W\u00f6chnerin ins Bett", "tokens": ["Ei\u00b7ne", "W\u00f6ch\u00b7ne\u00b7rin", "ins", "Bett"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lo\u00dfgesagt geht ihr; Ich wett.", "tokens": ["Lo\u00df\u00b7ge\u00b7sagt", "geht", "ihr", ";", "Ich", "wett", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$.", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}