{"textgrid.poem.57030": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Palmstr\u00f6m kann nicht ohne Post", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Palmstr\u00f6m kann nicht ohne Post", "tokens": ["Palm\u00b7str\u00f6m", "kann", "nicht", "oh\u00b7ne", "Post"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "leben:", "tokens": ["le\u00b7ben", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Sie ist seiner Tage Kost.", "tokens": ["Sie", "ist", "sei\u00b7ner", "Ta\u00b7ge", "Kost", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "T\u00e4glich dreimal ist er ganz", "tokens": ["T\u00e4g\u00b7lich", "drei\u00b7mal", "ist", "er", "ganz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Spannung.", "tokens": ["Span\u00b7nung", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "T\u00e4glich ist's der gleiche Tanz:", "tokens": ["T\u00e4g\u00b7lich", "ist's", "der", "glei\u00b7che", "Tanz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Selten h\u00f6rt er einen Brief", "tokens": ["Sel\u00b7ten", "h\u00f6rt", "er", "ei\u00b7nen", "Brief"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "plumpen", "tokens": ["plum\u00b7pen"], "token_info": ["word"], "pos": ["VVINF"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "in den Kasten breit und tief.", "tokens": ["in", "den", "Kas\u00b7ten", "breit", "und", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "D\u00fcster schilt er auf den Mann,", "tokens": ["D\u00fcs\u00b7ter", "schilt", "er", "auf", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "welcher,", "tokens": ["wel\u00b7cher", ","], "token_info": ["word", "punct"], "pos": ["PWAT", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "wie man wei\u00df, nichts daf\u00fcr kann.", "tokens": ["wie", "man", "wei\u00df", ",", "nichts", "da\u00b7f\u00fcr", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "PIS", "PAV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Endlich kommt er drauf zur\u00fcck:", "tokens": ["End\u00b7lich", "kommt", "er", "drauf", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "auf das:", "tokens": ["auf", "das", ":"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "ART", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "\u00bbwarenhaus f\u00fcr Kleines Gl\u00fcck\u00ab.", "tokens": ["\u00bb", "wa\u00b7ren\u00b7haus", "f\u00fcr", "Klei\u00b7nes", "Gl\u00fcck", "\u00ab", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "APPR", "ADJA", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und bestellt dort, frisch vom Rost,", "tokens": ["Und", "be\u00b7stellt", "dort", ",", "frisch", "vom", "Rost", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "(quasi):", "tokens": ["(", "qua\u00b7si", ")", ":"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "NE", "$(", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.3": {"text": "ein Quartal \u2013 \u00bbGemischte Post\u00ab!", "tokens": ["ein", "Quar\u00b7tal", "\u2013", "\u00bb", "Ge\u00b7mischte", "Post", "\u00ab", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "$(", "NN", "NN", "$(", "$."], "meter": "-+---+", "measure": "dactylic.init"}}, "stanza.7": {"line.1": {"text": "Und nun kommt von fr\u00fch bis sp\u00e4t", "tokens": ["Und", "nun", "kommt", "von", "fr\u00fch", "bis", "sp\u00e4t"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ADJD", "APPR", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Post von", "tokens": ["Post", "von"], "token_info": ["word", "word"], "pos": ["NN", "APPR"], "meter": "--", "measure": "unknown.measure.zero"}, "line.3": {"text": "aller Art und Qualit\u00e4t.", "tokens": ["al\u00b7ler", "Art", "und", "Qua\u00b7li\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Jedermann teilt sich ihm mit,", "tokens": ["Je\u00b7der\u00b7mann", "teilt", "sich", "ihm", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "PPER", "PTKVZ", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "brieflich,", "tokens": ["brief\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "denkt an ihn auf Schritt und Tritt.", "tokens": ["denkt", "an", "ihn", "auf", "Schritt", "und", "Tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Palmstr\u00f6m sieht sich in die Welt", "tokens": ["Palm\u00b7str\u00f6m", "sieht", "sich", "in", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "pl\u00f6tzlich", "tokens": ["pl\u00f6tz\u00b7lich"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "\u00fcberall hineingestellt ...", "tokens": ["\u00fc\u00b7be\u00b7rall", "hin\u00b7ein\u00b7ge\u00b7stellt", "..."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und ihm wird schon wirr und weh ...", "tokens": ["Und", "ihm", "wird", "schon", "wirr", "und", "weh", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch es", "tokens": ["Doch", "es"], "token_info": ["word", "word"], "pos": ["KON", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "ist ja nur das \u2013 \u00bbW.K.G.\u00ab", "tokens": ["ist", "ja", "nur", "das", "\u2013", "\u00bb", "W.", "K.", "G.", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "abbreviation", "abbreviation", "abbreviation", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "$(", "$(", "NE", "NE", "NE", "$("], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.11": {"line.1": {"text": "Palmstr\u00f6m kann nicht ohne Post", "tokens": ["Palm\u00b7str\u00f6m", "kann", "nicht", "oh\u00b7ne", "Post"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "leben:", "tokens": ["le\u00b7ben", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Sie ist seiner Tage Kost.", "tokens": ["Sie", "ist", "sei\u00b7ner", "Ta\u00b7ge", "Kost", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "T\u00e4glich dreimal ist er ganz", "tokens": ["T\u00e4g\u00b7lich", "drei\u00b7mal", "ist", "er", "ganz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Spannung.", "tokens": ["Span\u00b7nung", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "T\u00e4glich ist's der gleiche Tanz:", "tokens": ["T\u00e4g\u00b7lich", "ist's", "der", "glei\u00b7che", "Tanz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Selten h\u00f6rt er einen Brief", "tokens": ["Sel\u00b7ten", "h\u00f6rt", "er", "ei\u00b7nen", "Brief"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "plumpen", "tokens": ["plum\u00b7pen"], "token_info": ["word"], "pos": ["VVINF"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "in den Kasten breit und tief.", "tokens": ["in", "den", "Kas\u00b7ten", "breit", "und", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "D\u00fcster schilt er auf den Mann,", "tokens": ["D\u00fcs\u00b7ter", "schilt", "er", "auf", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "welcher,", "tokens": ["wel\u00b7cher", ","], "token_info": ["word", "punct"], "pos": ["PWAT", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "wie man wei\u00df, nichts daf\u00fcr kann.", "tokens": ["wie", "man", "wei\u00df", ",", "nichts", "da\u00b7f\u00fcr", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "PIS", "PAV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Endlich kommt er drauf zur\u00fcck:", "tokens": ["End\u00b7lich", "kommt", "er", "drauf", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "auf das:", "tokens": ["auf", "das", ":"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "ART", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "\u00bbwarenhaus f\u00fcr Kleines Gl\u00fcck\u00ab.", "tokens": ["\u00bb", "wa\u00b7ren\u00b7haus", "f\u00fcr", "Klei\u00b7nes", "Gl\u00fcck", "\u00ab", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "APPR", "ADJA", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Und bestellt dort, frisch vom Rost,", "tokens": ["Und", "be\u00b7stellt", "dort", ",", "frisch", "vom", "Rost", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "(quasi):", "tokens": ["(", "qua\u00b7si", ")", ":"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "NE", "$(", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.3": {"text": "ein Quartal \u2013 \u00bbGemischte Post\u00ab!", "tokens": ["ein", "Quar\u00b7tal", "\u2013", "\u00bb", "Ge\u00b7mischte", "Post", "\u00ab", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "$(", "NN", "NN", "$(", "$."], "meter": "-+---+", "measure": "dactylic.init"}}, "stanza.17": {"line.1": {"text": "Und nun kommt von fr\u00fch bis sp\u00e4t", "tokens": ["Und", "nun", "kommt", "von", "fr\u00fch", "bis", "sp\u00e4t"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ADJD", "APPR", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Post von", "tokens": ["Post", "von"], "token_info": ["word", "word"], "pos": ["NN", "APPR"], "meter": "--", "measure": "unknown.measure.zero"}, "line.3": {"text": "aller Art und Qualit\u00e4t.", "tokens": ["al\u00b7ler", "Art", "und", "Qua\u00b7li\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Jedermann teilt sich ihm mit,", "tokens": ["Je\u00b7der\u00b7mann", "teilt", "sich", "ihm", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "PPER", "PTKVZ", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "brieflich,", "tokens": ["brief\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "denkt an ihn auf Schritt und Tritt.", "tokens": ["denkt", "an", "ihn", "auf", "Schritt", "und", "Tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Palmstr\u00f6m sieht sich in die Welt", "tokens": ["Palm\u00b7str\u00f6m", "sieht", "sich", "in", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "pl\u00f6tzlich", "tokens": ["pl\u00f6tz\u00b7lich"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "\u00fcberall hineingestellt ...", "tokens": ["\u00fc\u00b7be\u00b7rall", "hin\u00b7ein\u00b7ge\u00b7stellt", "..."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Und ihm wird schon wirr und weh ...", "tokens": ["Und", "ihm", "wird", "schon", "wirr", "und", "weh", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch es", "tokens": ["Doch", "es"], "token_info": ["word", "word"], "pos": ["KON", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "ist ja nur das \u2013 \u00bbW.K.G.\u00ab", "tokens": ["ist", "ja", "nur", "das", "\u2013", "\u00bb", "W.", "K.", "G.", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "abbreviation", "abbreviation", "abbreviation", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "$(", "$(", "NE", "NE", "NE", "$("], "meter": "+--+", "measure": "iambic.di.chol"}}}}}