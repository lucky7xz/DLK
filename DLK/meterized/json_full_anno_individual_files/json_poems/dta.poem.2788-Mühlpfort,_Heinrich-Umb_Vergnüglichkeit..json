{"dta.poem.2788": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Umb Vergn\u00fcglichkeit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Zwey Dinge bitte ich/ O grosser GOtt/ von Dir/", "tokens": ["Zwey", "Din\u00b7ge", "bit\u00b7te", "ich", "/", "O", "gros\u00b7ser", "Gott", "/", "von", "Dir", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "$(", "NE", "ADJA", "NN", "$(", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "La\u00df mich Genade/ HErr/ f\u00fcr deinen Augen finden!", "tokens": ["La\u00df", "mich", "Ge\u00b7na\u00b7de", "/", "Herr", "/", "f\u00fcr", "dei\u00b7nen", "Au\u00b7gen", "fin\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "$(", "NN", "$(", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein Reichthum schencke mir/", "tokens": ["Kein", "Reicht\u00b7hum", "schen\u00b7cke", "mir", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und la\u00df hingegen mich nicht Armuths-Ketten binden!", "tokens": ["Und", "la\u00df", "hin\u00b7ge\u00b7gen", "mich", "nicht", "Ar\u00b7muths\u00b7Ket\u00b7ten", "bin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ADV", "PPER", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie leichte k\u00f6nt\u2019 ich nicht mich gar zu weit vergehn;", "tokens": ["Wie", "leich\u00b7te", "k\u00f6nt'", "ich", "nicht", "mich", "gar", "zu", "weit", "ver\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "VMFIN", "PPER", "PTKNEG", "PPER", "ADV", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So/ da\u00df mein Hertze m\u00f6cht an ird\u2019schen Dingen kleben/", "tokens": ["So", "/", "da\u00df", "mein", "Hert\u00b7ze", "m\u00f6cht", "an", "ird'\u00b7schen", "Din\u00b7gen", "kle\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPOSAT", "VVFIN", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil kaum beysammen stehn/", "tokens": ["Weil", "kaum", "bey\u00b7sam\u00b7men", "stehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVINF", "VVINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ein Geld ergebner Sinn/ und ein gottseelig Leben.", "tokens": ["Ein", "Geld", "er\u00b7geb\u00b7ner", "Sinn", "/", "und", "ein", "gott\u00b7see\u00b7lig", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "KON", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich baute meinem Gold eh Tempel und Altar/", "tokens": ["Ich", "bau\u00b7te", "mei\u00b7nem", "Gold", "eh", "Tem\u00b7pel", "und", "Al\u00b7tar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KOUS", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Eh\u2019 ich dich wahren GOtt mit reiner Andacht suchte/", "tokens": ["Eh'", "ich", "dich", "wah\u00b7ren", "Gott", "mit", "rei\u00b7ner", "An\u00b7dacht", "such\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr sch\u00e4tzt es ohn Gefahr/", "tokens": ["Ihr", "sch\u00e4tzt", "es", "ohn", "Ge\u00b7fahr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wenn meinen schn\u00f6den Geitz gleich alle Welt verfluchte.", "tokens": ["Wenn", "mei\u00b7nen", "schn\u00f6\u00b7den", "Geitz", "gleich", "al\u00b7le", "Welt", "ver\u00b7fluch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie viel hat nicht ihr Geld umb Seel und Leib gebracht/", "tokens": ["Wie", "viel", "hat", "nicht", "ihr", "Geld", "umb", "Seel", "und", "Leib", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PTKNEG", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie von dem Himmel-Weg/ der H\u00f6llen zu gezogen?", "tokens": ["Sie", "von", "dem", "Him\u00b7mel\u00b7Weg", "/", "der", "H\u00f6l\u00b7len", "zu", "ge\u00b7zo\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$(", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu Knechten sie gemacht/", "tokens": ["Zu", "Knech\u00b7ten", "sie", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Des Vaters alles Trugs der sie hernach betrogen.", "tokens": ["Des", "Va\u00b7ters", "al\u00b7les", "Trugs", "der", "sie", "her\u00b7nach", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "ART", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Und was ist Geld und Gold/ als ein verg\u00e4nglich Koth?", "tokens": ["Und", "was", "ist", "Geld", "und", "Gold", "/", "als", "ein", "ver\u00b7g\u00e4ng\u00b7lich", "Koth", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "NN", "KON", "NN", "$(", "KOUS", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was sind die Sch\u00e4tze mehr als Schl\u00fcssel zu den S\u00fcnden?", "tokens": ["Was", "sind", "die", "Sch\u00e4t\u00b7ze", "mehr", "als", "Schl\u00fcs\u00b7sel", "zu", "den", "S\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "KOUS", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kommts an die letzte Noth/", "tokens": ["Kommts", "an", "die", "letz\u00b7te", "Noth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wo wirst du Rath und Trost bey deinem Klumpen finden?", "tokens": ["Wo", "wirst", "du", "Rath", "und", "Trost", "bey", "dei\u00b7nem", "Klum\u00b7pen", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Und wird best\u00e4ndig auch hier dein Verm\u00f6gen seyn?", "tokens": ["Und", "wird", "be\u00b7st\u00e4n\u00b7dig", "auch", "hier", "dein", "Ver\u00b7m\u00f6\u00b7gen", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADV", "ADV", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Welch Zufall kan es nicht im Augenblick entwenden?", "tokens": ["Welch", "Zu\u00b7fall", "kan", "es", "nicht", "im", "Au\u00b7gen\u00b7blick", "ent\u00b7wen\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wer viel sammlet ein/", "tokens": ["Und", "wer", "viel", "samm\u00b7let", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "ART", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der schaut es noch zu letzt in frembder Leute H\u00e4nden.", "tokens": ["Der", "schaut", "es", "noch", "zu", "letzt", "in", "fremb\u00b7der", "Leu\u00b7te", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "ADV", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der M\u00fcntze Korn und Schrott/ wie sehr es uns gef\u00e4llt/", "tokens": ["Der", "M\u00fcnt\u00b7ze", "Korn", "und", "Schrott", "/", "wie", "sehr", "es", "uns", "ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$(", "KOKOM", "ADV", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist zwar ein herrlich Ding im Leben/ nicht im Sterben:", "tokens": ["Ist", "zwar", "ein", "herr\u00b7lich", "Ding", "im", "Le\u00b7ben", "/", "nicht", "im", "Ster\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "NN", "APPRART", "NN", "$(", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn es bleibt auf der Welt/", "tokens": ["Denn", "es", "bleibt", "auf", "der", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und trifft zum \u00f6fftern an nicht einen danckbarn Erben.", "tokens": ["Und", "trifft", "zum", "\u00f6ff\u00b7tern", "an", "nicht", "ei\u00b7nen", "dan\u00b7ck\u00b7barn", "Er\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADV", "APPR", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Viel/ die so sehr gescharrt nach einem grossen Gut/", "tokens": ["Viel", "/", "die", "so", "sehr", "ge\u00b7scharrt", "nach", "ei\u00b7nem", "gros\u00b7sen", "Gut", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ART", "ADV", "ADV", "VVPP", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die haben es hernach den Kindern nicht gelassen:", "tokens": ["Die", "ha\u00b7ben", "es", "her\u00b7nach", "den", "Kin\u00b7dern", "nicht", "ge\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn Krieg/ wenn Glut und Flut/", "tokens": ["Wenn", "Krieg", "/", "wenn", "Glut", "und", "Flut", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "KOUS", "NN", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und ungetreue Freund es nach dem Tode fassen.", "tokens": ["Und", "un\u00b7ge\u00b7treu\u00b7e", "Freund", "es", "nach", "dem", "To\u00b7de", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ach wende doch/ mein GOtt/ mein Hertze gantz hinweg!", "tokens": ["Ach", "wen\u00b7de", "doch", "/", "mein", "Gott", "/", "mein", "Hert\u00b7ze", "gantz", "hin\u00b7weg", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "$(", "PPOSAT", "NN", "$(", "PPOSAT", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich darff ein Weniges zum Unterhalt im Leben/", "tokens": ["Ich", "darff", "ein", "We\u00b7ni\u00b7ges", "zum", "Un\u00b7ter\u00b7halt", "im", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "PIS", "APPRART", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und meiner Hoffnung Zweck", "tokens": ["Und", "mei\u00b7ner", "Hoff\u00b7nung", "Zweck"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist/ da\u00df dein Vater-Hertz es mir wird gn\u00e4dig geben.", "tokens": ["Ist", "/", "da\u00df", "dein", "Va\u00b7ter\u00b7Hertz", "es", "mir", "wird", "gn\u00e4\u00b7dig", "ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "KOUS", "PPOSAT", "NN", "PPER", "PPER", "VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Nimm/ bitt ich/ auch von mir des Armuths schwere Last!", "tokens": ["Nimm", "/", "bitt", "ich", "/", "auch", "von", "mir", "des", "Ar\u00b7muths", "schwe\u00b7re", "Last", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "VVFIN", "PPER", "$(", "ADV", "APPR", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was kan elenders seyn als steten Mangel leiden;", "tokens": ["Was", "kan", "e\u00b7len\u00b7ders", "seyn", "als", "ste\u00b7ten", "Man\u00b7gel", "lei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VAINF", "KOKOM", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo weder Ruh noch Rast/", "tokens": ["Wo", "we\u00b7der", "Ruh", "noch", "Rast", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "NN", "ADV", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die Sorgen lassen zu/ die durch das Hertze schneiden!", "tokens": ["Die", "Sor\u00b7gen", "las\u00b7sen", "zu", "/", "die", "durch", "das", "Hert\u00b7ze", "schnei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PTKZU", "$(", "ART", "APPR", "PDS", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "La\u00df meinen Saamen nicht allhier nach Brodte gehn/", "tokens": ["La\u00df", "mei\u00b7nen", "Saa\u00b7men", "nicht", "all\u00b7hier", "nach", "Brod\u00b7te", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch in der D\u00fcrfftigkeit des Geistes Krafft ersticken.", "tokens": ["Noch", "in", "der", "D\u00fcr\u00b7ff\u00b7tig\u00b7keit", "des", "Geis\u00b7tes", "Krafft", "er\u00b7sti\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-++-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.3": {"text": "Der steigt nicht an die H\u00f6he", "tokens": ["Der", "steigt", "nicht", "an", "die", "H\u00f6\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PTKNEG", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Kummer und Gebruch zur Erden nieder dr\u00fccken.", "tokens": ["Den", "Kum\u00b7mer", "und", "Ge\u00b7bruch", "zur", "Er\u00b7den", "nie\u00b7der", "dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPRART", "NN", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ich bin mit wenigem von deiner Hand vergn\u00fcgt.", "tokens": ["Ich", "bin", "mit", "we\u00b7ni\u00b7gem", "von", "dei\u00b7ner", "Hand", "ver\u00b7gn\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIS", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es soll mein Bissen Brod f\u00fcr dem mir besser schmecken/", "tokens": ["Es", "soll", "mein", "Bis\u00b7sen", "Brod", "f\u00fcr", "dem", "mir", "bes\u00b7ser", "schme\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "NN", "APPR", "PRELS", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der stets zu Hofe ligt/", "tokens": ["Der", "stets", "zu", "Ho\u00b7fe", "ligt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und sieht halb hungrig an der F\u00fcrsten Tafel decken.", "tokens": ["Und", "sieht", "halb", "hung\u00b7rig", "an", "der", "F\u00fcrs\u00b7ten", "Ta\u00b7fel", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADJD", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Zu dem darff die Natur so grossen Vorrath nicht:", "tokens": ["Zu", "dem", "darff", "die", "Na\u00b7tur", "so", "gros\u00b7sen", "Vor\u00b7rath", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VMFIN", "ART", "NN", "ADV", "ADJA", "NN", "PTKNEG", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Das beste Gastmahl ist ein fr\u00f6liches Gewissen.", "tokens": ["Das", "bes\u00b7te", "Gast\u00b7mahl", "ist", "ein", "fr\u00f6\u00b7li\u00b7ches", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wem dieses schon gebricht/", "tokens": ["Wem", "die\u00b7ses", "schon", "ge\u00b7bricht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der wird bey bester Kost/ nur Gall und Gift geniesen.", "tokens": ["Der", "wird", "bey", "bes\u00b7ter", "Kost", "/", "nur", "Gall", "und", "Gift", "ge\u00b7nie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ADJA", "NN", "$(", "ADV", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Wenn die Vergn\u00fcgung nur mit mir zu Tische sitzt/", "tokens": ["Wenn", "die", "Ver\u00b7gn\u00fc\u00b7gung", "nur", "mit", "mir", "zu", "Ti\u00b7sche", "sitzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "PPER", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vertrauen auf dich\u2019 HErr/ mit mir zu Bette gehet;", "tokens": ["Ver\u00b7trau\u00b7en", "auf", "dich'", "Herr", "/", "mit", "mir", "zu", "Bet\u00b7te", "ge\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$(", "APPR", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mich deine Macht besch\u00fctzt;", "tokens": ["Mich", "dei\u00b7ne", "Macht", "be\u00b7sch\u00fctzt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "So frag ich weiter nicht/ wie der und jener stehet.", "tokens": ["So", "frag", "ich", "wei\u00b7ter", "nicht", "/", "wie", "der", "und", "je\u00b7ner", "ste\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "PTKNEG", "$(", "KOKOM", "ART", "KON", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Er halte diesen Muth/ befeste diesen Sinn/", "tokens": ["Er", "hal\u00b7te", "die\u00b7sen", "Muth", "/", "be\u00b7fes\u00b7te", "die\u00b7sen", "Sinn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "$(", "VVFIN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bi\u00df endlich ich den Lauff des m\u00fcden Lebens schliesse:", "tokens": ["Bi\u00df", "end\u00b7lich", "ich", "den", "Lauff", "des", "m\u00fc\u00b7den", "Le\u00b7bens", "schlies\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn nimm mich zu dir hin/", "tokens": ["Denn", "nimm", "mich", "zu", "dir", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wo ich des Lebens-Brod/ den Kelch des Heyls geniesse!", "tokens": ["Wo", "ich", "des", "Le\u00b7bens\u00b7Brod", "/", "den", "Kelch", "des", "Heyls", "ge\u00b7nies\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "$(", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}