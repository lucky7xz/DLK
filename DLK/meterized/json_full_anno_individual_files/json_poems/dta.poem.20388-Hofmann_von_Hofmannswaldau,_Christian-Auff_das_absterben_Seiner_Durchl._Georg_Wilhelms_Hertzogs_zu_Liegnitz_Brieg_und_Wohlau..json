{"dta.poem.20388": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Auff das absterben Seiner Durchl.  \n Georg Wilhelms/ Hertzogs zu Liegnitz/  \n Brieg und Wohlau.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So bricht der glantz der welt!", "tokens": ["So", "bricht", "der", "glantz", "der", "welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die zeit kan auch den purpur bleichen;", "tokens": ["Die", "zeit", "kan", "auch", "den", "pur\u00b7pur", "blei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die reinste sonne mu\u00df zu bald den west erreichen:", "tokens": ["Die", "reins\u00b7te", "son\u00b7ne", "mu\u00df", "zu", "bald", "den", "west", "er\u00b7rei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "APPR", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die s\u00e4ule reich an ertzt wird zeitlich hingef\u00e4llt.", "tokens": ["Die", "s\u00e4u\u00b7le", "reich", "an", "ertzt", "wird", "zeit\u00b7lich", "hin\u00b7ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "VVPP", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des himmels spruch ist nicht zu widerstehen/", "tokens": ["Des", "him\u00b7mels", "spruch", "ist", "nicht", "zu", "wi\u00b7der\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und wer ist gro\u00df genug demselben zu entgehen?", "tokens": ["Und", "wer", "ist", "gro\u00df", "ge\u00b7nug", "dem\u00b7sel\u00b7ben", "zu", "ent\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ADJD", "ADV", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "2.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Di\u00df/ was man ewig sch\u00e4tzt/", "tokens": ["Di\u00df", "/", "was", "man", "e\u00b7wig", "sch\u00e4tzt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "PWS", "PIS", "ADJD", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das wird in kurtzer zeit begraben;", "tokens": ["Das", "wird", "in", "kurt\u00b7zer", "zeit", "be\u00b7gra\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer wei\u00df/ wo ihrer viel itzt ihre gr\u00e4ber haben?", "tokens": ["Wer", "wei\u00df", "/", "wo", "ih\u00b7rer", "viel", "itzt", "ih\u00b7re", "gr\u00e4\u00b7ber", "ha\u00b7ben", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "PWAV", "PPER", "ADV", "ADV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die sich lebendig selbst den sternen beygesetzt.", "tokens": ["Die", "sich", "le\u00b7ben\u00b7dig", "selbst", "den", "ster\u00b7nen", "bey\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "ADV", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mich deucht/ wie die natur manch ding verlohren/", "tokens": ["Mich", "deucht", "/", "wie", "die", "na\u00b7tur", "manch", "ding", "ver\u00b7loh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOKOM", "ART", "NN", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Da\u00df die verg\u00e4nglichkeit zu trotzen sich verschwohren.", "tokens": ["Da\u00df", "die", "ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "zu", "trot\u00b7zen", "sich", "ver\u00b7schwoh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKZU", "VVINF", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "3.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Des Nimrods grosses reich/", "tokens": ["Des", "Nim\u00b7rods", "gros\u00b7ses", "reich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJA", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da haupt und herrschafft g\u00fclden waren/", "tokens": ["Da", "haupt", "und", "herr\u00b7schafft", "g\u00fcl\u00b7den", "wa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "VVFIN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist/ wie von wenig flut der spr\u00f6de thon/ zerfahren/", "tokens": ["Ist", "/", "wie", "von", "we\u00b7nig", "flut", "der", "spr\u00f6\u00b7de", "thon", "/", "zer\u00b7fah\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "$(", "KOKOM", "APPR", "PIAT", "NN", "ART", "ADJA", "NN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und seine macht ist itzt den todten-knochen gleich.", "tokens": ["Und", "sei\u00b7ne", "macht", "ist", "itzt", "den", "tod\u00b7ten\u00b7kno\u00b7chen", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VVFIN", "VAFIN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das feste land/ der grund-stein der pall\u00e4ste/", "tokens": ["Das", "fes\u00b7te", "land", "/", "der", "grun\u00b7dstein", "der", "pal\u00b7l\u00e4s\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Der schweren berge fu\u00df steht selber nicht gar feste.", "tokens": ["Der", "schwe\u00b7ren", "ber\u00b7ge", "fu\u00df", "steht", "sel\u00b7ber", "nicht", "gar", "fes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PTKVZ", "VVFIN", "ADV", "PTKNEG", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "4.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Von Artaxerxes Thron", "tokens": ["Von", "Ar\u00b7ta\u00b7xe\u00b7rxes", "Thron"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist schwerlich noch ein stein zu zeigen;", "tokens": ["Ist", "schwer\u00b7lich", "noch", "ein", "stein", "zu", "zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "ART", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer wei\u00df/ wo ringe sich um schlechte finger beugen/", "tokens": ["Wer", "wei\u00df", "/", "wo", "rin\u00b7ge", "sich", "um", "schlech\u00b7te", "fin\u00b7ger", "beu\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "PWAV", "VVFIN", "PRF", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aus derer golde vor bestund die k\u00f6nigs-kron.", "tokens": ["Aus", "de\u00b7rer", "gol\u00b7de", "vor", "be\u00b7stund", "die", "k\u00f6\u00b7nigs\u00b7kron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "NN", "APPR", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der moder hat den theuren zeug zerbissen/", "tokens": ["Der", "mo\u00b7der", "hat", "den", "theu\u00b7ren", "zeug", "zer\u00b7bis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den meinen ahnen hat manch sieger k\u00fcssen m\u00fcssen.", "tokens": ["Den", "mei\u00b7nen", "ah\u00b7nen", "hat", "manch", "sie\u00b7ger", "k\u00fcs\u00b7sen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "VVINF", "VAFIN", "PIAT", "ADJA", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "5.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Wie alles di\u00df geht ein/", "tokens": ["Wie", "al\u00b7les", "di\u00df", "geht", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PDS", "VVFIN", "ART", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie gantze reiche sich versetzen/", "tokens": ["Wie", "gant\u00b7ze", "rei\u00b7che", "sich", "ver\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der rest den stahl/ die zeit den marmol kan verletzen:", "tokens": ["Der", "rest", "den", "stahl", "/", "die", "zeit", "den", "mar\u00b7mol", "kan", "ver\u00b7let\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So mu\u00df geschlecht und mensch dem tod\u2019 auch zin\u00dfbar seyn.", "tokens": ["So", "mu\u00df", "ge\u00b7schlecht", "und", "mensch", "dem", "tod'", "auch", "zin\u00df\u00b7bar", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVPP", "KON", "ADJD", "ART", "NN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein alterthum der h\u00e4user und der w\u00fcrden/", "tokens": ["Kein", "al\u00b7ter\u00b7thum", "der", "h\u00e4u\u00b7ser", "und", "der", "w\u00fcr\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "ADJA", "KON", "ART", "VAFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wei\u00df f\u00fcrsten von der schuld des sterbens zu entb\u00fcrden.", "tokens": ["Wei\u00df", "f\u00fcrs\u00b7ten", "von", "der", "schuld", "des", "ster\u00b7bens", "zu", "ent\u00b7b\u00fcr\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "6.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Mein graues hau\u00df verf\u00e4llt/", "tokens": ["Mein", "grau\u00b7es", "hau\u00df", "ver\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das nun neun hundert jahr gestanden/", "tokens": ["Das", "nun", "neun", "hun\u00b7dert", "jahr", "ge\u00b7stan\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "CARD", "CARD", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch ist GOtt lob! kein grau\u00df von hohn und spott verhanden!", "tokens": ["Doch", "ist", "Gott", "lob", "!", "kein", "grau\u00df", "von", "hohn", "und", "spott", "ver\u00b7han\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "NN", "$.", "PIAT", "NN", "APPR", "ADJA", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Weil ihn die welt zum theil/ theils GOtt in ehren h\u00e4lt.", "tokens": ["Weil", "ihn", "die", "welt", "zum", "theil", "/", "theils", "Gott", "in", "eh\u00b7ren", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN", "$(", "ADV", "NN", "APPR", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es f\u00e4llt durch m\u00fch; Jedoch wird niemand schliessen/", "tokens": ["Es", "f\u00e4llt", "durch", "m\u00fch", ";", "Je\u00b7doch", "wird", "nie\u00b7mand", "schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJD", "$.", "ADV", "VAFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Da\u00df ich durch meine schuld den grund h\u00e4tt\u2019 eingerissen.", "tokens": ["Da\u00df", "ich", "durch", "mei\u00b7ne", "schuld", "den", "grund", "h\u00e4tt'", "ein\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "7.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Des allerh\u00f6chsten hand/", "tokens": ["Des", "al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "hand", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So Cedern setzt und wieder f\u00e4llet/", "tokens": ["So", "Ce\u00b7dern", "setzt", "und", "wie\u00b7der", "f\u00e4l\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "KON", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und an Pyastus stamm zum gipffel mich gestellet/", "tokens": ["Und", "an", "Py\u00b7as\u00b7tus", "stamm", "zum", "gipf\u00b7fel", "mich", "ge\u00b7stel\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "APPRART", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die bricht mich ab/ und setzt mich in ein ander land;", "tokens": ["Die", "bricht", "mich", "ab", "/", "und", "setzt", "mich", "in", "ein", "an\u00b7der", "land", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$(", "KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer dieser hand sich m\u00fcht zu widerstreben/", "tokens": ["Wer", "die\u00b7ser", "hand", "sich", "m\u00fcht", "zu", "wi\u00b7der\u00b7stre\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "PRF", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Der liebt sein ungel\u00fcck/ und ha\u00dft sein eigen leben.", "tokens": ["Der", "liebt", "sein", "un\u00b7ge\u00b7l\u00fcck", "/", "und", "ha\u00dft", "sein", "ei\u00b7gen", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "8.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Vorhin herrscht\u2019 ich mit lust/", "tokens": ["Vor\u00b7hin", "herrscht'", "ich", "mit", "lust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Itzt folg\u2019 ich noch mit gr\u00f6ssern freuden.", "tokens": ["Itzt", "fol\u00b7g'", "ich", "noch", "mit", "gr\u00f6s\u00b7sern", "freu\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Und mu\u00df ich gleich von ihr/ durchlauchte mutter/ scheiden/", "tokens": ["Und", "mu\u00df", "ich", "gleich", "von", "ihr", "/", "durch\u00b7lauch\u00b7te", "mut\u00b7ter", "/", "schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "APPR", "PPOSAT", "$(", "VVFIN", "NN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So sey ihr doch/ und auch/ frau schwester/ ihr bewust:", "tokens": ["So", "sey", "ihr", "doch", "/", "und", "auch", "/", "frau", "schwes\u00b7ter", "/", "ihr", "be\u00b7wust", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$(", "KON", "ADV", "$(", "ADJD", "ADJD", "$(", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df ich nur sey voran dahin geschritten/", "tokens": ["Da\u00df", "ich", "nur", "sey", "vo\u00b7ran", "da\u00b7hin", "ge\u00b7schrit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ADV", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wo die vergn\u00fcgung uns wird stets zusammen bitten.", "tokens": ["Wo", "die", "ver\u00b7gn\u00fc\u00b7gung", "uns", "wird", "stets", "zu\u00b7sam\u00b7men", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VAFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "9.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Hier lebt man gantz befreyt/", "tokens": ["Hier", "lebt", "man", "gantz", "be\u00b7freyt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von dem/ was zufall pflegt zu heissen.", "tokens": ["Von", "dem", "/", "was", "zu\u00b7fall", "pflegt", "zu", "heis\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PWS", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die steine/ so itzund in meinen haaren gleissen/", "tokens": ["Die", "stei\u00b7ne", "/", "so", "it\u00b7zund", "in", "mei\u00b7nen", "haa\u00b7ren", "gleis\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sind reiner sternen glantz/ und gold der ewigkeit.", "tokens": ["Sind", "rei\u00b7ner", "ster\u00b7nen", "glantz", "/", "und", "gold", "der", "e\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "ADJA", "NN", "$(", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die leibwacht/ die mich hier bestellt ist zu bedienen/", "tokens": ["Die", "leib\u00b7wacht", "/", "die", "mich", "hier", "be\u00b7stellt", "ist", "zu", "be\u00b7die\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "ADV", "VVPP", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sind freunde sonder falsch/ und heissen Seraphinen.", "tokens": ["Sind", "freun\u00b7de", "son\u00b7der", "falsch", "/", "und", "heis\u00b7sen", "Se\u00b7ra\u00b7phi\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "KON", "ADJD", "$(", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "10.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Lebt all\u2019 in guter ruh!", "tokens": ["Lebt", "all'", "in", "gu\u00b7ter", "ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie ihr mir freund und treu im leben;", "tokens": ["Wie", "ihr", "mir", "freund", "und", "treu", "im", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADJD", "KON", "ADJD", "APPRART", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So seyd des k\u00e4ysers huld und GOttes schutz ergeben;", "tokens": ["So", "seyd", "des", "k\u00e4y\u00b7sers", "huld", "und", "Got\u00b7tes", "schutz", "er\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "KON", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Di\u00df bitt\u2019 ich noch von euch: Schliest hinter mir nun zu/", "tokens": ["Di\u00df", "bitt'", "ich", "noch", "von", "euch", ":", "Schliest", "hin\u00b7ter", "mir", "nun", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$.", "VVFIN", "APPR", "PPER", "ADV", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lebt also den kurtzen rest der erden/", "tokens": ["Und", "lebt", "al\u00b7so", "den", "kurt\u00b7zen", "rest", "der", "er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Da\u00df ihr/ wie ich/ gekr\u00f6nt/ von GOtt bekr\u00e4ntzt m\u00f6gt werden.", "tokens": ["Da\u00df", "ihr", "/", "wie", "ich", "/", "ge\u00b7kr\u00f6nt", "/", "von", "Gott", "be\u00b7kr\u00b7\u00e4ntzt", "m\u00f6gt", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "PWAV", "PPER", "$(", "VVPP", "$(", "APPR", "NN", "VVFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}}}}