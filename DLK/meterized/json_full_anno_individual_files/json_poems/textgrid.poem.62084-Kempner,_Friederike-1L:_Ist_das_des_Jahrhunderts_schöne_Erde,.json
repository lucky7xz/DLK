{"textgrid.poem.62084": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ist das des Jahrhunderts sch\u00f6ne Erde,", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist das des Jahrhunderts sch\u00f6ne Erde,", "tokens": ["Ist", "das", "des", "Jahr\u00b7hun\u00b7derts", "sch\u00f6\u00b7ne", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Str\u00f6me Bluts und Berge voller Leichen!", "tokens": ["Str\u00f6\u00b7me", "Bluts", "und", "Ber\u00b7ge", "vol\u00b7ler", "Lei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wird das B\u00f6se nicht dem Guten weichen?", "tokens": ["Wird", "das", "B\u00f6\u00b7se", "nicht", "dem", "Gu\u00b7ten", "wei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "W\u00e4r's nicht Zeit, da\u00df endlich Frieden werde?", "tokens": ["W\u00e4r's", "nicht", "Zeit", ",", "da\u00df", "end\u00b7lich", "Frie\u00b7den", "wer\u00b7de", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "$,", "KOUS", "ADV", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Frevelnd ward der Krieg heraufbeschworen,", "tokens": ["Fre\u00b7velnd", "ward", "der", "Krieg", "her\u00b7auf\u00b7be\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Der Urheber Ansehn ging verloren,", "tokens": ["Der", "Ur\u00b7he\u00b7ber", "An\u00b7sehn", "ging", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ausgek\u00e4mpfet ist der Krieg, genug getan", "tokens": ["Aus\u00b7ge\u00b7k\u00e4mp\u00b7fet", "ist", "der", "Krieg", ",", "ge\u00b7nug", "ge\u00b7tan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,", "ADV", "VVPP"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Ist's an allem, was Europa's Augen sah'n!", "tokens": ["Ist's", "an", "al\u00b7lem", ",", "was", "Eu\u00b7ro\u00b7pa's", "Au\u00b7gen", "sah'n", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PIS", "$,", "PRELS", "NE", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.3": {"line.1": {"text": "Doch nicht Rache will der gro\u00dfe Sieger,", "tokens": ["Doch", "nicht", "Ra\u00b7che", "will", "der", "gro\u00b7\u00dfe", "Sie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "NN", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Menschlich f\u00fchlt der ruhmgekr\u00f6nte Krieger,", "tokens": ["Menschlich", "f\u00fchlt", "der", "ruhm\u00b7ge\u00b7kr\u00f6n\u00b7te", "Krie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Teuer ist ihm seines Volkes Blut,", "tokens": ["Teu\u00b7er", "ist", "ihm", "sei\u00b7nes", "Vol\u00b7kes", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Das vertrauensvoll in seinen H\u00e4nden ruht!", "tokens": ["Das", "ver\u00b7trau\u00b7ens\u00b7voll", "in", "sei\u00b7nen", "H\u00e4n\u00b7den", "ruht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Und die weisen Lehren der Geschichte treten,", "tokens": ["Und", "die", "wei\u00b7sen", "Leh\u00b7ren", "der", "Ge\u00b7schich\u00b7te", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Und das Wort, um das die V\u00f6lker beten,", "tokens": ["Und", "das", "Wort", ",", "um", "das", "die", "V\u00f6l\u00b7ker", "be\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "KOUI", "ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Das Erbarmen, es tritt vor ihn hin,", "tokens": ["Das", "Er\u00b7bar\u00b7men", ",", "es", "tritt", "vor", "ihn", "hin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Leuchtet heute seinem K\u00f6niglichen Sinn!", "tokens": ["Leuch\u00b7tet", "heu\u00b7te", "sei\u00b7nem", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.5": {"line.1": {"text": "Und des Ahnherrn wohlbekannte Sympathien \u2013", "tokens": ["Und", "des", "Ahn\u00b7herrn", "wohl\u00b7be\u00b7kann\u00b7te", "Sym\u00b7pa\u00b7thi\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Unbegr\u00fcndet \u2013 in der Sprache im Gedicht \u2013", "tokens": ["Un\u00b7be\u00b7gr\u00fcn\u00b7det", "\u2013", "in", "der", "Spra\u00b7che", "im", "Ge\u00b7dicht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "APPR", "ART", "NN", "APPRART", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Steigen auf vor seinem Angesicht,", "tokens": ["Stei\u00b7gen", "auf", "vor", "sei\u00b7nem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und des K\u00f6nigs Blicke Segen spr\u00fchen:", "tokens": ["Und", "des", "K\u00f6\u00b7nigs", "Bli\u00b7cke", "Se\u00b7gen", "spr\u00fc\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Wollen aller Welt den Frieden geben,", "tokens": ["Wol\u00b7len", "al\u00b7ler", "Welt", "den", "Frie\u00b7den", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Einen langen Sonntag uns'rem Vaterland,", "tokens": ["Ei\u00b7nen", "lan\u00b7gen", "Sonn\u00b7tag", "un\u00b7s'\u00b7rem", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Das um uns wie Heldenmauer stand, \u2013", "tokens": ["Das", "um", "uns", "wie", "Hel\u00b7den\u00b7mau\u00b7er", "stand", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "APPR", "PPER", "KOKOM", "NN", "VVFIN", "$,", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Und besiegtem Uebermute sei vergeben! \u2013", "tokens": ["Und", "be\u00b7sieg\u00b7tem", "Ue\u00b7ber\u00b7mu\u00b7te", "sei", "ver\u00b7ge\u00b7ben", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.7": {"line.1": {"text": "Ist das des Jahrhunderts sch\u00f6ne Erde,", "tokens": ["Ist", "das", "des", "Jahr\u00b7hun\u00b7derts", "sch\u00f6\u00b7ne", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Str\u00f6me Bluts und Berge voller Leichen!", "tokens": ["Str\u00f6\u00b7me", "Bluts", "und", "Ber\u00b7ge", "vol\u00b7ler", "Lei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wird das B\u00f6se nicht dem Guten weichen?", "tokens": ["Wird", "das", "B\u00f6\u00b7se", "nicht", "dem", "Gu\u00b7ten", "wei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "W\u00e4r's nicht Zeit, da\u00df endlich Frieden werde?", "tokens": ["W\u00e4r's", "nicht", "Zeit", ",", "da\u00df", "end\u00b7lich", "Frie\u00b7den", "wer\u00b7de", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "$,", "KOUS", "ADV", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Frevelnd ward der Krieg heraufbeschworen,", "tokens": ["Fre\u00b7velnd", "ward", "der", "Krieg", "her\u00b7auf\u00b7be\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Der Urheber Ansehn ging verloren,", "tokens": ["Der", "Ur\u00b7he\u00b7ber", "An\u00b7sehn", "ging", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ausgek\u00e4mpfet ist der Krieg, genug getan", "tokens": ["Aus\u00b7ge\u00b7k\u00e4mp\u00b7fet", "ist", "der", "Krieg", ",", "ge\u00b7nug", "ge\u00b7tan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,", "ADV", "VVPP"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Ist's an allem, was Europa's Augen sah'n!", "tokens": ["Ist's", "an", "al\u00b7lem", ",", "was", "Eu\u00b7ro\u00b7pa's", "Au\u00b7gen", "sah'n", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PIS", "$,", "PRELS", "NE", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.9": {"line.1": {"text": "Doch nicht Rache will der gro\u00dfe Sieger,", "tokens": ["Doch", "nicht", "Ra\u00b7che", "will", "der", "gro\u00b7\u00dfe", "Sie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "NN", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Menschlich f\u00fchlt der ruhmgekr\u00f6nte Krieger,", "tokens": ["Menschlich", "f\u00fchlt", "der", "ruhm\u00b7ge\u00b7kr\u00f6n\u00b7te", "Krie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Teuer ist ihm seines Volkes Blut,", "tokens": ["Teu\u00b7er", "ist", "ihm", "sei\u00b7nes", "Vol\u00b7kes", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Das vertrauensvoll in seinen H\u00e4nden ruht!", "tokens": ["Das", "ver\u00b7trau\u00b7ens\u00b7voll", "in", "sei\u00b7nen", "H\u00e4n\u00b7den", "ruht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.10": {"line.1": {"text": "Und die weisen Lehren der Geschichte treten,", "tokens": ["Und", "die", "wei\u00b7sen", "Leh\u00b7ren", "der", "Ge\u00b7schich\u00b7te", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Und das Wort, um das die V\u00f6lker beten,", "tokens": ["Und", "das", "Wort", ",", "um", "das", "die", "V\u00f6l\u00b7ker", "be\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "KOUI", "ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Das Erbarmen, es tritt vor ihn hin,", "tokens": ["Das", "Er\u00b7bar\u00b7men", ",", "es", "tritt", "vor", "ihn", "hin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Leuchtet heute seinem K\u00f6niglichen Sinn!", "tokens": ["Leuch\u00b7tet", "heu\u00b7te", "sei\u00b7nem", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.11": {"line.1": {"text": "Und des Ahnherrn wohlbekannte Sympathien \u2013", "tokens": ["Und", "des", "Ahn\u00b7herrn", "wohl\u00b7be\u00b7kann\u00b7te", "Sym\u00b7pa\u00b7thi\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Unbegr\u00fcndet \u2013 in der Sprache im Gedicht \u2013", "tokens": ["Un\u00b7be\u00b7gr\u00fcn\u00b7det", "\u2013", "in", "der", "Spra\u00b7che", "im", "Ge\u00b7dicht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "APPR", "ART", "NN", "APPRART", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Steigen auf vor seinem Angesicht,", "tokens": ["Stei\u00b7gen", "auf", "vor", "sei\u00b7nem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und des K\u00f6nigs Blicke Segen spr\u00fchen:", "tokens": ["Und", "des", "K\u00f6\u00b7nigs", "Bli\u00b7cke", "Se\u00b7gen", "spr\u00fc\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Wollen aller Welt den Frieden geben,", "tokens": ["Wol\u00b7len", "al\u00b7ler", "Welt", "den", "Frie\u00b7den", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Einen langen Sonntag uns'rem Vaterland,", "tokens": ["Ei\u00b7nen", "lan\u00b7gen", "Sonn\u00b7tag", "un\u00b7s'\u00b7rem", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Das um uns wie Heldenmauer stand, \u2013", "tokens": ["Das", "um", "uns", "wie", "Hel\u00b7den\u00b7mau\u00b7er", "stand", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "APPR", "PPER", "KOKOM", "NN", "VVFIN", "$,", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Und besiegtem Uebermute sei vergeben! \u2013", "tokens": ["Und", "be\u00b7sieg\u00b7tem", "Ue\u00b7ber\u00b7mu\u00b7te", "sei", "ver\u00b7ge\u00b7ben", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}}}}