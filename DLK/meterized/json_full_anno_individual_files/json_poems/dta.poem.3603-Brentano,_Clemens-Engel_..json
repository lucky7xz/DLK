{"dta.poem.3603": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Engel .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519172", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mit der Muschel sch\u00f6pft das B\u00fcblein,               ", "tokens": ["Mit", "der", "Mu\u00b7schel", "sch\u00f6pft", "das", "B\u00fcb\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus dem Meer in ein Sandgr\u00fcblein;", "tokens": ["Aus", "dem", "Meer", "in", "ein", "Sand\u00b7gr\u00fcb\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Augustinus stille stand,", "tokens": ["Au\u00b7gus\u00b7ti\u00b7nus", "stil\u00b7le", "stand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und das Kind zu ihm begann.", "tokens": ["Und", "das", "Kind", "zu", "ihm", "be\u00b7gann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Augustinus, Licht des Glaubens,", "tokens": ["Au\u00b7gus\u00b7ti\u00b7nus", ",", "Licht", "des", "Glau\u00b7bens", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Fromm und rein gleich wie die Tauben;", "tokens": ["Fromm", "und", "rein", "gleich", "wie", "die", "Tau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sag mir an, wo gehst du hin?", "tokens": ["Sag", "mir", "an", ",", "wo", "gehst", "du", "hin", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$,", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Du hast Neues wohl im Sinn.", "tokens": ["Du", "hast", "Neu\u00b7es", "wohl", "im", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Thust vielleicht was Neu's studieren,", "tokens": ["Thust", "viel\u00b7leicht", "was", "Neu's", "stu\u00b7die\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PWS", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder gehst du nur spazieren;", "tokens": ["O\u00b7der", "gehst", "du", "nur", "spa\u00b7zie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Augustinus sag es gleich,", "tokens": ["Au\u00b7gus\u00b7ti\u00b7nus", "sag", "es", "gleich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Sonst ich nicht von dir abweich.", "tokens": ["Sonst", "ich", "nicht", "von", "dir", "ab\u00b7weich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKNEG", "APPR", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Liebes Kind, ich thu betrachten,", "tokens": ["Lie\u00b7bes", "Kind", ",", "ich", "thu", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach und kann doch nimmer fassen,", "tokens": ["Ach", "und", "kann", "doch", "nim\u00b7mer", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KON", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die allerheiligste Dreifaltigkeit", "tokens": ["Die", "al\u00b7ler\u00b7hei\u00b7ligs\u00b7te", "Drei\u00b7fal\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.4": {"text": "Als eine wahre Einigkeit.", "tokens": ["Als", "ei\u00b7ne", "wah\u00b7re", "Ei\u00b7nig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Eh will ich das gro\u00df Weltwasser", "tokens": ["Eh", "will", "ich", "das", "gro\u00df", "Welt\u00b7was\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "ART", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In dies klein Sandgr\u00fcblein fassen;", "tokens": ["In", "dies", "klein", "Sand\u00b7gr\u00fcb\u00b7lein", "fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "ADJD", "NN", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Eh du dir wirst bilden ein,", "tokens": ["Eh", "du", "dir", "wirst", "bil\u00b7den", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie die Sach kann m\u00f6glich sein.", "tokens": ["Wie", "die", "Sach", "kann", "m\u00f6g\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "O wie hoch bin ich geflogen,", "tokens": ["O", "wie", "hoch", "bin", "ich", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie hat mich das Gem\u00fcth betrogen;", "tokens": ["Wie", "hat", "mich", "das", "Ge\u00b7m\u00fcth", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ich nach dem Kindlein sah,", "tokens": ["Als", "ich", "nach", "dem", "Kin\u00b7dlein", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "War es fort, war nicht mehr da.", "tokens": ["War", "es", "fort", ",", "war", "nicht", "mehr", "da", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKVZ", "$,", "VAFIN", "PTKNEG", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Nimmer werd ich so hoch fliegen,", "tokens": ["Nim\u00b7mer", "werd", "ich", "so", "hoch", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-++-++-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Nimmer michs Gem\u00fcth betr\u00fcgen;", "tokens": ["Nim\u00b7mer", "michs", "Ge\u00b7m\u00fcth", "be\u00b7tr\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bis zergehen wird die Erd,", "tokens": ["Bis", "zer\u00b7ge\u00b7hen", "wird", "die", "Erd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich nicht mehr denken werd.", "tokens": ["Und", "ich", "nicht", "mehr", "den\u00b7ken", "werd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "ADV", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}