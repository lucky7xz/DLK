{"textgrid.poem.62290": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "Zur Erinnerung an Herrn Joseph Wolfsohn", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Joseph Wolfsohn ist geschieden,", "tokens": ["Jo\u00b7se\u00b7ph", "Wolf\u00b7sohn", "ist", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Mann von Ehre, h\u00f6h'rem Sinn.", "tokens": ["Mann", "von", "Eh\u00b7re", ",", "h\u00f6h'\u00b7rem", "Sinn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unverstanden bliebst hienieden, \u2013", "tokens": ["Un\u00b7ver\u00b7stan\u00b7den", "bliebst", "hien\u00b7ie\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "ADV", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Joseph Wolfsohn, er ist hin! \u2013", "tokens": ["Jo\u00b7se\u00b7ph", "Wolf\u00b7sohn", ",", "er", "ist", "hin", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "ADV", "$.", "$("], "meter": "+--+---+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Joseph Wolfsohn bist geschieden,", "tokens": ["Jo\u00b7se\u00b7ph", "Wolf\u00b7sohn", "bist", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Fandest keinen Freund hienieden,", "tokens": ["Fan\u00b7dest", "kei\u00b7nen", "Freund", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner Freude traute Spur,", "tokens": ["Kei\u00b7ner", "Freu\u00b7de", "trau\u00b7te", "Spur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebtest traurig einsam nur.", "tokens": ["Leb\u00b7test", "trau\u00b7rig", "ein\u00b7sam", "nur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Festen Muts in jedem St\u00fccke", "tokens": ["Fes\u00b7ten", "Muts", "in", "je\u00b7dem", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fehlte Dir zum eigenen Gl\u00fccke,", "tokens": ["Fehl\u00b7te", "Dir", "zum", "ei\u00b7ge\u00b7nen", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Des Ergreifens rohe Kraft,", "tokens": ["Des", "Er\u00b7grei\u00b7fens", "ro\u00b7he", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Welche eignes Wohl nur schafft. \u2013", "tokens": ["Wel\u00b7che", "eig\u00b7nes", "Wohl", "nur", "schafft", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAT", "ADJA", "NN", "ADV", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bist auch Freimaurer gewesen,", "tokens": ["Bist", "auch", "Frei\u00b7mau\u00b7rer", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "VAPP", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Pyramiden hast gelesen, \u2013", "tokens": ["Py\u00b7ra\u00b7mi\u00b7den", "hast", "ge\u00b7le\u00b7sen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fandest nirgends Gl\u00fcck und Ruh,", "tokens": ["Fan\u00b7dest", "nir\u00b7gends", "Gl\u00fcck", "und", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch ein Menschenfreund warst Du. \u2013", "tokens": ["Doch", "ein", "Men\u00b7schen\u00b7freund", "warst", "Du", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Schon im Glanze Deiner Jugend,", "tokens": ["Schon", "im", "Glan\u00b7ze", "Dei\u00b7ner", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das war das Talent der Tugend,", "tokens": ["Das", "war", "das", "Ta\u00b7lent", "der", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dachtest Du an Gutes tun,", "tokens": ["Dach\u00b7test", "Du", "an", "Gu\u00b7tes", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es lie\u00df Dich nimmer ruh'n.", "tokens": ["Und", "es", "lie\u00df", "Dich", "nim\u00b7mer", "ruh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und Dein Name lebt f\u00fcr immer", "tokens": ["Und", "Dein", "Na\u00b7me", "lebt", "f\u00fcr", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Edel, einfach ohne Schimmer", "tokens": ["E\u00b7del", ",", "ein\u00b7fach", "oh\u00b7ne", "Schim\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hast Du Segen ausgestreut", "tokens": ["Hast", "Du", "Se\u00b7gen", "aus\u00b7ge\u00b7streut"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Dein Beispiel ihn erneut.", "tokens": ["Und", "Dein", "Bei\u00b7spiel", "ihn", "er\u00b7neut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Freue Dich in jenen Sph\u00e4ren,", "tokens": ["Freu\u00b7e", "Dich", "in", "je\u00b7nen", "Sph\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wirkest fort im Licht und Glanz,", "tokens": ["Wir\u00b7kest", "fort", "im", "Licht", "und", "Glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dort empf\u00e4ngt man Dich mit Ehren", "tokens": ["Dort", "emp\u00b7f\u00e4ngt", "man", "Dich", "mit", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit einem Lorbeerkranz.", "tokens": ["Und", "mit", "ei\u00b7nem", "Lor\u00b7beer\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Joseph Wolfsohn ist geschieden,", "tokens": ["Jo\u00b7se\u00b7ph", "Wolf\u00b7sohn", "ist", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Mann von Ehre, h\u00f6h'rem Sinn.", "tokens": ["Mann", "von", "Eh\u00b7re", ",", "h\u00f6h'\u00b7rem", "Sinn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unverstanden bliebst hienieden, \u2013", "tokens": ["Un\u00b7ver\u00b7stan\u00b7den", "bliebst", "hien\u00b7ie\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "ADV", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Joseph Wolfsohn, er ist hin! \u2013", "tokens": ["Jo\u00b7se\u00b7ph", "Wolf\u00b7sohn", ",", "er", "ist", "hin", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "ADV", "$.", "$("], "meter": "+--+---+", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "Joseph Wolfsohn bist geschieden,", "tokens": ["Jo\u00b7se\u00b7ph", "Wolf\u00b7sohn", "bist", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Fandest keinen Freund hienieden,", "tokens": ["Fan\u00b7dest", "kei\u00b7nen", "Freund", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner Freude traute Spur,", "tokens": ["Kei\u00b7ner", "Freu\u00b7de", "trau\u00b7te", "Spur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebtest traurig einsam nur.", "tokens": ["Leb\u00b7test", "trau\u00b7rig", "ein\u00b7sam", "nur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Festen Muts in jedem St\u00fccke", "tokens": ["Fes\u00b7ten", "Muts", "in", "je\u00b7dem", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fehlte Dir zum eigenen Gl\u00fccke,", "tokens": ["Fehl\u00b7te", "Dir", "zum", "ei\u00b7ge\u00b7nen", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Des Ergreifens rohe Kraft,", "tokens": ["Des", "Er\u00b7grei\u00b7fens", "ro\u00b7he", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Welche eignes Wohl nur schafft. \u2013", "tokens": ["Wel\u00b7che", "eig\u00b7nes", "Wohl", "nur", "schafft", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAT", "ADJA", "NN", "ADV", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Bist auch Freimaurer gewesen,", "tokens": ["Bist", "auch", "Frei\u00b7mau\u00b7rer", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "VAPP", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Pyramiden hast gelesen, \u2013", "tokens": ["Py\u00b7ra\u00b7mi\u00b7den", "hast", "ge\u00b7le\u00b7sen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fandest nirgends Gl\u00fcck und Ruh,", "tokens": ["Fan\u00b7dest", "nir\u00b7gends", "Gl\u00fcck", "und", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch ein Menschenfreund warst Du. \u2013", "tokens": ["Doch", "ein", "Men\u00b7schen\u00b7freund", "warst", "Du", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Schon im Glanze Deiner Jugend,", "tokens": ["Schon", "im", "Glan\u00b7ze", "Dei\u00b7ner", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das war das Talent der Tugend,", "tokens": ["Das", "war", "das", "Ta\u00b7lent", "der", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dachtest Du an Gutes tun,", "tokens": ["Dach\u00b7test", "Du", "an", "Gu\u00b7tes", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es lie\u00df Dich nimmer ruh'n.", "tokens": ["Und", "es", "lie\u00df", "Dich", "nim\u00b7mer", "ruh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und Dein Name lebt f\u00fcr immer", "tokens": ["Und", "Dein", "Na\u00b7me", "lebt", "f\u00fcr", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Edel, einfach ohne Schimmer", "tokens": ["E\u00b7del", ",", "ein\u00b7fach", "oh\u00b7ne", "Schim\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hast Du Segen ausgestreut", "tokens": ["Hast", "Du", "Se\u00b7gen", "aus\u00b7ge\u00b7streut"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Dein Beispiel ihn erneut.", "tokens": ["Und", "Dein", "Bei\u00b7spiel", "ihn", "er\u00b7neut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Freue Dich in jenen Sph\u00e4ren,", "tokens": ["Freu\u00b7e", "Dich", "in", "je\u00b7nen", "Sph\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wirkest fort im Licht und Glanz,", "tokens": ["Wir\u00b7kest", "fort", "im", "Licht", "und", "Glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dort empf\u00e4ngt man Dich mit Ehren", "tokens": ["Dort", "emp\u00b7f\u00e4ngt", "man", "Dich", "mit", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit einem Lorbeerkranz.", "tokens": ["Und", "mit", "ei\u00b7nem", "Lor\u00b7beer\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}