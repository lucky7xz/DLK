{"textgrid.poem.41508": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Die Vogelh\u00fctte", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Regen, Regen, immer Regen! will nicht das Gepl\u00e4tscher enden,", "tokens": ["Re\u00b7gen", ",", "Re\u00b7gen", ",", "im\u00b7mer", "Re\u00b7gen", "!", "will", "nicht", "das", "Ge\u00b7pl\u00e4t\u00b7scher", "en\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADV", "NN", "$.", "VMFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df ich aus dem Sarge brechen kann, aus diesen Bretterw\u00e4nden?", "tokens": ["Da\u00df", "ich", "aus", "dem", "Sar\u00b7ge", "bre\u00b7chen", "kann", ",", "aus", "die\u00b7sen", "Bret\u00b7ter\u00b7w\u00e4n\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "VMFIN", "$,", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.2": {"line.1": {"text": "Sieben Schuhe ins Gevierte, das ist doch ein \u00e4rmlich R\u00e4umchen", "tokens": ["Sie\u00b7ben", "Schu\u00b7he", "ins", "Ge\u00b7vier\u00b7te", ",", "das", "ist", "doch", "ein", "\u00e4rm\u00b7lich", "R\u00e4um\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "APPRART", "NN", "$,", "PDS", "VAFIN", "ADV", "ART", "ADJD", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "F\u00fcr ein Menschenkind, und w\u00e4r' es schlank auch wie ein Rosenb\u00e4umchen!", "tokens": ["F\u00fcr", "ein", "Men\u00b7schen\u00b7kind", ",", "und", "w\u00e4r'", "es", "schlank", "auch", "wie", "ein", "Ro\u00b7sen\u00b7b\u00e4um\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KON", "VAFIN", "PPER", "VVFIN", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.3": {"line.1": {"text": "O was lie\u00df ich mich gel\u00fcsten, in den Vogelherd zu fl\u00fcchten,", "tokens": ["O", "was", "lie\u00df", "ich", "mich", "ge\u00b7l\u00fcs\u00b7ten", ",", "in", "den", "Vo\u00b7gel\u00b7herd", "zu", "fl\u00fcch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "PRF", "VVPP", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Als nur schwach die Wolke tropfte, als noch fl\u00fcsterten die Fichten:", "tokens": ["Als", "nur", "schwach", "die", "Wol\u00b7ke", "tropf\u00b7te", ",", "als", "noch", "fl\u00fcs\u00b7ter\u00b7ten", "die", "Fich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ART", "NN", "VVFIN", "$,", "KOUS", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.4": {"line.1": {"text": "Und mu\u00df nun bestehn das Ganze, wie wenn z\u00f6gernd man dem Schw\u00e4tzer", "tokens": ["Und", "mu\u00df", "nun", "be\u00b7stehn", "das", "Gan\u00b7ze", ",", "wie", "wenn", "z\u00f6\u00b7gernd", "man", "dem", "Schw\u00e4t\u00b7zer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "ART", "NN", "$,", "KOKOM", "KOUS", "ADJD", "PIS", "ART", "NN"], "meter": "+---+-+-+-+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Raum gegeben, dem langweilig Seile drehnden Phrasensetzer;", "tokens": ["Raum", "ge\u00b7ge\u00b7ben", ",", "dem", "lang\u00b7wei\u00b7lig", "Sei\u00b7le", "drehn\u00b7den", "Phra\u00b7sen\u00b7set\u00b7zer", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "ADJD", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.5": {"line.1": {"text": "Und am Knopfe nun gehalten, oder schlimmer an den H\u00e4nden,", "tokens": ["Und", "am", "Knop\u00b7fe", "nun", "ge\u00b7hal\u00b7ten", ",", "o\u00b7der", "schlim\u00b7mer", "an", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "VVPP", "$,", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Zappelnd wie der Halbgeh\u00e4ngte langet nach des Strickes Enden!", "tokens": ["Zap\u00b7pelnd", "wie", "der", "Halb\u00b7ge\u00b7h\u00e4ng\u00b7te", "lan\u00b7get", "nach", "des", "Stri\u00b7ckes", "En\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.6": {"line.1": {"text": "Meine Ungl\u00fccksstrick' sind dieser Wasserstriemen L\u00e4ng' und Breite,", "tokens": ["Mei\u00b7ne", "Un\u00b7gl\u00fcckss\u00b7trick'", "sind", "die\u00b7ser", "Was\u00b7ser\u00b7strie\u00b7men", "L\u00e4ng'", "und", "Brei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PDAT", "NN", "NE", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Die verk\u00f6rperten Hyperbeln, denn Bindf\u00e4den regnet's heute.", "tokens": ["Die", "ver\u00b7k\u00f6r\u00b7per\u00b7ten", "Hy\u00b7per\u00b7beln", ",", "denn", "Bind\u00b7f\u00e4\u00b7den", "reg\u00b7net's", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "--+---+--++-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Denk' ich an die heitre Stube, an das weiche Kanapee,", "tokens": ["Denk'", "ich", "an", "die", "heit\u00b7re", "Stu\u00b7be", ",", "an", "das", "wei\u00b7che", "Ka\u00b7na\u00b7pee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und wie mein Gedicht, das meine, dort zerlesen wird beim Tee:", "tokens": ["Und", "wie", "mein", "Ge\u00b7dicht", ",", "das", "mei\u00b7ne", ",", "dort", "zer\u00b7le\u00b7sen", "wird", "beim", "Tee", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "$,", "ADV", "VVPP", "VAFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.8": {"line.1": {"text": "Denk' ich an die schwere Zunge, die statt meiner es zerdrischt,", "tokens": ["Denk'", "ich", "an", "die", "schwe\u00b7re", "Zun\u00b7ge", ",", "die", "statt", "mei\u00b7ner", "es", "zer\u00b7drischt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "PPOSAT", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Bohrend wie ein Schwertfisch m\u00f6cht' ich schie\u00dfen in den Wassergischt.", "tokens": ["Boh\u00b7rend", "wie", "ein", "Schwert\u00b7fisch", "m\u00f6cht'", "ich", "schie\u00b7\u00dfen", "in", "den", "Was\u00b7ser\u00b7gischt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.9": {"line.1": {"text": "Pah! was k\u00fcmmern mich die Tropfen, ob ich na\u00df ob s\u00e4uberlich!", "tokens": ["Pah", "!", "was", "k\u00fcm\u00b7mern", "mich", "die", "Trop\u00b7fen", ",", "ob", "ich", "na\u00df", "ob", "s\u00e4u\u00b7ber\u00b7lich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "ADJD", "KOUS", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Aber besser stramm und trocken, als durchn\u00e4\u00dft und l\u00e4cherlich.", "tokens": ["A\u00b7ber", "bes\u00b7ser", "stramm", "und", "tro\u00b7cken", ",", "als", "durc\u00b7hn\u00e4\u00dft", "und", "l\u00e4\u00b7cher\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "KON", "ADJD", "$,", "KOUS", "VVFIN", "KON", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.10": {"line.1": {"text": "Da \u2013 ein Fleck, ein Loch am Himmel; bist du endlich doch gebrochen,", "tokens": ["Da", "\u2013", "ein", "Fleck", ",", "ein", "Loch", "am", "Him\u00b7mel", ";", "bist", "du", "end\u00b7lich", "doch", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$.", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Alte Wassertonne, hab' ich endlich dich entzwei gesprochen?", "tokens": ["Al\u00b7te", "Was\u00b7ser\u00b7ton\u00b7ne", ",", "hab'", "ich", "end\u00b7lich", "dich", "ent\u00b7zwei", "ge\u00b7spro\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VAFIN", "PPER", "ADV", "PPER", "PTKVZ", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.11": {"line.1": {"text": "Aber wehe! wie's vom Fasse brodelt, wenn gesprengt der Zapfen,", "tokens": ["A\u00b7ber", "we\u00b7he", "!", "wie's", "vom", "Fas\u00b7se", "bro\u00b7delt", ",", "wenn", "ge\u00b7sprengt", "der", "Zap\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "VVFIN", "APPRART", "NN", "VVFIN", "$,", "KOUS", "VVPP", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "H\u00f6r' ich's auf dem Dache rasseln, f\u00f6rmlich wie mit F\u00fc\u00dfen stapfen.", "tokens": ["H\u00f6r'", "ich's", "auf", "dem", "Da\u00b7che", "ras\u00b7seln", ",", "f\u00f6rm\u00b7lich", "wie", "mit", "F\u00fc\u00b7\u00dfen", "stap\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "VVINF", "$,", "ADJD", "KOKOM", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.12": {"line.1": {"text": "Regen! unbarmherz'ger Regen! m\u00f6gst du braten oder sieden!", "tokens": ["Re\u00b7gen", "!", "un\u00b7barm\u00b7her\u00b7z'\u00b7ger", "Re\u00b7gen", "!", "m\u00f6gst", "du", "bra\u00b7ten", "o\u00b7der", "sie\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADJA", "NN", "$.", "VMFIN", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.invert"}, "line.2": {"text": "Wehe, diese alte Kufe ist das Fa\u00df der Danaiden!", "tokens": ["We\u00b7he", ",", "die\u00b7se", "al\u00b7te", "Ku\u00b7fe", "ist", "das", "Fa\u00df", "der", "Da\u00b7na\u00b7i\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDAT", "ADJA", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.13": {"line.1": {"text": "Ich habe mich gesetzt in Gottes Namen;", "tokens": ["Ich", "ha\u00b7be", "mich", "ge\u00b7setzt", "in", "Got\u00b7tes", "Na\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es hilft doch alles nicht, und mein Gedicht", "tokens": ["Es", "hilft", "doch", "al\u00b7les", "nicht", ",", "und", "mein", "Ge\u00b7dicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "PTKNEG", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist l\u00e4ngst gelesen und im Schlo\u00df die Damen,", "tokens": ["Ist", "l\u00e4ngst", "ge\u00b7le\u00b7sen", "und", "im", "Schlo\u00df", "die", "Da\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "KON", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie sa\u00dfen lange zu Gericht.", "tokens": ["Sie", "sa\u00b7\u00dfen", "lan\u00b7ge", "zu", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Statt einen neuen Lorbeerkranz zu dr\u00fccken", "tokens": ["Statt", "ei\u00b7nen", "neu\u00b7en", "Lor\u00b7beer\u00b7kranz", "zu", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In meine Ph\u00f6boslocken, hat man sacht", "tokens": ["In", "mei\u00b7ne", "Ph\u00f6\u00b7bos\u00b7lo\u00b7cken", ",", "hat", "man", "sacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VAFIN", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den alten losgezupft und hinterm R\u00fccken", "tokens": ["Den", "al\u00b7ten", "los\u00b7ge\u00b7zupft", "und", "hin\u00b7term", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVPP", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wohl Eselsohren mir gemacht.", "tokens": ["Wohl", "E\u00b7sel\u00b7soh\u00b7ren", "mir", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Verkannte Seele, fasse dich im Leiden,", "tokens": ["Ver\u00b7kann\u00b7te", "See\u00b7le", ",", "fas\u00b7se", "dich", "im", "Lei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sei stark, sei nobel, denk, der Ruhm ist leer,", "tokens": ["Sei", "stark", ",", "sei", "no\u00b7bel", ",", "denk", ",", "der", "Ruhm", "ist", "leer", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "VAFIN", "ADJD", "$,", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Leben kurz, es wechseln Schmerz und Freuden,", "tokens": ["Das", "Le\u00b7ben", "kurz", ",", "es", "wech\u00b7seln", "Schmerz", "und", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und was dergleichen Neugedachtes mehr!", "tokens": ["Und", "was", "derg\u00b7lei\u00b7chen", "Neu\u00b7ge\u00b7dach\u00b7tes", "mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Ich schau mich um in meiner kleinen Zelle:", "tokens": ["Ich", "schau", "mich", "um", "in", "mei\u00b7ner", "klei\u00b7nen", "Zel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr einen Klausner w\u00e4r's ein h\u00fcbscher Ort;", "tokens": ["F\u00fcr", "ei\u00b7nen", "Klaus\u00b7ner", "w\u00e4r's", "ein", "h\u00fcb\u00b7scher", "Ort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Bank, der Tisch, das h\u00f6lzerne Gestelle,", "tokens": ["Die", "Bank", ",", "der", "Tisch", ",", "das", "h\u00f6l\u00b7zer\u00b7ne", "Ge\u00b7stel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und an der Wand die Tasche dort;", "tokens": ["Und", "an", "der", "Wand", "die", "Ta\u00b7sche", "dort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ein Netz im Winkelchen, ein Rechen, Spaten \u2013", "tokens": ["Ein", "Netz", "im", "Win\u00b7kel\u00b7chen", ",", "ein", "Re\u00b7chen", ",", "Spa\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "$,", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Betten? nun, das macht sich einfach hier;", "tokens": ["Und", "Bet\u00b7ten", "?", "nun", ",", "das", "macht", "sich", "ein\u00b7fach", "hier", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "ADV", "$,", "PDS", "VVFIN", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Thimian ist heuer gut geraten,", "tokens": ["Der", "Thi\u00b7mi\u00b7an", "ist", "heu\u00b7er", "gut", "ge\u00b7ra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und bl\u00fcht mir grade vor der T\u00fcr.", "tokens": ["Und", "bl\u00fcht", "mir", "gra\u00b7de", "vor", "der", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Die Waldung dr\u00fcben \u2013 und das Quellgew\u00e4sser \u2013", "tokens": ["Die", "Wal\u00b7dung", "dr\u00fc\u00b7ben", "\u2013", "und", "das", "Quell\u00b7ge\u00b7w\u00e4s\u00b7ser", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hier m\u00f6cht' ich Heidebilder schreiben, zum Exempel:", "tokens": ["Hier", "m\u00f6cht'", "ich", "Hei\u00b7de\u00b7bil\u00b7der", "schrei\u00b7ben", ",", "zum", "Ex\u00b7em\u00b7pel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "VVINF", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbdie Vogelh\u00fctte\u00ab, nein \u2013 \u00bbder Herd\u00ab, nein besser:", "tokens": ["\u00bb", "die", "Vo\u00b7gel\u00b7h\u00fct\u00b7te", "\u00ab", ",", "nein", "\u2013", "\u00bb", "der", "Herd", "\u00ab", ",", "nein", "bes\u00b7ser", ":"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "$,", "PTKANT", "$(", "$(", "ART", "NN", "$(", "$,", "PTKANT", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbder Knieende in Gottes weitem Tempel.\u00ab", "tokens": ["\u00bb", "der", "Kni\u00b7e\u00b7en\u00b7de", "in", "Got\u00b7tes", "wei\u00b7tem", "Tem\u00b7pel", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "'s ist doch romantisch, wenn ein zart Geriesel", "tokens": ["'s", "ist", "doch", "ro\u00b7man\u00b7tisch", ",", "wenn", "ein", "zart", "Ge\u00b7rie\u00b7sel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "ART", "ADJD", "NN"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Durch Immortellen und Wacholderstrauch", "tokens": ["Durch", "Im\u00b7mor\u00b7tel\u00b7len", "und", "Wa\u00b7chol\u00b7der\u00b7strauch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Umzieht und gleitet, wie ein schl\u00fcpfend Wiesel,", "tokens": ["Um\u00b7zieht", "und", "glei\u00b7tet", ",", "wie", "ein", "schl\u00fcp\u00b7fend", "Wie\u00b7sel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PWAV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und dr\u00fcber flirrt der St\u00f6berrauch;", "tokens": ["Und", "dr\u00fc\u00b7ber", "flirrt", "der", "St\u00f6\u00b7berr\u00b7auch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Wenn Schimmer wechseln, wei\u00df und seladonen;", "tokens": ["Wenn", "Schim\u00b7mer", "wech\u00b7seln", ",", "wei\u00df", "und", "se\u00b7la\u00b7do\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$,", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die weite Ebne schaukelt wie ein Schiff,", "tokens": ["Die", "wei\u00b7te", "Eb\u00b7ne", "schau\u00b7kelt", "wie", "ein", "Schiff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hindurch der Kiebitz schrillt, wie Halkyonen", "tokens": ["Hin\u00b7durch", "der", "Kie\u00b7bitz", "schrillt", ",", "wie", "Hal\u00b7ky\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wehklagend ziehen um das Riff.", "tokens": ["Weh\u00b7kla\u00b7gend", "zie\u00b7hen", "um", "das", "Riff", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Am Horizont die kolossalen Br\u00fccken \u2013", "tokens": ["Am", "Ho\u00b7ri\u00b7zont", "die", "ko\u00b7los\u00b7sa\u00b7len", "Br\u00fc\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sind's Wolken oder ist's ein ferner Wald?", "tokens": ["Sin\u00b7d's", "Wol\u00b7ken", "o\u00b7der", "ist's", "ein", "fer\u00b7ner", "Wald", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ich will den Schemel an die Luke r\u00fccken,", "tokens": ["Ich", "will", "den", "Sche\u00b7mel", "an", "die", "Lu\u00b7ke", "r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da liegt mein Hut, mein Hammer, \u2013 halt:", "tokens": ["Da", "liegt", "mein", "Hut", ",", "mein", "Ham\u00b7mer", ",", "\u2013", "halt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "$(", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Ein Teller am Gestell! \u2013 was mag er bieten?", "tokens": ["Ein", "Tel\u00b7ler", "am", "Ge\u00b7stell", "!", "\u2013", "was", "mag", "er", "bie\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Fundus! bei Gott, ein Fund die Brezel drin!", "tokens": ["Fun\u00b7dus", "!", "bei", "Gott", ",", "ein", "Fund", "die", "Bre\u00b7zel", "drin", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "NN", "$,", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "F\u00fcr einen armen Hund von Eremiten,", "tokens": ["F\u00fcr", "ei\u00b7nen", "ar\u00b7men", "Hund", "von", "E\u00b7re\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie ich es leider heute bin!", "tokens": ["Wie", "ich", "es", "lei\u00b7der", "heu\u00b7te", "bin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Ein seidner Beutel noch \u2013 am Bort zerrissen;", "tokens": ["Ein", "seid\u00b7ner", "Beu\u00b7tel", "noch", "\u2013", "am", "Bort", "zer\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "$(", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich greife, greife Rundes mit der Hand;", "tokens": ["Ich", "grei\u00b7fe", ",", "grei\u00b7fe", "Run\u00b7des", "mit", "der", "Hand", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Weh! in die d\u00fcrre Erbs' hab' ich gebissen \u2013", "tokens": ["Weh", "!", "in", "die", "d\u00fcr\u00b7re", "Erbs'", "hab'", "ich", "ge\u00b7bis\u00b7sen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich dacht', es seie Zuckerkand.", "tokens": ["Ich", "dacht'", ",", "es", "sei\u00b7e", "Zu\u00b7cker\u00b7kand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Und nun die Tasche! he, wir m\u00fcssen klopfen \u2013", "tokens": ["Und", "nun", "die", "Ta\u00b7sche", "!", "he", ",", "wir", "m\u00fcs\u00b7sen", "klop\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "NE", "$,", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vielleicht liegt ein Gefangner hier in Haft;", "tokens": ["Viel\u00b7leicht", "liegt", "ein", "Ge\u00b7fang\u00b7ner", "hier", "in", "Haft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da \u2013 eine Flasche! schnell herab den Pfropfen \u2013", "tokens": ["Da", "\u2013", "ei\u00b7ne", "Fla\u00b7sche", "!", "schnell", "her\u00b7ab", "den", "Pfrop\u00b7fen", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ART", "NN", "$.", "ADJD", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist's Wasser? Wasser? \u2013 edler Rebensaft!", "tokens": ["Ist's", "Was\u00b7ser", "?", "Was\u00b7ser", "?", "\u2013", "ed\u00b7ler", "Re\u00b7ben\u00b7saft", "!"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "NN", "$.", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Und Edlerer, der ihn dem Sack vertraute,", "tokens": ["Und", "Ed\u00b7le\u00b7rer", ",", "der", "ihn", "dem", "Sack", "ver\u00b7trau\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Splendid barmherziger Wildh\u00fcter du,", "tokens": ["Splen\u00b7did", "barm\u00b7her\u00b7zi\u00b7ger", "Wild\u00b7h\u00fc\u00b7ter", "du", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PPER", "$,"], "meter": "+--+--++-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "F\u00fcr einen armen Schelm, der Erbsen kaute,", "tokens": ["F\u00fcr", "ei\u00b7nen", "ar\u00b7men", "Schelm", ",", "der", "Erb\u00b7sen", "kau\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den frommen Bruder Tuck im Ivanhoe!", "tokens": ["Den", "from\u00b7men", "Bru\u00b7der", "Tuck", "im", "I\u00b7van\u00b7hoe", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Mit dem Gek\u00f6rn will ich den Kiebitz letzen,", "tokens": ["Mit", "dem", "Ge\u00b7k\u00f6rn", "will", "ich", "den", "Kie\u00b7bitz", "let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es aus der L\u00fccke streun, wenn er im Flug", "tokens": ["Es", "aus", "der", "L\u00fc\u00b7cke", "streun", ",", "wenn", "er", "im", "Flug"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "VVINF", "$,", "KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Herschwirrt, mir auf die Schulter sich zu setzen,", "tokens": ["Her\u00b7schwirrt", ",", "mir", "auf", "die", "Schul\u00b7ter", "sich", "zu", "set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "APPR", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie man es liest in manchem Buch.", "tokens": ["Wie", "man", "es", "liest", "in", "man\u00b7chem", "Buch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Mir ist ganz wohl in meiner armen Zelle;", "tokens": ["Mir", "ist", "ganz", "wohl", "in", "mei\u00b7ner", "ar\u00b7men", "Zel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie mir das Klausnerleben so gef\u00e4llt!", "tokens": ["Wie", "mir", "das", "Klaus\u00b7ner\u00b7le\u00b7ben", "so", "ge\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bleibe hier, ich geh nicht von der Stelle,", "tokens": ["Ich", "blei\u00b7be", "hier", ",", "ich", "geh", "nicht", "von", "der", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bevor der letzte Tropfen f\u00e4llt.", "tokens": ["Be\u00b7vor", "der", "letz\u00b7te", "Trop\u00b7fen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Es verrieselt, es verraucht,", "tokens": ["Es", "ver\u00b7rie\u00b7selt", ",", "es", "ver\u00b7raucht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "M\u00e4hlich aus der Wolke taucht", "tokens": ["M\u00e4h\u00b7lich", "aus", "der", "Wol\u00b7ke", "taucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Neu hervor der Sonnenadel.", "tokens": ["Neu", "her\u00b7vor", "der", "Son\u00b7ne\u00b7na\u00b7del", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In den feinen Dunst die Fichte", "tokens": ["In", "den", "fei\u00b7nen", "Dunst", "die", "Fich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihre gr\u00fcnen Dornen streckt,", "tokens": ["Ih\u00b7re", "gr\u00fc\u00b7nen", "Dor\u00b7nen", "streckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie ein sch\u00f6nes Weib die Nadel", "tokens": ["Wie", "ein", "sch\u00f6\u00b7nes", "Weib", "die", "Na\u00b7del"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "In den Spitzenschleier steckt;", "tokens": ["In", "den", "Spit\u00b7zen\u00b7schlei\u00b7er", "steckt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und die Heide steht im Lichte", "tokens": ["Und", "die", "Hei\u00b7de", "steht", "im", "Lich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Zahllos blanker Tropfen, die", "tokens": ["Zahl\u00b7los", "blan\u00b7ker", "Trop\u00b7fen", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADJD", "ADJA", "NN", "$,", "PRELS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Am Wacholder zittern, wie", "tokens": ["Am", "Wa\u00b7chol\u00b7der", "zit\u00b7tern", ",", "wie"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PWAV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Glasgeh\u00e4nge an dem L\u00fcster.", "tokens": ["Glas\u00b7ge\u00b7h\u00e4n\u00b7ge", "an", "dem", "L\u00fcs\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "\u00dcberm Grund geht ein Gefl\u00fcster,", "tokens": ["\u00dc\u00b7berm", "Grund", "geht", "ein", "Ge\u00b7fl\u00fcs\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Jedes Kr\u00e4utchen reckt sich auf,", "tokens": ["Je\u00b7des", "Kr\u00e4ut\u00b7chen", "reckt", "sich", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Und in langgestrecktem Lauf,", "tokens": ["Und", "in", "lang\u00b7ge\u00b7streck\u00b7tem", "Lauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Durch den Sand des Pfades eilend,", "tokens": ["Durch", "den", "Sand", "des", "Pfa\u00b7des", "ei\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Blitzt das goldne Panzerhemd", "tokens": ["Blitzt", "das", "gold\u00b7ne", "Pan\u00b7zer\u00b7hemd"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Des Kuriers;", "tokens": ["Des", "Ku\u00b7riers", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.18": {"text": "Streicht die Grille sich das Na\u00df", "tokens": ["Streicht", "die", "Gril\u00b7le", "sich", "das", "Na\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PRF", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Von der Fl\u00fcgel gr\u00fcnem Glas.", "tokens": ["Von", "der", "Fl\u00fc\u00b7gel", "gr\u00fc\u00b7nem", "Glas", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "Grashalm gl\u00e4nzt wie eine Klinge,", "tokens": ["Gras\u00b7halm", "gl\u00e4nzt", "wie", "ei\u00b7ne", "Klin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Und die kleinen Schmetterlinge,", "tokens": ["Und", "die", "klei\u00b7nen", "Schmet\u00b7ter\u00b7lin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Blau, orange, gelb und wei\u00df,", "tokens": ["Blau", ",", "o\u00b7ran\u00b7ge", ",", "gelb", "und", "wei\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.23": {"text": "Jagen tummelnd sich im Kreis.", "tokens": ["Ja\u00b7gen", "tum\u00b7melnd", "sich", "im", "Kreis", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Alles Schimmer, alles Licht,", "tokens": ["Al\u00b7les", "Schim\u00b7mer", ",", "al\u00b7les", "Licht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.25": {"text": "Bergwald mag und Welle nicht", "tokens": ["Berg\u00b7wald", "mag", "und", "Wel\u00b7le", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "KON", "NN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.26": {"text": "Solche Farbent\u00f6ne hegen,", "tokens": ["Sol\u00b7che", "Far\u00b7ben\u00b7t\u00f6\u00b7ne", "he\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.27": {"text": "Wie die Heide nach dem Regen.", "tokens": ["Wie", "die", "Hei\u00b7de", "nach", "dem", "Re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Ein Schall \u2013 und wieder \u2013 wieder \u2013 was ist das? \u2013", "tokens": ["Ein", "Schall", "\u2013", "und", "wie\u00b7der", "\u2013", "wie\u00b7der", "\u2013", "was", "ist", "das", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "KON", "ADV", "$(", "ADV", "$(", "PWS", "VAFIN", "PDS", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bei Gott, das Schlo\u00df! Da schl\u00e4gt es acht im Turme \u2013", "tokens": ["Bei", "Gott", ",", "das", "Schlo\u00df", "!", "Da", "schl\u00e4gt", "es", "acht", "im", "Tur\u00b7me", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "CARD", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weh mein Gedicht! o weh mir armem Wurme,", "tokens": ["Weh", "mein", "Ge\u00b7dicht", "!", "o", "weh", "mir", "ar\u00b7mem", "Wur\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$.", "FM", "ADV", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nun f\u00e4llt mir alles ein, was ich verga\u00df!", "tokens": ["Nun", "f\u00e4llt", "mir", "al\u00b7les", "ein", ",", "was", "ich", "ver\u00b7ga\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PTKVZ", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mein Hut, mein Hammer, hurtig fortgetrabt \u2013", "tokens": ["Mein", "Hut", ",", "mein", "Ham\u00b7mer", ",", "hur\u00b7tig", "fort\u00b7ge\u00b7trabt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Vielleicht, vielleicht ist man diskret gewesen,", "tokens": ["Viel\u00b7leicht", ",", "viel\u00b7leicht", "ist", "man", "dis\u00b7kret", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VAFIN", "PIS", "VVFIN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und harrte meiner, der sein Federlesen", "tokens": ["Und", "harr\u00b7te", "mei\u00b7ner", ",", "der", "sein", "Fe\u00b7der\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Indes mit Kraut und W\u00fcrmern hat gehabt. \u2013", "tokens": ["In\u00b7des", "mit", "Kraut", "und", "W\u00fcr\u00b7mern", "hat", "ge\u00b7habt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "VAFIN", "VAPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Nun k\u00f6mmt der Steg und nun des Teiches Ried,", "tokens": ["Nun", "k\u00f6mmt", "der", "Steg", "und", "nun", "des", "Tei\u00b7ches", "Ried", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Nun steigen der Alleen schlanke Streifen;", "tokens": ["Nun", "stei\u00b7gen", "der", "Al\u00b7leen", "schlan\u00b7ke", "Strei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ich wei\u00df es nicht, ich kann es nicht begreifen,", "tokens": ["Ich", "wei\u00df", "es", "nicht", ",", "ich", "kann", "es", "nicht", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wie ich so g\u00e4nzlich mich vom Leben schied \u2013", "tokens": ["Wie", "ich", "so", "g\u00e4nz\u00b7lich", "mich", "vom", "Le\u00b7ben", "schied", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "PPER", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Doch freilich \u2013 damals war ich Eremit!", "tokens": ["Doch", "frei\u00b7lich", "\u2013", "da\u00b7mals", "war", "ich", "E\u00b7re\u00b7mit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Regen, Regen, immer Regen! will nicht das Gepl\u00e4tscher enden,", "tokens": ["Re\u00b7gen", ",", "Re\u00b7gen", ",", "im\u00b7mer", "Re\u00b7gen", "!", "will", "nicht", "das", "Ge\u00b7pl\u00e4t\u00b7scher", "en\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADV", "NN", "$.", "VMFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df ich aus dem Sarge brechen kann, aus diesen Bretterw\u00e4nden?", "tokens": ["Da\u00df", "ich", "aus", "dem", "Sar\u00b7ge", "bre\u00b7chen", "kann", ",", "aus", "die\u00b7sen", "Bret\u00b7ter\u00b7w\u00e4n\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "VMFIN", "$,", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.31": {"line.1": {"text": "Sieben Schuhe ins Gevierte, das ist doch ein \u00e4rmlich R\u00e4umchen", "tokens": ["Sie\u00b7ben", "Schu\u00b7he", "ins", "Ge\u00b7vier\u00b7te", ",", "das", "ist", "doch", "ein", "\u00e4rm\u00b7lich", "R\u00e4um\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "APPRART", "NN", "$,", "PDS", "VAFIN", "ADV", "ART", "ADJD", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "F\u00fcr ein Menschenkind, und w\u00e4r' es schlank auch wie ein Rosenb\u00e4umchen!", "tokens": ["F\u00fcr", "ein", "Men\u00b7schen\u00b7kind", ",", "und", "w\u00e4r'", "es", "schlank", "auch", "wie", "ein", "Ro\u00b7sen\u00b7b\u00e4um\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KON", "VAFIN", "PPER", "VVFIN", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.32": {"line.1": {"text": "O was lie\u00df ich mich gel\u00fcsten, in den Vogelherd zu fl\u00fcchten,", "tokens": ["O", "was", "lie\u00df", "ich", "mich", "ge\u00b7l\u00fcs\u00b7ten", ",", "in", "den", "Vo\u00b7gel\u00b7herd", "zu", "fl\u00fcch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "PRF", "VVPP", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Als nur schwach die Wolke tropfte, als noch fl\u00fcsterten die Fichten:", "tokens": ["Als", "nur", "schwach", "die", "Wol\u00b7ke", "tropf\u00b7te", ",", "als", "noch", "fl\u00fcs\u00b7ter\u00b7ten", "die", "Fich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ART", "NN", "VVFIN", "$,", "KOUS", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.33": {"line.1": {"text": "Und mu\u00df nun bestehn das Ganze, wie wenn z\u00f6gernd man dem Schw\u00e4tzer", "tokens": ["Und", "mu\u00df", "nun", "be\u00b7stehn", "das", "Gan\u00b7ze", ",", "wie", "wenn", "z\u00f6\u00b7gernd", "man", "dem", "Schw\u00e4t\u00b7zer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "ART", "NN", "$,", "KOKOM", "KOUS", "ADJD", "PIS", "ART", "NN"], "meter": "+---+-+-+-+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Raum gegeben, dem langweilig Seile drehnden Phrasensetzer;", "tokens": ["Raum", "ge\u00b7ge\u00b7ben", ",", "dem", "lang\u00b7wei\u00b7lig", "Sei\u00b7le", "drehn\u00b7den", "Phra\u00b7sen\u00b7set\u00b7zer", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "ADJD", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.34": {"line.1": {"text": "Und am Knopfe nun gehalten, oder schlimmer an den H\u00e4nden,", "tokens": ["Und", "am", "Knop\u00b7fe", "nun", "ge\u00b7hal\u00b7ten", ",", "o\u00b7der", "schlim\u00b7mer", "an", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "VVPP", "$,", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Zappelnd wie der Halbgeh\u00e4ngte langet nach des Strickes Enden!", "tokens": ["Zap\u00b7pelnd", "wie", "der", "Halb\u00b7ge\u00b7h\u00e4ng\u00b7te", "lan\u00b7get", "nach", "des", "Stri\u00b7ckes", "En\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.35": {"line.1": {"text": "Meine Ungl\u00fccksstrick' sind dieser Wasserstriemen L\u00e4ng' und Breite,", "tokens": ["Mei\u00b7ne", "Un\u00b7gl\u00fcckss\u00b7trick'", "sind", "die\u00b7ser", "Was\u00b7ser\u00b7strie\u00b7men", "L\u00e4ng'", "und", "Brei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PDAT", "NN", "NE", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Die verk\u00f6rperten Hyperbeln, denn Bindf\u00e4den regnet's heute.", "tokens": ["Die", "ver\u00b7k\u00f6r\u00b7per\u00b7ten", "Hy\u00b7per\u00b7beln", ",", "denn", "Bind\u00b7f\u00e4\u00b7den", "reg\u00b7net's", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "--+---+--++-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.36": {"line.1": {"text": "Denk' ich an die heitre Stube, an das weiche Kanapee,", "tokens": ["Denk'", "ich", "an", "die", "heit\u00b7re", "Stu\u00b7be", ",", "an", "das", "wei\u00b7che", "Ka\u00b7na\u00b7pee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und wie mein Gedicht, das meine, dort zerlesen wird beim Tee:", "tokens": ["Und", "wie", "mein", "Ge\u00b7dicht", ",", "das", "mei\u00b7ne", ",", "dort", "zer\u00b7le\u00b7sen", "wird", "beim", "Tee", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "$,", "ADV", "VVPP", "VAFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.37": {"line.1": {"text": "Denk' ich an die schwere Zunge, die statt meiner es zerdrischt,", "tokens": ["Denk'", "ich", "an", "die", "schwe\u00b7re", "Zun\u00b7ge", ",", "die", "statt", "mei\u00b7ner", "es", "zer\u00b7drischt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "PPOSAT", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Bohrend wie ein Schwertfisch m\u00f6cht' ich schie\u00dfen in den Wassergischt.", "tokens": ["Boh\u00b7rend", "wie", "ein", "Schwert\u00b7fisch", "m\u00f6cht'", "ich", "schie\u00b7\u00dfen", "in", "den", "Was\u00b7ser\u00b7gischt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.38": {"line.1": {"text": "Pah! was k\u00fcmmern mich die Tropfen, ob ich na\u00df ob s\u00e4uberlich!", "tokens": ["Pah", "!", "was", "k\u00fcm\u00b7mern", "mich", "die", "Trop\u00b7fen", ",", "ob", "ich", "na\u00df", "ob", "s\u00e4u\u00b7ber\u00b7lich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "ADJD", "KOUS", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Aber besser stramm und trocken, als durchn\u00e4\u00dft und l\u00e4cherlich.", "tokens": ["A\u00b7ber", "bes\u00b7ser", "stramm", "und", "tro\u00b7cken", ",", "als", "durc\u00b7hn\u00e4\u00dft", "und", "l\u00e4\u00b7cher\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "KON", "ADJD", "$,", "KOUS", "VVFIN", "KON", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.39": {"line.1": {"text": "Da \u2013 ein Fleck, ein Loch am Himmel; bist du endlich doch gebrochen,", "tokens": ["Da", "\u2013", "ein", "Fleck", ",", "ein", "Loch", "am", "Him\u00b7mel", ";", "bist", "du", "end\u00b7lich", "doch", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$.", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Alte Wassertonne, hab' ich endlich dich entzwei gesprochen?", "tokens": ["Al\u00b7te", "Was\u00b7ser\u00b7ton\u00b7ne", ",", "hab'", "ich", "end\u00b7lich", "dich", "ent\u00b7zwei", "ge\u00b7spro\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VAFIN", "PPER", "ADV", "PPER", "PTKVZ", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.40": {"line.1": {"text": "Aber wehe! wie's vom Fasse brodelt, wenn gesprengt der Zapfen,", "tokens": ["A\u00b7ber", "we\u00b7he", "!", "wie's", "vom", "Fas\u00b7se", "bro\u00b7delt", ",", "wenn", "ge\u00b7sprengt", "der", "Zap\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "VVFIN", "APPRART", "NN", "VVFIN", "$,", "KOUS", "VVPP", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "H\u00f6r' ich's auf dem Dache rasseln, f\u00f6rmlich wie mit F\u00fc\u00dfen stapfen.", "tokens": ["H\u00f6r'", "ich's", "auf", "dem", "Da\u00b7che", "ras\u00b7seln", ",", "f\u00f6rm\u00b7lich", "wie", "mit", "F\u00fc\u00b7\u00dfen", "stap\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "VVINF", "$,", "ADJD", "KOKOM", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.41": {"line.1": {"text": "Regen! unbarmherz'ger Regen! m\u00f6gst du braten oder sieden!", "tokens": ["Re\u00b7gen", "!", "un\u00b7barm\u00b7her\u00b7z'\u00b7ger", "Re\u00b7gen", "!", "m\u00f6gst", "du", "bra\u00b7ten", "o\u00b7der", "sie\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADJA", "NN", "$.", "VMFIN", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.invert"}, "line.2": {"text": "Wehe, diese alte Kufe ist das Fa\u00df der Danaiden!", "tokens": ["We\u00b7he", ",", "die\u00b7se", "al\u00b7te", "Ku\u00b7fe", "ist", "das", "Fa\u00df", "der", "Da\u00b7na\u00b7i\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDAT", "ADJA", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.42": {"line.1": {"text": "Ich habe mich gesetzt in Gottes Namen;", "tokens": ["Ich", "ha\u00b7be", "mich", "ge\u00b7setzt", "in", "Got\u00b7tes", "Na\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es hilft doch alles nicht, und mein Gedicht", "tokens": ["Es", "hilft", "doch", "al\u00b7les", "nicht", ",", "und", "mein", "Ge\u00b7dicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "PTKNEG", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist l\u00e4ngst gelesen und im Schlo\u00df die Damen,", "tokens": ["Ist", "l\u00e4ngst", "ge\u00b7le\u00b7sen", "und", "im", "Schlo\u00df", "die", "Da\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "KON", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie sa\u00dfen lange zu Gericht.", "tokens": ["Sie", "sa\u00b7\u00dfen", "lan\u00b7ge", "zu", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Statt einen neuen Lorbeerkranz zu dr\u00fccken", "tokens": ["Statt", "ei\u00b7nen", "neu\u00b7en", "Lor\u00b7beer\u00b7kranz", "zu", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In meine Ph\u00f6boslocken, hat man sacht", "tokens": ["In", "mei\u00b7ne", "Ph\u00f6\u00b7bos\u00b7lo\u00b7cken", ",", "hat", "man", "sacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VAFIN", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den alten losgezupft und hinterm R\u00fccken", "tokens": ["Den", "al\u00b7ten", "los\u00b7ge\u00b7zupft", "und", "hin\u00b7term", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVPP", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wohl Eselsohren mir gemacht.", "tokens": ["Wohl", "E\u00b7sel\u00b7soh\u00b7ren", "mir", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Verkannte Seele, fasse dich im Leiden,", "tokens": ["Ver\u00b7kann\u00b7te", "See\u00b7le", ",", "fas\u00b7se", "dich", "im", "Lei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sei stark, sei nobel, denk, der Ruhm ist leer,", "tokens": ["Sei", "stark", ",", "sei", "no\u00b7bel", ",", "denk", ",", "der", "Ruhm", "ist", "leer", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "VAFIN", "ADJD", "$,", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Leben kurz, es wechseln Schmerz und Freuden,", "tokens": ["Das", "Le\u00b7ben", "kurz", ",", "es", "wech\u00b7seln", "Schmerz", "und", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und was dergleichen Neugedachtes mehr!", "tokens": ["Und", "was", "derg\u00b7lei\u00b7chen", "Neu\u00b7ge\u00b7dach\u00b7tes", "mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Ich schau mich um in meiner kleinen Zelle:", "tokens": ["Ich", "schau", "mich", "um", "in", "mei\u00b7ner", "klei\u00b7nen", "Zel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr einen Klausner w\u00e4r's ein h\u00fcbscher Ort;", "tokens": ["F\u00fcr", "ei\u00b7nen", "Klaus\u00b7ner", "w\u00e4r's", "ein", "h\u00fcb\u00b7scher", "Ort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Bank, der Tisch, das h\u00f6lzerne Gestelle,", "tokens": ["Die", "Bank", ",", "der", "Tisch", ",", "das", "h\u00f6l\u00b7zer\u00b7ne", "Ge\u00b7stel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und an der Wand die Tasche dort;", "tokens": ["Und", "an", "der", "Wand", "die", "Ta\u00b7sche", "dort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Ein Netz im Winkelchen, ein Rechen, Spaten \u2013", "tokens": ["Ein", "Netz", "im", "Win\u00b7kel\u00b7chen", ",", "ein", "Re\u00b7chen", ",", "Spa\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "$,", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Betten? nun, das macht sich einfach hier;", "tokens": ["Und", "Bet\u00b7ten", "?", "nun", ",", "das", "macht", "sich", "ein\u00b7fach", "hier", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "ADV", "$,", "PDS", "VVFIN", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Thimian ist heuer gut geraten,", "tokens": ["Der", "Thi\u00b7mi\u00b7an", "ist", "heu\u00b7er", "gut", "ge\u00b7ra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und bl\u00fcht mir grade vor der T\u00fcr.", "tokens": ["Und", "bl\u00fcht", "mir", "gra\u00b7de", "vor", "der", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Die Waldung dr\u00fcben \u2013 und das Quellgew\u00e4sser \u2013", "tokens": ["Die", "Wal\u00b7dung", "dr\u00fc\u00b7ben", "\u2013", "und", "das", "Quell\u00b7ge\u00b7w\u00e4s\u00b7ser", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hier m\u00f6cht' ich Heidebilder schreiben, zum Exempel:", "tokens": ["Hier", "m\u00f6cht'", "ich", "Hei\u00b7de\u00b7bil\u00b7der", "schrei\u00b7ben", ",", "zum", "Ex\u00b7em\u00b7pel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "VVINF", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbdie Vogelh\u00fctte\u00ab, nein \u2013 \u00bbder Herd\u00ab, nein besser:", "tokens": ["\u00bb", "die", "Vo\u00b7gel\u00b7h\u00fct\u00b7te", "\u00ab", ",", "nein", "\u2013", "\u00bb", "der", "Herd", "\u00ab", ",", "nein", "bes\u00b7ser", ":"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "$,", "PTKANT", "$(", "$(", "ART", "NN", "$(", "$,", "PTKANT", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbder Knieende in Gottes weitem Tempel.\u00ab", "tokens": ["\u00bb", "der", "Kni\u00b7e\u00b7en\u00b7de", "in", "Got\u00b7tes", "wei\u00b7tem", "Tem\u00b7pel", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.48": {"line.1": {"text": "'s ist doch romantisch, wenn ein zart Geriesel", "tokens": ["'s", "ist", "doch", "ro\u00b7man\u00b7tisch", ",", "wenn", "ein", "zart", "Ge\u00b7rie\u00b7sel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "ART", "ADJD", "NN"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Durch Immortellen und Wacholderstrauch", "tokens": ["Durch", "Im\u00b7mor\u00b7tel\u00b7len", "und", "Wa\u00b7chol\u00b7der\u00b7strauch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Umzieht und gleitet, wie ein schl\u00fcpfend Wiesel,", "tokens": ["Um\u00b7zieht", "und", "glei\u00b7tet", ",", "wie", "ein", "schl\u00fcp\u00b7fend", "Wie\u00b7sel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PWAV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und dr\u00fcber flirrt der St\u00f6berrauch;", "tokens": ["Und", "dr\u00fc\u00b7ber", "flirrt", "der", "St\u00f6\u00b7berr\u00b7auch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Wenn Schimmer wechseln, wei\u00df und seladonen;", "tokens": ["Wenn", "Schim\u00b7mer", "wech\u00b7seln", ",", "wei\u00df", "und", "se\u00b7la\u00b7do\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$,", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die weite Ebne schaukelt wie ein Schiff,", "tokens": ["Die", "wei\u00b7te", "Eb\u00b7ne", "schau\u00b7kelt", "wie", "ein", "Schiff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hindurch der Kiebitz schrillt, wie Halkyonen", "tokens": ["Hin\u00b7durch", "der", "Kie\u00b7bitz", "schrillt", ",", "wie", "Hal\u00b7ky\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wehklagend ziehen um das Riff.", "tokens": ["Weh\u00b7kla\u00b7gend", "zie\u00b7hen", "um", "das", "Riff", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Am Horizont die kolossalen Br\u00fccken \u2013", "tokens": ["Am", "Ho\u00b7ri\u00b7zont", "die", "ko\u00b7los\u00b7sa\u00b7len", "Br\u00fc\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sind's Wolken oder ist's ein ferner Wald?", "tokens": ["Sin\u00b7d's", "Wol\u00b7ken", "o\u00b7der", "ist's", "ein", "fer\u00b7ner", "Wald", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ich will den Schemel an die Luke r\u00fccken,", "tokens": ["Ich", "will", "den", "Sche\u00b7mel", "an", "die", "Lu\u00b7ke", "r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da liegt mein Hut, mein Hammer, \u2013 halt:", "tokens": ["Da", "liegt", "mein", "Hut", ",", "mein", "Ham\u00b7mer", ",", "\u2013", "halt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "$(", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Ein Teller am Gestell! \u2013 was mag er bieten?", "tokens": ["Ein", "Tel\u00b7ler", "am", "Ge\u00b7stell", "!", "\u2013", "was", "mag", "er", "bie\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Fundus! bei Gott, ein Fund die Brezel drin!", "tokens": ["Fun\u00b7dus", "!", "bei", "Gott", ",", "ein", "Fund", "die", "Bre\u00b7zel", "drin", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "NN", "$,", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "F\u00fcr einen armen Hund von Eremiten,", "tokens": ["F\u00fcr", "ei\u00b7nen", "ar\u00b7men", "Hund", "von", "E\u00b7re\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie ich es leider heute bin!", "tokens": ["Wie", "ich", "es", "lei\u00b7der", "heu\u00b7te", "bin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Ein seidner Beutel noch \u2013 am Bort zerrissen;", "tokens": ["Ein", "seid\u00b7ner", "Beu\u00b7tel", "noch", "\u2013", "am", "Bort", "zer\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "$(", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich greife, greife Rundes mit der Hand;", "tokens": ["Ich", "grei\u00b7fe", ",", "grei\u00b7fe", "Run\u00b7des", "mit", "der", "Hand", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Weh! in die d\u00fcrre Erbs' hab' ich gebissen \u2013", "tokens": ["Weh", "!", "in", "die", "d\u00fcr\u00b7re", "Erbs'", "hab'", "ich", "ge\u00b7bis\u00b7sen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich dacht', es seie Zuckerkand.", "tokens": ["Ich", "dacht'", ",", "es", "sei\u00b7e", "Zu\u00b7cker\u00b7kand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Und nun die Tasche! he, wir m\u00fcssen klopfen \u2013", "tokens": ["Und", "nun", "die", "Ta\u00b7sche", "!", "he", ",", "wir", "m\u00fcs\u00b7sen", "klop\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "NE", "$,", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vielleicht liegt ein Gefangner hier in Haft;", "tokens": ["Viel\u00b7leicht", "liegt", "ein", "Ge\u00b7fang\u00b7ner", "hier", "in", "Haft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da \u2013 eine Flasche! schnell herab den Pfropfen \u2013", "tokens": ["Da", "\u2013", "ei\u00b7ne", "Fla\u00b7sche", "!", "schnell", "her\u00b7ab", "den", "Pfrop\u00b7fen", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ART", "NN", "$.", "ADJD", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist's Wasser? Wasser? \u2013 edler Rebensaft!", "tokens": ["Ist's", "Was\u00b7ser", "?", "Was\u00b7ser", "?", "\u2013", "ed\u00b7ler", "Re\u00b7ben\u00b7saft", "!"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "NN", "$.", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.54": {"line.1": {"text": "Und Edlerer, der ihn dem Sack vertraute,", "tokens": ["Und", "Ed\u00b7le\u00b7rer", ",", "der", "ihn", "dem", "Sack", "ver\u00b7trau\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Splendid barmherziger Wildh\u00fcter du,", "tokens": ["Splen\u00b7did", "barm\u00b7her\u00b7zi\u00b7ger", "Wild\u00b7h\u00fc\u00b7ter", "du", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PPER", "$,"], "meter": "+--+--++-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "F\u00fcr einen armen Schelm, der Erbsen kaute,", "tokens": ["F\u00fcr", "ei\u00b7nen", "ar\u00b7men", "Schelm", ",", "der", "Erb\u00b7sen", "kau\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den frommen Bruder Tuck im Ivanhoe!", "tokens": ["Den", "from\u00b7men", "Bru\u00b7der", "Tuck", "im", "I\u00b7van\u00b7hoe", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Mit dem Gek\u00f6rn will ich den Kiebitz letzen,", "tokens": ["Mit", "dem", "Ge\u00b7k\u00f6rn", "will", "ich", "den", "Kie\u00b7bitz", "let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es aus der L\u00fccke streun, wenn er im Flug", "tokens": ["Es", "aus", "der", "L\u00fc\u00b7cke", "streun", ",", "wenn", "er", "im", "Flug"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "VVINF", "$,", "KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Herschwirrt, mir auf die Schulter sich zu setzen,", "tokens": ["Her\u00b7schwirrt", ",", "mir", "auf", "die", "Schul\u00b7ter", "sich", "zu", "set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "APPR", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie man es liest in manchem Buch.", "tokens": ["Wie", "man", "es", "liest", "in", "man\u00b7chem", "Buch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Mir ist ganz wohl in meiner armen Zelle;", "tokens": ["Mir", "ist", "ganz", "wohl", "in", "mei\u00b7ner", "ar\u00b7men", "Zel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie mir das Klausnerleben so gef\u00e4llt!", "tokens": ["Wie", "mir", "das", "Klaus\u00b7ner\u00b7le\u00b7ben", "so", "ge\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bleibe hier, ich geh nicht von der Stelle,", "tokens": ["Ich", "blei\u00b7be", "hier", ",", "ich", "geh", "nicht", "von", "der", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bevor der letzte Tropfen f\u00e4llt.", "tokens": ["Be\u00b7vor", "der", "letz\u00b7te", "Trop\u00b7fen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Es verrieselt, es verraucht,", "tokens": ["Es", "ver\u00b7rie\u00b7selt", ",", "es", "ver\u00b7raucht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "M\u00e4hlich aus der Wolke taucht", "tokens": ["M\u00e4h\u00b7lich", "aus", "der", "Wol\u00b7ke", "taucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Neu hervor der Sonnenadel.", "tokens": ["Neu", "her\u00b7vor", "der", "Son\u00b7ne\u00b7na\u00b7del", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In den feinen Dunst die Fichte", "tokens": ["In", "den", "fei\u00b7nen", "Dunst", "die", "Fich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihre gr\u00fcnen Dornen streckt,", "tokens": ["Ih\u00b7re", "gr\u00fc\u00b7nen", "Dor\u00b7nen", "streckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie ein sch\u00f6nes Weib die Nadel", "tokens": ["Wie", "ein", "sch\u00f6\u00b7nes", "Weib", "die", "Na\u00b7del"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "In den Spitzenschleier steckt;", "tokens": ["In", "den", "Spit\u00b7zen\u00b7schlei\u00b7er", "steckt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und die Heide steht im Lichte", "tokens": ["Und", "die", "Hei\u00b7de", "steht", "im", "Lich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Zahllos blanker Tropfen, die", "tokens": ["Zahl\u00b7los", "blan\u00b7ker", "Trop\u00b7fen", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADJD", "ADJA", "NN", "$,", "PRELS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Am Wacholder zittern, wie", "tokens": ["Am", "Wa\u00b7chol\u00b7der", "zit\u00b7tern", ",", "wie"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PWAV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Glasgeh\u00e4nge an dem L\u00fcster.", "tokens": ["Glas\u00b7ge\u00b7h\u00e4n\u00b7ge", "an", "dem", "L\u00fcs\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "\u00dcberm Grund geht ein Gefl\u00fcster,", "tokens": ["\u00dc\u00b7berm", "Grund", "geht", "ein", "Ge\u00b7fl\u00fcs\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Jedes Kr\u00e4utchen reckt sich auf,", "tokens": ["Je\u00b7des", "Kr\u00e4ut\u00b7chen", "reckt", "sich", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Und in langgestrecktem Lauf,", "tokens": ["Und", "in", "lang\u00b7ge\u00b7streck\u00b7tem", "Lauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Durch den Sand des Pfades eilend,", "tokens": ["Durch", "den", "Sand", "des", "Pfa\u00b7des", "ei\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Blitzt das goldne Panzerhemd", "tokens": ["Blitzt", "das", "gold\u00b7ne", "Pan\u00b7zer\u00b7hemd"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Des Kuriers;", "tokens": ["Des", "Ku\u00b7riers", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.18": {"text": "Streicht die Grille sich das Na\u00df", "tokens": ["Streicht", "die", "Gril\u00b7le", "sich", "das", "Na\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PRF", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Von der Fl\u00fcgel gr\u00fcnem Glas.", "tokens": ["Von", "der", "Fl\u00fc\u00b7gel", "gr\u00fc\u00b7nem", "Glas", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "Grashalm gl\u00e4nzt wie eine Klinge,", "tokens": ["Gras\u00b7halm", "gl\u00e4nzt", "wie", "ei\u00b7ne", "Klin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Und die kleinen Schmetterlinge,", "tokens": ["Und", "die", "klei\u00b7nen", "Schmet\u00b7ter\u00b7lin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Blau, orange, gelb und wei\u00df,", "tokens": ["Blau", ",", "o\u00b7ran\u00b7ge", ",", "gelb", "und", "wei\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.23": {"text": "Jagen tummelnd sich im Kreis.", "tokens": ["Ja\u00b7gen", "tum\u00b7melnd", "sich", "im", "Kreis", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Alles Schimmer, alles Licht,", "tokens": ["Al\u00b7les", "Schim\u00b7mer", ",", "al\u00b7les", "Licht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.25": {"text": "Bergwald mag und Welle nicht", "tokens": ["Berg\u00b7wald", "mag", "und", "Wel\u00b7le", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "KON", "NN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.26": {"text": "Solche Farbent\u00f6ne hegen,", "tokens": ["Sol\u00b7che", "Far\u00b7ben\u00b7t\u00f6\u00b7ne", "he\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.27": {"text": "Wie die Heide nach dem Regen.", "tokens": ["Wie", "die", "Hei\u00b7de", "nach", "dem", "Re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Ein Schall \u2013 und wieder \u2013 wieder \u2013 was ist das? \u2013", "tokens": ["Ein", "Schall", "\u2013", "und", "wie\u00b7der", "\u2013", "wie\u00b7der", "\u2013", "was", "ist", "das", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "KON", "ADV", "$(", "ADV", "$(", "PWS", "VAFIN", "PDS", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bei Gott, das Schlo\u00df! Da schl\u00e4gt es acht im Turme \u2013", "tokens": ["Bei", "Gott", ",", "das", "Schlo\u00df", "!", "Da", "schl\u00e4gt", "es", "acht", "im", "Tur\u00b7me", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "CARD", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weh mein Gedicht! o weh mir armem Wurme,", "tokens": ["Weh", "mein", "Ge\u00b7dicht", "!", "o", "weh", "mir", "ar\u00b7mem", "Wur\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$.", "FM", "ADV", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nun f\u00e4llt mir alles ein, was ich verga\u00df!", "tokens": ["Nun", "f\u00e4llt", "mir", "al\u00b7les", "ein", ",", "was", "ich", "ver\u00b7ga\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PTKVZ", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mein Hut, mein Hammer, hurtig fortgetrabt \u2013", "tokens": ["Mein", "Hut", ",", "mein", "Ham\u00b7mer", ",", "hur\u00b7tig", "fort\u00b7ge\u00b7trabt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Vielleicht, vielleicht ist man diskret gewesen,", "tokens": ["Viel\u00b7leicht", ",", "viel\u00b7leicht", "ist", "man", "dis\u00b7kret", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VAFIN", "PIS", "VVFIN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und harrte meiner, der sein Federlesen", "tokens": ["Und", "harr\u00b7te", "mei\u00b7ner", ",", "der", "sein", "Fe\u00b7der\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Indes mit Kraut und W\u00fcrmern hat gehabt. \u2013", "tokens": ["In\u00b7des", "mit", "Kraut", "und", "W\u00fcr\u00b7mern", "hat", "ge\u00b7habt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "VAFIN", "VAPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Nun k\u00f6mmt der Steg und nun des Teiches Ried,", "tokens": ["Nun", "k\u00f6mmt", "der", "Steg", "und", "nun", "des", "Tei\u00b7ches", "Ried", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Nun steigen der Alleen schlanke Streifen;", "tokens": ["Nun", "stei\u00b7gen", "der", "Al\u00b7leen", "schlan\u00b7ke", "Strei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ich wei\u00df es nicht, ich kann es nicht begreifen,", "tokens": ["Ich", "wei\u00df", "es", "nicht", ",", "ich", "kann", "es", "nicht", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wie ich so g\u00e4nzlich mich vom Leben schied \u2013", "tokens": ["Wie", "ich", "so", "g\u00e4nz\u00b7lich", "mich", "vom", "Le\u00b7ben", "schied", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "PPER", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Doch freilich \u2013 damals war ich Eremit!", "tokens": ["Doch", "frei\u00b7lich", "\u2013", "da\u00b7mals", "war", "ich", "E\u00b7re\u00b7mit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}