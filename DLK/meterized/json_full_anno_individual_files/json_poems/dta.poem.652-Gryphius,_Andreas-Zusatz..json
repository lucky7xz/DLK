{"dta.poem.652": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "Zusatz.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Lernt/ die jhr lebt/ den zaum in ewre Lippen legen! ", "tokens": ["Lernt", "/", "die", "jhr", "lebt", "/", "den", "zaum", "in", "ew\u00b7re", "Lip\u00b7pen", "le\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PRELS", "PPER", "VVFIN", "$(", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In welchen heil vnd schaden wohnet/ ", "tokens": ["In", "wel\u00b7chen", "heil", "vnd", "scha\u00b7den", "woh\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd was verdam\u0303t/ vnd was belohnet. ", "tokens": ["Vnd", "was", "ver\u00b7dam\u0303t", "/", "vnd", "was", "be\u00b7loh\u00b7net", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "$(", "KON", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer nutz durch wortte such't/ sol jedes wort erwegen. ", "tokens": ["Wer", "nutz", "durch", "wort\u00b7te", "such't", "/", "sol", "je\u00b7des", "wort", "er\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "VVFIN", "$(", "VMFIN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "D", "tokens": ["D"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "So sch\u00fctzer vnd verletzt. ", "tokens": ["So", "sch\u00fct\u00b7zer", "vnd", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "D", "tokens": ["D"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Vnd eben wol ergetzt. ", "tokens": ["Vnd", "e\u00b7ben", "wol", "er\u00b7getzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ein Hammer welcher bawt vnd bricht/ ", "tokens": ["Ein", "Ham\u00b7mer", "wel\u00b7cher", "bawt", "vnd", "bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PWAT", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Rosenzweig/ der reucht vnd sticht/ ", "tokens": ["Ein", "Ro\u00b7sen\u00b7zweig", "/", "der", "reucht", "vnd", "sticht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ein strom der tr\u00e4ncket vnd ertr\u00e4ncket: ", "tokens": ["Ein", "strom", "der", "tr\u00e4n\u00b7cket", "vnd", "er\u00b7tr\u00e4n\u00b7cket", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "D", "tokens": ["D"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "D", "tokens": ["D"], "token_info": ["word"], "pos": ["XY"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Zungen. ", "tokens": ["Zun\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}}}}}