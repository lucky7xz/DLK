{"dta.poem.11660": {"metadata": {"author": {"name": "M\u00f6rike, Eduard", "birth": "N.A.", "death": "N.A."}, "title": "An meinen Vetter.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905193969", "language": ["de:0.99"], "booktitle": "M\u00f6rike, Eduard: Gedichte. Stuttgart, 1838."}, "poem": {"stanza.1": {"line.1": {"text": "Lieber Vetter! Er ist eine", "tokens": ["Lie\u00b7ber", "Vet\u00b7ter", "!", "Er", "ist", "ei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "NN", "$.", "PPER", "VAFIN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den freundlichen Naturen,", "tokens": ["Von", "den", "freund\u00b7li\u00b7chen", "Na\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ich ", "tokens": ["Die", "ich"], "token_info": ["word", "word"], "pos": ["ART", "PPER"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Denn sie haben wirklich etwas", "tokens": ["Denn", "sie", "ha\u00b7ben", "wirk\u00b7lich", "et\u00b7was"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sonniges in ihrem Wesen.", "tokens": ["Son\u00b7ni\u00b7ges", "in", "ih\u00b7rem", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Es sind weltliche Beamte,", "tokens": ["Es", "sind", "welt\u00b7li\u00b7che", "Be\u00b7am\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Rechnungsr\u00e4the, Revisoren,", "tokens": ["Rech\u00b7nungs\u00b7r\u00e4\u00b7the", ",", "Re\u00b7vi\u00b7so\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Oder Cameralverwalter,", "tokens": ["O\u00b7der", "Ca\u00b7me\u00b7ral\u00b7ver\u00b7wal\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Auch wohl manchmal Herrn vom Handel,", "tokens": ["Auch", "wohl", "manch\u00b7mal", "Herrn", "vom", "Han\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "NN", "APPRART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.10": {"text": "Aber meist vom \u00e4ltern Schlage,", "tokens": ["A\u00b7ber", "meist", "vom", "\u00e4l\u00b7tern", "Schla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Keinesweges Petitmaitres,", "tokens": ["Kei\u00b7nes\u00b7we\u00b7ges", "Pe\u00b7tit\u00b7mai\u00b7tres", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.12": {"text": "Haben manchmal h\u00fcbsche B\u00e4uche,", "tokens": ["Ha\u00b7ben", "manch\u00b7mal", "h\u00fcb\u00b7sche", "B\u00e4u\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Und ihr Vaterland ist Schwaben.", "tokens": ["Und", "ihr", "Va\u00b7ter\u00b7land", "ist", "Schwa\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Neulich auf der Reise traf ich", "tokens": ["Neu\u00b7lich", "auf", "der", "Rei\u00b7se", "traf", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch mit einer Sommerweste", "tokens": ["Auch", "mit", "ei\u00b7ner", "Som\u00b7mer\u00b7wes\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der Post zu Besigheim", "tokens": ["In", "der", "Post", "zu", "Be\u00b7sig\u00b7heim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eben zu Mittag zusammen.", "tokens": ["E\u00b7ben", "zu", "Mit\u00b7tag", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wir speisten eine Suppe,", "tokens": ["Und", "wir", "speis\u00b7ten", "ei\u00b7ne", "Sup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Darin rothe Krebse schwammen,", "tokens": ["Da\u00b7rin", "ro\u00b7the", "Kreb\u00b7se", "schwam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Rindfleisch mit franz\u00f6'schem Senfe,", "tokens": ["Rind\u00b7fleisch", "mit", "fran\u00b7z\u00f6'\u00b7schem", "Sen\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.8": {"text": "Dazu liebliche Radieschen,", "tokens": ["Da\u00b7zu", "lieb\u00b7li\u00b7che", "Ra\u00b7die\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.9": {"text": "Dann Gem\u00fcse, und so weiter;", "tokens": ["Dann", "Ge\u00b7m\u00fc\u00b7se", ",", "und", "so", "wei\u00b7ter", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "KON", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Schwazten von der neu'sten Zeitung,", "tokens": ["Schwaz\u00b7ten", "von", "der", "neu'\u00b7sten", "Zei\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Und da\u00df es an manchen Orten", "tokens": ["Und", "da\u00df", "es", "an", "man\u00b7chen", "Or\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Gestern stark gewittert habe.", "tokens": ["Ge\u00b7stern", "stark", "ge\u00b7wit\u00b7tert", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Dr\u00fcber zieht der wackre Herr ein", "tokens": ["Dr\u00fc\u00b7ber", "zieht", "der", "wack\u00b7re", "Herr", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Silbern B\u00fcchslein aus der Tasche,", "tokens": ["Sil\u00b7bern", "B\u00fcchs\u00b7lein", "aus", "der", "Ta\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich die Z\u00e4hne auszustochern;", "tokens": ["Sich", "die", "Z\u00e4h\u00b7ne", "aus\u00b7zu\u00b7sto\u00b7chern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Endlich stopft er sich zum schwarzen", "tokens": ["End\u00b7lich", "stopft", "er", "sich", "zum", "schwar\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kaffee seine Meerschaumpfeife,", "tokens": ["Kaf\u00b7fee", "sei\u00b7ne", "Meer\u00b7schaum\u00b7pfei\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dampft und discurrirt und schaut in-", "tokens": ["Dampft", "und", "dis\u00b7cur\u00b7rirt", "und", "schaut", "in"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "KON", "VVFIN", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "mittelst einmal nach den Pferden.", "tokens": ["mit\u00b7telst", "ein\u00b7mal", "nach", "den", "Pfer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und ich sah ihm so von hinten", "tokens": ["Und", "ich", "sah", "ihm", "so", "von", "hin\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ADV"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Nach und dachte: Ach, da\u00df diese", "tokens": ["Nach", "und", "dach\u00b7te", ":", "Ach", ",", "da\u00df", "die\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "KON", "VVFIN", "$.", "ITJ", "$,", "KOUS", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lieben, hellen Sommerwesten,", "tokens": ["Lie\u00b7ben", ",", "hel\u00b7len", "Som\u00b7mer\u00b7wes\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die bequemen, angenehmen,", "tokens": ["Die", "be\u00b7que\u00b7men", ",", "an\u00b7ge\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Endlich doch auch sterben m\u00fcssen!", "tokens": ["End\u00b7lich", "doch", "auch", "ster\u00b7ben", "m\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}