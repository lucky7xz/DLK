{"textgrid.poem.24541": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: wollen wir der Elbe Lust genie\u00dfen?", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "wollen wir der Elbe Lust genie\u00dfen?", "tokens": ["wol\u00b7len", "wir", "der", "El\u00b7be", "Lust", "ge\u00b7nie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Stimmst du in eine Fahrt nach \u2013 \u2013 \u2013 ein?", "tokens": ["Stimmst", "du", "in", "ei\u00b7ne", "Fahrt", "nach", "\u2013", "\u2013", "\u2013", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "$(", "$(", "$(", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wird die lange Weil dem Wasser gleich verfliessen/", "tokens": ["So", "wird", "die", "lan\u00b7ge", "Weil", "dem", "Was\u00b7ser", "gleich", "ver\u00b7flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alle mein Verdru\u00df durch dich versencket seyn.", "tokens": ["Und", "al\u00b7le", "mein", "Ver\u00b7dru\u00df", "durch", "dich", "ver\u00b7sen\u00b7cket", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Wetter ist beliebt/ doch nicht in meinen Hertzen:", "tokens": ["Das", "Wet\u00b7ter", "ist", "be\u00b7liebt", "/", "doch", "nicht", "in", "mei\u00b7nen", "Hert\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nun m\u00f6cht' ich mein Gem\u00fcth auch klar und freudig sehn.", "tokens": ["Nun", "m\u00f6cht'", "ich", "mein", "Ge\u00b7m\u00fcth", "auch", "klar", "und", "freu\u00b7dig", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wird heute nun dein Geist annehmlich thun und schertzen/", "tokens": ["Wird", "heu\u00b7te", "nun", "dein", "Geist", "an\u00b7nehm\u00b7lich", "thun", "und", "schert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "NN", "ADJD", "VVINF", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wird vor seinem Strahl mein Sturm vor\u00fcber gehn.", "tokens": ["So", "wird", "vor", "sei\u00b7nem", "Strahl", "mein", "Sturm", "vor\u00b7\u00fc\u00b7ber", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wein/ Austern/ Bier und Brodt/ wohl zugerichte Schnecken/", "tokens": ["Wein", "/", "Aus\u00b7tern", "/", "Bier", "und", "Brodt", "/", "wohl", "zu\u00b7ge\u00b7rich\u00b7te", "Schne\u00b7cken", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$(", "ADV", "ADJA", "NN", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Ein St\u00fcck Hamburger Fleisch/ und Fische noch darzu/", "tokens": ["Ein", "St\u00fcck", "Ham\u00b7bur\u00b7ger", "Fleisch", "/", "und", "Fi\u00b7sche", "noch", "dar\u00b7zu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "KON", "NN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sind vor dich eingepackt/ und m\u00fcssen dir auch schmecken.", "tokens": ["Sind", "vor", "dich", "ein\u00b7ge\u00b7packt", "/", "und", "m\u00fcs\u00b7sen", "dir", "auch", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "$(", "KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Speisen/ so ich will/ Geliebter Freund/ bringst du.", "tokens": ["Die", "Spei\u00b7sen", "/", "so", "ich", "will", "/", "Ge\u00b7lieb\u00b7ter", "Freund", "/", "bringst", "du", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PPER", "VMFIN", "$(", "ADJA", "NN", "$(", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "wollen wir der Elbe Lust genie\u00dfen?", "tokens": ["wol\u00b7len", "wir", "der", "El\u00b7be", "Lust", "ge\u00b7nie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Stimmst du in eine Fahrt nach \u2013 \u2013 \u2013 ein?", "tokens": ["Stimmst", "du", "in", "ei\u00b7ne", "Fahrt", "nach", "\u2013", "\u2013", "\u2013", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "$(", "$(", "$(", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wird die lange Weil dem Wasser gleich verfliessen/", "tokens": ["So", "wird", "die", "lan\u00b7ge", "Weil", "dem", "Was\u00b7ser", "gleich", "ver\u00b7flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alle mein Verdru\u00df durch dich versencket seyn.", "tokens": ["Und", "al\u00b7le", "mein", "Ver\u00b7dru\u00df", "durch", "dich", "ver\u00b7sen\u00b7cket", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Wetter ist beliebt/ doch nicht in meinen Hertzen:", "tokens": ["Das", "Wet\u00b7ter", "ist", "be\u00b7liebt", "/", "doch", "nicht", "in", "mei\u00b7nen", "Hert\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nun m\u00f6cht' ich mein Gem\u00fcth auch klar und freudig sehn.", "tokens": ["Nun", "m\u00f6cht'", "ich", "mein", "Ge\u00b7m\u00fcth", "auch", "klar", "und", "freu\u00b7dig", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wird heute nun dein Geist annehmlich thun und schertzen/", "tokens": ["Wird", "heu\u00b7te", "nun", "dein", "Geist", "an\u00b7nehm\u00b7lich", "thun", "und", "schert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "NN", "ADJD", "VVINF", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wird vor seinem Strahl mein Sturm vor\u00fcber gehn.", "tokens": ["So", "wird", "vor", "sei\u00b7nem", "Strahl", "mein", "Sturm", "vor\u00b7\u00fc\u00b7ber", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wein/ Austern/ Bier und Brodt/ wohl zugerichte Schnecken/", "tokens": ["Wein", "/", "Aus\u00b7tern", "/", "Bier", "und", "Brodt", "/", "wohl", "zu\u00b7ge\u00b7rich\u00b7te", "Schne\u00b7cken", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$(", "ADV", "ADJA", "NN", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Ein St\u00fcck Hamburger Fleisch/ und Fische noch darzu/", "tokens": ["Ein", "St\u00fcck", "Ham\u00b7bur\u00b7ger", "Fleisch", "/", "und", "Fi\u00b7sche", "noch", "dar\u00b7zu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "KON", "NN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sind vor dich eingepackt/ und m\u00fcssen dir auch schmecken.", "tokens": ["Sind", "vor", "dich", "ein\u00b7ge\u00b7packt", "/", "und", "m\u00fcs\u00b7sen", "dir", "auch", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "$(", "KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Speisen/ so ich will/ Geliebter Freund/ bringst du.", "tokens": ["Die", "Spei\u00b7sen", "/", "so", "ich", "will", "/", "Ge\u00b7lieb\u00b7ter", "Freund", "/", "bringst", "du", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PPER", "VMFIN", "$(", "ADJA", "NN", "$(", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}