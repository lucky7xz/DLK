{"textgrid.poem.44854": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "[mit Mittelhochdeutsch und Volkspoesie]", "genre": "verse", "period": "N.A.", "pub_year": 1831, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mit Mittelhochdeutsch und Volkspoesie", "tokens": ["Mit", "Mit\u00b7tel\u00b7hoch\u00b7deutsch", "und", "Volks\u00b7po\u00b7e\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wei\u00df ich f\u00fcrwahr nichts zu machen.", "tokens": ["Wei\u00df", "ich", "f\u00fcr\u00b7wahr", "nichts", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer trinkt auch, solang es Brunnen gibt,", "tokens": ["Wer", "trinkt", "auch", ",", "so\u00b7lang", "es", "Brun\u00b7nen", "gibt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aus Wegspur gern und Lachen.", "tokens": ["Aus", "Weg\u00b7spur", "gern", "und", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und fragst du mich, wo der Brunnen sei;", "tokens": ["Und", "fragst", "du", "mich", ",", "wo", "der", "Brun\u00b7nen", "sei", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hast du Homer nicht gelesen?", "tokens": ["Hast", "du", "Ho\u00b7mer", "nicht", "ge\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00e4llt dir der gro\u00dfe Brite nicht bei,", "tokens": ["F\u00e4llt", "dir", "der", "gro\u00b7\u00dfe", "Bri\u00b7te", "nicht", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Was Spanien und Welschland gewesen?", "tokens": ["Was", "Spa\u00b7ni\u00b7en", "und", "Wel\u00b7schland", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Dort l\u00f6sche deinen brennenden Durst,", "tokens": ["Dort", "l\u00f6\u00b7sche", "dei\u00b7nen", "bren\u00b7nen\u00b7den", "Durst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Dort aus dem Vollen dich letze!", "tokens": ["Dort", "aus", "dem", "Vol\u00b7len", "dich", "let\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Der P\u00f6bel erzeugt das Sch\u00f6ne nicht,", "tokens": ["Der", "P\u00f6\u00b7bel", "er\u00b7zeugt", "das", "Sch\u00f6\u00b7ne", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Noch gibt er dem Sch\u00f6nen Gesetze.", "tokens": ["Noch", "gibt", "er", "dem", "Sch\u00f6\u00b7nen", "Ge\u00b7set\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Mit Mittelhochdeutsch und Volkspoesie", "tokens": ["Mit", "Mit\u00b7tel\u00b7hoch\u00b7deutsch", "und", "Volks\u00b7po\u00b7e\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wei\u00df ich f\u00fcrwahr nichts zu machen.", "tokens": ["Wei\u00df", "ich", "f\u00fcr\u00b7wahr", "nichts", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer trinkt auch, solang es Brunnen gibt,", "tokens": ["Wer", "trinkt", "auch", ",", "so\u00b7lang", "es", "Brun\u00b7nen", "gibt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aus Wegspur gern und Lachen.", "tokens": ["Aus", "Weg\u00b7spur", "gern", "und", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und fragst du mich, wo der Brunnen sei;", "tokens": ["Und", "fragst", "du", "mich", ",", "wo", "der", "Brun\u00b7nen", "sei", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hast du Homer nicht gelesen?", "tokens": ["Hast", "du", "Ho\u00b7mer", "nicht", "ge\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00e4llt dir der gro\u00dfe Brite nicht bei,", "tokens": ["F\u00e4llt", "dir", "der", "gro\u00b7\u00dfe", "Bri\u00b7te", "nicht", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Was Spanien und Welschland gewesen?", "tokens": ["Was", "Spa\u00b7ni\u00b7en", "und", "Wel\u00b7schland", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Dort l\u00f6sche deinen brennenden Durst,", "tokens": ["Dort", "l\u00f6\u00b7sche", "dei\u00b7nen", "bren\u00b7nen\u00b7den", "Durst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Dort aus dem Vollen dich letze!", "tokens": ["Dort", "aus", "dem", "Vol\u00b7len", "dich", "let\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Der P\u00f6bel erzeugt das Sch\u00f6ne nicht,", "tokens": ["Der", "P\u00f6\u00b7bel", "er\u00b7zeugt", "das", "Sch\u00f6\u00b7ne", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Noch gibt er dem Sch\u00f6nen Gesetze.", "tokens": ["Noch", "gibt", "er", "dem", "Sch\u00f6\u00b7nen", "Ge\u00b7set\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}