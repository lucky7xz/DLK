{"textgrid.poem.48469": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "43. Auf einer edlen Jungfrauen (Christine M\u00fcller) Namenstag", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Freunde, ratet zu, wo sollen wir sie finden,", "tokens": ["Ihr", "Freun\u00b7de", ",", "ra\u00b7tet", "zu", ",", "wo", "sol\u00b7len", "wir", "sie", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$,", "PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "das fromme, liebe Kind? Sie, aller Jungfern Zier?", "tokens": ["das", "from\u00b7me", ",", "lie\u00b7be", "Kind", "?", "Sie", ",", "al\u00b7ler", "Jung\u00b7fern", "Zier", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$.", "PPER", "$,", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die so genennet wird, die ist zu weit von hier,", "tokens": ["Die", "so", "ge\u00b7nen\u00b7net", "wird", ",", "die", "ist", "zu", "weit", "von", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "VAFIN", "$,", "PRELS", "VAFIN", "PTKA", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wir allzuweit von ihr. Doch soll der Tag der Lieben", "tokens": ["wir", "all\u00b7zu\u00b7weit", "von", "ihr", ".", "Doch", "soll", "der", "Tag", "der", "Lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "$.", "KON", "VMFIN", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "in s\u00fc\u00dfer Fr\u00f6lichkeit noch werden hin vertrieben.", "tokens": ["in", "s\u00fc\u00b7\u00dfer", "Fr\u00f6\u00b7lich\u00b7keit", "noch", "wer\u00b7den", "hin", "ver\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er mu\u00df geehret sein. So tretet doch heran!", "tokens": ["Er", "mu\u00df", "ge\u00b7eh\u00b7ret", "sein", ".", "So", "tre\u00b7tet", "doch", "he\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$.", "ADV", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er gibt sich selbsten an, der hochgeehrte Man,", "tokens": ["Er", "gibt", "sich", "selbs\u00b7ten", "an", ",", "der", "hoch\u00b7geehr\u00b7te", "Man", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PTKVZ", "$,", "ART", "ADJA", "PIS", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "der lieben Freundin Freund. Was wollen wir mehr wollen?", "tokens": ["der", "lie\u00b7ben", "Freun\u00b7din", "Freund", ".", "Was", "wol\u00b7len", "wir", "mehr", "wol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$.", "PWS", "VMFIN", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er ist der, dem wir mehr als dieses gut tun sollen.", "tokens": ["Er", "ist", "der", ",", "dem", "wir", "mehr", "als", "die\u00b7ses", "gut", "tun", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "$,", "PRELS", "PPER", "PIAT", "KOKOM", "PDS", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So ist es billig auch, da\u00df Freunde vor sich stehn,", "tokens": ["So", "ist", "es", "bil\u00b7lig", "auch", ",", "da\u00df", "Freun\u00b7de", "vor", "sich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADV", "$,", "KOUS", "NN", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "zumal, wenn Absein sie nicht l\u00e4\u00dft zusammen gehn.", "tokens": ["zu\u00b7mal", ",", "wenn", "Ab\u00b7sein", "sie", "nicht", "l\u00e4\u00dft", "zu\u00b7sam\u00b7men", "gehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "NN", "PPER", "PTKNEG", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Freundschaft teilet sich. Wolan, er ist gefunden,", "tokens": ["Die", "Freund\u00b7schaft", "tei\u00b7let", "sich", ".", "Wo\u00b7lan", ",", "er", "ist", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$.", "ADV", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "der dieses Tags ist wert. Er sei hiermit gebunden", "tokens": ["der", "die\u00b7ses", "Tags", "ist", "wert", ".", "Er", "sei", "hier\u00b7mit", "ge\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PDAT", "NN", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "PAV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "an der Statt, die er meint, und halte di\u00df darf\u00fcr:", "tokens": ["an", "der", "Statt", ",", "die", "er", "meint", ",", "und", "hal\u00b7te", "di\u00df", "dar\u00b7f\u00fcr", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "VVFIN", "PDS", "PAV", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "ie besser er sich l\u00f6st, ie lieber ist es ihr.", "tokens": ["ie", "bes\u00b7ser", "er", "sich", "l\u00f6st", ",", "ie", "lie\u00b7ber", "ist", "es", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "VVFIN", "$,", "ADV", "ADV", "VAFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wir w\u00fcndschen ihm und ihr viel tausent guter Stunden,", "tokens": ["Wir", "w\u00fcnd\u00b7schen", "ihm", "und", "ihr", "viel", "tau\u00b7sent", "gu\u00b7ter", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PPER", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "viel tausent lieber Zeit. So sind sie wol gebunden,", "tokens": ["viel", "tau\u00b7sent", "lie\u00b7ber", "Zeit", ".", "So", "sind", "sie", "wol", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "zwar er f\u00fcr sie allhier und sie in ihrer Statt.", "tokens": ["zwar", "er", "f\u00fcr", "sie", "all\u00b7hier", "und", "sie", "in", "ih\u00b7rer", "Statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PPER", "ADV", "KON", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-----+-+-+-+", "measure": "unknown.measure.tetra"}, "line.19": {"text": "so wird ein iedes sehn, wo sichs zu l\u00f6sen hat.", "tokens": ["so", "wird", "ein", "ie\u00b7des", "sehn", ",", "wo", "sichs", "zu", "l\u00f6\u00b7sen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "PIS", "VVINF", "$,", "PWAV", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ihr Freunde, ratet zu, wo sollen wir sie finden,", "tokens": ["Ihr", "Freun\u00b7de", ",", "ra\u00b7tet", "zu", ",", "wo", "sol\u00b7len", "wir", "sie", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$,", "PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "das fromme, liebe Kind? Sie, aller Jungfern Zier?", "tokens": ["das", "from\u00b7me", ",", "lie\u00b7be", "Kind", "?", "Sie", ",", "al\u00b7ler", "Jung\u00b7fern", "Zier", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$.", "PPER", "$,", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die so genennet wird, die ist zu weit von hier,", "tokens": ["Die", "so", "ge\u00b7nen\u00b7net", "wird", ",", "die", "ist", "zu", "weit", "von", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "VAFIN", "$,", "PRELS", "VAFIN", "PTKA", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wir allzuweit von ihr. Doch soll der Tag der Lieben", "tokens": ["wir", "all\u00b7zu\u00b7weit", "von", "ihr", ".", "Doch", "soll", "der", "Tag", "der", "Lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "$.", "KON", "VMFIN", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "in s\u00fc\u00dfer Fr\u00f6lichkeit noch werden hin vertrieben.", "tokens": ["in", "s\u00fc\u00b7\u00dfer", "Fr\u00f6\u00b7lich\u00b7keit", "noch", "wer\u00b7den", "hin", "ver\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er mu\u00df geehret sein. So tretet doch heran!", "tokens": ["Er", "mu\u00df", "ge\u00b7eh\u00b7ret", "sein", ".", "So", "tre\u00b7tet", "doch", "he\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$.", "ADV", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er gibt sich selbsten an, der hochgeehrte Man,", "tokens": ["Er", "gibt", "sich", "selbs\u00b7ten", "an", ",", "der", "hoch\u00b7geehr\u00b7te", "Man", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PTKVZ", "$,", "ART", "ADJA", "PIS", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "der lieben Freundin Freund. Was wollen wir mehr wollen?", "tokens": ["der", "lie\u00b7ben", "Freun\u00b7din", "Freund", ".", "Was", "wol\u00b7len", "wir", "mehr", "wol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$.", "PWS", "VMFIN", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er ist der, dem wir mehr als dieses gut tun sollen.", "tokens": ["Er", "ist", "der", ",", "dem", "wir", "mehr", "als", "die\u00b7ses", "gut", "tun", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "$,", "PRELS", "PPER", "PIAT", "KOKOM", "PDS", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So ist es billig auch, da\u00df Freunde vor sich stehn,", "tokens": ["So", "ist", "es", "bil\u00b7lig", "auch", ",", "da\u00df", "Freun\u00b7de", "vor", "sich", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADV", "$,", "KOUS", "NN", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "zumal, wenn Absein sie nicht l\u00e4\u00dft zusammen gehn.", "tokens": ["zu\u00b7mal", ",", "wenn", "Ab\u00b7sein", "sie", "nicht", "l\u00e4\u00dft", "zu\u00b7sam\u00b7men", "gehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "NN", "PPER", "PTKNEG", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Freundschaft teilet sich. Wolan, er ist gefunden,", "tokens": ["Die", "Freund\u00b7schaft", "tei\u00b7let", "sich", ".", "Wo\u00b7lan", ",", "er", "ist", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$.", "ADV", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "der dieses Tags ist wert. Er sei hiermit gebunden", "tokens": ["der", "die\u00b7ses", "Tags", "ist", "wert", ".", "Er", "sei", "hier\u00b7mit", "ge\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PDAT", "NN", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "PAV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "an der Statt, die er meint, und halte di\u00df darf\u00fcr:", "tokens": ["an", "der", "Statt", ",", "die", "er", "meint", ",", "und", "hal\u00b7te", "di\u00df", "dar\u00b7f\u00fcr", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "VVFIN", "PDS", "PAV", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "ie besser er sich l\u00f6st, ie lieber ist es ihr.", "tokens": ["ie", "bes\u00b7ser", "er", "sich", "l\u00f6st", ",", "ie", "lie\u00b7ber", "ist", "es", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "VVFIN", "$,", "ADV", "ADV", "VAFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wir w\u00fcndschen ihm und ihr viel tausent guter Stunden,", "tokens": ["Wir", "w\u00fcnd\u00b7schen", "ihm", "und", "ihr", "viel", "tau\u00b7sent", "gu\u00b7ter", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PPER", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "viel tausent lieber Zeit. So sind sie wol gebunden,", "tokens": ["viel", "tau\u00b7sent", "lie\u00b7ber", "Zeit", ".", "So", "sind", "sie", "wol", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "zwar er f\u00fcr sie allhier und sie in ihrer Statt.", "tokens": ["zwar", "er", "f\u00fcr", "sie", "all\u00b7hier", "und", "sie", "in", "ih\u00b7rer", "Statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "PPER", "ADV", "KON", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-----+-+-+-+", "measure": "unknown.measure.tetra"}, "line.19": {"text": "so wird ein iedes sehn, wo sichs zu l\u00f6sen hat.", "tokens": ["so", "wird", "ein", "ie\u00b7des", "sehn", ",", "wo", "sichs", "zu", "l\u00f6\u00b7sen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "PIS", "VVINF", "$,", "PWAV", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}