{"textgrid.poem.41170": {"metadata": {"author": {"name": "Kerner, Justinus", "birth": "N.A.", "death": "N.A."}, "title": "8.", "genre": "verse", "period": "N.A.", "pub_year": 1824, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df ich ein Paar auch aus dem Hexenkluppe,", "tokens": ["Da\u00df", "ich", "ein", "Paar", "auch", "aus", "dem", "He\u00b7xen\u00b7klup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Die Amm' und die von ihr verhexte Puppe,", "tokens": ["Die", "Amm'", "und", "die", "von", "ihr", "ver\u00b7hex\u00b7te", "Pup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Klecksographierte ohne R\u00fccksicht dreist,", "tokens": ["Kleck\u00b7so\u00b7gra\u00b7phier\u00b7te", "oh\u00b7ne", "R\u00fcck\u00b7sicht", "dreist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Das hat emp\u00f6ret eine ganze Gruppe", "tokens": ["Das", "hat", "em\u00b7p\u00f6\u00b7ret", "ei\u00b7ne", "gan\u00b7ze", "Grup\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Beisitzer aus dem alten H\u00f6llenpfuhl,", "tokens": ["Bei\u00b7sit\u00b7zer", "aus", "dem", "al\u00b7ten", "H\u00f6l\u00b7len\u00b7pfuhl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Aufkl\u00e4rlinge, Ungl\u00e4ubige, allermeist", "tokens": ["Auf\u00b7kl\u00e4r\u00b7lin\u00b7ge", ",", "Un\u00b7gl\u00e4u\u00b7bi\u00b7ge", ",", "al\u00b7ler\u00b7meist"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ADJA", "$,", "XY"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Z\u00f6glinge aus Mephistos Musterschule,", "tokens": ["Z\u00f6g\u00b7lin\u00b7ge", "aus", "Me\u00b7phis\u00b7tos", "Mus\u00b7ter\u00b7schu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df sie aus ihrem Scho\u00df ", "tokens": ["Da\u00df", "sie", "aus", "ih\u00b7rem", "Scho\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Emporgeschickt, um vom Klecksographenstuhle", "tokens": ["Em\u00b7por\u00b7ge\u00b7schickt", ",", "um", "vom", "Kleck\u00b7so\u00b7gra\u00b7phen\u00b7stuh\u00b7le"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUI", "APPRART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Zu sto\u00dfen mich, zu brechen mir den Hals.", "tokens": ["Zu", "sto\u00b7\u00dfen", "mich", ",", "zu", "bre\u00b7chen", "mir", "den", "Hals", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "$,", "PTKZU", "VVINF", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ich sah ihn l\u00e4chelnd an, sprach gar nichts als:", "tokens": ["Ich", "sah", "ihn", "l\u00e4\u00b7chelnd", "an", ",", "sprach", "gar", "nichts", "als", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "VVFIN", "ADV", "PIS", "KOKOM", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbgelobt sei Jesus Christ!\u00ab \u2013 da fuhr er pl\u00f6tzlich", "tokens": ["\u00bb", "ge\u00b7lobt", "sei", "Je\u00b7sus", "Christ", "!", "\u00ab", "\u2013", "da", "fuhr", "er", "pl\u00f6tz\u00b7lich"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVPP", "VAFIN", "NE", "NE", "$.", "$(", "$(", "ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Hinab mit einem Wehschrei, der entsetzlich.", "tokens": ["Hin\u00b7ab", "mit", "ei\u00b7nem", "Weh\u00b7schrei", ",", "der", "ent\u00b7setz\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PRELS", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Da\u00df ich ein Paar auch aus dem Hexenkluppe,", "tokens": ["Da\u00df", "ich", "ein", "Paar", "auch", "aus", "dem", "He\u00b7xen\u00b7klup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Die Amm' und die von ihr verhexte Puppe,", "tokens": ["Die", "Amm'", "und", "die", "von", "ihr", "ver\u00b7hex\u00b7te", "Pup\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Klecksographierte ohne R\u00fccksicht dreist,", "tokens": ["Kleck\u00b7so\u00b7gra\u00b7phier\u00b7te", "oh\u00b7ne", "R\u00fcck\u00b7sicht", "dreist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Das hat emp\u00f6ret eine ganze Gruppe", "tokens": ["Das", "hat", "em\u00b7p\u00f6\u00b7ret", "ei\u00b7ne", "gan\u00b7ze", "Grup\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Beisitzer aus dem alten H\u00f6llenpfuhl,", "tokens": ["Bei\u00b7sit\u00b7zer", "aus", "dem", "al\u00b7ten", "H\u00f6l\u00b7len\u00b7pfuhl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Aufkl\u00e4rlinge, Ungl\u00e4ubige, allermeist", "tokens": ["Auf\u00b7kl\u00e4r\u00b7lin\u00b7ge", ",", "Un\u00b7gl\u00e4u\u00b7bi\u00b7ge", ",", "al\u00b7ler\u00b7meist"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ADJA", "$,", "XY"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Z\u00f6glinge aus Mephistos Musterschule,", "tokens": ["Z\u00f6g\u00b7lin\u00b7ge", "aus", "Me\u00b7phis\u00b7tos", "Mus\u00b7ter\u00b7schu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df sie aus ihrem Scho\u00df ", "tokens": ["Da\u00df", "sie", "aus", "ih\u00b7rem", "Scho\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Emporgeschickt, um vom Klecksographenstuhle", "tokens": ["Em\u00b7por\u00b7ge\u00b7schickt", ",", "um", "vom", "Kleck\u00b7so\u00b7gra\u00b7phen\u00b7stuh\u00b7le"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUI", "APPRART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Zu sto\u00dfen mich, zu brechen mir den Hals.", "tokens": ["Zu", "sto\u00b7\u00dfen", "mich", ",", "zu", "bre\u00b7chen", "mir", "den", "Hals", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "$,", "PTKZU", "VVINF", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ich sah ihn l\u00e4chelnd an, sprach gar nichts als:", "tokens": ["Ich", "sah", "ihn", "l\u00e4\u00b7chelnd", "an", ",", "sprach", "gar", "nichts", "als", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "VVFIN", "ADV", "PIS", "KOKOM", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbgelobt sei Jesus Christ!\u00ab \u2013 da fuhr er pl\u00f6tzlich", "tokens": ["\u00bb", "ge\u00b7lobt", "sei", "Je\u00b7sus", "Christ", "!", "\u00ab", "\u2013", "da", "fuhr", "er", "pl\u00f6tz\u00b7lich"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVPP", "VAFIN", "NE", "NE", "$.", "$(", "$(", "ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Hinab mit einem Wehschrei, der entsetzlich.", "tokens": ["Hin\u00b7ab", "mit", "ei\u00b7nem", "Weh\u00b7schrei", ",", "der", "ent\u00b7setz\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PRELS", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}