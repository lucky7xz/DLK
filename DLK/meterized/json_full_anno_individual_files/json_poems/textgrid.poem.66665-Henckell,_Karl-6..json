{"textgrid.poem.66665": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "6.", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer sprach mir denn von einem trocknen Tone,", "tokens": ["Wer", "sprach", "mir", "denn", "von", "ei\u00b7nem", "trock\u00b7nen", "To\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der h\u00f6rbar wird, sobald der Schleier fiel?", "tokens": ["Der", "h\u00f6r\u00b7bar", "wird", ",", "so\u00b7bald", "der", "Schlei\u00b7er", "fiel", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Liebe sei gewi\u00df der Dichtung Krone,", "tokens": ["Die", "Lie\u00b7be", "sei", "ge\u00b7wi\u00df", "der", "Dich\u00b7tung", "Kro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch nur im Walter-Vogelweide-Stil.", "tokens": ["Doch", "nur", "im", "Wal\u00b7ter\u00b7Vo\u00b7gel\u00b7wei\u00b7de\u00b7Stil", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Poetisch sei die Minnes\u00e4ngerzone,", "tokens": ["Poe\u00b7tisch", "sei", "die", "Min\u00b7ne\u00b7s\u00e4n\u00b7ger\u00b7zo\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Der standesamtentr\u00fcckte Dichterkiel,", "tokens": ["Der", "stan\u00b7des\u00b7am\u00b7ten\u00b7tr\u00fcck\u00b7te", "Dich\u00b7ter\u00b7kiel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Doch ehkontraktlich festgelegt und h\u00e4uslich", "tokens": ["Doch", "eh\u00b7kon\u00b7trakt\u00b7lich", "fest\u00b7ge\u00b7legt", "und", "h\u00e4us\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVPP", "KON", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sei die Erotik maustot oder scheu\u00dflich.", "tokens": ["Sei", "die", "E\u00b7ro\u00b7tik", "maus\u00b7tot", "o\u00b7der", "scheu\u00df\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Herr sprach so, weil er's nicht besser kannte,", "tokens": ["Der", "Herr", "sprach", "so", ",", "weil", "er's", "nicht", "bes\u00b7ser", "kann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "KOUS", "PIS", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zwar h\u00e4ufig trifft die Wandlung leider zu.", "tokens": ["Zwar", "h\u00e4u\u00b7fig", "trifft", "die", "Wand\u00b7lung", "lei\u00b7der", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "An Beatrice sang der gro\u00dfe Dante", "tokens": ["An", "Be\u00b7at\u00b7ri\u00b7ce", "sang", "der", "gro\u00b7\u00dfe", "Dan\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sein g\u00f6ttlich Lied. Sein Weib lie\u00df er in Ruh.", "tokens": ["Sein", "g\u00f6tt\u00b7lich", "Lied", ".", "Sein", "Weib", "lie\u00df", "er", "in", "Ruh", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie gab ihm nichts, wof\u00fcr sein Herz entbrannte,", "tokens": ["Sie", "gab", "ihm", "nichts", ",", "wo\u00b7f\u00fcr", "sein", "Herz", "ent\u00b7brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Vier Kinder nur, indes \u2013 ", "tokens": ["Vier", "Kin\u00b7der", "nur", ",", "in\u00b7des", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["CARD", "NN", "ADV", "$,", "ADV", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Weil aus \u00bbVernunft\u00ab er nahm Donatis Gemma,", "tokens": ["Weil", "aus", "\u00bb", "Ver\u00b7nunft", "\u00ab", "er", "nahm", "Do\u00b7na\u00b7tis", "Gem\u00b7ma", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "$(", "NN", "$(", "PPER", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Mu\u00dft' ihn Beatrix ziehn aus dem Dilemma.", "tokens": ["Mu\u00dft'", "ihn", "Be\u00b7at\u00b7rix", "ziehn", "aus", "dem", "Di\u00b7lem\u00b7ma", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NE", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}}, "stanza.3": {"line.1": {"text": "Wie traurig, wenn der Spiritus der Liebe", "tokens": ["Wie", "trau\u00b7rig", ",", "wenn", "der", "Spi\u00b7ri\u00b7tus", "der", "Lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "KOUS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vom heiligen Ehebette wird erstickt!", "tokens": ["Vom", "hei\u00b7li\u00b7gen", "E\u00b7he\u00b7bet\u00b7te", "wird", "er\u00b7stickt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sind denn die Myrten R\u00e4uber oder Diebe,", "tokens": ["Sind", "denn", "die", "Myr\u00b7ten", "R\u00e4u\u00b7ber", "o\u00b7der", "Die\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Davor die Muse meilenweit erschrickt?", "tokens": ["Da\u00b7vor", "die", "Mu\u00b7se", "mei\u00b7len\u00b7weit", "er\u00b7schrickt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn ich die \u00bbBeichte eines Toren\u00ab schriebe,", "tokens": ["Wenn", "ich", "die", "\u00bb", "Beich\u00b7te", "ei\u00b7nes", "To\u00b7ren", "\u00ab", "schrie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "$(", "NN", "ART", "NN", "$(", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "W\u00e4r's, weil ich Gift statt Honigbrot gepickt \u2013", "tokens": ["W\u00e4r's", ",", "weil", "ich", "Gift", "statt", "Ho\u00b7nig\u00b7brot", "ge\u00b7pickt", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Doch wenn ich mir ein musisch Weib genommen,", "tokens": ["Doch", "wenn", "ich", "mir", "ein", "mu\u00b7si\u00b7sch", "Weib", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ART", "ADJD", "NN", "VVPP", "$,"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Braucht dann mein Lied auch auf den Hund zu kommen?", "tokens": ["Braucht", "dann", "mein", "Lied", "auch", "auf", "den", "Hund", "zu", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ein musisch Weib \u2013 das hei\u00dft nicht, da\u00df sie dichtet!", "tokens": ["Ein", "mu\u00b7si\u00b7sch", "Weib", "\u2013", "das", "hei\u00dft", "nicht", ",", "da\u00df", "sie", "dich\u00b7tet", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$(", "PDS", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "F\u00fcr ", "tokens": ["F\u00fcr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Das h\u00e4tte mich schon l\u00e4ngst zugrund gerichtet,", "tokens": ["Das", "h\u00e4t\u00b7te", "mich", "schon", "l\u00e4ngst", "zu\u00b7grund", "ge\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn sie noch peitschte gar der Verse Flut.", "tokens": ["Wenn", "sie", "noch", "peitschte", "gar", "der", "Ver\u00b7se", "Flut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Auf Wettbewerb mit Sappho hat verzichtet", "tokens": ["Auf", "Wett\u00b7be\u00b7werb", "mit", "Sap\u00b7pho", "hat", "ver\u00b7zich\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sie von Natur \u2013 und das ist sch\u00f6n und gut \u2013", "tokens": ["Sie", "von", "Na\u00b7tur", "\u2013", "und", "das", "ist", "sch\u00f6n", "und", "gut", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "$(", "KON", "PDS", "VAFIN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sonst m\u00fc\u00dft' ich sicher sie noch kritisch schelten,", "tokens": ["Sonst", "m\u00fc\u00dft'", "ich", "si\u00b7cher", "sie", "noch", "kri\u00b7tisch", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Annetten Droste-H\u00fclshoffs sind so selten.", "tokens": ["An\u00b7net\u00b7ten", "Dros\u00b7te\u00b7H\u00fcls\u00b7hoffs", "sind", "so", "sel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ein musisch Weib \u2013 wie l\u00e4\u00dft das kurz sich packen,", "tokens": ["Ein", "mu\u00b7si\u00b7sch", "Weib", "\u2013", "wie", "l\u00e4\u00dft", "das", "kurz", "sich", "pa\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$(", "PWAV", "VVFIN", "ART", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ganz knapp und ohne gro\u00dfen Wortebrei?", "tokens": ["Ganz", "knapp", "und", "oh\u00b7ne", "gro\u00b7\u00dfen", "Wort\u00b7e\u00b7brei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie ist aus dichterischem Teig gebacken,", "tokens": ["Sie", "ist", "aus", "dich\u00b7te\u00b7ri\u00b7schem", "Teig", "ge\u00b7ba\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch vom aktiven Dichterwahnsinn frei.", "tokens": ["Doch", "vom", "ak\u00b7ti\u00b7ven", "Dich\u00b7ter\u00b7wahn\u00b7sinn", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Sie neigt verst\u00e4ndnisvoll den stolzen Nacken", "tokens": ["Sie", "neigt", "ver\u00b7st\u00e4nd\u00b7nis\u00b7voll", "den", "stol\u00b7zen", "Na\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und horcht herzinnig, weit vom Marktgeschrei,", "tokens": ["Und", "horcht", "her\u00b7zin\u00b7nig", ",", "weit", "vom", "Markt\u00b7ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Botschaft aus den stilleren Gefilden,", "tokens": ["Der", "Bot\u00b7schaft", "aus", "den", "stil\u00b7le\u00b7ren", "Ge\u00b7fil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wo sich der K\u00fcnste Wunderbl\u00fcten bilden.", "tokens": ["Wo", "sich", "der", "K\u00fcns\u00b7te", "Wun\u00b7der\u00b7bl\u00fc\u00b7ten", "bil\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ein musisch Weib \u2013 ich mag kein Ruhmeslaller", "tokens": ["Ein", "mu\u00b7si\u00b7sch", "Weib", "\u2013", "ich", "mag", "kein", "Ruh\u00b7mes\u00b7lal\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "$(", "PPER", "VMFIN", "PIAT", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der treusten Herzenskameradin sein,", "tokens": ["Der", "treus\u00b7ten", "Her\u00b7zen\u00b7ska\u00b7me\u00b7ra\u00b7din", "sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die fern sich h\u00e4lt vom Schwarm der Scheingefaller", "tokens": ["Die", "fern", "sich", "h\u00e4lt", "vom", "Schwarm", "der", "Schein\u00b7ge\u00b7fal\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "PRF", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und einzig liebt, was wahr, nat\u00fcrlich, rein.", "tokens": ["Und", "ein\u00b7zig", "liebt", ",", "was", "wahr", ",", "na\u00b7t\u00fcr\u00b7lich", ",", "rein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "PWS", "ADJD", "$,", "ADV", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Spukt noch von ihrem Stammverwandten Haller", "tokens": ["Spukt", "noch", "von", "ih\u00b7rem", "Stamm\u00b7ver\u00b7wand\u00b7ten", "Hal\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ein St\u00fcck Natur in ihrem Fleisch und Bein?", "tokens": ["Ein", "St\u00fcck", "Na\u00b7tur", "in", "ih\u00b7rem", "Fleisch", "und", "Bein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Enziane mu\u00df ich in ihr lieben,", "tokens": ["Die", "En\u00b7zi\u00b7a\u00b7ne", "mu\u00df", "ich", "in", "ihr", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die zart in seinen \u00bbAlpen\u00ab er beschrieben.", "tokens": ["Die", "zart", "in", "sei\u00b7nen", "\u00bb", "Al\u00b7pen", "\u00ab", "er", "be\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPOSAT", "$(", "NN", "$(", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "\u00bbdas hohe Haupt der Edelenziane", "tokens": ["\u00bb", "das", "ho\u00b7he", "Haupt", "der", "E\u00b7de\u00b7len\u00b7zi\u00b7a\u00b7ne"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ragt \u00fcberm Chor der P\u00f6belkr\u00e4uter hin,", "tokens": ["Ragt", "\u00fc\u00b7berm", "Chor", "der", "P\u00f6\u00b7bel\u00b7kr\u00e4u\u00b7ter", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Blumenvolk dient unter ihrer Fahne,", "tokens": ["Ein", "Blu\u00b7men\u00b7volk", "dient", "un\u00b7ter", "ih\u00b7rer", "Fah\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Grauwei\u00df ihr Blatt, Gold kr\u00f6nt die K\u00f6nigin.\u00ab", "tokens": ["Grau\u00b7wei\u00df", "ihr", "Blatt", ",", "Gold", "kr\u00f6nt", "die", "K\u00f6\u00b7ni\u00b7gin", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "NN", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So etwa sang der Liebsten Urgro\u00dfahne", "tokens": ["So", "et\u00b7wa", "sang", "der", "Liebs\u00b7ten", "Ur\u00b7gro\u00df\u00b7ah\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und gab dem Blumenbilde holden Sinn:", "tokens": ["Und", "gab", "dem", "Blu\u00b7men\u00b7bil\u00b7de", "hol\u00b7den", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbgerecht Gesetz! Da\u00df Kraft sich Zier verm\u00e4hle,", "tokens": ["\u00bb", "ge\u00b7recht", "Ge\u00b7setz", "!", "Da\u00df", "Kraft", "sich", "Zier", "ver\u00b7m\u00e4h\u00b7le", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$.", "KOUS", "NN", "PRF", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In sch\u00f6nem Leib wohnt eine sch\u00f6ne Seele.\u00ab", "tokens": ["In", "sch\u00f6\u00b7nem", "Leib", "wohnt", "ei\u00b7ne", "sch\u00f6\u00b7ne", "See\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Schon seh ich dich in Scham dein Auge decken,", "tokens": ["Schon", "seh", "ich", "dich", "in", "Scham", "dein", "Au\u00b7ge", "de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn du vernimmst, was ich von dir gesagt,", "tokens": ["Wenn", "du", "ver\u00b7nimmst", ",", "was", "ich", "von", "dir", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWS", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du m\u00f6chtest dich am liebsten mir verstecken,", "tokens": ["Du", "m\u00f6ch\u00b7test", "dich", "am", "liebs\u00b7ten", "mir", "ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PTKA", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil deinen Sinn die Eitelkeit nicht plagt.", "tokens": ["Weil", "dei\u00b7nen", "Sinn", "die", "Ei\u00b7tel\u00b7keit", "nicht", "plagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "O du! Mit Schmeichelei dich zu beflecken,", "tokens": ["O", "du", "!", "Mit", "Schmei\u00b7che\u00b7lei", "dich", "zu", "be\u00b7fle\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Hab ich verachtet stets und nie gewagt.", "tokens": ["Hab", "ich", "ver\u00b7ach\u00b7tet", "stets", "und", "nie", "ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "ADV", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Recht schroff und rauh bin ich dir oft gekommen,", "tokens": ["Recht", "schroff", "und", "rauh", "bin", "ich", "dir", "oft", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "ADJD", "VAFIN", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Drum sei von echtem Lobe nicht beklommen!", "tokens": ["Drum", "sei", "von", "ech\u00b7tem", "Lo\u00b7be", "nicht", "be\u00b7klom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "APPR", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Du wei\u00dft, wir haben beide harte K\u00f6pfe,", "tokens": ["Du", "wei\u00dft", ",", "wir", "ha\u00b7ben", "bei\u00b7de", "har\u00b7te", "K\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ich kann brausen wie ein Katarakt,", "tokens": ["Und", "ich", "kann", "brau\u00b7sen", "wie", "ein", "Ka\u00b7ta\u00b7rakt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir sind zwei leidenschaftliche Gesch\u00f6pfe", "tokens": ["Wir", "sind", "zwei", "lei\u00b7den\u00b7schaft\u00b7li\u00b7che", "Ge\u00b7sch\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schenken uns die Wahrheit splitternackt.", "tokens": ["Und", "schen\u00b7ken", "uns", "die", "Wahr\u00b7heit", "split\u00b7ter\u00b7nackt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir warfen ins Gesicht uns keine T\u00f6pfe,", "tokens": ["Wir", "war\u00b7fen", "ins", "Ge\u00b7sicht", "uns", "kei\u00b7ne", "T\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch hat's geblitzt ... Nun aber geht's im Takt.", "tokens": ["Doch", "hat's", "ge\u00b7blitzt", "...", "Nun", "a\u00b7ber", "geht's", "im", "Takt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$(", "ADV", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zwei Willen l\u00e4uterten sich mild zum Bunde", "tokens": ["Zwei", "Wil\u00b7len", "l\u00e4u\u00b7ter\u00b7ten", "sich", "mild", "zum", "Bun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PRF", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Durch jene Liebe, die sich sucht im Grunde.", "tokens": ["Durch", "je\u00b7ne", "Lie\u00b7be", ",", "die", "sich", "sucht", "im", "Grun\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PRF", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wer sprach mir denn von einem trocknen Tone,", "tokens": ["Wer", "sprach", "mir", "denn", "von", "ei\u00b7nem", "trock\u00b7nen", "To\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der h\u00f6rbar wird, sobald der Schleier fiel?", "tokens": ["Der", "h\u00f6r\u00b7bar", "wird", ",", "so\u00b7bald", "der", "Schlei\u00b7er", "fiel", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Liebe sei gewi\u00df der Dichtung Krone,", "tokens": ["Die", "Lie\u00b7be", "sei", "ge\u00b7wi\u00df", "der", "Dich\u00b7tung", "Kro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch nur im Walter-Vogelweide-Stil.", "tokens": ["Doch", "nur", "im", "Wal\u00b7ter\u00b7Vo\u00b7gel\u00b7wei\u00b7de\u00b7Stil", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Poetisch sei die Minnes\u00e4ngerzone,", "tokens": ["Poe\u00b7tisch", "sei", "die", "Min\u00b7ne\u00b7s\u00e4n\u00b7ger\u00b7zo\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Der standesamtentr\u00fcckte Dichterkiel,", "tokens": ["Der", "stan\u00b7des\u00b7am\u00b7ten\u00b7tr\u00fcck\u00b7te", "Dich\u00b7ter\u00b7kiel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Doch ehkontraktlich festgelegt und h\u00e4uslich", "tokens": ["Doch", "eh\u00b7kon\u00b7trakt\u00b7lich", "fest\u00b7ge\u00b7legt", "und", "h\u00e4us\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVPP", "KON", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sei die Erotik maustot oder scheu\u00dflich.", "tokens": ["Sei", "die", "E\u00b7ro\u00b7tik", "maus\u00b7tot", "o\u00b7der", "scheu\u00df\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Herr sprach so, weil er's nicht besser kannte,", "tokens": ["Der", "Herr", "sprach", "so", ",", "weil", "er's", "nicht", "bes\u00b7ser", "kann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "KOUS", "PIS", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zwar h\u00e4ufig trifft die Wandlung leider zu.", "tokens": ["Zwar", "h\u00e4u\u00b7fig", "trifft", "die", "Wand\u00b7lung", "lei\u00b7der", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "An Beatrice sang der gro\u00dfe Dante", "tokens": ["An", "Be\u00b7at\u00b7ri\u00b7ce", "sang", "der", "gro\u00b7\u00dfe", "Dan\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sein g\u00f6ttlich Lied. Sein Weib lie\u00df er in Ruh.", "tokens": ["Sein", "g\u00f6tt\u00b7lich", "Lied", ".", "Sein", "Weib", "lie\u00df", "er", "in", "Ruh", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie gab ihm nichts, wof\u00fcr sein Herz entbrannte,", "tokens": ["Sie", "gab", "ihm", "nichts", ",", "wo\u00b7f\u00fcr", "sein", "Herz", "ent\u00b7brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Vier Kinder nur, indes \u2013 ", "tokens": ["Vier", "Kin\u00b7der", "nur", ",", "in\u00b7des", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["CARD", "NN", "ADV", "$,", "ADV", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Weil aus \u00bbVernunft\u00ab er nahm Donatis Gemma,", "tokens": ["Weil", "aus", "\u00bb", "Ver\u00b7nunft", "\u00ab", "er", "nahm", "Do\u00b7na\u00b7tis", "Gem\u00b7ma", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "$(", "NN", "$(", "PPER", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Mu\u00dft' ihn Beatrix ziehn aus dem Dilemma.", "tokens": ["Mu\u00dft'", "ihn", "Be\u00b7at\u00b7rix", "ziehn", "aus", "dem", "Di\u00b7lem\u00b7ma", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NE", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}}, "stanza.12": {"line.1": {"text": "Wie traurig, wenn der Spiritus der Liebe", "tokens": ["Wie", "trau\u00b7rig", ",", "wenn", "der", "Spi\u00b7ri\u00b7tus", "der", "Lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "KOUS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vom heiligen Ehebette wird erstickt!", "tokens": ["Vom", "hei\u00b7li\u00b7gen", "E\u00b7he\u00b7bet\u00b7te", "wird", "er\u00b7stickt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sind denn die Myrten R\u00e4uber oder Diebe,", "tokens": ["Sind", "denn", "die", "Myr\u00b7ten", "R\u00e4u\u00b7ber", "o\u00b7der", "Die\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Davor die Muse meilenweit erschrickt?", "tokens": ["Da\u00b7vor", "die", "Mu\u00b7se", "mei\u00b7len\u00b7weit", "er\u00b7schrickt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn ich die \u00bbBeichte eines Toren\u00ab schriebe,", "tokens": ["Wenn", "ich", "die", "\u00bb", "Beich\u00b7te", "ei\u00b7nes", "To\u00b7ren", "\u00ab", "schrie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "$(", "NN", "ART", "NN", "$(", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "W\u00e4r's, weil ich Gift statt Honigbrot gepickt \u2013", "tokens": ["W\u00e4r's", ",", "weil", "ich", "Gift", "statt", "Ho\u00b7nig\u00b7brot", "ge\u00b7pickt", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Doch wenn ich mir ein musisch Weib genommen,", "tokens": ["Doch", "wenn", "ich", "mir", "ein", "mu\u00b7si\u00b7sch", "Weib", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ART", "ADJD", "NN", "VVPP", "$,"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Braucht dann mein Lied auch auf den Hund zu kommen?", "tokens": ["Braucht", "dann", "mein", "Lied", "auch", "auf", "den", "Hund", "zu", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Ein musisch Weib \u2013 das hei\u00dft nicht, da\u00df sie dichtet!", "tokens": ["Ein", "mu\u00b7si\u00b7sch", "Weib", "\u2013", "das", "hei\u00dft", "nicht", ",", "da\u00df", "sie", "dich\u00b7tet", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$(", "PDS", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "F\u00fcr ", "tokens": ["F\u00fcr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Das h\u00e4tte mich schon l\u00e4ngst zugrund gerichtet,", "tokens": ["Das", "h\u00e4t\u00b7te", "mich", "schon", "l\u00e4ngst", "zu\u00b7grund", "ge\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn sie noch peitschte gar der Verse Flut.", "tokens": ["Wenn", "sie", "noch", "peitschte", "gar", "der", "Ver\u00b7se", "Flut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Auf Wettbewerb mit Sappho hat verzichtet", "tokens": ["Auf", "Wett\u00b7be\u00b7werb", "mit", "Sap\u00b7pho", "hat", "ver\u00b7zich\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sie von Natur \u2013 und das ist sch\u00f6n und gut \u2013", "tokens": ["Sie", "von", "Na\u00b7tur", "\u2013", "und", "das", "ist", "sch\u00f6n", "und", "gut", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "$(", "KON", "PDS", "VAFIN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sonst m\u00fc\u00dft' ich sicher sie noch kritisch schelten,", "tokens": ["Sonst", "m\u00fc\u00dft'", "ich", "si\u00b7cher", "sie", "noch", "kri\u00b7tisch", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Annetten Droste-H\u00fclshoffs sind so selten.", "tokens": ["An\u00b7net\u00b7ten", "Dros\u00b7te\u00b7H\u00fcls\u00b7hoffs", "sind", "so", "sel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Ein musisch Weib \u2013 wie l\u00e4\u00dft das kurz sich packen,", "tokens": ["Ein", "mu\u00b7si\u00b7sch", "Weib", "\u2013", "wie", "l\u00e4\u00dft", "das", "kurz", "sich", "pa\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$(", "PWAV", "VVFIN", "ART", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ganz knapp und ohne gro\u00dfen Wortebrei?", "tokens": ["Ganz", "knapp", "und", "oh\u00b7ne", "gro\u00b7\u00dfen", "Wort\u00b7e\u00b7brei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie ist aus dichterischem Teig gebacken,", "tokens": ["Sie", "ist", "aus", "dich\u00b7te\u00b7ri\u00b7schem", "Teig", "ge\u00b7ba\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch vom aktiven Dichterwahnsinn frei.", "tokens": ["Doch", "vom", "ak\u00b7ti\u00b7ven", "Dich\u00b7ter\u00b7wahn\u00b7sinn", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Sie neigt verst\u00e4ndnisvoll den stolzen Nacken", "tokens": ["Sie", "neigt", "ver\u00b7st\u00e4nd\u00b7nis\u00b7voll", "den", "stol\u00b7zen", "Na\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und horcht herzinnig, weit vom Marktgeschrei,", "tokens": ["Und", "horcht", "her\u00b7zin\u00b7nig", ",", "weit", "vom", "Markt\u00b7ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Botschaft aus den stilleren Gefilden,", "tokens": ["Der", "Bot\u00b7schaft", "aus", "den", "stil\u00b7le\u00b7ren", "Ge\u00b7fil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wo sich der K\u00fcnste Wunderbl\u00fcten bilden.", "tokens": ["Wo", "sich", "der", "K\u00fcns\u00b7te", "Wun\u00b7der\u00b7bl\u00fc\u00b7ten", "bil\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Ein musisch Weib \u2013 ich mag kein Ruhmeslaller", "tokens": ["Ein", "mu\u00b7si\u00b7sch", "Weib", "\u2013", "ich", "mag", "kein", "Ruh\u00b7mes\u00b7lal\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "$(", "PPER", "VMFIN", "PIAT", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der treusten Herzenskameradin sein,", "tokens": ["Der", "treus\u00b7ten", "Her\u00b7zen\u00b7ska\u00b7me\u00b7ra\u00b7din", "sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die fern sich h\u00e4lt vom Schwarm der Scheingefaller", "tokens": ["Die", "fern", "sich", "h\u00e4lt", "vom", "Schwarm", "der", "Schein\u00b7ge\u00b7fal\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "PRF", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und einzig liebt, was wahr, nat\u00fcrlich, rein.", "tokens": ["Und", "ein\u00b7zig", "liebt", ",", "was", "wahr", ",", "na\u00b7t\u00fcr\u00b7lich", ",", "rein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "PWS", "ADJD", "$,", "ADV", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Spukt noch von ihrem Stammverwandten Haller", "tokens": ["Spukt", "noch", "von", "ih\u00b7rem", "Stamm\u00b7ver\u00b7wand\u00b7ten", "Hal\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ein St\u00fcck Natur in ihrem Fleisch und Bein?", "tokens": ["Ein", "St\u00fcck", "Na\u00b7tur", "in", "ih\u00b7rem", "Fleisch", "und", "Bein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Enziane mu\u00df ich in ihr lieben,", "tokens": ["Die", "En\u00b7zi\u00b7a\u00b7ne", "mu\u00df", "ich", "in", "ihr", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die zart in seinen \u00bbAlpen\u00ab er beschrieben.", "tokens": ["Die", "zart", "in", "sei\u00b7nen", "\u00bb", "Al\u00b7pen", "\u00ab", "er", "be\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPOSAT", "$(", "NN", "$(", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "\u00bbdas hohe Haupt der Edelenziane", "tokens": ["\u00bb", "das", "ho\u00b7he", "Haupt", "der", "E\u00b7de\u00b7len\u00b7zi\u00b7a\u00b7ne"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ragt \u00fcberm Chor der P\u00f6belkr\u00e4uter hin,", "tokens": ["Ragt", "\u00fc\u00b7berm", "Chor", "der", "P\u00f6\u00b7bel\u00b7kr\u00e4u\u00b7ter", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Blumenvolk dient unter ihrer Fahne,", "tokens": ["Ein", "Blu\u00b7men\u00b7volk", "dient", "un\u00b7ter", "ih\u00b7rer", "Fah\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Grauwei\u00df ihr Blatt, Gold kr\u00f6nt die K\u00f6nigin.\u00ab", "tokens": ["Grau\u00b7wei\u00df", "ihr", "Blatt", ",", "Gold", "kr\u00f6nt", "die", "K\u00f6\u00b7ni\u00b7gin", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "NN", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So etwa sang der Liebsten Urgro\u00dfahne", "tokens": ["So", "et\u00b7wa", "sang", "der", "Liebs\u00b7ten", "Ur\u00b7gro\u00df\u00b7ah\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und gab dem Blumenbilde holden Sinn:", "tokens": ["Und", "gab", "dem", "Blu\u00b7men\u00b7bil\u00b7de", "hol\u00b7den", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbgerecht Gesetz! Da\u00df Kraft sich Zier verm\u00e4hle,", "tokens": ["\u00bb", "ge\u00b7recht", "Ge\u00b7setz", "!", "Da\u00df", "Kraft", "sich", "Zier", "ver\u00b7m\u00e4h\u00b7le", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$.", "KOUS", "NN", "PRF", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In sch\u00f6nem Leib wohnt eine sch\u00f6ne Seele.\u00ab", "tokens": ["In", "sch\u00f6\u00b7nem", "Leib", "wohnt", "ei\u00b7ne", "sch\u00f6\u00b7ne", "See\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Schon seh ich dich in Scham dein Auge decken,", "tokens": ["Schon", "seh", "ich", "dich", "in", "Scham", "dein", "Au\u00b7ge", "de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn du vernimmst, was ich von dir gesagt,", "tokens": ["Wenn", "du", "ver\u00b7nimmst", ",", "was", "ich", "von", "dir", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWS", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du m\u00f6chtest dich am liebsten mir verstecken,", "tokens": ["Du", "m\u00f6ch\u00b7test", "dich", "am", "liebs\u00b7ten", "mir", "ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PTKA", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil deinen Sinn die Eitelkeit nicht plagt.", "tokens": ["Weil", "dei\u00b7nen", "Sinn", "die", "Ei\u00b7tel\u00b7keit", "nicht", "plagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "O du! Mit Schmeichelei dich zu beflecken,", "tokens": ["O", "du", "!", "Mit", "Schmei\u00b7che\u00b7lei", "dich", "zu", "be\u00b7fle\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Hab ich verachtet stets und nie gewagt.", "tokens": ["Hab", "ich", "ver\u00b7ach\u00b7tet", "stets", "und", "nie", "ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "ADV", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Recht schroff und rauh bin ich dir oft gekommen,", "tokens": ["Recht", "schroff", "und", "rauh", "bin", "ich", "dir", "oft", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "ADJD", "VAFIN", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Drum sei von echtem Lobe nicht beklommen!", "tokens": ["Drum", "sei", "von", "ech\u00b7tem", "Lo\u00b7be", "nicht", "be\u00b7klom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "APPR", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Du wei\u00dft, wir haben beide harte K\u00f6pfe,", "tokens": ["Du", "wei\u00dft", ",", "wir", "ha\u00b7ben", "bei\u00b7de", "har\u00b7te", "K\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ich kann brausen wie ein Katarakt,", "tokens": ["Und", "ich", "kann", "brau\u00b7sen", "wie", "ein", "Ka\u00b7ta\u00b7rakt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir sind zwei leidenschaftliche Gesch\u00f6pfe", "tokens": ["Wir", "sind", "zwei", "lei\u00b7den\u00b7schaft\u00b7li\u00b7che", "Ge\u00b7sch\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schenken uns die Wahrheit splitternackt.", "tokens": ["Und", "schen\u00b7ken", "uns", "die", "Wahr\u00b7heit", "split\u00b7ter\u00b7nackt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir warfen ins Gesicht uns keine T\u00f6pfe,", "tokens": ["Wir", "war\u00b7fen", "ins", "Ge\u00b7sicht", "uns", "kei\u00b7ne", "T\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch hat's geblitzt ... Nun aber geht's im Takt.", "tokens": ["Doch", "hat's", "ge\u00b7blitzt", "...", "Nun", "a\u00b7ber", "geht's", "im", "Takt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$(", "ADV", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zwei Willen l\u00e4uterten sich mild zum Bunde", "tokens": ["Zwei", "Wil\u00b7len", "l\u00e4u\u00b7ter\u00b7ten", "sich", "mild", "zum", "Bun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PRF", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Durch jene Liebe, die sich sucht im Grunde.", "tokens": ["Durch", "je\u00b7ne", "Lie\u00b7be", ",", "die", "sich", "sucht", "im", "Grun\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PRF", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}