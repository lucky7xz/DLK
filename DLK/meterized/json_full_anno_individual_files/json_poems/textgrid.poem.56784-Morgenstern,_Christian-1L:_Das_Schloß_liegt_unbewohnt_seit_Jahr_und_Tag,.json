{"textgrid.poem.56784": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das Schlo\u00df liegt unbewohnt seit Jahr und Tag,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Schlo\u00df liegt unbewohnt seit Jahr und Tag,", "tokens": ["Das", "Schlo\u00df", "liegt", "un\u00b7be\u00b7wohnt", "seit", "Jahr", "und", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der Park verwildert, pfadlos, unzug\u00e4nglich,", "tokens": ["der", "Park", "ver\u00b7wil\u00b7dert", ",", "pfad\u00b7los", ",", "un\u00b7zu\u00b7g\u00e4ng\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "dicht eingestr\u00fcppt von wirrem Wei\u00dfdornhag.", "tokens": ["dicht", "ein\u00b7ge\u00b7str\u00fcppt", "von", "wir\u00b7rem", "Wei\u00df\u00b7dorn\u00b7hag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wo Grotten, Treppen, H\u00fcgel uranf\u00e4nglich:", "tokens": ["Wo", "Grot\u00b7ten", ",", "Trep\u00b7pen", ",", "H\u00fc\u00b7gel", "u\u00b7ran\u00b7f\u00e4ng\u00b7lich", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "$,", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verfall nun: St\u00e4mme, Schutt, gesunkner Grund ...", "tokens": ["Ver\u00b7fall", "nun", ":", "St\u00e4m\u00b7me", ",", "Schutt", ",", "ge\u00b7sun\u00b7kner", "Grund", "..."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "NN", "$,", "NN", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "des Friedens St\u00e4tte einst, nun w\u00fcst und b\u00e4nglich.", "tokens": ["des", "Frie\u00b7dens", "St\u00e4t\u00b7te", "einst", ",", "nun", "w\u00fcst", "und", "b\u00e4ng\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "$,", "ADV", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "In dieses Parkes Tiefe birgt ein Rund", "tokens": ["In", "die\u00b7ses", "Par\u00b7kes", "Tie\u00b7fe", "birgt", "ein", "Rund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "von Birken zweier G\u00f6tter Steingebilde,", "tokens": ["von", "Bir\u00b7ken", "zwei\u00b7er", "G\u00f6t\u00b7ter", "Stein\u00b7ge\u00b7bil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Alten hochber\u00fchmt durch ihren Bund \u2013:", "tokens": ["den", "Al\u00b7ten", "hoch\u00b7be\u00b7r\u00fchmt", "durch", "ih\u00b7ren", "Bund", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "PPOSAT", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Den Gott des Krieges, mit zerbrochnem Schilde,", "tokens": ["Den", "Gott", "des", "Krie\u00b7ges", ",", "mit", "zer\u00b7broch\u00b7nem", "Schil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und sie, der Liebe hohe K\u00f6nigin,", "tokens": ["und", "sie", ",", "der", "Lie\u00b7be", "ho\u00b7he", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "in wohl gewahrter Lieblichkeit und Milde.", "tokens": ["in", "wohl", "ge\u00b7wahr\u00b7ter", "Lieb\u00b7lich\u00b7keit", "und", "Mil\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Sie blicken z\u00e4rtlich gen einander hin,", "tokens": ["Sie", "bli\u00b7cken", "z\u00e4rt\u00b7lich", "gen", "ein\u00b7an\u00b7der", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und bunte Falter tragen ihre Gr\u00fc\u00dfe, \u2013", "tokens": ["und", "bun\u00b7te", "Fal\u00b7ter", "tra\u00b7gen", "ih\u00b7re", "Gr\u00fc\u00b7\u00dfe", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "doch kennt ihr auch des Spiels geheimen Sinn? ...", "tokens": ["doch", "kennt", "ihr", "auch", "des", "Spiels", "ge\u00b7hei\u00b7men", "Sinn", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "In einer Sommermondnacht Wunders\u00fc\u00dfe,", "tokens": ["In", "ei\u00b7ner", "Som\u00b7mer\u00b7mond\u00b7nacht", "Wun\u00b7der\u00b7s\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "in einer Nacht, da eine Nachtigall", "tokens": ["in", "ei\u00b7ner", "Nacht", ",", "da", "ei\u00b7ne", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "tot niederst\u00fcrzte vor der G\u00f6ttin F\u00fc\u00dfe,", "tokens": ["tot", "nie\u00b7ders\u00b7t\u00fcrz\u00b7te", "vor", "der", "G\u00f6t\u00b7tin", "F\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "so wild war ihrer Sehnsucht \u00dcberschwall,", "tokens": ["so", "wild", "war", "ih\u00b7rer", "Sehn\u00b7sucht", "\u00dc\u00b7bersc\u00b7hwall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "in einer solchen Nacht des Drangs der S\u00e4fte", "tokens": ["in", "ei\u00b7ner", "sol\u00b7chen", "Nacht", "des", "Drangs", "der", "S\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "geschah der dunkle, unerh\u00f6rte Fall,", "tokens": ["ge\u00b7schah", "der", "dunk\u00b7le", ",", "un\u00b7er\u00b7h\u00f6r\u00b7te", "Fall", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "da\u00df aus dem \u00dcberma\u00df der Lebenskr\u00e4fte", "tokens": ["da\u00df", "aus", "dem", "\u00dc\u00b7berm\u00b7a\u00df", "der", "Le\u00b7bens\u00b7kr\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ein Strom in jenes Paar hin\u00fcberrann", "tokens": ["ein", "Strom", "in", "je\u00b7nes", "Paar", "hin\u00b7\u00fc\u00b7ber\u00b7rann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und es mit tr\u00fcgerischem Leben \u00e4ffte \u2013:", "tokens": ["und", "es", "mit", "tr\u00fc\u00b7ge\u00b7ri\u00b7schem", "Le\u00b7ben", "\u00e4ff\u00b7te", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Herab zur Erde springen Weib wie Mann ...", "tokens": ["Her\u00b7ab", "zur", "Er\u00b7de", "sprin\u00b7gen", "Weib", "wie", "Mann", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADJA", "NN", "KOKOM", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und st\u00fcrmisch, wie sich Glut und Flut umfassen,", "tokens": ["Und", "st\u00fcr\u00b7misch", ",", "wie", "sich", "Glut", "und", "Flut", "um\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "PRF", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "vergessen sie den langen, kalten Bann ...", "tokens": ["ver\u00b7ges\u00b7sen", "sie", "den", "lan\u00b7gen", ",", "kal\u00b7ten", "Bann", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Doch schon beginnt die Lippe zu erblassen,", "tokens": ["Doch", "schon", "be\u00b7ginnt", "die", "Lip\u00b7pe", "zu", "er\u00b7blas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "versagt das Blut den weitern tollen Lauf \u2013:", "tokens": ["ver\u00b7sagt", "das", "Blut", "den", "wei\u00b7tern", "tol\u00b7len", "Lauf", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie m\u00fcssen schaudernd von einander lassen ...", "tokens": ["Sie", "m\u00fcs\u00b7sen", "schau\u00b7dernd", "von", "ein\u00b7an\u00b7der", "las\u00b7sen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Nach ihren S\u00e4ulen streben sie hinauf \u2013", "tokens": ["Nach", "ih\u00b7ren", "S\u00e4u\u00b7len", "stre\u00b7ben", "sie", "hin\u00b7auf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "allein umsonst \u2013: Sie sinken, wo sie stehen:", "tokens": ["al\u00b7lein", "um\u00b7sonst", "\u2013", ":", "Sie", "sin\u00b7ken", ",", "wo", "sie", "ste\u00b7hen", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "$.", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wieder nimmt sie Steines Starrheit auf.", "tokens": ["Und", "wie\u00b7der", "nimmt", "sie", "Stei\u00b7nes", "Star\u00b7rheit", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Zw\u00f6lf Monde gingen hin, seit dies geschehen,", "tokens": ["Zw\u00f6lf", "Mon\u00b7de", "gin\u00b7gen", "hin", ",", "seit", "dies", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PTKVZ", "$,", "KOUS", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "als gleicher Frist das Gleiche sich begab:", "tokens": ["als", "glei\u00b7cher", "Frist", "das", "Glei\u00b7che", "sich", "be\u00b7gab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man wachte auf, doch Venus \u2013 lag in Wehen!", "tokens": ["Man", "wach\u00b7te", "auf", ",", "doch", "Ve\u00b7nus", "\u2013", "lag", "in", "We\u00b7hen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "$,", "KON", "NN", "$(", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Und alsobald erscheint ein muntrer Knab',", "tokens": ["Und", "al\u00b7so\u00b7bald", "er\u00b7scheint", "ein", "mun\u00b7trer", "Knab'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "zum Leben sichtlich denn zum Tod bereiter,", "tokens": ["zum", "Le\u00b7ben", "sicht\u00b7lich", "denn", "zum", "Tod", "be\u00b7rei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und bricht sich schon ein Birkenreislein ab ...", "tokens": ["und", "bricht", "sich", "schon", "ein", "Bir\u00b7ken\u00b7reis\u00b7lein", "ab", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und w\u00e4hrend Mars und Venus innig heiter", "tokens": ["Und", "w\u00e4h\u00b7rend", "Mars", "und", "Ve\u00b7nus", "in\u00b7nig", "hei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NN", "KON", "NN", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ihm zusehn, zielt er schon nach links und rechts", "tokens": ["ihm", "zu\u00b7sehn", ",", "zielt", "er", "schon", "nach", "links", "und", "rechts"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVINF", "$,", "VVFIN", "PPER", "ADV", "APPR", "ADV", "KON", "ADV"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "auf M\u00e4use, Hummeln, V\u00f6gel und so weiter.", "tokens": ["auf", "M\u00e4u\u00b7se", ",", "Hum\u00b7meln", ",", "V\u00f6\u00b7gel", "und", "so", "wei\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Und merkt es nicht im Eifer des Gefechts,", "tokens": ["Und", "merkt", "es", "nicht", "im", "Ei\u00b7fer", "des", "Ge\u00b7fechts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df seine Eltern still und stiller werden, \u2013", "tokens": ["da\u00df", "sei\u00b7ne", "El\u00b7tern", "still", "und", "stil\u00b7ler", "wer\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKVZ", "KON", "ADJD", "VAINF", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "bis pl\u00f6tzlich er der Letzte des Geschlechts.", "tokens": ["bis", "pl\u00f6tz\u00b7lich", "er", "der", "Letz\u00b7te", "des", "Ge\u00b7schlechts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Er springt hinzu mit kindlichen Geb\u00e4rden,", "tokens": ["Er", "springt", "hin\u00b7zu", "mit", "kind\u00b7li\u00b7chen", "Ge\u00b7b\u00e4r\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "er ruft und tastet, \u2013: Stein und nichts als Stein!", "tokens": ["er", "ruft", "und", "tas\u00b7tet", ",", "\u2013", ":", "Stein", "und", "nichts", "als", "Stein", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "$(", "$.", "NN", "KON", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und eben erst entr\u00fcckt dem Scho\u00df der Erden,", "tokens": ["Und", "e\u00b7ben", "erst", "ent\u00b7r\u00fcckt", "dem", "Scho\u00df", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "von niemandem belehrt als sich allein,", "tokens": ["von", "nie\u00b7man\u00b7dem", "be\u00b7lehrt", "als", "sich", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "KOUS", "PRF", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "verwirft er endlich all die eitlen Fragen", "tokens": ["ver\u00b7wirft", "er", "end\u00b7lich", "all", "die", "eit\u00b7len", "Fra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und richtet sich in seinem Reiche ein.", "tokens": ["und", "rich\u00b7tet", "sich", "in", "sei\u00b7nem", "Rei\u00b7che", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Ein freundlich Heer von ungetr\u00fcbten Tagen,", "tokens": ["Ein", "freund\u00b7lich", "Heer", "von", "un\u00b7ge\u00b7tr\u00fcb\u00b7ten", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "so schien es, war dem losen Schelm beschert ...", "tokens": ["so", "schien", "es", ",", "war", "dem", "lo\u00b7sen", "Schelm", "be\u00b7schert", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie manches Tierherz mu\u00dfte ihn verklagen:", "tokens": ["Wie", "man\u00b7ches", "Tier\u00b7herz", "mu\u00df\u00b7te", "ihn", "ver\u00b7kla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Denn ach wie manches ward von ihm versehrt!", "tokens": ["Denn", "ach", "wie", "man\u00b7ches", "ward", "von", "ihm", "ver\u00b7sehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "PIS", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn fr\u00fcher schon die Liebe hoch hier bl\u00fchte,", "tokens": ["Wenn", "fr\u00fc\u00b7her", "schon", "die", "Lie\u00b7be", "hoch", "hier", "bl\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ADV", "ART", "NN", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "so war ihr jetzt kein Herz mehr abgekehrt.", "tokens": ["so", "war", "ihr", "jetzt", "kein", "Herz", "mehr", "ab\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Bis eines Tags ein Paar bekr\u00e4nzter H\u00fcte,", "tokens": ["Bis", "ei\u00b7nes", "Tags", "ein", "Paar", "be\u00b7kr\u00e4nz\u00b7ter", "H\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "seit Jahr und Tag das erste Menschenpaar,", "tokens": ["seit", "Jahr", "und", "Tag", "das", "ers\u00b7te", "Men\u00b7schen\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sich kreuz und quer den alten Park durchm\u00fchte.", "tokens": ["sich", "kreuz", "und", "quer", "den", "al\u00b7ten", "Park", "durch\u00b7m\u00fch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Weh, Amor! nun ereilt dich die Gefahr! \u2013:", "tokens": ["Weh", ",", "A\u00b7mor", "!", "nun", "er\u00b7eilt", "dich", "die", "Ge\u00b7fahr", "!", "\u2013", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "NE", "$.", "ADV", "VVFIN", "PPER", "ART", "NN", "$.", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn, kaum da\u00df jene durchs Geb\u00fcsch gedrungen, \u2013", "tokens": ["Denn", ",", "kaum", "da\u00df", "je\u00b7ne", "durchs", "Ge\u00b7b\u00fcsch", "ge\u00b7drun\u00b7gen", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$,", "ADV", "KOUS", "PDS", "APPRART", "NN", "VVPP", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "der kleine Gott schon Stein geworden war.", "tokens": ["der", "klei\u00b7ne", "Gott", "schon", "Stein", "ge\u00b7wor\u00b7den", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "NN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "\u00bbo sieh doch! sieh!\u00ab so jubeln sich die jungen", "tokens": ["\u00bb", "o", "sieh", "doch", "!", "sieh", "!", "\u00ab", "so", "ju\u00b7beln", "sich", "die", "jun\u00b7gen"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "FM", "FM", "ADV", "$.", "VVIMP", "$.", "$(", "ADV", "VVFIN", "PRF", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Entdecker zu \u2013 \u00bbEin Fund! ein Schatz! ein Hort!\u00ab", "tokens": ["Ent\u00b7de\u00b7cker", "zu", "\u2013", "\u00bb", "Ein", "Fund", "!", "ein", "Schatz", "!", "ein", "Hort", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "PTKZU", "$(", "$(", "ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das M\u00e4dchen ist zu Amorn hingesprungen \u2013:", "tokens": ["Das", "M\u00e4d\u00b7chen", "ist", "zu", "A\u00b7morn", "hin\u00b7ge\u00b7sprun\u00b7gen", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NE", "VVPP", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Der spielt noch, steinern, seine Rolle fort", "tokens": ["Der", "spielt", "noch", ",", "stei\u00b7nern", ",", "sei\u00b7ne", "Rol\u00b7le", "fort"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "$,", "VVFIN", "$,", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und steht mit trotzig aufgespanntem Bogen \u2013", "tokens": ["und", "steht", "mit", "trot\u00b7zig", "auf\u00b7ge\u00b7spann\u00b7tem", "Bo\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und treibt den J\u00fcngling so zum rechten Wort ...", "tokens": ["und", "treibt", "den", "J\u00fcng\u00b7ling", "so", "zum", "rech\u00b7ten", "Wort", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Von j\u00e4her R\u00f6te Flammen \u00fcberflogen,", "tokens": ["Von", "j\u00e4\u00b7her", "R\u00f6\u00b7te", "Flam\u00b7men", "\u00fc\u00b7berf\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "bekennt sein Lieb sein Werben ihm zur\u00fcck \u2013", "tokens": ["be\u00b7kennt", "sein", "Lieb", "sein", "Wer\u00b7ben", "ihm", "zu\u00b7r\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VAINF", "VAFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und f\u00fchlt sich schon an seine Brust gezogen ...", "tokens": ["und", "f\u00fchlt", "sich", "schon", "an", "sei\u00b7ne", "Brust", "ge\u00b7zo\u00b7gen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Wer glaubte nicht der beiden reinem Gl\u00fcck?", "tokens": ["Wer", "glaub\u00b7te", "nicht", "der", "bei\u00b7den", "rei\u00b7nem", "Gl\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So la\u00dft uns nur die Frage noch beschwichten,", "tokens": ["So", "la\u00dft", "uns", "nur", "die", "Fra\u00b7ge", "noch", "be\u00b7schwich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie sich beschlie\u00dft das wunderliche St\u00fcck.", "tokens": ["wie", "sich", "be\u00b7schlie\u00dft", "das", "wun\u00b7der\u00b7li\u00b7che", "St\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Man wollte auf den Kleinen nicht verzichten", "tokens": ["Man", "woll\u00b7te", "auf", "den", "Klei\u00b7nen", "nicht", "ver\u00b7zich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "ART", "NN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und nahm ihn mit, er war ja \u00bbherrnlos Gut\u00ab!", "tokens": ["und", "nahm", "ihn", "mit", ",", "er", "war", "ja", "\u00bb", "herrn\u00b7los", "Gut", "\u00ab", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VAFIN", "ADV", "$(", "ADJD", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Eltern gl\u00fcckt' es wieder aufzurichten.", "tokens": ["Die", "El\u00b7tern", "gl\u00fcckt'", "es", "wie\u00b7der", "auf\u00b7zu\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Sie lie\u00df man wieder in der Wildnis Hut.", "tokens": ["Sie", "lie\u00df", "man", "wie\u00b7der", "in", "der", "Wild\u00b7nis", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie blicken immer noch voll Z\u00e4rtlichkeiten,", "tokens": ["Sie", "bli\u00b7cken", "im\u00b7mer", "noch", "voll", "Z\u00e4rt\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "doch ewig nun erloschen schweigt ihr Blut.", "tokens": ["doch", "e\u00b7wig", "nun", "er\u00b7lo\u00b7schen", "schweigt", "ihr", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVINF", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Indessen steht vor Amor man (dem Zweiten),", "tokens": ["In\u00b7des\u00b7sen", "steht", "vor", "A\u00b7mor", "man", "(", "dem", "Zwei\u00b7ten", ")", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "PIS", "$(", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "als allbekanntem \u00bbRaub\u00ab, bewundernd da ...", "tokens": ["als", "all\u00b7be\u00b7kann\u00b7tem", "\u00bb", "Raub", "\u00ab", ",", "be\u00b7wun\u00b7dernd", "da", "..."], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$(", "NN", "$(", "$,", "ADJD", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man glaubt, er stamme aus Canovas Zeiten ...", "tokens": ["Man", "glaubt", ",", "er", "stam\u00b7me", "aus", "Ca\u00b7no\u00b7vas", "Zei\u00b7ten", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Ich aber l\u00e4chelte, als ich ihn sah.", "tokens": ["Ich", "a\u00b7ber", "l\u00e4\u00b7chel\u00b7te", ",", "als", "ich", "ihn", "sah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Das Schlo\u00df liegt unbewohnt seit Jahr und Tag,", "tokens": ["Das", "Schlo\u00df", "liegt", "un\u00b7be\u00b7wohnt", "seit", "Jahr", "und", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der Park verwildert, pfadlos, unzug\u00e4nglich,", "tokens": ["der", "Park", "ver\u00b7wil\u00b7dert", ",", "pfad\u00b7los", ",", "un\u00b7zu\u00b7g\u00e4ng\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "dicht eingestr\u00fcppt von wirrem Wei\u00dfdornhag.", "tokens": ["dicht", "ein\u00b7ge\u00b7str\u00fcppt", "von", "wir\u00b7rem", "Wei\u00df\u00b7dorn\u00b7hag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Wo Grotten, Treppen, H\u00fcgel uranf\u00e4nglich:", "tokens": ["Wo", "Grot\u00b7ten", ",", "Trep\u00b7pen", ",", "H\u00fc\u00b7gel", "u\u00b7ran\u00b7f\u00e4ng\u00b7lich", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "$,", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verfall nun: St\u00e4mme, Schutt, gesunkner Grund ...", "tokens": ["Ver\u00b7fall", "nun", ":", "St\u00e4m\u00b7me", ",", "Schutt", ",", "ge\u00b7sun\u00b7kner", "Grund", "..."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "NN", "$,", "NN", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "des Friedens St\u00e4tte einst, nun w\u00fcst und b\u00e4nglich.", "tokens": ["des", "Frie\u00b7dens", "St\u00e4t\u00b7te", "einst", ",", "nun", "w\u00fcst", "und", "b\u00e4ng\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "$,", "ADV", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "In dieses Parkes Tiefe birgt ein Rund", "tokens": ["In", "die\u00b7ses", "Par\u00b7kes", "Tie\u00b7fe", "birgt", "ein", "Rund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "von Birken zweier G\u00f6tter Steingebilde,", "tokens": ["von", "Bir\u00b7ken", "zwei\u00b7er", "G\u00f6t\u00b7ter", "Stein\u00b7ge\u00b7bil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Alten hochber\u00fchmt durch ihren Bund \u2013:", "tokens": ["den", "Al\u00b7ten", "hoch\u00b7be\u00b7r\u00fchmt", "durch", "ih\u00b7ren", "Bund", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "PPOSAT", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Den Gott des Krieges, mit zerbrochnem Schilde,", "tokens": ["Den", "Gott", "des", "Krie\u00b7ges", ",", "mit", "zer\u00b7broch\u00b7nem", "Schil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und sie, der Liebe hohe K\u00f6nigin,", "tokens": ["und", "sie", ",", "der", "Lie\u00b7be", "ho\u00b7he", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "in wohl gewahrter Lieblichkeit und Milde.", "tokens": ["in", "wohl", "ge\u00b7wahr\u00b7ter", "Lieb\u00b7lich\u00b7keit", "und", "Mil\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Sie blicken z\u00e4rtlich gen einander hin,", "tokens": ["Sie", "bli\u00b7cken", "z\u00e4rt\u00b7lich", "gen", "ein\u00b7an\u00b7der", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und bunte Falter tragen ihre Gr\u00fc\u00dfe, \u2013", "tokens": ["und", "bun\u00b7te", "Fal\u00b7ter", "tra\u00b7gen", "ih\u00b7re", "Gr\u00fc\u00b7\u00dfe", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "doch kennt ihr auch des Spiels geheimen Sinn? ...", "tokens": ["doch", "kennt", "ihr", "auch", "des", "Spiels", "ge\u00b7hei\u00b7men", "Sinn", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "In einer Sommermondnacht Wunders\u00fc\u00dfe,", "tokens": ["In", "ei\u00b7ner", "Som\u00b7mer\u00b7mond\u00b7nacht", "Wun\u00b7der\u00b7s\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "in einer Nacht, da eine Nachtigall", "tokens": ["in", "ei\u00b7ner", "Nacht", ",", "da", "ei\u00b7ne", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "tot niederst\u00fcrzte vor der G\u00f6ttin F\u00fc\u00dfe,", "tokens": ["tot", "nie\u00b7ders\u00b7t\u00fcrz\u00b7te", "vor", "der", "G\u00f6t\u00b7tin", "F\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "so wild war ihrer Sehnsucht \u00dcberschwall,", "tokens": ["so", "wild", "war", "ih\u00b7rer", "Sehn\u00b7sucht", "\u00dc\u00b7bersc\u00b7hwall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "in einer solchen Nacht des Drangs der S\u00e4fte", "tokens": ["in", "ei\u00b7ner", "sol\u00b7chen", "Nacht", "des", "Drangs", "der", "S\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "geschah der dunkle, unerh\u00f6rte Fall,", "tokens": ["ge\u00b7schah", "der", "dunk\u00b7le", ",", "un\u00b7er\u00b7h\u00f6r\u00b7te", "Fall", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "da\u00df aus dem \u00dcberma\u00df der Lebenskr\u00e4fte", "tokens": ["da\u00df", "aus", "dem", "\u00dc\u00b7berm\u00b7a\u00df", "der", "Le\u00b7bens\u00b7kr\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ein Strom in jenes Paar hin\u00fcberrann", "tokens": ["ein", "Strom", "in", "je\u00b7nes", "Paar", "hin\u00b7\u00fc\u00b7ber\u00b7rann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und es mit tr\u00fcgerischem Leben \u00e4ffte \u2013:", "tokens": ["und", "es", "mit", "tr\u00fc\u00b7ge\u00b7ri\u00b7schem", "Le\u00b7ben", "\u00e4ff\u00b7te", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Herab zur Erde springen Weib wie Mann ...", "tokens": ["Her\u00b7ab", "zur", "Er\u00b7de", "sprin\u00b7gen", "Weib", "wie", "Mann", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADJA", "NN", "KOKOM", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und st\u00fcrmisch, wie sich Glut und Flut umfassen,", "tokens": ["Und", "st\u00fcr\u00b7misch", ",", "wie", "sich", "Glut", "und", "Flut", "um\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "PRF", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "vergessen sie den langen, kalten Bann ...", "tokens": ["ver\u00b7ges\u00b7sen", "sie", "den", "lan\u00b7gen", ",", "kal\u00b7ten", "Bann", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Doch schon beginnt die Lippe zu erblassen,", "tokens": ["Doch", "schon", "be\u00b7ginnt", "die", "Lip\u00b7pe", "zu", "er\u00b7blas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "versagt das Blut den weitern tollen Lauf \u2013:", "tokens": ["ver\u00b7sagt", "das", "Blut", "den", "wei\u00b7tern", "tol\u00b7len", "Lauf", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "ADJA", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie m\u00fcssen schaudernd von einander lassen ...", "tokens": ["Sie", "m\u00fcs\u00b7sen", "schau\u00b7dernd", "von", "ein\u00b7an\u00b7der", "las\u00b7sen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Nach ihren S\u00e4ulen streben sie hinauf \u2013", "tokens": ["Nach", "ih\u00b7ren", "S\u00e4u\u00b7len", "stre\u00b7ben", "sie", "hin\u00b7auf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "allein umsonst \u2013: Sie sinken, wo sie stehen:", "tokens": ["al\u00b7lein", "um\u00b7sonst", "\u2013", ":", "Sie", "sin\u00b7ken", ",", "wo", "sie", "ste\u00b7hen", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "$.", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wieder nimmt sie Steines Starrheit auf.", "tokens": ["Und", "wie\u00b7der", "nimmt", "sie", "Stei\u00b7nes", "Star\u00b7rheit", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Zw\u00f6lf Monde gingen hin, seit dies geschehen,", "tokens": ["Zw\u00f6lf", "Mon\u00b7de", "gin\u00b7gen", "hin", ",", "seit", "dies", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PTKVZ", "$,", "KOUS", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "als gleicher Frist das Gleiche sich begab:", "tokens": ["als", "glei\u00b7cher", "Frist", "das", "Glei\u00b7che", "sich", "be\u00b7gab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man wachte auf, doch Venus \u2013 lag in Wehen!", "tokens": ["Man", "wach\u00b7te", "auf", ",", "doch", "Ve\u00b7nus", "\u2013", "lag", "in", "We\u00b7hen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "$,", "KON", "NN", "$(", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "Und alsobald erscheint ein muntrer Knab',", "tokens": ["Und", "al\u00b7so\u00b7bald", "er\u00b7scheint", "ein", "mun\u00b7trer", "Knab'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "zum Leben sichtlich denn zum Tod bereiter,", "tokens": ["zum", "Le\u00b7ben", "sicht\u00b7lich", "denn", "zum", "Tod", "be\u00b7rei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und bricht sich schon ein Birkenreislein ab ...", "tokens": ["und", "bricht", "sich", "schon", "ein", "Bir\u00b7ken\u00b7reis\u00b7lein", "ab", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "Und w\u00e4hrend Mars und Venus innig heiter", "tokens": ["Und", "w\u00e4h\u00b7rend", "Mars", "und", "Ve\u00b7nus", "in\u00b7nig", "hei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NN", "KON", "NN", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ihm zusehn, zielt er schon nach links und rechts", "tokens": ["ihm", "zu\u00b7sehn", ",", "zielt", "er", "schon", "nach", "links", "und", "rechts"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVINF", "$,", "VVFIN", "PPER", "ADV", "APPR", "ADV", "KON", "ADV"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "auf M\u00e4use, Hummeln, V\u00f6gel und so weiter.", "tokens": ["auf", "M\u00e4u\u00b7se", ",", "Hum\u00b7meln", ",", "V\u00f6\u00b7gel", "und", "so", "wei\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.44": {"line.1": {"text": "Und merkt es nicht im Eifer des Gefechts,", "tokens": ["Und", "merkt", "es", "nicht", "im", "Ei\u00b7fer", "des", "Ge\u00b7fechts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df seine Eltern still und stiller werden, \u2013", "tokens": ["da\u00df", "sei\u00b7ne", "El\u00b7tern", "still", "und", "stil\u00b7ler", "wer\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKVZ", "KON", "ADJD", "VAINF", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "bis pl\u00f6tzlich er der Letzte des Geschlechts.", "tokens": ["bis", "pl\u00f6tz\u00b7lich", "er", "der", "Letz\u00b7te", "des", "Ge\u00b7schlechts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Er springt hinzu mit kindlichen Geb\u00e4rden,", "tokens": ["Er", "springt", "hin\u00b7zu", "mit", "kind\u00b7li\u00b7chen", "Ge\u00b7b\u00e4r\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "er ruft und tastet, \u2013: Stein und nichts als Stein!", "tokens": ["er", "ruft", "und", "tas\u00b7tet", ",", "\u2013", ":", "Stein", "und", "nichts", "als", "Stein", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "$(", "$.", "NN", "KON", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und eben erst entr\u00fcckt dem Scho\u00df der Erden,", "tokens": ["Und", "e\u00b7ben", "erst", "ent\u00b7r\u00fcckt", "dem", "Scho\u00df", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "von niemandem belehrt als sich allein,", "tokens": ["von", "nie\u00b7man\u00b7dem", "be\u00b7lehrt", "als", "sich", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "KOUS", "PRF", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "verwirft er endlich all die eitlen Fragen", "tokens": ["ver\u00b7wirft", "er", "end\u00b7lich", "all", "die", "eit\u00b7len", "Fra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und richtet sich in seinem Reiche ein.", "tokens": ["und", "rich\u00b7tet", "sich", "in", "sei\u00b7nem", "Rei\u00b7che", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.47": {"line.1": {"text": "Ein freundlich Heer von ungetr\u00fcbten Tagen,", "tokens": ["Ein", "freund\u00b7lich", "Heer", "von", "un\u00b7ge\u00b7tr\u00fcb\u00b7ten", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "so schien es, war dem losen Schelm beschert ...", "tokens": ["so", "schien", "es", ",", "war", "dem", "lo\u00b7sen", "Schelm", "be\u00b7schert", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie manches Tierherz mu\u00dfte ihn verklagen:", "tokens": ["Wie", "man\u00b7ches", "Tier\u00b7herz", "mu\u00df\u00b7te", "ihn", "ver\u00b7kla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "Denn ach wie manches ward von ihm versehrt!", "tokens": ["Denn", "ach", "wie", "man\u00b7ches", "ward", "von", "ihm", "ver\u00b7sehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "PIS", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn fr\u00fcher schon die Liebe hoch hier bl\u00fchte,", "tokens": ["Wenn", "fr\u00fc\u00b7her", "schon", "die", "Lie\u00b7be", "hoch", "hier", "bl\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ADV", "ART", "NN", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "so war ihr jetzt kein Herz mehr abgekehrt.", "tokens": ["so", "war", "ihr", "jetzt", "kein", "Herz", "mehr", "ab\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Bis eines Tags ein Paar bekr\u00e4nzter H\u00fcte,", "tokens": ["Bis", "ei\u00b7nes", "Tags", "ein", "Paar", "be\u00b7kr\u00e4nz\u00b7ter", "H\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "seit Jahr und Tag das erste Menschenpaar,", "tokens": ["seit", "Jahr", "und", "Tag", "das", "ers\u00b7te", "Men\u00b7schen\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sich kreuz und quer den alten Park durchm\u00fchte.", "tokens": ["sich", "kreuz", "und", "quer", "den", "al\u00b7ten", "Park", "durch\u00b7m\u00fch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "Weh, Amor! nun ereilt dich die Gefahr! \u2013:", "tokens": ["Weh", ",", "A\u00b7mor", "!", "nun", "er\u00b7eilt", "dich", "die", "Ge\u00b7fahr", "!", "\u2013", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "NE", "$.", "ADV", "VVFIN", "PPER", "ART", "NN", "$.", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn, kaum da\u00df jene durchs Geb\u00fcsch gedrungen, \u2013", "tokens": ["Denn", ",", "kaum", "da\u00df", "je\u00b7ne", "durchs", "Ge\u00b7b\u00fcsch", "ge\u00b7drun\u00b7gen", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$,", "ADV", "KOUS", "PDS", "APPRART", "NN", "VVPP", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "der kleine Gott schon Stein geworden war.", "tokens": ["der", "klei\u00b7ne", "Gott", "schon", "Stein", "ge\u00b7wor\u00b7den", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "NN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "\u00bbo sieh doch! sieh!\u00ab so jubeln sich die jungen", "tokens": ["\u00bb", "o", "sieh", "doch", "!", "sieh", "!", "\u00ab", "so", "ju\u00b7beln", "sich", "die", "jun\u00b7gen"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "FM", "FM", "ADV", "$.", "VVIMP", "$.", "$(", "ADV", "VVFIN", "PRF", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Entdecker zu \u2013 \u00bbEin Fund! ein Schatz! ein Hort!\u00ab", "tokens": ["Ent\u00b7de\u00b7cker", "zu", "\u2013", "\u00bb", "Ein", "Fund", "!", "ein", "Schatz", "!", "ein", "Hort", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "PTKZU", "$(", "$(", "ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das M\u00e4dchen ist zu Amorn hingesprungen \u2013:", "tokens": ["Das", "M\u00e4d\u00b7chen", "ist", "zu", "A\u00b7morn", "hin\u00b7ge\u00b7sprun\u00b7gen", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NE", "VVPP", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.52": {"line.1": {"text": "Der spielt noch, steinern, seine Rolle fort", "tokens": ["Der", "spielt", "noch", ",", "stei\u00b7nern", ",", "sei\u00b7ne", "Rol\u00b7le", "fort"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "$,", "VVFIN", "$,", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und steht mit trotzig aufgespanntem Bogen \u2013", "tokens": ["und", "steht", "mit", "trot\u00b7zig", "auf\u00b7ge\u00b7spann\u00b7tem", "Bo\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und treibt den J\u00fcngling so zum rechten Wort ...", "tokens": ["und", "treibt", "den", "J\u00fcng\u00b7ling", "so", "zum", "rech\u00b7ten", "Wort", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "Von j\u00e4her R\u00f6te Flammen \u00fcberflogen,", "tokens": ["Von", "j\u00e4\u00b7her", "R\u00f6\u00b7te", "Flam\u00b7men", "\u00fc\u00b7berf\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "bekennt sein Lieb sein Werben ihm zur\u00fcck \u2013", "tokens": ["be\u00b7kennt", "sein", "Lieb", "sein", "Wer\u00b7ben", "ihm", "zu\u00b7r\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VAINF", "VAFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und f\u00fchlt sich schon an seine Brust gezogen ...", "tokens": ["und", "f\u00fchlt", "sich", "schon", "an", "sei\u00b7ne", "Brust", "ge\u00b7zo\u00b7gen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.54": {"line.1": {"text": "Wer glaubte nicht der beiden reinem Gl\u00fcck?", "tokens": ["Wer", "glaub\u00b7te", "nicht", "der", "bei\u00b7den", "rei\u00b7nem", "Gl\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So la\u00dft uns nur die Frage noch beschwichten,", "tokens": ["So", "la\u00dft", "uns", "nur", "die", "Fra\u00b7ge", "noch", "be\u00b7schwich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie sich beschlie\u00dft das wunderliche St\u00fcck.", "tokens": ["wie", "sich", "be\u00b7schlie\u00dft", "das", "wun\u00b7der\u00b7li\u00b7che", "St\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Man wollte auf den Kleinen nicht verzichten", "tokens": ["Man", "woll\u00b7te", "auf", "den", "Klei\u00b7nen", "nicht", "ver\u00b7zich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "ART", "NN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und nahm ihn mit, er war ja \u00bbherrnlos Gut\u00ab!", "tokens": ["und", "nahm", "ihn", "mit", ",", "er", "war", "ja", "\u00bb", "herrn\u00b7los", "Gut", "\u00ab", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VAFIN", "ADV", "$(", "ADJD", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Eltern gl\u00fcckt' es wieder aufzurichten.", "tokens": ["Die", "El\u00b7tern", "gl\u00fcckt'", "es", "wie\u00b7der", "auf\u00b7zu\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.56": {"line.1": {"text": "Sie lie\u00df man wieder in der Wildnis Hut.", "tokens": ["Sie", "lie\u00df", "man", "wie\u00b7der", "in", "der", "Wild\u00b7nis", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie blicken immer noch voll Z\u00e4rtlichkeiten,", "tokens": ["Sie", "bli\u00b7cken", "im\u00b7mer", "noch", "voll", "Z\u00e4rt\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "doch ewig nun erloschen schweigt ihr Blut.", "tokens": ["doch", "e\u00b7wig", "nun", "er\u00b7lo\u00b7schen", "schweigt", "ihr", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVINF", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "Indessen steht vor Amor man (dem Zweiten),", "tokens": ["In\u00b7des\u00b7sen", "steht", "vor", "A\u00b7mor", "man", "(", "dem", "Zwei\u00b7ten", ")", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "PIS", "$(", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "als allbekanntem \u00bbRaub\u00ab, bewundernd da ...", "tokens": ["als", "all\u00b7be\u00b7kann\u00b7tem", "\u00bb", "Raub", "\u00ab", ",", "be\u00b7wun\u00b7dernd", "da", "..."], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$(", "NN", "$(", "$,", "ADJD", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man glaubt, er stamme aus Canovas Zeiten ...", "tokens": ["Man", "glaubt", ",", "er", "stam\u00b7me", "aus", "Ca\u00b7no\u00b7vas", "Zei\u00b7ten", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.58": {"line.1": {"text": "Ich aber l\u00e4chelte, als ich ihn sah.", "tokens": ["Ich", "a\u00b7ber", "l\u00e4\u00b7chel\u00b7te", ",", "als", "ich", "ihn", "sah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}