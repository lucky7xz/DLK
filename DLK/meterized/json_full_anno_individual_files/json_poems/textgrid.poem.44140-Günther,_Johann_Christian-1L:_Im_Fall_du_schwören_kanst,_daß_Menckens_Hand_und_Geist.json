{"textgrid.poem.44140": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Im Fall du schw\u00f6ren kanst, da\u00df Menckens Hand und Geist", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Fall du schw\u00f6ren kanst, da\u00df Menckens Hand und Geist", "tokens": ["Im", "Fall", "du", "schw\u00f6\u00b7ren", "kanst", ",", "da\u00df", "Men\u00b7ckens", "Hand", "und", "Geist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "PPER", "VVINF", "VMFIN", "$,", "KOUS", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dies Blat so w\u00fcrdig h\u00e4lt und eher nicht zerrei\u00dft,", "tokens": ["Dies", "Blat", "so", "w\u00fcr\u00b7dig", "h\u00e4lt", "und", "e\u00b7her", "nicht", "zer\u00b7rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "ADV", "ADJD", "VVFIN", "KON", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als bis sein kluger Blick, der oft mein Stern gewesen,", "tokens": ["Als", "bis", "sein", "klu\u00b7ger", "Blick", ",", "der", "oft", "mein", "Stern", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "ADV", "PPOSAT", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Inhalt und den Schmerz mit Langmuth durchgelesen,", "tokens": ["Den", "In\u00b7halt", "und", "den", "Schmerz", "mit", "Lang\u00b7muth", "durch\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So geh nur immer hin, bedr\u00e4ngte Musenschaar;", "tokens": ["So", "geh", "nur", "im\u00b7mer", "hin", ",", "be\u00b7dr\u00e4ng\u00b7te", "Mu\u00b7sen\u00b7schaar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch nimm, ich rathe dir, . . . . . . . . . . . wahr", "tokens": ["Doch", "nimm", ",", "ich", "ra\u00b7the", "dir", ",", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "wahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["KON", "VVIMP", "$,", "PPER", "VVFIN", "PPER", "$,", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADJD"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Und komm bey Ruh und Scherz den Augen auch gelegen,", "tokens": ["Und", "komm", "bey", "Ruh", "und", "Scherz", "den", "Au\u00b7gen", "auch", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die unter Sorg und Amt den Helicon bewegen.", "tokens": ["Die", "un\u00b7ter", "Sorg", "und", "Amt", "den", "He\u00b7li\u00b7con", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bewirb dich auch nicht erst um Schmuck und Feyerkleid,", "tokens": ["Be\u00b7wirb", "dich", "auch", "nicht", "erst", "um", "Schmuck", "und", "Fe\u00b7yer\u00b7kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Gem\u00fcthe, Zeit und Tracht begehren \u00c4hnligkeit.", "tokens": ["Ge\u00b7m\u00fc\u00b7the", ",", "Zeit", "und", "Tracht", "be\u00b7geh\u00b7ren", "\u00c4hn\u00b7lig\u00b7keit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein lustig Sontagskind mag . . . . und Aufsaz nehmen,", "tokens": ["Ein", "lus\u00b7tig", "Son\u00b7tags\u00b7kind", "mag", ".", ".", ".", ".", "und", "Auf\u00b7saz", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "$.", "$.", "$.", "$.", "KON", "NN", "VVINF", "$,"], "meter": "+--+-++-+-+-", "measure": "iambic.hexa.invert"}, "line.12": {"text": "Kein Aufzug armer . . . kan unsre Noth besch\u00e4men.", "tokens": ["Kein", "Auf\u00b7zug", "ar\u00b7mer", ".", ".", ".", "kan", "uns\u00b7re", "Noth", "be\u00b7sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "$.", "$.", "$.", "VMFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Drum geh nur sicher zu: Ber\u00fchmter M\u00e4cenat,", "tokens": ["Drum", "geh", "nur", "si\u00b7cher", "zu", ":", "Be\u00b7r\u00fchm\u00b7ter", "M\u00e4\u00b7ce\u00b7nat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ich suchte, wie du weist, vergangnen Sommer Rath", "tokens": ["Ich", "such\u00b7te", ",", "wie", "du", "weist", ",", "ver\u00b7gang\u00b7nen", "Som\u00b7mer", "Rath"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und zog mit Frieden heim auf Hofnung be\u00dfrer Zeiten", "tokens": ["Und", "zog", "mit", "Frie\u00b7den", "heim", "auf", "Hof\u00b7nung", "be\u00df\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKVZ", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und der so langen Qual ein Ende zu bereiten.", "tokens": ["Und", "der", "so", "lan\u00b7gen", "Qual", "ein", "En\u00b7de", "zu", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die gute Meynung kam, die gute Meynung fiel;", "tokens": ["Die", "gu\u00b7te", "Mey\u00b7nung", "kam", ",", "die", "gu\u00b7te", "Mey\u00b7nung", "fiel", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ich \u00e4nderte den Plaz, doch nicht das Trauerspiel,", "tokens": ["Ich", "\u00e4n\u00b7der\u00b7te", "den", "Plaz", ",", "doch", "nicht", "das", "Trau\u00b7er\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Indem mich Klag und Weh mit neuer Furcht umgaben.", "tokens": ["In\u00b7dem", "mich", "Klag", "und", "Weh", "mit", "neu\u00b7er", "Furcht", "um\u00b7ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Kurz, alles ist nun hin. Was die noch \u00fcbrig haben,", "tokens": ["Kurz", ",", "al\u00b7les", "ist", "nun", "hin", ".", "Was", "die", "noch", "\u00fcb\u00b7rig", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIS", "VAFIN", "ADV", "PTKVZ", "$.", "PWS", "ART", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die kaum mehr Eltern sind, ist ohne, was sie pre\u00dft,", "tokens": ["Die", "kaum", "mehr", "El\u00b7tern", "sind", ",", "ist", "oh\u00b7ne", ",", "was", "sie", "pre\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VAFIN", "$,", "VAFIN", "APPR", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ein Leben voller M\u00fch, zwo Kinder und ein Rest", "tokens": ["Ein", "Le\u00b7ben", "vol\u00b7ler", "M\u00fch", ",", "zwo", "Kin\u00b7der", "und", "ein", "Rest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "CARD", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Von Asch und D\u00fcrftigkeit, die das noch t\u00e4glich mindert,", "tokens": ["Von", "Asch", "und", "D\u00fcrf\u00b7tig\u00b7keit", ",", "die", "das", "noch", "t\u00e4g\u00b7lich", "min\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,", "PRELS", "ART", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Was Brodtkunst, Garthenbau und krancke Glieder hindert.", "tokens": ["Was", "Brodt\u00b7kunst", ",", "Gar\u00b7then\u00b7bau", "und", "kran\u00b7cke", "Glie\u00b7der", "hin\u00b7dert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Warum mich nun der Zorn des Vaterlandes trift,", "tokens": ["Wa\u00b7rum", "mich", "nun", "der", "Zorn", "des", "Va\u00b7ter\u00b7lan\u00b7des", "trift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "R\u00fchrt, wie ich glauben mu\u00df, von mancher Stachelschrift;", "tokens": ["R\u00fchrt", ",", "wie", "ich", "glau\u00b7ben", "mu\u00df", ",", "von", "man\u00b7cher", "Sta\u00b7chel\u00b7schrift", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Durch diese zeugt ich mir ein allgemeines Ha\u00dfen.", "tokens": ["Durch", "die\u00b7se", "zeugt", "ich", "mir", "ein", "all\u00b7ge\u00b7mei\u00b7nes", "Ha\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "PPER", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Der Kampf ist auch nicht jung, er fing sich in den Classen", "tokens": ["Der", "Kampf", "ist", "auch", "nicht", "jung", ",", "er", "fing", "sich", "in", "den", "Clas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der lezten Schulzeit an. Denn Schweidniz ist ein Ort,", "tokens": ["Der", "lez\u00b7ten", "Schul\u00b7zeit", "an", ".", "Denn", "Schweid\u00b7niz", "ist", "ein", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "KON", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Wo alles Striegeln flicht; entf\u00e4hrt ein schl\u00fcpfrig Wort,", "tokens": ["Wo", "al\u00b7les", "Strie\u00b7geln", "flicht", ";", "ent\u00b7f\u00e4hrt", "ein", "schl\u00fcpf\u00b7rig", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "$.", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So mu\u00df man gleich davor sogar auf Predigtst\u00fchlen", "tokens": ["So", "mu\u00df", "man", "gleich", "da\u00b7vor", "so\u00b7gar", "auf", "Pre\u00b7digt\u00b7st\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "PAV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Von Heuchlern b\u00f6ser Art . . . . . . . . . . . . . f\u00fchlen,", "tokens": ["Von", "Heuch\u00b7lern", "b\u00f6\u00b7ser", "Art", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.33": {"text": "Die Gott wohl nicht gebeuth und leicht kein Mensch verdaut.", "tokens": ["Die", "Gott", "wohl", "nicht", "ge\u00b7beuth", "und", "leicht", "kein", "Mensch", "ver\u00b7daut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "NN", "KON", "ADJD", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Ich gieng mit gleich vor gleich den Thoren auf die Haut.", "tokens": ["Ich", "gieng", "mit", "gleich", "vor", "gleich", "den", "Tho\u00b7ren", "auf", "die", "Haut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPR", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Verzeih derselben Zeit; die Jugendhize brannte,", "tokens": ["Ver\u00b7zeih", "der\u00b7sel\u00b7ben", "Zeit", ";", "die", "Ju\u00b7gend\u00b7hi\u00b7ze", "brann\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PDAT", "NN", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Indem sie dort noch nicht der . . . . . . . Moden kannte.", "tokens": ["In\u00b7dem", "sie", "dort", "noch", "nicht", "der", ".", ".", ".", ".", ".", ".", ".", "Mo\u00b7den", "kann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKNEG", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Vielleicht hat dazumahl mein Theodosius,", "tokens": ["Viel\u00b7leicht", "hat", "da\u00b7zu\u00b7mahl", "mein", "Theo\u00b7do\u00b7si\u00b7us", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.38": {"text": "An welchen Volck und Stadt und Schauplaz dencken mu\u00df,", "tokens": ["An", "wel\u00b7chen", "Volck", "und", "Stadt", "und", "Schau\u00b7plaz", "den\u00b7cken", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "KON", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Die L\u00e4strer hin und her mit Hasenschrot getrofen.", "tokens": ["Die", "L\u00e4st\u00b7rer", "hin", "und", "her", "mit", "Ha\u00b7sen\u00b7schrot", "ge\u00b7tro\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Doch damahls kunten sie noch wenig Rachlust hofen,", "tokens": ["Doch", "da\u00b7mahls", "kun\u00b7ten", "sie", "noch", "we\u00b7nig", "Rach\u00b7lust", "ho\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Indem mich weder Freund noch Schuz noch Geld verlies.", "tokens": ["In\u00b7dem", "mich", "we\u00b7der", "Freund", "noch", "Schuz", "noch", "Geld", "ver\u00b7lies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KON", "NN", "ADV", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So bald mir aber auch der Stab den R\u00fccken wies,", "tokens": ["So", "bald", "mir", "a\u00b7ber", "auch", "der", "Stab", "den", "R\u00fc\u00b7cken", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Der Brand mein Erbtheil fra\u00df, kein . . . . . helfen konte,", "tokens": ["Der", "Brand", "mein", "E\u00b7rbtheil", "fra\u00df", ",", "kein", ".", ".", ".", ".", ".", "hel\u00b7fen", "kon\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,", "PIAT", "$.", "$.", "$.", "$.", "$.", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "Erfuhr ich leider fr\u00fch, wie viel man G\u00fcnthern gonnte.", "tokens": ["Er\u00b7fuhr", "ich", "lei\u00b7der", "fr\u00fch", ",", "wie", "viel", "man", "G\u00fcn\u00b7thern", "gonn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "PWAV", "ADV", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Die Feinde wachten auf, die L\u00fcgner brachen los,", "tokens": ["Die", "Fein\u00b7de", "wach\u00b7ten", "auf", ",", "die", "L\u00fcg\u00b7ner", "bra\u00b7chen", "los", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Der Mangel band mich an, die Fehler schienen gro\u00df,", "tokens": ["Der", "Man\u00b7gel", "band", "mich", "an", ",", "die", "Feh\u00b7ler", "schie\u00b7nen", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Die G\u00f6nner sturben hin, da fing es an zu regnen.", "tokens": ["Die", "G\u00f6n\u00b7ner", "stur\u00b7ben", "hin", ",", "da", "fing", "es", "an", "zu", "reg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Ich sah die Noth vorher und wollt ihr auch begegnen.", "tokens": ["Ich", "sah", "die", "Noth", "vor\u00b7her", "und", "wollt", "ihr", "auch", "be\u00b7geg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "In Rendsburg war ein Freund, ein Freund von Wort und That,", "tokens": ["In", "Rends\u00b7burg", "war", "ein", "Freund", ",", "ein", "Freund", "von", "Wort", "und", "That", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "ART", "NN", "$,", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Bey dem ich nie umsonst und jezo kr\u00e4ftig bat.", "tokens": ["Bey", "dem", "ich", "nie", "um\u00b7sonst", "und", "je\u00b7zo", "kr\u00e4f\u00b7tig", "bat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "KON", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Er . . . . . . . . . . . . . . . . und hatte kaum geschrieben,", "tokens": ["Er", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "und", "hat\u00b7te", "kaum", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "KON", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.52": {"text": "So kam die Post hernach: Nun ist er auch geblieben.", "tokens": ["So", "kam", "die", "Post", "her\u00b7nach", ":", "Nun", "ist", "er", "auch", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ach Freund, ach treuer Freund, ach Peter\u00df, h\u00e4ttstu doch", "tokens": ["Ach", "Freund", ",", "ach", "treu\u00b7er", "Freund", ",", "ach", "Pe\u00b7ter\u00df", ",", "h\u00e4tts\u00b7tu", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "NN", "$,", "XY", "ADJA", "NN", "$,", "XY", "NE", "$,", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Nur mich nicht so geliebt, ich weis, du lebtest noch,", "tokens": ["Nur", "mich", "nicht", "so", "ge\u00b7liebt", ",", "ich", "weis", ",", "du", "leb\u00b7test", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKNEG", "ADV", "VVPP", "$,", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Denn was nur mir erst hilft (o . . . . . . . . . . Stunde", "tokens": ["Denn", "was", "nur", "mir", "erst", "hilft", "(", "o", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["KON", "PWS", "ADV", "PPER", "ADV", "VVFIN", "$(", "FM", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": ". . . . . . . . . . . . . . . . . . . .) das geht gewis zu Grunde.", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ")", "das", "geht", "ge\u00b7wis", "zu", "Grun\u00b7de", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$(", "PDS", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.57": {"text": "Da lag mein lezter Stab, ich fiel aus Noth in Schuld,", "tokens": ["Da", "lag", "mein", "lez\u00b7ter", "Stab", ",", "ich", "fiel", "aus", "Noth", "in", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ungedult", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Un\u00b7ge\u00b7dult"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.59": {"text": ". . . . . . . . . . . . . . . verga\u00df mich selbst und alles", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "ver\u00b7ga\u00df", "mich", "selbst", "und", "al\u00b7les"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "PPER", "ADV", "KON", "PIS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.60": {"text": "Und wurde doch aus Zwang die Ursach meines Falles,", "tokens": ["Und", "wur\u00b7de", "doch", "aus", "Zwang", "die", "Ur\u00b7sach", "mei\u00b7nes", "Fal\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "NN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Bey dem der P\u00f6bel lacht. Da hies ich nun ein Thor;", "tokens": ["Bey", "dem", "der", "P\u00f6\u00b7bel", "lacht", ".", "Da", "hies", "ich", "nun", "ein", "Thor", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Die Pfafen trugen es dem Vater listig vor,", "tokens": ["Die", "Pfa\u00b7fen", "tru\u00b7gen", "es", "dem", "Va\u00b7ter", "lis\u00b7tig", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Verschw\u00e4rzten mich entfernt durch . . . . . . . . Gr\u00fcnde,", "tokens": ["Ver\u00b7schw\u00e4rz\u00b7ten", "mich", "ent\u00b7fernt", "durch", ".", ".", ".", ".", ".", ".", ".", ".", "Gr\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "Und fremder Neid galt mehr als Bitt und Flehn vom Kinde,", "tokens": ["Und", "frem\u00b7der", "Neid", "galt", "mehr", "als", "Bitt", "und", "Flehn", "vom", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "ADV", "KOUS", "NN", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Das gern zum Creuze kroch. Du weist, gelehrter Mann,", "tokens": ["Das", "gern", "zum", "Creu\u00b7ze", "kroch", ".", "Du", "weist", ",", "ge\u00b7lehr\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPRART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Und siehst vern\u00fcnftig ein, was Aberglauben kan;", "tokens": ["Und", "siehst", "ver\u00b7n\u00fcnf\u00b7tig", "ein", ",", "was", "A\u00b7berg\u00b7lau\u00b7ben", "kan", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$,", "PWS", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Er ist . . . . . der Geiz die schlimmste Pest der Erden", "tokens": ["Er", "ist", ".", ".", ".", ".", ".", "der", "Geiz", "die", "schlimms\u00b7te", "Pest", "der", "Er\u00b7den"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "$.", "$.", "$.", "$.", "ART", "NN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Und kan . . . . . . . durch nichts bes\u00e4nftigt werden.", "tokens": ["Und", "kan", ".", ".", ".", ".", ".", ".", ".", "durch", "nichts", "be\u00b7s\u00e4nf\u00b7tigt", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "APPR", "PIS", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "Man thu auch, was man will, er schilt aus Eigensinn,", "tokens": ["Man", "thu", "auch", ",", "was", "man", "will", ",", "er", "schilt", "aus", "Ei\u00b7gen\u00b7sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PRELS", "PIS", "VMFIN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Nennt Be\u00dfrung Heucheley, st\u00f6\u00dft Bu\u00df und Thr\u00e4nen hin;", "tokens": ["Nennt", "Be\u00df\u00b7rung", "Heu\u00b7che\u00b7ley", ",", "st\u00f6\u00dft", "Bu\u00df", "und", "Thr\u00e4\u00b7nen", "hin", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NN", "$,", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Was einmahl sein Verdacht nur schon vor b\u00f6\u00df erkl\u00e4ret,", "tokens": ["Was", "ein\u00b7mahl", "sein", "Ver\u00b7dacht", "nur", "schon", "vor", "b\u00f6\u00df", "er\u00b7kl\u00e4\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "ADV", "ADV", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Dem flucht er, bis der Tod den . . . . . . Zorn verzehret.", "tokens": ["Dem", "flucht", "er", ",", "bis", "der", "Tod", "den", ".", ".", ".", ".", ".", ".", "Zorn", "ver\u00b7zeh\u00b7ret", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.73": {"text": "Ich strauchle freylich scharf, denn auf dergleichen Streich", "tokens": ["Ich", "strauch\u00b7le", "frey\u00b7lich", "scharf", ",", "denn", "auf", "derg\u00b7lei\u00b7chen", "Streich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KON", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Ger\u00e4th kein sichrer Schritt. Der erste Wurf in Teich", "tokens": ["Ge\u00b7r\u00e4\u00b7th", "kein", "sich\u00b7rer", "Schritt", ".", "Der", "ers\u00b7te", "Wurf", "in", "Teich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.75": {"text": "Ist aller Kreise Schuld, die aus dem ersten flie\u00dfen", "tokens": ["Ist", "al\u00b7ler", "Krei\u00b7se", "Schuld", ",", "die", "aus", "dem", "ers\u00b7ten", "flie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "NN", "$,", "PRELS", "APPR", "ART", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und nach und nach mehr Raum im Fortgehn in sich schlie\u00dfen.", "tokens": ["Und", "nach", "und", "nach", "mehr", "Raum", "im", "Fort\u00b7gehn", "in", "sich", "schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "KON", "APPR", "PIAT", "NN", "APPRART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Bedenck es nur ein Mensch; der . . . . . . . . w\u00e4chst,", "tokens": ["Be\u00b7denck", "es", "nur", "ein", "Mensch", ";", "der", ".", ".", ".", ".", ".", ".", ".", ".", "w\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "$.", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Seitdem . . . . . . . . . . . . . . . . . . . . . . . . . . . . lechst;", "tokens": ["Seit\u00b7dem", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "lechst", ";"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PAV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.79": {"text": "Ich schmeichle mir in nichts. Mein etwas freyes Leben", "tokens": ["Ich", "schmeich\u00b7le", "mir", "in", "nichts", ".", "Mein", "et\u00b7was", "frey\u00b7es", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PIS", "$.", "PPOSAT", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Hat auch wohl dann und wann dem Feuer \u00d6l gegeben.", "tokens": ["Hat", "auch", "wohl", "dann", "und", "wann", "dem", "Feu\u00b7er", "\u00d6l", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "KON", "PWAV", "ART", "NN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Allein, du lieber Gott, wie leichtlich ist's geschehn!", "tokens": ["Al\u00b7lein", ",", "du", "lie\u00b7ber", "Gott", ",", "wie", "leicht\u00b7lich", "ist's", "ge\u00b7schehn", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "ADV", "NN", "$,", "PWAV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Die Jugend weis sich ja nicht allzeit vorzusehn.", "tokens": ["Die", "Ju\u00b7gend", "weis", "sich", "ja", "nicht", "all\u00b7zeit", "vor\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PRF", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Verf\u00fchre Gott so scharf und wollt er ein Verbrechen", "tokens": ["Ver\u00b7f\u00fch\u00b7re", "Gott", "so", "scharf", "und", "wollt", "er", "ein", "Ver\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "ADV", "ADJD", "KON", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Der \u00dcbereilung stracks mit Bliz und Donner r\u00e4chen,", "tokens": ["Der", "\u00dc\u00b7be\u00b7rei\u00b7lung", "stracks", "mit", "Bliz", "und", "Don\u00b7ner", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Wie wenig w\u00fcrden alt. Vergebens H\u00fclfe schreyn", "tokens": ["Wie", "we\u00b7nig", "w\u00fcr\u00b7den", "alt", ".", "Ver\u00b7ge\u00b7bens", "H\u00fcl\u00b7fe", "schreyn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "VAFIN", "ADJD", "$.", "NN", "NN", "PPOSAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "F\u00fchrt gleichfalls, . . . . . . ., gar wenig Ordnung ein.", "tokens": ["F\u00fchrt", "gleich\u00b7falls", ",", ".", ".", ".", ".", ".", ".", ".", ",", "gar", "we\u00b7nig", "Ord\u00b7nung", "ein", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$,", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.87": {"text": "Wem nichts zur\u00fcckebleibt, der wird wohl wenig sparen,", "tokens": ["Wem", "nichts", "zu\u00b7r\u00fc\u00b7cke\u00b7bleibt", ",", "der", "wird", "wohl", "we\u00b7nig", "spa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "$,", "PRELS", "VAFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und wer f\u00fcnf Tag umsonst nach Hofnung ausgefahren,", "tokens": ["Und", "wer", "f\u00fcnf", "Tag", "um\u00b7sonst", "nach", "Hof\u00b7nung", "aus\u00b7ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "CARD", "NN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Der mu\u00df, wenn endlich auch der sechste Rath verschaft,", "tokens": ["Der", "mu\u00df", ",", "wenn", "end\u00b7lich", "auch", "der", "sechs\u00b7te", "Rath", "ver\u00b7schaft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "KOUS", "ADV", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Nothwendig mehr verthun als der, so Blut und Kraft", "tokens": ["Noth\u00b7wen\u00b7dig", "mehr", "ver\u00b7thun", "als", "der", ",", "so", "Blut", "und", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VVINF", "KOKOM", "ART", "$,", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Bey ordentlicher Kost in gleicher Waage n\u00e4hret.", "tokens": ["Bey", "or\u00b7dent\u00b7li\u00b7cher", "Kost", "in", "glei\u00b7cher", "Waa\u00b7ge", "n\u00e4h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.92": {"text": "Ja, wenn noch \u00fcberdies der L\u00e4strer Maul beschweret", "tokens": ["Ja", ",", "wenn", "noch", "\u00fc\u00b7ber\u00b7dies", "der", "L\u00e4st\u00b7rer", "Maul", "be\u00b7schwe\u00b7ret"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "ADV", "ADV", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Und mehr zur Sache f\u00fcgt und niemand uns verh\u00f6rt,", "tokens": ["Und", "mehr", "zur", "Sa\u00b7che", "f\u00fcgt", "und", "nie\u00b7mand", "uns", "ver\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "KON", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "So wird dadurch gewis die Ungedult vermehrt,", "tokens": ["So", "wird", "da\u00b7durch", "ge\u00b7wis", "die", "Un\u00b7ge\u00b7dult", "ver\u00b7mehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PAV", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Und manchen, welchem man ein Laster angelogen,", "tokens": ["Und", "man\u00b7chen", ",", "wel\u00b7chem", "man", "ein", "Las\u00b7ter", "an\u00b7ge\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Hat Vorwurf . . . . . . . . hernach zur That gezogen.", "tokens": ["Hat", "Vor\u00b7wurf", ".", ".", ".", ".", ".", ".", ".", ".", "her\u00b7nach", "zur", "That", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.97": {"text": "Ja, w\u00e4r auch alles wahr, womit man mich verschw\u00e4rzt,", "tokens": ["Ja", ",", "w\u00e4r", "auch", "al\u00b7les", "wahr", ",", "wo\u00b7mit", "man", "mich", "ver\u00b7schw\u00e4rzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VAFIN", "ADV", "PIS", "ADJD", "$,", "PWAV", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "So d\u00e4cht ich, wen darauf ein solches Ungl\u00fcck schmerzt,", "tokens": ["So", "d\u00e4cht", "ich", ",", "wen", "da\u00b7rauf", "ein", "sol\u00b7ches", "Un\u00b7gl\u00fcck", "schmerzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWS", "PAV", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Der sey gestraft genug; ich will es keinem g\u00f6nnen,", "tokens": ["Der", "sey", "ge\u00b7straft", "ge\u00b7nug", ";", "ich", "will", "es", "kei\u00b7nem", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "ADV", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Sogar auch denen nicht, die wider mich entbrennen.", "tokens": ["So\u00b7gar", "auch", "de\u00b7nen", "nicht", ",", "die", "wi\u00b7der", "mich", "ent\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDS", "PTKNEG", "$,", "PRELS", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Wer gar zu Boden liegt und keinen Arm mehr regt,", "tokens": ["Wer", "gar", "zu", "Bo\u00b7den", "liegt", "und", "kei\u00b7nen", "Arm", "mehr", "regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "VVFIN", "KON", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Dem wincket man umsonst. Was n\u00fczt es, da\u00df man schl\u00e4gt?", "tokens": ["Dem", "win\u00b7cket", "man", "um\u00b7sonst", ".", "Was", "n\u00fczt", "es", ",", "da\u00df", "man", "schl\u00e4gt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "$.", "PWS", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Man spring ihm lieber bey und heb ihn auf die Sohlen,", "tokens": ["Man", "spring", "ihm", "lie\u00b7ber", "bey", "und", "heb", "ihn", "auf", "die", "Soh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "APPR", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "So lauft er gl\u00fccklich fort, das S\u00e4umn\u00fc\u00df einzuholen.", "tokens": ["So", "lauft", "er", "gl\u00fcck\u00b7lich", "fort", ",", "das", "S\u00e4um\u00b7n\u00fc\u00df", "ein\u00b7zu\u00b7ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Man schreyt mir h\u00e4ufig zu: Verlas die Poesie!", "tokens": ["Man", "schreyt", "mir", "h\u00e4u\u00b7fig", "zu", ":", "Ver\u00b7las", "die", "Poe\u00b7sie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.106": {"text": "Was kan denn ich davor? So oft ich ihr entflieh,", "tokens": ["Was", "kan", "denn", "ich", "da\u00b7vor", "?", "So", "oft", "ich", "ihr", "ent\u00b7flieh", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "KON", "PPER", "PAV", "$.", "ADV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "So oft erhascht sie mich mit allzeit gr\u00f6\u00dfrer Liebe.", "tokens": ["So", "oft", "er\u00b7hascht", "sie", "mich", "mit", "all\u00b7zeit", "gr\u00f6\u00df\u00b7rer", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Die Reime fe\u00dfeln mich, es sind nicht falsche Triebe,", "tokens": ["Die", "Rei\u00b7me", "fe\u00b7\u00df\u00b7eln", "mich", ",", "es", "sind", "nicht", "fal\u00b7sche", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.109": {"text": "Es ist Natur und Hang, ist wie ein sch\u00f6nes Kind", "tokens": ["Es", "ist", "Na\u00b7tur", "und", "Hang", ",", "ist", "wie", "ein", "sch\u00f6\u00b7nes", "Kind"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "$,", "VAFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Des Buhlers leichten Zorn durch einen Blick gewinnt,", "tokens": ["Des", "Buh\u00b7lers", "leich\u00b7ten", "Zorn", "durch", "ei\u00b7nen", "Blick", "ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "So nimmt Calliope die schnelle Flucht gefangen,", "tokens": ["So", "nimmt", "Cal\u00b7li\u00b7o\u00b7pe", "die", "schnel\u00b7le", "Flucht", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und w\u00e4r ich noch so weit aus ihrer Schoos entgangen.", "tokens": ["Und", "w\u00e4r", "ich", "noch", "so", "weit", "aus", "ih\u00b7rer", "Schoos", "ent\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Ich weis auch eben nicht, ob sie viel Schaden thu;", "tokens": ["Ich", "weis", "auch", "e\u00b7ben", "nicht", ",", "ob", "sie", "viel", "Scha\u00b7den", "thu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "ADV", "ADV", "PTKNEG", "$,", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Sie bleibt in Noth getreu, sie stellt den Geist in Ruh", "tokens": ["Sie", "bleibt", "in", "Noth", "ge\u00b7treu", ",", "sie", "stellt", "den", "Geist", "in", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Und l\u00e4st . . . . . . . . . . . . von allen Wi\u00dfenschaften", "tokens": ["Und", "l\u00e4st", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "von", "al\u00b7len", "Wi\u00b7\u00dfen\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.116": {"text": "Die Anmuth und den Kern im Herzen fester haften.", "tokens": ["Die", "An\u00b7muth", "und", "den", "Kern", "im", "Her\u00b7zen", "fes\u00b7ter", "haf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "APPRART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Man wirft ihr t\u00e4glich vor, sie hab ein h\u00f6hnisch Maul,", "tokens": ["Man", "wirft", "ihr", "t\u00e4g\u00b7lich", "vor", ",", "sie", "hab", "ein", "h\u00f6h\u00b7nisch", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PPER", "VAFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Wie junge Weiber sind; ihr Scherz ist selten faul,", "tokens": ["Wie", "jun\u00b7ge", "Wei\u00b7ber", "sind", ";", "ihr", "Scherz", "ist", "sel\u00b7ten", "faul", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VAFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Sie redet etwas hin und meint es nicht so b\u00f6se", "tokens": ["Sie", "re\u00b7det", "et\u00b7was", "hin", "und", "meint", "es", "nicht", "so", "b\u00f6\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "PTKVZ", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Und spottet wohl mit Recht, so oft ein neuer Zese", "tokens": ["Und", "spot\u00b7tet", "wohl", "mit", "Recht", ",", "so", "oft", "ein", "neu\u00b7er", "Ze\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Ihr deutsches Kleid verstellt und wenn es ihr gelingt,", "tokens": ["Ihr", "deut\u00b7sches", "Kleid", "ver\u00b7stellt", "und", "wenn", "es", "ihr", "ge\u00b7lingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "KON", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Da\u00df der und jener Thor mit Flei\u00df ins Neze springt.", "tokens": ["Da\u00df", "der", "und", "je\u00b7ner", "Thor", "mit", "Flei\u00df", "ins", "Ne\u00b7ze", "springt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "KON", "PDAT", "NN", "APPR", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Und steht es andern frey, ihr Ungemach zu schrauben,", "tokens": ["Und", "steht", "es", "an\u00b7dern", "frey", ",", "ihr", "Un\u00b7ge\u00b7mach", "zu", "schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "ADJD", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "So kan sie sich wohl selbst die Gegenwehr erlauben.", "tokens": ["So", "kan", "sie", "sich", "wohl", "selbst", "die", "Ge\u00b7gen\u00b7wehr", "er\u00b7lau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Was will ihr Tadler mehr . . . . . . . . . . . . . . . . . . . .", "tokens": ["Was", "will", "ihr", "Tad\u00b7ler", "mehr", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.126": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.127": {"text": "Viel Dichter klagen blos, Gedancken anzubringen,", "tokens": ["Viel", "Dich\u00b7ter", "kla\u00b7gen", "blos", ",", "Ge\u00b7dan\u00b7cken", "an\u00b7zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "$,", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Erbetteln ihren Schmerz, zu dem sie sich erst zwingen,", "tokens": ["Er\u00b7bet\u00b7teln", "ih\u00b7ren", "Schmerz", ",", "zu", "dem", "sie", "sich", "erst", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Von fremder Traurigkeit und weinen k\u00fcnstlich toll", "tokens": ["Von", "frem\u00b7der", "Trau\u00b7rig\u00b7keit", "und", "wei\u00b7nen", "k\u00fcnst\u00b7lich", "toll"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "VVINF", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Und glauben selber nicht, was uns bewegen soll.", "tokens": ["Und", "glau\u00b7ben", "sel\u00b7ber", "nicht", ",", "was", "uns", "be\u00b7we\u00b7gen", "soll", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Wen aber r\u00fchrt die Qual gemahlter armer S\u00fcnder,", "tokens": ["Wen", "a\u00b7ber", "r\u00fchrt", "die", "Qual", "ge\u00b7mahl\u00b7ter", "ar\u00b7mer", "S\u00fcn\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "ART", "NN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Es w\u00e4re denn ein Weib und noch nicht trockne Kinder.", "tokens": ["Es", "w\u00e4\u00b7re", "denn", "ein", "Weib", "und", "noch", "nicht", "trock\u00b7ne", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "KON", "ADV", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Die Noth erkl\u00e4rt sich schlecht und redet, wie sie denckt.", "tokens": ["Die", "Noth", "er\u00b7kl\u00e4rt", "sich", "schlecht", "und", "re\u00b7det", ",", "wie", "sie", "denckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "KON", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Lis, pr\u00fcfe, theures Haupt, was hier den . . . . . kr\u00e4nckt.", "tokens": ["Lis", ",", "pr\u00fc\u00b7fe", ",", "theu\u00b7res", "Haupt", ",", "was", "hier", "den", ".", ".", ".", ".", ".", "kr\u00e4nckt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "ADJA", "NN", "$,", "PRELS", "ADV", "ART", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.135": {"text": "Die Warheit wird sich hier in keine Larve stecken,", "tokens": ["Die", "War\u00b7heit", "wird", "sich", "hier", "in", "kei\u00b7ne", "Lar\u00b7ve", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Wohl aber \u00fcberall ein treues Herz entdecken.", "tokens": ["Wohl", "a\u00b7ber", "\u00fc\u00b7be\u00b7rall", "ein", "treu\u00b7es", "Herz", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Ich habe nie begehrt, was mehr als Nothdurft heist;", "tokens": ["Ich", "ha\u00b7be", "nie", "be\u00b7gehrt", ",", "was", "mehr", "als", "Noth\u00b7durft", "heist", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "PRELS", "PIS", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Ein Alter kluger Ruh, das vom Erworbnen speist,", "tokens": ["Ein", "Al\u00b7ter", "klu\u00b7ger", "Ruh", ",", "das", "vom", "Er\u00b7worb\u00b7nen", "speist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Ist jederzeit mein Wuntsch. Mein Satyr mu\u00df oft g\u00e4hnen,", "tokens": ["Ist", "je\u00b7der\u00b7zeit", "mein", "Wunt\u00b7sch", ".", "Mein", "Sa\u00b7tyr", "mu\u00df", "oft", "g\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.140": {"text": "Wenn M\u00e4nner z\u00e4rtlich thun und durch ein th\u00f6richt Sehnen", "tokens": ["Wenn", "M\u00e4n\u00b7ner", "z\u00e4rt\u00b7lich", "thun", "und", "durch", "ein", "th\u00f6\u00b7richt", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADJD", "VVINF", "KON", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Geschlecht und Bart entweihn. Wie jener Cardinal,", "tokens": ["Ge\u00b7schlecht", "und", "Bart", "ent\u00b7weihn", ".", "Wie", "je\u00b7ner", "Car\u00b7di\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$.", "PWAV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Der, als ihm Pflicht und Amt das Reisen anbefahl,", "tokens": ["Der", ",", "als", "ihm", "Pflicht", "und", "Amt", "das", "Rei\u00b7sen", "an\u00b7be\u00b7fahl", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Ein Wirthshaus sucht und fand. Man lies ihm reinlich decken,", "tokens": ["Ein", "Wirths\u00b7haus", "sucht", "und", "fand", ".", "Man", "lies", "ihm", "rein\u00b7lich", "de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$.", "PIS", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Die Sch\u00fc\u00dfeln kamen voll und gaben viel zu schmecken.", "tokens": ["Die", "Sch\u00fc\u00b7\u00dfeln", "ka\u00b7men", "voll", "und", "ga\u00b7ben", "viel", "zu", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Doch als kein K\u00e4\u00df erschien, der Tisch und Magen schlo\u00df,", "tokens": ["Doch", "als", "kein", "K\u00e4\u00df", "er\u00b7schien", ",", "der", "Tisch", "und", "Ma\u00b7gen", "schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIAT", "NN", "VVFIN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "So fehlte wohl nicht viel, da\u00df nicht sein Auge flo\u00df.", "tokens": ["So", "fehl\u00b7te", "wohl", "nicht", "viel", ",", "da\u00df", "nicht", "sein", "Au\u00b7ge", "flo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKNEG", "ADV", "$,", "KOUS", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Er seufzte nach der H\u00f6h und sprach mit Creuz und Seegen:", "tokens": ["Er", "seufz\u00b7te", "nach", "der", "H\u00f6h", "und", "sprach", "mit", "Creuz", "und", "See\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "O Gott, was leidet man nicht deiner Kirche wegen.", "tokens": ["O", "Gott", ",", "was", "lei\u00b7det", "man", "nicht", "dei\u00b7ner", "Kir\u00b7che", "we\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWS", "VVFIN", "PIS", "PTKNEG", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Mein G\u00f6nner, glaub es mir. Es thut empfindlich weh,", "tokens": ["Mein", "G\u00f6n\u00b7ner", ",", "glaub", "es", "mir", ".", "Es", "thut", "emp\u00b7find\u00b7lich", "weh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPER", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Da\u00df, da ich von Natur nach Lob und Wei\u00dfheit steh", "tokens": ["Da\u00df", ",", "da", "ich", "von", "Na\u00b7tur", "nach", "Lob", "und", "Wei\u00df\u00b7heit", "steh"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "APPR", "NN", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Und soviel Nacht und Schwei\u00df an freye K\u00fcnste wende,", "tokens": ["Und", "so\u00b7viel", "Nacht", "und", "Schwei\u00df", "an", "frey\u00b7e", "K\u00fcns\u00b7te", "wen\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Gleichwohl kein gl\u00fccklich Ziel und angenehmes Ende", "tokens": ["Gleich\u00b7wohl", "kein", "gl\u00fcck\u00b7lich", "Ziel", "und", "an\u00b7ge\u00b7neh\u00b7mes", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJD", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Den Vorsaz fruchtbahr macht. Ich schw\u00e4ch in solcher Zeit", "tokens": ["Den", "Vor\u00b7saz", "frucht\u00b7bahr", "macht", ".", "Ich", "schw\u00e4ch", "in", "sol\u00b7cher", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Gesundheit, Geist und Blut und alle F\u00e4higkeit,", "tokens": ["Ge\u00b7sund\u00b7heit", ",", "Geist", "und", "Blut", "und", "al\u00b7le", "F\u00e4\u00b7hig\u00b7keit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Mein anvertrautes Pfund mit Wucher auszubiethen.", "tokens": ["Mein", "an\u00b7ver\u00b7trau\u00b7tes", "Pfund", "mit", "Wu\u00b7cher", "aus\u00b7zu\u00b7bie\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Man hat wohl so zu thun, sich vor sich selbst zu h\u00fcten,", "tokens": ["Man", "hat", "wohl", "so", "zu", "thun", ",", "sich", "vor", "sich", "selbst", "zu", "h\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADV", "PTKZU", "VVINF", "$,", "PRF", "APPR", "PRF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Da\u00df weder Wahn noch Schein noch blinde Prahlerey", "tokens": ["Da\u00df", "we\u00b7der", "Wahn", "noch", "Schein", "noch", "blin\u00b7de", "Prah\u00b7le\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KON", "NN", "ADV", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Der Warheit hinderlich, der Einsicht sch\u00e4dlich sey.", "tokens": ["Der", "War\u00b7heit", "hin\u00b7der\u00b7lich", ",", "der", "Ein\u00b7sicht", "sch\u00e4d\u00b7lich", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Was soll nicht erst geschehn, wenn eu\u00dferliche Plagen", "tokens": ["Was", "soll", "nicht", "erst", "ge\u00b7schehn", ",", "wenn", "eu\u00b7\u00dfer\u00b7li\u00b7che", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PTKNEG", "ADV", "VVPP", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Die Kr\u00e4fte der Vernunft mit . . . . . und Ohnmacht schlagen.", "tokens": ["Die", "Kr\u00e4f\u00b7te", "der", "Ver\u00b7nunft", "mit", ".", ".", ".", ".", ".", "und", "Ohn\u00b7macht", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.161": {"text": "Zu diesem kam die Furcht, die, wo es l\u00e4nger kracht,", "tokens": ["Zu", "die\u00b7sem", "kam", "die", "Furcht", ",", "die", ",", "wo", "es", "l\u00e4n\u00b7ger", "kracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ART", "NN", "$,", "PRELS", "$,", "PWAV", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Den Muth, der \u00fcbrig ist, noch gar zu Schanden macht.", "tokens": ["Den", "Muth", ",", "der", "\u00fcb\u00b7rig", "ist", ",", "noch", "gar", "zu", "Schan\u00b7den", "macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Je mehr ein Schneeball rollt, dies wist ihr Schweizerh\u00fcgel,", "tokens": ["Je", "mehr", "ein", "Schnee\u00b7ball", "rollt", ",", "dies", "wist", "ihr", "Schwei\u00b7zer\u00b7h\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Je mehr bekommt er auch vom Laufen Gr\u00f6\u00df und Fl\u00fcgel.", "tokens": ["Je", "mehr", "be\u00b7kommt", "er", "auch", "vom", "Lau\u00b7fen", "Gr\u00f6\u00df", "und", "Fl\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Mein . . . . . . . . ist schon starck, und nach dem Augenschein", "tokens": ["Mein", ".", ".", ".", ".", ".", ".", ".", ".", "ist", "schon", "starck", ",", "und", "nach", "dem", "Au\u00b7gen\u00b7schein"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VAFIN", "ADV", "ADJD", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.166": {"text": "Kan wohl mein Untergang nicht gar zu weit mehr seyn.", "tokens": ["Kan", "wohl", "mein", "Un\u00b7ter\u00b7gang", "nicht", "gar", "zu", "weit", "mehr", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "ADV", "PTKA", "ADJD", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Jedennoch k\u00f6nt es noch ein . . . . . . . . . . . . hemmen.", "tokens": ["Je\u00b7den\u00b7noch", "k\u00f6nt", "es", "noch", "ein", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "hem\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.168": {"text": "Wenn Salz und Feuchtigkeit sich um die Nerven stremmen", "tokens": ["Wenn", "Salz", "und", "Feuch\u00b7tig\u00b7keit", "sich", "um", "die", "Ner\u00b7ven", "strem\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "PRF", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Und Blut und Luft verstockt, ist freylich viel Gefahr.", "tokens": ["Und", "Blut", "und", "Luft", "ver\u00b7stockt", ",", "ist", "frey\u00b7lich", "viel", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVPP", "$,", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Inde\u00dfen l\u00e4st der Arzt den krancken Leib nicht gar;", "tokens": ["In\u00b7de\u00b7\u00dfen", "l\u00e4st", "der", "Arzt", "den", "kran\u00b7cken", "Leib", "nicht", "gar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Er thut, so viel er weis, das Leben aufzuhalten,", "tokens": ["Er", "thut", ",", "so", "viel", "er", "weis", ",", "das", "Le\u00b7ben", "auf\u00b7zu\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADV", "PPER", "PTKVZ", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Und mu\u00df sein sch\u00f6nes Amt gleichwohl mit Trost verwalten.", "tokens": ["Und", "mu\u00df", "sein", "sch\u00f6\u00b7nes", "Amt", "gleich\u00b7wohl", "mit", "Trost", "ver\u00b7wal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Verzweiflen will ich nicht, mein Elend hat Vernunft,", "tokens": ["Ver\u00b7zwei\u00b7flen", "will", "ich", "nicht", ",", "mein", "E\u00b7lend", "hat", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "$,", "PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Und d\u00e4chten Gl\u00fcck und Heil an keine Wiederkunft,", "tokens": ["Und", "d\u00e4ch\u00b7ten", "Gl\u00fcck", "und", "Heil", "an", "kei\u00b7ne", "Wie\u00b7der\u00b7kunft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Ja, m\u00fcst ich Brodt und Licht mit Wa\u00dferziehn erschwingen,", "tokens": ["Ja", ",", "m\u00fcst", "ich", "Brodt", "und", "Licht", "mit", "Wa\u00b7\u00df\u00b7er\u00b7ziehn", "er\u00b7schwin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VMFIN", "PPER", "NN", "KON", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.176": {"text": "Verk\u00fcrzt ich doch den Schlaf, mich noch emporzubringen.", "tokens": ["Ver\u00b7k\u00fcrzt", "ich", "doch", "den", "Schlaf", ",", "mich", "noch", "em\u00b7por\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Es d\u00fcrfte mancher seyn, der, wenn er erstlich s\u00e4h,", "tokens": ["Es", "d\u00fcrf\u00b7te", "man\u00b7cher", "seyn", ",", "der", ",", "wenn", "er", "erst\u00b7lich", "s\u00e4h", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "VAINF", "$,", "PRELS", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Mit was vor Ehrligkeit der gute Vorsaz fleh,", "tokens": ["Mit", "was", "vor", "Ehr\u00b7lig\u00b7keit", "der", "gu\u00b7te", "Vor\u00b7saz", "fleh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Aus Gro\u00dfmuth und Verstand den Musen Vorschub th\u00e4te.", "tokens": ["Aus", "Gro\u00df\u00b7muth", "und", "Ver\u00b7stand", "den", "Mu\u00b7sen", "Vor\u00b7schub", "th\u00e4\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Allein er kennt mich nicht, indem mein arm Ger\u00e4the", "tokens": ["Al\u00b7lein", "er", "kennt", "mich", "nicht", ",", "in\u00b7dem", "mein", "arm", "Ge\u00b7r\u00e4\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Der ungezwungnen Tracht den frommen Sinn verstellt.", "tokens": ["Der", "un\u00b7ge\u00b7zwung\u00b7nen", "Tracht", "den", "from\u00b7men", "Sinn", "ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Dies macht mich liederlich. Die, so vor aller Welt", "tokens": ["Dies", "macht", "mich", "lie\u00b7der\u00b7lich", ".", "Die", ",", "so", "vor", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$.", "ART", "$,", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Von Huren, Sof und Fra\u00df an H\u00e4nd und F\u00fc\u00dfen zittern,", "tokens": ["Von", "Hu\u00b7ren", ",", "Sof", "und", "Fra\u00df", "an", "H\u00e4nd", "und", "F\u00fc\u00b7\u00dfen", "zit\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Die Weste von Damast mit stummen Schulden f\u00fcttern,", "tokens": ["Die", "Wes\u00b7te", "von", "Da\u00b7mast", "mit", "stum\u00b7men", "Schul\u00b7den", "f\u00fct\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Dem Nechsten Unrecht thun, mehr plaudern als verstehn", "tokens": ["Dem", "Nechs\u00b7ten", "Un\u00b7recht", "thun", ",", "mehr", "plau\u00b7dern", "als", "ver\u00b7stehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,", "ADV", "VVINF", "KOKOM", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Und allzeit nur dabey wie Drechslerdocken gehn,", "tokens": ["Und", "all\u00b7zeit", "nur", "da\u00b7bey", "wie", "Drechs\u00b7ler\u00b7do\u00b7cken", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PAV", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Die schielen, wenn man gr\u00fc\u00dft, ver\u00e4chtlich nach der Seite", "tokens": ["Die", "schie\u00b7len", ",", "wenn", "man", "gr\u00fc\u00dft", ",", "ver\u00b7\u00e4cht\u00b7lich", "nach", "der", "Sei\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "KOUS", "PIS", "VVFIN", "$,", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Und hei\u00dfen \u00fcberall galant- und kluge Leute.", "tokens": ["Und", "hei\u00b7\u00dfen", "\u00fc\u00b7be\u00b7rall", "ga\u00b7lant", "und", "klu\u00b7ge", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Verzeih mir, gro\u00dfer Mann. Gerechter Schmerz entf\u00e4hrt.", "tokens": ["Ver\u00b7zeih", "mir", ",", "gro\u00b7\u00dfer", "Mann", ".", "Ge\u00b7rech\u00b7ter", "Schmerz", "ent\u00b7f\u00e4hrt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "ADJA", "NN", "$.", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Ich k\u00fc\u00dfe dein Verdienst und w\u00e4r der Huld nicht werth.", "tokens": ["Ich", "k\u00fc\u00b7\u00dfe", "dein", "Ver\u00b7dienst", "und", "w\u00e4r", "der", "Huld", "nicht", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Als Fremdling sucht ich l\u00e4ngst in Menckens Huld zu kommen,", "tokens": ["Als", "Fremd\u00b7ling", "sucht", "ich", "l\u00e4ngst", "in", "Men\u00b7ckens", "Huld", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "ADV", "APPR", "NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "Als Fremdling hastu mich mit Sanftmuth angenommen.", "tokens": ["Als", "Fremd\u00b7ling", "has\u00b7tu", "mich", "mit", "Sanft\u00b7muth", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "Dein Nahme trieb mich an. Vor diesem w\u00fcntscht ich mir", "tokens": ["Dein", "Nah\u00b7me", "trieb", "mich", "an", ".", "Vor", "die\u00b7sem", "w\u00fcnt\u00b7scht", "ich", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "APPR", "PDAT", "VVFIN", "PPER", "PPER"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.194": {"text": "Nur dieses Gl\u00fcck allein, ber\u00fchmter Mann, von dir", "tokens": ["Nur", "die\u00b7ses", "Gl\u00fcck", "al\u00b7lein", ",", "be\u00b7r\u00fchm\u00b7ter", "Mann", ",", "von", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "PDAT", "NN", "ADV", "$,", "ADJA", "NN", "$,", "APPR", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Und deiner Wi\u00dfenschaft ein gutes Wort zu heben;", "tokens": ["Und", "dei\u00b7ner", "Wi\u00b7\u00dfen\u00b7schaft", "ein", "gu\u00b7tes", "Wort", "zu", "he\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Du aber hast auch gar den Musen Brodt gegeben.", "tokens": ["Du", "a\u00b7ber", "hast", "auch", "gar", "den", "Mu\u00b7sen", "Brodt", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Ist's m\u00f6glich, da\u00df auch ich der Welt noch n\u00fczen kan,", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "da\u00df", "auch", "ich", "der", "Welt", "noch", "n\u00fc\u00b7zen", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "KOUS", "ADV", "PPER", "ART", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "So gieb mir auch zulezt . . . . . . . . . Mittel an.", "tokens": ["So", "gieb", "mir", "auch", "zu\u00b7lezt", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Mit\u00b7tel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.199": {"text": "Ich will gern alles thun und von der Pique dienen,", "tokens": ["Ich", "will", "gern", "al\u00b7les", "thun", "und", "von", "der", "Pi\u00b7que", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "VVINF", "KON", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Kan endlich nur mein Flei\u00df bey andrer . . . . gr\u00fcnen.", "tokens": ["Kan", "end\u00b7lich", "nur", "mein", "Flei\u00df", "bey", "an\u00b7drer", ".", ".", ".", ".", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "$.", "$.", "$.", "$.", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.201": {"text": "Man l\u00e4st den B\u00e4umen Zeit, die Brand und F\u00e4ule schw\u00e4cht,", "tokens": ["Man", "l\u00e4st", "den", "B\u00e4u\u00b7men", "Zeit", ",", "die", "Brand", "und", "F\u00e4u\u00b7le", "schw\u00e4cht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Und was man B\u00e4umen g\u00f6nnt, begehr auch ich mit Recht.", "tokens": ["Und", "was", "man", "B\u00e4u\u00b7men", "g\u00f6nnt", ",", "be\u00b7gehr", "auch", "ich", "mit", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "NN", "VVFIN", "$,", "VVFIN", "ADV", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Man seh der . . . . . . nach, ich will viel Fehler be\u00dfern,", "tokens": ["Man", "seh", "der", ".", ".", ".", ".", ".", ".", "nach", ",", "ich", "will", "viel", "Feh\u00b7ler", "be\u00b7\u00dfern", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "PTKVZ", "$,", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.204": {"text": "Die . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": ["Die", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["ART", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-", "measure": "single.down"}, "line.205": {"text": "Auch sag ich dieses nicht, als macht ich G\u00f6nnern M\u00fch,", "tokens": ["Auch", "sag", "ich", "die\u00b7ses", "nicht", ",", "als", "macht", "ich", "G\u00f6n\u00b7nern", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "PTKNEG", "$,", "KOUS", "VVFIN", "PPER", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Damit mein . . . . . . durch Fremder Unruh bl\u00fch;", "tokens": ["Da\u00b7mit", "mein", ".", ".", ".", ".", ".", ".", "durch", "Frem\u00b7der", "Un\u00b7ruh", "bl\u00fch", ";"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "$.", "$.", "$.", "$.", "$.", "$.", "APPR", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.207": {"text": "Ich hab ein . . . . . Herz, es lernt sich stets bescheiden", "tokens": ["Ich", "hab", "ein", ".", ".", ".", ".", ".", "Herz", ",", "es", "lernt", "sich", "stets", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "NN", "$,", "PPER", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.208": {"text": "Und will, das glaube mir, viel lieber Mangel leiden", "tokens": ["Und", "will", ",", "das", "glau\u00b7be", "mir", ",", "viel", "lie\u00b7ber", "Man\u00b7gel", "lei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "$,", "PDS", "VVFIN", "PPER", "$,", "ADV", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Als G\u00f6nner . . . . . . . . . beschwerlich seyn", "tokens": ["Als", "G\u00f6n\u00b7ner", ".", ".", ".", ".", ".", ".", ".", ".", ".", "be\u00b7schwer\u00b7lich", "seyn"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word"], "pos": ["KOUS", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADJD", "VAINF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.210": {"text": "Ein Rath, ein gutes Wort . . . . . . . . . . . . . . . . . .", "tokens": ["Ein", "Rath", ",", "ein", "gu\u00b7tes", "Wort", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.211": {"text": "Was raubt dir der Verlust? Mich kan . . . . sch\u00fczen.", "tokens": ["Was", "raubt", "dir", "der", "Ver\u00b7lust", "?", "Mich", "kan", ".", ".", ".", ".", "sch\u00fc\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "$.", "PPER", "VMFIN", "$.", "$.", "$.", "$.", "VVINF", "$."], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.212": {"text": "Kein Zuwurf ist so schlecht, er wird mir jezo n\u00fczen,", "tokens": ["Kein", "Zu\u00b7wurf", "ist", "so", "schlecht", ",", "er", "wird", "mir", "je\u00b7zo", "n\u00fc\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Mir, welchem alles fehlt, sogar der Glieder Ruh.", "tokens": ["Mir", ",", "wel\u00b7chem", "al\u00b7les", "fehlt", ",", "so\u00b7gar", "der", "Glie\u00b7der", "Ruh", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PIS", "VVFIN", "$,", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Nun ist die Welt mein Haus, die . . . . . . . . . dazu", "tokens": ["Nun", "ist", "die", "Welt", "mein", "Haus", ",", "die", ".", ".", ".", ".", ".", ".", ".", ".", ".", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,", "PRELS", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "PAV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.215": {"text": "(als w . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . h\u00e4tte)", "tokens": ["(", "als", "w", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "h\u00e4t\u00b7te", ")"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["$(", "KOUS", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VAFIN", "$("], "meter": "-++-", "measure": "unknown.measure.di"}, "line.216": {"text": "Und wirft den krancken Fu\u00df in fremder Luft aufs Bette,", "tokens": ["Und", "wirft", "den", "kran\u00b7cken", "Fu\u00df", "in", "frem\u00b7der", "Luft", "aufs", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Wo anders Stroh und Holz den weichen Tittel f\u00fchrt.", "tokens": ["Wo", "an\u00b7ders", "Stroh", "und", "Holz", "den", "wei\u00b7chen", "Tit\u00b7tel", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Und was noch \u00fcberdies . . . . . . . . . . . . . . . . gebiehrt,", "tokens": ["Und", "was", "noch", "\u00fc\u00b7ber\u00b7dies", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "ge\u00b7biehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.219": {"text": "Ist, da\u00df ich um und um auch wider Gottes Ehre", "tokens": ["Ist", ",", "da\u00df", "ich", "um", "und", "um", "auch", "wi\u00b7der", "Got\u00b7tes", "Eh\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "PTKVZ", "KON", "APPR", "ADV", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Auf Theurung, Krieg, Accis und . . . . . fluchen h\u00f6re.", "tokens": ["Auf", "Theu\u00b7rung", ",", "Krieg", ",", "Ac\u00b7cis", "und", ".", ".", ".", ".", ".", "flu\u00b7chen", "h\u00f6\u00b7re", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NE", "KON", "$.", "$.", "$.", "$.", "$.", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.221": {"text": "Gott f\u00fchrt mich wunderlich, vielleicht auf deinen Ruhm.", "tokens": ["Gott", "f\u00fchrt", "mich", "wun\u00b7der\u00b7lich", ",", "viel\u00b7leicht", "auf", "dei\u00b7nen", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Ist Gro\u00dfmuth und Gedult der Weisen Eigenthum,", "tokens": ["Ist", "Gro\u00df\u00b7muth", "und", "Ge\u00b7dult", "der", "Wei\u00b7sen", "Ei\u00b7gen\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ART", "NN", "NN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.223": {"text": "So hof ich, dir einmahl auf unsers Pindus Schrancken,", "tokens": ["So", "hof", "ich", ",", "dir", "ein\u00b7mahl", "auf", "un\u00b7sers", "Pin\u00b7dus", "Schran\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "ADV", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Gelehrter M\u00e4cenat, mein Wohlergehn zu dancken.", "tokens": ["Ge\u00b7lehr\u00b7ter", "M\u00e4\u00b7ce\u00b7nat", ",", "mein", "Woh\u00b7ler\u00b7gehn", "zu", "dan\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Das Gl\u00fccke sey dein Freund und breite durch dein Haus", "tokens": ["Das", "Gl\u00fc\u00b7cke", "sey", "dein", "Freund", "und", "brei\u00b7te", "durch", "dein", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "KON", "ADJA", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Den Seegen des Geschlechts dir noch vor Augen aus", "tokens": ["Den", "See\u00b7gen", "des", "Ge\u00b7schlechts", "dir", "noch", "vor", "Au\u00b7gen", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "PPER", "ADV", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Und la\u00dfe deinen Sohn, den hofnungsvollen Erben,", "tokens": ["Und", "la\u00b7\u00dfe", "dei\u00b7nen", "Sohn", ",", "den", "hof\u00b7nungs\u00b7vol\u00b7len", "Er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "An Wachsthum und Verdienst dem Alter Trost erwerben.", "tokens": ["An", "Wach\u00b7sthum", "und", "Ver\u00b7dienst", "dem", "Al\u00b7ter", "Trost", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Im Fall du schw\u00f6ren kanst, da\u00df Menckens Hand und Geist", "tokens": ["Im", "Fall", "du", "schw\u00f6\u00b7ren", "kanst", ",", "da\u00df", "Men\u00b7ckens", "Hand", "und", "Geist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "PPER", "VVINF", "VMFIN", "$,", "KOUS", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dies Blat so w\u00fcrdig h\u00e4lt und eher nicht zerrei\u00dft,", "tokens": ["Dies", "Blat", "so", "w\u00fcr\u00b7dig", "h\u00e4lt", "und", "e\u00b7her", "nicht", "zer\u00b7rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "ADV", "ADJD", "VVFIN", "KON", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als bis sein kluger Blick, der oft mein Stern gewesen,", "tokens": ["Als", "bis", "sein", "klu\u00b7ger", "Blick", ",", "der", "oft", "mein", "Stern", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "ADV", "PPOSAT", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Inhalt und den Schmerz mit Langmuth durchgelesen,", "tokens": ["Den", "In\u00b7halt", "und", "den", "Schmerz", "mit", "Lang\u00b7muth", "durch\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So geh nur immer hin, bedr\u00e4ngte Musenschaar;", "tokens": ["So", "geh", "nur", "im\u00b7mer", "hin", ",", "be\u00b7dr\u00e4ng\u00b7te", "Mu\u00b7sen\u00b7schaar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch nimm, ich rathe dir, . . . . . . . . . . . wahr", "tokens": ["Doch", "nimm", ",", "ich", "ra\u00b7the", "dir", ",", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "wahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["KON", "VVIMP", "$,", "PPER", "VVFIN", "PPER", "$,", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADJD"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Und komm bey Ruh und Scherz den Augen auch gelegen,", "tokens": ["Und", "komm", "bey", "Ruh", "und", "Scherz", "den", "Au\u00b7gen", "auch", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die unter Sorg und Amt den Helicon bewegen.", "tokens": ["Die", "un\u00b7ter", "Sorg", "und", "Amt", "den", "He\u00b7li\u00b7con", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bewirb dich auch nicht erst um Schmuck und Feyerkleid,", "tokens": ["Be\u00b7wirb", "dich", "auch", "nicht", "erst", "um", "Schmuck", "und", "Fe\u00b7yer\u00b7kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Gem\u00fcthe, Zeit und Tracht begehren \u00c4hnligkeit.", "tokens": ["Ge\u00b7m\u00fc\u00b7the", ",", "Zeit", "und", "Tracht", "be\u00b7geh\u00b7ren", "\u00c4hn\u00b7lig\u00b7keit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein lustig Sontagskind mag . . . . und Aufsaz nehmen,", "tokens": ["Ein", "lus\u00b7tig", "Son\u00b7tags\u00b7kind", "mag", ".", ".", ".", ".", "und", "Auf\u00b7saz", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "$.", "$.", "$.", "$.", "KON", "NN", "VVINF", "$,"], "meter": "+--+-++-+-+-", "measure": "iambic.hexa.invert"}, "line.12": {"text": "Kein Aufzug armer . . . kan unsre Noth besch\u00e4men.", "tokens": ["Kein", "Auf\u00b7zug", "ar\u00b7mer", ".", ".", ".", "kan", "uns\u00b7re", "Noth", "be\u00b7sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "$.", "$.", "$.", "VMFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Drum geh nur sicher zu: Ber\u00fchmter M\u00e4cenat,", "tokens": ["Drum", "geh", "nur", "si\u00b7cher", "zu", ":", "Be\u00b7r\u00fchm\u00b7ter", "M\u00e4\u00b7ce\u00b7nat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ich suchte, wie du weist, vergangnen Sommer Rath", "tokens": ["Ich", "such\u00b7te", ",", "wie", "du", "weist", ",", "ver\u00b7gang\u00b7nen", "Som\u00b7mer", "Rath"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und zog mit Frieden heim auf Hofnung be\u00dfrer Zeiten", "tokens": ["Und", "zog", "mit", "Frie\u00b7den", "heim", "auf", "Hof\u00b7nung", "be\u00df\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKVZ", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und der so langen Qual ein Ende zu bereiten.", "tokens": ["Und", "der", "so", "lan\u00b7gen", "Qual", "ein", "En\u00b7de", "zu", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die gute Meynung kam, die gute Meynung fiel;", "tokens": ["Die", "gu\u00b7te", "Mey\u00b7nung", "kam", ",", "die", "gu\u00b7te", "Mey\u00b7nung", "fiel", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ich \u00e4nderte den Plaz, doch nicht das Trauerspiel,", "tokens": ["Ich", "\u00e4n\u00b7der\u00b7te", "den", "Plaz", ",", "doch", "nicht", "das", "Trau\u00b7er\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Indem mich Klag und Weh mit neuer Furcht umgaben.", "tokens": ["In\u00b7dem", "mich", "Klag", "und", "Weh", "mit", "neu\u00b7er", "Furcht", "um\u00b7ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Kurz, alles ist nun hin. Was die noch \u00fcbrig haben,", "tokens": ["Kurz", ",", "al\u00b7les", "ist", "nun", "hin", ".", "Was", "die", "noch", "\u00fcb\u00b7rig", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIS", "VAFIN", "ADV", "PTKVZ", "$.", "PWS", "ART", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die kaum mehr Eltern sind, ist ohne, was sie pre\u00dft,", "tokens": ["Die", "kaum", "mehr", "El\u00b7tern", "sind", ",", "ist", "oh\u00b7ne", ",", "was", "sie", "pre\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VAFIN", "$,", "VAFIN", "APPR", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ein Leben voller M\u00fch, zwo Kinder und ein Rest", "tokens": ["Ein", "Le\u00b7ben", "vol\u00b7ler", "M\u00fch", ",", "zwo", "Kin\u00b7der", "und", "ein", "Rest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "CARD", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Von Asch und D\u00fcrftigkeit, die das noch t\u00e4glich mindert,", "tokens": ["Von", "Asch", "und", "D\u00fcrf\u00b7tig\u00b7keit", ",", "die", "das", "noch", "t\u00e4g\u00b7lich", "min\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,", "PRELS", "ART", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Was Brodtkunst, Garthenbau und krancke Glieder hindert.", "tokens": ["Was", "Brodt\u00b7kunst", ",", "Gar\u00b7then\u00b7bau", "und", "kran\u00b7cke", "Glie\u00b7der", "hin\u00b7dert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Warum mich nun der Zorn des Vaterlandes trift,", "tokens": ["Wa\u00b7rum", "mich", "nun", "der", "Zorn", "des", "Va\u00b7ter\u00b7lan\u00b7des", "trift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "R\u00fchrt, wie ich glauben mu\u00df, von mancher Stachelschrift;", "tokens": ["R\u00fchrt", ",", "wie", "ich", "glau\u00b7ben", "mu\u00df", ",", "von", "man\u00b7cher", "Sta\u00b7chel\u00b7schrift", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Durch diese zeugt ich mir ein allgemeines Ha\u00dfen.", "tokens": ["Durch", "die\u00b7se", "zeugt", "ich", "mir", "ein", "all\u00b7ge\u00b7mei\u00b7nes", "Ha\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "PPER", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Der Kampf ist auch nicht jung, er fing sich in den Classen", "tokens": ["Der", "Kampf", "ist", "auch", "nicht", "jung", ",", "er", "fing", "sich", "in", "den", "Clas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der lezten Schulzeit an. Denn Schweidniz ist ein Ort,", "tokens": ["Der", "lez\u00b7ten", "Schul\u00b7zeit", "an", ".", "Denn", "Schweid\u00b7niz", "ist", "ein", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "KON", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Wo alles Striegeln flicht; entf\u00e4hrt ein schl\u00fcpfrig Wort,", "tokens": ["Wo", "al\u00b7les", "Strie\u00b7geln", "flicht", ";", "ent\u00b7f\u00e4hrt", "ein", "schl\u00fcpf\u00b7rig", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "$.", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So mu\u00df man gleich davor sogar auf Predigtst\u00fchlen", "tokens": ["So", "mu\u00df", "man", "gleich", "da\u00b7vor", "so\u00b7gar", "auf", "Pre\u00b7digt\u00b7st\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "PAV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Von Heuchlern b\u00f6ser Art . . . . . . . . . . . . . f\u00fchlen,", "tokens": ["Von", "Heuch\u00b7lern", "b\u00f6\u00b7ser", "Art", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.33": {"text": "Die Gott wohl nicht gebeuth und leicht kein Mensch verdaut.", "tokens": ["Die", "Gott", "wohl", "nicht", "ge\u00b7beuth", "und", "leicht", "kein", "Mensch", "ver\u00b7daut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "NN", "KON", "ADJD", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Ich gieng mit gleich vor gleich den Thoren auf die Haut.", "tokens": ["Ich", "gieng", "mit", "gleich", "vor", "gleich", "den", "Tho\u00b7ren", "auf", "die", "Haut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPR", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Verzeih derselben Zeit; die Jugendhize brannte,", "tokens": ["Ver\u00b7zeih", "der\u00b7sel\u00b7ben", "Zeit", ";", "die", "Ju\u00b7gend\u00b7hi\u00b7ze", "brann\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PDAT", "NN", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Indem sie dort noch nicht der . . . . . . . Moden kannte.", "tokens": ["In\u00b7dem", "sie", "dort", "noch", "nicht", "der", ".", ".", ".", ".", ".", ".", ".", "Mo\u00b7den", "kann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKNEG", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Vielleicht hat dazumahl mein Theodosius,", "tokens": ["Viel\u00b7leicht", "hat", "da\u00b7zu\u00b7mahl", "mein", "Theo\u00b7do\u00b7si\u00b7us", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.38": {"text": "An welchen Volck und Stadt und Schauplaz dencken mu\u00df,", "tokens": ["An", "wel\u00b7chen", "Volck", "und", "Stadt", "und", "Schau\u00b7plaz", "den\u00b7cken", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "KON", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Die L\u00e4strer hin und her mit Hasenschrot getrofen.", "tokens": ["Die", "L\u00e4st\u00b7rer", "hin", "und", "her", "mit", "Ha\u00b7sen\u00b7schrot", "ge\u00b7tro\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Doch damahls kunten sie noch wenig Rachlust hofen,", "tokens": ["Doch", "da\u00b7mahls", "kun\u00b7ten", "sie", "noch", "we\u00b7nig", "Rach\u00b7lust", "ho\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Indem mich weder Freund noch Schuz noch Geld verlies.", "tokens": ["In\u00b7dem", "mich", "we\u00b7der", "Freund", "noch", "Schuz", "noch", "Geld", "ver\u00b7lies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KON", "NN", "ADV", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So bald mir aber auch der Stab den R\u00fccken wies,", "tokens": ["So", "bald", "mir", "a\u00b7ber", "auch", "der", "Stab", "den", "R\u00fc\u00b7cken", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Der Brand mein Erbtheil fra\u00df, kein . . . . . helfen konte,", "tokens": ["Der", "Brand", "mein", "E\u00b7rbtheil", "fra\u00df", ",", "kein", ".", ".", ".", ".", ".", "hel\u00b7fen", "kon\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,", "PIAT", "$.", "$.", "$.", "$.", "$.", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "Erfuhr ich leider fr\u00fch, wie viel man G\u00fcnthern gonnte.", "tokens": ["Er\u00b7fuhr", "ich", "lei\u00b7der", "fr\u00fch", ",", "wie", "viel", "man", "G\u00fcn\u00b7thern", "gonn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "PWAV", "ADV", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Die Feinde wachten auf, die L\u00fcgner brachen los,", "tokens": ["Die", "Fein\u00b7de", "wach\u00b7ten", "auf", ",", "die", "L\u00fcg\u00b7ner", "bra\u00b7chen", "los", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Der Mangel band mich an, die Fehler schienen gro\u00df,", "tokens": ["Der", "Man\u00b7gel", "band", "mich", "an", ",", "die", "Feh\u00b7ler", "schie\u00b7nen", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Die G\u00f6nner sturben hin, da fing es an zu regnen.", "tokens": ["Die", "G\u00f6n\u00b7ner", "stur\u00b7ben", "hin", ",", "da", "fing", "es", "an", "zu", "reg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Ich sah die Noth vorher und wollt ihr auch begegnen.", "tokens": ["Ich", "sah", "die", "Noth", "vor\u00b7her", "und", "wollt", "ihr", "auch", "be\u00b7geg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "In Rendsburg war ein Freund, ein Freund von Wort und That,", "tokens": ["In", "Rends\u00b7burg", "war", "ein", "Freund", ",", "ein", "Freund", "von", "Wort", "und", "That", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "ART", "NN", "$,", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Bey dem ich nie umsonst und jezo kr\u00e4ftig bat.", "tokens": ["Bey", "dem", "ich", "nie", "um\u00b7sonst", "und", "je\u00b7zo", "kr\u00e4f\u00b7tig", "bat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "KON", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Er . . . . . . . . . . . . . . . . und hatte kaum geschrieben,", "tokens": ["Er", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "und", "hat\u00b7te", "kaum", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "KON", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.52": {"text": "So kam die Post hernach: Nun ist er auch geblieben.", "tokens": ["So", "kam", "die", "Post", "her\u00b7nach", ":", "Nun", "ist", "er", "auch", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ach Freund, ach treuer Freund, ach Peter\u00df, h\u00e4ttstu doch", "tokens": ["Ach", "Freund", ",", "ach", "treu\u00b7er", "Freund", ",", "ach", "Pe\u00b7ter\u00df", ",", "h\u00e4tts\u00b7tu", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "NN", "$,", "XY", "ADJA", "NN", "$,", "XY", "NE", "$,", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Nur mich nicht so geliebt, ich weis, du lebtest noch,", "tokens": ["Nur", "mich", "nicht", "so", "ge\u00b7liebt", ",", "ich", "weis", ",", "du", "leb\u00b7test", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKNEG", "ADV", "VVPP", "$,", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Denn was nur mir erst hilft (o . . . . . . . . . . Stunde", "tokens": ["Denn", "was", "nur", "mir", "erst", "hilft", "(", "o", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["KON", "PWS", "ADV", "PPER", "ADV", "VVFIN", "$(", "FM", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": ". . . . . . . . . . . . . . . . . . . .) das geht gewis zu Grunde.", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ")", "das", "geht", "ge\u00b7wis", "zu", "Grun\u00b7de", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$(", "PDS", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.57": {"text": "Da lag mein lezter Stab, ich fiel aus Noth in Schuld,", "tokens": ["Da", "lag", "mein", "lez\u00b7ter", "Stab", ",", "ich", "fiel", "aus", "Noth", "in", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ungedult", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Un\u00b7ge\u00b7dult"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.59": {"text": ". . . . . . . . . . . . . . . verga\u00df mich selbst und alles", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "ver\u00b7ga\u00df", "mich", "selbst", "und", "al\u00b7les"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "PPER", "ADV", "KON", "PIS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.60": {"text": "Und wurde doch aus Zwang die Ursach meines Falles,", "tokens": ["Und", "wur\u00b7de", "doch", "aus", "Zwang", "die", "Ur\u00b7sach", "mei\u00b7nes", "Fal\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "NN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Bey dem der P\u00f6bel lacht. Da hies ich nun ein Thor;", "tokens": ["Bey", "dem", "der", "P\u00f6\u00b7bel", "lacht", ".", "Da", "hies", "ich", "nun", "ein", "Thor", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Die Pfafen trugen es dem Vater listig vor,", "tokens": ["Die", "Pfa\u00b7fen", "tru\u00b7gen", "es", "dem", "Va\u00b7ter", "lis\u00b7tig", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Verschw\u00e4rzten mich entfernt durch . . . . . . . . Gr\u00fcnde,", "tokens": ["Ver\u00b7schw\u00e4rz\u00b7ten", "mich", "ent\u00b7fernt", "durch", ".", ".", ".", ".", ".", ".", ".", ".", "Gr\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "Und fremder Neid galt mehr als Bitt und Flehn vom Kinde,", "tokens": ["Und", "frem\u00b7der", "Neid", "galt", "mehr", "als", "Bitt", "und", "Flehn", "vom", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "ADV", "KOUS", "NN", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Das gern zum Creuze kroch. Du weist, gelehrter Mann,", "tokens": ["Das", "gern", "zum", "Creu\u00b7ze", "kroch", ".", "Du", "weist", ",", "ge\u00b7lehr\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPRART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Und siehst vern\u00fcnftig ein, was Aberglauben kan;", "tokens": ["Und", "siehst", "ver\u00b7n\u00fcnf\u00b7tig", "ein", ",", "was", "A\u00b7berg\u00b7lau\u00b7ben", "kan", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$,", "PWS", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Er ist . . . . . der Geiz die schlimmste Pest der Erden", "tokens": ["Er", "ist", ".", ".", ".", ".", ".", "der", "Geiz", "die", "schlimms\u00b7te", "Pest", "der", "Er\u00b7den"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "$.", "$.", "$.", "$.", "ART", "NN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Und kan . . . . . . . durch nichts bes\u00e4nftigt werden.", "tokens": ["Und", "kan", ".", ".", ".", ".", ".", ".", ".", "durch", "nichts", "be\u00b7s\u00e4nf\u00b7tigt", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "APPR", "PIS", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "Man thu auch, was man will, er schilt aus Eigensinn,", "tokens": ["Man", "thu", "auch", ",", "was", "man", "will", ",", "er", "schilt", "aus", "Ei\u00b7gen\u00b7sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PRELS", "PIS", "VMFIN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Nennt Be\u00dfrung Heucheley, st\u00f6\u00dft Bu\u00df und Thr\u00e4nen hin;", "tokens": ["Nennt", "Be\u00df\u00b7rung", "Heu\u00b7che\u00b7ley", ",", "st\u00f6\u00dft", "Bu\u00df", "und", "Thr\u00e4\u00b7nen", "hin", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NN", "$,", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Was einmahl sein Verdacht nur schon vor b\u00f6\u00df erkl\u00e4ret,", "tokens": ["Was", "ein\u00b7mahl", "sein", "Ver\u00b7dacht", "nur", "schon", "vor", "b\u00f6\u00df", "er\u00b7kl\u00e4\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "ADV", "ADV", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Dem flucht er, bis der Tod den . . . . . . Zorn verzehret.", "tokens": ["Dem", "flucht", "er", ",", "bis", "der", "Tod", "den", ".", ".", ".", ".", ".", ".", "Zorn", "ver\u00b7zeh\u00b7ret", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.73": {"text": "Ich strauchle freylich scharf, denn auf dergleichen Streich", "tokens": ["Ich", "strauch\u00b7le", "frey\u00b7lich", "scharf", ",", "denn", "auf", "derg\u00b7lei\u00b7chen", "Streich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KON", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Ger\u00e4th kein sichrer Schritt. Der erste Wurf in Teich", "tokens": ["Ge\u00b7r\u00e4\u00b7th", "kein", "sich\u00b7rer", "Schritt", ".", "Der", "ers\u00b7te", "Wurf", "in", "Teich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.75": {"text": "Ist aller Kreise Schuld, die aus dem ersten flie\u00dfen", "tokens": ["Ist", "al\u00b7ler", "Krei\u00b7se", "Schuld", ",", "die", "aus", "dem", "ers\u00b7ten", "flie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "NN", "$,", "PRELS", "APPR", "ART", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und nach und nach mehr Raum im Fortgehn in sich schlie\u00dfen.", "tokens": ["Und", "nach", "und", "nach", "mehr", "Raum", "im", "Fort\u00b7gehn", "in", "sich", "schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "KON", "APPR", "PIAT", "NN", "APPRART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Bedenck es nur ein Mensch; der . . . . . . . . w\u00e4chst,", "tokens": ["Be\u00b7denck", "es", "nur", "ein", "Mensch", ";", "der", ".", ".", ".", ".", ".", ".", ".", ".", "w\u00e4chst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "$.", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Seitdem . . . . . . . . . . . . . . . . . . . . . . . . . . . . lechst;", "tokens": ["Seit\u00b7dem", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "lechst", ";"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PAV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.79": {"text": "Ich schmeichle mir in nichts. Mein etwas freyes Leben", "tokens": ["Ich", "schmeich\u00b7le", "mir", "in", "nichts", ".", "Mein", "et\u00b7was", "frey\u00b7es", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PIS", "$.", "PPOSAT", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Hat auch wohl dann und wann dem Feuer \u00d6l gegeben.", "tokens": ["Hat", "auch", "wohl", "dann", "und", "wann", "dem", "Feu\u00b7er", "\u00d6l", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "KON", "PWAV", "ART", "NN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Allein, du lieber Gott, wie leichtlich ist's geschehn!", "tokens": ["Al\u00b7lein", ",", "du", "lie\u00b7ber", "Gott", ",", "wie", "leicht\u00b7lich", "ist's", "ge\u00b7schehn", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "ADV", "NN", "$,", "PWAV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Die Jugend weis sich ja nicht allzeit vorzusehn.", "tokens": ["Die", "Ju\u00b7gend", "weis", "sich", "ja", "nicht", "all\u00b7zeit", "vor\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PRF", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Verf\u00fchre Gott so scharf und wollt er ein Verbrechen", "tokens": ["Ver\u00b7f\u00fch\u00b7re", "Gott", "so", "scharf", "und", "wollt", "er", "ein", "Ver\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "ADV", "ADJD", "KON", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Der \u00dcbereilung stracks mit Bliz und Donner r\u00e4chen,", "tokens": ["Der", "\u00dc\u00b7be\u00b7rei\u00b7lung", "stracks", "mit", "Bliz", "und", "Don\u00b7ner", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Wie wenig w\u00fcrden alt. Vergebens H\u00fclfe schreyn", "tokens": ["Wie", "we\u00b7nig", "w\u00fcr\u00b7den", "alt", ".", "Ver\u00b7ge\u00b7bens", "H\u00fcl\u00b7fe", "schreyn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "VAFIN", "ADJD", "$.", "NN", "NN", "PPOSAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "F\u00fchrt gleichfalls, . . . . . . ., gar wenig Ordnung ein.", "tokens": ["F\u00fchrt", "gleich\u00b7falls", ",", ".", ".", ".", ".", ".", ".", ".", ",", "gar", "we\u00b7nig", "Ord\u00b7nung", "ein", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$,", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.87": {"text": "Wem nichts zur\u00fcckebleibt, der wird wohl wenig sparen,", "tokens": ["Wem", "nichts", "zu\u00b7r\u00fc\u00b7cke\u00b7bleibt", ",", "der", "wird", "wohl", "we\u00b7nig", "spa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "$,", "PRELS", "VAFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und wer f\u00fcnf Tag umsonst nach Hofnung ausgefahren,", "tokens": ["Und", "wer", "f\u00fcnf", "Tag", "um\u00b7sonst", "nach", "Hof\u00b7nung", "aus\u00b7ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "CARD", "NN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Der mu\u00df, wenn endlich auch der sechste Rath verschaft,", "tokens": ["Der", "mu\u00df", ",", "wenn", "end\u00b7lich", "auch", "der", "sechs\u00b7te", "Rath", "ver\u00b7schaft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "KOUS", "ADV", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Nothwendig mehr verthun als der, so Blut und Kraft", "tokens": ["Noth\u00b7wen\u00b7dig", "mehr", "ver\u00b7thun", "als", "der", ",", "so", "Blut", "und", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VVINF", "KOKOM", "ART", "$,", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Bey ordentlicher Kost in gleicher Waage n\u00e4hret.", "tokens": ["Bey", "or\u00b7dent\u00b7li\u00b7cher", "Kost", "in", "glei\u00b7cher", "Waa\u00b7ge", "n\u00e4h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.92": {"text": "Ja, wenn noch \u00fcberdies der L\u00e4strer Maul beschweret", "tokens": ["Ja", ",", "wenn", "noch", "\u00fc\u00b7ber\u00b7dies", "der", "L\u00e4st\u00b7rer", "Maul", "be\u00b7schwe\u00b7ret"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "ADV", "ADV", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Und mehr zur Sache f\u00fcgt und niemand uns verh\u00f6rt,", "tokens": ["Und", "mehr", "zur", "Sa\u00b7che", "f\u00fcgt", "und", "nie\u00b7mand", "uns", "ver\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "KON", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "So wird dadurch gewis die Ungedult vermehrt,", "tokens": ["So", "wird", "da\u00b7durch", "ge\u00b7wis", "die", "Un\u00b7ge\u00b7dult", "ver\u00b7mehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PAV", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Und manchen, welchem man ein Laster angelogen,", "tokens": ["Und", "man\u00b7chen", ",", "wel\u00b7chem", "man", "ein", "Las\u00b7ter", "an\u00b7ge\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Hat Vorwurf . . . . . . . . hernach zur That gezogen.", "tokens": ["Hat", "Vor\u00b7wurf", ".", ".", ".", ".", ".", ".", ".", ".", "her\u00b7nach", "zur", "That", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.97": {"text": "Ja, w\u00e4r auch alles wahr, womit man mich verschw\u00e4rzt,", "tokens": ["Ja", ",", "w\u00e4r", "auch", "al\u00b7les", "wahr", ",", "wo\u00b7mit", "man", "mich", "ver\u00b7schw\u00e4rzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VAFIN", "ADV", "PIS", "ADJD", "$,", "PWAV", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "So d\u00e4cht ich, wen darauf ein solches Ungl\u00fcck schmerzt,", "tokens": ["So", "d\u00e4cht", "ich", ",", "wen", "da\u00b7rauf", "ein", "sol\u00b7ches", "Un\u00b7gl\u00fcck", "schmerzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWS", "PAV", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Der sey gestraft genug; ich will es keinem g\u00f6nnen,", "tokens": ["Der", "sey", "ge\u00b7straft", "ge\u00b7nug", ";", "ich", "will", "es", "kei\u00b7nem", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "ADV", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Sogar auch denen nicht, die wider mich entbrennen.", "tokens": ["So\u00b7gar", "auch", "de\u00b7nen", "nicht", ",", "die", "wi\u00b7der", "mich", "ent\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDS", "PTKNEG", "$,", "PRELS", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Wer gar zu Boden liegt und keinen Arm mehr regt,", "tokens": ["Wer", "gar", "zu", "Bo\u00b7den", "liegt", "und", "kei\u00b7nen", "Arm", "mehr", "regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "VVFIN", "KON", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Dem wincket man umsonst. Was n\u00fczt es, da\u00df man schl\u00e4gt?", "tokens": ["Dem", "win\u00b7cket", "man", "um\u00b7sonst", ".", "Was", "n\u00fczt", "es", ",", "da\u00df", "man", "schl\u00e4gt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "$.", "PWS", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Man spring ihm lieber bey und heb ihn auf die Sohlen,", "tokens": ["Man", "spring", "ihm", "lie\u00b7ber", "bey", "und", "heb", "ihn", "auf", "die", "Soh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "APPR", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "So lauft er gl\u00fccklich fort, das S\u00e4umn\u00fc\u00df einzuholen.", "tokens": ["So", "lauft", "er", "gl\u00fcck\u00b7lich", "fort", ",", "das", "S\u00e4um\u00b7n\u00fc\u00df", "ein\u00b7zu\u00b7ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Man schreyt mir h\u00e4ufig zu: Verlas die Poesie!", "tokens": ["Man", "schreyt", "mir", "h\u00e4u\u00b7fig", "zu", ":", "Ver\u00b7las", "die", "Poe\u00b7sie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.106": {"text": "Was kan denn ich davor? So oft ich ihr entflieh,", "tokens": ["Was", "kan", "denn", "ich", "da\u00b7vor", "?", "So", "oft", "ich", "ihr", "ent\u00b7flieh", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "KON", "PPER", "PAV", "$.", "ADV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "So oft erhascht sie mich mit allzeit gr\u00f6\u00dfrer Liebe.", "tokens": ["So", "oft", "er\u00b7hascht", "sie", "mich", "mit", "all\u00b7zeit", "gr\u00f6\u00df\u00b7rer", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Die Reime fe\u00dfeln mich, es sind nicht falsche Triebe,", "tokens": ["Die", "Rei\u00b7me", "fe\u00b7\u00df\u00b7eln", "mich", ",", "es", "sind", "nicht", "fal\u00b7sche", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.109": {"text": "Es ist Natur und Hang, ist wie ein sch\u00f6nes Kind", "tokens": ["Es", "ist", "Na\u00b7tur", "und", "Hang", ",", "ist", "wie", "ein", "sch\u00f6\u00b7nes", "Kind"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "$,", "VAFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Des Buhlers leichten Zorn durch einen Blick gewinnt,", "tokens": ["Des", "Buh\u00b7lers", "leich\u00b7ten", "Zorn", "durch", "ei\u00b7nen", "Blick", "ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "So nimmt Calliope die schnelle Flucht gefangen,", "tokens": ["So", "nimmt", "Cal\u00b7li\u00b7o\u00b7pe", "die", "schnel\u00b7le", "Flucht", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Und w\u00e4r ich noch so weit aus ihrer Schoos entgangen.", "tokens": ["Und", "w\u00e4r", "ich", "noch", "so", "weit", "aus", "ih\u00b7rer", "Schoos", "ent\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Ich weis auch eben nicht, ob sie viel Schaden thu;", "tokens": ["Ich", "weis", "auch", "e\u00b7ben", "nicht", ",", "ob", "sie", "viel", "Scha\u00b7den", "thu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "ADV", "ADV", "PTKNEG", "$,", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Sie bleibt in Noth getreu, sie stellt den Geist in Ruh", "tokens": ["Sie", "bleibt", "in", "Noth", "ge\u00b7treu", ",", "sie", "stellt", "den", "Geist", "in", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Und l\u00e4st . . . . . . . . . . . . von allen Wi\u00dfenschaften", "tokens": ["Und", "l\u00e4st", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "von", "al\u00b7len", "Wi\u00b7\u00dfen\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.116": {"text": "Die Anmuth und den Kern im Herzen fester haften.", "tokens": ["Die", "An\u00b7muth", "und", "den", "Kern", "im", "Her\u00b7zen", "fes\u00b7ter", "haf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "APPRART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Man wirft ihr t\u00e4glich vor, sie hab ein h\u00f6hnisch Maul,", "tokens": ["Man", "wirft", "ihr", "t\u00e4g\u00b7lich", "vor", ",", "sie", "hab", "ein", "h\u00f6h\u00b7nisch", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PPER", "VAFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Wie junge Weiber sind; ihr Scherz ist selten faul,", "tokens": ["Wie", "jun\u00b7ge", "Wei\u00b7ber", "sind", ";", "ihr", "Scherz", "ist", "sel\u00b7ten", "faul", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VAFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Sie redet etwas hin und meint es nicht so b\u00f6se", "tokens": ["Sie", "re\u00b7det", "et\u00b7was", "hin", "und", "meint", "es", "nicht", "so", "b\u00f6\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "PTKVZ", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Und spottet wohl mit Recht, so oft ein neuer Zese", "tokens": ["Und", "spot\u00b7tet", "wohl", "mit", "Recht", ",", "so", "oft", "ein", "neu\u00b7er", "Ze\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Ihr deutsches Kleid verstellt und wenn es ihr gelingt,", "tokens": ["Ihr", "deut\u00b7sches", "Kleid", "ver\u00b7stellt", "und", "wenn", "es", "ihr", "ge\u00b7lingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "KON", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Da\u00df der und jener Thor mit Flei\u00df ins Neze springt.", "tokens": ["Da\u00df", "der", "und", "je\u00b7ner", "Thor", "mit", "Flei\u00df", "ins", "Ne\u00b7ze", "springt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "KON", "PDAT", "NN", "APPR", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Und steht es andern frey, ihr Ungemach zu schrauben,", "tokens": ["Und", "steht", "es", "an\u00b7dern", "frey", ",", "ihr", "Un\u00b7ge\u00b7mach", "zu", "schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "ADJD", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "So kan sie sich wohl selbst die Gegenwehr erlauben.", "tokens": ["So", "kan", "sie", "sich", "wohl", "selbst", "die", "Ge\u00b7gen\u00b7wehr", "er\u00b7lau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Was will ihr Tadler mehr . . . . . . . . . . . . . . . . . . . .", "tokens": ["Was", "will", "ihr", "Tad\u00b7ler", "mehr", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.126": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.127": {"text": "Viel Dichter klagen blos, Gedancken anzubringen,", "tokens": ["Viel", "Dich\u00b7ter", "kla\u00b7gen", "blos", ",", "Ge\u00b7dan\u00b7cken", "an\u00b7zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "$,", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Erbetteln ihren Schmerz, zu dem sie sich erst zwingen,", "tokens": ["Er\u00b7bet\u00b7teln", "ih\u00b7ren", "Schmerz", ",", "zu", "dem", "sie", "sich", "erst", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Von fremder Traurigkeit und weinen k\u00fcnstlich toll", "tokens": ["Von", "frem\u00b7der", "Trau\u00b7rig\u00b7keit", "und", "wei\u00b7nen", "k\u00fcnst\u00b7lich", "toll"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "VVINF", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Und glauben selber nicht, was uns bewegen soll.", "tokens": ["Und", "glau\u00b7ben", "sel\u00b7ber", "nicht", ",", "was", "uns", "be\u00b7we\u00b7gen", "soll", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Wen aber r\u00fchrt die Qual gemahlter armer S\u00fcnder,", "tokens": ["Wen", "a\u00b7ber", "r\u00fchrt", "die", "Qual", "ge\u00b7mahl\u00b7ter", "ar\u00b7mer", "S\u00fcn\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "ART", "NN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Es w\u00e4re denn ein Weib und noch nicht trockne Kinder.", "tokens": ["Es", "w\u00e4\u00b7re", "denn", "ein", "Weib", "und", "noch", "nicht", "trock\u00b7ne", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "KON", "ADV", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Die Noth erkl\u00e4rt sich schlecht und redet, wie sie denckt.", "tokens": ["Die", "Noth", "er\u00b7kl\u00e4rt", "sich", "schlecht", "und", "re\u00b7det", ",", "wie", "sie", "denckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "KON", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Lis, pr\u00fcfe, theures Haupt, was hier den . . . . . kr\u00e4nckt.", "tokens": ["Lis", ",", "pr\u00fc\u00b7fe", ",", "theu\u00b7res", "Haupt", ",", "was", "hier", "den", ".", ".", ".", ".", ".", "kr\u00e4nckt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "ADJA", "NN", "$,", "PRELS", "ADV", "ART", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.135": {"text": "Die Warheit wird sich hier in keine Larve stecken,", "tokens": ["Die", "War\u00b7heit", "wird", "sich", "hier", "in", "kei\u00b7ne", "Lar\u00b7ve", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Wohl aber \u00fcberall ein treues Herz entdecken.", "tokens": ["Wohl", "a\u00b7ber", "\u00fc\u00b7be\u00b7rall", "ein", "treu\u00b7es", "Herz", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Ich habe nie begehrt, was mehr als Nothdurft heist;", "tokens": ["Ich", "ha\u00b7be", "nie", "be\u00b7gehrt", ",", "was", "mehr", "als", "Noth\u00b7durft", "heist", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "PRELS", "PIS", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Ein Alter kluger Ruh, das vom Erworbnen speist,", "tokens": ["Ein", "Al\u00b7ter", "klu\u00b7ger", "Ruh", ",", "das", "vom", "Er\u00b7worb\u00b7nen", "speist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Ist jederzeit mein Wuntsch. Mein Satyr mu\u00df oft g\u00e4hnen,", "tokens": ["Ist", "je\u00b7der\u00b7zeit", "mein", "Wunt\u00b7sch", ".", "Mein", "Sa\u00b7tyr", "mu\u00df", "oft", "g\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.140": {"text": "Wenn M\u00e4nner z\u00e4rtlich thun und durch ein th\u00f6richt Sehnen", "tokens": ["Wenn", "M\u00e4n\u00b7ner", "z\u00e4rt\u00b7lich", "thun", "und", "durch", "ein", "th\u00f6\u00b7richt", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADJD", "VVINF", "KON", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Geschlecht und Bart entweihn. Wie jener Cardinal,", "tokens": ["Ge\u00b7schlecht", "und", "Bart", "ent\u00b7weihn", ".", "Wie", "je\u00b7ner", "Car\u00b7di\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$.", "PWAV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Der, als ihm Pflicht und Amt das Reisen anbefahl,", "tokens": ["Der", ",", "als", "ihm", "Pflicht", "und", "Amt", "das", "Rei\u00b7sen", "an\u00b7be\u00b7fahl", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Ein Wirthshaus sucht und fand. Man lies ihm reinlich decken,", "tokens": ["Ein", "Wirths\u00b7haus", "sucht", "und", "fand", ".", "Man", "lies", "ihm", "rein\u00b7lich", "de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$.", "PIS", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Die Sch\u00fc\u00dfeln kamen voll und gaben viel zu schmecken.", "tokens": ["Die", "Sch\u00fc\u00b7\u00dfeln", "ka\u00b7men", "voll", "und", "ga\u00b7ben", "viel", "zu", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Doch als kein K\u00e4\u00df erschien, der Tisch und Magen schlo\u00df,", "tokens": ["Doch", "als", "kein", "K\u00e4\u00df", "er\u00b7schien", ",", "der", "Tisch", "und", "Ma\u00b7gen", "schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIAT", "NN", "VVFIN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "So fehlte wohl nicht viel, da\u00df nicht sein Auge flo\u00df.", "tokens": ["So", "fehl\u00b7te", "wohl", "nicht", "viel", ",", "da\u00df", "nicht", "sein", "Au\u00b7ge", "flo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKNEG", "ADV", "$,", "KOUS", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Er seufzte nach der H\u00f6h und sprach mit Creuz und Seegen:", "tokens": ["Er", "seufz\u00b7te", "nach", "der", "H\u00f6h", "und", "sprach", "mit", "Creuz", "und", "See\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "O Gott, was leidet man nicht deiner Kirche wegen.", "tokens": ["O", "Gott", ",", "was", "lei\u00b7det", "man", "nicht", "dei\u00b7ner", "Kir\u00b7che", "we\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWS", "VVFIN", "PIS", "PTKNEG", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Mein G\u00f6nner, glaub es mir. Es thut empfindlich weh,", "tokens": ["Mein", "G\u00f6n\u00b7ner", ",", "glaub", "es", "mir", ".", "Es", "thut", "emp\u00b7find\u00b7lich", "weh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPER", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Da\u00df, da ich von Natur nach Lob und Wei\u00dfheit steh", "tokens": ["Da\u00df", ",", "da", "ich", "von", "Na\u00b7tur", "nach", "Lob", "und", "Wei\u00df\u00b7heit", "steh"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "APPR", "NN", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Und soviel Nacht und Schwei\u00df an freye K\u00fcnste wende,", "tokens": ["Und", "so\u00b7viel", "Nacht", "und", "Schwei\u00df", "an", "frey\u00b7e", "K\u00fcns\u00b7te", "wen\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Gleichwohl kein gl\u00fccklich Ziel und angenehmes Ende", "tokens": ["Gleich\u00b7wohl", "kein", "gl\u00fcck\u00b7lich", "Ziel", "und", "an\u00b7ge\u00b7neh\u00b7mes", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJD", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Den Vorsaz fruchtbahr macht. Ich schw\u00e4ch in solcher Zeit", "tokens": ["Den", "Vor\u00b7saz", "frucht\u00b7bahr", "macht", ".", "Ich", "schw\u00e4ch", "in", "sol\u00b7cher", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Gesundheit, Geist und Blut und alle F\u00e4higkeit,", "tokens": ["Ge\u00b7sund\u00b7heit", ",", "Geist", "und", "Blut", "und", "al\u00b7le", "F\u00e4\u00b7hig\u00b7keit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Mein anvertrautes Pfund mit Wucher auszubiethen.", "tokens": ["Mein", "an\u00b7ver\u00b7trau\u00b7tes", "Pfund", "mit", "Wu\u00b7cher", "aus\u00b7zu\u00b7bie\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Man hat wohl so zu thun, sich vor sich selbst zu h\u00fcten,", "tokens": ["Man", "hat", "wohl", "so", "zu", "thun", ",", "sich", "vor", "sich", "selbst", "zu", "h\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADV", "PTKZU", "VVINF", "$,", "PRF", "APPR", "PRF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Da\u00df weder Wahn noch Schein noch blinde Prahlerey", "tokens": ["Da\u00df", "we\u00b7der", "Wahn", "noch", "Schein", "noch", "blin\u00b7de", "Prah\u00b7le\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KON", "NN", "ADV", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Der Warheit hinderlich, der Einsicht sch\u00e4dlich sey.", "tokens": ["Der", "War\u00b7heit", "hin\u00b7der\u00b7lich", ",", "der", "Ein\u00b7sicht", "sch\u00e4d\u00b7lich", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Was soll nicht erst geschehn, wenn eu\u00dferliche Plagen", "tokens": ["Was", "soll", "nicht", "erst", "ge\u00b7schehn", ",", "wenn", "eu\u00b7\u00dfer\u00b7li\u00b7che", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PTKNEG", "ADV", "VVPP", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Die Kr\u00e4fte der Vernunft mit . . . . . und Ohnmacht schlagen.", "tokens": ["Die", "Kr\u00e4f\u00b7te", "der", "Ver\u00b7nunft", "mit", ".", ".", ".", ".", ".", "und", "Ohn\u00b7macht", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.161": {"text": "Zu diesem kam die Furcht, die, wo es l\u00e4nger kracht,", "tokens": ["Zu", "die\u00b7sem", "kam", "die", "Furcht", ",", "die", ",", "wo", "es", "l\u00e4n\u00b7ger", "kracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ART", "NN", "$,", "PRELS", "$,", "PWAV", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Den Muth, der \u00fcbrig ist, noch gar zu Schanden macht.", "tokens": ["Den", "Muth", ",", "der", "\u00fcb\u00b7rig", "ist", ",", "noch", "gar", "zu", "Schan\u00b7den", "macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Je mehr ein Schneeball rollt, dies wist ihr Schweizerh\u00fcgel,", "tokens": ["Je", "mehr", "ein", "Schnee\u00b7ball", "rollt", ",", "dies", "wist", "ihr", "Schwei\u00b7zer\u00b7h\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Je mehr bekommt er auch vom Laufen Gr\u00f6\u00df und Fl\u00fcgel.", "tokens": ["Je", "mehr", "be\u00b7kommt", "er", "auch", "vom", "Lau\u00b7fen", "Gr\u00f6\u00df", "und", "Fl\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Mein . . . . . . . . ist schon starck, und nach dem Augenschein", "tokens": ["Mein", ".", ".", ".", ".", ".", ".", ".", ".", "ist", "schon", "starck", ",", "und", "nach", "dem", "Au\u00b7gen\u00b7schein"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VAFIN", "ADV", "ADJD", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.166": {"text": "Kan wohl mein Untergang nicht gar zu weit mehr seyn.", "tokens": ["Kan", "wohl", "mein", "Un\u00b7ter\u00b7gang", "nicht", "gar", "zu", "weit", "mehr", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "ADV", "PTKA", "ADJD", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Jedennoch k\u00f6nt es noch ein . . . . . . . . . . . . hemmen.", "tokens": ["Je\u00b7den\u00b7noch", "k\u00f6nt", "es", "noch", "ein", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "hem\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.168": {"text": "Wenn Salz und Feuchtigkeit sich um die Nerven stremmen", "tokens": ["Wenn", "Salz", "und", "Feuch\u00b7tig\u00b7keit", "sich", "um", "die", "Ner\u00b7ven", "strem\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "PRF", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Und Blut und Luft verstockt, ist freylich viel Gefahr.", "tokens": ["Und", "Blut", "und", "Luft", "ver\u00b7stockt", ",", "ist", "frey\u00b7lich", "viel", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVPP", "$,", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Inde\u00dfen l\u00e4st der Arzt den krancken Leib nicht gar;", "tokens": ["In\u00b7de\u00b7\u00dfen", "l\u00e4st", "der", "Arzt", "den", "kran\u00b7cken", "Leib", "nicht", "gar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Er thut, so viel er weis, das Leben aufzuhalten,", "tokens": ["Er", "thut", ",", "so", "viel", "er", "weis", ",", "das", "Le\u00b7ben", "auf\u00b7zu\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADV", "PPER", "PTKVZ", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Und mu\u00df sein sch\u00f6nes Amt gleichwohl mit Trost verwalten.", "tokens": ["Und", "mu\u00df", "sein", "sch\u00f6\u00b7nes", "Amt", "gleich\u00b7wohl", "mit", "Trost", "ver\u00b7wal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Verzweiflen will ich nicht, mein Elend hat Vernunft,", "tokens": ["Ver\u00b7zwei\u00b7flen", "will", "ich", "nicht", ",", "mein", "E\u00b7lend", "hat", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "$,", "PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Und d\u00e4chten Gl\u00fcck und Heil an keine Wiederkunft,", "tokens": ["Und", "d\u00e4ch\u00b7ten", "Gl\u00fcck", "und", "Heil", "an", "kei\u00b7ne", "Wie\u00b7der\u00b7kunft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Ja, m\u00fcst ich Brodt und Licht mit Wa\u00dferziehn erschwingen,", "tokens": ["Ja", ",", "m\u00fcst", "ich", "Brodt", "und", "Licht", "mit", "Wa\u00b7\u00df\u00b7er\u00b7ziehn", "er\u00b7schwin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VMFIN", "PPER", "NN", "KON", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.176": {"text": "Verk\u00fcrzt ich doch den Schlaf, mich noch emporzubringen.", "tokens": ["Ver\u00b7k\u00fcrzt", "ich", "doch", "den", "Schlaf", ",", "mich", "noch", "em\u00b7por\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Es d\u00fcrfte mancher seyn, der, wenn er erstlich s\u00e4h,", "tokens": ["Es", "d\u00fcrf\u00b7te", "man\u00b7cher", "seyn", ",", "der", ",", "wenn", "er", "erst\u00b7lich", "s\u00e4h", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "VAINF", "$,", "PRELS", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Mit was vor Ehrligkeit der gute Vorsaz fleh,", "tokens": ["Mit", "was", "vor", "Ehr\u00b7lig\u00b7keit", "der", "gu\u00b7te", "Vor\u00b7saz", "fleh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Aus Gro\u00dfmuth und Verstand den Musen Vorschub th\u00e4te.", "tokens": ["Aus", "Gro\u00df\u00b7muth", "und", "Ver\u00b7stand", "den", "Mu\u00b7sen", "Vor\u00b7schub", "th\u00e4\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Allein er kennt mich nicht, indem mein arm Ger\u00e4the", "tokens": ["Al\u00b7lein", "er", "kennt", "mich", "nicht", ",", "in\u00b7dem", "mein", "arm", "Ge\u00b7r\u00e4\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Der ungezwungnen Tracht den frommen Sinn verstellt.", "tokens": ["Der", "un\u00b7ge\u00b7zwung\u00b7nen", "Tracht", "den", "from\u00b7men", "Sinn", "ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Dies macht mich liederlich. Die, so vor aller Welt", "tokens": ["Dies", "macht", "mich", "lie\u00b7der\u00b7lich", ".", "Die", ",", "so", "vor", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$.", "ART", "$,", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Von Huren, Sof und Fra\u00df an H\u00e4nd und F\u00fc\u00dfen zittern,", "tokens": ["Von", "Hu\u00b7ren", ",", "Sof", "und", "Fra\u00df", "an", "H\u00e4nd", "und", "F\u00fc\u00b7\u00dfen", "zit\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Die Weste von Damast mit stummen Schulden f\u00fcttern,", "tokens": ["Die", "Wes\u00b7te", "von", "Da\u00b7mast", "mit", "stum\u00b7men", "Schul\u00b7den", "f\u00fct\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Dem Nechsten Unrecht thun, mehr plaudern als verstehn", "tokens": ["Dem", "Nechs\u00b7ten", "Un\u00b7recht", "thun", ",", "mehr", "plau\u00b7dern", "als", "ver\u00b7stehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,", "ADV", "VVINF", "KOKOM", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Und allzeit nur dabey wie Drechslerdocken gehn,", "tokens": ["Und", "all\u00b7zeit", "nur", "da\u00b7bey", "wie", "Drechs\u00b7ler\u00b7do\u00b7cken", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PAV", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Die schielen, wenn man gr\u00fc\u00dft, ver\u00e4chtlich nach der Seite", "tokens": ["Die", "schie\u00b7len", ",", "wenn", "man", "gr\u00fc\u00dft", ",", "ver\u00b7\u00e4cht\u00b7lich", "nach", "der", "Sei\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "KOUS", "PIS", "VVFIN", "$,", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Und hei\u00dfen \u00fcberall galant- und kluge Leute.", "tokens": ["Und", "hei\u00b7\u00dfen", "\u00fc\u00b7be\u00b7rall", "ga\u00b7lant", "und", "klu\u00b7ge", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Verzeih mir, gro\u00dfer Mann. Gerechter Schmerz entf\u00e4hrt.", "tokens": ["Ver\u00b7zeih", "mir", ",", "gro\u00b7\u00dfer", "Mann", ".", "Ge\u00b7rech\u00b7ter", "Schmerz", "ent\u00b7f\u00e4hrt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "ADJA", "NN", "$.", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Ich k\u00fc\u00dfe dein Verdienst und w\u00e4r der Huld nicht werth.", "tokens": ["Ich", "k\u00fc\u00b7\u00dfe", "dein", "Ver\u00b7dienst", "und", "w\u00e4r", "der", "Huld", "nicht", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Als Fremdling sucht ich l\u00e4ngst in Menckens Huld zu kommen,", "tokens": ["Als", "Fremd\u00b7ling", "sucht", "ich", "l\u00e4ngst", "in", "Men\u00b7ckens", "Huld", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "ADV", "APPR", "NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "Als Fremdling hastu mich mit Sanftmuth angenommen.", "tokens": ["Als", "Fremd\u00b7ling", "has\u00b7tu", "mich", "mit", "Sanft\u00b7muth", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "Dein Nahme trieb mich an. Vor diesem w\u00fcntscht ich mir", "tokens": ["Dein", "Nah\u00b7me", "trieb", "mich", "an", ".", "Vor", "die\u00b7sem", "w\u00fcnt\u00b7scht", "ich", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "APPR", "PDAT", "VVFIN", "PPER", "PPER"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.194": {"text": "Nur dieses Gl\u00fcck allein, ber\u00fchmter Mann, von dir", "tokens": ["Nur", "die\u00b7ses", "Gl\u00fcck", "al\u00b7lein", ",", "be\u00b7r\u00fchm\u00b7ter", "Mann", ",", "von", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "PDAT", "NN", "ADV", "$,", "ADJA", "NN", "$,", "APPR", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Und deiner Wi\u00dfenschaft ein gutes Wort zu heben;", "tokens": ["Und", "dei\u00b7ner", "Wi\u00b7\u00dfen\u00b7schaft", "ein", "gu\u00b7tes", "Wort", "zu", "he\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Du aber hast auch gar den Musen Brodt gegeben.", "tokens": ["Du", "a\u00b7ber", "hast", "auch", "gar", "den", "Mu\u00b7sen", "Brodt", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Ist's m\u00f6glich, da\u00df auch ich der Welt noch n\u00fczen kan,", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "da\u00df", "auch", "ich", "der", "Welt", "noch", "n\u00fc\u00b7zen", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "KOUS", "ADV", "PPER", "ART", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "So gieb mir auch zulezt . . . . . . . . . Mittel an.", "tokens": ["So", "gieb", "mir", "auch", "zu\u00b7lezt", ".", ".", ".", ".", ".", ".", ".", ".", ".", "Mit\u00b7tel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.199": {"text": "Ich will gern alles thun und von der Pique dienen,", "tokens": ["Ich", "will", "gern", "al\u00b7les", "thun", "und", "von", "der", "Pi\u00b7que", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "VVINF", "KON", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Kan endlich nur mein Flei\u00df bey andrer . . . . gr\u00fcnen.", "tokens": ["Kan", "end\u00b7lich", "nur", "mein", "Flei\u00df", "bey", "an\u00b7drer", ".", ".", ".", ".", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "$.", "$.", "$.", "$.", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.201": {"text": "Man l\u00e4st den B\u00e4umen Zeit, die Brand und F\u00e4ule schw\u00e4cht,", "tokens": ["Man", "l\u00e4st", "den", "B\u00e4u\u00b7men", "Zeit", ",", "die", "Brand", "und", "F\u00e4u\u00b7le", "schw\u00e4cht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Und was man B\u00e4umen g\u00f6nnt, begehr auch ich mit Recht.", "tokens": ["Und", "was", "man", "B\u00e4u\u00b7men", "g\u00f6nnt", ",", "be\u00b7gehr", "auch", "ich", "mit", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "NN", "VVFIN", "$,", "VVFIN", "ADV", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Man seh der . . . . . . nach, ich will viel Fehler be\u00dfern,", "tokens": ["Man", "seh", "der", ".", ".", ".", ".", ".", ".", "nach", ",", "ich", "will", "viel", "Feh\u00b7ler", "be\u00b7\u00dfern", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "$.", "$.", "$.", "$.", "$.", "$.", "PTKVZ", "$,", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.204": {"text": "Die . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": ["Die", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["ART", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-", "measure": "single.down"}, "line.205": {"text": "Auch sag ich dieses nicht, als macht ich G\u00f6nnern M\u00fch,", "tokens": ["Auch", "sag", "ich", "die\u00b7ses", "nicht", ",", "als", "macht", "ich", "G\u00f6n\u00b7nern", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "PTKNEG", "$,", "KOUS", "VVFIN", "PPER", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Damit mein . . . . . . durch Fremder Unruh bl\u00fch;", "tokens": ["Da\u00b7mit", "mein", ".", ".", ".", ".", ".", ".", "durch", "Frem\u00b7der", "Un\u00b7ruh", "bl\u00fch", ";"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "$.", "$.", "$.", "$.", "$.", "$.", "APPR", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.207": {"text": "Ich hab ein . . . . . Herz, es lernt sich stets bescheiden", "tokens": ["Ich", "hab", "ein", ".", ".", ".", ".", ".", "Herz", ",", "es", "lernt", "sich", "stets", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKVZ", "$.", "$.", "$.", "$.", "$.", "NN", "$,", "PPER", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.208": {"text": "Und will, das glaube mir, viel lieber Mangel leiden", "tokens": ["Und", "will", ",", "das", "glau\u00b7be", "mir", ",", "viel", "lie\u00b7ber", "Man\u00b7gel", "lei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "$,", "PDS", "VVFIN", "PPER", "$,", "ADV", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Als G\u00f6nner . . . . . . . . . beschwerlich seyn", "tokens": ["Als", "G\u00f6n\u00b7ner", ".", ".", ".", ".", ".", ".", ".", ".", ".", "be\u00b7schwer\u00b7lich", "seyn"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word"], "pos": ["KOUS", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADJD", "VAINF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.210": {"text": "Ein Rath, ein gutes Wort . . . . . . . . . . . . . . . . . .", "tokens": ["Ein", "Rath", ",", "ein", "gu\u00b7tes", "Wort", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.211": {"text": "Was raubt dir der Verlust? Mich kan . . . . sch\u00fczen.", "tokens": ["Was", "raubt", "dir", "der", "Ver\u00b7lust", "?", "Mich", "kan", ".", ".", ".", ".", "sch\u00fc\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "$.", "PPER", "VMFIN", "$.", "$.", "$.", "$.", "VVINF", "$."], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.212": {"text": "Kein Zuwurf ist so schlecht, er wird mir jezo n\u00fczen,", "tokens": ["Kein", "Zu\u00b7wurf", "ist", "so", "schlecht", ",", "er", "wird", "mir", "je\u00b7zo", "n\u00fc\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Mir, welchem alles fehlt, sogar der Glieder Ruh.", "tokens": ["Mir", ",", "wel\u00b7chem", "al\u00b7les", "fehlt", ",", "so\u00b7gar", "der", "Glie\u00b7der", "Ruh", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PIS", "VVFIN", "$,", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Nun ist die Welt mein Haus, die . . . . . . . . . dazu", "tokens": ["Nun", "ist", "die", "Welt", "mein", "Haus", ",", "die", ".", ".", ".", ".", ".", ".", ".", ".", ".", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,", "PRELS", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "PAV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.215": {"text": "(als w . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . h\u00e4tte)", "tokens": ["(", "als", "w", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "h\u00e4t\u00b7te", ")"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["$(", "KOUS", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VAFIN", "$("], "meter": "-++-", "measure": "unknown.measure.di"}, "line.216": {"text": "Und wirft den krancken Fu\u00df in fremder Luft aufs Bette,", "tokens": ["Und", "wirft", "den", "kran\u00b7cken", "Fu\u00df", "in", "frem\u00b7der", "Luft", "aufs", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Wo anders Stroh und Holz den weichen Tittel f\u00fchrt.", "tokens": ["Wo", "an\u00b7ders", "Stroh", "und", "Holz", "den", "wei\u00b7chen", "Tit\u00b7tel", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Und was noch \u00fcberdies . . . . . . . . . . . . . . . . gebiehrt,", "tokens": ["Und", "was", "noch", "\u00fc\u00b7ber\u00b7dies", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "ge\u00b7biehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADV", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.219": {"text": "Ist, da\u00df ich um und um auch wider Gottes Ehre", "tokens": ["Ist", ",", "da\u00df", "ich", "um", "und", "um", "auch", "wi\u00b7der", "Got\u00b7tes", "Eh\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "PTKVZ", "KON", "APPR", "ADV", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Auf Theurung, Krieg, Accis und . . . . . fluchen h\u00f6re.", "tokens": ["Auf", "Theu\u00b7rung", ",", "Krieg", ",", "Ac\u00b7cis", "und", ".", ".", ".", ".", ".", "flu\u00b7chen", "h\u00f6\u00b7re", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NE", "KON", "$.", "$.", "$.", "$.", "$.", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.221": {"text": "Gott f\u00fchrt mich wunderlich, vielleicht auf deinen Ruhm.", "tokens": ["Gott", "f\u00fchrt", "mich", "wun\u00b7der\u00b7lich", ",", "viel\u00b7leicht", "auf", "dei\u00b7nen", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Ist Gro\u00dfmuth und Gedult der Weisen Eigenthum,", "tokens": ["Ist", "Gro\u00df\u00b7muth", "und", "Ge\u00b7dult", "der", "Wei\u00b7sen", "Ei\u00b7gen\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ART", "NN", "NN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.223": {"text": "So hof ich, dir einmahl auf unsers Pindus Schrancken,", "tokens": ["So", "hof", "ich", ",", "dir", "ein\u00b7mahl", "auf", "un\u00b7sers", "Pin\u00b7dus", "Schran\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "ADV", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Gelehrter M\u00e4cenat, mein Wohlergehn zu dancken.", "tokens": ["Ge\u00b7lehr\u00b7ter", "M\u00e4\u00b7ce\u00b7nat", ",", "mein", "Woh\u00b7ler\u00b7gehn", "zu", "dan\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Das Gl\u00fccke sey dein Freund und breite durch dein Haus", "tokens": ["Das", "Gl\u00fc\u00b7cke", "sey", "dein", "Freund", "und", "brei\u00b7te", "durch", "dein", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "KON", "ADJA", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Den Seegen des Geschlechts dir noch vor Augen aus", "tokens": ["Den", "See\u00b7gen", "des", "Ge\u00b7schlechts", "dir", "noch", "vor", "Au\u00b7gen", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "PPER", "ADV", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Und la\u00dfe deinen Sohn, den hofnungsvollen Erben,", "tokens": ["Und", "la\u00b7\u00dfe", "dei\u00b7nen", "Sohn", ",", "den", "hof\u00b7nungs\u00b7vol\u00b7len", "Er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "An Wachsthum und Verdienst dem Alter Trost erwerben.", "tokens": ["An", "Wach\u00b7sthum", "und", "Ver\u00b7dienst", "dem", "Al\u00b7ter", "Trost", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}