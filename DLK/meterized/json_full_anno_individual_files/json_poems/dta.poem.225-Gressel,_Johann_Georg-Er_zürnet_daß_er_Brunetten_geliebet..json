{"dta.poem.225": {"metadata": {"author": {"name": "Gressel, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "Er z\u00fcrnet/ da\u00df er  Brunetten  geliebet.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1716", "urn": "urn:nbn:de:kobv:b4-200905199041", "language": ["de:0.99"], "booktitle": "Celander [i. e. Gressel, Johann Georg]: Verliebte-Galante/ Sinn-Vermischte und Grab-Gedichte. Hamburg u. a., 1716."}, "poem": {"stanza.1": {"line.1": {"text": "Ich bin ein rechter Narro", "tokens": ["Ich", "bin", "ein", "rech\u00b7ter", "Nar\u00b7ro"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Mir fehlet eine Sparre/", "tokens": ["Mir", "feh\u00b7let", "ei\u00b7ne", "Spar\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weil ich verliebet bin.", "tokens": ["Weil", "ich", "ver\u00b7lie\u00b7bet", "bin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Den Haasen la\u00df ich streichen", "tokens": ["Den", "Haa\u00b7sen", "la\u00df", "ich", "strei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVIMP", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und die Vernunfft entweichen", "tokens": ["Und", "die", "Ver\u00b7nunfft", "ent\u00b7wei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "O ungerahtner Sinn!", "tokens": ["O", "un\u00b7ge\u00b7raht\u00b7ner", "Sinn", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Leute werden lachen/", "tokens": ["Die", "Leu\u00b7te", "wer\u00b7den", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wenn sie die l\u00e4pschen Sachen", "tokens": ["Wenn", "sie", "die", "l\u00e4p\u00b7schen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jm vorgem Liede sehn.", "tokens": ["Jm", "vor\u00b7gem", "Lie\u00b7de", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mich wunderts wie ich k\u00f6nnen", "tokens": ["Mich", "wun\u00b7derts", "wie", "ich", "k\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "KOKOM", "PPER", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "In dieses Bild entbrennen", "tokens": ["In", "die\u00b7ses", "Bild", "ent\u00b7bren\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und ihr zu Dienste stehn?", "tokens": ["Und", "ihr", "zu", "Diens\u00b7te", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Geh Th\u00f6rin geh von hinnen/", "tokens": ["Geh", "Th\u00f6\u00b7rin", "geh", "von", "hin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "APPR", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es wollen meine Sinnen", "tokens": ["Es", "wol\u00b7len", "mei\u00b7ne", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dir nicht mehr dienstbahr seyn.", "tokens": ["Dir", "nicht", "mehr", "dienst\u00b7bahr", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich wei\u00df mich wol zu retten", "tokens": ["Ich", "wei\u00df", "mich", "wol", "zu", "ret\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Aus deinen Liebes Ketten/", "tokens": ["Aus", "dei\u00b7nen", "Lie\u00b7bes", "Ket\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und kan mich bald befreyn.", "tokens": ["Und", "kan", "mich", "bald", "be\u00b7freyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Weil du nicht k\u00f6nnen schweigen/", "tokens": ["Weil", "du", "nicht", "k\u00f6n\u00b7nen", "schwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So hab ich wollen zeigen/", "tokens": ["So", "hab", "ich", "wol\u00b7len", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df du zu mild bericht\u2019t.", "tokens": ["Da\u00df", "du", "zu", "mild", "be\u00b7richt'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PPER", "PTKA", "ADJD", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die Fesseln sind zerrissen/", "tokens": ["Die", "Fes\u00b7seln", "sind", "zer\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die mich sonst halten m\u00fcssen/", "tokens": ["Die", "mich", "sonst", "hal\u00b7ten", "m\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Mein Hertze liebt dich nicht.", "tokens": ["Mein", "Hert\u00b7ze", "liebt", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Mein/ geh erst hin und lerne/", "tokens": ["Mein", "/", "geh", "erst", "hin", "und", "ler\u00b7ne", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "VVFIN", "ADV", "PTKVZ", "KON", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das deiner Augen-Sterne", "tokens": ["Das", "dei\u00b7ner", "Au\u00b7gen\u00b7S\u00b7ter\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PDS", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht so durchdringend sind/", "tokens": ["Nicht", "so", "durch\u00b7drin\u00b7gend", "sind", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Als wie du wol vermeynest/", "tokens": ["Als", "wie", "du", "wol", "ver\u00b7mey\u00b7nest", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dem du annehmlich scheinest/", "tokens": ["Dem", "du", "an\u00b7nehm\u00b7lich", "schei\u00b7nest", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Der ist aus Wahnwitz blind.", "tokens": ["Der", "ist", "aus", "Wahn\u00b7witz", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Vordem war ich beth\u00f6ret/", "tokens": ["Vor\u00b7dem", "war", "ich", "be\u00b7th\u00f6\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "$("], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Da\u00df ich ein Bild verehret/", "tokens": ["Da\u00df", "ich", "ein", "Bild", "ver\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So keine G\u00f6ttin ist", "tokens": ["So", "kei\u00b7ne", "G\u00f6t\u00b7tin", "ist"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Weil nun mit meinem Lieben", "tokens": ["Weil", "nun", "mit", "mei\u00b7nem", "Lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich Ketzerey getrieben/", "tokens": ["Ich", "Ket\u00b7ze\u00b7rey", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "So wird sie jetzt geb\u00fc\u00dft.", "tokens": ["So", "wird", "sie", "jetzt", "ge\u00b7b\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich breche die Altare/", "tokens": ["Ich", "bre\u00b7che", "die", "Al\u00b7ta\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und was sonst heilig ware/", "tokens": ["Und", "was", "sonst", "hei\u00b7lig", "wa\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In meinem Hertzen ab;", "tokens": ["In", "mei\u00b7nem", "Hert\u00b7zen", "ab", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Weil mich die Freyheit gr\u00fcsset/", "tokens": ["Weil", "mich", "die", "Frey\u00b7heit", "gr\u00fcs\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So sey sie auch gek\u00fcsset", "tokens": ["So", "sey", "sie", "auch", "ge\u00b7k\u00fcs\u00b7set"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Bis in das dunckle Grab.", "tokens": ["Bis", "in", "das", "dunck\u00b7le", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}