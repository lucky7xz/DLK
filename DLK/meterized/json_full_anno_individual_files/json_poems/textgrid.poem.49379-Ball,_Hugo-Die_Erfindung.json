{"textgrid.poem.49379": {"metadata": {"author": {"name": "Ball, Hugo", "birth": "N.A.", "death": "N.A."}, "title": "Die Erfindung", "genre": "verse", "period": "N.A.", "pub_year": 1906, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich zum ersten Male diesen Narren", "tokens": ["Als", "ich", "zum", "ers\u00b7ten", "Ma\u00b7le", "die\u00b7sen", "Nar\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein neues Totenw\u00e4glein vorgef\u00fchrt,", "tokens": ["Mein", "neu\u00b7es", "To\u00b7ten\u00b7w\u00e4g\u00b7lein", "vor\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War alle Welt im Leichenhaus ger\u00fchrt", "tokens": ["War", "al\u00b7le", "Welt", "im", "Lei\u00b7chen\u00b7haus", "ge\u00b7r\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von ihren Selbstportraits und anderen Schmarren.", "tokens": ["Von", "ih\u00b7ren", "Selbst\u00b7por\u00b7traits", "und", "an\u00b7de\u00b7ren", "Schmar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Sie sagten mir: nun wohl, das sei ein Karren,", "tokens": ["Sie", "sag\u00b7ten", "mir", ":", "nun", "wohl", ",", "das", "sei", "ein", "Kar\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "ADV", "ADV", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jedoch die R\u00e4der seien nicht geschmiert,", "tokens": ["Je\u00b7doch", "die", "R\u00e4\u00b7der", "sei\u00b7en", "nicht", "ge\u00b7schmiert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch sei es innen nicht genug verziert", "tokens": ["Auch", "sei", "es", "in\u00b7nen", "nicht", "ge\u00b7nug", "ver\u00b7ziert"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und schlie\u00dflich wollten sie mich selbst verscharren.", "tokens": ["Und", "schlie\u00df\u00b7lich", "woll\u00b7ten", "sie", "mich", "selbst", "ver\u00b7schar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sie haben von der Sache nichts begriffen,", "tokens": ["Sie", "ha\u00b7ben", "von", "der", "Sa\u00b7che", "nichts", "be\u00b7grif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als da\u00df es wurmig zugeht im Geliege", "tokens": ["Als", "da\u00df", "es", "wur\u00b7mig", "zu\u00b7geht", "im", "Ge\u00b7lie\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "VVFIN", "APPRART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wenn ich mich vor Lachen jetzt noch biege,", "tokens": ["Und", "wenn", "ich", "mich", "vor", "La\u00b7chen", "jetzt", "noch", "bie\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "APPR", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "So ist es, weil sie drum herum gestanden,", "tokens": ["So", "ist", "es", ",", "weil", "sie", "drum", "he\u00b7rum", "ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PAV", "APZR", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Pfeife rauchten und den Mut nicht fanden,", "tokens": ["Die", "Pfei\u00b7fe", "rauch\u00b7ten", "und", "den", "Mut", "nicht", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hineinzusteigen in die schwarze Wiege.", "tokens": ["Hin\u00b7ein\u00b7zu\u00b7stei\u00b7gen", "in", "die", "schwar\u00b7ze", "Wie\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Als ich zum ersten Male diesen Narren", "tokens": ["Als", "ich", "zum", "ers\u00b7ten", "Ma\u00b7le", "die\u00b7sen", "Nar\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein neues Totenw\u00e4glein vorgef\u00fchrt,", "tokens": ["Mein", "neu\u00b7es", "To\u00b7ten\u00b7w\u00e4g\u00b7lein", "vor\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War alle Welt im Leichenhaus ger\u00fchrt", "tokens": ["War", "al\u00b7le", "Welt", "im", "Lei\u00b7chen\u00b7haus", "ge\u00b7r\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von ihren Selbstportraits und anderen Schmarren.", "tokens": ["Von", "ih\u00b7ren", "Selbst\u00b7por\u00b7traits", "und", "an\u00b7de\u00b7ren", "Schmar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Sie sagten mir: nun wohl, das sei ein Karren,", "tokens": ["Sie", "sag\u00b7ten", "mir", ":", "nun", "wohl", ",", "das", "sei", "ein", "Kar\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "ADV", "ADV", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jedoch die R\u00e4der seien nicht geschmiert,", "tokens": ["Je\u00b7doch", "die", "R\u00e4\u00b7der", "sei\u00b7en", "nicht", "ge\u00b7schmiert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch sei es innen nicht genug verziert", "tokens": ["Auch", "sei", "es", "in\u00b7nen", "nicht", "ge\u00b7nug", "ver\u00b7ziert"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und schlie\u00dflich wollten sie mich selbst verscharren.", "tokens": ["Und", "schlie\u00df\u00b7lich", "woll\u00b7ten", "sie", "mich", "selbst", "ver\u00b7schar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Sie haben von der Sache nichts begriffen,", "tokens": ["Sie", "ha\u00b7ben", "von", "der", "Sa\u00b7che", "nichts", "be\u00b7grif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als da\u00df es wurmig zugeht im Geliege", "tokens": ["Als", "da\u00df", "es", "wur\u00b7mig", "zu\u00b7geht", "im", "Ge\u00b7lie\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "VVFIN", "APPRART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wenn ich mich vor Lachen jetzt noch biege,", "tokens": ["Und", "wenn", "ich", "mich", "vor", "La\u00b7chen", "jetzt", "noch", "bie\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "APPR", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "So ist es, weil sie drum herum gestanden,", "tokens": ["So", "ist", "es", ",", "weil", "sie", "drum", "he\u00b7rum", "ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PAV", "APZR", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Pfeife rauchten und den Mut nicht fanden,", "tokens": ["Die", "Pfei\u00b7fe", "rauch\u00b7ten", "und", "den", "Mut", "nicht", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hineinzusteigen in die schwarze Wiege.", "tokens": ["Hin\u00b7ein\u00b7zu\u00b7stei\u00b7gen", "in", "die", "schwar\u00b7ze", "Wie\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}