{"textgrid.poem.33422": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "An die Schwestern", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schwestern, la\u00dft euch's nicht verdriessen,", "tokens": ["Schwes\u00b7tern", ",", "la\u00dft", "euch's", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df uns keine essen sieht;", "tokens": ["Da\u00df", "uns", "kei\u00b7ne", "es\u00b7sen", "sieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Danken w\u00fcrdet ihr uns m\u00fcssen,", "tokens": ["Dan\u00b7ken", "w\u00fcr\u00b7det", "ihr", "uns", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fc\u00dftet ihr, warum's geschieht.", "tokens": ["W\u00fc\u00df\u00b7tet", "ihr", ",", "war\u00b7um's", "ge\u00b7schieht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Solltet ihr das Wunderbare", "tokens": ["Soll\u00b7tet", "ihr", "das", "Wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Uns'rer Tafellogen seh'n,", "tokens": ["Un\u00b7s'\u00b7rer", "Ta\u00b7fel\u00b7lo\u00b7gen", "seh'n", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "O so glaubet mir, die Haare", "tokens": ["O", "so", "glau\u00b7bet", "mir", ",", "die", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "PPER", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fcrden euch zu Berge steh'n.", "tokens": ["W\u00fcr\u00b7den", "euch", "zu", "Ber\u00b7ge", "steh'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Drachenzungen, Kr\u00f6teneier,", "tokens": ["Dra\u00b7chen\u00b7zun\u00b7gen", ",", "Kr\u00f6\u00b7te\u00b7nei\u00b7er", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["PAV", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Faul und stinkend, wie die Pest,", "tokens": ["Faul", "und", "stin\u00b7kend", ",", "wie", "die", "Pest", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles, was bei'm H\u00f6llenfeuer", "tokens": ["Al\u00b7les", ",", "was", "bei'm", "H\u00f6l\u00b7len\u00b7feu\u00b7er"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Satan selber kochen l\u00e4\u00dft;", "tokens": ["Sa\u00b7tan", "sel\u00b7ber", "ko\u00b7chen", "l\u00e4\u00dft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Seine feu'rigen Pokale,", "tokens": ["Sei\u00b7ne", "feu'\u00b7ri\u00b7gen", "Po\u00b7ka\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Schwefel, der d'rin brennt,", "tokens": ["Und", "der", "Schwe\u00b7fel", ",", "der", "d'\u00b7rin", "brennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "W\u00e4ren gegen uns're Mahle", "tokens": ["W\u00e4\u00b7ren", "ge\u00b7gen", "un\u00b7s'\u00b7re", "Mah\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Noch ein f\u00fcrstlich Traktament.", "tokens": ["Noch", "ein", "f\u00fcrst\u00b7lich", "Trak\u00b7ta\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "H\u00f6rt, wir sitzen in der Runde,", "tokens": ["H\u00f6rt", ",", "wir", "sit\u00b7zen", "in", "der", "Run\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Essen mit dem Maul \u2013 o weh!", "tokens": ["Es\u00b7sen", "mit", "dem", "Maul", "\u2013", "o", "weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$(", "FM", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was wir k\u00e4uen, wird zur Stunde", "tokens": ["Was", "wir", "k\u00e4u\u00b7en", ",", "wird", "zur", "Stun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "VVINF", "$,", "VAFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns im Mund zum \u2013 Fricassee.", "tokens": ["Uns", "im", "Mund", "zum", "\u2013", "Fri\u00b7cas\u00b7see", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPRART", "$(", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wir zerschneiden, was wir finden,", "tokens": ["Wir", "zer\u00b7schnei\u00b7den", ",", "was", "wir", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schonen keines Tafelst\u00fcck's:", "tokens": ["Scho\u00b7nen", "kei\u00b7nes", "Ta\u00b7fel\u00b7st\u00fc\u00b7ck's", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, und aus der Sch\u00fcssel schwinden", "tokens": ["Ach", ",", "und", "aus", "der", "Sch\u00fcs\u00b7sel", "schwin\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KON", "APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns die Speisen Augenblick's.", "tokens": ["Uns", "die", "Spei\u00b7sen", "Au\u00b7gen\u00b7blick'", "s."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "ART", "NN", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Selbst die Teller, glaubt's ihr Sch\u00f6nen,", "tokens": ["Selbst", "die", "Tel\u00b7ler", ",", "glaubt's", "ihr", "Sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ritzen wir nicht selten wund;", "tokens": ["Rit\u00b7zen", "wir", "nicht", "sel\u00b7ten", "wund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das Gefror'ne wird zu Thr\u00e4nen,", "tokens": ["Das", "Ge\u00b7fror'\u00b7ne", "wird", "zu", "Thr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zergeht uns in dem Mund.", "tokens": ["Und", "zer\u00b7geht", "uns", "in", "dem", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Doch das Schrecklichste aus allen", "tokens": ["Doch", "das", "Schreck\u00b7lichs\u00b7te", "aus", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrde unser Trank euch sein;", "tokens": ["W\u00fcr\u00b7de", "un\u00b7ser", "Trank", "euch", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn bei \u00e4chten Maurermahlen", "tokens": ["Denn", "bei", "\u00e4ch\u00b7ten", "Mau\u00b7rer\u00b7mah\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Trinkt man nichts \u2013 als Vier und Wein.", "tokens": ["Trinkt", "man", "nichts", "\u2013", "als", "Vier", "und", "Wein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIS", "$(", "KOKOM", "CARD", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Was uns eingeweihte Zecher", "tokens": ["Was", "uns", "ein\u00b7ge\u00b7weih\u00b7te", "Ze\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Selbst oft Wunder nimmt, ist das:", "tokens": ["Selbst", "oft", "Wun\u00b7der", "nimmt", ",", "ist", "das", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "$,", "VAFIN", "PDS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns're Flaschen haben L\u00f6cher,", "tokens": ["Un\u00b7s'\u00b7re", "Fla\u00b7schen", "ha\u00b7ben", "L\u00f6\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch der Wein rinnt \u2013 nur in's Glas.", "tokens": ["Doch", "der", "Wein", "rinnt", "\u2013", "nur", "in's", "Glas", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$(", "ADV", "APPRART", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.10": {"line.1": {"text": "Was ihr ohne Schrecken sehen", "tokens": ["Was", "ihr", "oh\u00b7ne", "Schre\u00b7cken", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nntet, w\u00e4re dies allein,", "tokens": ["K\u00f6nn\u00b7tet", ",", "w\u00e4\u00b7re", "dies", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "VAFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir euer'm Wohlergehen", "tokens": ["Da\u00df", "wir", "eu\u00b7er'm", "Woh\u00b7ler\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Immer auch ein Gl\u00e4schen weih'n.", "tokens": ["Im\u00b7mer", "auch", "ein", "Gl\u00e4s\u00b7chen", "weih'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Schwestern, la\u00dft euch's nicht verdriessen,", "tokens": ["Schwes\u00b7tern", ",", "la\u00dft", "euch's", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df uns keine essen sieht;", "tokens": ["Da\u00df", "uns", "kei\u00b7ne", "es\u00b7sen", "sieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Danken w\u00fcrdet ihr uns m\u00fcssen,", "tokens": ["Dan\u00b7ken", "w\u00fcr\u00b7det", "ihr", "uns", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fc\u00dftet ihr, warum's geschieht.", "tokens": ["W\u00fc\u00df\u00b7tet", "ihr", ",", "war\u00b7um's", "ge\u00b7schieht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Solltet ihr das Wunderbare", "tokens": ["Soll\u00b7tet", "ihr", "das", "Wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Uns'rer Tafellogen seh'n,", "tokens": ["Un\u00b7s'\u00b7rer", "Ta\u00b7fel\u00b7lo\u00b7gen", "seh'n", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "O so glaubet mir, die Haare", "tokens": ["O", "so", "glau\u00b7bet", "mir", ",", "die", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "PPER", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fcrden euch zu Berge steh'n.", "tokens": ["W\u00fcr\u00b7den", "euch", "zu", "Ber\u00b7ge", "steh'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Drachenzungen, Kr\u00f6teneier,", "tokens": ["Dra\u00b7chen\u00b7zun\u00b7gen", ",", "Kr\u00f6\u00b7te\u00b7nei\u00b7er", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["PAV", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Faul und stinkend, wie die Pest,", "tokens": ["Faul", "und", "stin\u00b7kend", ",", "wie", "die", "Pest", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles, was bei'm H\u00f6llenfeuer", "tokens": ["Al\u00b7les", ",", "was", "bei'm", "H\u00f6l\u00b7len\u00b7feu\u00b7er"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Satan selber kochen l\u00e4\u00dft;", "tokens": ["Sa\u00b7tan", "sel\u00b7ber", "ko\u00b7chen", "l\u00e4\u00dft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Seine feu'rigen Pokale,", "tokens": ["Sei\u00b7ne", "feu'\u00b7ri\u00b7gen", "Po\u00b7ka\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Schwefel, der d'rin brennt,", "tokens": ["Und", "der", "Schwe\u00b7fel", ",", "der", "d'\u00b7rin", "brennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "W\u00e4ren gegen uns're Mahle", "tokens": ["W\u00e4\u00b7ren", "ge\u00b7gen", "un\u00b7s'\u00b7re", "Mah\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Noch ein f\u00fcrstlich Traktament.", "tokens": ["Noch", "ein", "f\u00fcrst\u00b7lich", "Trak\u00b7ta\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "H\u00f6rt, wir sitzen in der Runde,", "tokens": ["H\u00f6rt", ",", "wir", "sit\u00b7zen", "in", "der", "Run\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Essen mit dem Maul \u2013 o weh!", "tokens": ["Es\u00b7sen", "mit", "dem", "Maul", "\u2013", "o", "weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$(", "FM", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was wir k\u00e4uen, wird zur Stunde", "tokens": ["Was", "wir", "k\u00e4u\u00b7en", ",", "wird", "zur", "Stun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "VVINF", "$,", "VAFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns im Mund zum \u2013 Fricassee.", "tokens": ["Uns", "im", "Mund", "zum", "\u2013", "Fri\u00b7cas\u00b7see", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPRART", "$(", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Wir zerschneiden, was wir finden,", "tokens": ["Wir", "zer\u00b7schnei\u00b7den", ",", "was", "wir", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schonen keines Tafelst\u00fcck's:", "tokens": ["Scho\u00b7nen", "kei\u00b7nes", "Ta\u00b7fel\u00b7st\u00fc\u00b7ck's", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, und aus der Sch\u00fcssel schwinden", "tokens": ["Ach", ",", "und", "aus", "der", "Sch\u00fcs\u00b7sel", "schwin\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KON", "APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns die Speisen Augenblick's.", "tokens": ["Uns", "die", "Spei\u00b7sen", "Au\u00b7gen\u00b7blick'", "s."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "ART", "NN", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Selbst die Teller, glaubt's ihr Sch\u00f6nen,", "tokens": ["Selbst", "die", "Tel\u00b7ler", ",", "glaubt's", "ihr", "Sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ritzen wir nicht selten wund;", "tokens": ["Rit\u00b7zen", "wir", "nicht", "sel\u00b7ten", "wund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das Gefror'ne wird zu Thr\u00e4nen,", "tokens": ["Das", "Ge\u00b7fror'\u00b7ne", "wird", "zu", "Thr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zergeht uns in dem Mund.", "tokens": ["Und", "zer\u00b7geht", "uns", "in", "dem", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Doch das Schrecklichste aus allen", "tokens": ["Doch", "das", "Schreck\u00b7lichs\u00b7te", "aus", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrde unser Trank euch sein;", "tokens": ["W\u00fcr\u00b7de", "un\u00b7ser", "Trank", "euch", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn bei \u00e4chten Maurermahlen", "tokens": ["Denn", "bei", "\u00e4ch\u00b7ten", "Mau\u00b7rer\u00b7mah\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Trinkt man nichts \u2013 als Vier und Wein.", "tokens": ["Trinkt", "man", "nichts", "\u2013", "als", "Vier", "und", "Wein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIS", "$(", "KOKOM", "CARD", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Was uns eingeweihte Zecher", "tokens": ["Was", "uns", "ein\u00b7ge\u00b7weih\u00b7te", "Ze\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Selbst oft Wunder nimmt, ist das:", "tokens": ["Selbst", "oft", "Wun\u00b7der", "nimmt", ",", "ist", "das", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "$,", "VAFIN", "PDS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns're Flaschen haben L\u00f6cher,", "tokens": ["Un\u00b7s'\u00b7re", "Fla\u00b7schen", "ha\u00b7ben", "L\u00f6\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch der Wein rinnt \u2013 nur in's Glas.", "tokens": ["Doch", "der", "Wein", "rinnt", "\u2013", "nur", "in's", "Glas", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$(", "ADV", "APPRART", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.20": {"line.1": {"text": "Was ihr ohne Schrecken sehen", "tokens": ["Was", "ihr", "oh\u00b7ne", "Schre\u00b7cken", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nntet, w\u00e4re dies allein,", "tokens": ["K\u00f6nn\u00b7tet", ",", "w\u00e4\u00b7re", "dies", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "VAFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir euer'm Wohlergehen", "tokens": ["Da\u00df", "wir", "eu\u00b7er'm", "Woh\u00b7ler\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Immer auch ein Gl\u00e4schen weih'n.", "tokens": ["Im\u00b7mer", "auch", "ein", "Gl\u00e4s\u00b7chen", "weih'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}