{"textgrid.poem.44049": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Schreib an und las dir dieses Licht", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schreib an und las dir dieses Licht", "tokens": ["Schreib", "an", "und", "las", "dir", "die\u00b7ses", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "KON", "VVFIN", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von nun an zum Ged\u00e4chtn\u00fc\u00df dienen!", "tokens": ["Von", "nun", "an", "zum", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "die\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "APPRART", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ich bin ein Mensch und weis es nicht,", "tokens": ["Ich", "bin", "ein", "Mensch", "und", "weis", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "PTKVZ", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo Kr\u00e4uter meines Grabes gr\u00fcnen;", "tokens": ["Wo", "Kr\u00e4u\u00b7ter", "mei\u00b7nes", "Gra\u00b7bes", "gr\u00fc\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Auch weis ich nicht den Augenblick,", "tokens": ["Auch", "weis", "ich", "nicht", "den", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An dem mein Creuz und Ungel\u00fcck", "tokens": ["An", "dem", "mein", "Creuz", "und", "Un\u00b7ge\u00b7l\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sich miteinander schlie\u00dfen sollen;", "tokens": ["Sich", "mi\u00b7tein\u00b7an\u00b7der", "schlie\u00b7\u00dfen", "sol\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Drum sprech ich dich noch, weil ich kan,", "tokens": ["Drum", "sprech", "ich", "dich", "noch", ",", "weil", "ich", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Um dieses Freundschaftszeichen an:", "tokens": ["Um", "die\u00b7ses", "Freund\u00b7schafts\u00b7zei\u00b7chen", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Erzehl einmahl der Welt, wie viel wir leisten wollen.", "tokens": ["Er\u00b7zehl", "ein\u00b7mahl", "der", "Welt", ",", "wie", "viel", "wir", "leis\u00b7ten", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,", "PWAV", "PIS", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Mein treu Gem\u00fcthe nehm ich aus,", "tokens": ["Mein", "treu", "Ge\u00b7m\u00fc\u00b7the", "nehm", "ich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sonst bin ich nicht mehr Ich zu nennen;", "tokens": ["Sonst", "bin", "ich", "nicht", "mehr", "Ich", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nun mag ich keinen Lorbeerstraus,", "tokens": ["Nun", "mag", "ich", "kei\u00b7nen", "Lor\u00b7beer\u00b7straus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als den mir Baar und Freundschaft g\u00f6nnen.", "tokens": ["Als", "den", "mir", "Baar", "und", "Freund\u00b7schaft", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "NE", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es komme, was die Schickung will,", "tokens": ["Es", "kom\u00b7me", ",", "was", "die", "Schi\u00b7ckung", "will", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ART", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich halte wie ein Krancker still", "tokens": ["Ich", "hal\u00b7te", "wie", "ein", "Kran\u00b7cker", "still"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und weis nichts mehr von meinem Leben.", "tokens": ["Und", "weis", "nichts", "mehr", "von", "mei\u00b7nem", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "PIS", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Seelenruh, der Wei\u00dfheit Frucht,", "tokens": ["Die", "See\u00b7len\u00b7ruh", ",", "der", "Wei\u00df\u00b7heit", "Frucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So ich in Wi\u00dfenschaft gesucht,", "tokens": ["So", "ich", "in", "Wi\u00b7\u00dfen\u00b7schaft", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die, sag ich, las ich mir von der Verzweiflung geben.", "tokens": ["Die", ",", "sag", "ich", ",", "las", "ich", "mir", "von", "der", "Ver\u00b7zwei\u00b7flung", "ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dich und noch wenig, ja, kaum drey", "tokens": ["Dich", "und", "noch", "we\u00b7nig", ",", "ja", ",", "kaum", "drey"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "KON", "ADV", "PIS", "$,", "PTKANT", "$,", "ADV", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedaur ich mit betr\u00fcbten Herzen;", "tokens": ["Be\u00b7daur", "ich", "mit", "be\u00b7tr\u00fcb\u00b7ten", "Her\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst breche Mond und Erd entzwey,", "tokens": ["Sonst", "bre\u00b7che", "Mond", "und", "Erd", "ent\u00b7zwey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es dienet mir zum bittern Scherzen.", "tokens": ["Es", "die\u00b7net", "mir", "zum", "bit\u00b7tern", "Scher\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wie ein gro\u00dfes Theil der Welt", "tokens": ["Und", "wie", "ein", "gro\u00b7\u00dfes", "Theil", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich unwerth, toll und schimpflich h\u00e4lt,", "tokens": ["Mich", "un\u00b7werth", ",", "toll", "und", "schimpf\u00b7lich", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So lach ich nunmehr aller Sachen,", "tokens": ["So", "lach", "ich", "nun\u00b7mehr", "al\u00b7ler", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie seyn auch noch so klug, gelehrt,", "tokens": ["Sie", "seyn", "auch", "noch", "so", "klug", ",", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sch\u00f6n, weise, reich und hoch geehrt,", "tokens": ["Sch\u00f6n", ",", "wei\u00b7se", ",", "reich", "und", "hoch", "ge\u00b7ehrt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und nichts als Spott und Ha\u00df weis meine Lust zu machen.", "tokens": ["Und", "nichts", "als", "Spott", "und", "Ha\u00df", "weis", "mei\u00b7ne", "Lust", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "NN", "KON", "NN", "PTKVZ", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Auch diese Zeilen \u00e4rgern mich;", "tokens": ["Auch", "die\u00b7se", "Zei\u00b7len", "\u00e4r\u00b7gern", "mich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O k\u00f6nt ich doch nur nichts gedencken!", "tokens": ["O", "k\u00f6nt", "ich", "doch", "nur", "nichts", "ge\u00b7den\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein eignes Wesen martert sich.", "tokens": ["Mein", "eig\u00b7nes", "We\u00b7sen", "mar\u00b7tert", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist Gott zu schwach, mir Trost zu schencken,", "tokens": ["Ist", "Gott", "zu", "schwach", ",", "mir", "Trost", "zu", "schen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PTKZU", "VVFIN", "$,", "PPER", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O warum hat er mir ein Pfand", "tokens": ["O", "wa\u00b7rum", "hat", "er", "mir", "ein", "Pfand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PWAV", "VAFIN", "PPER", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von Kunst und Wei\u00dfheit zugewand?", "tokens": ["Von", "Kunst", "und", "Wei\u00df\u00b7heit", "zu\u00b7ge\u00b7wand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich kan es doch zu nichts gebrauchen.", "tokens": ["Ich", "kan", "es", "doch", "zu", "nichts", "ge\u00b7brau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKA", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "H\u00f6r, ewige Gerechtigkeit:", "tokens": ["H\u00f6r", ",", "e\u00b7wi\u00b7ge", "Ge\u00b7rech\u00b7tig\u00b7keit", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verdient mein Herz nicht gute Zeit,", "tokens": ["Ver\u00b7di\u00b7ent", "mein", "Herz", "nicht", "gu\u00b7te", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "So las es auf einmahl in Rauch und Glut verrauchen.", "tokens": ["So", "las", "es", "auf", "ein\u00b7mahl", "in", "Rauch", "und", "Glut", "ver\u00b7rau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Weist du noch was von Fried und Ruh,", "tokens": ["Weist", "du", "noch", "was", "von", "Fried", "und", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PWS", "APPR", "NN", "KON", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "So mach es dir bey Zeiten n\u00fcze;", "tokens": ["So", "mach", "es", "dir", "bey", "Zei\u00b7ten", "n\u00fc\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Gl\u00fccke f\u00e4hrt oft blindlings zu", "tokens": ["Das", "Gl\u00fc\u00b7cke", "f\u00e4hrt", "oft", "blind\u00b7lings", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und raubt uns mit geschwindem Blize.", "tokens": ["Und", "raubt", "uns", "mit", "ge\u00b7schwin\u00b7dem", "Bli\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es geh auch, kan's nicht anders seyn,", "tokens": ["Es", "geh", "auch", ",", "kan's", "nicht", "an\u00b7ders", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VMFIN", "PTKNEG", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mein Seegen und Ged\u00e4chtn\u00fc\u00df ein,", "tokens": ["Mein", "See\u00b7gen", "und", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich w\u00fcntsche ganz und gar zu sterben.", "tokens": ["Ich", "w\u00fcnt\u00b7sche", "ganz", "und", "gar", "zu", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Folgt dir nur, was mir hier gebrach,", "tokens": ["Folgt", "dir", "nur", ",", "was", "mir", "hier", "ge\u00b7brach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Von nun an zweyfach gl\u00fccklich nach,", "tokens": ["Von", "nun", "an", "zwey\u00b7fach", "gl\u00fcck\u00b7lich", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So tr\u00f6stet noch mein Freund mein g\u00e4nzliches Verderben.", "tokens": ["So", "tr\u00f6s\u00b7tet", "noch", "mein", "Freund", "mein", "g\u00e4nz\u00b7li\u00b7ches", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Schreib an und las dir dieses Licht", "tokens": ["Schreib", "an", "und", "las", "dir", "die\u00b7ses", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "KON", "VVFIN", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von nun an zum Ged\u00e4chtn\u00fc\u00df dienen!", "tokens": ["Von", "nun", "an", "zum", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "die\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "APPRART", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ich bin ein Mensch und weis es nicht,", "tokens": ["Ich", "bin", "ein", "Mensch", "und", "weis", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "PTKVZ", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo Kr\u00e4uter meines Grabes gr\u00fcnen;", "tokens": ["Wo", "Kr\u00e4u\u00b7ter", "mei\u00b7nes", "Gra\u00b7bes", "gr\u00fc\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Auch weis ich nicht den Augenblick,", "tokens": ["Auch", "weis", "ich", "nicht", "den", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An dem mein Creuz und Ungel\u00fcck", "tokens": ["An", "dem", "mein", "Creuz", "und", "Un\u00b7ge\u00b7l\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sich miteinander schlie\u00dfen sollen;", "tokens": ["Sich", "mi\u00b7tein\u00b7an\u00b7der", "schlie\u00b7\u00dfen", "sol\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Drum sprech ich dich noch, weil ich kan,", "tokens": ["Drum", "sprech", "ich", "dich", "noch", ",", "weil", "ich", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Um dieses Freundschaftszeichen an:", "tokens": ["Um", "die\u00b7ses", "Freund\u00b7schafts\u00b7zei\u00b7chen", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Erzehl einmahl der Welt, wie viel wir leisten wollen.", "tokens": ["Er\u00b7zehl", "ein\u00b7mahl", "der", "Welt", ",", "wie", "viel", "wir", "leis\u00b7ten", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,", "PWAV", "PIS", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Mein treu Gem\u00fcthe nehm ich aus,", "tokens": ["Mein", "treu", "Ge\u00b7m\u00fc\u00b7the", "nehm", "ich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sonst bin ich nicht mehr Ich zu nennen;", "tokens": ["Sonst", "bin", "ich", "nicht", "mehr", "Ich", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nun mag ich keinen Lorbeerstraus,", "tokens": ["Nun", "mag", "ich", "kei\u00b7nen", "Lor\u00b7beer\u00b7straus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als den mir Baar und Freundschaft g\u00f6nnen.", "tokens": ["Als", "den", "mir", "Baar", "und", "Freund\u00b7schaft", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "NE", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es komme, was die Schickung will,", "tokens": ["Es", "kom\u00b7me", ",", "was", "die", "Schi\u00b7ckung", "will", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ART", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich halte wie ein Krancker still", "tokens": ["Ich", "hal\u00b7te", "wie", "ein", "Kran\u00b7cker", "still"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und weis nichts mehr von meinem Leben.", "tokens": ["Und", "weis", "nichts", "mehr", "von", "mei\u00b7nem", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "PIS", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Seelenruh, der Wei\u00dfheit Frucht,", "tokens": ["Die", "See\u00b7len\u00b7ruh", ",", "der", "Wei\u00df\u00b7heit", "Frucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So ich in Wi\u00dfenschaft gesucht,", "tokens": ["So", "ich", "in", "Wi\u00b7\u00dfen\u00b7schaft", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die, sag ich, las ich mir von der Verzweiflung geben.", "tokens": ["Die", ",", "sag", "ich", ",", "las", "ich", "mir", "von", "der", "Ver\u00b7zwei\u00b7flung", "ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Dich und noch wenig, ja, kaum drey", "tokens": ["Dich", "und", "noch", "we\u00b7nig", ",", "ja", ",", "kaum", "drey"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "KON", "ADV", "PIS", "$,", "PTKANT", "$,", "ADV", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedaur ich mit betr\u00fcbten Herzen;", "tokens": ["Be\u00b7daur", "ich", "mit", "be\u00b7tr\u00fcb\u00b7ten", "Her\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst breche Mond und Erd entzwey,", "tokens": ["Sonst", "bre\u00b7che", "Mond", "und", "Erd", "ent\u00b7zwey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es dienet mir zum bittern Scherzen.", "tokens": ["Es", "die\u00b7net", "mir", "zum", "bit\u00b7tern", "Scher\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wie ein gro\u00dfes Theil der Welt", "tokens": ["Und", "wie", "ein", "gro\u00b7\u00dfes", "Theil", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich unwerth, toll und schimpflich h\u00e4lt,", "tokens": ["Mich", "un\u00b7werth", ",", "toll", "und", "schimpf\u00b7lich", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So lach ich nunmehr aller Sachen,", "tokens": ["So", "lach", "ich", "nun\u00b7mehr", "al\u00b7ler", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie seyn auch noch so klug, gelehrt,", "tokens": ["Sie", "seyn", "auch", "noch", "so", "klug", ",", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sch\u00f6n, weise, reich und hoch geehrt,", "tokens": ["Sch\u00f6n", ",", "wei\u00b7se", ",", "reich", "und", "hoch", "ge\u00b7ehrt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und nichts als Spott und Ha\u00df weis meine Lust zu machen.", "tokens": ["Und", "nichts", "als", "Spott", "und", "Ha\u00df", "weis", "mei\u00b7ne", "Lust", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "NN", "KON", "NN", "PTKVZ", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Auch diese Zeilen \u00e4rgern mich;", "tokens": ["Auch", "die\u00b7se", "Zei\u00b7len", "\u00e4r\u00b7gern", "mich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O k\u00f6nt ich doch nur nichts gedencken!", "tokens": ["O", "k\u00f6nt", "ich", "doch", "nur", "nichts", "ge\u00b7den\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein eignes Wesen martert sich.", "tokens": ["Mein", "eig\u00b7nes", "We\u00b7sen", "mar\u00b7tert", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist Gott zu schwach, mir Trost zu schencken,", "tokens": ["Ist", "Gott", "zu", "schwach", ",", "mir", "Trost", "zu", "schen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PTKZU", "VVFIN", "$,", "PPER", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O warum hat er mir ein Pfand", "tokens": ["O", "wa\u00b7rum", "hat", "er", "mir", "ein", "Pfand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PWAV", "VAFIN", "PPER", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von Kunst und Wei\u00dfheit zugewand?", "tokens": ["Von", "Kunst", "und", "Wei\u00df\u00b7heit", "zu\u00b7ge\u00b7wand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich kan es doch zu nichts gebrauchen.", "tokens": ["Ich", "kan", "es", "doch", "zu", "nichts", "ge\u00b7brau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKA", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "H\u00f6r, ewige Gerechtigkeit:", "tokens": ["H\u00f6r", ",", "e\u00b7wi\u00b7ge", "Ge\u00b7rech\u00b7tig\u00b7keit", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verdient mein Herz nicht gute Zeit,", "tokens": ["Ver\u00b7di\u00b7ent", "mein", "Herz", "nicht", "gu\u00b7te", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "So las es auf einmahl in Rauch und Glut verrauchen.", "tokens": ["So", "las", "es", "auf", "ein\u00b7mahl", "in", "Rauch", "und", "Glut", "ver\u00b7rau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Weist du noch was von Fried und Ruh,", "tokens": ["Weist", "du", "noch", "was", "von", "Fried", "und", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PWS", "APPR", "NN", "KON", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "So mach es dir bey Zeiten n\u00fcze;", "tokens": ["So", "mach", "es", "dir", "bey", "Zei\u00b7ten", "n\u00fc\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Gl\u00fccke f\u00e4hrt oft blindlings zu", "tokens": ["Das", "Gl\u00fc\u00b7cke", "f\u00e4hrt", "oft", "blind\u00b7lings", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und raubt uns mit geschwindem Blize.", "tokens": ["Und", "raubt", "uns", "mit", "ge\u00b7schwin\u00b7dem", "Bli\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es geh auch, kan's nicht anders seyn,", "tokens": ["Es", "geh", "auch", ",", "kan's", "nicht", "an\u00b7ders", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VMFIN", "PTKNEG", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mein Seegen und Ged\u00e4chtn\u00fc\u00df ein,", "tokens": ["Mein", "See\u00b7gen", "und", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich w\u00fcntsche ganz und gar zu sterben.", "tokens": ["Ich", "w\u00fcnt\u00b7sche", "ganz", "und", "gar", "zu", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Folgt dir nur, was mir hier gebrach,", "tokens": ["Folgt", "dir", "nur", ",", "was", "mir", "hier", "ge\u00b7brach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Von nun an zweyfach gl\u00fccklich nach,", "tokens": ["Von", "nun", "an", "zwey\u00b7fach", "gl\u00fcck\u00b7lich", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So tr\u00f6stet noch mein Freund mein g\u00e4nzliches Verderben.", "tokens": ["So", "tr\u00f6s\u00b7tet", "noch", "mein", "Freund", "mein", "g\u00e4nz\u00b7li\u00b7ches", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}