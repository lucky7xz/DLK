{"textgrid.poem.37843": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Betteley der V\u00f6gel", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist kommen, es ist kommen", "tokens": ["Es", "ist", "kom\u00b7men", ",", "es", "ist", "kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVINF", "$,", "PPER", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der gew\u00fcnschte Fr\u00fchlings-Both,", "tokens": ["Der", "ge\u00b7w\u00fcnschte", "Fr\u00fch\u00b7lings\u00b7Both", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So uns alles Leid benommen", "tokens": ["So", "uns", "al\u00b7les", "Leid", "be\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die kalte Winters-Noth,", "tokens": ["Und", "die", "kal\u00b7te", "Win\u00b7ter\u00b7sNoth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welcher gute Stunden bringet,", "tokens": ["Wel\u00b7cher", "gu\u00b7te", "Stun\u00b7den", "brin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und ein gutes Jahr bedinget.", "tokens": ["Und", "ein", "gu\u00b7tes", "Jahr", "be\u00b7din\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Kommen ist die liebe Schwalbe,", "tokens": ["Kom\u00b7men", "ist", "die", "lie\u00b7be", "Schwal\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das sch\u00f6ne V\u00f6gelein,", "tokens": ["Und", "das", "sch\u00f6\u00b7ne", "V\u00f6\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dessen Bauch ist wei\u00df und falbe,", "tokens": ["Des\u00b7sen", "Bauch", "ist", "wei\u00df", "und", "fal\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADJD", "KON", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dessen R\u00fccken schwarz und fein;", "tokens": ["Des\u00b7sen", "R\u00fc\u00b7cken", "schwarz", "und", "fein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schauet wie es rummer flieget,", "tokens": ["Schau\u00b7et", "wie", "es", "rum\u00b7mer", "flie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und sich bittend zu euch f\u00fcget.", "tokens": ["Und", "sich", "bit\u00b7tend", "zu", "euch", "f\u00fc\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wollet ihr nicht seyn gebeten,", "tokens": ["Wol\u00b7let", "ihr", "nicht", "seyn", "ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VAINF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und mit etwas Esselwaar", "tokens": ["Und", "mit", "et\u00b7was", "Es\u00b7sel\u00b7waar"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Kommen hie heraus getreten,", "tokens": ["Kom\u00b7men", "hie", "he\u00b7raus", "ge\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APZR", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu uns oder dieser Schaar?", "tokens": ["Zu", "uns", "o\u00b7der", "die\u00b7ser", "Schaar", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gebt ihr aus des Reichen Haus,", "tokens": ["Gebt", "ihr", "aus", "des", "Rei\u00b7chen", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht ein wenig Wein heraus?", "tokens": ["Nicht", "ein", "we\u00b7nig", "Wein", "he\u00b7raus", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Oder einen Korb mit K\u00e4sen,", "tokens": ["O\u00b7der", "ei\u00b7nen", "Korb", "mit", "K\u00e4\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder auch ein wenig Korn;", "tokens": ["O\u00b7der", "auch", "ein", "we\u00b7nig", "Korn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir wiederum genesen,", "tokens": ["Da\u00df", "wir", "wie\u00b7de\u00b7rum", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und uns quicken mit dem Born?", "tokens": ["Und", "uns", "qui\u00b7cken", "mit", "dem", "Born", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil die Schwalbe ohne Speisen", "tokens": ["Weil", "die", "Schwal\u00b7be", "oh\u00b7ne", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich nicht l\u00e4sset abeweisen.", "tokens": ["Sich", "nicht", "l\u00e4s\u00b7set", "a\u00b7be\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Oder sollen wir viel lieber", "tokens": ["O\u00b7der", "sol\u00b7len", "wir", "viel", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euch die Th\u00fcr und Pforte l\u00e4hmen?", "tokens": ["Euch", "die", "Th\u00fcr", "und", "Pfor\u00b7te", "l\u00e4h\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder sollen wir hin\u00fcber", "tokens": ["O\u00b7der", "sol\u00b7len", "wir", "hin\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Steigen, und die Jungfer nehmen?", "tokens": ["Stei\u00b7gen", ",", "und", "die", "Jung\u00b7fer", "neh\u00b7men", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche, weil sie klein zu nennen,", "tokens": ["Wel\u00b7che", ",", "weil", "sie", "klein", "zu", "nen\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "$,", "KOUS", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir gar wohl wegtragen k\u00f6nnen.", "tokens": ["Wir", "gar", "wohl", "weg\u00b7tra\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Oder wollt ihr euch besinnen,", "tokens": ["O\u00b7der", "wollt", "ihr", "euch", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dennoch uns noch was verehrn;", "tokens": ["Den\u00b7noch", "uns", "noch", "was", "ver\u00b7ehrn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So kann sie uns wohl entrinnen,", "tokens": ["So", "kann", "sie", "uns", "wohl", "ent\u00b7rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und sich, wenn sie gr\u00f6\u00dfer, wehren;", "tokens": ["Und", "sich", ",", "wenn", "sie", "gr\u00f6\u00b7\u00dfer", ",", "weh\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PRF", "$,", "KOUS", "PPER", "ADJD", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00dft der Schwalb die Th\u00fcr aufhalten,", "tokens": ["La\u00dft", "der", "Schwalb", "die", "Th\u00fcr", "auf\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir sind Junge und nicht Alte.", "tokens": ["Wir", "sind", "Jun\u00b7ge", "und", "nicht", "Al\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "PTKNEG", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Es ist kommen, es ist kommen", "tokens": ["Es", "ist", "kom\u00b7men", ",", "es", "ist", "kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVINF", "$,", "PPER", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der gew\u00fcnschte Fr\u00fchlings-Both,", "tokens": ["Der", "ge\u00b7w\u00fcnschte", "Fr\u00fch\u00b7lings\u00b7Both", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So uns alles Leid benommen", "tokens": ["So", "uns", "al\u00b7les", "Leid", "be\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die kalte Winters-Noth,", "tokens": ["Und", "die", "kal\u00b7te", "Win\u00b7ter\u00b7sNoth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welcher gute Stunden bringet,", "tokens": ["Wel\u00b7cher", "gu\u00b7te", "Stun\u00b7den", "brin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und ein gutes Jahr bedinget.", "tokens": ["Und", "ein", "gu\u00b7tes", "Jahr", "be\u00b7din\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Kommen ist die liebe Schwalbe,", "tokens": ["Kom\u00b7men", "ist", "die", "lie\u00b7be", "Schwal\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das sch\u00f6ne V\u00f6gelein,", "tokens": ["Und", "das", "sch\u00f6\u00b7ne", "V\u00f6\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dessen Bauch ist wei\u00df und falbe,", "tokens": ["Des\u00b7sen", "Bauch", "ist", "wei\u00df", "und", "fal\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADJD", "KON", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dessen R\u00fccken schwarz und fein;", "tokens": ["Des\u00b7sen", "R\u00fc\u00b7cken", "schwarz", "und", "fein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schauet wie es rummer flieget,", "tokens": ["Schau\u00b7et", "wie", "es", "rum\u00b7mer", "flie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und sich bittend zu euch f\u00fcget.", "tokens": ["Und", "sich", "bit\u00b7tend", "zu", "euch", "f\u00fc\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wollet ihr nicht seyn gebeten,", "tokens": ["Wol\u00b7let", "ihr", "nicht", "seyn", "ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VAINF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und mit etwas Esselwaar", "tokens": ["Und", "mit", "et\u00b7was", "Es\u00b7sel\u00b7waar"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Kommen hie heraus getreten,", "tokens": ["Kom\u00b7men", "hie", "he\u00b7raus", "ge\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APZR", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu uns oder dieser Schaar?", "tokens": ["Zu", "uns", "o\u00b7der", "die\u00b7ser", "Schaar", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gebt ihr aus des Reichen Haus,", "tokens": ["Gebt", "ihr", "aus", "des", "Rei\u00b7chen", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht ein wenig Wein heraus?", "tokens": ["Nicht", "ein", "we\u00b7nig", "Wein", "he\u00b7raus", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Oder einen Korb mit K\u00e4sen,", "tokens": ["O\u00b7der", "ei\u00b7nen", "Korb", "mit", "K\u00e4\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder auch ein wenig Korn;", "tokens": ["O\u00b7der", "auch", "ein", "we\u00b7nig", "Korn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir wiederum genesen,", "tokens": ["Da\u00df", "wir", "wie\u00b7de\u00b7rum", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und uns quicken mit dem Born?", "tokens": ["Und", "uns", "qui\u00b7cken", "mit", "dem", "Born", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil die Schwalbe ohne Speisen", "tokens": ["Weil", "die", "Schwal\u00b7be", "oh\u00b7ne", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich nicht l\u00e4sset abeweisen.", "tokens": ["Sich", "nicht", "l\u00e4s\u00b7set", "a\u00b7be\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Oder sollen wir viel lieber", "tokens": ["O\u00b7der", "sol\u00b7len", "wir", "viel", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euch die Th\u00fcr und Pforte l\u00e4hmen?", "tokens": ["Euch", "die", "Th\u00fcr", "und", "Pfor\u00b7te", "l\u00e4h\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder sollen wir hin\u00fcber", "tokens": ["O\u00b7der", "sol\u00b7len", "wir", "hin\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Steigen, und die Jungfer nehmen?", "tokens": ["Stei\u00b7gen", ",", "und", "die", "Jung\u00b7fer", "neh\u00b7men", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche, weil sie klein zu nennen,", "tokens": ["Wel\u00b7che", ",", "weil", "sie", "klein", "zu", "nen\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "$,", "KOUS", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir gar wohl wegtragen k\u00f6nnen.", "tokens": ["Wir", "gar", "wohl", "weg\u00b7tra\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Oder wollt ihr euch besinnen,", "tokens": ["O\u00b7der", "wollt", "ihr", "euch", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dennoch uns noch was verehrn;", "tokens": ["Den\u00b7noch", "uns", "noch", "was", "ver\u00b7ehrn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So kann sie uns wohl entrinnen,", "tokens": ["So", "kann", "sie", "uns", "wohl", "ent\u00b7rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und sich, wenn sie gr\u00f6\u00dfer, wehren;", "tokens": ["Und", "sich", ",", "wenn", "sie", "gr\u00f6\u00b7\u00dfer", ",", "weh\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PRF", "$,", "KOUS", "PPER", "ADJD", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00dft der Schwalb die Th\u00fcr aufhalten,", "tokens": ["La\u00dft", "der", "Schwalb", "die", "Th\u00fcr", "auf\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wir sind Junge und nicht Alte.", "tokens": ["Wir", "sind", "Jun\u00b7ge", "und", "nicht", "Al\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "PTKNEG", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}