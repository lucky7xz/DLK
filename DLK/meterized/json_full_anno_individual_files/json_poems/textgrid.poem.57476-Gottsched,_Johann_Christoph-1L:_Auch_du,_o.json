{"textgrid.poem.57476": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auch du, o ", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auch du, o ", "tokens": ["Auch", "du", ",", "o"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "PPER", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "La\u00dft von der Sterne blauen Bahn,", "tokens": ["La\u00dft", "von", "der", "Ster\u00b7ne", "blau\u00b7en", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohin der Dank euch hob, mir eure Gunst erscheinen.", "tokens": ["Wo\u00b7hin", "der", "Dank", "euch", "hob", ",", "mir", "eu\u00b7re", "Gunst", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "$,", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Belebt den bl\u00f6den Dichter hier,", "tokens": ["Be\u00b7lebt", "den", "bl\u00f6\u00b7den", "Dich\u00b7ter", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verleiht ihm Kraft, der Deutschen Zier,", "tokens": ["Ver\u00b7leiht", "ihm", "Kraft", ",", "der", "Deut\u00b7schen", "Zier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Ruhm der alten Zeit der neuen vorzusingen;", "tokens": ["Den", "Ruhm", "der", "al\u00b7ten", "Zeit", "der", "neu\u00b7en", "vor\u00b7zu\u00b7sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was ihr gepflanzt, gen\u00e4hrt, besch\u00fctzt,", "tokens": ["Was", "ihr", "ge\u00b7pflanzt", ",", "ge\u00b7n\u00e4hrt", ",", "be\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das deutsche Reich vergi\u00dft sich itzt,", "tokens": ["Das", "deut\u00b7sche", "Reich", "ver\u00b7gi\u00dft", "sich", "itzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verzagt an seiner Kraft, sich mehr empor zu schwingen.", "tokens": ["Ver\u00b7zagt", "an", "sei\u00b7ner", "Kraft", ",", "sich", "mehr", "em\u00b7por", "zu", "schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,", "PRF", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Man kennt den Muth, womit ihr bald,", "tokens": ["Man", "kennt", "den", "Muth", ",", "wo\u00b7mit", "ihr", "bald", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch die noch w\u00fcste Welt gedrungen,", "tokens": ["Durch", "die", "noch", "w\u00fcs\u00b7te", "Welt", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Euch Land gesucht, und Thier und Wald,", "tokens": ["Euch", "Land", "ge\u00b7sucht", ",", "und", "Thier", "und", "Wald", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVPP", "$,", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Fels und Strom gez\u00e4hmt, ja die Natur bezwungen.", "tokens": ["Und", "Fels", "und", "Strom", "ge\u00b7z\u00e4hmt", ",", "ja", "die", "Na\u00b7tur", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVPP", "$,", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man ehrt die Faust, die Rom geschw\u00e4cht:", "tokens": ["Man", "ehrt", "die", "Faust", ",", "die", "Rom", "ge\u00b7schw\u00e4cht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PRELS", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur euch war jenes Joch zu schlecht,", "tokens": ["Nur", "euch", "war", "je\u00b7nes", "Joch", "zu", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PDAT", "NN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das alle V\u00f6lker schon mit feiger Ehrfurcht k\u00fc\u00dften.", "tokens": ["Das", "al\u00b7le", "V\u00f6l\u00b7ker", "schon", "mit", "fei\u00b7ger", "Ehr\u00b7furcht", "k\u00fc\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Man weis, wie ", "tokens": ["Man", "weis", ",", "wie"], "token_info": ["word", "word", "punct", "word"], "pos": ["PIS", "PTKVZ", "$,", "PWAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Die Herrschbegier der stolzen Brust,", "tokens": ["Die", "Herrschbe\u00b7gier", "der", "stol\u00b7zen", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Bey der vereinten Macht der deutschen Sieger, b\u00fc\u00dften.", "tokens": ["Bey", "der", "ver\u00b7ein\u00b7ten", "Macht", "der", "deut\u00b7schen", "Sie\u00b7ger", ",", "b\u00fc\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Jedoch, was soll der gro\u00dfe Muth?", "tokens": ["Je\u00b7doch", ",", "was", "soll", "der", "gro\u00b7\u00dfe", "Muth", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VMFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedarf denn auch der ", "tokens": ["Be\u00b7darf", "denn", "auch", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Kann hier kein minder hei\u00dfes Blut", "tokens": ["Kann", "hier", "kein", "min\u00b7der", "hei\u00b7\u00dfes", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PIAT", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Musen Trieb und Lust zu hohen Liedern schaffen?", "tokens": ["Den", "Mu\u00b7sen", "Trieb", "und", "Lust", "zu", "ho\u00b7hen", "Lie\u00b7dern", "schaf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So scheints: allein, ein k\u00fchner Flug,", "tokens": ["So", "scheints", ":", "al\u00b7lein", ",", "ein", "k\u00fch\u00b7ner", "Flug", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum Ruhm der Deutschen, braucht den Zug,", "tokens": ["Zum", "Ruhm", "der", "Deut\u00b7schen", ",", "braucht", "den", "Zug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den du, o Heldenchor, zu Deiner Zeit empfunden.", "tokens": ["Den", "du", ",", "o", "Hel\u00b7den\u00b7chor", ",", "zu", "Dei\u00b7ner", "Zeit", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "FM", "NN", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Deutsche ringt nach eigner Schmach:", "tokens": ["Der", "Deut\u00b7sche", "ringt", "nach", "eig\u00b7ner", "Schmach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Drum k\u00e4mpft ein Dichter Helden nach,", "tokens": ["Drum", "k\u00e4mpft", "ein", "Dich\u00b7ter", "Hel\u00b7den", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der sich ein Lob erk\u00fchnt, das aus der Welt verschwunden.", "tokens": ["Der", "sich", "ein", "Lob", "er\u00b7k\u00fchnt", ",", "das", "aus", "der", "Welt", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$,", "PRELS", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Itzt, schlaue Nachbarn, h\u00f6rt mich nicht!", "tokens": ["Itzt", ",", "schlau\u00b7e", "Nach\u00b7barn", ",", "h\u00f6rt", "mich", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die\u00df Lied soll bis zu euch nicht dringen;", "tokens": ["Die\u00df", "Lied", "soll", "bis", "zu", "euch", "nicht", "drin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VMFIN", "ADV", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mein h\u00f6chst gerechtes Klaggedicht", "tokens": ["Mein", "h\u00f6chst", "ge\u00b7rech\u00b7tes", "Klag\u00b7ge\u00b7dicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Soll euch nicht neuen Stoff zu Spott und Tadel bringen.", "tokens": ["Soll", "euch", "nicht", "neu\u00b7en", "Stoff", "zu", "Spott", "und", "Ta\u00b7del", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ihr Alpen, werft den Schall zur\u00fcck,", "tokens": ["Ihr", "Al\u00b7pen", ",", "werft", "den", "Schall", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Damit kein W\u00e4lscher einen Blick", "tokens": ["Da\u00b7mit", "kein", "W\u00e4l\u00b7scher", "ei\u00b7nen", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Auf unsers Volkes Schimpf und schn\u00f6de Kleinmuth werfe;", "tokens": ["Auf", "un\u00b7sers", "Vol\u00b7kes", "Schimpf", "und", "schn\u00f6\u00b7de", "Klein\u00b7muth", "wer\u00b7fe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und du, uns noch getreuer Rhein,", "tokens": ["Und", "du", ",", "uns", "noch", "ge\u00b7treu\u00b7er", "Rhein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "ADV", "ADJD", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "La\u00df deine Wirbel rauschend seyn,", "tokens": ["La\u00df", "dei\u00b7ne", "Wir\u00b7bel", "rau\u00b7schend", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Da\u00df Gallien kein Ohr auf unsre Schande sch\u00e4rfe.", "tokens": ["Da\u00df", "Gal\u00b7li\u00b7en", "kein", "Ohr", "auf", "uns\u00b7re", "Schan\u00b7de", "sch\u00e4r\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die weite See beraubt das Land,", "tokens": ["Die", "wei\u00b7te", "See", "be\u00b7raubt", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An allen K\u00fcsten und Gestaden,", "tokens": ["An", "al\u00b7len", "K\u00fcs\u00b7ten", "und", "Ge\u00b7sta\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Reichthum bleibt ihr unbekannt,", "tokens": ["Ihr", "Reicht\u00b7hum", "bleibt", "ihr", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie sucht sich nur mit Koth und Steinen zu beladen.", "tokens": ["Sie", "sucht", "sich", "nur", "mit", "Koth", "und", "Stei\u00b7nen", "zu", "be\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was achtet sie der Perlen Gut,", "tokens": ["Was", "ach\u00b7tet", "sie", "der", "Per\u00b7len", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der theuren Schnecken Purpurblut,", "tokens": ["Der", "theu\u00b7ren", "Schne\u00b7cken", "Pur\u00b7pur\u00b7blut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Muscheln Wunderreich, und Stauden von Corallen?", "tokens": ["Der", "Mu\u00b7scheln", "Wun\u00b7der\u00b7reich", ",", "und", "Stau\u00b7den", "von", "Co\u00b7ral\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die\u00df alles speyt sie an den Strand,", "tokens": ["Die\u00df", "al\u00b7les", "speyt", "sie", "an", "den", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und geizt um den unfruchtbarn Sand,", "tokens": ["Und", "geizt", "um", "den", "un\u00b7frucht\u00b7barn", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Vergn\u00fcgt, wenn Berg und Fels in ihre Tiefen fallen.", "tokens": ["Ver\u00b7gn\u00fcgt", ",", "wenn", "Berg", "und", "Fels", "in", "ih\u00b7re", "Tie\u00b7fen", "fal\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "So, Deutschland! irrt dein Vorwitz sich,", "tokens": ["So", ",", "Deutschland", "!", "irrt", "dein", "Vor\u00b7witz", "sich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$.", "VVFIN", "PPOSAT", "NN", "PRF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ganz blind bey eignen Trefflichkeiten:", "tokens": ["Ganz", "blind", "bey", "eig\u00b7nen", "Treff\u00b7lich\u00b7kei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein toller D\u00fcnkel reizet dich,", "tokens": ["Ein", "tol\u00b7ler", "D\u00fcn\u00b7kel", "rei\u00b7zet", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach fremder V\u00f6lker Tracht, und Witz und Kunst zu streiten.", "tokens": ["Nach", "frem\u00b7der", "V\u00f6l\u00b7ker", "Tracht", ",", "und", "Witz", "und", "Kunst", "zu", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "KON", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die G\u00fcter, so der Allmacht Hand", "tokens": ["Die", "G\u00fc\u00b7ter", ",", "so", "der", "All\u00b7macht", "Hand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir \u00fcberfl\u00fc\u00dfig zugewandt,", "tokens": ["Dir", "\u00fc\u00b7berf\u00b7l\u00fc\u00b7\u00dfig", "zu\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In deiner Berge Mark, in Land und Strom geleget;", "tokens": ["In", "dei\u00b7ner", "Ber\u00b7ge", "Mark", ",", "in", "Land", "und", "Strom", "ge\u00b7le\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was Luft und Teich und Garten beut,", "tokens": ["Was", "Luft", "und", "Teich", "und", "Gar\u00b7ten", "beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das ekelt deiner L\u00fcsternheit,", "tokens": ["Das", "e\u00b7kelt", "dei\u00b7ner", "L\u00fcs\u00b7tern\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die nur ein fernes Land mit fremdem Pracht erreget.", "tokens": ["Die", "nur", "ein", "fer\u00b7nes", "Land", "mit", "frem\u00b7dem", "Pracht", "er\u00b7re\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So weit die Schranken der Natur", "tokens": ["So", "weit", "die", "Schran\u00b7ken", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Sich \u00fcber Erd und Meer erstrecken,", "tokens": ["Sich", "\u00fc\u00b7ber", "Erd", "und", "Meer", "er\u00b7stre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Erblickt man nie die mindste Spur,", "tokens": ["Er\u00b7blickt", "man", "nie", "die", "minds\u00b7te", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Von Thieren, die den Rumpf mit fremden H\u00e4uten decken.", "tokens": ["Von", "Thie\u00b7ren", ",", "die", "den", "Rumpf", "mit", "frem\u00b7den", "H\u00e4u\u00b7ten", "de\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kein Schuppenheer legt Federn an,", "tokens": ["Kein", "Schup\u00b7pen\u00b7heer", "legt", "Fe\u00b7dern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Kein Volk in W\u00e4ldern hegt den Wahn,", "tokens": ["Kein", "Volk", "in", "W\u00e4l\u00b7dern", "hegt", "den", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Den reichbehaarten Balg mit Schuppen zu vertauschen.", "tokens": ["Den", "reich\u00b7be\u00b7haar\u00b7ten", "Balg", "mit", "Schup\u00b7pen", "zu", "ver\u00b7tau\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Kein L\u00f6we w\u00fcnscht ein Tygerkleid,", "tokens": ["Kein", "L\u00f6\u00b7we", "w\u00fcnscht", "ein", "Ty\u00b7ger\u00b7kleid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Kein Straus begeht die Eitelkeit,", "tokens": ["Kein", "Straus", "be\u00b7geht", "die", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Dem bunten Pfauenschweif den Zierath abzulauschen.", "tokens": ["Dem", "bun\u00b7ten", "Pfau\u00b7en\u00b7schweif", "den", "Zie\u00b7rath", "ab\u00b7zu\u00b7lau\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Verf\u00fchrtes Deutschland! du allein", "tokens": ["Ver\u00b7f\u00fchr\u00b7tes", "Deutschland", "!", "du", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPER", "ADV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ver\u00e4nderst t\u00e4glich die Gestalten;", "tokens": ["Ver\u00b7\u00e4n\u00b7derst", "t\u00e4g\u00b7lich", "die", "Ge\u00b7stal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die deutsche Tracht schien dir zu klein,", "tokens": ["Die", "deut\u00b7sche", "Tracht", "schien", "dir", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Tagus \u00e4ffst du nach, mit M\u00e4nteln voller Falten.", "tokens": ["Dem", "Ta\u00b7gus", "\u00e4ffst", "du", "nach", ",", "mit", "M\u00e4n\u00b7teln", "vol\u00b7ler", "Fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du schnittest Wamms und Hosen auf,", "tokens": ["Du", "schnit\u00b7test", "Wamms", "und", "Ho\u00b7sen", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als h\u00e4tte ", "tokens": ["Als", "h\u00e4t\u00b7te"], "token_info": ["word", "word"], "pos": ["KOUS", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Dein k\u00fchles Land so stark, als Granada, entz\u00fcndet.", "tokens": ["Dein", "k\u00fch\u00b7les", "Land", "so", "stark", ",", "als", "Gra\u00b7na\u00b7da", ",", "ent\u00b7z\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADJD", "$,", "KOUS", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald schien dir Frankreichs Thorheit sch\u00f6n,", "tokens": ["Bald", "schien", "dir", "Fran\u00b7kreichs", "Thor\u00b7heit", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wo niemand noch den Tag gesehn,", "tokens": ["Wo", "nie\u00b7mand", "noch", "den", "Tag", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da nicht der Schneiderwitz ein neu Gesch\u00f6pf erfindet.", "tokens": ["Da", "nicht", "der", "Schnei\u00b7der\u00b7witz", "ein", "neu", "Ge\u00b7sch\u00f6pf", "er\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "So th\u00f6richt sind doch nicht Madrit,", "tokens": ["So", "th\u00f6\u00b7richt", "sind", "doch", "nicht", "Mad\u00b7rit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Stambols Reich, nicht die Sarmaten;", "tokens": ["Nicht", "Stam\u00b7bols", "Reich", ",", "nicht", "die", "Sar\u00b7ma\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "NN", "$,", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Venedig macht kein Spielwerk mit,", "tokens": ["Ve\u00b7ne\u00b7dig", "macht", "kein", "Spiel\u00b7werk", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "So bunt es in Paris der Stutzerzunft gerathen.", "tokens": ["So", "bunt", "es", "in", "Pa\u00b7ris", "der", "Stut\u00b7zer\u00b7zunft", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "NE", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur du sch\u00e4mst dich der deutschen Tracht,", "tokens": ["Nur", "du", "sch\u00e4mst", "dich", "der", "deut\u00b7schen", "Tracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hast dir eine Kunst erdacht,", "tokens": ["Und", "hast", "dir", "ei\u00b7ne", "Kunst", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Auch deutsche Nahrung schmeckt dir nicht;", "tokens": ["Auch", "deut\u00b7sche", "Nah\u00b7rung", "schmeckt", "dir", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du mu\u00dft manch ekelhaft Ger\u00fccht", "tokens": ["Du", "mu\u00dft", "manch", "e\u00b7kel\u00b7haft", "Ge\u00b7r\u00fccht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit l\u00fcsternem Geschmack nach fremdem Gaum erhandeln.", "tokens": ["Mit", "l\u00fcs\u00b7ter\u00b7nem", "Ge\u00b7schmack", "nach", "frem\u00b7dem", "Gaum", "er\u00b7han\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wo pflegt die laute Nachtigall", "tokens": ["Wo", "pflegt", "die", "lau\u00b7te", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Des Guckucks Sylben nachzu\u00e4ffen?", "tokens": ["Des", "Gu\u00b7ckucks", "Syl\u00b7ben", "nach\u00b7zu\u00b7\u00e4f\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wo sucht durch ihrer Kehle Schall", "tokens": ["Wo", "sucht", "durch", "ih\u00b7rer", "Keh\u00b7le", "Schall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die Lerche das Geplerr des Wachtelvolks zu treffen?", "tokens": ["Die", "Ler\u00b7che", "das", "Ge\u00b7plerr", "des", "Wach\u00b7tel\u00b7volks", "zu", "tref\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Schwalbe singt, die Taube girrt:", "tokens": ["Die", "Schwal\u00b7be", "singt", ",", "die", "Tau\u00b7be", "girrt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und beyder Ton wird nie verwirrt,", "tokens": ["Und", "bey\u00b7der", "Ton", "wird", "nie", "ver\u00b7wirrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Wenn gleich der Fr\u00f6sche Heer in lauen S\u00fcmpfen kr\u00f6chzet.", "tokens": ["Wenn", "gleich", "der", "Fr\u00f6\u00b7sche", "Heer", "in", "lau\u00b7en", "S\u00fcmp\u00b7fen", "kr\u00f6ch\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Das deutsche Volk vergeht sich nur;", "tokens": ["Das", "deut\u00b7sche", "Volk", "ver\u00b7geht", "sich", "nur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Indem es wider die Natur", "tokens": ["In\u00b7dem", "es", "wi\u00b7der", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Die eigne Mundart ha\u00dft, nach fremden Sprachen lechzet.", "tokens": ["Die", "eig\u00b7ne", "Mund\u00b7art", "ha\u00dft", ",", "nach", "frem\u00b7den", "Spra\u00b7chen", "lech\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Kein Wunder, da\u00df die Zunge stockt,", "tokens": ["Kein", "Wun\u00b7der", ",", "da\u00df", "die", "Zun\u00b7ge", "stockt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie kann sie deutsch und redlich sprechen:", "tokens": ["Wie", "kann", "sie", "deutsch", "und", "red\u00b7lich", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seit Frankreichs List das Ohr gelockt,", "tokens": ["Seit", "Fran\u00b7kreichs", "List", "das", "Ohr", "ge\u00b7lockt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und alle Welt gelehrt, so Sylb als Eide brechen?", "tokens": ["Und", "al\u00b7le", "Welt", "ge\u00b7lehrt", ",", "so", "Sylb", "als", "Ei\u00b7de", "bre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$,", "ADV", "NE", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Sprache von vermischter Art,", "tokens": ["Der", "Spra\u00b7che", "von", "ver\u00b7mischter", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die damals erst gebohren ward,", "tokens": ["Die", "da\u00b7mals", "erst", "ge\u00b7boh\u00b7ren", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als Deutschland Gallien und Rom gehorchen lehrte;", "tokens": ["Als", "Deutschland", "Gal\u00b7li\u00b7en", "und", "Rom", "ge\u00b7hor\u00b7chen", "lehr\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "KON", "NE", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Dem Bastart alter Barbarey", "tokens": ["Dem", "Bas\u00b7tart", "al\u00b7ter", "Bar\u00b7ba\u00b7rey"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Legt man der Sch\u00f6nheit Gipfel bey,", "tokens": ["Legt", "man", "der", "Sch\u00f6n\u00b7heit", "Gip\u00b7fel", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die unsrer Mundart doch mit besserm Recht geh\u00f6rte.", "tokens": ["Die", "uns\u00b7rer", "Mund\u00b7art", "doch", "mit", "bes\u00b7serm", "Recht", "ge\u00b7h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "So reizend hat kein Honigseim", "tokens": ["So", "rei\u00b7zend", "hat", "kein", "Ho\u00b7ni\u00b7gseim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verzognen Kindern noch geschmecket,", "tokens": ["Ver\u00b7zog\u00b7nen", "Kin\u00b7dern", "noch", "ge\u00b7schme\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als uns ein halbverstandner Reim,", "tokens": ["Als", "uns", "ein", "halb\u00b7ver\u00b7stand\u00b7ner", "Reim", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo aller Witz und Geist in fremden Sylben stecket.", "tokens": ["Wo", "al\u00b7ler", "Witz", "und", "Geist", "in", "frem\u00b7den", "Syl\u00b7ben", "ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Toscaniens beruffner Dunst,", "tokens": ["Tos\u00b7ca\u00b7ni\u00b7ens", "be\u00b7ruff\u00b7ner", "Dunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der w\u00e4lschen T\u00f6ne Zauberkunst,", "tokens": ["Der", "w\u00e4l\u00b7schen", "T\u00f6\u00b7ne", "Zau\u00b7ber\u00b7kunst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die ein geschwollnes Nichts in langen Trillern zerret;", "tokens": ["Die", "ein", "ge\u00b7schwoll\u00b7nes", "Nichts", "in", "lan\u00b7gen", "Tril\u00b7lern", "zer\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Der niedern B\u00fchne freche Zunft,", "tokens": ["Der", "nie\u00b7dern", "B\u00fch\u00b7ne", "fre\u00b7che", "Zunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der tollsten Gaukler Unvernunft", "tokens": ["Der", "tolls\u00b7ten", "Gauk\u00b7ler", "Un\u00b7ver\u00b7nunft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Hat aller Alten Kunst den Eingang l\u00e4ngst versperret.", "tokens": ["Hat", "al\u00b7ler", "Al\u00b7ten", "Kunst", "den", "Ein\u00b7gang", "l\u00e4ngst", "ver\u00b7sper\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Als noch der ", "tokens": ["Als", "noch", "der"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Die alten Teutonen vergn\u00fcgte,", "tokens": ["Die", "al\u00b7ten", "Teu\u00b7to\u00b7nen", "ver\u00b7gn\u00fcg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Hat kein Gesang ihr Ohr bem\u00fcht,", "tokens": ["Hat", "kein", "Ge\u00b7sang", "ihr", "Ohr", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der nicht gesundern Witz zum Ruhm der Tugend f\u00fcgte.", "tokens": ["Der", "nicht", "ge\u00b7sun\u00b7dern", "Witz", "zum", "Ruhm", "der", "Tu\u00b7gend", "f\u00fcg\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJA", "NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und h\u00e4tt uns noch kein ", "tokens": ["Und", "h\u00e4tt", "uns", "noch", "kein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PIAT"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "An Geist, Geschmack und Einsicht reich,", "tokens": ["An", "Geist", ",", "Ge\u00b7schmack", "und", "Ein\u00b7sicht", "reich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zum wahren ", "tokens": ["Zum", "wah\u00b7ren"], "token_info": ["word", "word"], "pos": ["APPRART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "So h\u00e4tten wir, mit besserm Recht,", "tokens": ["So", "h\u00e4t\u00b7ten", "wir", ",", "mit", "bes\u00b7serm", "Recht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein itzt ver\u00e4chtliches Geschlecht,", "tokens": ["Ein", "itzt", "ver\u00b7\u00e4cht\u00b7li\u00b7ches", "Ge\u00b7schlecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Von S\u00e4ngern alter Zucht, nach N\u00fcrnbergs Art, gepriesen.", "tokens": ["Von", "S\u00e4n\u00b7gern", "al\u00b7ter", "Zucht", ",", "nach", "N\u00fcrn\u00b7bergs", "Art", ",", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$,", "APPR", "NE", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Auch ihr, ihr Gr\u00fcbler! geht zu weit,", "tokens": ["Auch", "ihr", ",", "ihr", "Gr\u00fcb\u00b7ler", "!", "geht", "zu", "weit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die nur Athen und Rom geblendet,", "tokens": ["Die", "nur", "A\u00b7then", "und", "Rom", "ge\u00b7blen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NE", "KON", "NE", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Da\u00df ihr die kurze Lebenszeit", "tokens": ["Da\u00df", "ihr", "die", "kur\u00b7ze", "Le\u00b7bens\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bey fremder W\u00f6rter Zier und dunkler Kunst verschwendet.", "tokens": ["Bey", "frem\u00b7der", "W\u00f6r\u00b7ter", "Zier", "und", "dunk\u00b7ler", "Kunst", "ver\u00b7schwen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja! forscht der Alten Regeln aus;", "tokens": ["Ja", "!", "forscht", "der", "Al\u00b7ten", "Re\u00b7geln", "aus", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur lehrt uns nicht in Staub und Graus", "tokens": ["Nur", "lehrt", "uns", "nicht", "in", "Staub", "und", "Graus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der freyen Geister Kraft, zu eigner Schmach, begraben.", "tokens": ["Der", "frey\u00b7en", "Geis\u00b7ter", "Kraft", ",", "zu", "eig\u00b7ner", "Schmach", ",", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "APPR", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Singt deutsch so edel, als Homer!", "tokens": ["Singt", "deutsch", "so", "e\u00b7del", ",", "als", "Ho\u00b7mer", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "ADJD", "$,", "KOUS", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.10": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}, "stanza.12": {"line.1": {"text": "Singt ", "tokens": ["Singt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Und blutbespritzte Lorberkronen.", "tokens": ["Und", "blut\u00b7be\u00b7spritz\u00b7te", "Lor\u00b7ber\u00b7kro\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was gilts! der hier erfochtne Sieg", "tokens": ["Was", "gilts", "!", "der", "hier", "er\u00b7focht\u00b7ne", "Sieg"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird euch die Arbeit mehr, als Trojens Schutt belohnen.", "tokens": ["Wird", "euch", "die", "Ar\u00b7beit", "mehr", ",", "als", "Tro\u00b7jens", "Schutt", "be\u00b7loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "$,", "KOUS", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "La\u00dft uns die Weisen aus Athen", "tokens": ["La\u00dft", "uns", "die", "Wei\u00b7sen", "aus", "A\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "APPR", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "In deutschverfa\u00dften Schriften sehn,", "tokens": ["In", "deutschver\u00b7fa\u00df\u00b7ten", "Schrif\u00b7ten", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und lehret unsre Zeit ein attisch Salz im Sprechen.", "tokens": ["Und", "leh\u00b7ret", "uns\u00b7re", "Zeit", "ein", "at\u00b7tisch", "Salz", "im", "Spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ART", "ADJD", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bringt uns der R\u00f6mer Gro\u00dfmuth bey;", "tokens": ["Bringt", "uns", "der", "R\u00f6\u00b7mer", "Gro\u00df\u00b7muth", "bey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So folgt ein ewig Lobgeschrey,", "tokens": ["So", "folgt", "ein", "e\u00b7wig", "Lob\u00b7ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und eures Namens Ruhm wird Gruft und Zeit nicht schw\u00e4chen.", "tokens": ["Und", "eu\u00b7res", "Na\u00b7mens", "Ruhm", "wird", "Gruft", "und", "Zeit", "nicht", "schw\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VAFIN", "NN", "KON", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Singt eurer Ahnen Flei\u00df und Witz", "tokens": ["Singt", "eu\u00b7rer", "Ah\u00b7nen", "Flei\u00df", "und", "Witz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daran kein Volk sie noch bezwungen;", "tokens": ["Da\u00b7ran", "kein", "Volk", "sie", "noch", "be\u00b7zwun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seit sie durch Pulver und Gesch\u00fctz", "tokens": ["Seit", "sie", "durch", "Pul\u00b7ver", "und", "Ge\u00b7sch\u00fctz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der donnernden Gewalt des Himmels nachgerungen.", "tokens": ["Der", "don\u00b7nern\u00b7den", "Ge\u00b7walt", "des", "Him\u00b7mels", "nach\u00b7ge\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Singt, wie der Minen Wunderkraft,", "tokens": ["Singt", ",", "wie", "der", "Mi\u00b7nen", "Wun\u00b7der\u00b7kraft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch des Salpeters Eigenschaft,", "tokens": ["Durch", "des", "Sal\u00b7pe\u00b7ters", "Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Dem Aetna und Vesuv an schneller Macht nicht weichet.", "tokens": ["Dem", "A\u00b7et\u00b7na", "und", "Ve\u00b7suv", "an", "schnel\u00b7ler", "Macht", "nicht", "wei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NN", "APPR", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Erz\u00e4hlt, was Deutschland sonst erfand,", "tokens": ["Er\u00b7z\u00e4hlt", ",", "was", "Deutschland", "sonst", "er\u00b7fand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Wenn es durch forschenden Verstand", "tokens": ["Wenn", "es", "durch", "for\u00b7schen\u00b7den", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Wunder der Natur vor fremdem Witz erreichet.", "tokens": ["Die", "Wun\u00b7der", "der", "Na\u00b7tur", "vor", "frem\u00b7dem", "Witz", "er\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Vor andern singt das Lob der Kunst,", "tokens": ["Vor", "an\u00b7dern", "singt", "das", "Lob", "der", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dadurch die Todten ewig leben;", "tokens": ["Da\u00b7durch", "die", "Tod\u00b7ten", "e\u00b7wig", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die des geneigten Himmels Gunst", "tokens": ["Die", "des", "ge\u00b7neig\u00b7ten", "Him\u00b7mels", "Gunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor allen V\u00f6lkern, nur der deutschen Welt gegeben.", "tokens": ["Vor", "al\u00b7len", "V\u00f6l\u00b7kern", ",", "nur", "der", "deut\u00b7schen", "Welt", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erhebt das k\u00fcnstliche Metall,", "tokens": ["Er\u00b7hebt", "das", "k\u00fcnst\u00b7li\u00b7che", "Me\u00b7tall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem ein mit Ru\u00df geschw\u00e4rzter Ball", "tokens": ["Dem", "ein", "mit", "Ru\u00df", "ge\u00b7schw\u00e4rz\u00b7ter", "Ball"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die edle Kraft verleiht, die Tugend auszubreiten.", "tokens": ["Die", "ed\u00b7le", "Kraft", "ver\u00b7leiht", ",", "die", "Tu\u00b7gend", "aus\u00b7zu\u00b7brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Erhebt die Presse, deren Druck", "tokens": ["Er\u00b7hebt", "die", "Pres\u00b7se", ",", "de\u00b7ren", "Druck"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verstand und Witz, mit neuem Schmuck", "tokens": ["Ver\u00b7stand", "und", "Witz", ",", "mit", "neu\u00b7em", "Schmuck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und reicher Fruchtbarkeit, kann in die Welt begleiten.", "tokens": ["Und", "rei\u00b7cher", "Frucht\u00b7bar\u00b7keit", ",", "kann", "in", "die", "Welt", "be\u00b7glei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "$,", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Verewigt jener K\u00fcnstler Preis,", "tokens": ["Ve\u00b7re\u00b7wigt", "je\u00b7ner", "K\u00fcnst\u00b7ler", "Preis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die M\u00fch und Zeit und Geld nicht reute:", "tokens": ["Die", "M\u00fch", "und", "Zeit", "und", "Geld", "nicht", "reu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "KON", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bis sie ein klugverwandter Flei\u00df", "tokens": ["Bis", "sie", "ein", "klug\u00b7ver\u00b7wand\u00b7ter", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Mit dieser Wunderkunst und vielem Ruhm erfreute.", "tokens": ["Mit", "die\u00b7ser", "Wun\u00b7der\u00b7kunst", "und", "vie\u00b7lem", "Ruhm", "er\u00b7freu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Das macht die K\u00fcnstler noch bey aller Welt zum Wunder.", "tokens": ["Das", "macht", "die", "K\u00fcnst\u00b7ler", "noch", "bey", "al\u00b7ler", "Welt", "zum", "Wun\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV", "APPR", "PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du edles Kleeblatt! w\u00fcrde nur,", "tokens": ["Du", "ed\u00b7les", "Klee\u00b7blatt", "!", "w\u00fcr\u00b7de", "nur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Auf der so loberf\u00fcllten Spur,", "tokens": ["Auf", "der", "so", "lo\u00b7berf\u00b7\u00fcll\u00b7ten", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dein gro\u00dfes Beyspiel noch der tr\u00e4gen Deutschen Zunder!", "tokens": ["Dein", "gro\u00b7\u00dfes", "Bey\u00b7spiel", "noch", "der", "tr\u00e4\u00b7gen", "Deut\u00b7schen", "Zun\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Wie Wei\u00df, der Orpheus unsrer Zeit,", "tokens": ["Wie", "Wei\u00df", ",", "der", "Or\u00b7pheus", "uns\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ART", "NE", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eh er die Zauberlaute r\u00fchret,", "tokens": ["Eh", "er", "die", "Zau\u00b7berl\u00b7au\u00b7te", "r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mit ungemeiner Achtsamkeit", "tokens": ["Mit", "un\u00b7ge\u00b7mei\u00b7ner", "Acht\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Seyten Kl\u00e4nge pr\u00fcft, und durch die T\u00f6ne f\u00fchret;", "tokens": ["Der", "Sey\u00b7ten", "Kl\u00e4n\u00b7ge", "pr\u00fcft", ",", "und", "durch", "die", "T\u00f6\u00b7ne", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er fa\u00dft die Wirbel, horcht und stimmt,", "tokens": ["Er", "fa\u00dft", "die", "Wir\u00b7bel", ",", "horcht", "und", "stimmt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bis er den Mishall nicht vernimmt,", "tokens": ["Bis", "er", "den", "Mis\u00b7hall", "nicht", "ver\u00b7nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der anfangs sein Geh\u00f6r durch falschen Laut verletzet;", "tokens": ["Der", "an\u00b7fangs", "sein", "Ge\u00b7h\u00f6r", "durch", "fal\u00b7schen", "Laut", "ver\u00b7let\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Rechte l\u00e4uft durch manchen Gang,", "tokens": ["Die", "Rech\u00b7te", "l\u00e4uft", "durch", "man\u00b7chen", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bis ihm ein fehlerfreyer Klang,", "tokens": ["Bis", "ihm", "ein", "feh\u00b7ler\u00b7fre\u00b7yer", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das zarte Meisterohr mit reinem Ton ergetzet.", "tokens": ["Das", "zar\u00b7te", "Meis\u00b7te\u00b7rohr", "mit", "rei\u00b7nem", "Ton", "er\u00b7get\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "So, d\u00fcnkt mich, seh ich euch, entbrannt,", "tokens": ["So", ",", "d\u00fcnkt", "mich", ",", "seh", "ich", "euch", ",", "ent\u00b7brannt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr ewig werthen K\u00fcnstler! sitzen,", "tokens": ["Ihr", "e\u00b7wig", "wert\u00b7hen", "K\u00fcnst\u00b7ler", "!", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "NN", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und durch den Stahl in kluger Hand", "tokens": ["Und", "durch", "den", "Stahl", "in", "klu\u00b7ger", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Seiten voller Schrift in glatte Tafeln schnitzen.", "tokens": ["Viel", "Sei\u00b7ten", "vol\u00b7ler", "Schrift", "in", "glat\u00b7te", "Ta\u00b7feln", "schnit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die M\u00fch ist gro\u00df, der Vortheil schwach:", "tokens": ["Die", "M\u00fch", "ist", "gro\u00df", ",", "der", "Vor\u00b7theil", "schwach", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum sinnt und denkt ihr eifrig nach,", "tokens": ["Drum", "sinnt", "und", "denkt", "ihr", "eif\u00b7rig", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr bessert, putzt, vergleicht und ziert die festen Zeilen.", "tokens": ["Ihr", "bes\u00b7sert", ",", "putzt", ",", "ver\u00b7gleicht", "und", "ziert", "die", "fes\u00b7ten", "Zei\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald trennt ihr Wort und Sylben ab;", "tokens": ["Bald", "trennt", "ihr", "Wort", "und", "Syl\u00b7ben", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zuletzt mu\u00df ein gevierter Stab", "tokens": ["Zu\u00b7letzt", "mu\u00df", "ein", "ge\u00b7vier\u00b7ter", "Stab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Aus starrendem Metall metallne Lettern feilen.", "tokens": ["Aus", "star\u00b7ren\u00b7dem", "Me\u00b7tall", "me\u00b7tall\u00b7ne", "Let\u00b7tern", "fei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Nun folgt ein St\u00e4mpel, dessen Schlag", "tokens": ["Nun", "folgt", "ein", "St\u00e4m\u00b7pel", ",", "des\u00b7sen", "Schlag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Kupfer seinen Abdruck leget;", "tokens": ["In", "Kup\u00b7fer", "sei\u00b7nen", "Ab\u00b7druck", "le\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So k\u00f6mmt die Mutter an den Tag,", "tokens": ["So", "k\u00f6mmt", "die", "Mut\u00b7ter", "an", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die ihr vertieftes Bley in tausend S\u00f6hne pr\u00e4get.", "tokens": ["Die", "ihr", "ver\u00b7tief\u00b7tes", "Bley", "in", "tau\u00b7send", "S\u00f6h\u00b7ne", "pr\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Zeug, aus Eisen, Bley und Zinn,", "tokens": ["Ein", "Zeug", ",", "aus", "Ei\u00b7sen", ",", "Bley", "und", "Zinn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "L\u00e4uft durch den schnellen Gu\u00df dahin,", "tokens": ["L\u00e4uft", "durch", "den", "schnel\u00b7len", "Gu\u00df", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo sich des Vaters Kraft in sch\u00f6nen Z\u00fcgen weiset.", "tokens": ["Wo", "sich", "des", "Va\u00b7ters", "Kraft", "in", "sch\u00f6\u00b7nen", "Z\u00fc\u00b7gen", "wei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So tritt der Lettern Heer ans Licht,", "tokens": ["So", "tritt", "der", "Let\u00b7tern", "Heer", "ans", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Durch deren Erzt man lauter spricht,", "tokens": ["Durch", "de\u00b7ren", "Erzt", "man", "lau\u00b7ter", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als uns das Alterthum von Stentors Stimme preiset.", "tokens": ["Als", "uns", "das", "Al\u00b7ter\u00b7thum", "von", "Sten\u00b7tors", "Stim\u00b7me", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Wie war dir, starrendes Paris,", "tokens": ["Wie", "war", "dir", ",", "star\u00b7ren\u00b7des", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du stolze Pflegerinn der K\u00fcnste,", "tokens": ["Du", "stol\u00b7ze", "Pfle\u00b7ge\u00b7rinn", "der", "K\u00fcns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "An Sch\u00f6nheit wunderbar, mit m\u00e4\u00dfigem Gewinnste?", "tokens": ["An", "Sch\u00f6n\u00b7heit", "wun\u00b7der\u00b7bar", ",", "mit", "m\u00e4\u00b7\u00dfi\u00b7gem", "Ge\u00b7winns\u00b7te", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Gleichheit machte dich verwirrt:", "tokens": ["Die", "Gleich\u00b7heit", "mach\u00b7te", "dich", "ver\u00b7wirrt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Punct ist falsch, kein Buchstab irrt;", "tokens": ["Kein", "Punct", "ist", "falsch", ",", "kein", "Buch\u00b7stab", "irrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$,", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ein so leichter Preis kann solch ein Werk bezahlen!", "tokens": ["Und", "ein", "so", "leich\u00b7ter", "Preis", "kann", "solch", "ein", "Werk", "be\u00b7zah\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADJD", "NN", "VMFIN", "PIAT", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie geht es zu? Wer schreibt so sch\u00f6n?", "tokens": ["Wie", "geht", "es", "zu", "?", "Wer", "schreibt", "so", "sch\u00f6n", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein Zaubrer scheint ihm beyzustehn:", "tokens": ["Ein", "Zaub\u00b7rer", "scheint", "ihm", "bey\u00b7zu\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Unm\u00f6glich kann ein Mensch so gleich, so schleunig malen!", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "kann", "ein", "Mensch", "so", "gleich", ",", "so", "schleu\u00b7nig", "ma\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "ADV", "ADV", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "So dachtest du, betrogne Stadt;", "tokens": ["So", "dach\u00b7test", "du", ",", "be\u00b7trog\u00b7ne", "Stadt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch List und Argwohn ward besch\u00e4met.", "tokens": ["Doch", "List", "und", "Arg\u00b7wohn", "ward", "be\u00b7sch\u00e4\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Kunst, die ", "tokens": ["Die", "Kunst", ",", "die"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Hat Deutschlands Witz gezeigt, und deinen Stolz gel\u00e4hmet.", "tokens": ["Hat", "Deutschlands", "Witz", "ge\u00b7zeigt", ",", "und", "dei\u00b7nen", "Stolz", "ge\u00b7l\u00e4h\u00b7met", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$,", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-++-+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.5": {"text": "Nun geh, und forsch, o eitles Land!", "tokens": ["Nun", "geh", ",", "und", "forsch", ",", "o", "eit\u00b7les", "Land", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KON", "ADJD", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was deines Volkes Flei\u00df erkannt,", "tokens": ["Was", "dei\u00b7nes", "Vol\u00b7kes", "Flei\u00df", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und komm, die seltne Kunst mit unsrer zu vergleichen.", "tokens": ["Und", "komm", ",", "die", "selt\u00b7ne", "Kunst", "mit", "uns\u00b7rer", "zu", "ver\u00b7glei\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "ADJA", "NN", "APPR", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Umsonst! der Seidenweber Flei\u00df,", "tokens": ["Um\u00b7sonst", "!", "der", "Sei\u00b7den\u00b7we\u00b7ber", "Flei\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Orgeln Bau, dein ganzer Preis,", "tokens": ["Der", "Or\u00b7geln", "Bau", ",", "dein", "gan\u00b7zer", "Preis", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wird nimmermehr das Lob der Druckerkunst erreichen.", "tokens": ["Wird", "nim\u00b7mer\u00b7mehr", "das", "Lob", "der", "Dru\u00b7cker\u00b7kunst", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Ihr Deutschen! folgt dem Beyspiel nach,", "tokens": ["Ihr", "Deut\u00b7schen", "!", "folgt", "dem", "Bey\u00b7spiel", "nach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Euch lockt der Ahnen Flei\u00df und Gl\u00fccke:", "tokens": ["Euch", "lockt", "der", "Ah\u00b7nen", "Flei\u00df", "und", "Gl\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erweist, zu eurer L\u00e4strer Schmach,", "tokens": ["Er\u00b7weist", ",", "zu", "eu\u00b7rer", "L\u00e4st\u00b7rer", "Schmach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Witz und Einfall noch die Allemannen schm\u00fccke.", "tokens": ["Da\u00df", "Witz", "und", "Ein\u00b7fall", "noch", "die", "Al\u00b7le\u00b7man\u00b7nen", "schm\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur k\u00fchn gewagt! wer zaghaft bebt,", "tokens": ["Nur", "k\u00fchn", "ge\u00b7wagt", "!", "wer", "zag\u00b7haft", "bebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$.", "PWS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat nie was Treffliches erstrebt:", "tokens": ["Hat", "nie", "was", "Treff\u00b7li\u00b7ches", "er\u00b7strebt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PWS", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Beherzter Streiter Haupt erlangt nur Siegeskronen.", "tokens": ["Be\u00b7herz\u00b7ter", "Strei\u00b7ter", "Haupt", "er\u00b7langt", "nur", "Sie\u00b7ges\u00b7kro\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo nicht, so putzt der Alten Kunst,", "tokens": ["Wo", "nicht", ",", "so", "putzt", "der", "Al\u00b7ten", "Kunst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Auch die\u00df erwirbt so Ruhm als Gunst,", "tokens": ["Auch", "die\u00df", "er\u00b7wirbt", "so", "Ruhm", "als", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "ADV", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und wird den Flei\u00df weit mehr, als fremde Thorheit lohnen.", "tokens": ["Und", "wird", "den", "Flei\u00df", "weit", "mehr", ",", "als", "frem\u00b7de", "Thor\u00b7heit", "loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "ADV", "$,", "KOUS", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Wie ist mir? sing ich tauber Luft?", "tokens": ["Wie", "ist", "mir", "?", "sing", "ich", "tau\u00b7ber", "Luft", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$.", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will mich Germanien nicht h\u00f6ren?", "tokens": ["Will", "mich", "Ger\u00b7ma\u00b7ni\u00b7en", "nicht", "h\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Kann nichts, womit man Tr\u00e4ge ruft,", "tokens": ["Kann", "nichts", ",", "wo\u00b7mit", "man", "Tr\u00e4\u00b7ge", "ruft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "$,", "PWAV", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die lang gewohnte Ruh des faulen Schlummers st\u00f6ren?", "tokens": ["Die", "lang", "ge\u00b7wohn\u00b7te", "Ruh", "des", "fau\u00b7len", "Schlum\u00b7mers", "st\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auf! edles ", "tokens": ["Auf", "!", "ed\u00b7les"], "token_info": ["word", "punct", "word"], "pos": ["APPR", "$.", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Auf! mache du der Welt bekannt,", "tokens": ["Auf", "!", "ma\u00b7che", "du", "der", "Welt", "be\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df wahres deutsches Blut in deinen Adern walle;", "tokens": ["Da\u00df", "wah\u00b7res", "deut\u00b7sches", "Blut", "in", "dei\u00b7nen", "A\u00b7dern", "wal\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dir der Deutschen Eigenthum", "tokens": ["Da\u00df", "dir", "der", "Deut\u00b7schen", "Ei\u00b7gen\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Weit mehr, als fremder V\u00f6lker Ruhm,", "tokens": ["Weit", "mehr", ",", "als", "frem\u00b7der", "V\u00f6l\u00b7ker", "Ruhm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dein eignes Vaterland mehr, als die Welt, gefalle.", "tokens": ["Dein", "eig\u00b7nes", "Va\u00b7ter\u00b7land", "mehr", ",", "als", "die", "Welt", ",", "ge\u00b7fal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "$,", "KOUS", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Du hast auch Grund! Natur und Zeit,", "tokens": ["Du", "hast", "auch", "Grund", "!", "Na\u00b7tur", "und", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$.", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Gl\u00fcck und Kunst hat dich erhoben;", "tokens": ["Und", "Gl\u00fcck", "und", "Kunst", "hat", "dich", "er\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df deinen Werth schon weit und breit,", "tokens": ["Da\u00df", "dei\u00b7nen", "Werth", "schon", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So weit Europa reicht, entlegne V\u00f6lker loben.", "tokens": ["So", "weit", "Eu\u00b7ro\u00b7pa", "reicht", ",", "ent\u00b7leg\u00b7ne", "V\u00f6l\u00b7ker", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NE", "VVFIN", "$,", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Himmels Vorsicht ist dir hold,", "tokens": ["Des", "Him\u00b7mels", "Vor\u00b7sicht", "ist", "dir", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und l\u00e4\u00dft der Zeiten altes Gold,", "tokens": ["Und", "l\u00e4\u00dft", "der", "Zei\u00b7ten", "al\u00b7tes", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch ", "tokens": ["Durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Was sonst dein ", "tokens": ["Was", "sonst", "dein"], "token_info": ["word", "word", "word"], "pos": ["PWS", "ADV", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Stellt itzt sein ", "tokens": ["Stellt", "itzt", "sein"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Und dieses Gl\u00fcck soll dir auf sp\u00e4te Zeiten w\u00e4hren.", "tokens": ["Und", "die\u00b7ses", "Gl\u00fcck", "soll", "dir", "auf", "sp\u00e4\u00b7te", "Zei\u00b7ten", "w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VMFIN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Er liebt den treuen Unterthan,", "tokens": ["Er", "liebt", "den", "treu\u00b7en", "Un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ha\u00dft nicht seiner L\u00e4nder Freude:", "tokens": ["Und", "ha\u00dft", "nicht", "sei\u00b7ner", "L\u00e4n\u00b7der", "Freu\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Handel schafft Er freye Bahn,", "tokens": ["Dem", "Han\u00b7del", "schafft", "Er", "frey\u00b7e", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sch\u00fctzt Pallas und Apoll, und kennt und liebt sie beyde.", "tokens": ["Sch\u00fctzt", "Pal\u00b7las", "und", "A\u00b7poll", ",", "und", "kennt", "und", "liebt", "sie", "bey\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "NN", "$,", "KON", "VVFIN", "KON", "VVFIN", "PPER", "PIS", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Auch selbst im Strafen zeigt Er Huld,", "tokens": ["Auch", "selbst", "im", "Stra\u00b7fen", "zeigt", "Er", "Huld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kann zitternder Verbrecher Schuld,", "tokens": ["Kann", "zit\u00b7tern\u00b7der", "Ver\u00b7bre\u00b7cher", "Schuld", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit Gro\u00dfmuth \u00fcbersehn und Feind und Neid besiegen.", "tokens": ["Mit", "Gro\u00df\u00b7muth", "\u00fc\u00b7ber\u00b7sehn", "und", "Feind", "und", "Neid", "be\u00b7sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "KON", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Wo hat ein Prinz so k\u00f6niglich,", "tokens": ["Wo", "hat", "ein", "Prinz", "so", "k\u00f6\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als Du bereits gethan, den neuen Thron bestiegen?", "tokens": ["Als", "Du", "be\u00b7reits", "ge\u00b7than", ",", "den", "neu\u00b7en", "Thron", "be\u00b7stie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "O Vaterland! wie dringt dein Heil", "tokens": ["O", "Va\u00b7ter\u00b7land", "!", "wie", "dringt", "dein", "Heil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PWAV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir jetzt durch Sinnen und Ge\u00e4der!", "tokens": ["Mir", "jetzt", "durch", "Sin\u00b7nen", "und", "Ge\u00b7\u00e4\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Herz nimmt selbst an allem Theil,", "tokens": ["Mein", "Herz", "nimmt", "selbst", "an", "al\u00b7lem", "Theil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Drum stockt vor reger Lust auch Einfall, Hand und Feder.", "tokens": ["Drum", "stockt", "vor", "re\u00b7ger", "Lust", "auch", "Ein\u00b7fall", ",", "Hand", "und", "Fe\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "ADJA", "NN", "ADV", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was sag ich viel? Dein Wohlseyn steigt,", "tokens": ["Was", "sag", "ich", "viel", "?", "Dein", "Wohl\u00b7seyn", "steigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da sich die\u00df ", "tokens": ["Da", "sich", "die\u00df"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PRF", "PDS"], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Das seinen holden Stral schon Land und Stadt gewiesen.", "tokens": ["Das", "sei\u00b7nen", "hol\u00b7den", "Stral", "schon", "Land", "und", "Stadt", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "ADJA", "NN", "ADV", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Einflu\u00df wirkt mit schneller Kraft:", "tokens": ["Sein", "Ein\u00b7flu\u00df", "wirkt", "mit", "schnel\u00b7ler", "Kraft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ist hier das Schweigen fehlerhaft;", "tokens": ["Ist", "hier", "das", "Schwei\u00b7gen", "feh\u00b7ler\u00b7haft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird doch, was Er thut, noch viel zu schwach gepriesen.", "tokens": ["So", "wird", "doch", ",", "was", "Er", "thut", ",", "noch", "viel", "zu", "schwach", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Genug, erfreute Pregelstadt!", "tokens": ["Ge\u00b7nug", ",", "er\u00b7freu\u00b7te", "Pre\u00b7gel\u00b7stadt", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df deine Musen besser singen,", "tokens": ["La\u00df", "dei\u00b7ne", "Mu\u00b7sen", "bes\u00b7ser", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und durch ein unzerst\u00f6rlich Blatt,", "tokens": ["Und", "durch", "ein", "un\u00b7zer\u00b7st\u00f6r\u00b7lich", "Blatt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem ", "tokens": ["Dem"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "O lebte Pietsch, dein Maro, noch!", "tokens": ["O", "leb\u00b7te", "Pietsch", ",", "dein", "Ma\u00b7ro", ",", "noch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$,", "PPOSAT", "NE", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie froh w\u00fcrd seine Clio doch", "tokens": ["Wie", "froh", "w\u00fcrd", "sei\u00b7ne", "Clio", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das Wachsthum deines Gl\u00fccks durch hohe Lieder ehren:", "tokens": ["Das", "Wach\u00b7sthum", "dei\u00b7nes", "Gl\u00fccks", "durch", "ho\u00b7he", "Lie\u00b7der", "eh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vorjetzt la\u00df nur mit froher Brust,", "tokens": ["Vor\u00b7jetzt", "la\u00df", "nur", "mit", "fro\u00b7her", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Auch au\u00dfer Deutschland, deine Lust,", "tokens": ["Auch", "au\u00b7\u00dfer", "Deutschland", ",", "dei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "Von der erfundnen Kunst der Druckerpressen h\u00f6ren.", "tokens": ["Von", "der", "er\u00b7fund\u00b7nen", "Kunst", "der", "Dru\u00b7cker\u00b7pres\u00b7sen", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Dein Reu\u00dfner selbst kann jetzt zugleich,", "tokens": ["Dein", "Reu\u00df\u00b7ner", "selbst", "kann", "jetzt", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VMFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein hundertj\u00e4hrig Fest begehen,", "tokens": ["Ein", "hun\u00b7dert\u00b7j\u00e4h\u00b7rig", "Fest", "be\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seit sein Geschlecht das Musenreich", "tokens": ["Seit", "sein", "Ge\u00b7schlecht", "das", "Mu\u00b7sen\u00b7reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bem\u00fcht und eifrig war durchs Drucken zu erh\u00f6hen.", "tokens": ["Be\u00b7m\u00fcht", "und", "eif\u00b7rig", "war", "durchs", "Dru\u00b7cken", "zu", "er\u00b7h\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "VAFIN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Freund! der Du Gott und Menschen dienst,", "tokens": ["Freund", "!", "der", "Du", "Gott", "und", "Men\u00b7schen", "dienst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PRELS", "PPER", "NN", "KON", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und selbst an Kunst und Wissen gr\u00fcnst,", "tokens": ["Und", "selbst", "an", "Kunst", "und", "Wis\u00b7sen", "gr\u00fcnst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nach alter Drucker Art, die selbst den Pindus kannten;", "tokens": ["Nach", "al\u00b7ter", "Dru\u00b7cker", "Art", ",", "die", "selbst", "den", "Pin\u00b7dus", "kann\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "PRELS", "ADV", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bl\u00fch stets auf Kind und Kindes Kind!", "tokens": ["Bl\u00fch", "stets", "auf", "Kind", "und", "Kin\u00b7des", "Kind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NN", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bis einst die Wesen Menschen sind,", "tokens": ["Bis", "einst", "die", "We\u00b7sen", "Men\u00b7schen", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die unsre Tage nur die sp\u00e4te Nachwelt nannten.", "tokens": ["Die", "uns\u00b7re", "Ta\u00b7ge", "nur", "die", "sp\u00e4\u00b7te", "Nach\u00b7welt", "nann\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Auf! eifre Sachsens K\u00fcnstlern nach,", "tokens": ["Auf", "!", "eif\u00b7re", "Sach\u00b7sens", "K\u00fcnst\u00b7lern", "nach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "ADJA", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sich der Barbarey entrissen;", "tokens": ["Die", "sich", "der", "Bar\u00b7ba\u00b7rey", "ent\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In deren Joch, der Zeit zur Schmach,", "tokens": ["In", "de\u00b7ren", "Joch", ",", "der", "Zeit", "zur", "Schmach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die edle Kunst sich j\u00fcngst ver\u00e4chtlich schmiegen m\u00fcssen.", "tokens": ["Die", "ed\u00b7le", "Kunst", "sich", "j\u00fcngst", "ver\u00b7\u00e4cht\u00b7lich", "schmie\u00b7gen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "ADV", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sieh unsers Breitkopfs Schriften an;", "tokens": ["Sieh", "un\u00b7sers", "Breit\u00b7kopfs", "Schrif\u00b7ten", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der \u00f6ffnete zuerst die Bahn,", "tokens": ["Der", "\u00f6ff\u00b7ne\u00b7te", "zu\u00b7erst", "die", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und trotzet itzt bereits der Elzevirer Pressen.", "tokens": ["Und", "trot\u00b7zet", "itzt", "be\u00b7reits", "der", "El\u00b7ze\u00b7vi\u00b7rer", "Pres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "O folg ihm nach! so wird die Welt,", "tokens": ["O", "folg", "ihm", "nach", "!", "so", "wird", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die einst auf sch\u00f6ne B\u00fccher h\u00e4lt,", "tokens": ["Die", "einst", "auf", "sch\u00f6\u00b7ne", "B\u00fc\u00b7cher", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wenig Dich, als Ihn, aus Dankbarkeit vergessen.", "tokens": ["So", "we\u00b7nig", "Dich", ",", "als", "Ihn", ",", "aus", "Dank\u00b7bar\u00b7keit", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "$,", "KOUS", "PPER", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Auch du, o ", "tokens": ["Auch", "du", ",", "o"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "PPER", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "La\u00dft von der Sterne blauen Bahn,", "tokens": ["La\u00dft", "von", "der", "Ster\u00b7ne", "blau\u00b7en", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohin der Dank euch hob, mir eure Gunst erscheinen.", "tokens": ["Wo\u00b7hin", "der", "Dank", "euch", "hob", ",", "mir", "eu\u00b7re", "Gunst", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "$,", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Belebt den bl\u00f6den Dichter hier,", "tokens": ["Be\u00b7lebt", "den", "bl\u00f6\u00b7den", "Dich\u00b7ter", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verleiht ihm Kraft, der Deutschen Zier,", "tokens": ["Ver\u00b7leiht", "ihm", "Kraft", ",", "der", "Deut\u00b7schen", "Zier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Ruhm der alten Zeit der neuen vorzusingen;", "tokens": ["Den", "Ruhm", "der", "al\u00b7ten", "Zeit", "der", "neu\u00b7en", "vor\u00b7zu\u00b7sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was ihr gepflanzt, gen\u00e4hrt, besch\u00fctzt,", "tokens": ["Was", "ihr", "ge\u00b7pflanzt", ",", "ge\u00b7n\u00e4hrt", ",", "be\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das deutsche Reich vergi\u00dft sich itzt,", "tokens": ["Das", "deut\u00b7sche", "Reich", "ver\u00b7gi\u00dft", "sich", "itzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verzagt an seiner Kraft, sich mehr empor zu schwingen.", "tokens": ["Ver\u00b7zagt", "an", "sei\u00b7ner", "Kraft", ",", "sich", "mehr", "em\u00b7por", "zu", "schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,", "PRF", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Man kennt den Muth, womit ihr bald,", "tokens": ["Man", "kennt", "den", "Muth", ",", "wo\u00b7mit", "ihr", "bald", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch die noch w\u00fcste Welt gedrungen,", "tokens": ["Durch", "die", "noch", "w\u00fcs\u00b7te", "Welt", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Euch Land gesucht, und Thier und Wald,", "tokens": ["Euch", "Land", "ge\u00b7sucht", ",", "und", "Thier", "und", "Wald", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVPP", "$,", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Fels und Strom gez\u00e4hmt, ja die Natur bezwungen.", "tokens": ["Und", "Fels", "und", "Strom", "ge\u00b7z\u00e4hmt", ",", "ja", "die", "Na\u00b7tur", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVPP", "$,", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man ehrt die Faust, die Rom geschw\u00e4cht:", "tokens": ["Man", "ehrt", "die", "Faust", ",", "die", "Rom", "ge\u00b7schw\u00e4cht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PRELS", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur euch war jenes Joch zu schlecht,", "tokens": ["Nur", "euch", "war", "je\u00b7nes", "Joch", "zu", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PDAT", "NN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das alle V\u00f6lker schon mit feiger Ehrfurcht k\u00fc\u00dften.", "tokens": ["Das", "al\u00b7le", "V\u00f6l\u00b7ker", "schon", "mit", "fei\u00b7ger", "Ehr\u00b7furcht", "k\u00fc\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Man weis, wie ", "tokens": ["Man", "weis", ",", "wie"], "token_info": ["word", "word", "punct", "word"], "pos": ["PIS", "PTKVZ", "$,", "PWAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Die Herrschbegier der stolzen Brust,", "tokens": ["Die", "Herrschbe\u00b7gier", "der", "stol\u00b7zen", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Bey der vereinten Macht der deutschen Sieger, b\u00fc\u00dften.", "tokens": ["Bey", "der", "ver\u00b7ein\u00b7ten", "Macht", "der", "deut\u00b7schen", "Sie\u00b7ger", ",", "b\u00fc\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Jedoch, was soll der gro\u00dfe Muth?", "tokens": ["Je\u00b7doch", ",", "was", "soll", "der", "gro\u00b7\u00dfe", "Muth", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VMFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedarf denn auch der ", "tokens": ["Be\u00b7darf", "denn", "auch", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Kann hier kein minder hei\u00dfes Blut", "tokens": ["Kann", "hier", "kein", "min\u00b7der", "hei\u00b7\u00dfes", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PIAT", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Musen Trieb und Lust zu hohen Liedern schaffen?", "tokens": ["Den", "Mu\u00b7sen", "Trieb", "und", "Lust", "zu", "ho\u00b7hen", "Lie\u00b7dern", "schaf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So scheints: allein, ein k\u00fchner Flug,", "tokens": ["So", "scheints", ":", "al\u00b7lein", ",", "ein", "k\u00fch\u00b7ner", "Flug", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum Ruhm der Deutschen, braucht den Zug,", "tokens": ["Zum", "Ruhm", "der", "Deut\u00b7schen", ",", "braucht", "den", "Zug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den du, o Heldenchor, zu Deiner Zeit empfunden.", "tokens": ["Den", "du", ",", "o", "Hel\u00b7den\u00b7chor", ",", "zu", "Dei\u00b7ner", "Zeit", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "FM", "NN", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Deutsche ringt nach eigner Schmach:", "tokens": ["Der", "Deut\u00b7sche", "ringt", "nach", "eig\u00b7ner", "Schmach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Drum k\u00e4mpft ein Dichter Helden nach,", "tokens": ["Drum", "k\u00e4mpft", "ein", "Dich\u00b7ter", "Hel\u00b7den", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der sich ein Lob erk\u00fchnt, das aus der Welt verschwunden.", "tokens": ["Der", "sich", "ein", "Lob", "er\u00b7k\u00fchnt", ",", "das", "aus", "der", "Welt", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$,", "PRELS", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Itzt, schlaue Nachbarn, h\u00f6rt mich nicht!", "tokens": ["Itzt", ",", "schlau\u00b7e", "Nach\u00b7barn", ",", "h\u00f6rt", "mich", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die\u00df Lied soll bis zu euch nicht dringen;", "tokens": ["Die\u00df", "Lied", "soll", "bis", "zu", "euch", "nicht", "drin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VMFIN", "ADV", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mein h\u00f6chst gerechtes Klaggedicht", "tokens": ["Mein", "h\u00f6chst", "ge\u00b7rech\u00b7tes", "Klag\u00b7ge\u00b7dicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Soll euch nicht neuen Stoff zu Spott und Tadel bringen.", "tokens": ["Soll", "euch", "nicht", "neu\u00b7en", "Stoff", "zu", "Spott", "und", "Ta\u00b7del", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ihr Alpen, werft den Schall zur\u00fcck,", "tokens": ["Ihr", "Al\u00b7pen", ",", "werft", "den", "Schall", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Damit kein W\u00e4lscher einen Blick", "tokens": ["Da\u00b7mit", "kein", "W\u00e4l\u00b7scher", "ei\u00b7nen", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Auf unsers Volkes Schimpf und schn\u00f6de Kleinmuth werfe;", "tokens": ["Auf", "un\u00b7sers", "Vol\u00b7kes", "Schimpf", "und", "schn\u00f6\u00b7de", "Klein\u00b7muth", "wer\u00b7fe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und du, uns noch getreuer Rhein,", "tokens": ["Und", "du", ",", "uns", "noch", "ge\u00b7treu\u00b7er", "Rhein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "ADV", "ADJD", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "La\u00df deine Wirbel rauschend seyn,", "tokens": ["La\u00df", "dei\u00b7ne", "Wir\u00b7bel", "rau\u00b7schend", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Da\u00df Gallien kein Ohr auf unsre Schande sch\u00e4rfe.", "tokens": ["Da\u00df", "Gal\u00b7li\u00b7en", "kein", "Ohr", "auf", "uns\u00b7re", "Schan\u00b7de", "sch\u00e4r\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Die weite See beraubt das Land,", "tokens": ["Die", "wei\u00b7te", "See", "be\u00b7raubt", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An allen K\u00fcsten und Gestaden,", "tokens": ["An", "al\u00b7len", "K\u00fcs\u00b7ten", "und", "Ge\u00b7sta\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Reichthum bleibt ihr unbekannt,", "tokens": ["Ihr", "Reicht\u00b7hum", "bleibt", "ihr", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie sucht sich nur mit Koth und Steinen zu beladen.", "tokens": ["Sie", "sucht", "sich", "nur", "mit", "Koth", "und", "Stei\u00b7nen", "zu", "be\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was achtet sie der Perlen Gut,", "tokens": ["Was", "ach\u00b7tet", "sie", "der", "Per\u00b7len", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der theuren Schnecken Purpurblut,", "tokens": ["Der", "theu\u00b7ren", "Schne\u00b7cken", "Pur\u00b7pur\u00b7blut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Muscheln Wunderreich, und Stauden von Corallen?", "tokens": ["Der", "Mu\u00b7scheln", "Wun\u00b7der\u00b7reich", ",", "und", "Stau\u00b7den", "von", "Co\u00b7ral\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die\u00df alles speyt sie an den Strand,", "tokens": ["Die\u00df", "al\u00b7les", "speyt", "sie", "an", "den", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und geizt um den unfruchtbarn Sand,", "tokens": ["Und", "geizt", "um", "den", "un\u00b7frucht\u00b7barn", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Vergn\u00fcgt, wenn Berg und Fels in ihre Tiefen fallen.", "tokens": ["Ver\u00b7gn\u00fcgt", ",", "wenn", "Berg", "und", "Fels", "in", "ih\u00b7re", "Tie\u00b7fen", "fal\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "So, Deutschland! irrt dein Vorwitz sich,", "tokens": ["So", ",", "Deutschland", "!", "irrt", "dein", "Vor\u00b7witz", "sich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$.", "VVFIN", "PPOSAT", "NN", "PRF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ganz blind bey eignen Trefflichkeiten:", "tokens": ["Ganz", "blind", "bey", "eig\u00b7nen", "Treff\u00b7lich\u00b7kei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein toller D\u00fcnkel reizet dich,", "tokens": ["Ein", "tol\u00b7ler", "D\u00fcn\u00b7kel", "rei\u00b7zet", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach fremder V\u00f6lker Tracht, und Witz und Kunst zu streiten.", "tokens": ["Nach", "frem\u00b7der", "V\u00f6l\u00b7ker", "Tracht", ",", "und", "Witz", "und", "Kunst", "zu", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "KON", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die G\u00fcter, so der Allmacht Hand", "tokens": ["Die", "G\u00fc\u00b7ter", ",", "so", "der", "All\u00b7macht", "Hand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir \u00fcberfl\u00fc\u00dfig zugewandt,", "tokens": ["Dir", "\u00fc\u00b7berf\u00b7l\u00fc\u00b7\u00dfig", "zu\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In deiner Berge Mark, in Land und Strom geleget;", "tokens": ["In", "dei\u00b7ner", "Ber\u00b7ge", "Mark", ",", "in", "Land", "und", "Strom", "ge\u00b7le\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was Luft und Teich und Garten beut,", "tokens": ["Was", "Luft", "und", "Teich", "und", "Gar\u00b7ten", "beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das ekelt deiner L\u00fcsternheit,", "tokens": ["Das", "e\u00b7kelt", "dei\u00b7ner", "L\u00fcs\u00b7tern\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die nur ein fernes Land mit fremdem Pracht erreget.", "tokens": ["Die", "nur", "ein", "fer\u00b7nes", "Land", "mit", "frem\u00b7dem", "Pracht", "er\u00b7re\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So weit die Schranken der Natur", "tokens": ["So", "weit", "die", "Schran\u00b7ken", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Sich \u00fcber Erd und Meer erstrecken,", "tokens": ["Sich", "\u00fc\u00b7ber", "Erd", "und", "Meer", "er\u00b7stre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Erblickt man nie die mindste Spur,", "tokens": ["Er\u00b7blickt", "man", "nie", "die", "minds\u00b7te", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Von Thieren, die den Rumpf mit fremden H\u00e4uten decken.", "tokens": ["Von", "Thie\u00b7ren", ",", "die", "den", "Rumpf", "mit", "frem\u00b7den", "H\u00e4u\u00b7ten", "de\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kein Schuppenheer legt Federn an,", "tokens": ["Kein", "Schup\u00b7pen\u00b7heer", "legt", "Fe\u00b7dern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Kein Volk in W\u00e4ldern hegt den Wahn,", "tokens": ["Kein", "Volk", "in", "W\u00e4l\u00b7dern", "hegt", "den", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Den reichbehaarten Balg mit Schuppen zu vertauschen.", "tokens": ["Den", "reich\u00b7be\u00b7haar\u00b7ten", "Balg", "mit", "Schup\u00b7pen", "zu", "ver\u00b7tau\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Kein L\u00f6we w\u00fcnscht ein Tygerkleid,", "tokens": ["Kein", "L\u00f6\u00b7we", "w\u00fcnscht", "ein", "Ty\u00b7ger\u00b7kleid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Kein Straus begeht die Eitelkeit,", "tokens": ["Kein", "Straus", "be\u00b7geht", "die", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Dem bunten Pfauenschweif den Zierath abzulauschen.", "tokens": ["Dem", "bun\u00b7ten", "Pfau\u00b7en\u00b7schweif", "den", "Zie\u00b7rath", "ab\u00b7zu\u00b7lau\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Verf\u00fchrtes Deutschland! du allein", "tokens": ["Ver\u00b7f\u00fchr\u00b7tes", "Deutschland", "!", "du", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPER", "ADV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ver\u00e4nderst t\u00e4glich die Gestalten;", "tokens": ["Ver\u00b7\u00e4n\u00b7derst", "t\u00e4g\u00b7lich", "die", "Ge\u00b7stal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die deutsche Tracht schien dir zu klein,", "tokens": ["Die", "deut\u00b7sche", "Tracht", "schien", "dir", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Tagus \u00e4ffst du nach, mit M\u00e4nteln voller Falten.", "tokens": ["Dem", "Ta\u00b7gus", "\u00e4ffst", "du", "nach", ",", "mit", "M\u00e4n\u00b7teln", "vol\u00b7ler", "Fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du schnittest Wamms und Hosen auf,", "tokens": ["Du", "schnit\u00b7test", "Wamms", "und", "Ho\u00b7sen", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als h\u00e4tte ", "tokens": ["Als", "h\u00e4t\u00b7te"], "token_info": ["word", "word"], "pos": ["KOUS", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Dein k\u00fchles Land so stark, als Granada, entz\u00fcndet.", "tokens": ["Dein", "k\u00fch\u00b7les", "Land", "so", "stark", ",", "als", "Gra\u00b7na\u00b7da", ",", "ent\u00b7z\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADJD", "$,", "KOUS", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald schien dir Frankreichs Thorheit sch\u00f6n,", "tokens": ["Bald", "schien", "dir", "Fran\u00b7kreichs", "Thor\u00b7heit", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wo niemand noch den Tag gesehn,", "tokens": ["Wo", "nie\u00b7mand", "noch", "den", "Tag", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da nicht der Schneiderwitz ein neu Gesch\u00f6pf erfindet.", "tokens": ["Da", "nicht", "der", "Schnei\u00b7der\u00b7witz", "ein", "neu", "Ge\u00b7sch\u00f6pf", "er\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "So th\u00f6richt sind doch nicht Madrit,", "tokens": ["So", "th\u00f6\u00b7richt", "sind", "doch", "nicht", "Mad\u00b7rit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Stambols Reich, nicht die Sarmaten;", "tokens": ["Nicht", "Stam\u00b7bols", "Reich", ",", "nicht", "die", "Sar\u00b7ma\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "NN", "$,", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Venedig macht kein Spielwerk mit,", "tokens": ["Ve\u00b7ne\u00b7dig", "macht", "kein", "Spiel\u00b7werk", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "So bunt es in Paris der Stutzerzunft gerathen.", "tokens": ["So", "bunt", "es", "in", "Pa\u00b7ris", "der", "Stut\u00b7zer\u00b7zunft", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "NE", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur du sch\u00e4mst dich der deutschen Tracht,", "tokens": ["Nur", "du", "sch\u00e4mst", "dich", "der", "deut\u00b7schen", "Tracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hast dir eine Kunst erdacht,", "tokens": ["Und", "hast", "dir", "ei\u00b7ne", "Kunst", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Auch deutsche Nahrung schmeckt dir nicht;", "tokens": ["Auch", "deut\u00b7sche", "Nah\u00b7rung", "schmeckt", "dir", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du mu\u00dft manch ekelhaft Ger\u00fccht", "tokens": ["Du", "mu\u00dft", "manch", "e\u00b7kel\u00b7haft", "Ge\u00b7r\u00fccht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit l\u00fcsternem Geschmack nach fremdem Gaum erhandeln.", "tokens": ["Mit", "l\u00fcs\u00b7ter\u00b7nem", "Ge\u00b7schmack", "nach", "frem\u00b7dem", "Gaum", "er\u00b7han\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wo pflegt die laute Nachtigall", "tokens": ["Wo", "pflegt", "die", "lau\u00b7te", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Des Guckucks Sylben nachzu\u00e4ffen?", "tokens": ["Des", "Gu\u00b7ckucks", "Syl\u00b7ben", "nach\u00b7zu\u00b7\u00e4f\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wo sucht durch ihrer Kehle Schall", "tokens": ["Wo", "sucht", "durch", "ih\u00b7rer", "Keh\u00b7le", "Schall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die Lerche das Geplerr des Wachtelvolks zu treffen?", "tokens": ["Die", "Ler\u00b7che", "das", "Ge\u00b7plerr", "des", "Wach\u00b7tel\u00b7volks", "zu", "tref\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Schwalbe singt, die Taube girrt:", "tokens": ["Die", "Schwal\u00b7be", "singt", ",", "die", "Tau\u00b7be", "girrt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und beyder Ton wird nie verwirrt,", "tokens": ["Und", "bey\u00b7der", "Ton", "wird", "nie", "ver\u00b7wirrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Wenn gleich der Fr\u00f6sche Heer in lauen S\u00fcmpfen kr\u00f6chzet.", "tokens": ["Wenn", "gleich", "der", "Fr\u00f6\u00b7sche", "Heer", "in", "lau\u00b7en", "S\u00fcmp\u00b7fen", "kr\u00f6ch\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Das deutsche Volk vergeht sich nur;", "tokens": ["Das", "deut\u00b7sche", "Volk", "ver\u00b7geht", "sich", "nur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Indem es wider die Natur", "tokens": ["In\u00b7dem", "es", "wi\u00b7der", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Die eigne Mundart ha\u00dft, nach fremden Sprachen lechzet.", "tokens": ["Die", "eig\u00b7ne", "Mund\u00b7art", "ha\u00dft", ",", "nach", "frem\u00b7den", "Spra\u00b7chen", "lech\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Kein Wunder, da\u00df die Zunge stockt,", "tokens": ["Kein", "Wun\u00b7der", ",", "da\u00df", "die", "Zun\u00b7ge", "stockt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie kann sie deutsch und redlich sprechen:", "tokens": ["Wie", "kann", "sie", "deutsch", "und", "red\u00b7lich", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seit Frankreichs List das Ohr gelockt,", "tokens": ["Seit", "Fran\u00b7kreichs", "List", "das", "Ohr", "ge\u00b7lockt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und alle Welt gelehrt, so Sylb als Eide brechen?", "tokens": ["Und", "al\u00b7le", "Welt", "ge\u00b7lehrt", ",", "so", "Sylb", "als", "Ei\u00b7de", "bre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$,", "ADV", "NE", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Sprache von vermischter Art,", "tokens": ["Der", "Spra\u00b7che", "von", "ver\u00b7mischter", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die damals erst gebohren ward,", "tokens": ["Die", "da\u00b7mals", "erst", "ge\u00b7boh\u00b7ren", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als Deutschland Gallien und Rom gehorchen lehrte;", "tokens": ["Als", "Deutschland", "Gal\u00b7li\u00b7en", "und", "Rom", "ge\u00b7hor\u00b7chen", "lehr\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "KON", "NE", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Dem Bastart alter Barbarey", "tokens": ["Dem", "Bas\u00b7tart", "al\u00b7ter", "Bar\u00b7ba\u00b7rey"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Legt man der Sch\u00f6nheit Gipfel bey,", "tokens": ["Legt", "man", "der", "Sch\u00f6n\u00b7heit", "Gip\u00b7fel", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die unsrer Mundart doch mit besserm Recht geh\u00f6rte.", "tokens": ["Die", "uns\u00b7rer", "Mund\u00b7art", "doch", "mit", "bes\u00b7serm", "Recht", "ge\u00b7h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "So reizend hat kein Honigseim", "tokens": ["So", "rei\u00b7zend", "hat", "kein", "Ho\u00b7ni\u00b7gseim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verzognen Kindern noch geschmecket,", "tokens": ["Ver\u00b7zog\u00b7nen", "Kin\u00b7dern", "noch", "ge\u00b7schme\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als uns ein halbverstandner Reim,", "tokens": ["Als", "uns", "ein", "halb\u00b7ver\u00b7stand\u00b7ner", "Reim", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo aller Witz und Geist in fremden Sylben stecket.", "tokens": ["Wo", "al\u00b7ler", "Witz", "und", "Geist", "in", "frem\u00b7den", "Syl\u00b7ben", "ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Toscaniens beruffner Dunst,", "tokens": ["Tos\u00b7ca\u00b7ni\u00b7ens", "be\u00b7ruff\u00b7ner", "Dunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der w\u00e4lschen T\u00f6ne Zauberkunst,", "tokens": ["Der", "w\u00e4l\u00b7schen", "T\u00f6\u00b7ne", "Zau\u00b7ber\u00b7kunst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die ein geschwollnes Nichts in langen Trillern zerret;", "tokens": ["Die", "ein", "ge\u00b7schwoll\u00b7nes", "Nichts", "in", "lan\u00b7gen", "Tril\u00b7lern", "zer\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Der niedern B\u00fchne freche Zunft,", "tokens": ["Der", "nie\u00b7dern", "B\u00fch\u00b7ne", "fre\u00b7che", "Zunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der tollsten Gaukler Unvernunft", "tokens": ["Der", "tolls\u00b7ten", "Gauk\u00b7ler", "Un\u00b7ver\u00b7nunft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Hat aller Alten Kunst den Eingang l\u00e4ngst versperret.", "tokens": ["Hat", "al\u00b7ler", "Al\u00b7ten", "Kunst", "den", "Ein\u00b7gang", "l\u00e4ngst", "ver\u00b7sper\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Als noch der ", "tokens": ["Als", "noch", "der"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Die alten Teutonen vergn\u00fcgte,", "tokens": ["Die", "al\u00b7ten", "Teu\u00b7to\u00b7nen", "ver\u00b7gn\u00fcg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Hat kein Gesang ihr Ohr bem\u00fcht,", "tokens": ["Hat", "kein", "Ge\u00b7sang", "ihr", "Ohr", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der nicht gesundern Witz zum Ruhm der Tugend f\u00fcgte.", "tokens": ["Der", "nicht", "ge\u00b7sun\u00b7dern", "Witz", "zum", "Ruhm", "der", "Tu\u00b7gend", "f\u00fcg\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJA", "NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und h\u00e4tt uns noch kein ", "tokens": ["Und", "h\u00e4tt", "uns", "noch", "kein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PIAT"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "An Geist, Geschmack und Einsicht reich,", "tokens": ["An", "Geist", ",", "Ge\u00b7schmack", "und", "Ein\u00b7sicht", "reich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zum wahren ", "tokens": ["Zum", "wah\u00b7ren"], "token_info": ["word", "word"], "pos": ["APPRART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "So h\u00e4tten wir, mit besserm Recht,", "tokens": ["So", "h\u00e4t\u00b7ten", "wir", ",", "mit", "bes\u00b7serm", "Recht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein itzt ver\u00e4chtliches Geschlecht,", "tokens": ["Ein", "itzt", "ver\u00b7\u00e4cht\u00b7li\u00b7ches", "Ge\u00b7schlecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Von S\u00e4ngern alter Zucht, nach N\u00fcrnbergs Art, gepriesen.", "tokens": ["Von", "S\u00e4n\u00b7gern", "al\u00b7ter", "Zucht", ",", "nach", "N\u00fcrn\u00b7bergs", "Art", ",", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$,", "APPR", "NE", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Auch ihr, ihr Gr\u00fcbler! geht zu weit,", "tokens": ["Auch", "ihr", ",", "ihr", "Gr\u00fcb\u00b7ler", "!", "geht", "zu", "weit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die nur Athen und Rom geblendet,", "tokens": ["Die", "nur", "A\u00b7then", "und", "Rom", "ge\u00b7blen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NE", "KON", "NE", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Da\u00df ihr die kurze Lebenszeit", "tokens": ["Da\u00df", "ihr", "die", "kur\u00b7ze", "Le\u00b7bens\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bey fremder W\u00f6rter Zier und dunkler Kunst verschwendet.", "tokens": ["Bey", "frem\u00b7der", "W\u00f6r\u00b7ter", "Zier", "und", "dunk\u00b7ler", "Kunst", "ver\u00b7schwen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja! forscht der Alten Regeln aus;", "tokens": ["Ja", "!", "forscht", "der", "Al\u00b7ten", "Re\u00b7geln", "aus", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur lehrt uns nicht in Staub und Graus", "tokens": ["Nur", "lehrt", "uns", "nicht", "in", "Staub", "und", "Graus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der freyen Geister Kraft, zu eigner Schmach, begraben.", "tokens": ["Der", "frey\u00b7en", "Geis\u00b7ter", "Kraft", ",", "zu", "eig\u00b7ner", "Schmach", ",", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "APPR", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Singt deutsch so edel, als Homer!", "tokens": ["Singt", "deutsch", "so", "e\u00b7del", ",", "als", "Ho\u00b7mer", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "ADJD", "$,", "KOUS", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.10": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}, "stanza.40": {"line.1": {"text": "Singt ", "tokens": ["Singt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Und blutbespritzte Lorberkronen.", "tokens": ["Und", "blut\u00b7be\u00b7spritz\u00b7te", "Lor\u00b7ber\u00b7kro\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was gilts! der hier erfochtne Sieg", "tokens": ["Was", "gilts", "!", "der", "hier", "er\u00b7focht\u00b7ne", "Sieg"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird euch die Arbeit mehr, als Trojens Schutt belohnen.", "tokens": ["Wird", "euch", "die", "Ar\u00b7beit", "mehr", ",", "als", "Tro\u00b7jens", "Schutt", "be\u00b7loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "$,", "KOUS", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "La\u00dft uns die Weisen aus Athen", "tokens": ["La\u00dft", "uns", "die", "Wei\u00b7sen", "aus", "A\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "APPR", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "In deutschverfa\u00dften Schriften sehn,", "tokens": ["In", "deutschver\u00b7fa\u00df\u00b7ten", "Schrif\u00b7ten", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und lehret unsre Zeit ein attisch Salz im Sprechen.", "tokens": ["Und", "leh\u00b7ret", "uns\u00b7re", "Zeit", "ein", "at\u00b7tisch", "Salz", "im", "Spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ART", "ADJD", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bringt uns der R\u00f6mer Gro\u00dfmuth bey;", "tokens": ["Bringt", "uns", "der", "R\u00f6\u00b7mer", "Gro\u00df\u00b7muth", "bey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So folgt ein ewig Lobgeschrey,", "tokens": ["So", "folgt", "ein", "e\u00b7wig", "Lob\u00b7ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und eures Namens Ruhm wird Gruft und Zeit nicht schw\u00e4chen.", "tokens": ["Und", "eu\u00b7res", "Na\u00b7mens", "Ruhm", "wird", "Gruft", "und", "Zeit", "nicht", "schw\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VAFIN", "NN", "KON", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Singt eurer Ahnen Flei\u00df und Witz", "tokens": ["Singt", "eu\u00b7rer", "Ah\u00b7nen", "Flei\u00df", "und", "Witz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daran kein Volk sie noch bezwungen;", "tokens": ["Da\u00b7ran", "kein", "Volk", "sie", "noch", "be\u00b7zwun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seit sie durch Pulver und Gesch\u00fctz", "tokens": ["Seit", "sie", "durch", "Pul\u00b7ver", "und", "Ge\u00b7sch\u00fctz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der donnernden Gewalt des Himmels nachgerungen.", "tokens": ["Der", "don\u00b7nern\u00b7den", "Ge\u00b7walt", "des", "Him\u00b7mels", "nach\u00b7ge\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Singt, wie der Minen Wunderkraft,", "tokens": ["Singt", ",", "wie", "der", "Mi\u00b7nen", "Wun\u00b7der\u00b7kraft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch des Salpeters Eigenschaft,", "tokens": ["Durch", "des", "Sal\u00b7pe\u00b7ters", "Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Dem Aetna und Vesuv an schneller Macht nicht weichet.", "tokens": ["Dem", "A\u00b7et\u00b7na", "und", "Ve\u00b7suv", "an", "schnel\u00b7ler", "Macht", "nicht", "wei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NN", "APPR", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Erz\u00e4hlt, was Deutschland sonst erfand,", "tokens": ["Er\u00b7z\u00e4hlt", ",", "was", "Deutschland", "sonst", "er\u00b7fand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Wenn es durch forschenden Verstand", "tokens": ["Wenn", "es", "durch", "for\u00b7schen\u00b7den", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Wunder der Natur vor fremdem Witz erreichet.", "tokens": ["Die", "Wun\u00b7der", "der", "Na\u00b7tur", "vor", "frem\u00b7dem", "Witz", "er\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Vor andern singt das Lob der Kunst,", "tokens": ["Vor", "an\u00b7dern", "singt", "das", "Lob", "der", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dadurch die Todten ewig leben;", "tokens": ["Da\u00b7durch", "die", "Tod\u00b7ten", "e\u00b7wig", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die des geneigten Himmels Gunst", "tokens": ["Die", "des", "ge\u00b7neig\u00b7ten", "Him\u00b7mels", "Gunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor allen V\u00f6lkern, nur der deutschen Welt gegeben.", "tokens": ["Vor", "al\u00b7len", "V\u00f6l\u00b7kern", ",", "nur", "der", "deut\u00b7schen", "Welt", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erhebt das k\u00fcnstliche Metall,", "tokens": ["Er\u00b7hebt", "das", "k\u00fcnst\u00b7li\u00b7che", "Me\u00b7tall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem ein mit Ru\u00df geschw\u00e4rzter Ball", "tokens": ["Dem", "ein", "mit", "Ru\u00df", "ge\u00b7schw\u00e4rz\u00b7ter", "Ball"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die edle Kraft verleiht, die Tugend auszubreiten.", "tokens": ["Die", "ed\u00b7le", "Kraft", "ver\u00b7leiht", ",", "die", "Tu\u00b7gend", "aus\u00b7zu\u00b7brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Erhebt die Presse, deren Druck", "tokens": ["Er\u00b7hebt", "die", "Pres\u00b7se", ",", "de\u00b7ren", "Druck"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verstand und Witz, mit neuem Schmuck", "tokens": ["Ver\u00b7stand", "und", "Witz", ",", "mit", "neu\u00b7em", "Schmuck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und reicher Fruchtbarkeit, kann in die Welt begleiten.", "tokens": ["Und", "rei\u00b7cher", "Frucht\u00b7bar\u00b7keit", ",", "kann", "in", "die", "Welt", "be\u00b7glei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "$,", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Verewigt jener K\u00fcnstler Preis,", "tokens": ["Ve\u00b7re\u00b7wigt", "je\u00b7ner", "K\u00fcnst\u00b7ler", "Preis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die M\u00fch und Zeit und Geld nicht reute:", "tokens": ["Die", "M\u00fch", "und", "Zeit", "und", "Geld", "nicht", "reu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "KON", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bis sie ein klugverwandter Flei\u00df", "tokens": ["Bis", "sie", "ein", "klug\u00b7ver\u00b7wand\u00b7ter", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Mit dieser Wunderkunst und vielem Ruhm erfreute.", "tokens": ["Mit", "die\u00b7ser", "Wun\u00b7der\u00b7kunst", "und", "vie\u00b7lem", "Ruhm", "er\u00b7freu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Das macht die K\u00fcnstler noch bey aller Welt zum Wunder.", "tokens": ["Das", "macht", "die", "K\u00fcnst\u00b7ler", "noch", "bey", "al\u00b7ler", "Welt", "zum", "Wun\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV", "APPR", "PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du edles Kleeblatt! w\u00fcrde nur,", "tokens": ["Du", "ed\u00b7les", "Klee\u00b7blatt", "!", "w\u00fcr\u00b7de", "nur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Auf der so loberf\u00fcllten Spur,", "tokens": ["Auf", "der", "so", "lo\u00b7berf\u00b7\u00fcll\u00b7ten", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dein gro\u00dfes Beyspiel noch der tr\u00e4gen Deutschen Zunder!", "tokens": ["Dein", "gro\u00b7\u00dfes", "Bey\u00b7spiel", "noch", "der", "tr\u00e4\u00b7gen", "Deut\u00b7schen", "Zun\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Wie Wei\u00df, der Orpheus unsrer Zeit,", "tokens": ["Wie", "Wei\u00df", ",", "der", "Or\u00b7pheus", "uns\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ART", "NE", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eh er die Zauberlaute r\u00fchret,", "tokens": ["Eh", "er", "die", "Zau\u00b7berl\u00b7au\u00b7te", "r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mit ungemeiner Achtsamkeit", "tokens": ["Mit", "un\u00b7ge\u00b7mei\u00b7ner", "Acht\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Seyten Kl\u00e4nge pr\u00fcft, und durch die T\u00f6ne f\u00fchret;", "tokens": ["Der", "Sey\u00b7ten", "Kl\u00e4n\u00b7ge", "pr\u00fcft", ",", "und", "durch", "die", "T\u00f6\u00b7ne", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er fa\u00dft die Wirbel, horcht und stimmt,", "tokens": ["Er", "fa\u00dft", "die", "Wir\u00b7bel", ",", "horcht", "und", "stimmt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bis er den Mishall nicht vernimmt,", "tokens": ["Bis", "er", "den", "Mis\u00b7hall", "nicht", "ver\u00b7nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der anfangs sein Geh\u00f6r durch falschen Laut verletzet;", "tokens": ["Der", "an\u00b7fangs", "sein", "Ge\u00b7h\u00f6r", "durch", "fal\u00b7schen", "Laut", "ver\u00b7let\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Rechte l\u00e4uft durch manchen Gang,", "tokens": ["Die", "Rech\u00b7te", "l\u00e4uft", "durch", "man\u00b7chen", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bis ihm ein fehlerfreyer Klang,", "tokens": ["Bis", "ihm", "ein", "feh\u00b7ler\u00b7fre\u00b7yer", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das zarte Meisterohr mit reinem Ton ergetzet.", "tokens": ["Das", "zar\u00b7te", "Meis\u00b7te\u00b7rohr", "mit", "rei\u00b7nem", "Ton", "er\u00b7get\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "So, d\u00fcnkt mich, seh ich euch, entbrannt,", "tokens": ["So", ",", "d\u00fcnkt", "mich", ",", "seh", "ich", "euch", ",", "ent\u00b7brannt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PPER", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr ewig werthen K\u00fcnstler! sitzen,", "tokens": ["Ihr", "e\u00b7wig", "wert\u00b7hen", "K\u00fcnst\u00b7ler", "!", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "NN", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und durch den Stahl in kluger Hand", "tokens": ["Und", "durch", "den", "Stahl", "in", "klu\u00b7ger", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Seiten voller Schrift in glatte Tafeln schnitzen.", "tokens": ["Viel", "Sei\u00b7ten", "vol\u00b7ler", "Schrift", "in", "glat\u00b7te", "Ta\u00b7feln", "schnit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die M\u00fch ist gro\u00df, der Vortheil schwach:", "tokens": ["Die", "M\u00fch", "ist", "gro\u00df", ",", "der", "Vor\u00b7theil", "schwach", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum sinnt und denkt ihr eifrig nach,", "tokens": ["Drum", "sinnt", "und", "denkt", "ihr", "eif\u00b7rig", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr bessert, putzt, vergleicht und ziert die festen Zeilen.", "tokens": ["Ihr", "bes\u00b7sert", ",", "putzt", ",", "ver\u00b7gleicht", "und", "ziert", "die", "fes\u00b7ten", "Zei\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald trennt ihr Wort und Sylben ab;", "tokens": ["Bald", "trennt", "ihr", "Wort", "und", "Syl\u00b7ben", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zuletzt mu\u00df ein gevierter Stab", "tokens": ["Zu\u00b7letzt", "mu\u00df", "ein", "ge\u00b7vier\u00b7ter", "Stab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Aus starrendem Metall metallne Lettern feilen.", "tokens": ["Aus", "star\u00b7ren\u00b7dem", "Me\u00b7tall", "me\u00b7tall\u00b7ne", "Let\u00b7tern", "fei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Nun folgt ein St\u00e4mpel, dessen Schlag", "tokens": ["Nun", "folgt", "ein", "St\u00e4m\u00b7pel", ",", "des\u00b7sen", "Schlag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Kupfer seinen Abdruck leget;", "tokens": ["In", "Kup\u00b7fer", "sei\u00b7nen", "Ab\u00b7druck", "le\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So k\u00f6mmt die Mutter an den Tag,", "tokens": ["So", "k\u00f6mmt", "die", "Mut\u00b7ter", "an", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die ihr vertieftes Bley in tausend S\u00f6hne pr\u00e4get.", "tokens": ["Die", "ihr", "ver\u00b7tief\u00b7tes", "Bley", "in", "tau\u00b7send", "S\u00f6h\u00b7ne", "pr\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Zeug, aus Eisen, Bley und Zinn,", "tokens": ["Ein", "Zeug", ",", "aus", "Ei\u00b7sen", ",", "Bley", "und", "Zinn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "L\u00e4uft durch den schnellen Gu\u00df dahin,", "tokens": ["L\u00e4uft", "durch", "den", "schnel\u00b7len", "Gu\u00df", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo sich des Vaters Kraft in sch\u00f6nen Z\u00fcgen weiset.", "tokens": ["Wo", "sich", "des", "Va\u00b7ters", "Kraft", "in", "sch\u00f6\u00b7nen", "Z\u00fc\u00b7gen", "wei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So tritt der Lettern Heer ans Licht,", "tokens": ["So", "tritt", "der", "Let\u00b7tern", "Heer", "ans", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Durch deren Erzt man lauter spricht,", "tokens": ["Durch", "de\u00b7ren", "Erzt", "man", "lau\u00b7ter", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als uns das Alterthum von Stentors Stimme preiset.", "tokens": ["Als", "uns", "das", "Al\u00b7ter\u00b7thum", "von", "Sten\u00b7tors", "Stim\u00b7me", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Wie war dir, starrendes Paris,", "tokens": ["Wie", "war", "dir", ",", "star\u00b7ren\u00b7des", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du stolze Pflegerinn der K\u00fcnste,", "tokens": ["Du", "stol\u00b7ze", "Pfle\u00b7ge\u00b7rinn", "der", "K\u00fcns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "An Sch\u00f6nheit wunderbar, mit m\u00e4\u00dfigem Gewinnste?", "tokens": ["An", "Sch\u00f6n\u00b7heit", "wun\u00b7der\u00b7bar", ",", "mit", "m\u00e4\u00b7\u00dfi\u00b7gem", "Ge\u00b7winns\u00b7te", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Gleichheit machte dich verwirrt:", "tokens": ["Die", "Gleich\u00b7heit", "mach\u00b7te", "dich", "ver\u00b7wirrt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Punct ist falsch, kein Buchstab irrt;", "tokens": ["Kein", "Punct", "ist", "falsch", ",", "kein", "Buch\u00b7stab", "irrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$,", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ein so leichter Preis kann solch ein Werk bezahlen!", "tokens": ["Und", "ein", "so", "leich\u00b7ter", "Preis", "kann", "solch", "ein", "Werk", "be\u00b7zah\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADJD", "NN", "VMFIN", "PIAT", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie geht es zu? Wer schreibt so sch\u00f6n?", "tokens": ["Wie", "geht", "es", "zu", "?", "Wer", "schreibt", "so", "sch\u00f6n", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein Zaubrer scheint ihm beyzustehn:", "tokens": ["Ein", "Zaub\u00b7rer", "scheint", "ihm", "bey\u00b7zu\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Unm\u00f6glich kann ein Mensch so gleich, so schleunig malen!", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "kann", "ein", "Mensch", "so", "gleich", ",", "so", "schleu\u00b7nig", "ma\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "ADV", "ADV", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "So dachtest du, betrogne Stadt;", "tokens": ["So", "dach\u00b7test", "du", ",", "be\u00b7trog\u00b7ne", "Stadt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch List und Argwohn ward besch\u00e4met.", "tokens": ["Doch", "List", "und", "Arg\u00b7wohn", "ward", "be\u00b7sch\u00e4\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Kunst, die ", "tokens": ["Die", "Kunst", ",", "die"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Hat Deutschlands Witz gezeigt, und deinen Stolz gel\u00e4hmet.", "tokens": ["Hat", "Deutschlands", "Witz", "ge\u00b7zeigt", ",", "und", "dei\u00b7nen", "Stolz", "ge\u00b7l\u00e4h\u00b7met", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$,", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-++-+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.5": {"text": "Nun geh, und forsch, o eitles Land!", "tokens": ["Nun", "geh", ",", "und", "forsch", ",", "o", "eit\u00b7les", "Land", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KON", "ADJD", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was deines Volkes Flei\u00df erkannt,", "tokens": ["Was", "dei\u00b7nes", "Vol\u00b7kes", "Flei\u00df", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und komm, die seltne Kunst mit unsrer zu vergleichen.", "tokens": ["Und", "komm", ",", "die", "selt\u00b7ne", "Kunst", "mit", "uns\u00b7rer", "zu", "ver\u00b7glei\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "ADJA", "NN", "APPR", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Umsonst! der Seidenweber Flei\u00df,", "tokens": ["Um\u00b7sonst", "!", "der", "Sei\u00b7den\u00b7we\u00b7ber", "Flei\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Orgeln Bau, dein ganzer Preis,", "tokens": ["Der", "Or\u00b7geln", "Bau", ",", "dein", "gan\u00b7zer", "Preis", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wird nimmermehr das Lob der Druckerkunst erreichen.", "tokens": ["Wird", "nim\u00b7mer\u00b7mehr", "das", "Lob", "der", "Dru\u00b7cker\u00b7kunst", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Ihr Deutschen! folgt dem Beyspiel nach,", "tokens": ["Ihr", "Deut\u00b7schen", "!", "folgt", "dem", "Bey\u00b7spiel", "nach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Euch lockt der Ahnen Flei\u00df und Gl\u00fccke:", "tokens": ["Euch", "lockt", "der", "Ah\u00b7nen", "Flei\u00df", "und", "Gl\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erweist, zu eurer L\u00e4strer Schmach,", "tokens": ["Er\u00b7weist", ",", "zu", "eu\u00b7rer", "L\u00e4st\u00b7rer", "Schmach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Witz und Einfall noch die Allemannen schm\u00fccke.", "tokens": ["Da\u00df", "Witz", "und", "Ein\u00b7fall", "noch", "die", "Al\u00b7le\u00b7man\u00b7nen", "schm\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur k\u00fchn gewagt! wer zaghaft bebt,", "tokens": ["Nur", "k\u00fchn", "ge\u00b7wagt", "!", "wer", "zag\u00b7haft", "bebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$.", "PWS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat nie was Treffliches erstrebt:", "tokens": ["Hat", "nie", "was", "Treff\u00b7li\u00b7ches", "er\u00b7strebt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PWS", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Beherzter Streiter Haupt erlangt nur Siegeskronen.", "tokens": ["Be\u00b7herz\u00b7ter", "Strei\u00b7ter", "Haupt", "er\u00b7langt", "nur", "Sie\u00b7ges\u00b7kro\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo nicht, so putzt der Alten Kunst,", "tokens": ["Wo", "nicht", ",", "so", "putzt", "der", "Al\u00b7ten", "Kunst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Auch die\u00df erwirbt so Ruhm als Gunst,", "tokens": ["Auch", "die\u00df", "er\u00b7wirbt", "so", "Ruhm", "als", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "ADV", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und wird den Flei\u00df weit mehr, als fremde Thorheit lohnen.", "tokens": ["Und", "wird", "den", "Flei\u00df", "weit", "mehr", ",", "als", "frem\u00b7de", "Thor\u00b7heit", "loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "ADV", "$,", "KOUS", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Wie ist mir? sing ich tauber Luft?", "tokens": ["Wie", "ist", "mir", "?", "sing", "ich", "tau\u00b7ber", "Luft", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$.", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will mich Germanien nicht h\u00f6ren?", "tokens": ["Will", "mich", "Ger\u00b7ma\u00b7ni\u00b7en", "nicht", "h\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Kann nichts, womit man Tr\u00e4ge ruft,", "tokens": ["Kann", "nichts", ",", "wo\u00b7mit", "man", "Tr\u00e4\u00b7ge", "ruft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "$,", "PWAV", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die lang gewohnte Ruh des faulen Schlummers st\u00f6ren?", "tokens": ["Die", "lang", "ge\u00b7wohn\u00b7te", "Ruh", "des", "fau\u00b7len", "Schlum\u00b7mers", "st\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auf! edles ", "tokens": ["Auf", "!", "ed\u00b7les"], "token_info": ["word", "punct", "word"], "pos": ["APPR", "$.", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Auf! mache du der Welt bekannt,", "tokens": ["Auf", "!", "ma\u00b7che", "du", "der", "Welt", "be\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df wahres deutsches Blut in deinen Adern walle;", "tokens": ["Da\u00df", "wah\u00b7res", "deut\u00b7sches", "Blut", "in", "dei\u00b7nen", "A\u00b7dern", "wal\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dir der Deutschen Eigenthum", "tokens": ["Da\u00df", "dir", "der", "Deut\u00b7schen", "Ei\u00b7gen\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Weit mehr, als fremder V\u00f6lker Ruhm,", "tokens": ["Weit", "mehr", ",", "als", "frem\u00b7der", "V\u00f6l\u00b7ker", "Ruhm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dein eignes Vaterland mehr, als die Welt, gefalle.", "tokens": ["Dein", "eig\u00b7nes", "Va\u00b7ter\u00b7land", "mehr", ",", "als", "die", "Welt", ",", "ge\u00b7fal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "$,", "KOUS", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Du hast auch Grund! Natur und Zeit,", "tokens": ["Du", "hast", "auch", "Grund", "!", "Na\u00b7tur", "und", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$.", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Gl\u00fcck und Kunst hat dich erhoben;", "tokens": ["Und", "Gl\u00fcck", "und", "Kunst", "hat", "dich", "er\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df deinen Werth schon weit und breit,", "tokens": ["Da\u00df", "dei\u00b7nen", "Werth", "schon", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So weit Europa reicht, entlegne V\u00f6lker loben.", "tokens": ["So", "weit", "Eu\u00b7ro\u00b7pa", "reicht", ",", "ent\u00b7leg\u00b7ne", "V\u00f6l\u00b7ker", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NE", "VVFIN", "$,", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Himmels Vorsicht ist dir hold,", "tokens": ["Des", "Him\u00b7mels", "Vor\u00b7sicht", "ist", "dir", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und l\u00e4\u00dft der Zeiten altes Gold,", "tokens": ["Und", "l\u00e4\u00dft", "der", "Zei\u00b7ten", "al\u00b7tes", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch ", "tokens": ["Durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Was sonst dein ", "tokens": ["Was", "sonst", "dein"], "token_info": ["word", "word", "word"], "pos": ["PWS", "ADV", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Stellt itzt sein ", "tokens": ["Stellt", "itzt", "sein"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Und dieses Gl\u00fcck soll dir auf sp\u00e4te Zeiten w\u00e4hren.", "tokens": ["Und", "die\u00b7ses", "Gl\u00fcck", "soll", "dir", "auf", "sp\u00e4\u00b7te", "Zei\u00b7ten", "w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VMFIN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Er liebt den treuen Unterthan,", "tokens": ["Er", "liebt", "den", "treu\u00b7en", "Un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ha\u00dft nicht seiner L\u00e4nder Freude:", "tokens": ["Und", "ha\u00dft", "nicht", "sei\u00b7ner", "L\u00e4n\u00b7der", "Freu\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Handel schafft Er freye Bahn,", "tokens": ["Dem", "Han\u00b7del", "schafft", "Er", "frey\u00b7e", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sch\u00fctzt Pallas und Apoll, und kennt und liebt sie beyde.", "tokens": ["Sch\u00fctzt", "Pal\u00b7las", "und", "A\u00b7poll", ",", "und", "kennt", "und", "liebt", "sie", "bey\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "NN", "$,", "KON", "VVFIN", "KON", "VVFIN", "PPER", "PIS", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Auch selbst im Strafen zeigt Er Huld,", "tokens": ["Auch", "selbst", "im", "Stra\u00b7fen", "zeigt", "Er", "Huld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kann zitternder Verbrecher Schuld,", "tokens": ["Kann", "zit\u00b7tern\u00b7der", "Ver\u00b7bre\u00b7cher", "Schuld", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit Gro\u00dfmuth \u00fcbersehn und Feind und Neid besiegen.", "tokens": ["Mit", "Gro\u00df\u00b7muth", "\u00fc\u00b7ber\u00b7sehn", "und", "Feind", "und", "Neid", "be\u00b7sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "KON", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Wo hat ein Prinz so k\u00f6niglich,", "tokens": ["Wo", "hat", "ein", "Prinz", "so", "k\u00f6\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als Du bereits gethan, den neuen Thron bestiegen?", "tokens": ["Als", "Du", "be\u00b7reits", "ge\u00b7than", ",", "den", "neu\u00b7en", "Thron", "be\u00b7stie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "O Vaterland! wie dringt dein Heil", "tokens": ["O", "Va\u00b7ter\u00b7land", "!", "wie", "dringt", "dein", "Heil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PWAV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir jetzt durch Sinnen und Ge\u00e4der!", "tokens": ["Mir", "jetzt", "durch", "Sin\u00b7nen", "und", "Ge\u00b7\u00e4\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Herz nimmt selbst an allem Theil,", "tokens": ["Mein", "Herz", "nimmt", "selbst", "an", "al\u00b7lem", "Theil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Drum stockt vor reger Lust auch Einfall, Hand und Feder.", "tokens": ["Drum", "stockt", "vor", "re\u00b7ger", "Lust", "auch", "Ein\u00b7fall", ",", "Hand", "und", "Fe\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "ADJA", "NN", "ADV", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was sag ich viel? Dein Wohlseyn steigt,", "tokens": ["Was", "sag", "ich", "viel", "?", "Dein", "Wohl\u00b7seyn", "steigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da sich die\u00df ", "tokens": ["Da", "sich", "die\u00df"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PRF", "PDS"], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Das seinen holden Stral schon Land und Stadt gewiesen.", "tokens": ["Das", "sei\u00b7nen", "hol\u00b7den", "Stral", "schon", "Land", "und", "Stadt", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "ADJA", "NN", "ADV", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Einflu\u00df wirkt mit schneller Kraft:", "tokens": ["Sein", "Ein\u00b7flu\u00df", "wirkt", "mit", "schnel\u00b7ler", "Kraft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ist hier das Schweigen fehlerhaft;", "tokens": ["Ist", "hier", "das", "Schwei\u00b7gen", "feh\u00b7ler\u00b7haft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird doch, was Er thut, noch viel zu schwach gepriesen.", "tokens": ["So", "wird", "doch", ",", "was", "Er", "thut", ",", "noch", "viel", "zu", "schwach", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Genug, erfreute Pregelstadt!", "tokens": ["Ge\u00b7nug", ",", "er\u00b7freu\u00b7te", "Pre\u00b7gel\u00b7stadt", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df deine Musen besser singen,", "tokens": ["La\u00df", "dei\u00b7ne", "Mu\u00b7sen", "bes\u00b7ser", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und durch ein unzerst\u00f6rlich Blatt,", "tokens": ["Und", "durch", "ein", "un\u00b7zer\u00b7st\u00f6r\u00b7lich", "Blatt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem ", "tokens": ["Dem"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "O lebte Pietsch, dein Maro, noch!", "tokens": ["O", "leb\u00b7te", "Pietsch", ",", "dein", "Ma\u00b7ro", ",", "noch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$,", "PPOSAT", "NE", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie froh w\u00fcrd seine Clio doch", "tokens": ["Wie", "froh", "w\u00fcrd", "sei\u00b7ne", "Clio", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das Wachsthum deines Gl\u00fccks durch hohe Lieder ehren:", "tokens": ["Das", "Wach\u00b7sthum", "dei\u00b7nes", "Gl\u00fccks", "durch", "ho\u00b7he", "Lie\u00b7der", "eh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vorjetzt la\u00df nur mit froher Brust,", "tokens": ["Vor\u00b7jetzt", "la\u00df", "nur", "mit", "fro\u00b7her", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Auch au\u00dfer Deutschland, deine Lust,", "tokens": ["Auch", "au\u00b7\u00dfer", "Deutschland", ",", "dei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "Von der erfundnen Kunst der Druckerpressen h\u00f6ren.", "tokens": ["Von", "der", "er\u00b7fund\u00b7nen", "Kunst", "der", "Dru\u00b7cker\u00b7pres\u00b7sen", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Dein Reu\u00dfner selbst kann jetzt zugleich,", "tokens": ["Dein", "Reu\u00df\u00b7ner", "selbst", "kann", "jetzt", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VMFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein hundertj\u00e4hrig Fest begehen,", "tokens": ["Ein", "hun\u00b7dert\u00b7j\u00e4h\u00b7rig", "Fest", "be\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seit sein Geschlecht das Musenreich", "tokens": ["Seit", "sein", "Ge\u00b7schlecht", "das", "Mu\u00b7sen\u00b7reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bem\u00fcht und eifrig war durchs Drucken zu erh\u00f6hen.", "tokens": ["Be\u00b7m\u00fcht", "und", "eif\u00b7rig", "war", "durchs", "Dru\u00b7cken", "zu", "er\u00b7h\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "VAFIN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Freund! der Du Gott und Menschen dienst,", "tokens": ["Freund", "!", "der", "Du", "Gott", "und", "Men\u00b7schen", "dienst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PRELS", "PPER", "NN", "KON", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und selbst an Kunst und Wissen gr\u00fcnst,", "tokens": ["Und", "selbst", "an", "Kunst", "und", "Wis\u00b7sen", "gr\u00fcnst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nach alter Drucker Art, die selbst den Pindus kannten;", "tokens": ["Nach", "al\u00b7ter", "Dru\u00b7cker", "Art", ",", "die", "selbst", "den", "Pin\u00b7dus", "kann\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "PRELS", "ADV", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bl\u00fch stets auf Kind und Kindes Kind!", "tokens": ["Bl\u00fch", "stets", "auf", "Kind", "und", "Kin\u00b7des", "Kind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NN", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bis einst die Wesen Menschen sind,", "tokens": ["Bis", "einst", "die", "We\u00b7sen", "Men\u00b7schen", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die unsre Tage nur die sp\u00e4te Nachwelt nannten.", "tokens": ["Die", "uns\u00b7re", "Ta\u00b7ge", "nur", "die", "sp\u00e4\u00b7te", "Nach\u00b7welt", "nann\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Auf! eifre Sachsens K\u00fcnstlern nach,", "tokens": ["Auf", "!", "eif\u00b7re", "Sach\u00b7sens", "K\u00fcnst\u00b7lern", "nach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "ADJA", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sich der Barbarey entrissen;", "tokens": ["Die", "sich", "der", "Bar\u00b7ba\u00b7rey", "ent\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In deren Joch, der Zeit zur Schmach,", "tokens": ["In", "de\u00b7ren", "Joch", ",", "der", "Zeit", "zur", "Schmach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die edle Kunst sich j\u00fcngst ver\u00e4chtlich schmiegen m\u00fcssen.", "tokens": ["Die", "ed\u00b7le", "Kunst", "sich", "j\u00fcngst", "ver\u00b7\u00e4cht\u00b7lich", "schmie\u00b7gen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "ADV", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sieh unsers Breitkopfs Schriften an;", "tokens": ["Sieh", "un\u00b7sers", "Breit\u00b7kopfs", "Schrif\u00b7ten", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der \u00f6ffnete zuerst die Bahn,", "tokens": ["Der", "\u00f6ff\u00b7ne\u00b7te", "zu\u00b7erst", "die", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und trotzet itzt bereits der Elzevirer Pressen.", "tokens": ["Und", "trot\u00b7zet", "itzt", "be\u00b7reits", "der", "El\u00b7ze\u00b7vi\u00b7rer", "Pres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "O folg ihm nach! so wird die Welt,", "tokens": ["O", "folg", "ihm", "nach", "!", "so", "wird", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die einst auf sch\u00f6ne B\u00fccher h\u00e4lt,", "tokens": ["Die", "einst", "auf", "sch\u00f6\u00b7ne", "B\u00fc\u00b7cher", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wenig Dich, als Ihn, aus Dankbarkeit vergessen.", "tokens": ["So", "we\u00b7nig", "Dich", ",", "als", "Ihn", ",", "aus", "Dank\u00b7bar\u00b7keit", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "$,", "KOUS", "PPER", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}