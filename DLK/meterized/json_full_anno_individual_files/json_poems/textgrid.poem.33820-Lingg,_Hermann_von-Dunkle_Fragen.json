{"textgrid.poem.33820": {"metadata": {"author": {"name": "Lingg, Hermann von", "birth": "N.A.", "death": "N.A."}, "title": "Dunkle Fragen", "genre": "verse", "period": "N.A.", "pub_year": 1862, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vor\u00fcber war schon l\u00e4ngst die Stunde,", "tokens": ["Vor\u00b7\u00fc\u00b7ber", "war", "schon", "l\u00e4ngst", "die", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo sich der M\u00fcde schlafen legt,", "tokens": ["Wo", "sich", "der", "M\u00fc\u00b7de", "schla\u00b7fen", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da, fern von jeder frohen Stunde,", "tokens": ["Da", ",", "fern", "von", "je\u00b7der", "fro\u00b7hen", "Stun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da zechten wir noch tiefbewegt.", "tokens": ["Da", "zech\u00b7ten", "wir", "noch", "tief\u00b7be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Schon wob sich um die Lichtergarben", "tokens": ["Schon", "wob", "sich", "um", "die", "Lich\u00b7ter\u00b7gar\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stets n\u00e4her her die Finsternis", "tokens": ["Stets", "n\u00e4\u00b7her", "her", "die", "Fins\u00b7ter\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und brannt' in lang verharrschte Narben", "tokens": ["Und", "brannt'", "in", "lang", "ver\u00b7harrschte", "Nar\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Der alten Zweifel Schlangenbi\u00df.", "tokens": ["Der", "al\u00b7ten", "Zwei\u00b7fel", "Schlan\u00b7gen\u00b7bi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wir rechneten in langen Ziffern", "tokens": ["Wir", "rech\u00b7ne\u00b7ten", "in", "lan\u00b7gen", "Zif\u00b7fern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Der Sch\u00f6pfung ihre L\u00fccken vor,", "tokens": ["Der", "Sch\u00f6p\u00b7fung", "ih\u00b7re", "L\u00fc\u00b7cken", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis sich in magisch dunkle Chiffern", "tokens": ["Bis", "sich", "in", "ma\u00b7gisch", "dunk\u00b7le", "Chif\u00b7fern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das letzte Fragewort verlor.", "tokens": ["Das", "letz\u00b7te", "Fra\u00b7ge\u00b7wort", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wir konnten nicht den Zwiespalt l\u00f6sen,", "tokens": ["Wir", "konn\u00b7ten", "nicht", "den", "Zwies\u00b7palt", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der trotz des Herzens Widerstand", "tokens": ["Der", "trotz", "des", "Her\u00b7zens", "Wi\u00b7der\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch stets das Gute mit dem B\u00f6sen", "tokens": ["Doch", "stets", "das", "Gu\u00b7te", "mit", "dem", "B\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einem Weltgesetz verband.", "tokens": ["Zu", "ei\u00b7nem", "Welt\u00b7ge\u00b7setz", "ver\u00b7band", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Du stundest auf, die leere Flasche", "tokens": ["Du", "stun\u00b7dest", "auf", ",", "die", "lee\u00b7re", "Fla\u00b7sche"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sah hohl und umgest\u00fcrzt uns an,", "tokens": ["Sah", "hohl", "und", "um\u00b7ge\u00b7st\u00fcrzt", "uns", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Versch\u00fcttet von Zigarrenasche,", "tokens": ["Ver\u00b7sch\u00fct\u00b7tet", "von", "Zi\u00b7gar\u00b7ren\u00b7a\u00b7sche", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein ausgebrannter Weinvulkan.", "tokens": ["Ein", "aus\u00b7ge\u00b7brann\u00b7ter", "Wein\u00b7vul\u00b7kan", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und drau\u00dfen vor der dunklen Schwelle,", "tokens": ["Und", "drau\u00b7\u00dfen", "vor", "der", "dunk\u00b7len", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da lag die Welt im Nebeltau,", "tokens": ["Da", "lag", "die", "Welt", "im", "Ne\u00b7bel\u00b7tau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lag in d\u00fcstrer Morgenhelle,", "tokens": ["Und", "lag", "in", "d\u00fcst\u00b7rer", "Mor\u00b7gen\u00b7hel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In leichenfahlem D\u00e4mmergrau.", "tokens": ["In", "lei\u00b7chen\u00b7fah\u00b7lem", "D\u00e4m\u00b7mer\u00b7grau", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und als wir uns nun Abschied boten,", "tokens": ["Und", "als", "wir", "uns", "nun", "Ab\u00b7schied", "bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Noch war kein Leben sonst erwacht.", "tokens": ["Noch", "war", "kein", "Le\u00b7ben", "sonst", "er\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind Schl\u00e4fer, dacht' ich, nicht gleich Toten,", "tokens": ["Sind", "Schl\u00e4\u00b7fer", ",", "dacht'", "ich", ",", "nicht", "gleich", "To\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "VVFIN", "PPER", "$,", "PTKNEG", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Nichtsein ist nur eine Nacht?", "tokens": ["Und", "Nich\u00b7tsein", "ist", "nur", "ei\u00b7ne", "Nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und f\u00fchrt ein Weg durch Schlaf und Tr\u00e4ume", "tokens": ["Und", "f\u00fchrt", "ein", "Weg", "durch", "Schlaf", "und", "Tr\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vielleicht in andre Welten ein,", "tokens": ["Viel\u00b7leicht", "in", "and\u00b7re", "Wel\u00b7ten", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ins Innre nie geschauter R\u00e4ume,", "tokens": ["Ins", "Inn\u00b7re", "nie", "ge\u00b7schau\u00b7ter", "R\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In ein ins All Versunkensein?", "tokens": ["In", "ein", "ins", "All", "Ver\u00b7sun\u00b7ken\u00b7sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und dort scheint endlich sich zu l\u00f6sen", "tokens": ["Und", "dort", "scheint", "end\u00b7lich", "sich", "zu", "l\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kampf, der nie hier au\u00dfen ruht,", "tokens": ["Der", "Kampf", ",", "der", "nie", "hier", "au\u00b7\u00dfen", "ruht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der ew'ge Kampf vom Gut' und B\u00f6sen,", "tokens": ["Der", "ew'\u00b7ge", "Kampf", "vom", "Gut'", "und", "B\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Licht und Dunkel, Frost und Glut?", "tokens": ["Von", "Licht", "und", "Dun\u00b7kel", ",", "Frost", "und", "Glut", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Hier au\u00dfen nur ist Blutvergie\u00dfen,", "tokens": ["Hier", "au\u00b7\u00dfen", "nur", "ist", "Blut\u00b7ver\u00b7gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier sind die Schalen und der Dorn,", "tokens": ["Hier", "sind", "die", "Scha\u00b7len", "und", "der", "Dorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und doch strebt alles aufzusprie\u00dfen", "tokens": ["Und", "doch", "strebt", "al\u00b7les", "auf\u00b7zu\u00b7sprie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus H\u00fclle, Schlaf und Saatenkorn.", "tokens": ["Aus", "H\u00fcl\u00b7le", ",", "Schlaf", "und", "Saa\u00b7ten\u00b7korn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Zur K\u00f6rperwelt hervorzudringen,", "tokens": ["Zur", "K\u00f6r\u00b7per\u00b7welt", "her\u00b7vor\u00b7zu\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Str\u00f6mt ewig aus die ruh'nde Kraft,", "tokens": ["Str\u00f6mt", "e\u00b7wig", "aus", "die", "ruh'n\u00b7de", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mit dem Feind sich abzuringen,", "tokens": ["Und", "mit", "dem", "Feind", "sich", "ab\u00b7zu\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch den sie wieder wird entrafft.", "tokens": ["Durch", "den", "sie", "wie\u00b7der", "wird", "en\u00b7trafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Was ist der Zweck von all dem Streben?", "tokens": ["Was", "ist", "der", "Zweck", "von", "all", "dem", "Stre\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "APPR", "PIAT", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nur ein sich selbst gen\u00fcgend Spiel?", "tokens": ["Nur", "ein", "sich", "selbst", "ge\u00b7n\u00fc\u00b7gend", "Spiel", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PRF", "ADV", "VVPP", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie, oder hat vielleicht das Leben", "tokens": ["Wie", ",", "o\u00b7der", "hat", "viel\u00b7leicht", "das", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KON", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein unbekanntes gro\u00dfes Ziel?", "tokens": ["Ein", "un\u00b7be\u00b7kann\u00b7tes", "gro\u00b7\u00dfes", "Ziel", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Vor\u00fcber war schon l\u00e4ngst die Stunde,", "tokens": ["Vor\u00b7\u00fc\u00b7ber", "war", "schon", "l\u00e4ngst", "die", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo sich der M\u00fcde schlafen legt,", "tokens": ["Wo", "sich", "der", "M\u00fc\u00b7de", "schla\u00b7fen", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da, fern von jeder frohen Stunde,", "tokens": ["Da", ",", "fern", "von", "je\u00b7der", "fro\u00b7hen", "Stun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da zechten wir noch tiefbewegt.", "tokens": ["Da", "zech\u00b7ten", "wir", "noch", "tief\u00b7be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Schon wob sich um die Lichtergarben", "tokens": ["Schon", "wob", "sich", "um", "die", "Lich\u00b7ter\u00b7gar\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stets n\u00e4her her die Finsternis", "tokens": ["Stets", "n\u00e4\u00b7her", "her", "die", "Fins\u00b7ter\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und brannt' in lang verharrschte Narben", "tokens": ["Und", "brannt'", "in", "lang", "ver\u00b7harrschte", "Nar\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Der alten Zweifel Schlangenbi\u00df.", "tokens": ["Der", "al\u00b7ten", "Zwei\u00b7fel", "Schlan\u00b7gen\u00b7bi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Wir rechneten in langen Ziffern", "tokens": ["Wir", "rech\u00b7ne\u00b7ten", "in", "lan\u00b7gen", "Zif\u00b7fern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Der Sch\u00f6pfung ihre L\u00fccken vor,", "tokens": ["Der", "Sch\u00f6p\u00b7fung", "ih\u00b7re", "L\u00fc\u00b7cken", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis sich in magisch dunkle Chiffern", "tokens": ["Bis", "sich", "in", "ma\u00b7gisch", "dunk\u00b7le", "Chif\u00b7fern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das letzte Fragewort verlor.", "tokens": ["Das", "letz\u00b7te", "Fra\u00b7ge\u00b7wort", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wir konnten nicht den Zwiespalt l\u00f6sen,", "tokens": ["Wir", "konn\u00b7ten", "nicht", "den", "Zwies\u00b7palt", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der trotz des Herzens Widerstand", "tokens": ["Der", "trotz", "des", "Her\u00b7zens", "Wi\u00b7der\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch stets das Gute mit dem B\u00f6sen", "tokens": ["Doch", "stets", "das", "Gu\u00b7te", "mit", "dem", "B\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einem Weltgesetz verband.", "tokens": ["Zu", "ei\u00b7nem", "Welt\u00b7ge\u00b7setz", "ver\u00b7band", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Du stundest auf, die leere Flasche", "tokens": ["Du", "stun\u00b7dest", "auf", ",", "die", "lee\u00b7re", "Fla\u00b7sche"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sah hohl und umgest\u00fcrzt uns an,", "tokens": ["Sah", "hohl", "und", "um\u00b7ge\u00b7st\u00fcrzt", "uns", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Versch\u00fcttet von Zigarrenasche,", "tokens": ["Ver\u00b7sch\u00fct\u00b7tet", "von", "Zi\u00b7gar\u00b7ren\u00b7a\u00b7sche", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein ausgebrannter Weinvulkan.", "tokens": ["Ein", "aus\u00b7ge\u00b7brann\u00b7ter", "Wein\u00b7vul\u00b7kan", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Und drau\u00dfen vor der dunklen Schwelle,", "tokens": ["Und", "drau\u00b7\u00dfen", "vor", "der", "dunk\u00b7len", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da lag die Welt im Nebeltau,", "tokens": ["Da", "lag", "die", "Welt", "im", "Ne\u00b7bel\u00b7tau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lag in d\u00fcstrer Morgenhelle,", "tokens": ["Und", "lag", "in", "d\u00fcst\u00b7rer", "Mor\u00b7gen\u00b7hel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In leichenfahlem D\u00e4mmergrau.", "tokens": ["In", "lei\u00b7chen\u00b7fah\u00b7lem", "D\u00e4m\u00b7mer\u00b7grau", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Und als wir uns nun Abschied boten,", "tokens": ["Und", "als", "wir", "uns", "nun", "Ab\u00b7schied", "bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Noch war kein Leben sonst erwacht.", "tokens": ["Noch", "war", "kein", "Le\u00b7ben", "sonst", "er\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind Schl\u00e4fer, dacht' ich, nicht gleich Toten,", "tokens": ["Sind", "Schl\u00e4\u00b7fer", ",", "dacht'", "ich", ",", "nicht", "gleich", "To\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "VVFIN", "PPER", "$,", "PTKNEG", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Nichtsein ist nur eine Nacht?", "tokens": ["Und", "Nich\u00b7tsein", "ist", "nur", "ei\u00b7ne", "Nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Und f\u00fchrt ein Weg durch Schlaf und Tr\u00e4ume", "tokens": ["Und", "f\u00fchrt", "ein", "Weg", "durch", "Schlaf", "und", "Tr\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vielleicht in andre Welten ein,", "tokens": ["Viel\u00b7leicht", "in", "and\u00b7re", "Wel\u00b7ten", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ins Innre nie geschauter R\u00e4ume,", "tokens": ["Ins", "Inn\u00b7re", "nie", "ge\u00b7schau\u00b7ter", "R\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In ein ins All Versunkensein?", "tokens": ["In", "ein", "ins", "All", "Ver\u00b7sun\u00b7ken\u00b7sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und dort scheint endlich sich zu l\u00f6sen", "tokens": ["Und", "dort", "scheint", "end\u00b7lich", "sich", "zu", "l\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kampf, der nie hier au\u00dfen ruht,", "tokens": ["Der", "Kampf", ",", "der", "nie", "hier", "au\u00b7\u00dfen", "ruht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der ew'ge Kampf vom Gut' und B\u00f6sen,", "tokens": ["Der", "ew'\u00b7ge", "Kampf", "vom", "Gut'", "und", "B\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Licht und Dunkel, Frost und Glut?", "tokens": ["Von", "Licht", "und", "Dun\u00b7kel", ",", "Frost", "und", "Glut", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Hier au\u00dfen nur ist Blutvergie\u00dfen,", "tokens": ["Hier", "au\u00b7\u00dfen", "nur", "ist", "Blut\u00b7ver\u00b7gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier sind die Schalen und der Dorn,", "tokens": ["Hier", "sind", "die", "Scha\u00b7len", "und", "der", "Dorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und doch strebt alles aufzusprie\u00dfen", "tokens": ["Und", "doch", "strebt", "al\u00b7les", "auf\u00b7zu\u00b7sprie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus H\u00fclle, Schlaf und Saatenkorn.", "tokens": ["Aus", "H\u00fcl\u00b7le", ",", "Schlaf", "und", "Saa\u00b7ten\u00b7korn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Zur K\u00f6rperwelt hervorzudringen,", "tokens": ["Zur", "K\u00f6r\u00b7per\u00b7welt", "her\u00b7vor\u00b7zu\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Str\u00f6mt ewig aus die ruh'nde Kraft,", "tokens": ["Str\u00f6mt", "e\u00b7wig", "aus", "die", "ruh'n\u00b7de", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mit dem Feind sich abzuringen,", "tokens": ["Und", "mit", "dem", "Feind", "sich", "ab\u00b7zu\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch den sie wieder wird entrafft.", "tokens": ["Durch", "den", "sie", "wie\u00b7der", "wird", "en\u00b7trafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Was ist der Zweck von all dem Streben?", "tokens": ["Was", "ist", "der", "Zweck", "von", "all", "dem", "Stre\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "APPR", "PIAT", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nur ein sich selbst gen\u00fcgend Spiel?", "tokens": ["Nur", "ein", "sich", "selbst", "ge\u00b7n\u00fc\u00b7gend", "Spiel", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PRF", "ADV", "VVPP", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie, oder hat vielleicht das Leben", "tokens": ["Wie", ",", "o\u00b7der", "hat", "viel\u00b7leicht", "das", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KON", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein unbekanntes gro\u00dfes Ziel?", "tokens": ["Ein", "un\u00b7be\u00b7kann\u00b7tes", "gro\u00b7\u00dfes", "Ziel", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}