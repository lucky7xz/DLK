{"textgrid.poem.32578": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "An die durchlauchtigste Herzogin Anna Amalia", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was hab ich, leider! ohne Frucht", "tokens": ["Was", "hab", "ich", ",", "lei\u00b7der", "!", "oh\u00b7ne", "Frucht"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "$,", "ADV", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "an diesem Abend nicht versucht,", "tokens": ["an", "die\u00b7sem", "A\u00b7bend", "nicht", "ver\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "um, meiner F\u00fcrstin zu Preis und Ehren,", "tokens": ["um", ",", "mei\u00b7ner", "F\u00fcrs\u00b7tin", "zu", "Preis", "und", "Eh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "$,", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "in dieser Gratulantenzeit", "tokens": ["in", "die\u00b7ser", "Gra\u00b7tu\u00b7lan\u00b7ten\u00b7zeit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die dreimal drei Kastalische D\u00f6ren", "tokens": ["die", "drei\u00b7mal", "drei", "Kas\u00b7ta\u00b7li\u00b7sche", "D\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "CARD", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "zu einem Liede zu beschw\u00f6ren?", "tokens": ["zu", "ei\u00b7nem", "Lie\u00b7de", "zu", "be\u00b7schw\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und weil die Musen sonder Streit", "tokens": ["Und", "weil", "die", "Mu\u00b7sen", "son\u00b7der", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "zur guten Geisterschar geh\u00f6ren,", "tokens": ["zur", "gu\u00b7ten", "Geis\u00b7ter\u00b7schar", "ge\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "die man (wie Doctor Obereit", "tokens": ["die", "man", "(", "wie", "Doc\u00b7tor", "O\u00b7be\u00b7reit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIS", "$(", "KOKOM", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "und andre weise M\u00e4nner lehren)", "tokens": ["und", "and\u00b7re", "wei\u00b7se", "M\u00e4n\u00b7ner", "leh\u00b7ren", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "durch ", "tokens": ["durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.12": {"text": "griff ich das Werk mit ", "tokens": ["griff", "ich", "das", "Werk", "mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "go\u00df Storax und Borax, Musk und Mazis,", "tokens": ["go\u00df", "Sto\u00b7rax", "und", "Bo\u00b7rax", ",", "Musk", "und", "Ma\u00b7zis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "NE", "$,", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "und Jusquiam und Alo\u00ebs", "tokens": ["und", "Jus\u00b7qui\u00b7am", "und", "A\u00b7lo\u00ebs"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "und sieben andre Species", "tokens": ["und", "sie\u00b7ben", "and\u00b7re", "Spe\u00b7cies"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "CARD", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "die Avicenna, Psellus und Razis", "tokens": ["die", "A\u00b7vi\u00b7cen\u00b7na", ",", "Psel\u00b7lus", "und", "Ra\u00b7zis"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "uns vorgeschrieben, auf Kohlenglut", "tokens": ["uns", "vor\u00b7ge\u00b7schrie\u00b7ben", ",", "auf", "Koh\u00b7len\u00b7glut"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVPP", "$,", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "in vollem Glauben und festem Mut,", "tokens": ["in", "vol\u00b7lem", "Glau\u00b7ben", "und", "fes\u00b7tem", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "die vorbesagten Kastalischen Feen", "tokens": ["die", "vor\u00b7be\u00b7sag\u00b7ten", "Kas\u00b7ta\u00b7li\u00b7schen", "Feen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "leibhaftig, alle drei zumal,", "tokens": ["leib\u00b7haf\u00b7tig", ",", "al\u00b7le", "drei", "zu\u00b7mal", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIAT", "CARD", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.21": {"text": "vor meinem Pult erscheinen zu sehen.", "tokens": ["vor", "mei\u00b7nem", "Pult", "er\u00b7schei\u00b7nen", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Der Rauch stieg, wie zu Alpenh\u00f6hen", "tokens": ["Der", "Rauch", "stieg", ",", "wie", "zu", "Al\u00b7pen\u00b7h\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "ein Nebel aus einem engen Tal,", "tokens": ["ein", "Ne\u00b7bel", "aus", "ei\u00b7nem", "en\u00b7gen", "Tal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "in Wolken hoch zum Sternensaal", "tokens": ["in", "Wol\u00b7ken", "hoch", "zum", "Ster\u00b7nen\u00b7saal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "empor \u2013 Allein, bei allen Busen", "tokens": ["em\u00b7por", "\u2013", "Al\u00b7lein", ",", "bei", "al\u00b7len", "Bu\u00b7sen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKVZ", "$(", "ADV", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "der gro\u00dfen Diana zu Ephesus!", "tokens": ["der", "gro\u00b7\u00dfen", "Di\u00b7a\u00b7na", "zu", "E\u00b7phe\u00b7sus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "APPR", "NE", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.27": {"text": "wer, mir zum bittersten Verdru\u00df,", "tokens": ["wer", ",", "mir", "zum", "bit\u00b7ters\u00b7ten", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.28": {"text": "nicht kam \u2013 das waren meine Musen.", "tokens": ["nicht", "kam", "\u2013", "das", "wa\u00b7ren", "mei\u00b7ne", "Mu\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$(", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Itzt fing mir, wie ich sagen mu\u00df,", "tokens": ["Itzt", "fing", "mir", ",", "wie", "ich", "sa\u00b7gen", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die Galle m\u00e4chtig an zu sprudeln.", "tokens": ["die", "Gal\u00b7le", "m\u00e4ch\u00b7tig", "an", "zu", "spru\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbnein!\u00ab rief ich, in meinem Zorn, \u00bbbeim Styx!", "tokens": ["\u00bb", "nein", "!", "\u00ab", "rief", "ich", ",", "in", "mei\u00b7nem", "Zorn", ",", "\u00bb", "beim", "Styx", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$.", "$(", "VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "$(", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "So sollen die Jungfern mich nicht hudeln!", "tokens": ["So", "sol\u00b7len", "die", "Jung\u00b7fern", "mich", "nicht", "hu\u00b7deln", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Erscheinen sie nicht augenblicks,", "tokens": ["Er\u00b7schei\u00b7nen", "sie", "nicht", "au\u00b7gen\u00b7blicks", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit einem demutsvollen Knicks", "tokens": ["mit", "ei\u00b7nem", "de\u00b7muts\u00b7vol\u00b7len", "Knicks"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "ihr bestes Lied mir vorzududeln:", "tokens": ["ihr", "bes\u00b7tes", "Lied", "mir", "vor\u00b7zu\u00b7du\u00b7deln", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "so soll, ich schw\u00f6rs beim Wunderzahn", "tokens": ["so", "soll", ",", "ich", "schw\u00f6rs", "beim", "Wun\u00b7der\u00b7zahn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "$,", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "des Obermeisters aller Affen,", "tokens": ["des", "O\u00b7ber\u00b7meis\u00b7ters", "al\u00b7ler", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "beim gro\u00dfen Zaubrer Hanneman,", "tokens": ["beim", "gro\u00b7\u00dfen", "Zaub\u00b7rer", "Han\u00b7ne\u00b7man", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "so soll Hans Faust mir Recht verschaffen!\u00ab", "tokens": ["so", "soll", "Hans", "Faust", "mir", "Recht", "ver\u00b7schaf\u00b7fen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "NE", "NN", "PPER", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wiewohl ich mit Herrn Urian", "tokens": ["Wie\u00b7wohl", "ich", "mit", "Herrn", "U\u00b7ri\u00b7an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "sonst auf dem besten Fu\u00df nicht stehe,", "tokens": ["sonst", "auf", "dem", "bes\u00b7ten", "Fu\u00df", "nicht", "ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "und, weil er mir von Jugend an", "tokens": ["und", ",", "weil", "er", "mir", "von", "Ju\u00b7gend", "an"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "APPR", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "schon manchen b\u00f6sen T\u00fcck getan,", "tokens": ["schon", "man\u00b7chen", "b\u00f6\u00b7sen", "T\u00fcck", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "ihm sonst gern aus dem Wege gehe,", "tokens": ["ihm", "sonst", "gern", "aus", "dem", "We\u00b7ge", "ge\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "f\u00fcr diesmal bringt die Not mich dran.", "tokens": ["f\u00fcr", "dies\u00b7mal", "bringt", "die", "Not", "mich", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Es schl\u00e4gt schon Eins! Bald kr\u00e4ht der Hahn", "tokens": ["Es", "schl\u00e4gt", "schon", "Eins", "!", "Bald", "kr\u00e4ht", "der", "Hahn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$.", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "und auch ein Blatt nur voll zu reimen", "tokens": ["und", "auch", "ein", "Blatt", "nur", "voll", "zu", "rei\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "ist keine Minute zu vers\u00e4umen.", "tokens": ["ist", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "ver\u00b7s\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Zwar mu\u00df ich bekennen, ", "tokens": ["Zwar", "mu\u00df", "ich", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "mir ward ein wenig gr\u00fcn und blau", "tokens": ["mir", "ward", "ein", "we\u00b7nig", "gr\u00fcn", "und", "blau"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "PIS", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "vorm Auge, da ich den ersten Bogen", "tokens": ["vorm", "Au\u00b7ge", ",", "da", "ich", "den", "ers\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "zum Zauberkreis um mich gezogen.", "tokens": ["zum", "Zau\u00b7ber\u00b7kreis", "um", "mich", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Allein nun war der Rubicon", "tokens": ["Al\u00b7lein", "nun", "war", "der", "Ru\u00b7bi\u00b7con"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "passiert, und nennt mir den Haymons Sohn", "tokens": ["pas\u00b7siert", ",", "und", "nennt", "mir", "den", "Hay\u00b7mons", "Sohn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "dem nicht das Herz, wenn's Ernst gilt, schlottert!", "tokens": ["dem", "nicht", "das", "Herz", ",", "wenn's", "Ernst", "gilt", ",", "schlot\u00b7tert", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PTKNEG", "ART", "NN", "$,", "KOUS", "NE", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Genug, ich stund in meinem Kreis", "tokens": ["Ge\u00b7nug", ",", "ich", "stund", "in", "mei\u00b7nem", "Kreis"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "und las \u2013 zwar freilich ein wenig leis \u2013", "tokens": ["und", "las", "\u2013", "zwar", "frei\u00b7lich", "ein", "we\u00b7nig", "leis", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "ADV", "ADV", "ART", "PIS", "ADJD", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "(mit unter ward auch wohl gestottert)", "tokens": ["(", "mit", "un\u00b7ter", "ward", "auch", "wohl", "ge\u00b7stot\u00b7tert", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "APPR", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "mit hochemporgehaltnem Stab", "tokens": ["mit", "hoc\u00b7hem\u00b7por\u00b7ge\u00b7halt\u00b7nem", "Stab"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "den ganzen ", "tokens": ["den", "gan\u00b7zen"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "durch den sonst, wie wir alle wissen,", "tokens": ["durch", "den", "sonst", ",", "wie", "wir", "al\u00b7le", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "$,", "PWAV", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "die Geister unterm Monde stracks", "tokens": ["die", "Geis\u00b7ter", "un\u00b7term", "Mon\u00b7de", "stracks"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "auf allen Vieren, wie ein Dachs,", "tokens": ["auf", "al\u00b7len", "Vie\u00b7ren", ",", "wie", "ein", "Dachs", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "herangekrochen kommen m\u00fcssen.", "tokens": ["her\u00b7an\u00b7ge\u00b7kro\u00b7chen", "kom\u00b7men", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Allein, wo auch der Fehler gesteckt,", "tokens": ["Al\u00b7lein", ",", "wo", "auch", "der", "Feh\u00b7ler", "ge\u00b7steckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "das Zauberwerk blieb ohne Effekt.", "tokens": ["das", "Zau\u00b7ber\u00b7werk", "blieb", "oh\u00b7ne", "Ef\u00b7fekt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Zitieren kann jeder die Geister freilich;", "tokens": ["Zi\u00b7tie\u00b7ren", "kann", "je\u00b7der", "die", "Geis\u00b7ter", "frei\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ART", "NN", "ADV", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "doch, ob sie kommen wollen, das steht", "tokens": ["doch", ",", "ob", "sie", "kom\u00b7men", "wol\u00b7len", ",", "das", "steht"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "PDS", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "bei ihnen! \u2013 \u00bbUngl\u00fccklicher Poet!", "tokens": ["bei", "ih\u00b7nen", "!", "\u2013", "\u00bb", "Un\u00b7gl\u00fcck\u00b7li\u00b7cher", "Po\u00b7et", "!"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$.", "$(", "$(", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Ist dies dein Lohn? So lang und treulich", "tokens": ["Ist", "dies", "dein", "Lohn", "?", "So", "lang", "und", "treu\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "PPOSAT", "NN", "$.", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "dienst du den Hexen vom Helikon", "tokens": ["dienst", "du", "den", "He\u00b7xen", "vom", "He\u00b7li\u00b7kon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.24": {"text": "wohl sechs und drei\u00dfig Jahre schon", "tokens": ["wohl", "sechs", "und", "drei\u00b7\u00dfig", "Jah\u00b7re", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "KON", "CARD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "und dr\u00fcber! Hast so treubeflissen", "tokens": ["und", "dr\u00fc\u00b7ber", "!", "Hast", "so", "treu\u00b7be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PAV", "$.", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "so manchen sch\u00f6nen G\u00e4nsekiel", "tokens": ["so", "man\u00b7chen", "sch\u00f6\u00b7nen", "G\u00e4n\u00b7se\u00b7kiel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "in ihrem sauren Dienst zerbissen,", "tokens": ["in", "ih\u00b7rem", "sau\u00b7ren", "Dienst", "zer\u00b7bis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "so manche Stanze gedreht, soviel", "tokens": ["so", "man\u00b7che", "Stan\u00b7ze", "ge\u00b7dreht", ",", "so\u00b7viel"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,", "XY"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "nach Reimen, wie Kakadus nach N\u00fcssen,", "tokens": ["nach", "Rei\u00b7men", ",", "wie", "Ka\u00b7ka\u00b7dus", "nach", "N\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "NE", "APPR", "NE", "$,"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.30": {"text": "und Baham nach Fliegen, haschen m\u00fcssen,", "tokens": ["und", "Ba\u00b7ham", "nach", "Flie\u00b7gen", ",", "ha\u00b7schen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "$,", "VVINF", "VMINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "und ach! so manches Ries Papier", "tokens": ["und", "ach", "!", "so", "man\u00b7ches", "Ries", "Pa\u00b7pier"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "ADV", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "f\u00fcr sie besudelt und zerrissen,", "tokens": ["f\u00fcr", "sie", "be\u00b7su\u00b7delt", "und", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "und das ist nun der Dank daf\u00fcr!\u00ab", "tokens": ["und", "das", "ist", "nun", "der", "Dank", "da\u00b7f\u00fcr", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ART", "NN", "PAV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "So rief ich mit gesenkten Ohren,", "tokens": ["So", "rief", "ich", "mit", "ge\u00b7senk\u00b7ten", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "allein die Musen h\u00f6rten's nicht;", "tokens": ["al\u00b7lein", "die", "Mu\u00b7sen", "h\u00f6r\u00b7ten's", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "und, Zauber, Rauchwerk, \u00d6l und Licht", "tokens": ["und", ",", "Zau\u00b7ber", ",", "Rauch\u00b7werk", ",", "\u00d6l", "und", "Licht"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "kurz, Malz und Hopfen war verloren!", "tokens": ["kurz", ",", "Malz", "und", "Hop\u00b7fen", "war", "ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NE", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ja freilich im ganzen Heiligen Reich", "tokens": ["Ja", "frei\u00b7lich", "im", "gan\u00b7zen", "Hei\u00b7li\u00b7gen", "Reich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "APPRART", "ADJA", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "ist diesen eigensinnigen Miezen", "tokens": ["ist", "die\u00b7sen", "ei\u00b7gen\u00b7sin\u00b7ni\u00b7gen", "Mie\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "von alten zieraffischen Cantatrizen", "tokens": ["von", "al\u00b7ten", "zier\u00b7af\u00b7fi\u00b7schen", "Can\u00b7ta\u00b7tri\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "kein Maid of Honour an Laune gleich.", "tokens": ["kein", "Maid", "of", "Ho\u00b7nour", "an", "Lau\u00b7ne", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NE", "NE", "APPR", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ich m\u00f6chte wie Orlando rasen,", "tokens": ["Ich", "m\u00f6ch\u00b7te", "wie", "Or\u00b7lan\u00b7do", "ra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KOKOM", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "wenn ich bedenke, wie leicht es auch", "tokens": ["wenn", "ich", "be\u00b7den\u00b7ke", ",", "wie", "leicht", "es", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPER", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "den M\u00e4dchen war, mit Einem Hauch", "tokens": ["den", "M\u00e4d\u00b7chen", "war", ",", "mit", "Ei\u00b7nem", "Hauch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "die sch\u00f6nsten Verse mir einzublasen!", "tokens": ["die", "sch\u00f6ns\u00b7ten", "Ver\u00b7se", "mir", "ein\u00b7zu\u00b7bla\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Nun sitz ich, sauge wie ein Gauch", "tokens": ["Nun", "sitz", "ich", ",", "sau\u00b7ge", "wie", "ein", "Gauch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "$,", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "am Daumen, ziehe mich bei der Nasen,", "tokens": ["am", "Dau\u00b7men", ",", "zie\u00b7he", "mich", "bei", "der", "Na\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "kratz hinterm Ohr, reib an der Stirne,", "tokens": ["kratz", "hin\u00b7term", "Ohr", ",", "reib", "an", "der", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "und strapaziere mein Gehirne", "tokens": ["und", "stra\u00b7pa\u00b7zie\u00b7re", "mein", "Ge\u00b7hir\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "und melkte doch eher von einem Bock", "tokens": ["und", "melk\u00b7te", "doch", "e\u00b7her", "von", "ei\u00b7nem", "Bock"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "APPR", "ART", "NE"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "den besten Wein aus Languedoc", "tokens": ["den", "bes\u00b7ten", "Wein", "aus", "Lan\u00b7gue\u00b7doc"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "als einen einzigen Fingerhut", "tokens": ["als", "ei\u00b7nen", "ein\u00b7zi\u00b7gen", "Fin\u00b7ger\u00b7hut"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "voll Witz aus meinem Occiput.", "tokens": ["voll", "Witz", "aus", "mei\u00b7nem", "Oc\u00b7ci\u00b7put", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was nun zu machen? Allenfalls", "tokens": ["Was", "nun", "zu", "ma\u00b7chen", "?", "Al\u00b7len\u00b7falls"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "ADV", "PTKZU", "VVINF", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gleich einem Schwan mit langem Hals", "tokens": ["gleich", "ei\u00b7nem", "Schwan", "mit", "lan\u00b7gem", "Hals"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "was am Gesange fehlt durch Heulen", "tokens": ["was", "am", "Ge\u00b7san\u00b7ge", "fehlt", "durch", "Heu\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPRART", "NN", "VVFIN", "APPR", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "ersetzen? Wir w\u00fcrden die Ehre zwar", "tokens": ["er\u00b7set\u00b7zen", "?", "Wir", "w\u00fcr\u00b7den", "die", "Eh\u00b7re", "zwar"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVINF", "$.", "PPER", "VAFIN", "ART", "NN", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Mit mancher ", "tokens": ["Mit", "man\u00b7cher"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "doch scheint in solchen F\u00e4llen klar,", "tokens": ["doch", "scheint", "in", "sol\u00b7chen", "F\u00e4l\u00b7len", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "das Kl\u00fcgste sei zum Schlusse zu eilen;", "tokens": ["das", "Kl\u00fcgs\u00b7te", "sei", "zum", "Schlus\u00b7se", "zu", "ei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "denn Heulen quadriert doch nur auf Eulen,", "tokens": ["denn", "Heu\u00b7len", "quad\u00b7riert", "doch", "nur", "auf", "Eu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "ADV", "APPR", "NE", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "und Persiflieren bringt Gefahr.", "tokens": ["und", "Per\u00b7sif\u00b7lie\u00b7ren", "bringt", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Drum w\u00fcnsch ich ohne l\u00e4ngeres Weilen", "tokens": ["Drum", "w\u00fcnsch", "ich", "oh\u00b7ne", "l\u00e4n\u00b7ge\u00b7res", "Wei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "mit diesen treugemeinten Zeilen", "tokens": ["mit", "die\u00b7sen", "treu\u00b7ge\u00b7mein\u00b7ten", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Drei hundert F\u00fcnf und Sechzig Tage,", "tokens": ["Drei", "hun\u00b7dert", "F\u00fcnf", "und", "Sech\u00b7zig", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "CARD", "KON", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "an denen von der ganzen Schar", "tokens": ["an", "de\u00b7nen", "von", "der", "gan\u00b7zen", "Schar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "der magern Sorgen keine nage:", "tokens": ["der", "ma\u00b7gern", "Sor\u00b7gen", "kei\u00b7ne", "na\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "auf jeden Tag an reinem Ertrage", "tokens": ["auf", "je\u00b7den", "Tag", "an", "rei\u00b7nem", "Er\u00b7tra\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "stets volle vier und zwanzig Stunden", "tokens": ["stets", "vol\u00b7le", "vier", "und", "zwan\u00b7zig", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "CARD", "KON", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "die Stunde zu Sechzig Minuten gez\u00e4hlt,", "tokens": ["die", "Stun\u00b7de", "zu", "Sech\u00b7zig", "Mi\u00b7nu\u00b7ten", "ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.18": {"text": "und jede Minute zu Sechzig Secunden,", "tokens": ["und", "je\u00b7de", "Mi\u00b7nu\u00b7te", "zu", "Sech\u00b7zig", "Se\u00b7cun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.19": {"text": "und jede Secunde, da\u00df keine fehlt,", "tokens": ["und", "je\u00b7de", "Se\u00b7cun\u00b7de", ",", "da\u00df", "kei\u00b7ne", "fehlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "KOUS", "PIAT", "VVFIN", "$,"], "meter": "-+-----+-+", "measure": "dactylic.init"}, "line.20": {"text": "von einem reinen Genu\u00df beseelt,", "tokens": ["von", "ei\u00b7nem", "rei\u00b7nen", "Ge\u00b7nu\u00df", "be\u00b7seelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "mit etwas dessen man gerne sich wieder", "tokens": ["mit", "et\u00b7was", "des\u00b7sen", "man", "ger\u00b7ne", "sich", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "PDS", "PIS", "ADV", "PRF", "ADV"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "erinnert wenn alles andre fehlt,", "tokens": ["e\u00b7rin\u00b7nert", "wenn", "al\u00b7les", "and\u00b7re", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "PIS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.23": {"text": "und frei von allem was Seel und Glieder", "tokens": ["und", "frei", "von", "al\u00b7lem", "was", "Seel", "und", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PIS", "PWS", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "was Augen, Ohren und \u2013 F\u00fc\u00dfe qu\u00e4lt.", "tokens": ["was", "Au\u00b7gen", ",", "Oh\u00b7ren", "und", "\u2013", "F\u00fc\u00b7\u00dfe", "qu\u00e4lt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "NN", "KON", "$(", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Im \u00fcbrigen ist, zumal im Gr\u00fcnen", "tokens": ["Im", "\u00fcb\u00b7ri\u00b7gen", "ist", ",", "zu\u00b7mal", "im", "Gr\u00fc\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN", "$,", "KOUS", "APPRART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "von Longus und von Lucian", "tokens": ["von", "Lon\u00b7gus", "und", "von", "Lu\u00b7ci\u00b7an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "als Kammerjunkern sich bedienen", "tokens": ["als", "Kam\u00b7mer\u00b7jun\u00b7kern", "sich", "be\u00b7die\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zu lassen, immer wohlgetan.", "tokens": ["zu", "las\u00b7sen", ",", "im\u00b7mer", "wohl\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zwar sind die Herren, an denen man", "tokens": ["Zwar", "sind", "die", "Her\u00b7ren", ",", "an", "de\u00b7nen", "man"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "PIS"], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.6": {"text": "sich schon zweitausend Jahre zu Tode", "tokens": ["sich", "schon", "zweit\u00b7au\u00b7send", "Jah\u00b7re", "zu", "To\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADV", "CARD", "NN", "APPR", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "gelesen, ein wenig aus der Mode;", "tokens": ["ge\u00b7le\u00b7sen", ",", "ein", "we\u00b7nig", "aus", "der", "Mo\u00b7de", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ART", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "doch immer f\u00fcr eine Episode", "tokens": ["doch", "im\u00b7mer", "f\u00fcr", "ei\u00b7ne", "E\u00b7pi\u00b7so\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "noch gut genug, und haben auch", "tokens": ["noch", "gut", "ge\u00b7nug", ",", "und", "ha\u00b7ben", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "$,", "KON", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "vor andern edeln Kammertieren", "tokens": ["vor", "an\u00b7dern", "e\u00b7deln", "Kam\u00b7mer\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "die Tugend und den l\u00f6blichen Brauch", "tokens": ["die", "Tu\u00b7gend", "und", "den", "l\u00f6b\u00b7li\u00b7chen", "Brauch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "die F\u00fcrsten nicht l\u00e4nger zu ennuyieren", "tokens": ["die", "F\u00fcrs\u00b7ten", "nicht", "l\u00e4n\u00b7ger", "zu", "en\u00b7nu\u00b7yie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "ADJD", "PTKZU", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "als Ihnen selbst belieben mag.", "tokens": ["als", "Ih\u00b7nen", "selbst", "be\u00b7lie\u00b7ben", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Das \u00fcbrige alles was dieser Tag", "tokens": ["Das", "\u00fcb\u00b7ri\u00b7ge", "al\u00b7les", "was", "die\u00b7ser", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "PIS", "PWS", "PDAT", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "zu w\u00fcnschen pflegt, sei den Najaden", "tokens": ["zu", "w\u00fcn\u00b7schen", "pflegt", ",", "sei", "den", "Na\u00b7ja\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VVFIN", "$,", "VAFIN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.16": {"text": "Sylphiden, Dryaden und Oreaden", "tokens": ["Syl\u00b7phi\u00b7den", ",", "Dry\u00b7a\u00b7den", "und", "O\u00b7rea\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NN", "KON", "NN"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.17": {"text": "und allen den geistigen ", "tokens": ["und", "al\u00b7len", "den", "geis\u00b7ti\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIS", "ART", "ADJA"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "die mit der Sublunarischen Welt", "tokens": ["die", "mit", "der", "Sub\u00b7lu\u00b7na\u00b7ri\u00b7schen", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "gern oder ungern sich beladen,", "tokens": ["gern", "o\u00b7der", "un\u00b7gern", "sich", "be\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "ins Werk zu setzen heimgestellt!", "tokens": ["ins", "Werk", "zu", "set\u00b7zen", "heim\u00b7ge\u00b7stellt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wohl dem, dem Alles wie's ist gef\u00e4llt!", "tokens": ["Wohl", "dem", ",", "dem", "Al\u00b7les", "wie's", "ist", "ge\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "PIS", "KOKOM", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Und so empfehl ich mich zu Gnaden.", "tokens": ["Und", "so", "emp\u00b7fehl", "ich", "mich", "zu", "Gna\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was hab ich, leider! ohne Frucht", "tokens": ["Was", "hab", "ich", ",", "lei\u00b7der", "!", "oh\u00b7ne", "Frucht"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "$,", "ADV", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "an diesem Abend nicht versucht,", "tokens": ["an", "die\u00b7sem", "A\u00b7bend", "nicht", "ver\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "um, meiner F\u00fcrstin zu Preis und Ehren,", "tokens": ["um", ",", "mei\u00b7ner", "F\u00fcrs\u00b7tin", "zu", "Preis", "und", "Eh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "$,", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "in dieser Gratulantenzeit", "tokens": ["in", "die\u00b7ser", "Gra\u00b7tu\u00b7lan\u00b7ten\u00b7zeit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die dreimal drei Kastalische D\u00f6ren", "tokens": ["die", "drei\u00b7mal", "drei", "Kas\u00b7ta\u00b7li\u00b7sche", "D\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "CARD", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "zu einem Liede zu beschw\u00f6ren?", "tokens": ["zu", "ei\u00b7nem", "Lie\u00b7de", "zu", "be\u00b7schw\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und weil die Musen sonder Streit", "tokens": ["Und", "weil", "die", "Mu\u00b7sen", "son\u00b7der", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "zur guten Geisterschar geh\u00f6ren,", "tokens": ["zur", "gu\u00b7ten", "Geis\u00b7ter\u00b7schar", "ge\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "die man (wie Doctor Obereit", "tokens": ["die", "man", "(", "wie", "Doc\u00b7tor", "O\u00b7be\u00b7reit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIS", "$(", "KOKOM", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "und andre weise M\u00e4nner lehren)", "tokens": ["und", "and\u00b7re", "wei\u00b7se", "M\u00e4n\u00b7ner", "leh\u00b7ren", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "durch ", "tokens": ["durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.12": {"text": "griff ich das Werk mit ", "tokens": ["griff", "ich", "das", "Werk", "mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "go\u00df Storax und Borax, Musk und Mazis,", "tokens": ["go\u00df", "Sto\u00b7rax", "und", "Bo\u00b7rax", ",", "Musk", "und", "Ma\u00b7zis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "NE", "$,", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "und Jusquiam und Alo\u00ebs", "tokens": ["und", "Jus\u00b7qui\u00b7am", "und", "A\u00b7lo\u00ebs"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "und sieben andre Species", "tokens": ["und", "sie\u00b7ben", "and\u00b7re", "Spe\u00b7cies"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "CARD", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "die Avicenna, Psellus und Razis", "tokens": ["die", "A\u00b7vi\u00b7cen\u00b7na", ",", "Psel\u00b7lus", "und", "Ra\u00b7zis"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "uns vorgeschrieben, auf Kohlenglut", "tokens": ["uns", "vor\u00b7ge\u00b7schrie\u00b7ben", ",", "auf", "Koh\u00b7len\u00b7glut"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVPP", "$,", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "in vollem Glauben und festem Mut,", "tokens": ["in", "vol\u00b7lem", "Glau\u00b7ben", "und", "fes\u00b7tem", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "die vorbesagten Kastalischen Feen", "tokens": ["die", "vor\u00b7be\u00b7sag\u00b7ten", "Kas\u00b7ta\u00b7li\u00b7schen", "Feen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "leibhaftig, alle drei zumal,", "tokens": ["leib\u00b7haf\u00b7tig", ",", "al\u00b7le", "drei", "zu\u00b7mal", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIAT", "CARD", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.21": {"text": "vor meinem Pult erscheinen zu sehen.", "tokens": ["vor", "mei\u00b7nem", "Pult", "er\u00b7schei\u00b7nen", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Der Rauch stieg, wie zu Alpenh\u00f6hen", "tokens": ["Der", "Rauch", "stieg", ",", "wie", "zu", "Al\u00b7pen\u00b7h\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "ein Nebel aus einem engen Tal,", "tokens": ["ein", "Ne\u00b7bel", "aus", "ei\u00b7nem", "en\u00b7gen", "Tal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "in Wolken hoch zum Sternensaal", "tokens": ["in", "Wol\u00b7ken", "hoch", "zum", "Ster\u00b7nen\u00b7saal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "empor \u2013 Allein, bei allen Busen", "tokens": ["em\u00b7por", "\u2013", "Al\u00b7lein", ",", "bei", "al\u00b7len", "Bu\u00b7sen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKVZ", "$(", "ADV", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "der gro\u00dfen Diana zu Ephesus!", "tokens": ["der", "gro\u00b7\u00dfen", "Di\u00b7a\u00b7na", "zu", "E\u00b7phe\u00b7sus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "APPR", "NE", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.27": {"text": "wer, mir zum bittersten Verdru\u00df,", "tokens": ["wer", ",", "mir", "zum", "bit\u00b7ters\u00b7ten", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.28": {"text": "nicht kam \u2013 das waren meine Musen.", "tokens": ["nicht", "kam", "\u2013", "das", "wa\u00b7ren", "mei\u00b7ne", "Mu\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$(", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Itzt fing mir, wie ich sagen mu\u00df,", "tokens": ["Itzt", "fing", "mir", ",", "wie", "ich", "sa\u00b7gen", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die Galle m\u00e4chtig an zu sprudeln.", "tokens": ["die", "Gal\u00b7le", "m\u00e4ch\u00b7tig", "an", "zu", "spru\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbnein!\u00ab rief ich, in meinem Zorn, \u00bbbeim Styx!", "tokens": ["\u00bb", "nein", "!", "\u00ab", "rief", "ich", ",", "in", "mei\u00b7nem", "Zorn", ",", "\u00bb", "beim", "Styx", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$.", "$(", "VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "$(", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "So sollen die Jungfern mich nicht hudeln!", "tokens": ["So", "sol\u00b7len", "die", "Jung\u00b7fern", "mich", "nicht", "hu\u00b7deln", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Erscheinen sie nicht augenblicks,", "tokens": ["Er\u00b7schei\u00b7nen", "sie", "nicht", "au\u00b7gen\u00b7blicks", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit einem demutsvollen Knicks", "tokens": ["mit", "ei\u00b7nem", "de\u00b7muts\u00b7vol\u00b7len", "Knicks"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "ihr bestes Lied mir vorzududeln:", "tokens": ["ihr", "bes\u00b7tes", "Lied", "mir", "vor\u00b7zu\u00b7du\u00b7deln", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "so soll, ich schw\u00f6rs beim Wunderzahn", "tokens": ["so", "soll", ",", "ich", "schw\u00f6rs", "beim", "Wun\u00b7der\u00b7zahn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "$,", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "des Obermeisters aller Affen,", "tokens": ["des", "O\u00b7ber\u00b7meis\u00b7ters", "al\u00b7ler", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "beim gro\u00dfen Zaubrer Hanneman,", "tokens": ["beim", "gro\u00b7\u00dfen", "Zaub\u00b7rer", "Han\u00b7ne\u00b7man", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "so soll Hans Faust mir Recht verschaffen!\u00ab", "tokens": ["so", "soll", "Hans", "Faust", "mir", "Recht", "ver\u00b7schaf\u00b7fen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "NE", "NN", "PPER", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wiewohl ich mit Herrn Urian", "tokens": ["Wie\u00b7wohl", "ich", "mit", "Herrn", "U\u00b7ri\u00b7an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "sonst auf dem besten Fu\u00df nicht stehe,", "tokens": ["sonst", "auf", "dem", "bes\u00b7ten", "Fu\u00df", "nicht", "ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "und, weil er mir von Jugend an", "tokens": ["und", ",", "weil", "er", "mir", "von", "Ju\u00b7gend", "an"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "APPR", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "schon manchen b\u00f6sen T\u00fcck getan,", "tokens": ["schon", "man\u00b7chen", "b\u00f6\u00b7sen", "T\u00fcck", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "ihm sonst gern aus dem Wege gehe,", "tokens": ["ihm", "sonst", "gern", "aus", "dem", "We\u00b7ge", "ge\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "f\u00fcr diesmal bringt die Not mich dran.", "tokens": ["f\u00fcr", "dies\u00b7mal", "bringt", "die", "Not", "mich", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Es schl\u00e4gt schon Eins! Bald kr\u00e4ht der Hahn", "tokens": ["Es", "schl\u00e4gt", "schon", "Eins", "!", "Bald", "kr\u00e4ht", "der", "Hahn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$.", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "und auch ein Blatt nur voll zu reimen", "tokens": ["und", "auch", "ein", "Blatt", "nur", "voll", "zu", "rei\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "ist keine Minute zu vers\u00e4umen.", "tokens": ["ist", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "ver\u00b7s\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Zwar mu\u00df ich bekennen, ", "tokens": ["Zwar", "mu\u00df", "ich", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "mir ward ein wenig gr\u00fcn und blau", "tokens": ["mir", "ward", "ein", "we\u00b7nig", "gr\u00fcn", "und", "blau"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "PIS", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "vorm Auge, da ich den ersten Bogen", "tokens": ["vorm", "Au\u00b7ge", ",", "da", "ich", "den", "ers\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "zum Zauberkreis um mich gezogen.", "tokens": ["zum", "Zau\u00b7ber\u00b7kreis", "um", "mich", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Allein nun war der Rubicon", "tokens": ["Al\u00b7lein", "nun", "war", "der", "Ru\u00b7bi\u00b7con"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "passiert, und nennt mir den Haymons Sohn", "tokens": ["pas\u00b7siert", ",", "und", "nennt", "mir", "den", "Hay\u00b7mons", "Sohn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "dem nicht das Herz, wenn's Ernst gilt, schlottert!", "tokens": ["dem", "nicht", "das", "Herz", ",", "wenn's", "Ernst", "gilt", ",", "schlot\u00b7tert", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PTKNEG", "ART", "NN", "$,", "KOUS", "NE", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Genug, ich stund in meinem Kreis", "tokens": ["Ge\u00b7nug", ",", "ich", "stund", "in", "mei\u00b7nem", "Kreis"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "und las \u2013 zwar freilich ein wenig leis \u2013", "tokens": ["und", "las", "\u2013", "zwar", "frei\u00b7lich", "ein", "we\u00b7nig", "leis", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "ADV", "ADV", "ART", "PIS", "ADJD", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "(mit unter ward auch wohl gestottert)", "tokens": ["(", "mit", "un\u00b7ter", "ward", "auch", "wohl", "ge\u00b7stot\u00b7tert", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "APPR", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "mit hochemporgehaltnem Stab", "tokens": ["mit", "hoc\u00b7hem\u00b7por\u00b7ge\u00b7halt\u00b7nem", "Stab"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "den ganzen ", "tokens": ["den", "gan\u00b7zen"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "durch den sonst, wie wir alle wissen,", "tokens": ["durch", "den", "sonst", ",", "wie", "wir", "al\u00b7le", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "$,", "PWAV", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "die Geister unterm Monde stracks", "tokens": ["die", "Geis\u00b7ter", "un\u00b7term", "Mon\u00b7de", "stracks"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "auf allen Vieren, wie ein Dachs,", "tokens": ["auf", "al\u00b7len", "Vie\u00b7ren", ",", "wie", "ein", "Dachs", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "herangekrochen kommen m\u00fcssen.", "tokens": ["her\u00b7an\u00b7ge\u00b7kro\u00b7chen", "kom\u00b7men", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Allein, wo auch der Fehler gesteckt,", "tokens": ["Al\u00b7lein", ",", "wo", "auch", "der", "Feh\u00b7ler", "ge\u00b7steckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "das Zauberwerk blieb ohne Effekt.", "tokens": ["das", "Zau\u00b7ber\u00b7werk", "blieb", "oh\u00b7ne", "Ef\u00b7fekt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Zitieren kann jeder die Geister freilich;", "tokens": ["Zi\u00b7tie\u00b7ren", "kann", "je\u00b7der", "die", "Geis\u00b7ter", "frei\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ART", "NN", "ADV", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "doch, ob sie kommen wollen, das steht", "tokens": ["doch", ",", "ob", "sie", "kom\u00b7men", "wol\u00b7len", ",", "das", "steht"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "PDS", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "bei ihnen! \u2013 \u00bbUngl\u00fccklicher Poet!", "tokens": ["bei", "ih\u00b7nen", "!", "\u2013", "\u00bb", "Un\u00b7gl\u00fcck\u00b7li\u00b7cher", "Po\u00b7et", "!"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$.", "$(", "$(", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Ist dies dein Lohn? So lang und treulich", "tokens": ["Ist", "dies", "dein", "Lohn", "?", "So", "lang", "und", "treu\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "PPOSAT", "NN", "$.", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "dienst du den Hexen vom Helikon", "tokens": ["dienst", "du", "den", "He\u00b7xen", "vom", "He\u00b7li\u00b7kon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.24": {"text": "wohl sechs und drei\u00dfig Jahre schon", "tokens": ["wohl", "sechs", "und", "drei\u00b7\u00dfig", "Jah\u00b7re", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "KON", "CARD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "und dr\u00fcber! Hast so treubeflissen", "tokens": ["und", "dr\u00fc\u00b7ber", "!", "Hast", "so", "treu\u00b7be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PAV", "$.", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "so manchen sch\u00f6nen G\u00e4nsekiel", "tokens": ["so", "man\u00b7chen", "sch\u00f6\u00b7nen", "G\u00e4n\u00b7se\u00b7kiel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "in ihrem sauren Dienst zerbissen,", "tokens": ["in", "ih\u00b7rem", "sau\u00b7ren", "Dienst", "zer\u00b7bis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "so manche Stanze gedreht, soviel", "tokens": ["so", "man\u00b7che", "Stan\u00b7ze", "ge\u00b7dreht", ",", "so\u00b7viel"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,", "XY"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "nach Reimen, wie Kakadus nach N\u00fcssen,", "tokens": ["nach", "Rei\u00b7men", ",", "wie", "Ka\u00b7ka\u00b7dus", "nach", "N\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "NE", "APPR", "NE", "$,"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.30": {"text": "und Baham nach Fliegen, haschen m\u00fcssen,", "tokens": ["und", "Ba\u00b7ham", "nach", "Flie\u00b7gen", ",", "ha\u00b7schen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "$,", "VVINF", "VMINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "und ach! so manches Ries Papier", "tokens": ["und", "ach", "!", "so", "man\u00b7ches", "Ries", "Pa\u00b7pier"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "ADV", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "f\u00fcr sie besudelt und zerrissen,", "tokens": ["f\u00fcr", "sie", "be\u00b7su\u00b7delt", "und", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "und das ist nun der Dank daf\u00fcr!\u00ab", "tokens": ["und", "das", "ist", "nun", "der", "Dank", "da\u00b7f\u00fcr", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ART", "NN", "PAV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "So rief ich mit gesenkten Ohren,", "tokens": ["So", "rief", "ich", "mit", "ge\u00b7senk\u00b7ten", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "allein die Musen h\u00f6rten's nicht;", "tokens": ["al\u00b7lein", "die", "Mu\u00b7sen", "h\u00f6r\u00b7ten's", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "und, Zauber, Rauchwerk, \u00d6l und Licht", "tokens": ["und", ",", "Zau\u00b7ber", ",", "Rauch\u00b7werk", ",", "\u00d6l", "und", "Licht"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "kurz, Malz und Hopfen war verloren!", "tokens": ["kurz", ",", "Malz", "und", "Hop\u00b7fen", "war", "ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NE", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ja freilich im ganzen Heiligen Reich", "tokens": ["Ja", "frei\u00b7lich", "im", "gan\u00b7zen", "Hei\u00b7li\u00b7gen", "Reich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "APPRART", "ADJA", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "ist diesen eigensinnigen Miezen", "tokens": ["ist", "die\u00b7sen", "ei\u00b7gen\u00b7sin\u00b7ni\u00b7gen", "Mie\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "von alten zieraffischen Cantatrizen", "tokens": ["von", "al\u00b7ten", "zier\u00b7af\u00b7fi\u00b7schen", "Can\u00b7ta\u00b7tri\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "kein Maid of Honour an Laune gleich.", "tokens": ["kein", "Maid", "of", "Ho\u00b7nour", "an", "Lau\u00b7ne", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NE", "NE", "APPR", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ich m\u00f6chte wie Orlando rasen,", "tokens": ["Ich", "m\u00f6ch\u00b7te", "wie", "Or\u00b7lan\u00b7do", "ra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KOKOM", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "wenn ich bedenke, wie leicht es auch", "tokens": ["wenn", "ich", "be\u00b7den\u00b7ke", ",", "wie", "leicht", "es", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPER", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "den M\u00e4dchen war, mit Einem Hauch", "tokens": ["den", "M\u00e4d\u00b7chen", "war", ",", "mit", "Ei\u00b7nem", "Hauch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "die sch\u00f6nsten Verse mir einzublasen!", "tokens": ["die", "sch\u00f6ns\u00b7ten", "Ver\u00b7se", "mir", "ein\u00b7zu\u00b7bla\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Nun sitz ich, sauge wie ein Gauch", "tokens": ["Nun", "sitz", "ich", ",", "sau\u00b7ge", "wie", "ein", "Gauch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "$,", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "am Daumen, ziehe mich bei der Nasen,", "tokens": ["am", "Dau\u00b7men", ",", "zie\u00b7he", "mich", "bei", "der", "Na\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "kratz hinterm Ohr, reib an der Stirne,", "tokens": ["kratz", "hin\u00b7term", "Ohr", ",", "reib", "an", "der", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "und strapaziere mein Gehirne", "tokens": ["und", "stra\u00b7pa\u00b7zie\u00b7re", "mein", "Ge\u00b7hir\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "und melkte doch eher von einem Bock", "tokens": ["und", "melk\u00b7te", "doch", "e\u00b7her", "von", "ei\u00b7nem", "Bock"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "APPR", "ART", "NE"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "den besten Wein aus Languedoc", "tokens": ["den", "bes\u00b7ten", "Wein", "aus", "Lan\u00b7gue\u00b7doc"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "als einen einzigen Fingerhut", "tokens": ["als", "ei\u00b7nen", "ein\u00b7zi\u00b7gen", "Fin\u00b7ger\u00b7hut"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "voll Witz aus meinem Occiput.", "tokens": ["voll", "Witz", "aus", "mei\u00b7nem", "Oc\u00b7ci\u00b7put", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was nun zu machen? Allenfalls", "tokens": ["Was", "nun", "zu", "ma\u00b7chen", "?", "Al\u00b7len\u00b7falls"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "ADV", "PTKZU", "VVINF", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gleich einem Schwan mit langem Hals", "tokens": ["gleich", "ei\u00b7nem", "Schwan", "mit", "lan\u00b7gem", "Hals"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "was am Gesange fehlt durch Heulen", "tokens": ["was", "am", "Ge\u00b7san\u00b7ge", "fehlt", "durch", "Heu\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPRART", "NN", "VVFIN", "APPR", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "ersetzen? Wir w\u00fcrden die Ehre zwar", "tokens": ["er\u00b7set\u00b7zen", "?", "Wir", "w\u00fcr\u00b7den", "die", "Eh\u00b7re", "zwar"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVINF", "$.", "PPER", "VAFIN", "ART", "NN", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Mit mancher ", "tokens": ["Mit", "man\u00b7cher"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "doch scheint in solchen F\u00e4llen klar,", "tokens": ["doch", "scheint", "in", "sol\u00b7chen", "F\u00e4l\u00b7len", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "das Kl\u00fcgste sei zum Schlusse zu eilen;", "tokens": ["das", "Kl\u00fcgs\u00b7te", "sei", "zum", "Schlus\u00b7se", "zu", "ei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "denn Heulen quadriert doch nur auf Eulen,", "tokens": ["denn", "Heu\u00b7len", "quad\u00b7riert", "doch", "nur", "auf", "Eu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "ADV", "APPR", "NE", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "und Persiflieren bringt Gefahr.", "tokens": ["und", "Per\u00b7sif\u00b7lie\u00b7ren", "bringt", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Drum w\u00fcnsch ich ohne l\u00e4ngeres Weilen", "tokens": ["Drum", "w\u00fcnsch", "ich", "oh\u00b7ne", "l\u00e4n\u00b7ge\u00b7res", "Wei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "mit diesen treugemeinten Zeilen", "tokens": ["mit", "die\u00b7sen", "treu\u00b7ge\u00b7mein\u00b7ten", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Drei hundert F\u00fcnf und Sechzig Tage,", "tokens": ["Drei", "hun\u00b7dert", "F\u00fcnf", "und", "Sech\u00b7zig", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "CARD", "KON", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "an denen von der ganzen Schar", "tokens": ["an", "de\u00b7nen", "von", "der", "gan\u00b7zen", "Schar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "der magern Sorgen keine nage:", "tokens": ["der", "ma\u00b7gern", "Sor\u00b7gen", "kei\u00b7ne", "na\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "auf jeden Tag an reinem Ertrage", "tokens": ["auf", "je\u00b7den", "Tag", "an", "rei\u00b7nem", "Er\u00b7tra\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "stets volle vier und zwanzig Stunden", "tokens": ["stets", "vol\u00b7le", "vier", "und", "zwan\u00b7zig", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "CARD", "KON", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "die Stunde zu Sechzig Minuten gez\u00e4hlt,", "tokens": ["die", "Stun\u00b7de", "zu", "Sech\u00b7zig", "Mi\u00b7nu\u00b7ten", "ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.18": {"text": "und jede Minute zu Sechzig Secunden,", "tokens": ["und", "je\u00b7de", "Mi\u00b7nu\u00b7te", "zu", "Sech\u00b7zig", "Se\u00b7cun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.19": {"text": "und jede Secunde, da\u00df keine fehlt,", "tokens": ["und", "je\u00b7de", "Se\u00b7cun\u00b7de", ",", "da\u00df", "kei\u00b7ne", "fehlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "KOUS", "PIAT", "VVFIN", "$,"], "meter": "-+-----+-+", "measure": "dactylic.init"}, "line.20": {"text": "von einem reinen Genu\u00df beseelt,", "tokens": ["von", "ei\u00b7nem", "rei\u00b7nen", "Ge\u00b7nu\u00df", "be\u00b7seelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "mit etwas dessen man gerne sich wieder", "tokens": ["mit", "et\u00b7was", "des\u00b7sen", "man", "ger\u00b7ne", "sich", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "PDS", "PIS", "ADV", "PRF", "ADV"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "erinnert wenn alles andre fehlt,", "tokens": ["e\u00b7rin\u00b7nert", "wenn", "al\u00b7les", "and\u00b7re", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "PIS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.23": {"text": "und frei von allem was Seel und Glieder", "tokens": ["und", "frei", "von", "al\u00b7lem", "was", "Seel", "und", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PIS", "PWS", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "was Augen, Ohren und \u2013 F\u00fc\u00dfe qu\u00e4lt.", "tokens": ["was", "Au\u00b7gen", ",", "Oh\u00b7ren", "und", "\u2013", "F\u00fc\u00b7\u00dfe", "qu\u00e4lt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "NN", "KON", "$(", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Im \u00fcbrigen ist, zumal im Gr\u00fcnen", "tokens": ["Im", "\u00fcb\u00b7ri\u00b7gen", "ist", ",", "zu\u00b7mal", "im", "Gr\u00fc\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN", "$,", "KOUS", "APPRART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "von Longus und von Lucian", "tokens": ["von", "Lon\u00b7gus", "und", "von", "Lu\u00b7ci\u00b7an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "als Kammerjunkern sich bedienen", "tokens": ["als", "Kam\u00b7mer\u00b7jun\u00b7kern", "sich", "be\u00b7die\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zu lassen, immer wohlgetan.", "tokens": ["zu", "las\u00b7sen", ",", "im\u00b7mer", "wohl\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zwar sind die Herren, an denen man", "tokens": ["Zwar", "sind", "die", "Her\u00b7ren", ",", "an", "de\u00b7nen", "man"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "PIS"], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.6": {"text": "sich schon zweitausend Jahre zu Tode", "tokens": ["sich", "schon", "zweit\u00b7au\u00b7send", "Jah\u00b7re", "zu", "To\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADV", "CARD", "NN", "APPR", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "gelesen, ein wenig aus der Mode;", "tokens": ["ge\u00b7le\u00b7sen", ",", "ein", "we\u00b7nig", "aus", "der", "Mo\u00b7de", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ART", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "doch immer f\u00fcr eine Episode", "tokens": ["doch", "im\u00b7mer", "f\u00fcr", "ei\u00b7ne", "E\u00b7pi\u00b7so\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "noch gut genug, und haben auch", "tokens": ["noch", "gut", "ge\u00b7nug", ",", "und", "ha\u00b7ben", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "$,", "KON", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "vor andern edeln Kammertieren", "tokens": ["vor", "an\u00b7dern", "e\u00b7deln", "Kam\u00b7mer\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "die Tugend und den l\u00f6blichen Brauch", "tokens": ["die", "Tu\u00b7gend", "und", "den", "l\u00f6b\u00b7li\u00b7chen", "Brauch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "die F\u00fcrsten nicht l\u00e4nger zu ennuyieren", "tokens": ["die", "F\u00fcrs\u00b7ten", "nicht", "l\u00e4n\u00b7ger", "zu", "en\u00b7nu\u00b7yie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "ADJD", "PTKZU", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "als Ihnen selbst belieben mag.", "tokens": ["als", "Ih\u00b7nen", "selbst", "be\u00b7lie\u00b7ben", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Das \u00fcbrige alles was dieser Tag", "tokens": ["Das", "\u00fcb\u00b7ri\u00b7ge", "al\u00b7les", "was", "die\u00b7ser", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "PIS", "PWS", "PDAT", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "zu w\u00fcnschen pflegt, sei den Najaden", "tokens": ["zu", "w\u00fcn\u00b7schen", "pflegt", ",", "sei", "den", "Na\u00b7ja\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VVFIN", "$,", "VAFIN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.16": {"text": "Sylphiden, Dryaden und Oreaden", "tokens": ["Syl\u00b7phi\u00b7den", ",", "Dry\u00b7a\u00b7den", "und", "O\u00b7rea\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NN", "KON", "NN"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.17": {"text": "und allen den geistigen ", "tokens": ["und", "al\u00b7len", "den", "geis\u00b7ti\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIS", "ART", "ADJA"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "die mit der Sublunarischen Welt", "tokens": ["die", "mit", "der", "Sub\u00b7lu\u00b7na\u00b7ri\u00b7schen", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "gern oder ungern sich beladen,", "tokens": ["gern", "o\u00b7der", "un\u00b7gern", "sich", "be\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "ins Werk zu setzen heimgestellt!", "tokens": ["ins", "Werk", "zu", "set\u00b7zen", "heim\u00b7ge\u00b7stellt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wohl dem, dem Alles wie's ist gef\u00e4llt!", "tokens": ["Wohl", "dem", ",", "dem", "Al\u00b7les", "wie's", "ist", "ge\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "PIS", "KOKOM", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Und so empfehl ich mich zu Gnaden.", "tokens": ["Und", "so", "emp\u00b7fehl", "ich", "mich", "zu", "Gna\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}