{"textgrid.poem.46125": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Der lieb unz\u00e4hliche zahl", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nachdem die Nymf aus Albion,", "tokens": ["Nach\u00b7dem", "die", "Nymf", "aus", "Al\u00b7bi\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der fromkeit und der tugend kron,", "tokens": ["der", "from\u00b7keit", "und", "der", "tu\u00b7gend", "kron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "hat ihrer diener wert erwegen;", "tokens": ["hat", "ih\u00b7rer", "die\u00b7ner", "wert", "er\u00b7we\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zog sie ihren landshirten vor", "tokens": ["zog", "sie", "ih\u00b7ren", "lands\u00b7hir\u00b7ten", "vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "APPR"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "den fremdling, welcher Filodor", "tokens": ["den", "fremd\u00b7ling", ",", "wel\u00b7cher", "Fi\u00b7lo\u00b7dor"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "VVFIN", "$,", "PRELS", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "genant ist, seiner tugend wegen.", "tokens": ["ge\u00b7nant", "ist", ",", "sei\u00b7ner", "tu\u00b7gend", "we\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Fieng demnach an (f\u00fcr seine pein", "tokens": ["Fi\u00b7eng", "dem\u00b7nach", "an", "(", "f\u00fcr", "sei\u00b7ne", "pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PAV", "PTKVZ", "$(", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und pure treu dankbar zu sein)", "tokens": ["und", "pu\u00b7re", "treu", "dank\u00b7bar", "zu", "sein", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJD", "ADJD", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit gleicher lieb ihm zu begegnen,", "tokens": ["mit", "glei\u00b7cher", "lieb", "ihm", "zu", "be\u00b7geg\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df er bald seines leidens stand", "tokens": ["da\u00df", "er", "bald", "sei\u00b7nes", "lei\u00b7dens", "stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "auch Amors tyrannei und brand", "tokens": ["auch", "A\u00b7mors", "ty\u00b7ran\u00b7nei", "und", "brand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und stralen nu anfieng zu segnen.", "tokens": ["und", "stra\u00b7len", "nu", "an\u00b7fi\u00b7eng", "zu", "seg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Also ihr beeder schmerz und scherz", "tokens": ["Al\u00b7so", "ihr", "bee\u00b7der", "schmerz", "und", "scherz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "KON", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "wurd gleich, gleich wurd ihr will und herz,", "tokens": ["wurd", "gleich", ",", "gleich", "wurd", "ihr", "will", "und", "herz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "ADV", "VAFIN", "PPER", "VMFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "gleichwol verdr\u00fc\u00dflich den landsleuten:", "tokens": ["gleich\u00b7wol", "ver\u00b7dr\u00fc\u00df\u00b7lich", "den", "lands\u00b7leu\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "geliebet lieben sie so sehr,", "tokens": ["ge\u00b7lie\u00b7bet", "lie\u00b7ben", "sie", "so", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df all ihr sorg ist, welches mehr", "tokens": ["da\u00df", "all", "ihr", "sorg", "ist", ",", "wel\u00b7ches", "mehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PIAT", "PPOSAT", "NN", "VAFIN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "das ander lieben kan, zu streiten.", "tokens": ["das", "an\u00b7der", "lie\u00b7ben", "kan", ",", "zu", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVINF", "VMFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Einmal nu an des meers gestad", "tokens": ["Ein\u00b7mal", "nu", "an", "des", "meers", "ge\u00b7stad"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "ADJD"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "sprach er zu ihr: \u00bbO deren gnad", "tokens": ["sprach", "er", "zu", "ihr", ":", "\u00bb", "O", "de\u00b7ren", "gnad"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "$.", "$(", "NE", "PRELAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "und lieb mich ewiglich verbinden!", "tokens": ["und", "lieb", "mich", "e\u00b7wig\u00b7lich", "ver\u00b7bin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "f\u00fcr dich hab ich mehr qual und m\u00fch,", "tokens": ["f\u00fcr", "dich", "hab", "ich", "mehr", "qual", "und", "m\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "PIAT", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dan man kan k\u00f6rnlein sands alhie", "tokens": ["dan", "man", "kan", "k\u00f6rn\u00b7lein", "sands", "al\u00b7hie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VMFIN", "FM.la", "FM.la", "FM.la"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "und tropfen in dem meere finden.\u00ab", "tokens": ["und", "trop\u00b7fen", "in", "dem", "mee\u00b7re", "fin\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Myrta gab ihm hierauf antwort:", "tokens": ["Myr\u00b7ta", "gab", "ihm", "hier\u00b7auf", "ant\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PAV", "NN", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "\u00bbo meiner seelen s\u00fc\u00dfer hort,", "tokens": ["\u00bb", "o", "mei\u00b7ner", "see\u00b7len", "s\u00fc\u00b7\u00dfer", "hort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ich trag zu dir in meinem herzen", "tokens": ["ich", "trag", "zu", "dir", "in", "mei\u00b7nem", "her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mehr lieb dan augenblick im jahr;", "tokens": ["mehr", "lieb", "dan", "au\u00b7gen\u00b7blick", "im", "jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mehr, dan stern hat der himmel klar,", "tokens": ["mehr", ",", "dan", "stern", "hat", "der", "him\u00b7mel", "klar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVINF", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "leid ich f\u00fcr dich liebreiche schmerzen.\u00ab", "tokens": ["leid", "ich", "f\u00fcr", "dich", "lieb\u00b7rei\u00b7che", "schmer\u00b7zen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PPER", "APPR", "PPER", "VVFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Alsdan der hirt mit gro\u00dfem lust", "tokens": ["Als\u00b7dan", "der", "hirt", "mit", "gro\u00b7\u00dfem", "lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zog dise wort aus seiner brust:", "tokens": ["zog", "di\u00b7se", "wort", "aus", "sei\u00b7ner", "brust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "\u00bbla\u00df so vil s\u00fc\u00dfigkeit uns f\u00fchlen,", "tokens": ["\u00bb", "la\u00df", "so", "vil", "s\u00fc\u00b7\u00dfig\u00b7keit", "uns", "f\u00fch\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "ADV", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "mit wie vil blumen sich das feld,", "tokens": ["mit", "wie", "vil", "blu\u00b7men", "sich", "das", "feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mit wie vil laub sich auch die w\u00e4ld", "tokens": ["mit", "wie", "vil", "laub", "sich", "auch", "die", "w\u00e4ld"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "PRF", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bereichen, so vil la\u00df uns spielen.\u00ab", "tokens": ["be\u00b7rei\u00b7chen", ",", "so", "vil", "la\u00df", "uns", "spie\u00b7len", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVINF", "$,", "ADV", "ADV", "VVIMP", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Darauf mit schmollend s\u00fc\u00dfem mund", "tokens": ["Da\u00b7rauf", "mit", "schmol\u00b7lend", "s\u00fc\u00b7\u00dfem", "mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sprach sie zu ihm von herzensgrund:", "tokens": ["sprach", "sie", "zu", "ihm", "von", "her\u00b7zens\u00b7grund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbso la\u00df einm\u00fctiglich uns lieben,", "tokens": ["\u00bb", "so", "la\u00df", "ein\u00b7m\u00fc\u00b7tig\u00b7lich", "uns", "lie\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und la\u00df uns nu f\u00fcr tausend pein,", "tokens": ["und", "la\u00df", "uns", "nu", "f\u00fcr", "tau\u00b7send", "pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df gleich dem leid die freud m\u00f6g sein,", "tokens": ["da\u00df", "gleich", "dem", "leid", "die", "freud", "m\u00f6g", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJD", "ART", "VVFIN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit tausend k\u00fcssen auch enttr\u00fcben.\u00ab", "tokens": ["mit", "tau\u00b7send", "k\u00fcs\u00b7sen", "auch", "ent\u00b7tr\u00fc\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "CARD", "VVFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nachdem die Nymf aus Albion,", "tokens": ["Nach\u00b7dem", "die", "Nymf", "aus", "Al\u00b7bi\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der fromkeit und der tugend kron,", "tokens": ["der", "from\u00b7keit", "und", "der", "tu\u00b7gend", "kron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "hat ihrer diener wert erwegen;", "tokens": ["hat", "ih\u00b7rer", "die\u00b7ner", "wert", "er\u00b7we\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zog sie ihren landshirten vor", "tokens": ["zog", "sie", "ih\u00b7ren", "lands\u00b7hir\u00b7ten", "vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "APPR"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "den fremdling, welcher Filodor", "tokens": ["den", "fremd\u00b7ling", ",", "wel\u00b7cher", "Fi\u00b7lo\u00b7dor"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "VVFIN", "$,", "PRELS", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "genant ist, seiner tugend wegen.", "tokens": ["ge\u00b7nant", "ist", ",", "sei\u00b7ner", "tu\u00b7gend", "we\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Fieng demnach an (f\u00fcr seine pein", "tokens": ["Fi\u00b7eng", "dem\u00b7nach", "an", "(", "f\u00fcr", "sei\u00b7ne", "pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PAV", "PTKVZ", "$(", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und pure treu dankbar zu sein)", "tokens": ["und", "pu\u00b7re", "treu", "dank\u00b7bar", "zu", "sein", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJD", "ADJD", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit gleicher lieb ihm zu begegnen,", "tokens": ["mit", "glei\u00b7cher", "lieb", "ihm", "zu", "be\u00b7geg\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df er bald seines leidens stand", "tokens": ["da\u00df", "er", "bald", "sei\u00b7nes", "lei\u00b7dens", "stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "auch Amors tyrannei und brand", "tokens": ["auch", "A\u00b7mors", "ty\u00b7ran\u00b7nei", "und", "brand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und stralen nu anfieng zu segnen.", "tokens": ["und", "stra\u00b7len", "nu", "an\u00b7fi\u00b7eng", "zu", "seg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Also ihr beeder schmerz und scherz", "tokens": ["Al\u00b7so", "ihr", "bee\u00b7der", "schmerz", "und", "scherz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "KON", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "wurd gleich, gleich wurd ihr will und herz,", "tokens": ["wurd", "gleich", ",", "gleich", "wurd", "ihr", "will", "und", "herz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "ADV", "VAFIN", "PPER", "VMFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "gleichwol verdr\u00fc\u00dflich den landsleuten:", "tokens": ["gleich\u00b7wol", "ver\u00b7dr\u00fc\u00df\u00b7lich", "den", "lands\u00b7leu\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "geliebet lieben sie so sehr,", "tokens": ["ge\u00b7lie\u00b7bet", "lie\u00b7ben", "sie", "so", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df all ihr sorg ist, welches mehr", "tokens": ["da\u00df", "all", "ihr", "sorg", "ist", ",", "wel\u00b7ches", "mehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PIAT", "PPOSAT", "NN", "VAFIN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "das ander lieben kan, zu streiten.", "tokens": ["das", "an\u00b7der", "lie\u00b7ben", "kan", ",", "zu", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVINF", "VMFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Einmal nu an des meers gestad", "tokens": ["Ein\u00b7mal", "nu", "an", "des", "meers", "ge\u00b7stad"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "ADJD"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "sprach er zu ihr: \u00bbO deren gnad", "tokens": ["sprach", "er", "zu", "ihr", ":", "\u00bb", "O", "de\u00b7ren", "gnad"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "$.", "$(", "NE", "PRELAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "und lieb mich ewiglich verbinden!", "tokens": ["und", "lieb", "mich", "e\u00b7wig\u00b7lich", "ver\u00b7bin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "f\u00fcr dich hab ich mehr qual und m\u00fch,", "tokens": ["f\u00fcr", "dich", "hab", "ich", "mehr", "qual", "und", "m\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "PIAT", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dan man kan k\u00f6rnlein sands alhie", "tokens": ["dan", "man", "kan", "k\u00f6rn\u00b7lein", "sands", "al\u00b7hie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VMFIN", "FM.la", "FM.la", "FM.la"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "und tropfen in dem meere finden.\u00ab", "tokens": ["und", "trop\u00b7fen", "in", "dem", "mee\u00b7re", "fin\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Myrta gab ihm hierauf antwort:", "tokens": ["Myr\u00b7ta", "gab", "ihm", "hier\u00b7auf", "ant\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PAV", "NN", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "\u00bbo meiner seelen s\u00fc\u00dfer hort,", "tokens": ["\u00bb", "o", "mei\u00b7ner", "see\u00b7len", "s\u00fc\u00b7\u00dfer", "hort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ich trag zu dir in meinem herzen", "tokens": ["ich", "trag", "zu", "dir", "in", "mei\u00b7nem", "her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mehr lieb dan augenblick im jahr;", "tokens": ["mehr", "lieb", "dan", "au\u00b7gen\u00b7blick", "im", "jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mehr, dan stern hat der himmel klar,", "tokens": ["mehr", ",", "dan", "stern", "hat", "der", "him\u00b7mel", "klar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVINF", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "leid ich f\u00fcr dich liebreiche schmerzen.\u00ab", "tokens": ["leid", "ich", "f\u00fcr", "dich", "lieb\u00b7rei\u00b7che", "schmer\u00b7zen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PPER", "APPR", "PPER", "VVFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Alsdan der hirt mit gro\u00dfem lust", "tokens": ["Als\u00b7dan", "der", "hirt", "mit", "gro\u00b7\u00dfem", "lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zog dise wort aus seiner brust:", "tokens": ["zog", "di\u00b7se", "wort", "aus", "sei\u00b7ner", "brust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "\u00bbla\u00df so vil s\u00fc\u00dfigkeit uns f\u00fchlen,", "tokens": ["\u00bb", "la\u00df", "so", "vil", "s\u00fc\u00b7\u00dfig\u00b7keit", "uns", "f\u00fch\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "ADV", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "mit wie vil blumen sich das feld,", "tokens": ["mit", "wie", "vil", "blu\u00b7men", "sich", "das", "feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mit wie vil laub sich auch die w\u00e4ld", "tokens": ["mit", "wie", "vil", "laub", "sich", "auch", "die", "w\u00e4ld"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "PRF", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bereichen, so vil la\u00df uns spielen.\u00ab", "tokens": ["be\u00b7rei\u00b7chen", ",", "so", "vil", "la\u00df", "uns", "spie\u00b7len", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVINF", "$,", "ADV", "ADV", "VVIMP", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Darauf mit schmollend s\u00fc\u00dfem mund", "tokens": ["Da\u00b7rauf", "mit", "schmol\u00b7lend", "s\u00fc\u00b7\u00dfem", "mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sprach sie zu ihm von herzensgrund:", "tokens": ["sprach", "sie", "zu", "ihm", "von", "her\u00b7zens\u00b7grund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbso la\u00df einm\u00fctiglich uns lieben,", "tokens": ["\u00bb", "so", "la\u00df", "ein\u00b7m\u00fc\u00b7tig\u00b7lich", "uns", "lie\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und la\u00df uns nu f\u00fcr tausend pein,", "tokens": ["und", "la\u00df", "uns", "nu", "f\u00fcr", "tau\u00b7send", "pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df gleich dem leid die freud m\u00f6g sein,", "tokens": ["da\u00df", "gleich", "dem", "leid", "die", "freud", "m\u00f6g", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJD", "ART", "VVFIN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit tausend k\u00fcssen auch enttr\u00fcben.\u00ab", "tokens": ["mit", "tau\u00b7send", "k\u00fcs\u00b7sen", "auch", "ent\u00b7tr\u00fc\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "CARD", "VVFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}