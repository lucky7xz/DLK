{"textgrid.poem.34989": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Welsche Sage", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Turin, im alten Schlosse,", "tokens": ["Zu", "Tu\u00b7rin", ",", "im", "al\u00b7ten", "Schlos\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Sehen wir, aus Stein gemetzt,", "tokens": ["Se\u00b7hen", "wir", ",", "aus", "Stein", "ge\u00b7metzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Weib mit einem Rosse", "tokens": ["Wie", "ein", "Weib", "mit", "ei\u00b7nem", "Ros\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sodomitisch sich erg\u00f6tzt.", "tokens": ["So\u00b7do\u00b7mi\u00b7tisch", "sich", "er\u00b7g\u00f6tzt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "Und es hei\u00dft: da\u00df jene Dame", "tokens": ["Und", "es", "hei\u00dft", ":", "da\u00df", "je\u00b7ne", "Da\u00b7me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "KOUS", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die erlauchte Mutter ward", "tokens": ["Die", "er\u00b7lauch\u00b7te", "Mut\u00b7ter", "ward"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eines F\u00fcrstenstamms; der Same", "tokens": ["Ei\u00b7nes", "F\u00fcrs\u00b7ten\u00b7stamms", ";", "der", "Sa\u00b7me"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schlug f\u00fcrwahr nicht aus der Art.", "tokens": ["Schlug", "f\u00fcr\u00b7wahr", "nicht", "aus", "der", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ja, sie hatten alle wenig", "tokens": ["Ja", ",", "sie", "hat\u00b7ten", "al\u00b7le", "we\u00b7nig"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PIAT", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der menschlichen Natur!", "tokens": ["Von", "der", "menschli\u00b7chen", "Na\u00b7tur", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und an jedem Sardenk\u00f6nig", "tokens": ["Und", "an", "je\u00b7dem", "Sar\u00b7den\u00b7k\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Merkte man die Pferdespur.", "tokens": ["Merk\u00b7te", "man", "die", "Pfer\u00b7de\u00b7spur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Stets brutal zugleich und bl\u00f6de,", "tokens": ["Stets", "bru\u00b7tal", "zu\u00b7gleich", "und", "bl\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "KON", "ADJA", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Stallgedanken, jammervoll,", "tokens": ["Stall\u00b7ge\u00b7dan\u00b7ken", ",", "jam\u00b7mer\u00b7voll", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Gewieher ihre Rede,", "tokens": ["Ein", "Ge\u00b7wie\u00b7her", "ih\u00b7re", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Eine Bestie jeder Zoll.", "tokens": ["Ei\u00b7ne", "Be\u00b7stie", "je\u00b7der", "Zoll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Du allein, du des Geschlechtes", "tokens": ["Du", "al\u00b7lein", ",", "du", "des", "Ge\u00b7schlech\u00b7tes"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "PPER", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Letzter Spr\u00f6\u00dfling, f\u00fchlst und denkst", "tokens": ["Letz\u00b7ter", "Spr\u00f6\u00df\u00b7ling", ",", "f\u00fchlst", "und", "denkst"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Mensch, und hast ein echtes", "tokens": ["Wie", "ein", "Mensch", ",", "und", "hast", "ein", "ech\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "$,", "KON", "VAFIN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Christenherz, und bist kein Hengst.", "tokens": ["Chris\u00b7ten\u00b7herz", ",", "und", "bist", "kein", "Hengst", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Zu Turin, im alten Schlosse,", "tokens": ["Zu", "Tu\u00b7rin", ",", "im", "al\u00b7ten", "Schlos\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Sehen wir, aus Stein gemetzt,", "tokens": ["Se\u00b7hen", "wir", ",", "aus", "Stein", "ge\u00b7metzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Weib mit einem Rosse", "tokens": ["Wie", "ein", "Weib", "mit", "ei\u00b7nem", "Ros\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sodomitisch sich erg\u00f6tzt.", "tokens": ["So\u00b7do\u00b7mi\u00b7tisch", "sich", "er\u00b7g\u00f6tzt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "Und es hei\u00dft: da\u00df jene Dame", "tokens": ["Und", "es", "hei\u00dft", ":", "da\u00df", "je\u00b7ne", "Da\u00b7me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "KOUS", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die erlauchte Mutter ward", "tokens": ["Die", "er\u00b7lauch\u00b7te", "Mut\u00b7ter", "ward"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eines F\u00fcrstenstamms; der Same", "tokens": ["Ei\u00b7nes", "F\u00fcrs\u00b7ten\u00b7stamms", ";", "der", "Sa\u00b7me"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schlug f\u00fcrwahr nicht aus der Art.", "tokens": ["Schlug", "f\u00fcr\u00b7wahr", "nicht", "aus", "der", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ja, sie hatten alle wenig", "tokens": ["Ja", ",", "sie", "hat\u00b7ten", "al\u00b7le", "we\u00b7nig"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PIAT", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der menschlichen Natur!", "tokens": ["Von", "der", "menschli\u00b7chen", "Na\u00b7tur", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und an jedem Sardenk\u00f6nig", "tokens": ["Und", "an", "je\u00b7dem", "Sar\u00b7den\u00b7k\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Merkte man die Pferdespur.", "tokens": ["Merk\u00b7te", "man", "die", "Pfer\u00b7de\u00b7spur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Stets brutal zugleich und bl\u00f6de,", "tokens": ["Stets", "bru\u00b7tal", "zu\u00b7gleich", "und", "bl\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "KON", "ADJA", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Stallgedanken, jammervoll,", "tokens": ["Stall\u00b7ge\u00b7dan\u00b7ken", ",", "jam\u00b7mer\u00b7voll", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Gewieher ihre Rede,", "tokens": ["Ein", "Ge\u00b7wie\u00b7her", "ih\u00b7re", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Eine Bestie jeder Zoll.", "tokens": ["Ei\u00b7ne", "Be\u00b7stie", "je\u00b7der", "Zoll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.10": {"line.1": {"text": "Du allein, du des Geschlechtes", "tokens": ["Du", "al\u00b7lein", ",", "du", "des", "Ge\u00b7schlech\u00b7tes"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "PPER", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Letzter Spr\u00f6\u00dfling, f\u00fchlst und denkst", "tokens": ["Letz\u00b7ter", "Spr\u00f6\u00df\u00b7ling", ",", "f\u00fchlst", "und", "denkst"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Mensch, und hast ein echtes", "tokens": ["Wie", "ein", "Mensch", ",", "und", "hast", "ein", "ech\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "$,", "KON", "VAFIN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Christenherz, und bist kein Hengst.", "tokens": ["Chris\u00b7ten\u00b7herz", ",", "und", "bist", "kein", "Hengst", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}