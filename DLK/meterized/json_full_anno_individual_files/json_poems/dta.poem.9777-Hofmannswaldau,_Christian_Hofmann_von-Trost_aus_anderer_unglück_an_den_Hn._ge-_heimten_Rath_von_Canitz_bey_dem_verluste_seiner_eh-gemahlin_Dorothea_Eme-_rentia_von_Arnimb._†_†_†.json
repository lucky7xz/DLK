{"dta.poem.9777": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Trost aus anderer ungl\u00fcck/ an den Hn. ge-  \n heimten Rath von Canitz/ bey dem verluste  \n seiner eh-gemahlin/ Dorothea Eme-  \n rentia von Arnimb.  \n \u2020 \u2020 \u2020", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So ungeneigt ich auch zum schreiben/", "tokens": ["So", "un\u00b7ge\u00b7neigt", "ich", "auch", "zum", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "APPRART", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kanst du dennoch/ betr\u00fcbter freund/", "tokens": ["Kanst", "du", "den\u00b7noch", "/", "be\u00b7tr\u00fcb\u00b7ter", "freund", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indem dein treues auge weint/", "tokens": ["In\u00b7dem", "dein", "treu\u00b7es", "au\u00b7ge", "weint", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von mir nicht ungetr\u00f6stet bleiben.", "tokens": ["Von", "mir", "nicht", "un\u00b7ge\u00b7tr\u00f6s\u00b7tet", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich r\u00fchre/ wie du mir gethan/", "tokens": ["Ich", "r\u00fch\u00b7re", "/", "wie", "du", "mir", "ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWAV", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mitleidig deine wunden an.", "tokens": ["Mit\u00b7lei\u00b7dig", "dei\u00b7ne", "wun\u00b7den", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Dir wird dein eh gemahl entrissen.", "tokens": ["Dir", "wird", "dein", "eh", "ge\u00b7mahl", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "KOUS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was dir der tod mit ihr entwandt/", "tokens": ["Was", "dir", "der", "tod", "mit", "ihr", "ent\u00b7wandt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "APPR", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist beydes hof und stadt bekandt;", "tokens": ["Ist", "bey\u00b7des", "hof", "und", "stadt", "be\u00b7kandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVFIN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch wer kan deinen kummer wissen?", "tokens": ["Doch", "wer", "kan", "dei\u00b7nen", "kum\u00b7mer", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weh dem! den die erfahrung lehrt/", "tokens": ["Weh", "dem", "!", "den", "die", "er\u00b7fah\u00b7rung", "lehrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "$.", "ART", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie sehr dich dieser fall beschwert.", "tokens": ["Wie", "sehr", "dich", "die\u00b7ser", "fall", "be\u00b7schwert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Als GOtt/ das erste weib zu bauen/", "tokens": ["Als", "Gott", "/", "das", "ers\u00b7te", "weib", "zu", "bau\u00b7en", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die ribbe/ davon Eva kam/", "tokens": ["Die", "rib\u00b7be", "/", "da\u00b7von", "E\u00b7va", "kam", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "PAV", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus Adams seiner seiten nahm/", "tokens": ["Aus", "A\u00b7dams", "sei\u00b7ner", "sei\u00b7ten", "nahm", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Must\u2019 Adam diesen ri\u00df nicht schauen.", "tokens": ["Must'", "A\u00b7dam", "die\u00b7sen", "ri\u00df", "nicht", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "PDAT", "VVFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er schlieff/ weil ihm zu weh geschehn/", "tokens": ["Er", "schlieff", "/", "weil", "ihm", "zu", "weh", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "PTKA", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dergleichen schmertzen auszustehn.", "tokens": ["Derg\u00b7lei\u00b7chen", "schmert\u00b7zen", "aus\u00b7zu\u00b7stehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "O! wer begreifft dann itzt das leiden/", "tokens": ["O", "!", "wer", "be\u00b7greifft", "dann", "itzt", "das", "lei\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "ADV", "ADV", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da wir das schon erbaute weib/", "tokens": ["Da", "wir", "das", "schon", "er\u00b7bau\u00b7te", "weib", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mit ihr unser seel und leib/", "tokens": ["Und", "mit", "ihr", "un\u00b7ser", "seel", "und", "leib", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sehn in das grab auf ewig scheiden!", "tokens": ["Sehn", "in", "das", "grab", "auf", "e\u00b7wig", "schei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da man uns/ wer es nur erkennt/", "tokens": ["Da", "man", "uns", "/", "wer", "es", "nur", "er\u00b7kennt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "$(", "PWS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie mitten von einander trennt.", "tokens": ["Wie", "mit\u00b7ten", "von", "ein\u00b7an\u00b7der", "trennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Gewi\u00df/ die von den frauen sagen:", "tokens": ["Ge\u00b7wi\u00df", "/", "die", "von", "den", "frau\u00b7en", "sa\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ART", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sie die unruh/ die man sp\u00fchrt/", "tokens": ["Da\u00df", "sie", "die", "un\u00b7ruh", "/", "die", "man", "sp\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$(", "PRELS", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum ersten in die welt gef\u00fchrt/", "tokens": ["Zum", "ers\u00b7ten", "in", "die", "welt", "ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die solten deinen jammer tragen.", "tokens": ["Die", "sol\u00b7ten", "dei\u00b7nen", "jam\u00b7mer", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Denn di\u00df gesp\u00f6tte wird nicht wahr", "tokens": ["Denn", "di\u00df", "ge\u00b7sp\u00f6t\u00b7te", "wird", "nicht", "wahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVPP", "VAFIN", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als auf der frauen todten-bahr.", "tokens": ["Als", "auf", "der", "frau\u00b7en", "tod\u00b7ten\u00b7bahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zum minsten ist der tod der deinen", "tokens": ["Zum", "mins\u00b7ten", "ist", "der", "tod", "der", "dei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN", "ART", "NN", "ART", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die allererst- und letzte that/", "tokens": ["Die", "al\u00b7le\u00b7rer\u00b7st", "und", "letz\u00b7te", "that", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "ADJA", "VVFIN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Womit sie dich betr\u00fcbet hat/", "tokens": ["Wo\u00b7mit", "sie", "dich", "be\u00b7tr\u00fc\u00b7bet", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wodurch du hast lernen weinen.", "tokens": ["Und", "wo\u00b7durch", "du", "hast", "ler\u00b7nen", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VAFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die unruh/ die sie dir gebracht/", "tokens": ["Die", "un\u00b7ruh", "/", "die", "sie", "dir", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist/ da\u00df sie dich zum wittwer macht.", "tokens": ["Ist", "/", "da\u00df", "sie", "dich", "zum", "witt\u00b7wer", "macht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Man wei\u00df wie liebreich sie gewesen/", "tokens": ["Man", "wei\u00df", "wie", "lieb\u00b7reich", "sie", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOKOM", "ADJD", "PPER", "VAPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie fromm/ wie g\u00fctig/ wie erfreut;", "tokens": ["Wie", "fromm", "/", "wie", "g\u00fc\u00b7tig", "/", "wie", "er\u00b7freut", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$(", "PWAV", "ADJD", "$(", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ihres hertzens mildigkeit", "tokens": ["Und", "ih\u00b7res", "hert\u00b7zens", "mil\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kont man aus ihren augen lesen.", "tokens": ["Kont", "man", "aus", "ih\u00b7ren", "au\u00b7gen", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Di\u00df aber alles wie\u00df sie dir", "tokens": ["Di\u00df", "a\u00b7ber", "al\u00b7les", "wie\u00df", "sie", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "PIS", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit so viel hertzlicher begier.", "tokens": ["Mit", "so", "viel", "hertz\u00b7li\u00b7cher", "be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Viel/ die sich vor der ehe scheuen/", "tokens": ["Viel", "/", "die", "sich", "vor", "der", "e\u00b7he", "scheu\u00b7en", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PRELS", "PRF", "APPR", "ART", "KOUS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Begunten/ wenn sie euch gesehn/", "tokens": ["Be\u00b7gun\u00b7ten", "/", "wenn", "sie", "euch", "ge\u00b7sehn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von ihrem d\u00fcnckel abzustehn/", "tokens": ["Von", "ih\u00b7rem", "d\u00fcn\u00b7ckel", "ab\u00b7zu\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "VVIZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in gedancken schon zu freyen.", "tokens": ["Und", "in", "ge\u00b7dan\u00b7cken", "schon", "zu", "frey\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich aber sah auff euer gl\u00fcck", "tokens": ["Ich", "a\u00b7ber", "sah", "auff", "eu\u00b7er", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit einem sorgens-vollen blick.", "tokens": ["Mit", "ei\u00b7nem", "sor\u00b7gens\u00b7vol\u00b7len", "blick", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich dacht\u2019/ o h\u00f6chstbegl\u00fcckten beyde!", "tokens": ["Ich", "dacht'", "/", "o", "h\u00f6chst\u00b7be\u00b7gl\u00fcck\u00b7ten", "bey\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "FM", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch machte mein verlust mir bang.", "tokens": ["Doch", "mach\u00b7te", "mein", "ver\u00b7lust", "mir", "bang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Seyd gl\u00fccklich/ sprach ich; doch wie lang!", "tokens": ["Seyd", "gl\u00fcck\u00b7lich", "/", "sprach", "ich", ";", "doch", "wie", "lang", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$(", "VVFIN", "PPER", "$.", "ADV", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie bald st\u00f6rt euch der tod die freude?", "tokens": ["Wie", "bald", "st\u00f6rt", "euch", "der", "tod", "die", "freu\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was hilfft euch dann die gute wahl/", "tokens": ["Was", "hilfft", "euch", "dann", "die", "gu\u00b7te", "wahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Je s\u00fcsser eh/ je gr\u00f6sser qual!", "tokens": ["Je", "s\u00fcs\u00b7ser", "eh", "/", "je", "gr\u00f6s\u00b7ser", "qual", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOUS", "$(", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ein weib kan alle tugend haben/", "tokens": ["Ein", "weib", "kan", "al\u00b7le", "tu\u00b7gend", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auch sch\u00f6nheit/ stand und \u00fcberflu\u00df;", "tokens": ["Auch", "sch\u00f6n\u00b7heit", "/", "stand", "und", "\u00fc\u00b7berf\u00b7lu\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fcrcket dennoch nur verdru\u00df", "tokens": ["Und", "w\u00fcr\u00b7cket", "den\u00b7noch", "nur", "ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit allen ihren vorzugs-gaben:", "tokens": ["Mit", "al\u00b7len", "ih\u00b7ren", "vor\u00b7zugs\u00b7ga\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn nemlich sie voll \u00fcbermuth/", "tokens": ["Wenn", "nem\u00b7lich", "sie", "voll", "\u00fc\u00b7ber\u00b7muth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bey ihrer tugend trotzig thut.", "tokens": ["Bey", "ih\u00b7rer", "tu\u00b7gend", "trot\u00b7zig", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Dir war die deine so ergeben/", "tokens": ["Dir", "war", "die", "dei\u00b7ne", "so", "er\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PPOSAT", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als wenn in ihr kein wille w\u00e4r\u2019/", "tokens": ["Als", "wenn", "in", "ihr", "kein", "wil\u00b7le", "w\u00e4r'", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "APPR", "PPOSAT", "PIAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als sucht ihr gantzer wunsch nichts mehr/", "tokens": ["Als", "sucht", "ihr", "gant\u00b7zer", "wunsch", "nichts", "mehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPOSAT", "ADJA", "NN", "PIS", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denn deinem v\u00f6llig nachzuleben.", "tokens": ["Denn", "dei\u00b7nem", "v\u00f6l\u00b7lig", "nach\u00b7zu\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was dir beliebig und bequem/", "tokens": ["Was", "dir", "be\u00b7lie\u00b7big", "und", "be\u00b7quem", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War ihr durchgehends angenehm.", "tokens": ["War", "ihr", "durch\u00b7ge\u00b7hends", "an\u00b7ge\u00b7nehm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "In freuden war sie dein vergn\u00fcgen/", "tokens": ["In", "freu\u00b7den", "war", "sie", "dein", "ver\u00b7gn\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jm trauren deine tr\u00f6sterin.", "tokens": ["Jm", "trau\u00b7ren", "dei\u00b7ne", "tr\u00f6s\u00b7te\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie wuste sie dich abzuziehn/", "tokens": ["Wie", "wus\u00b7te", "sie", "dich", "ab\u00b7zu\u00b7ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "VVIZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und aller unlust vorzubiegen?", "tokens": ["Und", "al\u00b7ler", "un\u00b7lust", "vor\u00b7zu\u00b7bie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie machte sie es noch den tag/", "tokens": ["Wie", "mach\u00b7te", "sie", "es", "noch", "den", "tag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als Blumberg in den aschen lag.", "tokens": ["Als", "Blum\u00b7berg", "in", "den", "asc\u00b7hen", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Jhr saht das halbe gut verbrennen/", "tokens": ["Ihr", "saht", "das", "hal\u00b7be", "gut", "ver\u00b7bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das vorspiel leider! deiner n\u00f6th/", "tokens": ["Das", "vor\u00b7spiel", "lei\u00b7der", "!", "dei\u00b7ner", "n\u00f6th", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$.", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Worinn dich nun gest\u00fcrtzt ihr tod!", "tokens": ["Wo\u00b7rinn", "dich", "nun", "ge\u00b7st\u00fcrtzt", "ihr", "tod", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVPP", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch war es kaum bey ihr zu kennen.", "tokens": ["Doch", "war", "es", "kaum", "bey", "ihr", "zu", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Die klage lieff von hau\u00df zu hau\u00df/", "tokens": ["Die", "kla\u00b7ge", "lieff", "von", "hau\u00df", "zu", "hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur ihr saht unbek\u00fcmmert aus.", "tokens": ["Nur", "ihr", "saht", "un\u00b7be\u00b7k\u00fcm\u00b7mert", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ja selbst der tod mit seinem schrecken/", "tokens": ["Ja", "selbst", "der", "tod", "mit", "sei\u00b7nem", "schre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "APPR", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als er sich endlich eingestell\u2019t/", "tokens": ["Als", "er", "sich", "end\u00b7lich", "ein\u00b7ge\u00b7stell't", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vom brandte gleichsam angemeld\u2019t/", "tokens": ["Vom", "brand\u00b7te", "gleich\u00b7sam", "an\u00b7ge\u00b7meld't", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kont\u2019 ihr doch keine furcht erwecken.", "tokens": ["Kont'", "ihr", "doch", "kei\u00b7ne", "furcht", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So ruhig wie sie pflag zu seyn/", "tokens": ["So", "ru\u00b7hig", "wie", "sie", "pflag", "zu", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "VVFIN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schlieff sie auch in dem sterben ein.", "tokens": ["Schlieff", "sie", "auch", "in", "dem", "ster\u00b7ben", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "VVFIN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.15": {"line.1": {"text": "Sie sprach: seht ihr nicht da\u00df ich schlaffe?", "tokens": ["Sie", "sprach", ":", "seht", "ihr", "nicht", "da\u00df", "ich", "schlaf\u00b7fe", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PPER", "PTKNEG", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und schlo\u00df darauff die augen zu.", "tokens": ["Und", "schlo\u00df", "dar\u00b7auff", "die", "au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie starb/ als gienge sie zur ruh/", "tokens": ["Sie", "starb", "/", "als", "gien\u00b7ge", "sie", "zur", "ruh", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOKOM", "VVFIN", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und litte nicht der s\u00fcnden straffe.", "tokens": ["Und", "lit\u00b7te", "nicht", "der", "s\u00fcn\u00b7den", "straf\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die freundlichkeit verlie\u00df auch nicht", "tokens": ["Die", "freund\u00b7lich\u00b7keit", "ver\u00b7lie\u00df", "auch", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jhr schon erblastes angesicht.", "tokens": ["Ihr", "schon", "er\u00b7blas\u00b7tes", "an\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Kaum kan ich mich hierbey erwehren/", "tokens": ["Kaum", "kan", "ich", "mich", "hier\u00b7bey", "er\u00b7weh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die thr\u00e4nen netzen meine schrifft.", "tokens": ["Die", "thr\u00e4\u00b7nen", "net\u00b7zen", "mei\u00b7ne", "schrifft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie aber mu\u00df dann/ den es trifft/", "tokens": ["Wie", "a\u00b7ber", "mu\u00df", "dann", "/", "den", "es", "trifft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "ADV", "$(", "ART", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dich/ werther freund/ di\u00df leid verzehren!", "tokens": ["Dich", "/", "wert\u00b7her", "freund", "/", "di\u00df", "leid", "ver\u00b7zeh\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "ADJA", "NN", "$(", "PDS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der du in ihr/ die du verlierst/", "tokens": ["Der", "du", "in", "ihr", "/", "die", "du", "ver\u00b7lierst", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die g\u00fcte selbst zu grabe f\u00fchrst!", "tokens": ["Die", "g\u00fc\u00b7te", "selbst", "zu", "gra\u00b7be", "f\u00fchrst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Man kennt dich von den welt-gesch\u00e4fften/", "tokens": ["Man", "kennt", "dich", "von", "den", "welt\u00b7ge\u00b7sch\u00e4ff\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die du so r\u00fchmlich \u00fcberstrebt.", "tokens": ["Die", "du", "so", "r\u00fchm\u00b7lich", "\u00fc\u00b7bers\u00b7trebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man wei\u00df/ wie standhafft du gelebt/", "tokens": ["Man", "wei\u00df", "/", "wie", "stand\u00b7hafft", "du", "ge\u00b7lebt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "PWAV", "VVFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nun bist du von allen kr\u00e4fften:", "tokens": ["Und", "nun", "bist", "du", "von", "al\u00b7len", "kr\u00e4ff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil nemlich/ was dich ietzt ergreifft/", "tokens": ["Weil", "nem\u00b7lich", "/", "was", "dich", "ietzt", "er\u00b7greifft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$(", "PWS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hertze trifft/ und \u00fcberh\u00e4ufft.", "tokens": ["Das", "hert\u00b7ze", "trifft", "/", "und", "\u00fc\u00b7berh\u00b7\u00e4ufft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Du bist von den belebten feelen/", "tokens": ["Du", "bist", "von", "den", "be\u00b7leb\u00b7ten", "fee\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die zur empfindligkeit geneigt/", "tokens": ["Die", "zur", "emp\u00b7find\u00b7lig\u00b7keit", "ge\u00b7neigt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und von der musen brust ges\u00e4ugt/", "tokens": ["Und", "von", "der", "mu\u00b7sen", "brust", "ge\u00b7s\u00e4ugt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich mehr als grobe sinnen qu\u00e4len:", "tokens": ["Sich", "mehr", "als", "gro\u00b7be", "sin\u00b7nen", "qu\u00e4\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIS", "KOKOM", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dieweil je z\u00e4rter ein gem\u00fcth/", "tokens": ["Die\u00b7weil", "je", "z\u00e4r\u00b7ter", "ein", "ge\u00b7m\u00fcth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Je mehr und weiter es auch sieht.", "tokens": ["Je", "mehr", "und", "wei\u00b7ter", "es", "auch", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Sag\u2019 ich: du soltest dich besinnen/", "tokens": ["Sag'", "ich", ":", "du", "sol\u00b7test", "dich", "be\u00b7sin\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was noch f\u00fcr trost dein leiden hat/", "tokens": ["Was", "noch", "f\u00fcr", "trost", "dein", "lei\u00b7den", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "VVFIN", "PPOSAT", "VVINF", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das beyleid dieser gantzen stadt/", "tokens": ["Das", "bey\u00b7leid", "die\u00b7ser", "gant\u00b7zen", "stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ja zweyer grossen Churf\u00fcrstinnen.", "tokens": ["Ja", "zwey\u00b7er", "gros\u00b7sen", "Chur\u00b7f\u00fcrs\u00b7tin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sprichst du: ein trost von solcher h\u00f6h", "tokens": ["Sprichst", "du", ":", "ein", "trost", "von", "sol\u00b7cher", "h\u00f6h"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Rechtfertige vielmehr dein weh.", "tokens": ["Recht\u00b7fer\u00b7ti\u00b7ge", "viel\u00b7mehr", "dein", "weh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.20": {"line.1": {"text": "Sag\u2019 ich: da\u00df von den sieben erben/", "tokens": ["Sag'", "ich", ":", "da\u00df", "von", "den", "sie\u00b7ben", "er\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "KOUS", "APPR", "ART", "CARD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das liebste pfand von ihrer treu/", "tokens": ["Das", "liebs\u00b7te", "pfand", "von", "ih\u00b7rer", "treu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dein sohn dir \u00fcberblieben sey:", "tokens": ["Dein", "sohn", "dir", "\u00fc\u00b7berb\u00b7lie\u00b7ben", "sey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Siehst du in ihm sie t\u00e4glich sterben.", "tokens": ["Siehst", "du", "in", "ihm", "sie", "t\u00e4g\u00b7lich", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Indem ihr bildni\u00df/ das er tr\u00e4gt/", "tokens": ["In\u00b7dem", "ihr", "bild\u00b7ni\u00df", "/", "das", "er", "tr\u00e4gt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir ihren tod vor augen legt.", "tokens": ["Dir", "ih\u00b7ren", "tod", "vor", "au\u00b7gen", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Sag\u2019 ich denn/ dich vergn\u00fcgt zu machen/", "tokens": ["Sag'", "ich", "denn", "/", "dich", "ver\u00b7gn\u00fcgt", "zu", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$(", "PPER", "VVPP", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie schlaffe/ wecke sie nicht auf/", "tokens": ["Sie", "schlaf\u00b7fe", "/", "we\u00b7cke", "sie", "nicht", "auf", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch deiner thr\u00e4nen steken lauf:", "tokens": ["Durch", "dei\u00b7ner", "thr\u00e4\u00b7nen", "ste\u00b7ken", "lauf", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wartest du/ sie soll erwachen.", "tokens": ["So", "war\u00b7test", "du", "/", "sie", "soll", "er\u00b7wa\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch wenn der neue morgen tagt/", "tokens": ["Doch", "wenn", "der", "neu\u00b7e", "mor\u00b7gen", "tagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird sie viel hefftiger beklagt.", "tokens": ["Wird", "sie", "viel", "heff\u00b7ti\u00b7ger", "be\u00b7klagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Dermassen wei\u00df ich nichts zu finden/", "tokens": ["Der\u00b7mas\u00b7sen", "wei\u00df", "ich", "nichts", "zu", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wodurch dein schmertz zu stillen sey.", "tokens": ["Wo\u00b7durch", "dein", "schmertz", "zu", "stil\u00b7len", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJD", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die wunden sind noch allzu neu/", "tokens": ["Die", "wun\u00b7den", "sind", "noch", "all\u00b7zu", "neu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nur die zeit mu\u00df sie verbinden.", "tokens": ["Und", "nur", "die", "zeit", "mu\u00df", "sie", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zumahl dein kummerreicher geist", "tokens": ["Zu\u00b7mahl", "dein", "kum\u00b7mer\u00b7rei\u00b7cher", "geist"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie immer weit und weiter reist.", "tokens": ["Sie", "im\u00b7mer", "weit", "und", "wei\u00b7ter", "reist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Jedoch/ wofern ich was soll rathen/", "tokens": ["Je\u00b7doch", "/", "wo\u00b7fern", "ich", "was", "soll", "ra\u00b7then", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPER", "PIS", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Weil doch mein unfall mich ge\u00fcbt:", "tokens": ["Weil", "doch", "mein", "un\u00b7fall", "mich", "ge\u00b7\u00fcbt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verla\u00df den ort/ der dich betr\u00fcbt/", "tokens": ["Ver\u00b7la\u00df", "den", "ort", "/", "der", "dich", "be\u00b7tr\u00fcbt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sieh dich um in fremden staaten:", "tokens": ["Und", "sieh", "dich", "um", "in", "frem\u00b7den", "staa\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vielleicht wird deine traurigkeit/", "tokens": ["Viel\u00b7leicht", "wird", "dei\u00b7ne", "trau\u00b7rig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo nicht vertrieben/ doch zerstreut.", "tokens": ["Wo", "nicht", "ver\u00b7trie\u00b7ben", "/", "doch", "zer\u00b7streut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "VVPP", "$(", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Du kanst ohn di\u00df/ in diesem stande/", "tokens": ["Du", "kanst", "ohn", "di\u00df", "/", "in", "die\u00b7sem", "stan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PDS", "$(", "APPR", "PDAT", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bey uns nicht bleiben/ wo du bist.", "tokens": ["Bey", "uns", "nicht", "blei\u00b7ben", "/", "wo", "du", "bist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "VVINF", "$(", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der tod hat hier dem hau\u00df verw\u00fcst\u2019t/", "tokens": ["Der", "tod", "hat", "hier", "dem", "hau\u00df", "ver\u00b7w\u00fcst't", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das feuer aber auf dem lande.", "tokens": ["Das", "feu\u00b7er", "a\u00b7ber", "auf", "dem", "lan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wohin sich nur dein auge kehrt/", "tokens": ["Wo\u00b7hin", "sich", "nur", "dein", "au\u00b7ge", "kehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Liegt alles einsam und verst\u00f6rt.", "tokens": ["Liegt", "al\u00b7les", "ein\u00b7sam", "und", "ver\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Zeuch hin/ weil noch der schmertz am gr\u00f6\u00dften/", "tokens": ["Zeuch", "hin", "/", "weil", "noch", "der", "schmertz", "am", "gr\u00f6\u00df\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$(", "KOUS", "ADV", "ART", "NN", "APPRART", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo der ber\u00fchmte Gr\u00e4vius/", "tokens": ["Wo", "der", "be\u00b7r\u00fchm\u00b7te", "Gr\u00e4\u00b7vius", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo Spanheim/ Brockhu\u00df/ Francius/", "tokens": ["Wo", "Span\u00b7heim", "/", "Brock\u00b7hu\u00df", "/", "Fran\u00b7ci\u00b7us", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "NE", "$(", "NN", "$(", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den grossen K\u00f6nig Wilhelm tr\u00f6sten:", "tokens": ["Den", "gros\u00b7sen", "K\u00f6\u00b7nig", "Wil\u00b7helm", "tr\u00f6s\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der eine K\u00f6nigin bedaurt/", "tokens": ["Der", "ei\u00b7ne", "K\u00f6\u00b7ni\u00b7gin", "be\u00b7daurt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Um welche gantz Europa traurt.", "tokens": ["Um", "wel\u00b7che", "gantz", "Eu\u00b7ro\u00b7pa", "traurt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Es klagen so viel nationen/", "tokens": ["Es", "kla\u00b7gen", "so", "viel", "na\u00b7ti\u00b7o\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als st\u00fcrb in ihr zugleich dahin", "tokens": ["Als", "st\u00fcrb", "in", "ihr", "zu\u00b7gleich", "da\u00b7hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "APPR", "PPER", "ADV", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "All dieser v\u00f6lcker K\u00f6nigin:", "tokens": ["All", "die\u00b7ser", "v\u00f6l\u00b7cker", "K\u00f6\u00b7ni\u00b7gin", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch mu\u00df ihr wittwer es gewohnen.", "tokens": ["Doch", "mu\u00df", "ihr", "witt\u00b7wer", "es", "ge\u00b7woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was einen solchen tr\u00f6sten kan/", "tokens": ["Was", "ei\u00b7nen", "sol\u00b7chen", "tr\u00f6s\u00b7ten", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "PIAT", "NN", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nimt billiger dein leiden an.", "tokens": ["Nimt", "bil\u00b7li\u00b7ger", "dein", "lei\u00b7den", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Bist du nun/ wo die musen hausen/", "tokens": ["Bist", "du", "nun", "/", "wo", "die", "mu\u00b7sen", "hau\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$(", "PWAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf der Bataver Helicon;", "tokens": ["Auf", "der", "Ba\u00b7ta\u00b7ver", "He\u00b7li\u00b7con", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Wirst du vielleicht nicht weit davon", "tokens": ["Wirst", "du", "viel\u00b7leicht", "nicht", "weit", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch die carthaunen h\u00f6ren sausen:", "tokens": ["Auch", "die", "car\u00b7thau\u00b7nen", "h\u00f6\u00b7ren", "sau\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wo gleichsam sich die halbe welt", "tokens": ["Wo", "gleich\u00b7sam", "sich", "die", "hal\u00b7be", "welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu streit und kriegen eingestellt.", "tokens": ["Zu", "streit", "und", "krie\u00b7gen", "ein\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Da wird der held/ von dem wir sprechen/", "tokens": ["Da", "wird", "der", "held", "/", "von", "dem", "wir", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$(", "APPR", "PRELS", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den kummer/ der ihn traurig macht/", "tokens": ["Den", "kum\u00b7mer", "/", "der", "ihn", "trau\u00b7rig", "macht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo nicht in einer strengen schlacht/", "tokens": ["Wo", "nicht", "in", "ei\u00b7ner", "stren\u00b7gen", "schlacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dennoch an einer vestung brechen:", "tokens": ["Den\u00b7noch", "an", "ei\u00b7ner", "ves\u00b7tung", "bre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und so mir recht ist/ h\u00f6rt man schon", "tokens": ["Und", "so", "mir", "recht", "ist", "/", "h\u00f6rt", "man", "schon"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PPER", "ADJD", "VAFIN", "$(", "VVFIN", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor Namur seinen donner-thon.", "tokens": ["Vor", "Na\u00b7mur", "sei\u00b7nen", "don\u00b7ner\u00b7thon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Was d\u00fcnckt dich bey den dicken w\u00e4llen/", "tokens": ["Was", "d\u00fcnckt", "dich", "bey", "den", "di\u00b7cken", "w\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den steilen felsen/ da sie stehn/", "tokens": ["Den", "stei\u00b7len", "fel\u00b7sen", "/", "da", "sie", "stehn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KOUS", "PPER", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den mauren/ die kaum abzusehn:", "tokens": ["Den", "mau\u00b7ren", "/", "die", "kaum", "ab\u00b7zu\u00b7sehn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Solt\u2019 einen hier auch etwas f\u00e4llen?", "tokens": ["Solt'", "ei\u00b7nen", "hier", "auch", "et\u00b7was", "f\u00e4l\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Voraus/ da Boufler sie besch\u00fctzt/", "tokens": ["Vo\u00b7raus", "/", "da", "Bouf\u00b7ler", "sie", "be\u00b7sch\u00fctzt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und zwischen hundert st\u00fccken sitzt.", "tokens": ["Und", "zwi\u00b7schen", "hun\u00b7dert", "st\u00fc\u00b7cken", "sitzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Gieb acht/ die dort ihr lager schlagen/", "tokens": ["Gieb", "acht", "/", "die", "dort", "ihr", "la\u00b7ger", "schla\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$(", "ART", "ADV", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die r\u00fcsten sich in diese klufft/", "tokens": ["Die", "r\u00fcs\u00b7ten", "sich", "in", "die\u00b7se", "klufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hoch erhaben in die lufft/", "tokens": ["So", "hoch", "er\u00b7ha\u00b7ben", "in", "die", "lufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den tod durch feur und schwerdt zu tragen:", "tokens": ["Den", "tod", "durch", "feur", "und", "schwerdt", "zu", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und brechen w\u00fcrcklich durch den stein", "tokens": ["Und", "bre\u00b7chen", "w\u00fcrck\u00b7lich", "durch", "den", "stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von allen eck- und seiten ein.", "tokens": ["Von", "al\u00b7len", "eck", "und", "sei\u00b7ten", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "TRUNC", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Da wird ein gantzes werck ersteigen/", "tokens": ["Da", "wird", "ein", "gant\u00b7zes", "werck", "er\u00b7stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hier ein halber thurm gesprengt:", "tokens": ["Und", "hier", "ein", "hal\u00b7ber", "thurm", "ge\u00b7sprengt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sieht man freund und feind vermengt/", "tokens": ["Da", "sieht", "man", "freund", "und", "feind", "ver\u00b7mengt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bey tausenden darnieder liegen.", "tokens": ["Bey", "tau\u00b7sen\u00b7den", "dar\u00b7nie\u00b7der", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Des siegers und besiegten fall", "tokens": ["Des", "sie\u00b7gers", "und", "be\u00b7sieg\u00b7ten", "fall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcllt in- und ausserhalb den wall.", "tokens": ["F\u00fcllt", "in", "und", "aus\u00b7ser\u00b7halb", "den", "wall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "TRUNC", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Und zwar wilst du bekandte suchen/", "tokens": ["Und", "zwar", "wilst", "du", "be\u00b7kand\u00b7te", "su\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Besieh der Brandenburger schaar.", "tokens": ["Be\u00b7sieh", "der", "Bran\u00b7den\u00b7bur\u00b7ger", "schaar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie dr\u00e4ngen die sich zur gefahr/", "tokens": ["Wie", "dr\u00e4n\u00b7gen", "die", "sich", "zur", "ge\u00b7fahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "PRF", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df auch die Frantzen auff sie fluchen/", "tokens": ["Da\u00df", "auch", "die", "Frant\u00b7zen", "auff", "sie", "flu\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Als wenn von ihrer seiten her", "tokens": ["Als", "wenn", "von", "ih\u00b7rer", "sei\u00b7ten", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "APPR", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der tod noch eins so gr\u00e4\u00dflich w\u00e4r.", "tokens": ["Der", "tod", "noch", "eins", "so", "gr\u00e4\u00df\u00b7lich", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIS", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Allein/ indem sie auffwerts klimmen/", "tokens": ["Al\u00b7lein", "/", "in\u00b7dem", "sie", "auff\u00b7werts", "klim\u00b7men", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und an den fels wie gemsen ziehn;", "tokens": ["Und", "an", "den", "fels", "wie", "gem\u00b7sen", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "KOKOM", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Klagt manches stamm-hau\u00df in Berlin:", "tokens": ["Klagt", "man\u00b7ches", "stam\u00b7mhau\u00df", "in", "Ber\u00b7lin", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df ihrer viel im blute schwimmen/", "tokens": ["Da\u00df", "ih\u00b7rer", "viel", "im", "blu\u00b7te", "schwim\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und mancher/ der uns lieb gewest/", "tokens": ["Und", "man\u00b7cher", "/", "der", "uns", "lieb", "ge\u00b7west", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "$(", "PRELS", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den geist hier in die l\u00fcffte bl\u00e4st.", "tokens": ["Den", "geist", "hier", "in", "die", "l\u00fcff\u00b7te", "bl\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Ja selbst die stadt mit ihren mauren", "tokens": ["Ja", "selbst", "die", "stadt", "mit", "ih\u00b7ren", "mau\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zerf\u00e4llt und sinckt in asch\u2019 und grau\u00df.", "tokens": ["Zer\u00b7f\u00e4llt", "und", "sinckt", "in", "asch'", "und", "grau\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "APPR", "NE", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist in derselben auch ein hau\u00df/", "tokens": ["Ist", "in", "der\u00b7sel\u00b7ben", "auch", "ein", "hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In welchem man nicht h\u00f6re trauren?", "tokens": ["In", "wel\u00b7chem", "man", "nicht", "h\u00f6\u00b7re", "trau\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "PTKNEG", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zumahl da \u00f6ffters weib und kind", "tokens": ["Zu\u00b7mahl", "da", "\u00f6ff\u00b7ters", "weib", "und", "kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zugleich mit auffgeflogen sind.", "tokens": ["Zu\u00b7gleich", "mit", "auff\u00b7ge\u00b7flo\u00b7gen", "sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Bey so viel unzehlbaren leichen/", "tokens": ["Bey", "so", "viel", "un\u00b7zehl\u00b7ba\u00b7ren", "lei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "ADJA", "VVINF", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Mit maur und wall dahin gestreckt;", "tokens": ["Mit", "maur", "und", "wall", "da\u00b7hin", "ge\u00b7streckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was meynst du/ wirst du nicht erschreckt/", "tokens": ["Was", "meynst", "du", "/", "wirst", "du", "nicht", "er\u00b7schreckt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$(", "VAFIN", "PPER", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein leid mit dieser fall vergleichen?", "tokens": ["Dein", "leid", "mit", "die\u00b7ser", "fall", "ver\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und finden gegen ihrer last/", "tokens": ["Und", "fin\u00b7den", "ge\u00b7gen", "ih\u00b7rer", "last", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df du gar nicht zu klagen hast.", "tokens": ["Da\u00df", "du", "gar", "nicht", "zu", "kla\u00b7gen", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Wie d\u00fcrfftest du vom tode klagen/", "tokens": ["Wie", "d\u00fcrff\u00b7test", "du", "vom", "to\u00b7de", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo sterben ein geringes ist?", "tokens": ["Wo", "ster\u00b7ben", "ein", "ge\u00b7rin\u00b7ges", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Di\u00df/ warum du bek\u00fcmmert bist/", "tokens": ["Di\u00df", "/", "wa\u00b7rum", "du", "be\u00b7k\u00fcm\u00b7mert", "bist", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "PWAV", "PPER", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sieht man auff allen gassen tragen:", "tokens": ["Sieht", "man", "auff", "al\u00b7len", "gas\u00b7sen", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn nur nicht/ an des grabes statt/", "tokens": ["Wenn", "nur", "nicht", "/", "an", "des", "gra\u00b7bes", "statt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "$(", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hau\u00df sie \u00fcbersch\u00fcttet hat.", "tokens": ["Das", "hau\u00df", "sie", "\u00fc\u00b7ber\u00b7sch\u00fct\u00b7tet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Wie viel sind hier zu wittwen worden/", "tokens": ["Wie", "viel", "sind", "hier", "zu", "witt\u00b7wen", "wor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "ADV", "PTKZU", "VVINF", "VAPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie vielen stirbt der gantze stamm?", "tokens": ["Wie", "vie\u00b7len", "stirbt", "der", "gant\u00b7ze", "stamm", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was dir der tod geruhig nahm/", "tokens": ["Was", "dir", "der", "tod", "ge\u00b7ru\u00b7hig", "nahm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00e4llt hier durch lauter schwerdt und morden/", "tokens": ["F\u00e4llt", "hier", "durch", "lau\u00b7ter", "schwerdt", "und", "mor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PIAT", "NN", "KON", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So da\u00df auch \u00f6ffters die gebein", "tokens": ["So", "da\u00df", "auch", "\u00f6ff\u00b7ters", "die", "ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der todten nicht zu finden seyn.", "tokens": ["Der", "tod\u00b7ten", "nicht", "zu", "fin\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKNEG", "PTKZU", "VVINF", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Als dorten gar kein trost zu hoffen/", "tokens": ["Als", "dor\u00b7ten", "gar", "kein", "trost", "zu", "hof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da Tullius sein kind verlohr/", "tokens": ["Da", "Tul\u00b7li\u00b7us", "sein", "kind", "ver\u00b7lohr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hielt man ihm die verw\u00fcstung vor/", "tokens": ["Hielt", "man", "ihm", "die", "ver\u00b7w\u00fcs\u00b7tung", "vor", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die damahls Africa betroffen/", "tokens": ["Die", "da\u00b7mahls", "A\u00b7fri\u00b7ca", "be\u00b7trof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NE", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und welche durch des raubes hand", "tokens": ["Und", "wel\u00b7che", "durch", "des", "rau\u00b7bes", "hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die gantze gegend umgewandt.", "tokens": ["Die", "gant\u00b7ze", "ge\u00b7gend", "um\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Wenn du di\u00df wirst vor Namur finden/", "tokens": ["Wenn", "du", "di\u00df", "wirst", "vor", "Na\u00b7mur", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VAFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Alsdann wird deine k\u00fcmmerni\u00df/", "tokens": ["Als\u00b7dann", "wird", "dei\u00b7ne", "k\u00fcm\u00b7mer\u00b7ni\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum wenigsten so lang gewi\u00df/", "tokens": ["Zum", "we\u00b7nigs\u00b7ten", "so", "lang", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ADV", "ADJD", "ADV", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Als du vor Namur bist/ verschwinden:", "tokens": ["Als", "du", "vor", "Na\u00b7mur", "bist", "/", "ver\u00b7schwin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VAFIN", "$(", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Wie sich ein kleiner flu\u00df verliert/", "tokens": ["Wie", "sich", "ein", "klei\u00b7ner", "flu\u00df", "ver\u00b7liert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn er sich in das meer gef\u00fchrt.", "tokens": ["Wenn", "er", "sich", "in", "das", "meer", "ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Alsdann wirst du/ nach allen f\u00e4llen/", "tokens": ["Als\u00b7dann", "wirst", "du", "/", "nach", "al\u00b7len", "f\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "APPR", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die du vor Namur siehst und h\u00f6rst/", "tokens": ["Die", "du", "vor", "Na\u00b7mur", "siehst", "und", "h\u00f6rst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Wenn du nun wieder zu uns kehrst/", "tokens": ["Wenn", "du", "nun", "wie\u00b7der", "zu", "uns", "kehrst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dir auch Berlin vor augen stellen:", "tokens": ["Dir", "auch", "Ber\u00b7lin", "vor", "au\u00b7gen", "stel\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NE", "APPR", "NN", "VVINF", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Und da auch finden/ was dein leid", "tokens": ["Und", "da", "auch", "fin\u00b7den", "/", "was", "dein", "leid"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVINF", "$(", "PWS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch fremde traurigkeit zerstreut.", "tokens": ["Durch", "frem\u00b7de", "trau\u00b7rig\u00b7keit", "zer\u00b7streut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Da wird sich (derer zu geschweigen/", "tokens": ["Da", "wird", "sich", "(", "de\u00b7rer", "zu", "ge\u00b7schwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "$(", "PDS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So Namurs sturm dahin gerafft)", "tokens": ["So", "Na\u00b7murs", "sturm", "da\u00b7hin", "ge\u00b7rafft", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJD", "PAV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Selbst deines F\u00fcrstens leidenschafft", "tokens": ["Selbst", "dei\u00b7nes", "F\u00fcrs\u00b7tens", "lei\u00b7den\u00b7schafft"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und seines nechsten dieners zeigen:", "tokens": ["Und", "sei\u00b7nes", "nechs\u00b7ten", "die\u00b7ners", "zei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der/ wie sein F\u00fcrst/ durch gleichen schlu\u00df", "tokens": ["Der", "/", "wie", "sein", "F\u00fcrst", "/", "durch", "glei\u00b7chen", "schlu\u00df"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "$(", "KOKOM", "PPOSAT", "NN", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Um einen bruder trauren mu\u00df.", "tokens": ["Um", "ei\u00b7nen", "bru\u00b7der", "trau\u00b7ren", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Da wird dir (wilst du wittwers haben/)", "tokens": ["Da", "wird", "dir", "(", "wilst", "du", "witt\u00b7wers", "ha\u00b7ben", "/", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "VMFIN", "PPER", "ADV", "VAFIN", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Below zum exempel stehn.", "tokens": ["Dein", "Be\u00b7low", "zum", "ex\u00b7em\u00b7pel", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da wirst du einen Kniphau\u00df sehn/", "tokens": ["Da", "wirst", "du", "ei\u00b7nen", "Kni\u00b7phau\u00df", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der gar drey leichen mu\u00df begraben:", "tokens": ["Der", "gar", "drey", "lei\u00b7chen", "mu\u00df", "be\u00b7gra\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "CARD", "VVINF", "VMFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und Lottum/ dem der tod entreist/", "tokens": ["Und", "Lot\u00b7tum", "/", "dem", "der", "tod", "en\u00b7treist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "ART", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was selbst der neid unsch\u00e4tzbar heist.", "tokens": ["Was", "selbst", "der", "neid", "un\u00b7sch\u00e4tz\u00b7bar", "heist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Da wirst du endlich auch erfahren/", "tokens": ["Da", "wirst", "du", "end\u00b7lich", "auch", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie alles trauren ohne frucht:", "tokens": ["Wie", "al\u00b7les", "trau\u00b7ren", "oh\u00b7ne", "frucht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVINF", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie ich/ der dich zu tr\u00f6sten sucht/", "tokens": ["Wie", "ich", "/", "der", "dich", "zu", "tr\u00f6s\u00b7ten", "sucht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$(", "PRELS", "PPER", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich leide seit so vielen jahren;", "tokens": ["Mich", "lei\u00b7de", "seit", "so", "vie\u00b7len", "jah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und den verlust/ den ich gethan/", "tokens": ["Und", "den", "ver\u00b7lust", "/", "den", "ich", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$(", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die zeit auch nicht ersetzen kan.", "tokens": ["Die", "zeit", "auch", "nicht", "er\u00b7set\u00b7zen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "O la\u00df doch zu/ da\u00df bey dem singen/", "tokens": ["O", "la\u00df", "doch", "zu", "/", "da\u00df", "bey", "dem", "sin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKZU", "$(", "KOUS", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von deiner Arnimb s\u00fcssen eh/", "tokens": ["Von", "dei\u00b7ner", "Ar\u00b7nimb", "s\u00fcs\u00b7sen", "eh", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "KOUS", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich einmahl noch mein herbes weh/", "tokens": ["Ich", "ein\u00b7mahl", "noch", "mein", "her\u00b7bes", "weh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die K\u00fchleweinin la\u00df\u2019 erklingen!", "tokens": ["Die", "K\u00fch\u00b7le\u00b7wei\u00b7nin", "la\u00df'", "er\u00b7klin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vielleicht/ in dem ich solches thu/", "tokens": ["Viel\u00b7leicht", "/", "in", "dem", "ich", "sol\u00b7ches", "thu", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "APPR", "PRELS", "PPER", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vergist du dich/ und h\u00f6rst mir zu.", "tokens": ["Ver\u00b7gist", "du", "dich", "/", "und", "h\u00f6rst", "mir", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$(", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}