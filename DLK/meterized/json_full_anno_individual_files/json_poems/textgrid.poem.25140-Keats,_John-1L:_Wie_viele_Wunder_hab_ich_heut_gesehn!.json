{"textgrid.poem.25140": {"metadata": {"author": {"name": "Keats, John", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie viele Wunder hab ich heut gesehn!", "genre": "verse", "period": "N.A.", "pub_year": 1816, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie viele Wunder hab ich heut gesehn!", "tokens": ["Wie", "vie\u00b7le", "Wun\u00b7der", "hab", "ich", "heut", "ge\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den hei\u00dfen Ku\u00df, mit dem das Sonnenlicht", "tokens": ["Den", "hei\u00b7\u00dfen", "Ku\u00df", ",", "mit", "dem", "das", "Son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Des Morgens Tr\u00e4ne trank, \u2013 im Abendlicht", "tokens": ["Des", "Mor\u00b7gens", "Tr\u00e4\u00b7ne", "trank", ",", "\u2013", "im", "A\u00b7bend\u00b7licht"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ART", "ADV", "NN", "VVFIN", "$,", "$(", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Lang tote Helden \u00fcber Wolken gehn \u2013", "tokens": ["Lang", "to\u00b7te", "Hel\u00b7den", "\u00fc\u00b7ber", "Wol\u00b7ken", "gehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "APPR", "NN", "VVINF", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Des Ozeans urewiges Ph\u00e4nomen:", "tokens": ["Des", "O\u00b7ze\u00b7ans", "u\u00b7re\u00b7wi\u00b7ges", "Ph\u00e4\u00b7no\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Meer, das Hoffnung tr\u00e4gt und Hoffnung bricht", "tokens": ["Das", "Meer", ",", "das", "Hoff\u00b7nung", "tr\u00e4gt", "und", "Hoff\u00b7nung", "bricht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wilde urweltliche Sprache spricht", "tokens": ["Und", "wil\u00b7de", "ur\u00b7welt\u00b7li\u00b7che", "Spra\u00b7che", "spricht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "ADJA", "NN", "VVFIN"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.4": {"text": "Und grollt und seufzt von Werden und Vergehn.", "tokens": ["Und", "grollt", "und", "seufzt", "von", "Wer\u00b7den", "und", "Ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und jetzt, Georg, da ich dir dieses schreibe,", "tokens": ["Und", "jetzt", ",", "Ge\u00b7org", ",", "da", "ich", "dir", "die\u00b7ses", "schrei\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "NE", "$,", "KOUS", "PPER", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lugt Cynthia bleich aus wei\u00dfen Wolkenb\u00e4nken,", "tokens": ["Lugt", "Cyn\u00b7thia", "bleich", "aus", "wei\u00b7\u00dfen", "Wol\u00b7ken\u00b7b\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein wenig nur, als sei heut Hochzeitnacht.", "tokens": ["Ein", "we\u00b7nig", "nur", ",", "als", "sei", "heut", "Hoch\u00b7zeit\u00b7nacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "$,", "KOKOM", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und lade sie zu be\u00dfrem Zeitvertreibe.", "tokens": ["Und", "la\u00b7de", "sie", "zu", "be\u00df\u00b7rem", "Zeit\u00b7ver\u00b7trei\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch h\u00e4tt' ich nicht dies treue Deingedenken,", "tokens": ["Doch", "h\u00e4tt'", "ich", "nicht", "dies", "treu\u00b7e", "Dein\u00b7ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PDS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was w\u00e4r des Meers und was des Himmels Pracht!", "tokens": ["Was", "w\u00e4r", "des", "Meers", "und", "was", "des", "Him\u00b7mels", "Pracht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "KON", "PWS", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wie viele Wunder hab ich heut gesehn!", "tokens": ["Wie", "vie\u00b7le", "Wun\u00b7der", "hab", "ich", "heut", "ge\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den hei\u00dfen Ku\u00df, mit dem das Sonnenlicht", "tokens": ["Den", "hei\u00b7\u00dfen", "Ku\u00df", ",", "mit", "dem", "das", "Son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Des Morgens Tr\u00e4ne trank, \u2013 im Abendlicht", "tokens": ["Des", "Mor\u00b7gens", "Tr\u00e4\u00b7ne", "trank", ",", "\u2013", "im", "A\u00b7bend\u00b7licht"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ART", "ADV", "NN", "VVFIN", "$,", "$(", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Lang tote Helden \u00fcber Wolken gehn \u2013", "tokens": ["Lang", "to\u00b7te", "Hel\u00b7den", "\u00fc\u00b7ber", "Wol\u00b7ken", "gehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "APPR", "NN", "VVINF", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.6": {"line.1": {"text": "Des Ozeans urewiges Ph\u00e4nomen:", "tokens": ["Des", "O\u00b7ze\u00b7ans", "u\u00b7re\u00b7wi\u00b7ges", "Ph\u00e4\u00b7no\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Meer, das Hoffnung tr\u00e4gt und Hoffnung bricht", "tokens": ["Das", "Meer", ",", "das", "Hoff\u00b7nung", "tr\u00e4gt", "und", "Hoff\u00b7nung", "bricht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wilde urweltliche Sprache spricht", "tokens": ["Und", "wil\u00b7de", "ur\u00b7welt\u00b7li\u00b7che", "Spra\u00b7che", "spricht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "ADJA", "NN", "VVFIN"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.4": {"text": "Und grollt und seufzt von Werden und Vergehn.", "tokens": ["Und", "grollt", "und", "seufzt", "von", "Wer\u00b7den", "und", "Ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und jetzt, Georg, da ich dir dieses schreibe,", "tokens": ["Und", "jetzt", ",", "Ge\u00b7org", ",", "da", "ich", "dir", "die\u00b7ses", "schrei\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "NE", "$,", "KOUS", "PPER", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lugt Cynthia bleich aus wei\u00dfen Wolkenb\u00e4nken,", "tokens": ["Lugt", "Cyn\u00b7thia", "bleich", "aus", "wei\u00b7\u00dfen", "Wol\u00b7ken\u00b7b\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein wenig nur, als sei heut Hochzeitnacht.", "tokens": ["Ein", "we\u00b7nig", "nur", ",", "als", "sei", "heut", "Hoch\u00b7zeit\u00b7nacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "$,", "KOKOM", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Und lade sie zu be\u00dfrem Zeitvertreibe.", "tokens": ["Und", "la\u00b7de", "sie", "zu", "be\u00df\u00b7rem", "Zeit\u00b7ver\u00b7trei\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch h\u00e4tt' ich nicht dies treue Deingedenken,", "tokens": ["Doch", "h\u00e4tt'", "ich", "nicht", "dies", "treu\u00b7e", "Dein\u00b7ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PDS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was w\u00e4r des Meers und was des Himmels Pracht!", "tokens": ["Was", "w\u00e4r", "des", "Meers", "und", "was", "des", "Him\u00b7mels", "Pracht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "KON", "PWS", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}