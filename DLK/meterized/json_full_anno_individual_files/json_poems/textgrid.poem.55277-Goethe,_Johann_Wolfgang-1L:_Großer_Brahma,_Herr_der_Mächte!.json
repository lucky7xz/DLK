{"textgrid.poem.55277": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gro\u00dfer Brahma, Herr der M\u00e4chte!", "genre": "verse", "period": "N.A.", "pub_year": 1803, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gro\u00dfer Brahma, Herr der M\u00e4chte!", "tokens": ["Gro\u00b7\u00dfer", "Brah\u00b7ma", ",", "Herr", "der", "M\u00e4ch\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles ist von deinem Samen,", "tokens": ["Al\u00b7les", "ist", "von", "dei\u00b7nem", "Sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so bist du der Gerechte!", "tokens": ["Und", "so", "bist", "du", "der", "Ge\u00b7rech\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Hast du denn allein die Brahmen,", "tokens": ["Hast", "du", "denn", "al\u00b7lein", "die", "Brah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nur die Rajas und die Reichen,", "tokens": ["Nur", "die", "Ra\u00b7jas", "und", "die", "Rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Hast du sie allein geschaffen?", "tokens": ["Hast", "du", "sie", "al\u00b7lein", "ge\u00b7schaf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder bist auch du's, der Affen", "tokens": ["O\u00b7der", "bist", "auch", "du's", ",", "der", "Af\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PIS", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Werden lie\u00df und unseresgleichen?", "tokens": ["Wer\u00b7den", "lie\u00df", "und", "un\u00b7se\u00b7res\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "KON", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Edel sind wir nicht zu nennen:", "tokens": ["E\u00b7del", "sind", "wir", "nicht", "zu", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn das Schlechte, das geh\u00f6rt uns,", "tokens": ["Denn", "das", "Schlech\u00b7te", ",", "das", "ge\u00b7h\u00f6rt", "uns", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PDS", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was andre t\u00f6dlich kennen,", "tokens": ["Und", "was", "and\u00b7re", "t\u00f6d\u00b7lich", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das alleine, das vermehrt uns.", "tokens": ["Das", "al\u00b7lei\u00b7ne", ",", "das", "ver\u00b7mehrt", "uns", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "$,", "PRELS", "ADJD", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mag dies f\u00fcr die Menschen gelten,", "tokens": ["Mag", "dies", "f\u00fcr", "die", "Men\u00b7schen", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "M\u00f6gen sie uns doch verachten;", "tokens": ["M\u00f6\u00b7gen", "sie", "uns", "doch", "ver\u00b7ach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.7": {"text": "Aber du, du sollst uns achten,", "tokens": ["A\u00b7ber", "du", ",", "du", "sollst", "uns", "ach\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Denn du k\u00f6nntest alle schelten.", "tokens": ["Denn", "du", "k\u00f6nn\u00b7test", "al\u00b7le", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Also, Herr, nach diesem Flehen,", "tokens": ["Al\u00b7so", ",", "Herr", ",", "nach", "die\u00b7sem", "Fle\u00b7hen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Segne mich zu deinem Kinde;", "tokens": ["Seg\u00b7ne", "mich", "zu", "dei\u00b7nem", "Kin\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder ", "tokens": ["O\u00b7der"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Das auch mich mit dir verbinde!", "tokens": ["Das", "auch", "mich", "mit", "dir", "ver\u00b7bin\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn du hast den Bajaderen", "tokens": ["Denn", "du", "hast", "den", "Ba\u00b7ja\u00b7de\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.2": {"text": "Eine G\u00f6ttin selbst erhoben;", "tokens": ["Ei\u00b7ne", "G\u00f6t\u00b7tin", "selbst", "er\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch wir andern, dich zu loben,", "tokens": ["Auch", "wir", "an\u00b7dern", ",", "dich", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PIS", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wollen solch ein Wunder h\u00f6ren.", "tokens": ["Wol\u00b7len", "solch", "ein", "Wun\u00b7der", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Gro\u00dfer Brahma, Herr der M\u00e4chte!", "tokens": ["Gro\u00b7\u00dfer", "Brah\u00b7ma", ",", "Herr", "der", "M\u00e4ch\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles ist von deinem Samen,", "tokens": ["Al\u00b7les", "ist", "von", "dei\u00b7nem", "Sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so bist du der Gerechte!", "tokens": ["Und", "so", "bist", "du", "der", "Ge\u00b7rech\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Hast du denn allein die Brahmen,", "tokens": ["Hast", "du", "denn", "al\u00b7lein", "die", "Brah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nur die Rajas und die Reichen,", "tokens": ["Nur", "die", "Ra\u00b7jas", "und", "die", "Rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Hast du sie allein geschaffen?", "tokens": ["Hast", "du", "sie", "al\u00b7lein", "ge\u00b7schaf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder bist auch du's, der Affen", "tokens": ["O\u00b7der", "bist", "auch", "du's", ",", "der", "Af\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PIS", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Werden lie\u00df und unseresgleichen?", "tokens": ["Wer\u00b7den", "lie\u00df", "und", "un\u00b7se\u00b7res\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "KON", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Edel sind wir nicht zu nennen:", "tokens": ["E\u00b7del", "sind", "wir", "nicht", "zu", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn das Schlechte, das geh\u00f6rt uns,", "tokens": ["Denn", "das", "Schlech\u00b7te", ",", "das", "ge\u00b7h\u00f6rt", "uns", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PDS", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was andre t\u00f6dlich kennen,", "tokens": ["Und", "was", "and\u00b7re", "t\u00f6d\u00b7lich", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das alleine, das vermehrt uns.", "tokens": ["Das", "al\u00b7lei\u00b7ne", ",", "das", "ver\u00b7mehrt", "uns", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "$,", "PRELS", "ADJD", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Mag dies f\u00fcr die Menschen gelten,", "tokens": ["Mag", "dies", "f\u00fcr", "die", "Men\u00b7schen", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "M\u00f6gen sie uns doch verachten;", "tokens": ["M\u00f6\u00b7gen", "sie", "uns", "doch", "ver\u00b7ach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.7": {"text": "Aber du, du sollst uns achten,", "tokens": ["A\u00b7ber", "du", ",", "du", "sollst", "uns", "ach\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Denn du k\u00f6nntest alle schelten.", "tokens": ["Denn", "du", "k\u00f6nn\u00b7test", "al\u00b7le", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Also, Herr, nach diesem Flehen,", "tokens": ["Al\u00b7so", ",", "Herr", ",", "nach", "die\u00b7sem", "Fle\u00b7hen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Segne mich zu deinem Kinde;", "tokens": ["Seg\u00b7ne", "mich", "zu", "dei\u00b7nem", "Kin\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder ", "tokens": ["O\u00b7der"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Das auch mich mit dir verbinde!", "tokens": ["Das", "auch", "mich", "mit", "dir", "ver\u00b7bin\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Denn du hast den Bajaderen", "tokens": ["Denn", "du", "hast", "den", "Ba\u00b7ja\u00b7de\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.2": {"text": "Eine G\u00f6ttin selbst erhoben;", "tokens": ["Ei\u00b7ne", "G\u00f6t\u00b7tin", "selbst", "er\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch wir andern, dich zu loben,", "tokens": ["Auch", "wir", "an\u00b7dern", ",", "dich", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PIS", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wollen solch ein Wunder h\u00f6ren.", "tokens": ["Wol\u00b7len", "solch", "ein", "Wun\u00b7der", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}