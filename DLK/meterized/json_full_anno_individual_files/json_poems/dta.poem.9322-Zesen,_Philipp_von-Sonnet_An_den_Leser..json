{"dta.poem.9322": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "Sonnet  \n An den Leser.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Hier mustu was gemach im ersten Buche schleichen", "tokens": ["Hier", "mus\u00b7tu", "was", "ge\u00b7mach", "im", "ers\u00b7ten", "Bu\u00b7che", "schlei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PWS", "ADV", "APPRART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "den wohlbedachten tritt nach jambischer manier/", "tokens": ["den", "wohl\u00b7be\u00b7dach\u00b7ten", "tritt", "nach", "jam\u00b7bi\u00b7scher", "ma\u00b7nier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "so lange/ bi\u00df sich auch das Andre l\u00e4sst berf\u00fcr/", "tokens": ["so", "lan\u00b7ge", "/", "bi\u00df", "sich", "auch", "das", "And\u00b7re", "l\u00e4sst", "ber\u00b7f\u00fcr", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "APPR", "PRF", "ADV", "ART", "PIS", "VVFIN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "darinnen dan\u0303 die Ver\u00df den schwinden gang erreichen/", "tokens": ["da\u00b7rin\u00b7nen", "da\u00f1", "die", "Ver\u00df", "den", "schwin\u00b7den", "gang", "er\u00b7rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "auf zweyen f\u00fc\u00dfen gehn/ und so den Ersten gleichen/", "tokens": ["auf", "zwe\u00b7yen", "f\u00fc\u00b7\u00dfen", "gehn", "/", "und", "so", "den", "Ers\u00b7ten", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "VVINF", "VVINF", "$(", "KON", "ADV", "ART", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "nur da\u00df sie schneller seyn und eylen mit begier", "tokens": ["nur", "da\u00df", "sie", "schnel\u00b7ler", "seyn", "und", "ey\u00b7len", "mit", "be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VAINF", "KON", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "gleich einer wasserfluth; Drauf zeigt sich/ Leser/ Dier", "tokens": ["gleich", "ei\u00b7ner", "was\u00b7ser\u00b7fluth", ";", "Drauf", "zeigt", "sich", "/", "Le\u00b7ser", "/", "Dier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "ART", "NN", "$.", "PAV", "VVFIN", "PRF", "$(", "NN", "$(", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "das dritte Musterbuch/ dem alle beyde weichen", "tokens": ["das", "drit\u00b7te", "Mus\u00b7ter\u00b7buch", "/", "dem", "al\u00b7le", "bey\u00b7de", "wei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "PIAT", "PIS", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "an fl\u00fcchtigkeit und zier; Darinnen alles springt/", "tokens": ["an", "fl\u00fcch\u00b7tig\u00b7keit", "und", "zier", ";", "Da\u00b7rin\u00b7nen", "al\u00b7les", "springt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$.", "ADV", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und geht den trippeltantz/ da auch die Sappho", "tokens": ["und", "geht", "den", "trip\u00b7pel\u00b7tantz", "/", "da", "auch", "die", "Sap\u00b7pho"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "$(", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "schwingt", "tokens": ["schwingt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "jhr f\u00fc\u00dfes spiel empor. Dann werden uns die Lieder", "tokens": ["jhr", "f\u00fc\u00b7\u00dfes", "spiel", "em\u00b7por", ".", "Dann", "wer\u00b7den", "uns", "die", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "VVFIN", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "im Vierden auch gezeigt/ darinnen f\u00fcr und f\u00fcr", "tokens": ["im", "Vier\u00b7den", "auch", "ge\u00b7zeigt", "/", "da\u00b7rin\u00b7nen", "f\u00fcr", "und", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$(", "ADV", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die Arten seyn vermischt; Nun sey gewogen mier;", "tokens": ["die", "Ar\u00b7ten", "seyn", "ver\u00b7mischt", ";", "Nun", "sey", "ge\u00b7wo\u00b7gen", "mier", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "VVFIN", "$.", "ADV", "VAFIN", "VVPP", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Leser/ wer du bist/ so thu Ich gleich fals wieder!", "tokens": ["Mein", "Le\u00b7ser", "/", "wer", "du", "bist", "/", "so", "thu", "Ich", "gleich", "fals", "wie\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PWS", "PPER", "VAFIN", "$(", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}