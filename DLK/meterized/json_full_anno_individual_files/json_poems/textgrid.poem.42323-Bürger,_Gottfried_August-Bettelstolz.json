{"textgrid.poem.42323": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Bettelstolz", "genre": "verse", "period": "N.A.", "pub_year": 1770, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es gibt der bettelstolzen Hachen,", "tokens": ["Es", "gibt", "der", "bet\u00b7tel\u00b7stol\u00b7zen", "Ha\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die mehr aus \u00e4rmlicher Kathedertheorei,", "tokens": ["Die", "mehr", "aus", "\u00e4rm\u00b7li\u00b7cher", "Ka\u00b7the\u00b7der\u00b7the\u00b7o\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als aus Homers Gesang, Amphions Melodei,", "tokens": ["Als", "aus", "Ho\u00b7mers", "Ge\u00b7sang", ",", "Am\u00b7phi\u00b7ons", "Me\u00b7lo\u00b7dei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NE", "NN", "$,", "NE", "NE", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Und jedem G\u00f6tterwerk der Muse selber machen.", "tokens": ["Und", "je\u00b7dem", "G\u00f6t\u00b7ter\u00b7werk", "der", "Mu\u00b7se", "sel\u00b7ber", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sprich, Menschensinn, und sag es laut den Hachen,", "tokens": ["Sprich", ",", "Men\u00b7schen\u00b7sinn", ",", "und", "sag", "es", "laut", "den", "Ha\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NN", "$,", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df diesem Wahnsinn ganz der Wahnsinn \u00e4hnlich sei:", "tokens": ["Da\u00df", "die\u00b7sem", "Wahn\u00b7sinn", "ganz", "der", "Wahn\u00b7sinn", "\u00e4hn\u00b7lich", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Aus dem Compendio der Anthropologei,", "tokens": ["Aus", "dem", "Com\u00b7pen\u00b7dio", "der", "An\u00b7th\u00b7ro\u00b7po\u00b7lo\u00b7gei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Das ein Professor schreibt, f\u00fcr seine Klerisei,", "tokens": ["Das", "ein", "Pro\u00b7fes\u00b7sor", "schreibt", ",", "f\u00fcr", "sei\u00b7ne", "Kle\u00b7ri\u00b7sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mehr als aus Gottes Werk, dem Menschen selbst, zu machen.", "tokens": ["Mehr", "als", "aus", "Got\u00b7tes", "Werk", ",", "dem", "Men\u00b7schen", "selbst", ",", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "APPR", "NN", "NN", "$,", "ART", "NN", "ADV", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es gibt der bettelstolzen Hachen,", "tokens": ["Es", "gibt", "der", "bet\u00b7tel\u00b7stol\u00b7zen", "Ha\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die mehr aus \u00e4rmlicher Kathedertheorei,", "tokens": ["Die", "mehr", "aus", "\u00e4rm\u00b7li\u00b7cher", "Ka\u00b7the\u00b7der\u00b7the\u00b7o\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als aus Homers Gesang, Amphions Melodei,", "tokens": ["Als", "aus", "Ho\u00b7mers", "Ge\u00b7sang", ",", "Am\u00b7phi\u00b7ons", "Me\u00b7lo\u00b7dei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NE", "NN", "$,", "NE", "NE", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Und jedem G\u00f6tterwerk der Muse selber machen.", "tokens": ["Und", "je\u00b7dem", "G\u00f6t\u00b7ter\u00b7werk", "der", "Mu\u00b7se", "sel\u00b7ber", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sprich, Menschensinn, und sag es laut den Hachen,", "tokens": ["Sprich", ",", "Men\u00b7schen\u00b7sinn", ",", "und", "sag", "es", "laut", "den", "Ha\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NN", "$,", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df diesem Wahnsinn ganz der Wahnsinn \u00e4hnlich sei:", "tokens": ["Da\u00df", "die\u00b7sem", "Wahn\u00b7sinn", "ganz", "der", "Wahn\u00b7sinn", "\u00e4hn\u00b7lich", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Aus dem Compendio der Anthropologei,", "tokens": ["Aus", "dem", "Com\u00b7pen\u00b7dio", "der", "An\u00b7th\u00b7ro\u00b7po\u00b7lo\u00b7gei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Das ein Professor schreibt, f\u00fcr seine Klerisei,", "tokens": ["Das", "ein", "Pro\u00b7fes\u00b7sor", "schreibt", ",", "f\u00fcr", "sei\u00b7ne", "Kle\u00b7ri\u00b7sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mehr als aus Gottes Werk, dem Menschen selbst, zu machen.", "tokens": ["Mehr", "als", "aus", "Got\u00b7tes", "Werk", ",", "dem", "Men\u00b7schen", "selbst", ",", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "APPR", "NN", "NN", "$,", "ART", "NN", "ADV", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}