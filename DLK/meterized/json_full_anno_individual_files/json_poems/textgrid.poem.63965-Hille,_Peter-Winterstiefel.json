{"textgrid.poem.63965": {"metadata": {"author": {"name": "Hille, Peter", "birth": "N.A.", "death": "N.A."}, "title": "Winterstiefel", "genre": "verse", "period": "N.A.", "pub_year": 1879, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hat ja nur sich selber an,", "tokens": ["Hat", "ja", "nur", "sich", "sel\u00b7ber", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PRF", "ADV", "PTKVZ", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Sch\u00e4mt sich nicht, hat Freud' daran", "tokens": ["Sch\u00e4mt", "sich", "nicht", ",", "hat", "Freud'", "da\u00b7ran"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PTKNEG", "$,", "VAFIN", "NN", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Krauses Haar wie lachend Gold,", "tokens": ["Krau\u00b7ses", "Haar", "wie", "la\u00b7chend", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KOKOM", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das von tausend Teufeln tollt.", "tokens": ["Das", "von", "tau\u00b7send", "Teu\u00b7feln", "tollt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Beide Beine flink und fein", "tokens": ["Bei\u00b7de", "Bei\u00b7ne", "flink", "und", "fein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sinken in zwei Stiefel ein.", "tokens": ["Sin\u00b7ken", "in", "zwei", "Stie\u00b7fel", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Kappen plump und Absatz schwer,", "tokens": ["Kap\u00b7pen", "plump", "und", "Ab\u00b7satz", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lachend schleppt es sich daher.", "tokens": ["La\u00b7chend", "schleppt", "es", "sich", "da\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Also ob die Welt nur Leder w\u00e4r!", "tokens": ["Al\u00b7so", "ob", "die", "Welt", "nur", "Le\u00b7der", "w\u00e4r", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Schwarz das Leder, ros' das Bein:", "tokens": ["Schwarz", "das", "Le\u00b7der", ",", "ros'", "das", "Bein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Stiefel, sag', was f\u00e4llt dir ein?", "tokens": ["Stie\u00b7fel", ",", "sag'", ",", "was", "f\u00e4llt", "dir", "ein", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbhup, mein Jung, da fliegt er hin:", "tokens": ["\u00bb", "hup", ",", "mein", "Jung", ",", "da", "fliegt", "er", "hin", ":"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Will dir zeigen, was ich bin!\u00ab", "tokens": ["Will", "dir", "zei\u00b7gen", ",", "was", "ich", "bin", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Heissa, wie der Stiefel flog", "tokens": ["Heis\u00b7sa", ",", "wie", "der", "Stie\u00b7fel", "flog"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Beide H\u00e4nde klatschen hoch.", "tokens": ["Bei\u00b7de", "H\u00e4n\u00b7de", "klat\u00b7schen", "hoch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Und die F\u00fc\u00dflein ganz befreit", "tokens": ["Und", "die", "F\u00fc\u00df\u00b7lein", "ganz", "be\u00b7freit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Machen die ein Zehengespreit.", "tokens": ["Ma\u00b7chen", "die", "ein", "Ze\u00b7hen\u00b7ge\u00b7spreit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.10": {"line.1": {"text": "Hat ja nur sich selber an,", "tokens": ["Hat", "ja", "nur", "sich", "sel\u00b7ber", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PRF", "ADV", "PTKVZ", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Sch\u00e4mt sich nicht, hat Freud' daran", "tokens": ["Sch\u00e4mt", "sich", "nicht", ",", "hat", "Freud'", "da\u00b7ran"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PTKNEG", "$,", "VAFIN", "NN", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Krauses Haar wie lachend Gold,", "tokens": ["Krau\u00b7ses", "Haar", "wie", "la\u00b7chend", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KOKOM", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das von tausend Teufeln tollt.", "tokens": ["Das", "von", "tau\u00b7send", "Teu\u00b7feln", "tollt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Beide Beine flink und fein", "tokens": ["Bei\u00b7de", "Bei\u00b7ne", "flink", "und", "fein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sinken in zwei Stiefel ein.", "tokens": ["Sin\u00b7ken", "in", "zwei", "Stie\u00b7fel", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Kappen plump und Absatz schwer,", "tokens": ["Kap\u00b7pen", "plump", "und", "Ab\u00b7satz", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lachend schleppt es sich daher.", "tokens": ["La\u00b7chend", "schleppt", "es", "sich", "da\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Also ob die Welt nur Leder w\u00e4r!", "tokens": ["Al\u00b7so", "ob", "die", "Welt", "nur", "Le\u00b7der", "w\u00e4r", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.15": {"line.1": {"text": "Schwarz das Leder, ros' das Bein:", "tokens": ["Schwarz", "das", "Le\u00b7der", ",", "ros'", "das", "Bein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Stiefel, sag', was f\u00e4llt dir ein?", "tokens": ["Stie\u00b7fel", ",", "sag'", ",", "was", "f\u00e4llt", "dir", "ein", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bbhup, mein Jung, da fliegt er hin:", "tokens": ["\u00bb", "hup", ",", "mein", "Jung", ",", "da", "fliegt", "er", "hin", ":"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Will dir zeigen, was ich bin!\u00ab", "tokens": ["Will", "dir", "zei\u00b7gen", ",", "was", "ich", "bin", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Heissa, wie der Stiefel flog", "tokens": ["Heis\u00b7sa", ",", "wie", "der", "Stie\u00b7fel", "flog"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Beide H\u00e4nde klatschen hoch.", "tokens": ["Bei\u00b7de", "H\u00e4n\u00b7de", "klat\u00b7schen", "hoch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Und die F\u00fc\u00dflein ganz befreit", "tokens": ["Und", "die", "F\u00fc\u00df\u00b7lein", "ganz", "be\u00b7freit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Machen die ein Zehengespreit.", "tokens": ["Ma\u00b7chen", "die", "ein", "Ze\u00b7hen\u00b7ge\u00b7spreit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}}}}