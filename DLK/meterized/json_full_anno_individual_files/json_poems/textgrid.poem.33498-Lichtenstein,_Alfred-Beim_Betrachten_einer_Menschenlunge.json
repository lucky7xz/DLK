{"textgrid.poem.33498": {"metadata": {"author": {"name": "Lichtenstein, Alfred", "birth": "N.A.", "death": "N.A."}, "title": "Beim Betrachten einer Menschenlunge", "genre": "verse", "period": "N.A.", "pub_year": 1914, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ganz ohne Grauen fri\u00dft du t\u00e4glich totes Fleisch.", "tokens": ["Ganz", "oh\u00b7ne", "Grau\u00b7en", "fri\u00dft", "du", "t\u00e4g\u00b7lich", "to\u00b7tes", "Fleisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und totes Blut ist dir ein s\u00fc\u00dfer Saft.", "tokens": ["Und", "to\u00b7tes", "Blut", "ist", "dir", "ein", "s\u00fc\u00b7\u00dfer", "Saft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erschrickst du nicht? \u2013", "tokens": ["Er\u00b7schrickst", "du", "nicht", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Zwar haben deine fr\u00fchsten V\u00e4ter auch", "tokens": ["Zwar", "ha\u00b7ben", "dei\u00b7ne", "fr\u00fchs\u00b7ten", "V\u00e4\u00b7ter", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ehe du erwachtest wurde schon", "tokens": ["Und", "e\u00b7he", "du", "er\u00b7wach\u00b7test", "wur\u00b7de", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dir tausend Totes in den Leib gestopft.", "tokens": ["Dir", "tau\u00b7send", "To\u00b7tes", "in", "den", "Leib", "ge\u00b7stopft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wie aber mu\u00df der erste, der das Tier", "tokens": ["Wie", "a\u00b7ber", "mu\u00df", "der", "ers\u00b7te", ",", "der", "das", "Tier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "VMFIN", "ART", "ADJA", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Erschlug, herzlich erschrocken sein \u2013", "tokens": ["Er\u00b7schlug", ",", "herz\u00b7lich", "er\u00b7schro\u00b7cken", "sein", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Da, als er sah, da\u00df das, was flatterte,", "tokens": ["Da", ",", "als", "er", "sah", ",", "da\u00df", "das", ",", "was", "flat\u00b7ter\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "KOUS", "PDS", "$,", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was sprang und schreien konnte und im Sterben noch", "tokens": ["Was", "sprang", "und", "schrei\u00b7en", "konn\u00b7te", "und", "im", "Ster\u00b7ben", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "KON", "VVINF", "VMFIN", "KON", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So flehende Welt in den Augen hatte,", "tokens": ["So", "fle\u00b7hen\u00b7de", "Welt", "in", "den", "Au\u00b7gen", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mit einemmal", "tokens": ["Mit", "ei\u00b7nem\u00b7mal"], "token_info": ["word", "word"], "pos": ["APPR", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Nicht mehr da war.", "tokens": ["Nicht", "mehr", "da", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Ganz ohne Grauen fri\u00dft du t\u00e4glich totes Fleisch.", "tokens": ["Ganz", "oh\u00b7ne", "Grau\u00b7en", "fri\u00dft", "du", "t\u00e4g\u00b7lich", "to\u00b7tes", "Fleisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und totes Blut ist dir ein s\u00fc\u00dfer Saft.", "tokens": ["Und", "to\u00b7tes", "Blut", "ist", "dir", "ein", "s\u00fc\u00b7\u00dfer", "Saft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erschrickst du nicht? \u2013", "tokens": ["Er\u00b7schrickst", "du", "nicht", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Zwar haben deine fr\u00fchsten V\u00e4ter auch", "tokens": ["Zwar", "ha\u00b7ben", "dei\u00b7ne", "fr\u00fchs\u00b7ten", "V\u00e4\u00b7ter", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ehe du erwachtest wurde schon", "tokens": ["Und", "e\u00b7he", "du", "er\u00b7wach\u00b7test", "wur\u00b7de", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dir tausend Totes in den Leib gestopft.", "tokens": ["Dir", "tau\u00b7send", "To\u00b7tes", "in", "den", "Leib", "ge\u00b7stopft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Wie aber mu\u00df der erste, der das Tier", "tokens": ["Wie", "a\u00b7ber", "mu\u00df", "der", "ers\u00b7te", ",", "der", "das", "Tier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "VMFIN", "ART", "ADJA", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Erschlug, herzlich erschrocken sein \u2013", "tokens": ["Er\u00b7schlug", ",", "herz\u00b7lich", "er\u00b7schro\u00b7cken", "sein", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Da, als er sah, da\u00df das, was flatterte,", "tokens": ["Da", ",", "als", "er", "sah", ",", "da\u00df", "das", ",", "was", "flat\u00b7ter\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "KOUS", "PDS", "$,", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was sprang und schreien konnte und im Sterben noch", "tokens": ["Was", "sprang", "und", "schrei\u00b7en", "konn\u00b7te", "und", "im", "Ster\u00b7ben", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "KON", "VVINF", "VMFIN", "KON", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So flehende Welt in den Augen hatte,", "tokens": ["So", "fle\u00b7hen\u00b7de", "Welt", "in", "den", "Au\u00b7gen", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mit einemmal", "tokens": ["Mit", "ei\u00b7nem\u00b7mal"], "token_info": ["word", "word"], "pos": ["APPR", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Nicht mehr da war.", "tokens": ["Nicht", "mehr", "da", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}