{"textgrid.poem.62742": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Unterth\u00e4nigstes Sendschreiben an Ihro Hochf\u00fcrstl. Durchl. zu Sachsen Meinungen", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist dieses nicht zu viel,", "tokens": ["Ist", "die\u00b7ses", "nicht", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df meine Niedrigkeit, da\u00df sich mein Dichterkiel", "tokens": ["Da\u00df", "mei\u00b7ne", "Nied\u00b7rig\u00b7keit", ",", "da\u00df", "sich", "mein", "Dich\u00b7ter\u00b7kiel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "KOUS", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu deiner Hoheit wagt? darf ich mich unterstehen", "tokens": ["Zu", "dei\u00b7ner", "Ho\u00b7heit", "wagt", "?", "darf", "ich", "mich", "un\u00b7ter\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durchlauchtster! durch ein Blat vor dein Gesicht zu gehen?", "tokens": ["Durch\u00b7lauchts\u00b7ter", "!", "durch", "ein", "Blat", "vor", "dein", "Ge\u00b7sicht", "zu", "ge\u00b7hen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich zittre mit der Hand, ich werf die Feder hin!", "tokens": ["Ich", "zitt\u00b7re", "mit", "der", "Hand", ",", "ich", "werf", "die", "Fe\u00b7der", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Trieb, Ehrfurcht, Hofnung, Furcht verwirrt jetzt meinen Sinn.", "tokens": ["Trieb", ",", "Ehr\u00b7furcht", ",", "Hof\u00b7nung", ",", "Furcht", "ver\u00b7wirrt", "jetzt", "mei\u00b7nen", "Sinn", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch was verzage ich! Ich nehm die Feder wieder.", "tokens": ["Doch", "was", "ver\u00b7za\u00b7ge", "ich", "!", "Ich", "nehm", "die", "Fe\u00b7der", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Dichter nicht verschm\u00e4ht. Er h\u00e4lt gelehrten Flei\u00df", "tokens": ["Der", "Dich\u00b7ter", "nicht", "ver\u00b7schm\u00e4ht", ".", "Er", "h\u00e4lt", "ge\u00b7lehr\u00b7ten", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$.", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nach seiner Weisheit wehrt. Er kennt, Er sieht und wei\u00df", "tokens": ["Nach", "sei\u00b7ner", "Weis\u00b7heit", "wehrt", ".", "Er", "kennt", ",", "Er", "sieht", "und", "wei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nach seiner Einsicht wohl, wer sich dahin bestrebet,", "tokens": ["Nach", "sei\u00b7ner", "Ein\u00b7sicht", "wohl", ",", "wer", "sich", "da\u00b7hin", "be\u00b7stre\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$,", "PWS", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da\u00df er durch Wissenschaft sich aus dem Staub erhebet,", "tokens": ["Da\u00df", "er", "durch", "Wis\u00b7sen\u00b7schaft", "sich", "aus", "dem", "Staub", "er\u00b7he\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und sucht, kein faules Glied der Republik zu seyn.", "tokens": ["Und", "sucht", ",", "kein", "fau\u00b7les", "Glied", "der", "Re\u00b7pub\u00b7lik", "zu", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PIAT", "ADJA", "NN", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mir f\u00e4llt ", "tokens": ["Mir", "f\u00e4llt"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "Wie hoch ", "tokens": ["Wie", "hoch"], "token_info": ["word", "word"], "pos": ["PWAV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Wodurch ", "tokens": ["Wo\u00b7durch"], "token_info": ["word"], "pos": ["PWAV"], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "Allein ", "tokens": ["Al\u00b7lein"], "token_info": ["word"], "pos": ["ADV"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Auch an und vor sich selbst, wohl deine Gnad und Gunst?", "tokens": ["Auch", "an", "und", "vor", "sich", "selbst", ",", "wohl", "dei\u00b7ne", "Gnad", "und", "Gunst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "APPR", "PRF", "ADV", "$,", "ADV", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man schimpft und h\u00f6hnt sie ja; man nennt sie offt bey Hofe", "tokens": ["Man", "schimpft", "und", "h\u00f6hnt", "sie", "ja", ";", "man", "nennt", "sie", "offt", "bey", "Ho\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$.", "PIS", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie G\u00fcnther schon gesagt, die abgedankte Zofe.", "tokens": ["Wie", "G\u00fcn\u00b7ther", "schon", "ge\u00b7sagt", ",", "die", "ab\u00b7ge\u00b7dank\u00b7te", "Zo\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "VVPP", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie heist ein Hirngespinst, und eine Bettel-Magd,", "tokens": ["Sie", "heist", "ein", "Hirn\u00b7ge\u00b7spinst", ",", "und", "ei\u00b7ne", "Bet\u00b7tel\u00b7Magd", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und eine Heuchlerin die nur zum Scheine klagt.", "tokens": ["Und", "ei\u00b7ne", "Heuch\u00b7le\u00b7rin", "die", "nur", "zum", "Schei\u00b7ne", "klagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie schmeichle um Gewinst, und wisse zuverblenden,", "tokens": ["Sie", "schmeich\u00b7le", "um", "Ge\u00b7winst", ",", "und", "wis\u00b7se", "zu\u00b7ver\u00b7blen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "KON", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und k\u00f6nte meisterlich die edle Zeit verschwenden.", "tokens": ["Und", "k\u00f6n\u00b7te", "meis\u00b7ter\u00b7lich", "die", "ed\u00b7le", "Zeit", "ver\u00b7schwen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Laster sind weit mehr die man ihr angedicht.", "tokens": ["Die", "Las\u00b7ter", "sind", "weit", "mehr", "die", "man", "ihr", "an\u00b7ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADV", "ART", "PIS", "PPER", "VVPP", "$."], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Bist du ihr dennoch hold? Ists nicht zuviel vor Helden", "tokens": ["Bist", "du", "ihr", "den\u00b7noch", "hold", "?", "Ists", "nicht", "zu\u00b7viel", "vor", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADJD", "$.", "NE", "PTKNEG", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und F\u00fcrsten, wenn sie was zu ihrem Ruhme melden?", "tokens": ["Und", "F\u00fcrs\u00b7ten", ",", "wenn", "sie", "was", "zu", "ih\u00b7rem", "Ruh\u00b7me", "mel\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KOUS", "PPER", "PIS", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ruft nicht der Weisheit Feind, der S\u00fcd und West durchzieht.", "tokens": ["Ruft", "nicht", "der", "Weis\u00b7heit", "Feind", ",", "der", "S\u00fcd", "und", "West", "durch\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ver\u00e4chtlich w\u00e4rs, wenn sich ein Prinz um sie bem\u00fcht.", "tokens": ["Ver\u00b7\u00e4cht\u00b7lich", "w\u00e4rs", ",", "wenn", "sich", "ein", "Prinz", "um", "sie", "be\u00b7m\u00fcht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "KOUS", "PRF", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein Herzog d\u00f6rfte sie nicht lesen oder kennen,", "tokens": ["Ein", "Her\u00b7zog", "d\u00f6rf\u00b7te", "sie", "nicht", "le\u00b7sen", "o\u00b7der", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "PTKNEG", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er k\u00f6nte sie, wie dort Sibillens Buch verbrennen.", "tokens": ["Er", "k\u00f6n\u00b7te", "sie", ",", "wie", "dort", "Si\u00b7bil\u00b7lens", "Buch", "ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "$,", "PWAV", "ADV", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "(das sie zwar selbst gethan.) Der F\u00fcrsten Lust allein", "tokens": ["(", "das", "sie", "zwar", "selbst", "ge\u00b7than", ".", ")", "Der", "F\u00fcrs\u00b7ten", "Lust", "al\u00b7lein"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$.", "$(", "ART", "NN", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Solt nur die Lust der Welt, das Trink und Jagen seyn.", "tokens": ["Solt", "nur", "die", "Lust", "der", "Welt", ",", "das", "Trink", "und", "Ja\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vortreflich sch\u00f6ner Spruch! wie? sind denn nicht die Prinzen", "tokens": ["Vor\u00b7tre\u00b7flich", "sch\u00f6\u00b7ner", "Spruch", "!", "wie", "?", "sind", "denn", "nicht", "die", "Prin\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "$.", "PWAV", "$.", "VAFIN", "ADV", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ein Vorbild und ein Licht und V\u00e4ter der Provinzen?", "tokens": ["Ein", "Vor\u00b7bild", "und", "ein", "Licht", "und", "V\u00e4\u00b7ter", "der", "Pro\u00b7vin\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ein F\u00fcrst mu\u00df Wissenschaft, Verstand, beherztes Blut,", "tokens": ["Ein", "F\u00fcrst", "mu\u00df", "Wis\u00b7sen\u00b7schaft", ",", "Ver\u00b7stand", ",", "be\u00b7herz\u00b7tes", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Huld, Gnade, Warheit, Treu, gerecht, doch sanften Muth,", "tokens": ["Huld", ",", "Gna\u00b7de", ",", "War\u00b7heit", ",", "Treu", ",", "ge\u00b7recht", ",", "doch", "sanf\u00b7ten", "Muth", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "ADJD", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Erbarmen, G\u00fctigkeit, und andre F\u00fcrsten-Gaben,", "tokens": ["Er\u00b7bar\u00b7men", ",", "G\u00fc\u00b7tig\u00b7keit", ",", "und", "and\u00b7re", "F\u00fcrs\u00b7ten\u00b7Ga\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Zu seines Namens Ruhm, und Gl\u00fcck des Landes haben.", "tokens": ["Zu", "sei\u00b7nes", "Na\u00b7mens", "Ruhm", ",", "und", "Gl\u00fcck", "des", "Lan\u00b7des", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "KON", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die Weisheit, der Verstand, die lautere Vernunft,", "tokens": ["Die", "Weis\u00b7heit", ",", "der", "Ver\u00b7stand", ",", "die", "lau\u00b7te\u00b7re", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die einen Herzog schm\u00fcckt, schlie\u00dft nun die Musen-Zunft", "tokens": ["Die", "ei\u00b7nen", "Her\u00b7zog", "schm\u00fcckt", ",", "schlie\u00dft", "nun", "die", "Mu\u00b7sen\u00b7Zunft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Aus seiner Brust nicht aus. Sie steht mit unter diesen,", "tokens": ["Aus", "sei\u00b7ner", "Brust", "nicht", "aus", ".", "Sie", "steht", "mit", "un\u00b7ter", "die\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "APPR", "PDAT", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die F\u00fcrsten Gnadenreich und Gro\u00dfmuthsvoll begr\u00fcssen,", "tokens": ["Die", "F\u00fcrs\u00b7ten", "Gna\u00b7den\u00b7reich", "und", "Gro\u00df\u00b7muths\u00b7voll", "be\u00b7gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Es ist die Poesie kein niedertr\u00e4chtig Werk;", "tokens": ["Es", "ist", "die", "Poe\u00b7sie", "kein", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "Werk", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sie ist der weisesten und gr\u00f6\u00dften Augenmerk,", "tokens": ["Sie", "ist", "der", "wei\u00b7ses\u00b7ten", "und", "gr\u00f6\u00df\u00b7ten", "Au\u00b7gen\u00b7merk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Und s\u00fcsser Zeitvertreib. Die Potentanten m\u00fcssen", "tokens": ["Und", "s\u00fcs\u00b7ser", "Zeit\u00b7ver\u00b7treib", ".", "Die", "Po\u00b7ten\u00b7tan\u00b7ten", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$.", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An etwas eine Lust nach ihrer Last geniessen.", "tokens": ["An", "et\u00b7was", "ei\u00b7ne", "Lust", "nach", "ih\u00b7rer", "Last", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der F\u00fcrsten ihre Lust ist zwar gar mancherley,", "tokens": ["Der", "F\u00fcrs\u00b7ten", "ih\u00b7re", "Lust", "ist", "zwar", "gar", "man\u00b7cher\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "ADV", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Rudolphens Pinsel kam den Mahlern treflich bey.", "tokens": ["Ru\u00b7dol\u00b7phens", "Pin\u00b7sel", "kam", "den", "Mah\u00b7lern", "tref\u00b7lich", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der junge Cyrus fand an junger B\u00e4ume setzen", "tokens": ["Der", "jun\u00b7ge", "Cy\u00b7rus", "fand", "an", "jun\u00b7ger", "B\u00e4u\u00b7me", "set\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "VVFIN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die angenehmste Lust, das herrlichste Ergetzen.", "tokens": ["Die", "an\u00b7ge\u00b7nehms\u00b7te", "Lust", ",", "das", "herr\u00b7lichs\u00b7te", "Er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Gambrivius braut Bier. Albertus drechslet sch\u00f6n.", "tokens": ["Gam\u00b7bri\u00b7vius", "braut", "Bier", ".", "Al\u00b7ber\u00b7tus", "drechs\u00b7let", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$.", "NE", "VVFIN", "ADJD", "$."], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Es wu\u00dfte Carl geschickt mit Uhren umzugehn.", "tokens": ["Es", "wu\u00df\u00b7te", "Carl", "ge\u00b7schickt", "mit", "Uh\u00b7ren", "um\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "VVPP", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wilhelmus gleichfals auch. Und Ferdinand polirte", "tokens": ["Wil\u00b7hel\u00b7mus", "gleich\u00b7fals", "auch", ".", "Und", "Fer\u00b7di\u00b7nand", "po\u00b7lir\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADV", "ADV", "$.", "KON", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gold und die Waffen sch\u00f6n. Garochus schnitzt und zierte,", "tokens": ["Gold", "und", "die", "Waf\u00b7fen", "sch\u00f6n", ".", "Ga\u00b7ro\u00b7chus", "schnitzt", "und", "zier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "ADJD", "$.", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.13": {"text": "Der Bogen Pfeile wohl. Aeropus ward bedacht,", "tokens": ["Der", "Bo\u00b7gen", "Pfei\u00b7le", "wohl", ".", "A\u00b7e\u00b7ro\u00b7pus", "ward", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "$.", "NE", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Wie er bald Lichtergen und bald Laternen macht'.", "tokens": ["Wie", "er", "bald", "Lich\u00b7ter\u00b7gen", "und", "bald", "La\u00b7ter\u00b7nen", "macht'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "NN", "KON", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Atheus putzt sein Ro\u00df. Und Abas schlug die Eisen", "tokens": ["A\u00b7theus", "putzt", "sein", "Ro\u00df", ".", "Und", "A\u00b7bas", "schlug", "die", "Ei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "$.", "KON", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Dem Reitpferd selbsten an, und z\u00e4umt es auf den Reisen.", "tokens": ["Dem", "Reit\u00b7pferd", "selbs\u00b7ten", "an", ",", "und", "z\u00e4umt", "es", "auf", "den", "Rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was macht Domitius? Er spie\u00dft die Fliegen an.", "tokens": ["Was", "macht", "Do\u00b7mi\u00b7tius", "?", "Er", "spie\u00dft", "die", "Flie\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NE", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Ich wei\u00df zwar nicht, ob man die\u00df F\u00fcrstlich nennen kan!", "tokens": ["Ich", "wei\u00df", "zwar", "nicht", ",", "ob", "man", "die\u00df", "F\u00fcrst\u00b7lich", "nen\u00b7nen", "kan", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "KOUS", "PIS", "PDS", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ich wei\u00df nicht, hab ich recht? bey F\u00fcrstlichem Vergn\u00fcgen,", "tokens": ["Ich", "wei\u00df", "nicht", ",", "hab", "ich", "recht", "?", "bey", "F\u00fcrst\u00b7li\u00b7chem", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "VAFIN", "PPER", "ADJD", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mu\u00df doch der grosse Geist allzeit zum Grunde liegen.", "tokens": ["Mu\u00df", "doch", "der", "gros\u00b7se", "Geist", "all\u00b7zeit", "zum", "Grun\u00b7de", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie sch\u00f6n ists, wenn ein F\u00fcrst kein F\u00fcrsten-Haupt erhebt,", "tokens": ["Wie", "sch\u00f6n", "ists", ",", "wenn", "ein", "F\u00fcrst", "kein", "F\u00fcrs\u00b7ten\u00b7Haupt", "er\u00b7hebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nach der sch\u00f6nsten Lust der Weisheit eifrig strebt,", "tokens": ["Und", "nach", "der", "sch\u00f6ns\u00b7ten", "Lust", "der", "Weis\u00b7heit", "eif\u00b7rig", "strebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sich an ihr erg\u00f6tzt: So kan er klug regieren,", "tokens": ["Und", "sich", "an", "ihr", "er\u00b7g\u00f6tzt", ":", "So", "kan", "er", "klug", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPER", "VVPP", "$.", "ADV", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und seinen F\u00fcrsten-Hut durch sich noch gr\u00f6sser zieren.", "tokens": ["Und", "sei\u00b7nen", "F\u00fcrs\u00b7ten\u00b7Hut", "durch", "sich", "noch", "gr\u00f6s\u00b7ser", "zie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PRF", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Weisheit find kein Haus, zu ihrem Gl\u00fcck und Ehr,", "tokens": ["Die", "Weis\u00b7heit", "find", "kein", "Haus", ",", "zu", "ih\u00b7rem", "Gl\u00fcck", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,", "APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das sch\u00f6ner, als die Brust der Potentanten w\u00e4r.", "tokens": ["Das", "sch\u00f6\u00b7ner", ",", "als", "die", "Brust", "der", "Po\u00b7ten\u00b7tan\u00b7ten", "w\u00e4r", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "KOUS", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch kluge F\u00fcrsten kan die Weisheit herrlich gl\u00e4nzen;", "tokens": ["Durch", "klu\u00b7ge", "F\u00fcrs\u00b7ten", "kan", "die", "Weis\u00b7heit", "herr\u00b7lich", "gl\u00e4n\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Durch sie erweitert sich ihr Reich und seine Gr\u00e4nzen.", "tokens": ["Durch", "sie", "er\u00b7wei\u00b7tert", "sich", "ihr", "Reich", "und", "sei\u00b7ne", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PRF", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der R\u00f6mer edles Haupt Aurelius Anton", "tokens": ["Der", "R\u00f6\u00b7mer", "ed\u00b7les", "Haupt", "Au\u00b7re\u00b7li\u00b7us", "An\u00b7ton"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "NE", "NE"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "War ihrer Augenlust, und ihr warhaftger Sohn.", "tokens": ["War", "ih\u00b7rer", "Au\u00b7gen\u00b7lust", ",", "und", "ihr", "war\u00b7haft\u00b7ger", "Sohn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Was that Vespasian? Was Zeno? sie studirten.", "tokens": ["Was", "that", "Ves\u00b7pa\u00b7si\u00b7an", "?", "Was", "Ze\u00b7no", "?", "sie", "stu\u00b7dir\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NE", "$.", "PWS", "NE", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was C\u00e4sar? Friederich? Sie lasen, meditirten.", "tokens": ["Was", "C\u00e4\u00b7sar", "?", "Frie\u00b7de\u00b7rich", "?", "Sie", "la\u00b7sen", ",", "me\u00b7di\u00b7tir\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "NE", "$.", "NE", "$.", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "August und Adrian, Alphonsus liebten sie:", "tokens": ["Au\u00b7gust", "und", "Ad\u00b7ri\u00b7an", ",", "Al\u00b7phon\u00b7sus", "lieb\u00b7ten", "sie", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,", "NE", "VVFIN", "PPER", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.14": {"text": "Und Carl verehrte auch die Weisheit spat und fr\u00fch.", "tokens": ["Und", "Carl", "ver\u00b7ehr\u00b7te", "auch", "die", "Weis\u00b7heit", "spat", "und", "fr\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Franciscus, Heinrich la\u00df mit Lust gelehrte Schriften.", "tokens": ["Fran\u00b7cis\u00b7cus", ",", "Hein\u00b7rich", "la\u00df", "mit", "Lust", "ge\u00b7lehr\u00b7te", "Schrif\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "VVFIN", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "O sch\u00f6ne F\u00fcrsten-Lust! die kan ein Denkmaal stiften", "tokens": ["O", "sch\u00f6\u00b7ne", "F\u00fcrs\u00b7ten\u00b7Lust", "!", "die", "kan", "ein", "Denk\u00b7maal", "stif\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "VMFIN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Das ewiglich besteht. War Nero voller Wuth;", "tokens": ["Das", "e\u00b7wig\u00b7lich", "be\u00b7steht", ".", "War", "Ne\u00b7ro", "vol\u00b7ler", "Wuth", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "$.", "VAFIN", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So nahm die Wissenschaft und Dichtkunst doch sein Blut,", "tokens": ["So", "nahm", "die", "Wis\u00b7sen\u00b7schaft", "und", "Dicht\u00b7kunst", "doch", "sein", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und seine Seele ein: Er hat geschickt geschrieben,", "tokens": ["Und", "sei\u00b7ne", "See\u00b7le", "ein", ":", "Er", "hat", "ge\u00b7schickt", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und mit der Poesie die Zeit gar oft vertrieben.", "tokens": ["Und", "mit", "der", "Poe\u00b7sie", "die", "Zeit", "gar", "oft", "ver\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Wie mancher grosser F\u00fcrst, den Deutschland in sich schlie\u00dft", "tokens": ["Wie", "man\u00b7cher", "gros\u00b7ser", "F\u00fcrst", ",", "den", "Deutschland", "in", "sich", "schlie\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "$,", "ART", "NN", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.22": {"text": "Trinkt \u00f6fters aus dem Flu\u00df, der am Parnasso flie\u00dft.", "tokens": ["Trinkt", "\u00f6f\u00b7ters", "aus", "dem", "Flu\u00df", ",", "der", "am", "Par\u00b7nas\u00b7so", "flie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Man geh die Prinzen durch, so wird man kl\u00e4rlich lesen,", "tokens": ["Man", "geh", "die", "Prin\u00b7zen", "durch", ",", "so", "wird", "man", "kl\u00e4r\u00b7lich", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "VAFIN", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und finden, da\u00df ihr Herz der Musensitz gewesen.", "tokens": ["Und", "fin\u00b7den", ",", "da\u00df", "ihr", "Herz", "der", "Mu\u00b7sen\u00b7sitz", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Hat nicht der Held Eugen die Dichtkunst hochgesch\u00e4tzt?", "tokens": ["Hat", "nicht", "der", "Held", "Eu\u00b7gen", "die", "Dicht\u00b7kunst", "hoch\u00b7ge\u00b7sch\u00e4tzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "NE", "ART", "NN", "VVPP", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Was Wunder, wenn ", "tokens": ["Was", "Wun\u00b7der", ",", "wenn"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWS", "NN", "$,", "KOUS"], "meter": "-+-+", "measure": "iambic.di"}, "line.27": {"text": "Was Wunder, da\u00df du Sie ", "tokens": ["Was", "Wun\u00b7der", ",", "da\u00df", "du", "Sie"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NN", "$,", "KOUS", "PPER", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Und ihr dein grosses Herz zu eine Wohnhaus giebest.", "tokens": ["Und", "ihr", "dein", "gros\u00b7ses", "Herz", "zu", "ei\u00b7ne", "Wohn\u00b7haus", "gie\u00b7best", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Dein hocherleuchter Geist sieht ihre Sch\u00f6nheit ein.", "tokens": ["Dein", "ho\u00b7cher\u00b7leuch\u00b7ter", "Geist", "sieht", "ih\u00b7re", "Sch\u00f6n\u00b7heit", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Du weist sie will besitzt, sie will verwahret seyn.", "tokens": ["Du", "weist", "sie", "will", "be\u00b7sitzt", ",", "sie", "will", "ver\u00b7wah\u00b7ret", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VMFIN", "VVPP", "$,", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Du bist ein weiser F\u00fcrst, den Pallas auferzogen,", "tokens": ["Du", "bist", "ein", "wei\u00b7ser", "F\u00fcrst", ",", "den", "Pal\u00b7las", "auf\u00b7er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Drum bist du ihrem Volk auch Gro\u00dfmuthsvoll gewogen.", "tokens": ["Drum", "bist", "du", "ih\u00b7rem", "Volk", "auch", "Gro\u00df\u00b7muths\u00b7voll", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ein Dichter findt bey dir ein gn\u00e4diges Geh\u00f6r,", "tokens": ["Ein", "Dich\u00b7ter", "findt", "bey", "dir", "ein", "gn\u00e4\u00b7di\u00b7ges", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Und wenn der Zoil auch mit Macht darwieder w\u00e4r.", "tokens": ["Und", "wenn", "der", "Zoil", "auch", "mit", "Macht", "dar\u00b7wie\u00b7der", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "APPR", "NN", "PAV", "VAFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "So liebst und lobest du, ", "tokens": ["So", "liebst", "und", "lo\u00b7best", "du", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.36": {"text": "Die Federn und das Blat der klug und weisen M\u00e4nner,", "tokens": ["Die", "Fe\u00b7dern", "und", "das", "Blat", "der", "klug", "und", "wei\u00b7sen", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ART", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Nach deiner Einsicht hoch, und siehst es gn\u00e4dig an.", "tokens": ["Nach", "dei\u00b7ner", "Ein\u00b7sicht", "hoch", ",", "und", "siehst", "es", "gn\u00e4\u00b7dig", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Allein, ", "tokens": ["Al\u00b7lein", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "(ich bitte demuthsvoll, vergieb den k\u00fchnen Fragen,", "tokens": ["(", "ich", "bit\u00b7te", "de\u00b7muths\u00b7voll", ",", "ver\u00b7gieb", "den", "k\u00fch\u00b7nen", "Fra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "ADJD", "$,", "VVIMP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verzeihe gn\u00e4diglich, was jetzt die Worte sagen!)", "tokens": ["Ver\u00b7zei\u00b7he", "gn\u00e4\u00b7di\u00b7glich", ",", "was", "jetzt", "die", "Wor\u00b7te", "sa\u00b7gen", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADJD", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df du der H\u00e4nde Werk von einem Weibesbild,", "tokens": ["Da\u00df", "du", "der", "H\u00e4n\u00b7de", "Werk", "von", "ei\u00b7nem", "Wei\u00b7bes\u00b7bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das ja mit keinem Witz; mit Schwachheit angef\u00fcllt,", "tokens": ["Das", "ja", "mit", "kei\u00b7nem", "Witz", ";", "mit", "Schwach\u00b7heit", "an\u00b7ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PIAT", "NN", "$.", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So gn\u00e4diglich verehrst? wo hat man wohl vernommen,", "tokens": ["So", "gn\u00e4\u00b7di\u00b7glich", "ver\u00b7ehrst", "?", "wo", "hat", "man", "wohl", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$.", "PWAV", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das von dem Frauenvolk was Gutes w\u00e4r gekommen?", "tokens": ["Das", "von", "dem", "Frau\u00b7en\u00b7volk", "was", "Gu\u00b7tes", "w\u00e4r", "ge\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "PWS", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So spricht der Klugheit Feind; so spricht der tolle Neid.", "tokens": ["So", "spricht", "der", "Klug\u00b7heit", "Feind", ";", "so", "spricht", "der", "tol\u00b7le", "Neid", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man h\u00f6rts ja, wie er oft mit vollem Munde schreyt:", "tokens": ["Man", "h\u00f6rts", "ja", ",", "wie", "er", "oft", "mit", "vol\u00b7lem", "Mun\u00b7de", "schreyt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein Weibsbild sey kein Mensch. Wir w\u00e4ren Plage-Geister", "tokens": ["Ein", "Weibs\u00b7bild", "sey", "kein", "Mensch", ".", "Wir", "w\u00e4\u00b7ren", "Pla\u00b7ge\u00b7Geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$.", "PPER", "VAFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der M\u00e4nner. Und was mehr? Xantippens Obermeister.", "tokens": ["Der", "M\u00e4n\u00b7ner", ".", "Und", "was", "mehr", "?", "Xan\u00b7tip\u00b7pens", "O\u00b7ber\u00b7meis\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "KON", "PWS", "ADV", "$.", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und solche Tittel mehr, die er umsonst verschenkt.", "tokens": ["Und", "sol\u00b7che", "Tit\u00b7tel", "mehr", ",", "die", "er", "um\u00b7sonst", "ver\u00b7schenkt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "$,", "PRELS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Ein Weibsbild, das an Kiel und Wissenschafft gedenkt,", "tokens": ["Ein", "Weibs\u00b7bild", ",", "das", "an", "Kiel", "und", "Wis\u00b7sen\u00b7schafft", "ge\u00b7denkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NE", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und sie zu forschen sucht, das mu\u00df ein Monstrum heisen,", "tokens": ["Und", "sie", "zu", "for\u00b7schen", "sucht", ",", "das", "mu\u00df", "ein", "Monst\u00b7rum", "hei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "VVFIN", "$,", "PDS", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man m\u00fc\u00df im Buch und Kiel aus denen H\u00e4nden reisen.", "tokens": ["Man", "m\u00fc\u00df", "im", "Buch", "und", "Kiel", "aus", "de\u00b7nen", "H\u00e4n\u00b7den", "rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPRART", "NN", "KON", "NE", "APPR", "PRELS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Degen in der Faust, die Feder in der Hand,", "tokens": ["Der", "De\u00b7gen", "in", "der", "Faust", ",", "die", "Fe\u00b7der", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Den Hut auf Schl\u00e4ff und Kopf w\u00e4r M\u00e4nnern zuerkant,", "tokens": ["Den", "Hut", "auf", "Schl\u00e4ff", "und", "Kopf", "w\u00e4r", "M\u00e4n\u00b7nern", "zu\u00b7er\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und nicht dem Frauenvolk. Da\u00df m\u00fcsse dum verbleiben,", "tokens": ["Und", "nicht", "dem", "Frau\u00b7en\u00b7volk", ".", "Da\u00df", "m\u00fcs\u00b7se", "dum", "ver\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "NN", "$.", "KOUS", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die h\u00f6chste Klugheit sey, den Namen nur zu schreiben,", "tokens": ["Die", "h\u00f6chs\u00b7te", "Klug\u00b7heit", "sey", ",", "den", "Na\u00b7men", "nur", "zu", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Kehrt sich ein Weibsbild an die\u00df Geboth nun nicht,", "tokens": ["Kehrt", "sich", "ein", "Weibs\u00b7bild", "an", "die\u00df", "Ge\u00b7both", "nun", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "PDS", "NN", "ADV", "PTKNEG", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.21": {"text": "Hilf Himmel! wie wird es getadelt und gericht!", "tokens": ["Hilf", "Him\u00b7mel", "!", "wie", "wird", "es", "ge\u00b7ta\u00b7delt", "und", "ge\u00b7richt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWAV", "VAFIN", "PPER", "VVPP", "KON", "VVPP", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.22": {"text": "Du aber Grosser F\u00fcrst! wilst dich daran nicht kehren,", "tokens": ["Du", "a\u00b7ber", "Gros\u00b7ser", "F\u00fcrst", "!", "wilst", "dich", "da\u00b7ran", "nicht", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$.", "VMFIN", "PRF", "PAV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Vielmehr gedenkst du mich dem Neid zu Trutz zu ehren.", "tokens": ["Viel\u00b7mehr", "ge\u00b7denkst", "du", "mich", "dem", "Neid", "zu", "Trutz", "zu", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Mein! was kan ich davor, da\u00df mich Apollo liebt;", "tokens": ["Mein", "!", "was", "kan", "ich", "da\u00b7vor", ",", "da\u00df", "mich", "A\u00b7pol\u00b7lo", "liebt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VMFIN", "PPER", "PAV", "$,", "KOUS", "PPER", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da\u00df Pallas mir die Brust daraus zu saugen giebt;", "tokens": ["Da\u00df", "Pal\u00b7las", "mir", "die", "Brust", "da\u00b7raus", "zu", "sau\u00b7gen", "giebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "ART", "NN", "PAV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da\u00df mir die Musen hold! Soll ich denn ihre Gaben;", "tokens": ["Da\u00df", "mir", "die", "Mu\u00b7sen", "hold", "!", "Soll", "ich", "denn", "ih\u00b7re", "Ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "$.", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Soll ich des Sch\u00f6pfers Pfund so liederlich vergraben?", "tokens": ["Soll", "ich", "des", "Sch\u00f6p\u00b7fers", "Pfund", "so", "lie\u00b7der\u00b7lich", "ver\u00b7gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Nein? warlich, dieses geht Sidonia nicht ein,", "tokens": ["Nein", "?", "war\u00b7lich", ",", "die\u00b7ses", "geht", "Si\u00b7do\u00b7nia", "nicht", "ein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "$,", "PDS", "VVFIN", "NE", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.29": {"text": "Und solte Jupiter mit Donnerkeilen dr\u00e4un!", "tokens": ["Und", "sol\u00b7te", "Ju\u00b7pi\u00b7ter", "mit", "Don\u00b7ner\u00b7kei\u00b7len", "dr\u00e4un", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ich schw\u00f6r: Jemehr der Neid sich denkt an mir zu reiben;", "tokens": ["Ich", "schw\u00f6r", ":", "Je\u00b7mehr", "der", "Neid", "sich", "denkt", "an", "mir", "zu", "rei\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PIS", "ART", "NN", "PRF", "VVFIN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Jemehr bestreb ich mich zu lesen und zu schreiben!", "tokens": ["Je\u00b7mehr", "be\u00b7streb", "ich", "mich", "zu", "le\u00b7sen", "und", "zu", "schrei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Vor deine Gnad und Huld, wormit du jederzeit", "tokens": ["Vor", "dei\u00b7ne", "Gnad", "und", "Huld", ",", "wor\u00b7mit", "du", "je\u00b7der\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$,", "PWAV", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Arbeit meiner Hand so gn\u00e4digst angesehen.", "tokens": ["Die", "Ar\u00b7beit", "mei\u00b7ner", "Hand", "so", "gn\u00e4\u00b7digst", "an\u00b7ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fahr fort ", "tokens": ["Fahr", "fort"], "token_info": ["word", "word"], "pos": ["NN", "PTKVZ"], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "Da\u00df als du deine Reis' durch unsre Stadt verricht,", "tokens": ["Da\u00df", "als", "du", "dei\u00b7ne", "Reis'", "durch", "uns\u00b7re", "Stadt", "ver\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und als ein Graf durchgiengst, h\u00e4tt'st du dir vorgenommen,", "tokens": ["Und", "als", "ein", "Graf", "durch\u00b7giengst", ",", "h\u00e4tt'st", "du", "dir", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sidonien zu sehn, zu Hedewig zu kommen.", "tokens": ["Si\u00b7do\u00b7ni\u00b7en", "zu", "sehn", ",", "zu", "He\u00b7de\u00b7wig", "zu", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKZU", "VVINF", "$,", "APPR", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein du h\u00e4tt'st gesorgt, dein Ausgang m\u00f6chte dich", "tokens": ["Al\u00b7lein", "du", "h\u00e4tt'st", "ge\u00b7sorgt", ",", "dein", "Aus\u00b7gang", "m\u00f6ch\u00b7te", "dich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "VMFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In unsrer Geren-Stadt ", "tokens": ["In", "uns\u00b7rer", "Ge\u00b7ren\u00b7Stadt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Verrathen, und dich sehn. Wie z\u00fcrn ich aufs Geschicke", "tokens": ["Ver\u00b7ra\u00b7then", ",", "und", "dich", "sehn", ".", "Wie", "z\u00fcrn", "ich", "aufs", "Ge\u00b7schi\u00b7cke"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PPER", "VVINF", "$.", "PWAV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Schicksaal, da\u00df es mir die Gnade und das Gl\u00fccke,", "tokens": ["Und", "Schick\u00b7saal", ",", "da\u00df", "es", "mir", "die", "Gna\u00b7de", "und", "das", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Freude h\u00e4tte ich, ", "tokens": ["Die", "Freu\u00b7de", "h\u00e4t\u00b7te", "ich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Durch Dint und Kiel gebracht, die ich dadurch empfunden.", "tokens": ["Durch", "Dint", "und", "Kiel", "ge\u00b7bracht", ",", "die", "ich", "da\u00b7durch", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "VVPP", "$,", "PRELS", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie sich ", "tokens": ["Wie", "sich"], "token_info": ["word", "word"], "pos": ["PWAV", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Nicht ohne ist es zwar, ", "tokens": ["Nicht", "oh\u00b7ne", "ist", "es", "zwar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Man h\u00e4tte es gemerkt, man h\u00e4tte dich gekennt.", "tokens": ["Man", "h\u00e4t\u00b7te", "es", "ge\u00b7merkt", ",", "man", "h\u00e4t\u00b7te", "dich", "ge\u00b7kennt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVPP", "$,", "PIS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein F\u00fcrst kan sich nicht leicht verbergen und verhehlen.", "tokens": ["Ein", "F\u00fcrst", "kan", "sich", "nicht", "leicht", "ver\u00b7ber\u00b7gen", "und", "ver\u00b7heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "PTKNEG", "ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Gewi\u00df, man h\u00e4tte ", "tokens": ["Ge\u00b7wi\u00df", ",", "man", "h\u00e4t\u00b7te"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "PIS", "VAFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.15": {"text": "Sich auch im Reise-Hut, und Reise-Kleider wei\u00dft", "tokens": ["Sich", "auch", "im", "Rei\u00b7se\u00b7Hut", ",", "und", "Rei\u00b7se\u00b7Klei\u00b7der", "wei\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADV", "APPRART", "NN", "$,", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Aus Antlitz und Gestalt, Geberden, Augen, Wesen", "tokens": ["Aus", "Ant\u00b7litz", "und", "Ge\u00b7stalt", ",", "Ge\u00b7ber\u00b7den", ",", "Au\u00b7gen", ",", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Kan man das F\u00fcrstliche erkennen, sehn und lesen.", "tokens": ["Kan", "man", "das", "F\u00fcrst\u00b7li\u00b7che", "er\u00b7ken\u00b7nen", ",", "sehn", "und", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "NN", "VVINF", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Was Wunder, wenn ich dich so gleich als F\u00fcrst gegr\u00fc\u00dft.", "tokens": ["Was", "Wun\u00b7der", ",", "wenn", "ich", "dich", "so", "gleich", "als", "F\u00fcrst", "ge\u00b7gr\u00fc\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "KOUS", "PPER", "PRF", "ADV", "ADV", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und unterm Reise-Rock den Purpur-Saum gek\u00fc\u00dft.", "tokens": ["Und", "un\u00b7term", "Rei\u00b7se\u00b7Rock", "den", "Pur\u00b7pur\u00b7Saum", "ge\u00b7k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ich danke Dir ", "tokens": ["Ich", "dan\u00b7ke", "Dir"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Die Du mir unverdient erzeigst. ", "tokens": ["Die", "Du", "mir", "un\u00b7ver\u00b7di\u00b7ent", "er\u00b7zeigst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Dieselbe nicht zur\u00fcck. Erhalt mir deine Gnad,", "tokens": ["Die\u00b7sel\u00b7be", "nicht", "zu\u00b7r\u00fcck", ".", "Er\u00b7halt", "mir", "dei\u00b7ne", "Gnad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "PTKNEG", "PTKVZ", "$.", "NN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und schaffe, da\u00df mein Mund einmahl die Gnade hat,", "tokens": ["Und", "schaf\u00b7fe", ",", "da\u00df", "mein", "Mund", "ein\u00b7mahl", "die", "Gna\u00b7de", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Deinen F\u00fcrsten-Rock und Purpur-Saum zu k\u00fcssen.", "tokens": ["Und", "Dei\u00b7nen", "F\u00fcrs\u00b7ten\u00b7Rock", "und", "Pur\u00b7pur\u00b7Saum", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ist dieses nicht zu viel,", "tokens": ["Ist", "die\u00b7ses", "nicht", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df meine Niedrigkeit, da\u00df sich mein Dichterkiel", "tokens": ["Da\u00df", "mei\u00b7ne", "Nied\u00b7rig\u00b7keit", ",", "da\u00df", "sich", "mein", "Dich\u00b7ter\u00b7kiel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "KOUS", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu deiner Hoheit wagt? darf ich mich unterstehen", "tokens": ["Zu", "dei\u00b7ner", "Ho\u00b7heit", "wagt", "?", "darf", "ich", "mich", "un\u00b7ter\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durchlauchtster! durch ein Blat vor dein Gesicht zu gehen?", "tokens": ["Durch\u00b7lauchts\u00b7ter", "!", "durch", "ein", "Blat", "vor", "dein", "Ge\u00b7sicht", "zu", "ge\u00b7hen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich zittre mit der Hand, ich werf die Feder hin!", "tokens": ["Ich", "zitt\u00b7re", "mit", "der", "Hand", ",", "ich", "werf", "die", "Fe\u00b7der", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Trieb, Ehrfurcht, Hofnung, Furcht verwirrt jetzt meinen Sinn.", "tokens": ["Trieb", ",", "Ehr\u00b7furcht", ",", "Hof\u00b7nung", ",", "Furcht", "ver\u00b7wirrt", "jetzt", "mei\u00b7nen", "Sinn", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch was verzage ich! Ich nehm die Feder wieder.", "tokens": ["Doch", "was", "ver\u00b7za\u00b7ge", "ich", "!", "Ich", "nehm", "die", "Fe\u00b7der", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Dichter nicht verschm\u00e4ht. Er h\u00e4lt gelehrten Flei\u00df", "tokens": ["Der", "Dich\u00b7ter", "nicht", "ver\u00b7schm\u00e4ht", ".", "Er", "h\u00e4lt", "ge\u00b7lehr\u00b7ten", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$.", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nach seiner Weisheit wehrt. Er kennt, Er sieht und wei\u00df", "tokens": ["Nach", "sei\u00b7ner", "Weis\u00b7heit", "wehrt", ".", "Er", "kennt", ",", "Er", "sieht", "und", "wei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nach seiner Einsicht wohl, wer sich dahin bestrebet,", "tokens": ["Nach", "sei\u00b7ner", "Ein\u00b7sicht", "wohl", ",", "wer", "sich", "da\u00b7hin", "be\u00b7stre\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$,", "PWS", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da\u00df er durch Wissenschaft sich aus dem Staub erhebet,", "tokens": ["Da\u00df", "er", "durch", "Wis\u00b7sen\u00b7schaft", "sich", "aus", "dem", "Staub", "er\u00b7he\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und sucht, kein faules Glied der Republik zu seyn.", "tokens": ["Und", "sucht", ",", "kein", "fau\u00b7les", "Glied", "der", "Re\u00b7pub\u00b7lik", "zu", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PIAT", "ADJA", "NN", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mir f\u00e4llt ", "tokens": ["Mir", "f\u00e4llt"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "Wie hoch ", "tokens": ["Wie", "hoch"], "token_info": ["word", "word"], "pos": ["PWAV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Wodurch ", "tokens": ["Wo\u00b7durch"], "token_info": ["word"], "pos": ["PWAV"], "meter": "-+", "measure": "iambic.single"}}, "stanza.10": {"line.1": {"text": "Allein ", "tokens": ["Al\u00b7lein"], "token_info": ["word"], "pos": ["ADV"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Auch an und vor sich selbst, wohl deine Gnad und Gunst?", "tokens": ["Auch", "an", "und", "vor", "sich", "selbst", ",", "wohl", "dei\u00b7ne", "Gnad", "und", "Gunst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "APPR", "PRF", "ADV", "$,", "ADV", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man schimpft und h\u00f6hnt sie ja; man nennt sie offt bey Hofe", "tokens": ["Man", "schimpft", "und", "h\u00f6hnt", "sie", "ja", ";", "man", "nennt", "sie", "offt", "bey", "Ho\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$.", "PIS", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie G\u00fcnther schon gesagt, die abgedankte Zofe.", "tokens": ["Wie", "G\u00fcn\u00b7ther", "schon", "ge\u00b7sagt", ",", "die", "ab\u00b7ge\u00b7dank\u00b7te", "Zo\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "VVPP", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie heist ein Hirngespinst, und eine Bettel-Magd,", "tokens": ["Sie", "heist", "ein", "Hirn\u00b7ge\u00b7spinst", ",", "und", "ei\u00b7ne", "Bet\u00b7tel\u00b7Magd", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und eine Heuchlerin die nur zum Scheine klagt.", "tokens": ["Und", "ei\u00b7ne", "Heuch\u00b7le\u00b7rin", "die", "nur", "zum", "Schei\u00b7ne", "klagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie schmeichle um Gewinst, und wisse zuverblenden,", "tokens": ["Sie", "schmeich\u00b7le", "um", "Ge\u00b7winst", ",", "und", "wis\u00b7se", "zu\u00b7ver\u00b7blen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "KON", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und k\u00f6nte meisterlich die edle Zeit verschwenden.", "tokens": ["Und", "k\u00f6n\u00b7te", "meis\u00b7ter\u00b7lich", "die", "ed\u00b7le", "Zeit", "ver\u00b7schwen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Laster sind weit mehr die man ihr angedicht.", "tokens": ["Die", "Las\u00b7ter", "sind", "weit", "mehr", "die", "man", "ihr", "an\u00b7ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADV", "ART", "PIS", "PPER", "VVPP", "$."], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Bist du ihr dennoch hold? Ists nicht zuviel vor Helden", "tokens": ["Bist", "du", "ihr", "den\u00b7noch", "hold", "?", "Ists", "nicht", "zu\u00b7viel", "vor", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADJD", "$.", "NE", "PTKNEG", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und F\u00fcrsten, wenn sie was zu ihrem Ruhme melden?", "tokens": ["Und", "F\u00fcrs\u00b7ten", ",", "wenn", "sie", "was", "zu", "ih\u00b7rem", "Ruh\u00b7me", "mel\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KOUS", "PPER", "PIS", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ruft nicht der Weisheit Feind, der S\u00fcd und West durchzieht.", "tokens": ["Ruft", "nicht", "der", "Weis\u00b7heit", "Feind", ",", "der", "S\u00fcd", "und", "West", "durch\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ver\u00e4chtlich w\u00e4rs, wenn sich ein Prinz um sie bem\u00fcht.", "tokens": ["Ver\u00b7\u00e4cht\u00b7lich", "w\u00e4rs", ",", "wenn", "sich", "ein", "Prinz", "um", "sie", "be\u00b7m\u00fcht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "KOUS", "PRF", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein Herzog d\u00f6rfte sie nicht lesen oder kennen,", "tokens": ["Ein", "Her\u00b7zog", "d\u00f6rf\u00b7te", "sie", "nicht", "le\u00b7sen", "o\u00b7der", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "PTKNEG", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Er k\u00f6nte sie, wie dort Sibillens Buch verbrennen.", "tokens": ["Er", "k\u00f6n\u00b7te", "sie", ",", "wie", "dort", "Si\u00b7bil\u00b7lens", "Buch", "ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "$,", "PWAV", "ADV", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "(das sie zwar selbst gethan.) Der F\u00fcrsten Lust allein", "tokens": ["(", "das", "sie", "zwar", "selbst", "ge\u00b7than", ".", ")", "Der", "F\u00fcrs\u00b7ten", "Lust", "al\u00b7lein"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$.", "$(", "ART", "NN", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Solt nur die Lust der Welt, das Trink und Jagen seyn.", "tokens": ["Solt", "nur", "die", "Lust", "der", "Welt", ",", "das", "Trink", "und", "Ja\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vortreflich sch\u00f6ner Spruch! wie? sind denn nicht die Prinzen", "tokens": ["Vor\u00b7tre\u00b7flich", "sch\u00f6\u00b7ner", "Spruch", "!", "wie", "?", "sind", "denn", "nicht", "die", "Prin\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "$.", "PWAV", "$.", "VAFIN", "ADV", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ein Vorbild und ein Licht und V\u00e4ter der Provinzen?", "tokens": ["Ein", "Vor\u00b7bild", "und", "ein", "Licht", "und", "V\u00e4\u00b7ter", "der", "Pro\u00b7vin\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ein F\u00fcrst mu\u00df Wissenschaft, Verstand, beherztes Blut,", "tokens": ["Ein", "F\u00fcrst", "mu\u00df", "Wis\u00b7sen\u00b7schaft", ",", "Ver\u00b7stand", ",", "be\u00b7herz\u00b7tes", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Huld, Gnade, Warheit, Treu, gerecht, doch sanften Muth,", "tokens": ["Huld", ",", "Gna\u00b7de", ",", "War\u00b7heit", ",", "Treu", ",", "ge\u00b7recht", ",", "doch", "sanf\u00b7ten", "Muth", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "ADJD", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Erbarmen, G\u00fctigkeit, und andre F\u00fcrsten-Gaben,", "tokens": ["Er\u00b7bar\u00b7men", ",", "G\u00fc\u00b7tig\u00b7keit", ",", "und", "and\u00b7re", "F\u00fcrs\u00b7ten\u00b7Ga\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Zu seines Namens Ruhm, und Gl\u00fcck des Landes haben.", "tokens": ["Zu", "sei\u00b7nes", "Na\u00b7mens", "Ruhm", ",", "und", "Gl\u00fcck", "des", "Lan\u00b7des", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "KON", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die Weisheit, der Verstand, die lautere Vernunft,", "tokens": ["Die", "Weis\u00b7heit", ",", "der", "Ver\u00b7stand", ",", "die", "lau\u00b7te\u00b7re", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die einen Herzog schm\u00fcckt, schlie\u00dft nun die Musen-Zunft", "tokens": ["Die", "ei\u00b7nen", "Her\u00b7zog", "schm\u00fcckt", ",", "schlie\u00dft", "nun", "die", "Mu\u00b7sen\u00b7Zunft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Aus seiner Brust nicht aus. Sie steht mit unter diesen,", "tokens": ["Aus", "sei\u00b7ner", "Brust", "nicht", "aus", ".", "Sie", "steht", "mit", "un\u00b7ter", "die\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "APPR", "PDAT", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die F\u00fcrsten Gnadenreich und Gro\u00dfmuthsvoll begr\u00fcssen,", "tokens": ["Die", "F\u00fcrs\u00b7ten", "Gna\u00b7den\u00b7reich", "und", "Gro\u00df\u00b7muths\u00b7voll", "be\u00b7gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Es ist die Poesie kein niedertr\u00e4chtig Werk;", "tokens": ["Es", "ist", "die", "Poe\u00b7sie", "kein", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "Werk", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sie ist der weisesten und gr\u00f6\u00dften Augenmerk,", "tokens": ["Sie", "ist", "der", "wei\u00b7ses\u00b7ten", "und", "gr\u00f6\u00df\u00b7ten", "Au\u00b7gen\u00b7merk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Und s\u00fcsser Zeitvertreib. Die Potentanten m\u00fcssen", "tokens": ["Und", "s\u00fcs\u00b7ser", "Zeit\u00b7ver\u00b7treib", ".", "Die", "Po\u00b7ten\u00b7tan\u00b7ten", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$.", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An etwas eine Lust nach ihrer Last geniessen.", "tokens": ["An", "et\u00b7was", "ei\u00b7ne", "Lust", "nach", "ih\u00b7rer", "Last", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der F\u00fcrsten ihre Lust ist zwar gar mancherley,", "tokens": ["Der", "F\u00fcrs\u00b7ten", "ih\u00b7re", "Lust", "ist", "zwar", "gar", "man\u00b7cher\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "ADV", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Rudolphens Pinsel kam den Mahlern treflich bey.", "tokens": ["Ru\u00b7dol\u00b7phens", "Pin\u00b7sel", "kam", "den", "Mah\u00b7lern", "tref\u00b7lich", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der junge Cyrus fand an junger B\u00e4ume setzen", "tokens": ["Der", "jun\u00b7ge", "Cy\u00b7rus", "fand", "an", "jun\u00b7ger", "B\u00e4u\u00b7me", "set\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "VVFIN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die angenehmste Lust, das herrlichste Ergetzen.", "tokens": ["Die", "an\u00b7ge\u00b7nehms\u00b7te", "Lust", ",", "das", "herr\u00b7lichs\u00b7te", "Er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Gambrivius braut Bier. Albertus drechslet sch\u00f6n.", "tokens": ["Gam\u00b7bri\u00b7vius", "braut", "Bier", ".", "Al\u00b7ber\u00b7tus", "drechs\u00b7let", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$.", "NE", "VVFIN", "ADJD", "$."], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Es wu\u00dfte Carl geschickt mit Uhren umzugehn.", "tokens": ["Es", "wu\u00df\u00b7te", "Carl", "ge\u00b7schickt", "mit", "Uh\u00b7ren", "um\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "VVPP", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wilhelmus gleichfals auch. Und Ferdinand polirte", "tokens": ["Wil\u00b7hel\u00b7mus", "gleich\u00b7fals", "auch", ".", "Und", "Fer\u00b7di\u00b7nand", "po\u00b7lir\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADV", "ADV", "$.", "KON", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gold und die Waffen sch\u00f6n. Garochus schnitzt und zierte,", "tokens": ["Gold", "und", "die", "Waf\u00b7fen", "sch\u00f6n", ".", "Ga\u00b7ro\u00b7chus", "schnitzt", "und", "zier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "ADJD", "$.", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.13": {"text": "Der Bogen Pfeile wohl. Aeropus ward bedacht,", "tokens": ["Der", "Bo\u00b7gen", "Pfei\u00b7le", "wohl", ".", "A\u00b7e\u00b7ro\u00b7pus", "ward", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "$.", "NE", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Wie er bald Lichtergen und bald Laternen macht'.", "tokens": ["Wie", "er", "bald", "Lich\u00b7ter\u00b7gen", "und", "bald", "La\u00b7ter\u00b7nen", "macht'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "NN", "KON", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Atheus putzt sein Ro\u00df. Und Abas schlug die Eisen", "tokens": ["A\u00b7theus", "putzt", "sein", "Ro\u00df", ".", "Und", "A\u00b7bas", "schlug", "die", "Ei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "$.", "KON", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.16": {"text": "Dem Reitpferd selbsten an, und z\u00e4umt es auf den Reisen.", "tokens": ["Dem", "Reit\u00b7pferd", "selbs\u00b7ten", "an", ",", "und", "z\u00e4umt", "es", "auf", "den", "Rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was macht Domitius? Er spie\u00dft die Fliegen an.", "tokens": ["Was", "macht", "Do\u00b7mi\u00b7tius", "?", "Er", "spie\u00dft", "die", "Flie\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NE", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Ich wei\u00df zwar nicht, ob man die\u00df F\u00fcrstlich nennen kan!", "tokens": ["Ich", "wei\u00df", "zwar", "nicht", ",", "ob", "man", "die\u00df", "F\u00fcrst\u00b7lich", "nen\u00b7nen", "kan", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "KOUS", "PIS", "PDS", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ich wei\u00df nicht, hab ich recht? bey F\u00fcrstlichem Vergn\u00fcgen,", "tokens": ["Ich", "wei\u00df", "nicht", ",", "hab", "ich", "recht", "?", "bey", "F\u00fcrst\u00b7li\u00b7chem", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "VAFIN", "PPER", "ADJD", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mu\u00df doch der grosse Geist allzeit zum Grunde liegen.", "tokens": ["Mu\u00df", "doch", "der", "gros\u00b7se", "Geist", "all\u00b7zeit", "zum", "Grun\u00b7de", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wie sch\u00f6n ists, wenn ein F\u00fcrst kein F\u00fcrsten-Haupt erhebt,", "tokens": ["Wie", "sch\u00f6n", "ists", ",", "wenn", "ein", "F\u00fcrst", "kein", "F\u00fcrs\u00b7ten\u00b7Haupt", "er\u00b7hebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und nach der sch\u00f6nsten Lust der Weisheit eifrig strebt,", "tokens": ["Und", "nach", "der", "sch\u00f6ns\u00b7ten", "Lust", "der", "Weis\u00b7heit", "eif\u00b7rig", "strebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sich an ihr erg\u00f6tzt: So kan er klug regieren,", "tokens": ["Und", "sich", "an", "ihr", "er\u00b7g\u00f6tzt", ":", "So", "kan", "er", "klug", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPER", "VVPP", "$.", "ADV", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und seinen F\u00fcrsten-Hut durch sich noch gr\u00f6sser zieren.", "tokens": ["Und", "sei\u00b7nen", "F\u00fcrs\u00b7ten\u00b7Hut", "durch", "sich", "noch", "gr\u00f6s\u00b7ser", "zie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PRF", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Weisheit find kein Haus, zu ihrem Gl\u00fcck und Ehr,", "tokens": ["Die", "Weis\u00b7heit", "find", "kein", "Haus", ",", "zu", "ih\u00b7rem", "Gl\u00fcck", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,", "APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das sch\u00f6ner, als die Brust der Potentanten w\u00e4r.", "tokens": ["Das", "sch\u00f6\u00b7ner", ",", "als", "die", "Brust", "der", "Po\u00b7ten\u00b7tan\u00b7ten", "w\u00e4r", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "KOUS", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch kluge F\u00fcrsten kan die Weisheit herrlich gl\u00e4nzen;", "tokens": ["Durch", "klu\u00b7ge", "F\u00fcrs\u00b7ten", "kan", "die", "Weis\u00b7heit", "herr\u00b7lich", "gl\u00e4n\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Durch sie erweitert sich ihr Reich und seine Gr\u00e4nzen.", "tokens": ["Durch", "sie", "er\u00b7wei\u00b7tert", "sich", "ihr", "Reich", "und", "sei\u00b7ne", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PRF", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der R\u00f6mer edles Haupt Aurelius Anton", "tokens": ["Der", "R\u00f6\u00b7mer", "ed\u00b7les", "Haupt", "Au\u00b7re\u00b7li\u00b7us", "An\u00b7ton"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "NE", "NE"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "War ihrer Augenlust, und ihr warhaftger Sohn.", "tokens": ["War", "ih\u00b7rer", "Au\u00b7gen\u00b7lust", ",", "und", "ihr", "war\u00b7haft\u00b7ger", "Sohn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Was that Vespasian? Was Zeno? sie studirten.", "tokens": ["Was", "that", "Ves\u00b7pa\u00b7si\u00b7an", "?", "Was", "Ze\u00b7no", "?", "sie", "stu\u00b7dir\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NE", "$.", "PWS", "NE", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was C\u00e4sar? Friederich? Sie lasen, meditirten.", "tokens": ["Was", "C\u00e4\u00b7sar", "?", "Frie\u00b7de\u00b7rich", "?", "Sie", "la\u00b7sen", ",", "me\u00b7di\u00b7tir\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "NE", "$.", "NE", "$.", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "August und Adrian, Alphonsus liebten sie:", "tokens": ["Au\u00b7gust", "und", "Ad\u00b7ri\u00b7an", ",", "Al\u00b7phon\u00b7sus", "lieb\u00b7ten", "sie", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,", "NE", "VVFIN", "PPER", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.14": {"text": "Und Carl verehrte auch die Weisheit spat und fr\u00fch.", "tokens": ["Und", "Carl", "ver\u00b7ehr\u00b7te", "auch", "die", "Weis\u00b7heit", "spat", "und", "fr\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Franciscus, Heinrich la\u00df mit Lust gelehrte Schriften.", "tokens": ["Fran\u00b7cis\u00b7cus", ",", "Hein\u00b7rich", "la\u00df", "mit", "Lust", "ge\u00b7lehr\u00b7te", "Schrif\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "VVFIN", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "O sch\u00f6ne F\u00fcrsten-Lust! die kan ein Denkmaal stiften", "tokens": ["O", "sch\u00f6\u00b7ne", "F\u00fcrs\u00b7ten\u00b7Lust", "!", "die", "kan", "ein", "Denk\u00b7maal", "stif\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "VMFIN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Das ewiglich besteht. War Nero voller Wuth;", "tokens": ["Das", "e\u00b7wig\u00b7lich", "be\u00b7steht", ".", "War", "Ne\u00b7ro", "vol\u00b7ler", "Wuth", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "$.", "VAFIN", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So nahm die Wissenschaft und Dichtkunst doch sein Blut,", "tokens": ["So", "nahm", "die", "Wis\u00b7sen\u00b7schaft", "und", "Dicht\u00b7kunst", "doch", "sein", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und seine Seele ein: Er hat geschickt geschrieben,", "tokens": ["Und", "sei\u00b7ne", "See\u00b7le", "ein", ":", "Er", "hat", "ge\u00b7schickt", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und mit der Poesie die Zeit gar oft vertrieben.", "tokens": ["Und", "mit", "der", "Poe\u00b7sie", "die", "Zeit", "gar", "oft", "ver\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Wie mancher grosser F\u00fcrst, den Deutschland in sich schlie\u00dft", "tokens": ["Wie", "man\u00b7cher", "gros\u00b7ser", "F\u00fcrst", ",", "den", "Deutschland", "in", "sich", "schlie\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "$,", "ART", "NN", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.22": {"text": "Trinkt \u00f6fters aus dem Flu\u00df, der am Parnasso flie\u00dft.", "tokens": ["Trinkt", "\u00f6f\u00b7ters", "aus", "dem", "Flu\u00df", ",", "der", "am", "Par\u00b7nas\u00b7so", "flie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Man geh die Prinzen durch, so wird man kl\u00e4rlich lesen,", "tokens": ["Man", "geh", "die", "Prin\u00b7zen", "durch", ",", "so", "wird", "man", "kl\u00e4r\u00b7lich", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "VAFIN", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und finden, da\u00df ihr Herz der Musensitz gewesen.", "tokens": ["Und", "fin\u00b7den", ",", "da\u00df", "ihr", "Herz", "der", "Mu\u00b7sen\u00b7sitz", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Hat nicht der Held Eugen die Dichtkunst hochgesch\u00e4tzt?", "tokens": ["Hat", "nicht", "der", "Held", "Eu\u00b7gen", "die", "Dicht\u00b7kunst", "hoch\u00b7ge\u00b7sch\u00e4tzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "NE", "ART", "NN", "VVPP", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Was Wunder, wenn ", "tokens": ["Was", "Wun\u00b7der", ",", "wenn"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWS", "NN", "$,", "KOUS"], "meter": "-+-+", "measure": "iambic.di"}, "line.27": {"text": "Was Wunder, da\u00df du Sie ", "tokens": ["Was", "Wun\u00b7der", ",", "da\u00df", "du", "Sie"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NN", "$,", "KOUS", "PPER", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Und ihr dein grosses Herz zu eine Wohnhaus giebest.", "tokens": ["Und", "ihr", "dein", "gros\u00b7ses", "Herz", "zu", "ei\u00b7ne", "Wohn\u00b7haus", "gie\u00b7best", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Dein hocherleuchter Geist sieht ihre Sch\u00f6nheit ein.", "tokens": ["Dein", "ho\u00b7cher\u00b7leuch\u00b7ter", "Geist", "sieht", "ih\u00b7re", "Sch\u00f6n\u00b7heit", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Du weist sie will besitzt, sie will verwahret seyn.", "tokens": ["Du", "weist", "sie", "will", "be\u00b7sitzt", ",", "sie", "will", "ver\u00b7wah\u00b7ret", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VMFIN", "VVPP", "$,", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Du bist ein weiser F\u00fcrst, den Pallas auferzogen,", "tokens": ["Du", "bist", "ein", "wei\u00b7ser", "F\u00fcrst", ",", "den", "Pal\u00b7las", "auf\u00b7er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Drum bist du ihrem Volk auch Gro\u00dfmuthsvoll gewogen.", "tokens": ["Drum", "bist", "du", "ih\u00b7rem", "Volk", "auch", "Gro\u00df\u00b7muths\u00b7voll", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ein Dichter findt bey dir ein gn\u00e4diges Geh\u00f6r,", "tokens": ["Ein", "Dich\u00b7ter", "findt", "bey", "dir", "ein", "gn\u00e4\u00b7di\u00b7ges", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Und wenn der Zoil auch mit Macht darwieder w\u00e4r.", "tokens": ["Und", "wenn", "der", "Zoil", "auch", "mit", "Macht", "dar\u00b7wie\u00b7der", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "APPR", "NN", "PAV", "VAFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "So liebst und lobest du, ", "tokens": ["So", "liebst", "und", "lo\u00b7best", "du", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.36": {"text": "Die Federn und das Blat der klug und weisen M\u00e4nner,", "tokens": ["Die", "Fe\u00b7dern", "und", "das", "Blat", "der", "klug", "und", "wei\u00b7sen", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ART", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Nach deiner Einsicht hoch, und siehst es gn\u00e4dig an.", "tokens": ["Nach", "dei\u00b7ner", "Ein\u00b7sicht", "hoch", ",", "und", "siehst", "es", "gn\u00e4\u00b7dig", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Allein, ", "tokens": ["Al\u00b7lein", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "(ich bitte demuthsvoll, vergieb den k\u00fchnen Fragen,", "tokens": ["(", "ich", "bit\u00b7te", "de\u00b7muths\u00b7voll", ",", "ver\u00b7gieb", "den", "k\u00fch\u00b7nen", "Fra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "ADJD", "$,", "VVIMP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verzeihe gn\u00e4diglich, was jetzt die Worte sagen!)", "tokens": ["Ver\u00b7zei\u00b7he", "gn\u00e4\u00b7di\u00b7glich", ",", "was", "jetzt", "die", "Wor\u00b7te", "sa\u00b7gen", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADJD", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df du der H\u00e4nde Werk von einem Weibesbild,", "tokens": ["Da\u00df", "du", "der", "H\u00e4n\u00b7de", "Werk", "von", "ei\u00b7nem", "Wei\u00b7bes\u00b7bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das ja mit keinem Witz; mit Schwachheit angef\u00fcllt,", "tokens": ["Das", "ja", "mit", "kei\u00b7nem", "Witz", ";", "mit", "Schwach\u00b7heit", "an\u00b7ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PIAT", "NN", "$.", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So gn\u00e4diglich verehrst? wo hat man wohl vernommen,", "tokens": ["So", "gn\u00e4\u00b7di\u00b7glich", "ver\u00b7ehrst", "?", "wo", "hat", "man", "wohl", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$.", "PWAV", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das von dem Frauenvolk was Gutes w\u00e4r gekommen?", "tokens": ["Das", "von", "dem", "Frau\u00b7en\u00b7volk", "was", "Gu\u00b7tes", "w\u00e4r", "ge\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "PWS", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So spricht der Klugheit Feind; so spricht der tolle Neid.", "tokens": ["So", "spricht", "der", "Klug\u00b7heit", "Feind", ";", "so", "spricht", "der", "tol\u00b7le", "Neid", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man h\u00f6rts ja, wie er oft mit vollem Munde schreyt:", "tokens": ["Man", "h\u00f6rts", "ja", ",", "wie", "er", "oft", "mit", "vol\u00b7lem", "Mun\u00b7de", "schreyt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein Weibsbild sey kein Mensch. Wir w\u00e4ren Plage-Geister", "tokens": ["Ein", "Weibs\u00b7bild", "sey", "kein", "Mensch", ".", "Wir", "w\u00e4\u00b7ren", "Pla\u00b7ge\u00b7Geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$.", "PPER", "VAFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der M\u00e4nner. Und was mehr? Xantippens Obermeister.", "tokens": ["Der", "M\u00e4n\u00b7ner", ".", "Und", "was", "mehr", "?", "Xan\u00b7tip\u00b7pens", "O\u00b7ber\u00b7meis\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "KON", "PWS", "ADV", "$.", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und solche Tittel mehr, die er umsonst verschenkt.", "tokens": ["Und", "sol\u00b7che", "Tit\u00b7tel", "mehr", ",", "die", "er", "um\u00b7sonst", "ver\u00b7schenkt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "$,", "PRELS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Ein Weibsbild, das an Kiel und Wissenschafft gedenkt,", "tokens": ["Ein", "Weibs\u00b7bild", ",", "das", "an", "Kiel", "und", "Wis\u00b7sen\u00b7schafft", "ge\u00b7denkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NE", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und sie zu forschen sucht, das mu\u00df ein Monstrum heisen,", "tokens": ["Und", "sie", "zu", "for\u00b7schen", "sucht", ",", "das", "mu\u00df", "ein", "Monst\u00b7rum", "hei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "VVFIN", "$,", "PDS", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man m\u00fc\u00df im Buch und Kiel aus denen H\u00e4nden reisen.", "tokens": ["Man", "m\u00fc\u00df", "im", "Buch", "und", "Kiel", "aus", "de\u00b7nen", "H\u00e4n\u00b7den", "rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPRART", "NN", "KON", "NE", "APPR", "PRELS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Degen in der Faust, die Feder in der Hand,", "tokens": ["Der", "De\u00b7gen", "in", "der", "Faust", ",", "die", "Fe\u00b7der", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Den Hut auf Schl\u00e4ff und Kopf w\u00e4r M\u00e4nnern zuerkant,", "tokens": ["Den", "Hut", "auf", "Schl\u00e4ff", "und", "Kopf", "w\u00e4r", "M\u00e4n\u00b7nern", "zu\u00b7er\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und nicht dem Frauenvolk. Da\u00df m\u00fcsse dum verbleiben,", "tokens": ["Und", "nicht", "dem", "Frau\u00b7en\u00b7volk", ".", "Da\u00df", "m\u00fcs\u00b7se", "dum", "ver\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "NN", "$.", "KOUS", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die h\u00f6chste Klugheit sey, den Namen nur zu schreiben,", "tokens": ["Die", "h\u00f6chs\u00b7te", "Klug\u00b7heit", "sey", ",", "den", "Na\u00b7men", "nur", "zu", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Kehrt sich ein Weibsbild an die\u00df Geboth nun nicht,", "tokens": ["Kehrt", "sich", "ein", "Weibs\u00b7bild", "an", "die\u00df", "Ge\u00b7both", "nun", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "PDS", "NN", "ADV", "PTKNEG", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.21": {"text": "Hilf Himmel! wie wird es getadelt und gericht!", "tokens": ["Hilf", "Him\u00b7mel", "!", "wie", "wird", "es", "ge\u00b7ta\u00b7delt", "und", "ge\u00b7richt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWAV", "VAFIN", "PPER", "VVPP", "KON", "VVPP", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.22": {"text": "Du aber Grosser F\u00fcrst! wilst dich daran nicht kehren,", "tokens": ["Du", "a\u00b7ber", "Gros\u00b7ser", "F\u00fcrst", "!", "wilst", "dich", "da\u00b7ran", "nicht", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$.", "VMFIN", "PRF", "PAV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Vielmehr gedenkst du mich dem Neid zu Trutz zu ehren.", "tokens": ["Viel\u00b7mehr", "ge\u00b7denkst", "du", "mich", "dem", "Neid", "zu", "Trutz", "zu", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Mein! was kan ich davor, da\u00df mich Apollo liebt;", "tokens": ["Mein", "!", "was", "kan", "ich", "da\u00b7vor", ",", "da\u00df", "mich", "A\u00b7pol\u00b7lo", "liebt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VMFIN", "PPER", "PAV", "$,", "KOUS", "PPER", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da\u00df Pallas mir die Brust daraus zu saugen giebt;", "tokens": ["Da\u00df", "Pal\u00b7las", "mir", "die", "Brust", "da\u00b7raus", "zu", "sau\u00b7gen", "giebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "ART", "NN", "PAV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da\u00df mir die Musen hold! Soll ich denn ihre Gaben;", "tokens": ["Da\u00df", "mir", "die", "Mu\u00b7sen", "hold", "!", "Soll", "ich", "denn", "ih\u00b7re", "Ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "$.", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Soll ich des Sch\u00f6pfers Pfund so liederlich vergraben?", "tokens": ["Soll", "ich", "des", "Sch\u00f6p\u00b7fers", "Pfund", "so", "lie\u00b7der\u00b7lich", "ver\u00b7gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Nein? warlich, dieses geht Sidonia nicht ein,", "tokens": ["Nein", "?", "war\u00b7lich", ",", "die\u00b7ses", "geht", "Si\u00b7do\u00b7nia", "nicht", "ein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "$,", "PDS", "VVFIN", "NE", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.29": {"text": "Und solte Jupiter mit Donnerkeilen dr\u00e4un!", "tokens": ["Und", "sol\u00b7te", "Ju\u00b7pi\u00b7ter", "mit", "Don\u00b7ner\u00b7kei\u00b7len", "dr\u00e4un", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ich schw\u00f6r: Jemehr der Neid sich denkt an mir zu reiben;", "tokens": ["Ich", "schw\u00f6r", ":", "Je\u00b7mehr", "der", "Neid", "sich", "denkt", "an", "mir", "zu", "rei\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PIS", "ART", "NN", "PRF", "VVFIN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Jemehr bestreb ich mich zu lesen und zu schreiben!", "tokens": ["Je\u00b7mehr", "be\u00b7streb", "ich", "mich", "zu", "le\u00b7sen", "und", "zu", "schrei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Vor deine Gnad und Huld, wormit du jederzeit", "tokens": ["Vor", "dei\u00b7ne", "Gnad", "und", "Huld", ",", "wor\u00b7mit", "du", "je\u00b7der\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$,", "PWAV", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Arbeit meiner Hand so gn\u00e4digst angesehen.", "tokens": ["Die", "Ar\u00b7beit", "mei\u00b7ner", "Hand", "so", "gn\u00e4\u00b7digst", "an\u00b7ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fahr fort ", "tokens": ["Fahr", "fort"], "token_info": ["word", "word"], "pos": ["NN", "PTKVZ"], "meter": "-+", "measure": "iambic.single"}}, "stanza.15": {"line.1": {"text": "Da\u00df als du deine Reis' durch unsre Stadt verricht,", "tokens": ["Da\u00df", "als", "du", "dei\u00b7ne", "Reis'", "durch", "uns\u00b7re", "Stadt", "ver\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und als ein Graf durchgiengst, h\u00e4tt'st du dir vorgenommen,", "tokens": ["Und", "als", "ein", "Graf", "durch\u00b7giengst", ",", "h\u00e4tt'st", "du", "dir", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sidonien zu sehn, zu Hedewig zu kommen.", "tokens": ["Si\u00b7do\u00b7ni\u00b7en", "zu", "sehn", ",", "zu", "He\u00b7de\u00b7wig", "zu", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKZU", "VVINF", "$,", "APPR", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein du h\u00e4tt'st gesorgt, dein Ausgang m\u00f6chte dich", "tokens": ["Al\u00b7lein", "du", "h\u00e4tt'st", "ge\u00b7sorgt", ",", "dein", "Aus\u00b7gang", "m\u00f6ch\u00b7te", "dich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "VMFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In unsrer Geren-Stadt ", "tokens": ["In", "uns\u00b7rer", "Ge\u00b7ren\u00b7Stadt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Verrathen, und dich sehn. Wie z\u00fcrn ich aufs Geschicke", "tokens": ["Ver\u00b7ra\u00b7then", ",", "und", "dich", "sehn", ".", "Wie", "z\u00fcrn", "ich", "aufs", "Ge\u00b7schi\u00b7cke"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PPER", "VVINF", "$.", "PWAV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Schicksaal, da\u00df es mir die Gnade und das Gl\u00fccke,", "tokens": ["Und", "Schick\u00b7saal", ",", "da\u00df", "es", "mir", "die", "Gna\u00b7de", "und", "das", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Freude h\u00e4tte ich, ", "tokens": ["Die", "Freu\u00b7de", "h\u00e4t\u00b7te", "ich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Durch Dint und Kiel gebracht, die ich dadurch empfunden.", "tokens": ["Durch", "Dint", "und", "Kiel", "ge\u00b7bracht", ",", "die", "ich", "da\u00b7durch", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "VVPP", "$,", "PRELS", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie sich ", "tokens": ["Wie", "sich"], "token_info": ["word", "word"], "pos": ["PWAV", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Nicht ohne ist es zwar, ", "tokens": ["Nicht", "oh\u00b7ne", "ist", "es", "zwar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Man h\u00e4tte es gemerkt, man h\u00e4tte dich gekennt.", "tokens": ["Man", "h\u00e4t\u00b7te", "es", "ge\u00b7merkt", ",", "man", "h\u00e4t\u00b7te", "dich", "ge\u00b7kennt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVPP", "$,", "PIS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein F\u00fcrst kan sich nicht leicht verbergen und verhehlen.", "tokens": ["Ein", "F\u00fcrst", "kan", "sich", "nicht", "leicht", "ver\u00b7ber\u00b7gen", "und", "ver\u00b7heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "PTKNEG", "ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Gewi\u00df, man h\u00e4tte ", "tokens": ["Ge\u00b7wi\u00df", ",", "man", "h\u00e4t\u00b7te"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "PIS", "VAFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.15": {"text": "Sich auch im Reise-Hut, und Reise-Kleider wei\u00dft", "tokens": ["Sich", "auch", "im", "Rei\u00b7se\u00b7Hut", ",", "und", "Rei\u00b7se\u00b7Klei\u00b7der", "wei\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADV", "APPRART", "NN", "$,", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Aus Antlitz und Gestalt, Geberden, Augen, Wesen", "tokens": ["Aus", "Ant\u00b7litz", "und", "Ge\u00b7stalt", ",", "Ge\u00b7ber\u00b7den", ",", "Au\u00b7gen", ",", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Kan man das F\u00fcrstliche erkennen, sehn und lesen.", "tokens": ["Kan", "man", "das", "F\u00fcrst\u00b7li\u00b7che", "er\u00b7ken\u00b7nen", ",", "sehn", "und", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "NN", "VVINF", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Was Wunder, wenn ich dich so gleich als F\u00fcrst gegr\u00fc\u00dft.", "tokens": ["Was", "Wun\u00b7der", ",", "wenn", "ich", "dich", "so", "gleich", "als", "F\u00fcrst", "ge\u00b7gr\u00fc\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "KOUS", "PPER", "PRF", "ADV", "ADV", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und unterm Reise-Rock den Purpur-Saum gek\u00fc\u00dft.", "tokens": ["Und", "un\u00b7term", "Rei\u00b7se\u00b7Rock", "den", "Pur\u00b7pur\u00b7Saum", "ge\u00b7k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Ich danke Dir ", "tokens": ["Ich", "dan\u00b7ke", "Dir"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Die Du mir unverdient erzeigst. ", "tokens": ["Die", "Du", "mir", "un\u00b7ver\u00b7di\u00b7ent", "er\u00b7zeigst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Dieselbe nicht zur\u00fcck. Erhalt mir deine Gnad,", "tokens": ["Die\u00b7sel\u00b7be", "nicht", "zu\u00b7r\u00fcck", ".", "Er\u00b7halt", "mir", "dei\u00b7ne", "Gnad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "PTKNEG", "PTKVZ", "$.", "NN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und schaffe, da\u00df mein Mund einmahl die Gnade hat,", "tokens": ["Und", "schaf\u00b7fe", ",", "da\u00df", "mein", "Mund", "ein\u00b7mahl", "die", "Gna\u00b7de", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Deinen F\u00fcrsten-Rock und Purpur-Saum zu k\u00fcssen.", "tokens": ["Und", "Dei\u00b7nen", "F\u00fcrs\u00b7ten\u00b7Rock", "und", "Pur\u00b7pur\u00b7Saum", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}