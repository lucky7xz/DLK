{"textgrid.poem.26861": {"metadata": {"author": {"name": "Schiller, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Ein Geb\u00e4ude steht da ...", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Geb\u00e4ude steht da von uralten Zeiten,", "tokens": ["Ein", "Ge\u00b7b\u00e4u\u00b7de", "steht", "da", "von", "ur\u00b7al\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Es ist kein Tempel, es ist kein Haus,", "tokens": ["Es", "ist", "kein", "Tem\u00b7pel", ",", "es", "ist", "kein", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Reiter kann hundert Tage reiten,", "tokens": ["Ein", "Rei\u00b7ter", "kann", "hun\u00b7dert", "Ta\u00b7ge", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er umwandert es nicht, er reitets nicht aus.", "tokens": ["Er", "um\u00b7wan\u00b7dert", "es", "nicht", ",", "er", "rei\u00b7tets", "nicht", "aus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Jahrhunderte sind vor\u00fcbergeflogen,", "tokens": ["Jahr\u00b7hun\u00b7der\u00b7te", "sind", "vor\u00b7\u00fc\u00b7ber\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es trotzte der Zeit und der St\u00fcrme Heer,", "tokens": ["Es", "trotz\u00b7te", "der", "Zeit", "und", "der", "St\u00fcr\u00b7me", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Frei steht es unter dem himmlischen Bogen,", "tokens": ["Frei", "steht", "es", "un\u00b7ter", "dem", "himm\u00b7li\u00b7schen", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "++-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Es reicht in die Wolken, es netzt sich im Meer.", "tokens": ["Es", "reicht", "in", "die", "Wol\u00b7ken", ",", "es", "netzt", "sich", "im", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Nicht eitle Prahlsucht hat es get\u00fcrmet,", "tokens": ["Nicht", "eit\u00b7le", "Prahl\u00b7sucht", "hat", "es", "ge\u00b7t\u00fcr\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es dienet zum Heil, es rettet und schirmet,", "tokens": ["Es", "die\u00b7net", "zum", "Heil", ",", "es", "ret\u00b7tet", "und", "schir\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Seinesgleichen ist nicht auf Erden bekannt,", "tokens": ["Sei\u00b7nes\u00b7glei\u00b7chen", "ist", "nicht", "auf", "Er\u00b7den", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "APPR", "NN", "PTKVZ", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und doch ists ein Werk von Menschenhand.", "tokens": ["Und", "doch", "ists", "ein", "Werk", "von", "Men\u00b7schen\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Das alte fest gegr\u00fcndete Geb\u00e4ude,", "tokens": ["Das", "al\u00b7te", "fest", "ge\u00b7gr\u00fcn\u00b7de\u00b7te", "Ge\u00b7b\u00e4u\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das St\u00fcrmen und Jahrhunderten getrotzt,", "tokens": ["Das", "St\u00fcr\u00b7men", "und", "Jahr\u00b7hun\u00b7der\u00b7ten", "ge\u00b7trotzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das sich unendlich, unabsehlich leitet", "tokens": ["Das", "sich", "un\u00b7end\u00b7lich", ",", "un\u00b7ab\u00b7seh\u00b7lich", "lei\u00b7tet"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "PRF", "ADJD", "$,", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Tausende beschirmt, die gro\u00dfe Mauer ists,", "tokens": ["Und", "Tau\u00b7sen\u00b7de", "be\u00b7schirmt", ",", "die", "gro\u00b7\u00dfe", "Mau\u00b7er", "ists", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "$,", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die China von der Tartarw\u00fcste scheidet.", "tokens": ["Die", "Chi\u00b7na", "von", "der", "Tar\u00b7tar\u00b7w\u00fcs\u00b7te", "schei\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ein Geb\u00e4ude steht da von uralten Zeiten,", "tokens": ["Ein", "Ge\u00b7b\u00e4u\u00b7de", "steht", "da", "von", "ur\u00b7al\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Es ist kein Tempel, es ist kein Haus,", "tokens": ["Es", "ist", "kein", "Tem\u00b7pel", ",", "es", "ist", "kein", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Reiter kann hundert Tage reiten,", "tokens": ["Ein", "Rei\u00b7ter", "kann", "hun\u00b7dert", "Ta\u00b7ge", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er umwandert es nicht, er reitets nicht aus.", "tokens": ["Er", "um\u00b7wan\u00b7dert", "es", "nicht", ",", "er", "rei\u00b7tets", "nicht", "aus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "Jahrhunderte sind vor\u00fcbergeflogen,", "tokens": ["Jahr\u00b7hun\u00b7der\u00b7te", "sind", "vor\u00b7\u00fc\u00b7ber\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es trotzte der Zeit und der St\u00fcrme Heer,", "tokens": ["Es", "trotz\u00b7te", "der", "Zeit", "und", "der", "St\u00fcr\u00b7me", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Frei steht es unter dem himmlischen Bogen,", "tokens": ["Frei", "steht", "es", "un\u00b7ter", "dem", "himm\u00b7li\u00b7schen", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "++-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Es reicht in die Wolken, es netzt sich im Meer.", "tokens": ["Es", "reicht", "in", "die", "Wol\u00b7ken", ",", "es", "netzt", "sich", "im", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "Nicht eitle Prahlsucht hat es get\u00fcrmet,", "tokens": ["Nicht", "eit\u00b7le", "Prahl\u00b7sucht", "hat", "es", "ge\u00b7t\u00fcr\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es dienet zum Heil, es rettet und schirmet,", "tokens": ["Es", "die\u00b7net", "zum", "Heil", ",", "es", "ret\u00b7tet", "und", "schir\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Seinesgleichen ist nicht auf Erden bekannt,", "tokens": ["Sei\u00b7nes\u00b7glei\u00b7chen", "ist", "nicht", "auf", "Er\u00b7den", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "APPR", "NN", "PTKVZ", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und doch ists ein Werk von Menschenhand.", "tokens": ["Und", "doch", "ists", "ein", "Werk", "von", "Men\u00b7schen\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Das alte fest gegr\u00fcndete Geb\u00e4ude,", "tokens": ["Das", "al\u00b7te", "fest", "ge\u00b7gr\u00fcn\u00b7de\u00b7te", "Ge\u00b7b\u00e4u\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das St\u00fcrmen und Jahrhunderten getrotzt,", "tokens": ["Das", "St\u00fcr\u00b7men", "und", "Jahr\u00b7hun\u00b7der\u00b7ten", "ge\u00b7trotzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das sich unendlich, unabsehlich leitet", "tokens": ["Das", "sich", "un\u00b7end\u00b7lich", ",", "un\u00b7ab\u00b7seh\u00b7lich", "lei\u00b7tet"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "PRF", "ADJD", "$,", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Tausende beschirmt, die gro\u00dfe Mauer ists,", "tokens": ["Und", "Tau\u00b7sen\u00b7de", "be\u00b7schirmt", ",", "die", "gro\u00b7\u00dfe", "Mau\u00b7er", "ists", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "$,", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die China von der Tartarw\u00fcste scheidet.", "tokens": ["Die", "Chi\u00b7na", "von", "der", "Tar\u00b7tar\u00b7w\u00fcs\u00b7te", "schei\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}