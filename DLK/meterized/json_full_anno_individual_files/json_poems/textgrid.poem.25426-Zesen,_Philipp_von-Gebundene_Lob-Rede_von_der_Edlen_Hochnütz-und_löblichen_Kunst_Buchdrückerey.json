{"textgrid.poem.25426": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "Gebundene Lob-Rede von der Edlen/ Hochn\u00fctz-und l\u00f6blichen Kunst Buchdr\u00fcckerey", "genre": "verse", "period": "N.A.", "pub_year": 1654, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich der ich fl\u00fcgen lie\u00df vor zweyen Jahres-Zeiten", "tokens": ["Ich", "der", "ich", "fl\u00fc\u00b7gen", "lie\u00df", "vor", "zwe\u00b7yen", "Jah\u00b7res\u00b7Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "PPER", "VVINF", "VVFIN", "APPR", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Feder in dein Lob und r\u00fchmte dich von weiten/", "tokens": ["Die", "Fe\u00b7der", "in", "dein", "Lob", "und", "r\u00fchm\u00b7te", "dich", "von", "wei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du edle Dr\u00fccker-Kunst/ bin itzund auch bedacht/", "tokens": ["Du", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "bin", "it\u00b7zund", "auch", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie doch dein ursprung nur werd' offenbahr gemacht:", "tokens": ["Wie", "doch", "dein", "ur\u00b7sprung", "nur", "werd'", "of\u00b7fen\u00b7bahr", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "ADV", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wil durch diesen Mund die bl\u00f6den Menschen lehren/", "tokens": ["Ich", "wil", "durch", "die\u00b7sen", "Mund", "die", "bl\u00f6\u00b7den", "Men\u00b7schen", "leh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PDAT", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die noch nicht Menschen sind/ wie sie dich sollen ehren;", "tokens": ["Die", "noch", "nicht", "Men\u00b7schen", "sind", "/", "wie", "sie", "dich", "sol\u00b7len", "eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "NN", "VAFIN", "$(", "PWAV", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch diesen meinen Mund der sich was schwach befindt/", "tokens": ["Durch", "die\u00b7sen", "mei\u00b7nen", "Mund", "der", "sich", "was", "schwach", "be\u00b7findt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PPOSAT", "NN", "ART", "PRF", "PWS", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dr\u00fcm/ Clio/ ruff' ich dier/ du sch\u00f6nes Musen-Kind/", "tokens": ["Dr\u00fcm", "/", "Clio", "/", "ruff'", "ich", "dier", "/", "du", "sch\u00f6\u00b7nes", "Mu\u00b7sen\u00b7Kind", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "VVFIN", "PPER", "PPER", "$(", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Komm/ komm und hilff mir auff; flicht aus die g\u00fcldnen Z\u00f6pffe/", "tokens": ["Komm", "/", "komm", "und", "hilff", "mir", "auff", ";", "flicht", "aus", "die", "g\u00fcld\u00b7nen", "Z\u00f6pf\u00b7fe", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "KON", "NN", "PPER", "PTKVZ", "$.", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df Zephyr spielen mag und ich die Kr\u00e4ffte sch\u00f6pffe;", "tokens": ["Da\u00df", "Ze\u00b7phyr", "spie\u00b7len", "mag", "und", "ich", "die", "Kr\u00e4ff\u00b7te", "sch\u00f6pf\u00b7fe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "VMFIN", "KON", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wenn er von dier auff mich den feuchten Nectar weht/", "tokens": ["Wenn", "er", "von", "dier", "auff", "mich", "den", "feuch\u00b7ten", "Nec\u00b7tar", "weht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So wei\u00df ich da\u00df es mier gew\u00fcndscht von statten geht.", "tokens": ["So", "wei\u00df", "ich", "da\u00df", "es", "mier", "ge\u00b7w\u00fcnd\u00b7scht", "von", "stat\u00b7ten", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PPER", "PPER", "VVPP", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Komm balde/ denn ich wil von solchen Sachen reden/", "tokens": ["Komm", "bal\u00b7de", "/", "denn", "ich", "wil", "von", "sol\u00b7chen", "Sa\u00b7chen", "re\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "KON", "PPER", "VMFIN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die h\u00f6her seyn als hoch; nicht wie uns Arme Bl\u00f6den", "tokens": ["Die", "h\u00f6\u00b7her", "seyn", "als", "hoch", ";", "nicht", "wie", "uns", "Ar\u00b7me", "Bl\u00f6\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VAINF", "KOKOM", "ADJD", "$.", "PTKNEG", "PWAV", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der kleine Hertzen-Sch\u00fctz aus Paphos f\u00e4llen kann;", "tokens": ["Der", "klei\u00b7ne", "Hert\u00b7zen\u00b7Sch\u00fctz", "aus", "Pa\u00b7phos", "f\u00e4l\u00b7len", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Nicht wie Callicrates der Kunst-erfahrne Mann", "tokens": ["Nicht", "wie", "Cal\u00b7li\u00b7cra\u00b7tes", "der", "Kunst\u00b7er\u00b7fahr\u00b7ne", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "KOKOM", "NE", "ART", "NN", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "Sein Wunder-schiff gemacht; Wil nicht den Ruhm erlangen", "tokens": ["Sein", "Wun\u00b7der\u00b7schiff", "ge\u00b7macht", ";", "Wil", "nicht", "den", "Ruhm", "er\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP", "$.", "VMFIN", "PTKNEG", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Venus Bild/ das einst Apelles angefangen/", "tokens": ["Der", "Ve\u00b7nus", "Bild", "/", "das", "einst", "A\u00b7pel\u00b7les", "an\u00b7ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "PDS", "ADV", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Nach ihm zu mahlen aus; Es soll Hymettus nicht/", "tokens": ["Nach", "ihm", "zu", "mah\u00b7len", "aus", ";", "Es", "soll", "Hy\u00b7met\u00b7tus", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "PTKVZ", "$.", "PPER", "VMFIN", "NE", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Noch seine sch\u00f6nste Lust hier werden mein Gedicht;", "tokens": ["Noch", "sei\u00b7ne", "sch\u00f6ns\u00b7te", "Lust", "hier", "wer\u00b7den", "mein", "Ge\u00b7dicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zumahl weil Maro sie mit seiner scharffen Zungen", "tokens": ["Zu\u00b7mahl", "weil", "Ma\u00b7ro", "sie", "mit", "sei\u00b7ner", "scharf\u00b7fen", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NE", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "An Minces ufer schon hat zweymahl hergesungen:", "tokens": ["An", "Min\u00b7ces", "u\u00b7fer", "schon", "hat", "zwey\u00b7mahl", "her\u00b7ge\u00b7sun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ich wil auch sagen nicht von Cocos aus Zebuth/", "tokens": ["Ich", "wil", "auch", "sa\u00b7gen", "nicht", "von", "Co\u00b7cos", "aus", "Ze\u00b7buth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "PTKNEG", "APPR", "NE", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dem Wunder-Baum und Stamm/ von dem man Rebenblut/", "tokens": ["Dem", "Wun\u00b7der\u00b7Baum", "und", "Stamm", "/", "von", "dem", "man", "Re\u00b7ben\u00b7blut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$(", "APPR", "PRELS", "PIS", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Oehl/ Butter/ Linnewand und Essig kan geniessen/", "tokens": ["O\u00b7ehl", "/", "But\u00b7ter", "/", "Lin\u00b7ne\u00b7wand", "und", "Es\u00b7sig", "kan", "ge\u00b7nies\u00b7sen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NE", "KON", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.26": {"text": "Ja Zucker noch dazu: Auch wil ich nicht vergiessen", "tokens": ["Ja", "Zu\u00b7cker", "noch", "da\u00b7zu", ":", "Auch", "wil", "ich", "nicht", "ver\u00b7gies\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "NN", "ADV", "PAV", "$.", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die Thr\u00e4nen \u00fcber dich/ du edles Vater-Land/", "tokens": ["Die", "Thr\u00e4\u00b7nen", "\u00fc\u00b7ber", "dich", "/", "du", "ed\u00b7les", "Va\u00b7ter\u00b7Land", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Das von sich selbsten itzt fast nicht mehr wird erkant/", "tokens": ["Das", "von", "sich", "selbs\u00b7ten", "itzt", "fast", "nicht", "mehr", "wird", "er\u00b7kant", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PRF", "VVFIN", "ADV", "ADV", "PTKNEG", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So als es \u00f6de steht. Di\u00df alles bleibt verschwiegen", "tokens": ["So", "als", "es", "\u00f6\u00b7de", "steht", ".", "Di\u00df", "al\u00b7les", "bleibt", "ver\u00b7schwie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVFIN", "$.", "PDS", "PIS", "VVFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Von mir auff dieses mahl; Ich la\u00dfe mir gen\u00fcgen/", "tokens": ["Von", "mir", "auff", "die\u00b7ses", "mahl", ";", "Ich", "la\u00b7\u00dfe", "mir", "ge\u00b7n\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "PDAT", "ADV", "$.", "PPER", "VVFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wenn ich nur reden mag nach Zierligkeit von Dier/", "tokens": ["Wenn", "ich", "nur", "re\u00b7den", "mag", "nach", "Zier\u00b7lig\u00b7keit", "von", "Dier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "APPR", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Du edle Dr\u00fccker-Kunst. Dr\u00fcm/ Clio/ meine Zier/", "tokens": ["Du", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", ".", "Dr\u00fcm", "/", "Clio", "/", "mei\u00b7ne", "Zier", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "NN", "$(", "NE", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.33": {"text": "Geruhe doch Entsatz und Worte zu zuschicken/", "tokens": ["Ge\u00b7ru\u00b7he", "doch", "Ent\u00b7satz", "und", "Wor\u00b7te", "zu", "zu\u00b7schi\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "KON", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wann mir der Mund besteht: Ach! la\u00df mich doch erblicken", "tokens": ["Wann", "mir", "der", "Mund", "be\u00b7steht", ":", "Ach", "!", "la\u00df", "mich", "doch", "er\u00b7bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$.", "ITJ", "$.", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Dein G\u00f6ttlich Angesicht; Dier fleh ich noch einmahl", "tokens": ["Dein", "G\u00f6tt\u00b7lich", "An\u00b7ge\u00b7sicht", ";", "Dier", "fleh", "ich", "noch", "ein\u00b7mahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "$.", "PDS", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Gib/ da\u00df ich zieren mag mit Reden diesen Saal.", "tokens": ["Gib", "/", "da\u00df", "ich", "zie\u00b7ren", "mag", "mit", "Re\u00b7den", "die\u00b7sen", "Saal", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$(", "KOUS", "PPER", "VVINF", "VMFIN", "APPR", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Komt auch und h\u00f6rt mir zu/ Ihr tr\u00e4fflichen Elbinnen/", "tokens": ["Komt", "auch", "und", "h\u00f6rt", "mir", "zu", "/", "Ihr", "tr\u00e4ff\u00b7li\u00b7chen", "El\u00b7bin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "PPER", "PTKZU", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Komm Hamburg/ komm heran und h\u00f6re mein Beginnen/", "tokens": ["Komm", "Ham\u00b7burg", "/", "komm", "he\u00b7ran", "und", "h\u00f6\u00b7re", "mein", "Be\u00b7gin\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "La\u00df deine Schiffe stehn am blancken Elben-Stroom/", "tokens": ["La\u00df", "dei\u00b7ne", "Schif\u00b7fe", "stehn", "am", "blan\u00b7cken", "El\u00b7ben\u00b7Stroom", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "VVFIN", "APPRART", "ADJA", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "So lange/ bi\u00df ich das/ was noch Athen und Room/", "tokens": ["So", "lan\u00b7ge", "/", "bi\u00df", "ich", "das", "/", "was", "noch", "A\u00b7then", "und", "Room", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "KOUS", "PPER", "ART", "$(", "PWS", "ADV", "NE", "KON", "NE", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.41": {"text": "Wie hoch sie fl\u00fcgen/ trotzt/ urspr\u00fcnglich dier entdecket/", "tokens": ["Wie", "hoch", "sie", "fl\u00fc\u00b7gen", "/", "trotzt", "/", "ur\u00b7spr\u00fcng\u00b7lich", "dier", "ent\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVINF", "$(", "VVFIN", "$(", "ADJD", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Die edle Dr\u00fccker-Kunst/ vor der der Pabst erschrecket", "tokens": ["Die", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "vor", "der", "der", "Pabst", "er\u00b7schre\u00b7cket"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "APPR", "ART", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Auff seiner Siebenburg: La\u00dft eurer Presse Ruh/", "tokens": ["Auff", "sei\u00b7ner", "Sie\u00b7ben\u00b7burg", ":", "La\u00dft", "eu\u00b7rer", "Pres\u00b7se", "Ruh", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "VVIMP", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Ihr edlen Drucker Ihr und h\u00f6rt ein wenig zu/", "tokens": ["Ihr", "ed\u00b7len", "Dru\u00b7cker", "Ihr", "und", "h\u00f6rt", "ein", "we\u00b7nig", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "KON", "VVFIN", "ART", "PIS", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Merckt/ merckt auff meine Wort/ weil ich vornemlich preise:", "tokens": ["Merckt", "/", "merckt", "auff", "mei\u00b7ne", "Wort", "/", "weil", "ich", "vor\u00b7nem\u00b7lich", "prei\u00b7se", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Die G\u00f6tter-gleiche Kunst und ihren Ursprung weise;", "tokens": ["Die", "G\u00f6t\u00b7ter\u00b7glei\u00b7che", "Kunst", "und", "ih\u00b7ren", "Ur\u00b7sprung", "wei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Die euch zu Ehren setzt/ die euch ber\u00fchmet macht/", "tokens": ["Die", "euch", "zu", "Eh\u00b7ren", "setzt", "/", "die", "euch", "be\u00b7r\u00fch\u00b7met", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$(", "PRELS", "PPER", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Die alle K\u00fcnstler trotzt und reisst hin aus der Nacht", "tokens": ["Die", "al\u00b7le", "K\u00fcnst\u00b7ler", "trotzt", "und", "reisst", "hin", "aus", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVFIN", "KON", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Zur grauen Ewigkeit. Di\u00df Lob la\u00dft euch gefallen/", "tokens": ["Zur", "grau\u00b7en", "E\u00b7wig\u00b7keit", ".", "Di\u00df", "Lob", "la\u00dft", "euch", "ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$.", "PDS", "NN", "VVFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Das durch das Deutsche Reich anitzo wird erschallen/", "tokens": ["Das", "durch", "das", "Deut\u00b7sche", "Reich", "a\u00b7nit\u00b7zo", "wird", "er\u00b7schal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "ADV", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "und das \u00fcm desto mehr/ weil keiner di\u00df gethan", "tokens": ["und", "das", "\u00fcm", "des\u00b7to", "mehr", "/", "weil", "kei\u00b7ner", "di\u00df", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "ADV", "$(", "KOUS", "PIS", "PDS", "VVPP"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.52": {"text": "Vor mir in dieser Stadt/ merckt auff/ nun fang' ich an.", "tokens": ["Vor", "mir", "in", "die\u00b7ser", "Stadt", "/", "merckt", "auff", "/", "nun", "fang'", "ich", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "PDAT", "NN", "$(", "VVFIN", "APPR", "$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Als vierzehn hundert Jahr und viertzig war verflossen", "tokens": ["Als", "vier\u00b7zehn", "hun\u00b7dert", "Jahr", "und", "viert\u00b7zig", "war", "ver\u00b7flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "CARD", "CARD", "NN", "KON", "CARD", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Nach unser Christ-Geburt/ war Gott der Herr entschlossen", "tokens": ["Nach", "un\u00b7ser", "Christ\u00b7Ge\u00b7burt", "/", "war", "Gott", "der", "Herr", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NE", "$(", "VAFIN", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Sein Wort zu breiten aus: Es war fast auff der Bahn/", "tokens": ["Sein", "Wort", "zu", "brei\u00b7ten", "aus", ":", "Es", "war", "fast", "auff", "der", "Bahn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Den Hu\u00df im Geiste sah/ der theure Wunder-Schwaan.", "tokens": ["Den", "Hu\u00df", "im", "Geis\u00b7te", "sah", "/", "der", "theu\u00b7re", "Wun\u00b7der\u00b7Schwaan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Der Keyser Albrecht starb der Ander so genennet/", "tokens": ["Der", "Key\u00b7ser", "Al\u00b7brecht", "starb", "der", "An\u00b7der", "so", "ge\u00b7nen\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Drauff Friederich der Dritt' als Keyser ward erkennet;", "tokens": ["Drauff", "Frie\u00b7de\u00b7rich", "der", "Dritt'", "als", "Key\u00b7ser", "ward", "er\u00b7ken\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "ART", "NN", "KOUS", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Im ebenselben Jahr ward uns die Dr\u00fcckerey", "tokens": ["Im", "e\u00b7ben\u00b7sel\u00b7ben", "Jahr", "ward", "uns", "die", "Dr\u00fc\u00b7cke\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Von Gott geschenckt/ da\u00df sie der K\u00fcnste Mutter sey.", "tokens": ["Von", "Gott", "ge\u00b7schenckt", "/", "da\u00df", "sie", "der", "K\u00fcns\u00b7te", "Mut\u00b7ter", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$(", "KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "O F\u00fcrstin aller Kunst/ Du aller Lehrer Amme/", "tokens": ["O", "F\u00fcrs\u00b7tin", "al\u00b7ler", "Kunst", "/", "Du", "al\u00b7ler", "Leh\u00b7rer", "Am\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PIAT", "NN", "$(", "PPER", "PIAT", "NN", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Durch dich hat Gott gezeigt im Dunckeln seine Flamme/", "tokens": ["Durch", "dich", "hat", "Gott", "ge\u00b7zeigt", "im", "Dun\u00b7ckeln", "sei\u00b7ne", "Flam\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "NN", "VVPP", "APPRART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Die Fackel seines Worts. Wer hat dich dann erdacht?", "tokens": ["Die", "Fa\u00b7ckel", "sei\u00b7nes", "Worts", ".", "Wer", "hat", "dich", "dann", "er\u00b7dacht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Wer hat ein solches Werck mit kluger Hand gemacht?", "tokens": ["Wer", "hat", "ein", "sol\u00b7ches", "Werck", "mit", "klu\u00b7ger", "Hand", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "PIAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Und wo ist das geschehn? Ists Phidias gewesen", "tokens": ["Und", "wo", "ist", "das", "ge\u00b7schehn", "?", "Ists", "Phi\u00b7di\u00b7as", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "VAFIN", "PDS", "VVINF", "$.", "NE", "NE", "VAPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Der K\u00fcnstler von Athen? von dem man noch kan lesen/", "tokens": ["Der", "K\u00fcnst\u00b7ler", "von", "A\u00b7then", "?", "von", "dem", "man", "noch", "kan", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$.", "APPR", "PRELS", "PIS", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.67": {"text": "Da\u00df er Minerven Bild neun Klafftern hoch gemacht", "tokens": ["Da\u00df", "er", "Mi\u00b7ner\u00b7ven", "Bild", "neun", "Klaff\u00b7tern", "hoch", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "NN", "CARD", "NN", "ADJD", "VVPP"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.68": {"text": "Au\u00df Gold und Helffenbein und in das Schild die Schlacht", "tokens": ["Au\u00df", "Gold", "und", "Helf\u00b7fen\u00b7bein", "und", "in", "das", "Schild", "die", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Der Amazonen grub? Sol man es dier zumessen/", "tokens": ["Der", "A\u00b7maz\u00b7o\u00b7nen", "grub", "?", "Sol", "man", "es", "dier", "zu\u00b7mes\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VMFIN", "PIS", "PPER", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Lysippus/ weil nur dir dein K\u00f6nig ist gesessen", "tokens": ["Ly\u00b7sip\u00b7pus", "/", "weil", "nur", "dir", "dein", "K\u00f6\u00b7nig", "ist", "ge\u00b7ses\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "KOUS", "ADV", "PPER", "PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Sein Bild zu bilden ab? Praxiteles vielleicht/", "tokens": ["Sein", "Bild", "zu", "bil\u00b7den", "ab", "?", "Pra\u00b7xi\u00b7te\u00b7les", "viel\u00b7leicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "PTKVZ", "$.", "NE", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "In dessen Venus sich/ dem keines sonsten gleicht/", "tokens": ["In", "des\u00b7sen", "Ve\u00b7nus", "sich", "/", "dem", "kei\u00b7nes", "sons\u00b7ten", "gleicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PRF", "$(", "ART", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Ein J\u00fcngling hat verliebt? Hats Daedalus erfunden?", "tokens": ["Ein", "J\u00fcng\u00b7ling", "hat", "ver\u00b7liebt", "?", "Hats", "Dae\u00b7da\u00b7lus", "er\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "NE", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Der sonst das Labyrinth zur ungl\u00fcckhafften Stunden", "tokens": ["Der", "sonst", "das", "La\u00b7by\u00b7rinth", "zur", "un\u00b7gl\u00fcck\u00b7haff\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Ihm selbst und seinem Sohn' in Creta hat gemacht/", "tokens": ["Ihm", "selbst", "und", "sei\u00b7nem", "Sohn'", "in", "Cre\u00b7ta", "hat", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "PPOSAT", "NN", "APPR", "NE", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Daraus er wieder\u00fcm mit Fl\u00fcgeln ward gebracht/", "tokens": ["Da\u00b7raus", "er", "wie\u00b7de\u00b7r\u00fcm", "mit", "Fl\u00fc\u00b7geln", "ward", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Die Kunst ihm angesetzt? Hastu es dann ersonnen/", "tokens": ["Die", "Kunst", "ihm", "an\u00b7ge\u00b7setzt", "?", "Has\u00b7tu", "es", "dann", "er\u00b7son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "$.", "NE", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Perillus? oder wie? hat sich von dir entsponnen/", "tokens": ["Pe\u00b7ril\u00b7lus", "?", "o\u00b7der", "wie", "?", "hat", "sich", "von", "dir", "ent\u00b7spon\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KON", "PWAV", "$.", "VAFIN", "PRF", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.79": {"text": "Epeus/ diese Kunst? Ists Alcman ein Poet/", "tokens": ["E\u00b7peus", "/", "die\u00b7se", "Kunst", "?", "Ists", "A\u00b7lcman", "ein", "Po\u00b7et", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PDAT", "NN", "$.", "NE", "NE", "ART", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.80": {"text": "Der erste/ der ein Lied von Liebes-Lust anf\u00e4ht?", "tokens": ["Der", "ers\u00b7te", "/", "der", "ein", "Lied", "von", "Lie\u00b7bes\u00b7Lust", "an\u00b7f\u00e4ht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ART", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Dem man so emsig folgt? Sol Palamedes lehren", "tokens": ["Dem", "man", "so", "em\u00b7sig", "folgt", "?", "Sol", "Pa\u00b7la\u00b7me\u00b7des", "leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "ADJD", "VVFIN", "$.", "VMFIN", "NN", "VVINF"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.82": {"text": "Die sch\u00f6ne Dr\u00fccker-Kunst/ von dem wir sehn und h\u00f6ren/", "tokens": ["Die", "sch\u00f6\u00b7ne", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "von", "dem", "wir", "sehn", "und", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "APPR", "PRELS", "PPER", "VVINF", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Da\u00df er das Abece geordnet auff ein Schild?", "tokens": ["Da\u00df", "er", "das", "A\u00b7be\u00b7ce", "ge\u00b7ord\u00b7net", "auff", "ein", "Schild", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Ists dann Pyrgoteles/ der Alexanders Bild", "tokens": ["Ists", "dann", "Pyr\u00b7go\u00b7te\u00b7les", "/", "der", "A\u00b7lex\u00b7an\u00b7ders", "Bild"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NE", "$(", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "In Perlen graben mag? Nein/ nein! hier ist es keiner/", "tokens": ["In", "Per\u00b7len", "gra\u00b7ben", "mag", "?", "Nein", "/", "nein", "!", "hier", "ist", "es", "kei\u00b7ner", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VMFIN", "$.", "PTKANT", "$(", "PTKANT", "$.", "ADV", "VAFIN", "PPER", "PIS", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Die Deutschen \u00fcbergehn die Griechen und Lateiner.", "tokens": ["Die", "Deut\u00b7schen", "\u00fc\u00b7ber\u00b7gehn", "die", "Grie\u00b7chen", "und", "La\u00b7tei\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Schweig/ Anagallis/ still/ die du dein Ebenbild/", "tokens": ["Schweig", "/", "A\u00b7na\u00b7gal\u00b7lis", "/", "still", "/", "die", "du", "dein", "E\u00b7ben\u00b7bild", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "ADJD", "$(", "PRELS", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Das Ballen-Spiel erdacht: Ertichte was du wilt/", "tokens": ["Das", "Bal\u00b7len\u00b7Spiel", "er\u00b7dacht", ":", "Er\u00b7tich\u00b7te", "was", "du", "wilt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "VVFIN", "PWS", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Du frische Thymele; Den Deutschen m\u00fcsst ihr weichen", "tokens": ["Du", "fri\u00b7sche", "Thy\u00b7me\u00b7le", ";", "Den", "Deut\u00b7schen", "m\u00fcsst", "ihr", "wei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$.", "ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Ihr K\u00fcnstler von Athen/ Ihr Griechen m\u00fcsst verbleichen;", "tokens": ["Ihr", "K\u00fcnst\u00b7ler", "von", "A\u00b7then", "/", "Ihr", "Grie\u00b7chen", "m\u00fcsst", "ver\u00b7blei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "$(", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.91": {"text": "Du gro\u00dfes China du/ du r\u00fchmest dich \u00fcmsunst/", "tokens": ["Du", "gro\u00b7\u00dfes", "Chi\u00b7na", "du", "/", "du", "r\u00fch\u00b7mest", "dich", "\u00fcm\u00b7sunst", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NE", "NE", "$(", "PPER", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Auch hast du/ Franckreich/ nicht erfunden diese Kunst.", "tokens": ["Auch", "hast", "du", "/", "Fran\u00b7ck\u00b7reich", "/", "nicht", "er\u00b7fun\u00b7den", "die\u00b7se", "Kunst", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "NE", "$(", "PTKNEG", "VVPP", "PDAT", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.93": {"text": "Ihr Niederl\u00e4nder ihr la\u00dft euer Harlem schweigen/", "tokens": ["Ihr", "Nie\u00b7der\u00b7l\u00e4n\u00b7der", "ihr", "la\u00dft", "eu\u00b7er", "Har\u00b7lem", "schwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Auch Welschland kan uns nicht den urerfinder zeigen.", "tokens": ["Auch", "Wel\u00b7schland", "kan", "uns", "nicht", "den", "ur\u00b7er\u00b7fin\u00b7der", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "PPER", "PTKNEG", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Kommt/ nehmt uns dieses Lob: Johannes Guttenberg/", "tokens": ["Kommt", "/", "nehmt", "uns", "die\u00b7ses", "Lob", ":", "Jo\u00b7han\u00b7nes", "Gut\u00b7ten\u00b7berg", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "PPER", "PDAT", "NN", "$.", "NE", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Ein Mann von edlem Stamm bringt auff das Drucker-Werck/", "tokens": ["Ein", "Mann", "von", "ed\u00b7lem", "Stamm", "bringt", "auff", "das", "Dru\u00b7cke\u00b7r\u00b7Werck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.97": {"text": "Zu Meyntz im Deutschen Reich; Er hilft mit scharffen Sinnen", "tokens": ["Zu", "Meyntz", "im", "Deut\u00b7schen", "Reich", ";", "Er", "hilft", "mit", "scharf\u00b7fen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPRART", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Was Peter Sch\u00f6fer hier und Faust zu erst beginnen;", "tokens": ["Was", "Pe\u00b7ter", "Sch\u00f6\u00b7fer", "hier", "und", "Faust", "zu", "erst", "be\u00b7gin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NE", "ADV", "KON", "NN", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Was sonst Hans M\u00e4ntelin zu Stra\u00dfburg hat erdacht", "tokens": ["Was", "sonst", "Hans", "M\u00e4n\u00b7te\u00b7lin", "zu", "Stra\u00df\u00b7burg", "hat", "er\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "NE", "NE", "APPR", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "und (wie man wil) von dar Hans Gense-Fleisch gebracht", "tokens": ["und", "(", "wie", "man", "wil", ")", "von", "dar", "Hans", "Gen\u00b7se\u00b7Fleisch", "ge\u00b7bracht"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "PWAV", "PIS", "VMFIN", "$(", "APPR", "NE", "NE", "NE", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "An vorermeldten Ort/ Den billich wir erkennen", "tokens": ["An", "vor\u00b7er\u00b7meld\u00b7ten", "Ort", "/", "Den", "bil\u00b7lich", "wir", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$(", "ART", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Vor unsre Schreiber-Stadt und Kirjath-Sepher nennen/", "tokens": ["Vor", "uns\u00b7re", "Schrei\u00b7ber\u00b7Stadt", "und", "Kir\u00b7ja\u00b7th\u00b7Se\u00b7pher", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+--", "measure": "unknown.measure.hexa"}, "line.103": {"text": "Weil da der erste Pfeil aus Dinten ward gemacht/", "tokens": ["Weil", "da", "der", "ers\u00b7te", "Pfeil", "aus", "Din\u00b7ten", "ward", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Weil Sie die Dr\u00fccker-Kunst zum ersten ausgebracht/", "tokens": ["Weil", "Sie", "die", "Dr\u00fc\u00b7cker\u00b7Kunst", "zum", "ers\u00b7ten", "aus\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Da\u00df sie nunmehr bey uns so sch\u00f6n und herrlich bl\u00fchet;", "tokens": ["Da\u00df", "sie", "nun\u00b7mehr", "bey", "uns", "so", "sch\u00f6n", "und", "herr\u00b7lich", "bl\u00fc\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Da Guttenberg sich erst so trefflich hat bem\u00fchet;", "tokens": ["Da", "Gut\u00b7ten\u00b7berg", "sich", "erst", "so", "treff\u00b7lich", "hat", "be\u00b7m\u00fc\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "ADV", "ADV", "ADJD", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Er macht' erst breite Schrifft und bracht es auch so weit/", "tokens": ["Er", "macht'", "erst", "brei\u00b7te", "Schrifft", "und", "bracht", "es", "auch", "so", "weit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "KON", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Da\u00df mit Verwunderung man drauff in kurtzer Zeit", "tokens": ["Da\u00df", "mit", "Ver\u00b7wun\u00b7de\u00b7rung", "man", "drauff", "in", "kurt\u00b7zer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "PIS", "PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Gedruckte Schrifften la\u00df. Nun werden tausend Bogen", "tokens": ["Ge\u00b7druck\u00b7te", "Schriff\u00b7ten", "la\u00df", ".", "Nun", "wer\u00b7den", "tau\u00b7send", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "PTKVZ", "$.", "ADV", "VAFIN", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "In einer Tages-Frist auch eher abgezogen/", "tokens": ["In", "ei\u00b7ner", "Ta\u00b7ges\u00b7Frist", "auch", "e\u00b7her", "ab\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Wenn nur die Schrifft gesetzt. Ging deine Schreiberey", "tokens": ["Wenn", "nur", "die", "Schrifft", "ge\u00b7setzt", ".", "Ging", "dei\u00b7ne", "Schrei\u00b7be\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "VVPP", "$.", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Athen und Room so fort? da du in Wachs und Bley", "tokens": ["A\u00b7then", "und", "Room", "so", "fort", "?", "da", "du", "in", "Wachs", "und", "Bley"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NE", "ADV", "PTKVZ", "$.", "KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.113": {"text": "Annoch die Zeit verderbt? Gings auch so wol von statten/", "tokens": ["An\u00b7noch", "die", "Zeit", "ver\u00b7derbt", "?", "Gings", "auch", "so", "wol", "von", "stat\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$.", "NE", "ADV", "ADV", "ADV", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Ihr Alten/ wann ihr schriebt/ was euch gelehret hatten", "tokens": ["Ihr", "Al\u00b7ten", "/", "wann", "ihr", "schriebt", "/", "was", "euch", "ge\u00b7leh\u00b7ret", "hat\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PWAV", "PPER", "VVFIN", "$(", "PWS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Die Weisen von Athen? was Cicero/ Lucan/", "tokens": ["Die", "Wei\u00b7sen", "von", "A\u00b7then", "?", "was", "Ci\u00b7ce\u00b7ro", "/", "Lu\u00b7can", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$.", "PWS", "NN", "$(", "NE", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.116": {"text": "Was Aristoteles/ der Mantuaner Schwan", "tokens": ["Was", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "/", "der", "Man\u00b7tu\u00b7a\u00b7ner", "Schwan"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NE", "$(", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "und der von Sulm euch lehrt? O nein! ihr stoltzen Griechen/", "tokens": ["und", "der", "von", "Sulm", "euch", "lehrt", "?", "O", "nein", "!", "ihr", "stolt\u00b7zen", "Grie\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NE", "PPER", "VVFIN", "$.", "NE", "PTKANT", "$.", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Wie weis' ihr immer seyd/ nun m\u00f6cht ihr euch verkriechen:", "tokens": ["Wie", "weis'", "ihr", "im\u00b7mer", "seyd", "/", "nun", "m\u00f6cht", "ihr", "euch", "ver\u00b7krie\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "VAFIN", "$(", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Seht/ seht der Deutsche schreibt so viel auff einen Tag/", "tokens": ["Seht", "/", "seht", "der", "Deut\u00b7sche", "schreibt", "so", "viel", "auff", "ei\u00b7nen", "Tag", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Als einer unter euch im Jahre schreiben mag.", "tokens": ["Als", "ei\u00b7ner", "un\u00b7ter", "euch", "im", "Jah\u00b7re", "schrei\u00b7ben", "mag."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "ART", "APPR", "PPER", "APPRART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.121": {"text": "Wie elend war es nur: Ihr schriebt auff Wachs und Rinden/", "tokens": ["Wie", "e\u00b7lend", "war", "es", "nur", ":", "Ihr", "schriebt", "auff", "Wachs", "und", "Rin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Bis endlich einer kam und wies' euch armen Blinden", "tokens": ["Bis", "end\u00b7lich", "ei\u00b7ner", "kam", "und", "wies'", "euch", "ar\u00b7men", "Blin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIS", "VVFIN", "KON", "VVFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Papier und Pergamen. Der Reiche kont' allein", "tokens": ["Pa\u00b7pier", "und", "Per\u00b7ga\u00b7men", ".", "Der", "Rei\u00b7che", "kont'", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$.", "ART", "NE", "VMFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Was lernen dazumahl und B\u00fccher kauffen ein", "tokens": ["Was", "ler\u00b7nen", "da\u00b7zu\u00b7mahl", "und", "B\u00fc\u00b7cher", "kauf\u00b7fen", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "KON", "NN", "VVFIN", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "\u00fcm einen solchen Werth; Wer solt' itzt wol bezahlen/", "tokens": ["\u00fcm", "ei\u00b7nen", "sol\u00b7chen", "Werth", ";", "Wer", "solt'", "itzt", "wol", "be\u00b7zah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIAT", "NN", "$.", "PWS", "VMFIN", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Dier Triphon deinen Kraam/ nun darffstu nicht mehr pralen", "tokens": ["Dier", "Tri\u00b7phon", "dei\u00b7nen", "Kraam", "/", "nun", "darffs\u00b7tu", "nicht", "mehr", "pra\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "PPOSAT", "NN", "$(", "ADV", "PAV", "PTKNEG", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Du gro\u00dfer Gordian/ du Tullius und Du", "tokens": ["Du", "gro\u00b7\u00dfer", "Gor\u00b7di\u00b7an", "/", "du", "Tul\u00b7li\u00b7us", "und", "Du"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NE", "$(", "PPER", "NN", "KON", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Tyrannion schleu\u00df nur die B\u00fccher-Schr\u00e4ncke zu.", "tokens": ["Ty\u00b7ran\u00b7ni\u00b7on", "schleu\u00df", "nur", "die", "B\u00fc\u00b7cher\u00b7Schr\u00e4n\u00b7cke", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Was war zu Heidelberg? wie viel geschriebne Sachen/", "tokens": ["Was", "war", "zu", "Hei\u00b7del\u00b7berg", "?", "wie", "viel", "ge\u00b7schrieb\u00b7ne", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "NE", "$.", "PWAV", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Was B\u00fccher waren da? die manchen traurig machen", "tokens": ["Was", "B\u00fc\u00b7cher", "wa\u00b7ren", "da", "?", "die", "man\u00b7chen", "trau\u00b7rig", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "NN", "VAFIN", "ADV", "$.", "ART", "PIAT", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Durch ihren untergang? der Wald der Wei\u00dfheit weicht", "tokens": ["Durch", "ih\u00b7ren", "un\u00b7ter\u00b7gang", "?", "der", "Wald", "der", "Wei\u00df\u00b7heit", "weicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "In Constantinus Stadt: Alphonsus auch verbleicht.", "tokens": ["In", "Con\u00b7stan\u00b7ti\u00b7nus", "Stadt", ":", "Al\u00b7phon\u00b7sus", "auch", "ver\u00b7bleicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$.", "NE", "ADV", "VVPP", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.133": {"text": "Der Deutsche zeigt itzt mehr durch sein so sch\u00f6nes Dr\u00fccken/", "tokens": ["Der", "Deut\u00b7sche", "zeigt", "itzt", "mehr", "durch", "sein", "so", "sch\u00f6\u00b7nes", "Dr\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Das ihm gegeben ward durch Gottes hohes Schicken;", "tokens": ["Das", "ihm", "ge\u00b7ge\u00b7ben", "ward", "durch", "Got\u00b7tes", "ho\u00b7hes", "Schi\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Die B\u00fccher werden mehr. Die edle Dr\u00fcckerey", "tokens": ["Die", "B\u00fc\u00b7cher", "wer\u00b7den", "mehr", ".", "Die", "ed\u00b7le", "Dr\u00fc\u00b7cke\u00b7rey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Geht nun durch alle Welt und steht den K\u00fcnsten bey.", "tokens": ["Geht", "nun", "durch", "al\u00b7le", "Welt", "und", "steht", "den", "K\u00fcns\u00b7ten", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PIAT", "NN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Room weis itzt auch davon/ dahin sie mit sich f\u00fchrte", "tokens": ["Room", "weis", "itzt", "auch", "da\u00b7von", "/", "da\u00b7hin", "sie", "mit", "sich", "f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "ADV", "ADV", "PAV", "$(", "PAV", "PPER", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Zum ersten Ulrich Hahn und ihren Nutzen sp\u00fcrte.", "tokens": ["Zum", "ers\u00b7ten", "Ul\u00b7rich", "Hahn", "und", "ih\u00b7ren", "Nut\u00b7zen", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "NE", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "In Franckreich hat zu erst Sixt R\u00fcssinger gedr\u00fcckt;", "tokens": ["In", "Fran\u00b7ck\u00b7reich", "hat", "zu", "erst", "Sixt", "R\u00fcs\u00b7sin\u00b7ger", "ge\u00b7dr\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "APPR", "ADV", "NE", "NE", "VVPP", "$."], "meter": "-+--+-+-++--+", "measure": "iambic.hexa.relaxed"}, "line.140": {"text": "Ist also diese Kunst in kurtzen fortger\u00fcckt.", "tokens": ["Ist", "al\u00b7so", "die\u00b7se", "Kunst", "in", "kurt\u00b7zen", "fort\u00b7ge\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "NN", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Viel F\u00fcrsten haben sie so sehr und hoch geliebet", "tokens": ["Viel", "F\u00fcrs\u00b7ten", "ha\u00b7ben", "sie", "so", "sehr", "und", "hoch", "ge\u00b7lie\u00b7bet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "KON", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "und diese sch\u00f6ne Kunst mit eigner Hand ge\u00fcbet:", "tokens": ["und", "die\u00b7se", "sch\u00f6\u00b7ne", "Kunst", "mit", "eig\u00b7ner", "Hand", "ge\u00b7\u00fc\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Es hat sie Friederich der Dritte so erh\u00f6ht/", "tokens": ["Es", "hat", "sie", "Frie\u00b7de\u00b7rich", "der", "Drit\u00b7te", "so", "er\u00b7h\u00f6ht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NE", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Da\u00df auch der Dr\u00fccker-Stand fast gleich dem Adel steht,", "tokens": ["Da\u00df", "auch", "der", "Dr\u00fc\u00b7cker\u00b7Stand", "fast", "gleich", "dem", "A\u00b7del", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Er l\u00e4sset ihnen zu vor andern Gold zu tragen/", "tokens": ["Er", "l\u00e4s\u00b7set", "ih\u00b7nen", "zu", "vor", "an\u00b7dern", "Gold", "zu", "tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKZU", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Begnadigt sie so sehr und setzt sie auff den Wagen", "tokens": ["Be\u00b7gna\u00b7digt", "sie", "so", "sehr", "und", "setzt", "sie", "auff", "den", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Des adlichen Triumffs/ wie irgend einen Held/", "tokens": ["Des", "ad\u00b7li\u00b7chen", "Tri\u00b7umffs", "/", "wie", "ir\u00b7gend", "ei\u00b7nen", "Held", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KOKOM", "ADV", "ART", "NN", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.148": {"text": "Der seinen starcken Feind mit Ehr und R\u00fchm gef\u00e4llt;", "tokens": ["Der", "sei\u00b7nen", "star\u00b7cken", "Feind", "mit", "Ehr", "und", "R\u00fchm", "ge\u00b7f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Gibt ihnen freye Macht den offnen Helm zu f\u00fchren/", "tokens": ["Gibt", "ih\u00b7nen", "frey\u00b7e", "Macht", "den", "off\u00b7nen", "Helm", "zu", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Ein Adler mu\u00df zur Pracht des Setzers Wapen zieren/", "tokens": ["Ein", "Ad\u00b7ler", "mu\u00df", "zur", "Pracht", "des", "Set\u00b7zers", "Wa\u00b7pen", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPRART", "NN", "ART", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Weil er sich schwingt empor/ nimmt Adlers-Fl\u00fcgel an", "tokens": ["Weil", "er", "sich", "schwingt", "em\u00b7por", "/", "nimmt", "Ad\u00b7ler\u00b7sF\u00b7l\u00fc\u00b7gel", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "PTKVZ", "$(", "VVFIN", "NN", "APPR"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.152": {"text": "und fleucht mit mancher Schrifft zur grauen Lebens-bahn", "tokens": ["und", "fleucht", "mit", "man\u00b7cher", "Schrifft", "zur", "grau\u00b7en", "Le\u00b7bens\u00b7bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Der Unverg\u00e4ngligkeit. Dem Drucker ist gegeben", "tokens": ["Der", "Un\u00b7ver\u00b7g\u00e4n\u00b7glig\u00b7keit", ".", "Dem", "Dru\u00b7cker", "ist", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Der nimmerschwache Greyff/ und dann ein Ball darneben/", "tokens": ["Der", "nim\u00b7mer\u00b7schwa\u00b7che", "Greyff", "/", "und", "dann", "ein", "Ball", "dar\u00b7ne\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "ADV", "ART", "NN", "PAV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Den er nach Druckers-Art in seinen Klauen f\u00fchrt", "tokens": ["Den", "er", "nach", "Dru\u00b7cker\u00b7sArt", "in", "sei\u00b7nen", "Klau\u00b7en", "f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "und so gantz adelich die Wapen-Felder ziert.", "tokens": ["und", "so", "gantz", "a\u00b7de\u00b7lich", "die", "Wa\u00b7pen\u00b7Fel\u00b7der", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "So wird ihr Stand verehrt. Sie werden von den Alten", "tokens": ["So", "wird", "ihr", "Stand", "ver\u00b7ehrt", ".", "Sie", "wer\u00b7den", "von", "den", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$.", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Wie von den Jungen auch sehr lieb und wehrt gehalten/", "tokens": ["Wie", "von", "den", "Jun\u00b7gen", "auch", "sehr", "lieb", "und", "wehrt", "ge\u00b7hal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Des Dr\u00fcckers Haus und Hoff ist frey in mancher Stadt", "tokens": ["Des", "Dr\u00fc\u00b7ckers", "Haus", "und", "Hoff", "ist", "frey", "in", "man\u00b7cher", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "VVFIN", "VAFIN", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Da\u00df mit gelehrten er offt gleiche Freyheit hat.", "tokens": ["Da\u00df", "mit", "ge\u00b7lehr\u00b7ten", "er", "offt", "glei\u00b7che", "Frey\u00b7heit", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "PPER", "ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Di\u00df hat das Heupt der Welt vor zweymahl hundert Jahren", "tokens": ["Di\u00df", "hat", "das", "Heupt", "der", "Welt", "vor", "zwey\u00b7mahl", "hun\u00b7dert", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "APPR", "ADV", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Aus lauter Gnad und Gunst euch la\u00dfen wiederfahren;", "tokens": ["Aus", "lau\u00b7ter", "Gnad", "und", "Gunst", "euch", "la\u00b7\u00dfen", "wie\u00b7der\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "PPER", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "F\u00fcrst Friedrich Wilhelm auch von Sachsen hielt euch werth/", "tokens": ["F\u00fcrst", "Fried\u00b7rich", "Wil\u00b7helm", "auch", "von", "Sach\u00b7sen", "hielt", "euch", "werth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "ADV", "APPR", "NE", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Ein' eigne Dr\u00fcckerey zu haben Er begehrt:", "tokens": ["Ein'", "eig\u00b7ne", "Dr\u00fc\u00b7cke\u00b7rey", "zu", "ha\u00b7ben", "Er", "be\u00b7gehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VAINF", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Nam Drucker auff sein Schlo\u00df/ lie\u00df sch\u00f6ne Schrifften giessen", "tokens": ["Nam", "Dru\u00b7cker", "auff", "sein", "Schlo\u00df", "/", "lie\u00df", "sch\u00f6\u00b7ne", "Schriff\u00b7ten", "gies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "PPOSAT", "NN", "$(", "VVFIN", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "und seine Gnad' und Gunst den Druckern auch geniessen.", "tokens": ["und", "sei\u00b7ne", "Gnad'", "und", "Gunst", "den", "Dru\u00b7ckern", "auch", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Viel F\u00fcrsten wolten sehn/ was Faust und Guttenberg", "tokens": ["Viel", "F\u00fcrs\u00b7ten", "wol\u00b7ten", "sehn", "/", "was", "Faust", "und", "Gut\u00b7ten\u00b7berg"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$(", "PWS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Vor eine sch\u00f6ne Kunst und k\u00fcnstlich Wunder-Werck", "tokens": ["Vor", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Kunst", "und", "k\u00fcnst\u00b7lich", "Wun\u00b7der\u00b7\u00b7Werck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Zu Meyntz herf\u00fcr gebracht. Der Pabst auch selbst erstarrte", "tokens": ["Zu", "Meyntz", "her\u00b7f\u00fcr", "ge\u00b7bracht", ".", "Der", "Pabst", "auch", "selbst", "er\u00b7starr\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADV", "VVPP", "$.", "ART", "NN", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Vor diesem Feder-Kiel/ f\u00fcrnemlich da er knarrte", "tokens": ["Vor", "die\u00b7sem", "Fe\u00b7der\u00b7Kiel", "/", "f\u00fcr\u00b7nem\u00b7lich", "da", "er", "knarr\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$(", "ADV", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.171": {"text": "In Luthers Schrifft so sehr/ da\u00df auch gantz Room erschrack", "tokens": ["In", "Lu\u00b7thers", "Schrifft", "so", "sehr", "/", "da\u00df", "auch", "gantz", "Room", "er\u00b7schrack"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "ADV", "ADV", "$(", "KOUS", "ADV", "ADV", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "und h\u00f6rte seinen Knall. O seelig ist der Tag/", "tokens": ["und", "h\u00f6r\u00b7te", "sei\u00b7nen", "Knall", ".", "O", "see\u00b7lig", "ist", "der", "Tag", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "NE", "ADJD", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Da diese Schreiberey zum ersten ist erfunden!", "tokens": ["Da", "die\u00b7se", "Schrei\u00b7be\u00b7rey", "zum", "ers\u00b7ten", "ist", "er\u00b7fun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPRART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Die Wunder-Feder die! o seelig seyn die Stunden/", "tokens": ["Die", "Wun\u00b7der\u00b7Fe\u00b7der", "die", "!", "o", "see\u00b7lig", "seyn", "die", "Stun\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "$.", "FM", "ADJD", "VAINF", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Da Faust und Guttenberg zum ersten mahl gedacht", "tokens": ["Da", "Faust", "und", "Gut\u00b7ten\u00b7berg", "zum", "ers\u00b7ten", "mahl", "ge\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "APPRART", "ADJA", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Auff diese Schreibe-Kunst! o seelig ist die Nacht/", "tokens": ["Auff", "die\u00b7se", "Schrei\u00b7be\u00b7Kunst", "!", "o", "see\u00b7lig", "ist", "die", "Nacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$.", "FM", "ADJD", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Die Schlafflo\u00df ging vorbey. Es muste so geschehen/", "tokens": ["Die", "Schlaf\u00b7flo\u00df", "ging", "vor\u00b7bey", ".", "Es", "mus\u00b7te", "so", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "VMFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Weil Gott es l\u00e4ngst zuvor der Wunder-Gott versehen;", "tokens": ["Weil", "Gott", "es", "l\u00e4ngst", "zu\u00b7vor", "der", "Wun\u00b7der\u00b7Gott", "ver\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Es solte Luthers Lehr in aller Welt ausgehn", "tokens": ["Es", "sol\u00b7te", "Lu\u00b7thers", "Lehr", "in", "al\u00b7ler", "Welt", "aus\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NE", "NN", "APPR", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Durch diese sch\u00f6ne Kunst und voll im bl\u00fchen stehn.", "tokens": ["Durch", "die\u00b7se", "sch\u00f6\u00b7ne", "Kunst", "und", "voll", "im", "bl\u00fc\u00b7hen", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "KON", "ADJD", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Halt Clio/ meine Zier/ halt doch ein wenig inne/", "tokens": ["Halt", "Clio", "/", "mei\u00b7ne", "Zier", "/", "halt", "doch", "ein", "we\u00b7nig", "in\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$(", "PPOSAT", "NN", "$(", "VVFIN", "ADV", "ART", "PIS", "PTKVZ", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.182": {"text": "Damit ich auff ihr Thun und Wesen mich besinne.", "tokens": ["Da\u00b7mit", "ich", "auff", "ihr", "Thun", "und", "We\u00b7sen", "mich", "be\u00b7sin\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Wie geht es bey euch zu? Was habt ihr Dr\u00fccker dann", "tokens": ["Wie", "geht", "es", "bey", "euch", "zu", "?", "Was", "habt", "ihr", "Dr\u00fc\u00b7cker", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$.", "PWS", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "In eurer Dr\u00fcckerey/ da\u00df itzt ein jedermann", "tokens": ["In", "eu\u00b7rer", "Dr\u00fc\u00b7cke\u00b7rey", "/", "da\u00df", "itzt", "ein", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "KOUS", "ADV", "ART", "PIS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Mit Wunder schaut und siht? Was habet ihr vor Sachen/", "tokens": ["Mit", "Wun\u00b7der", "schaut", "und", "siht", "?", "Was", "ha\u00b7bet", "ihr", "vor", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "VVFIN", "$.", "PWS", "VAFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Da\u00df in so kurtzer Zeit ihr k\u00f6nnet B\u00fccher machen?", "tokens": ["Da\u00df", "in", "so", "kurt\u00b7zer", "Zeit", "ihr", "k\u00f6n\u00b7net", "B\u00fc\u00b7cher", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADV", "ADJA", "NN", "PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Vors erste seh' ich hier Buchstaben die von Bley", "tokens": ["Vors", "ers\u00b7te", "seh'", "ich", "hier", "Buch\u00b7sta\u00b7ben", "die", "von", "Bley"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "ADV", "NN", "ART", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Der Schrifften-Giesser macht/ so viel und mancherley", "tokens": ["Der", "Schriff\u00b7ten\u00b7Gies\u00b7ser", "macht", "/", "so", "viel", "und", "man\u00b7cher\u00b7ley"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$(", "ADV", "ADV", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "In kleinen F\u00e4chern stehn. Da ligt bey gro\u00dfen Lasten", "tokens": ["In", "klei\u00b7nen", "F\u00e4\u00b7chern", "stehn", ".", "Da", "ligt", "bey", "gro\u00b7\u00dfen", "Las\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$.", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Die allergr\u00f6bste Schrifft in ihrem eignen Kasten:", "tokens": ["Die", "al\u00b7ler\u00b7gr\u00f6bs\u00b7te", "Schrifft", "in", "ih\u00b7rem", "eig\u00b7nen", "Kas\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Hier ligt Canon Versal/ Missal Antiqua dort/", "tokens": ["Hier", "ligt", "Ca\u00b7non", "Ver\u00b7sal", "/", "Mis\u00b7sal", "An\u00b7ti\u00b7qua", "dort", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NN", "$(", "NE", "NE", "ADV", "$("], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.192": {"text": "Roman-Antiqua dann an einem andern Ort.", "tokens": ["Ro\u00b7man\u00b7An\u00b7ti\u00b7qua", "dann", "an", "ei\u00b7nem", "an\u00b7dern", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.193": {"text": "Bey Parion Cursiv k\u00f6mmt Parion die Alte/", "tokens": ["Bey", "Pa\u00b7ri\u00b7on", "Cur\u00b7siv", "k\u00f6mmt", "Pa\u00b7ri\u00b7on", "die", "Al\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.194": {"text": "Die wohl beysammen stehn in einer Zeil und Spalte/", "tokens": ["Die", "wohl", "bey\u00b7sam\u00b7men", "stehn", "in", "ei\u00b7ner", "Zeil", "und", "Spal\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVINF", "VVFIN", "APPR", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Die dritt' Antiqua folgt und Tertia Cursiv;", "tokens": ["Die", "dritt'", "An\u00b7ti\u00b7qua", "folgt", "und", "Ter\u00b7tia", "Cur\u00b7siv", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "VVFIN", "KON", "NE", "NE", "$."], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.196": {"text": "Dann bey der Mittel-Schrifft/ die etwas kr\u00fcmmer lieff/", "tokens": ["Dann", "bey", "der", "Mit\u00b7tel\u00b7Schrifft", "/", "die", "et\u00b7was", "kr\u00fcm\u00b7mer", "lieff", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$(", "ART", "PIAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Antiqua Mittel steht. Nun komm' ich zu den beyden/", "tokens": ["An\u00b7ti\u00b7qua", "Mit\u00b7tel", "steht", ".", "Nun", "komm'", "ich", "zu", "den", "bey\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "APPR", "ART", "PIAT", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.198": {"text": "In welchen Guttenberg den Cicero mit Freuden", "tokens": ["In", "wel\u00b7chen", "Gut\u00b7ten\u00b7berg", "den", "Ci\u00b7ce\u00b7ro", "mit", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Zum ersten hat gesetzt/ dr\u00fcm sie auch heissen so", "tokens": ["Zum", "ers\u00b7ten", "hat", "ge\u00b7setzt", "/", "dr\u00fcm", "sie", "auch", "heis\u00b7sen", "so"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN", "VVPP", "$(", "VVFIN", "PPER", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Nach ihm/ die Alte nun und Schieffe Cicero.", "tokens": ["Nach", "ihm", "/", "die", "Al\u00b7te", "nun", "und", "Schief\u00b7fe", "Ci\u00b7ce\u00b7ro", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$(", "ART", "NN", "ADV", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Seh' ich mich weiter \u00fcm/ so seh' ich eben liegen", "tokens": ["Seh'", "ich", "mich", "wei\u00b7ter", "\u00fcm", "/", "so", "seh'", "ich", "e\u00b7ben", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADJD", "$(", "ADV", "VVFIN", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Garmuth-Antiqua dort zu der man pflegt zu f\u00fcgen", "tokens": ["Gar\u00b7muth\u00b7An\u00b7ti\u00b7qua", "dort", "zu", "der", "man", "pflegt", "zu", "f\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "PIS", "VVFIN", "PTKZU", "VVINF"], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.203": {"text": "Cursiv/ doch nicht \u00fcmsonst. Was kleinre nun betrifft/", "tokens": ["Cur\u00b7siv", "/", "doch", "nicht", "\u00fcm\u00b7sonst", ".", "Was", "klein\u00b7re", "nun", "be\u00b7tr\u00b7ifft", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADV", "PTKNEG", "ADV", "$.", "PWS", "VVFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.204": {"text": "Findt man die neue schieff- und alte Jungferschrifft.", "tokens": ["Findt", "man", "die", "neu\u00b7e", "schief\u00b7f", "und", "al\u00b7te", "Jung\u00b7fer\u00b7schrifft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.205": {"text": "Di\u00df seyn die Schrifften nun/ damit man pflegt zu dr\u00fccken", "tokens": ["Di\u00df", "seyn", "die", "Schriff\u00b7ten", "nun", "/", "da\u00b7mit", "man", "pflegt", "zu", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$(", "KOUS", "PIS", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Welsch/ Ungrisch und Latein/ zu denen sie sich schicken.", "tokens": ["Welsch", "/", "Un\u00b7grisch", "und", "La\u00b7tein", "/", "zu", "de\u00b7nen", "sie", "sich", "schi\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "KON", "NN", "$(", "APPR", "PRELS", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.207": {"text": "Nun fahr' ich weiter fort und setz' auch ordentlich", "tokens": ["Nun", "fahr'", "ich", "wei\u00b7ter", "fort", "und", "setz'", "auch", "or\u00b7dent\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "Dieselbe/ die gar sch\u00f6n zum Griechschen schicket sich.", "tokens": ["Die\u00b7sel\u00b7be", "/", "die", "gar", "sch\u00f6n", "zum", "Griech\u00b7schen", "schi\u00b7cket", "sich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "$(", "ART", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Da pflegt man auch zu erst die grobe Schrifft zu haben/", "tokens": ["Da", "pflegt", "man", "auch", "zu", "erst", "die", "gro\u00b7be", "Schrifft", "zu", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "ADV", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "Darnach die Cicero/ die etwas schmaal gegraben;", "tokens": ["Dar\u00b7nach", "die", "Ci\u00b7ce\u00b7ro", "/", "die", "et\u00b7was", "schmaal", "ge\u00b7gra\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$(", "ART", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Dann auch das Corpus folgt/ so Garmuth sonst genennt/", "tokens": ["Dann", "auch", "das", "Cor\u00b7pus", "folgt", "/", "so", "Gar\u00b7muth", "sonst", "ge\u00b7nennt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$(", "ADV", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "und/ weil sie kleiner ist/ gar leichtlich wird erkennt.", "tokens": ["und", "/", "weil", "sie", "klei\u00b7ner", "ist", "/", "gar", "leicht\u00b7lich", "wird", "er\u00b7kennt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PPER", "ADJD", "VAFIN", "$(", "ADV", "ADJD", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Auch hat man eure Schrifft und Puncten ihr Hebr\u00e4er/", "tokens": ["Auch", "hat", "man", "eu\u00b7re", "Schrifft", "und", "Punc\u00b7ten", "ihr", "Heb\u00b7r\u00e4\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PPOSAT", "NN", "KON", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.214": {"text": "Die etwas schwerer ist/ dieweil im andern eher", "tokens": ["Die", "et\u00b7was", "schwe\u00b7rer", "ist", "/", "die\u00b7weil", "im", "an\u00b7dern", "e\u00b7her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "ADJA", "VAFIN", "$(", "ADV", "APPRART", "ADJA", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Drey Bl\u00e4tter seyn gesetzt/ als hier ein eintzig Blat/", "tokens": ["Drey", "Bl\u00e4t\u00b7ter", "seyn", "ge\u00b7setzt", "/", "als", "hier", "ein", "eint\u00b7zig", "Blat", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PPOSAT", "VVPP", "$(", "KOKOM", "ADV", "ART", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "Denn sie was sonderlichs vor andern Sprachen hat.", "tokens": ["Denn", "sie", "was", "son\u00b7der\u00b7lichs", "vor", "an\u00b7dern", "Spra\u00b7chen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PWS", "PIS", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Wie auch das Syrische; der T\u00fcrcken Schrifft ingleichen;", "tokens": ["Wie", "auch", "das", "Sy\u00b7ri\u00b7sche", ";", "der", "T\u00fcr\u00b7cken", "Schrifft", "in\u00b7glei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "$.", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Hier k\u00f6nnen wir auch sehn der Memphen Schreibe-Zeichen", "tokens": ["Hier", "k\u00f6n\u00b7nen", "wir", "auch", "sehn", "der", "Mem\u00b7phen", "Schrei\u00b7be\u00b7Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.219": {"text": "Die gleich den Bildern seyn: Arabisch und so fort", "tokens": ["Die", "gleich", "den", "Bil\u00b7dern", "seyn", ":", "A\u00b7ra\u00b7bisch", "und", "so", "fort"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "VAINF", "$.", "NN", "KON", "ADV", "PTKVZ"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.220": {"text": "Chald\u00e4isch dr\u00fccket man und was an jenem Ort/", "tokens": ["Chal\u00b7d\u00e4isch", "dr\u00fc\u00b7cket", "man", "und", "was", "an", "je\u00b7nem", "Ort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "KON", "PWS", "APPR", "PDAT", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.221": {"text": "Da sich zu fr\u00fcher Zeit des Himmels Buhlschafft schm\u00fccket", "tokens": ["Da", "sich", "zu", "fr\u00fc\u00b7her", "Zeit", "des", "Him\u00b7mels", "Buhl\u00b7schafft", "schm\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PTKA", "ADJD", "NN", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "und aus dem Schlaaff-Gemach zum ersten mahle blicket/", "tokens": ["und", "aus", "dem", "Schlaaff\u00b7Ge\u00b7mach", "zum", "ers\u00b7ten", "mah\u00b7le", "bli\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Noch mehr vor Sprachen seyn; ja was der Welt bewust/", "tokens": ["Noch", "mehr", "vor", "Spra\u00b7chen", "seyn", ";", "ja", "was", "der", "Welt", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VAINF", "$.", "ADV", "PWS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Das k\u00f6nnen alles wir im Drucke sehn mit Lust.", "tokens": ["Das", "k\u00f6n\u00b7nen", "al\u00b7les", "wir", "im", "Dru\u00b7cke", "sehn", "mit", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "PPER", "APPRART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Zuletzt la\u00dft uns die Schrifft der Deutschen auch ber\u00fchren/", "tokens": ["Zu\u00b7letzt", "la\u00dft", "uns", "die", "Schrifft", "der", "Deut\u00b7schen", "auch", "be\u00b7r\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Die/ weil sie immer steigt/ viel neue Schrifften f\u00fchren.", "tokens": ["Die", "/", "weil", "sie", "im\u00b7mer", "steigt", "/", "viel", "neu\u00b7e", "Schriff\u00b7ten", "f\u00fch\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "KOUS", "PPER", "ADV", "VVFIN", "$(", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Erst findet man Canon gar zierlich grob und klein", "tokens": ["Erst", "fin\u00b7det", "man", "Ca\u00b7non", "gar", "zier\u00b7lich", "grob", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "NE", "ADV", "ADJD", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Darnach ist Teuerdanck und Fibelschrifft gemein/", "tokens": ["Dar\u00b7nach", "ist", "Teu\u00b7er\u00b7danck", "und", "Fi\u00b7bel\u00b7schrifft", "ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "NN", "KON", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Wie auch gebrochne Schrifft/ so man die Dritte nennet/", "tokens": ["Wie", "auch", "ge\u00b7broch\u00b7ne", "Schrifft", "/", "so", "man", "die", "Drit\u00b7te", "nen\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJA", "NN", "$(", "ADV", "PIS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Mit Tertia Fractur/ so leichtlich wird erkennet;", "tokens": ["Mit", "Ter\u00b7tia", "Frac\u00b7tur", "/", "so", "leicht\u00b7lich", "wird", "er\u00b7ken\u00b7net", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$(", "ADV", "ADJD", "VAFIN", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.231": {"text": "Die Grobe Mittel auch/ Schwabacher/ welche mann", "tokens": ["Die", "Gro\u00b7be", "Mit\u00b7tel", "auch", "/", "Schwab\u00b7a\u00b7cher", "/", "wel\u00b7che", "mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "NN", "$(", "PWAT", "NN"], "meter": "-+-+-+++-+-+", "measure": "unknown.measure.septa"}, "line.232": {"text": "Postillen Schrifft sonst heist und wol gebrauchen kann", "tokens": ["Pos\u00b7til\u00b7len", "Schrifft", "sonst", "heist", "und", "wol", "ge\u00b7brau\u00b7chen", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "ADJD", "KON", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "Zur Mittel Schrifft Fractur: Hiern\u00e4chst ist auch zu finden", "tokens": ["Zur", "Mit\u00b7tel", "Schrifft", "Frac\u00b7tur", ":", "Hier\u00b7n\u00e4chst", "ist", "auch", "zu", "fin\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NN", "NN", "$.", "ADV", "VAFIN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Schwabacher Cicero und bleibet nicht dahinden;", "tokens": ["Schwab\u00b7a\u00b7cher", "Ci\u00b7ce\u00b7ro", "und", "blei\u00b7bet", "nicht", "da\u00b7hin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "VVFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Bald Cicero Fractur/ so Gabon auch sonst heist/", "tokens": ["Bald", "Ci\u00b7ce\u00b7ro", "Frac\u00b7tur", "/", "so", "Ga\u00b7bon", "auch", "sonst", "heist", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "NN", "$(", "ADV", "NE", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Vielleicht von dem der sie zum ersten mahl abreisst.", "tokens": ["Viel\u00b7leicht", "von", "dem", "der", "sie", "zum", "ers\u00b7ten", "mahl", "ab\u00b7reisst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "PRELS", "PPER", "APPRART", "ADJA", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.237": {"text": "Hier siht man auch mit Lust Schwabacher Corpus liegen", "tokens": ["Hier", "siht", "man", "auch", "mit", "Lust", "Schwab\u00b7a\u00b7cher", "Cor\u00b7pus", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "NN", "NE", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.238": {"text": "und Corpus von Fractur so sch\u00f6n zusammen f\u00fcgen;", "tokens": ["und", "Cor\u00b7pus", "von", "Frac\u00b7tur", "so", "sch\u00f6n", "zu\u00b7sam\u00b7men", "f\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "NN", "ADV", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Zuletzt die Jungferschrifft Fractur und was uns mehr/", "tokens": ["Zu\u00b7letzt", "die", "Jung\u00b7fer\u00b7schrifft", "Frac\u00b7tur", "und", "was", "uns", "mehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "KON", "PWS", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Die sch\u00f6ne Nomperell/ Ihr Dr\u00fccker/ wundert sehr/", "tokens": ["Die", "sch\u00f6\u00b7ne", "Nom\u00b7pe\u00b7rell", "/", "Ihr", "Dr\u00fc\u00b7cker", "/", "wun\u00b7dert", "sehr", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PPOSAT", "NN", "$(", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Die Zieffern/ R\u00f6selein/ die gro\u00df- und kleine Noten/", "tokens": ["Die", "Zief\u00b7fern", "/", "R\u00f6\u00b7se\u00b7lein", "/", "die", "gro\u00df", "und", "klei\u00b7ne", "No\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "$(", "ART", "TRUNC", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Die Leisten/ Z\u00fcg' und St\u00f6ck/ einfache Strich und Knoten/", "tokens": ["Die", "Leis\u00b7ten", "/", "Z\u00fcg'", "und", "St\u00f6ck", "/", "ein\u00b7fa\u00b7che", "Strich", "und", "Kno\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "KON", "NN", "$(", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Figuren allerhand auff Kupffer Holtz und Bley", "tokens": ["Fi\u00b7gu\u00b7ren", "al\u00b7ler\u00b7hand", "auff", "Kupf\u00b7fer", "Holtz", "und", "Bley"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "APPR", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "und was man alles siht in dieser Schreyberey.", "tokens": ["und", "was", "man", "al\u00b7les", "siht", "in", "die\u00b7ser", "Schrey\u00b7be\u00b7rey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PIS", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Di\u00df seyn die Schrifften nun/ die aus den F\u00e4chern langet/", "tokens": ["Di\u00df", "seyn", "die", "Schriff\u00b7ten", "nun", "/", "die", "aus", "den", "F\u00e4\u00b7chern", "lan\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.246": {"text": "Ihr s\u00e4tzer alsobald/ wenn ihr ein Werck anfanget", "tokens": ["Ihr", "s\u00e4t\u00b7zer", "al\u00b7so\u00b7bald", "/", "wenn", "ihr", "ein", "Werck", "an\u00b7fan\u00b7get"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.247": {"text": "und setzt sie ordentlich ins Winckel-Maa\u00df hinein/", "tokens": ["und", "setzt", "sie", "or\u00b7dent\u00b7lich", "ins", "Win\u00b7ckel\u00b7Maa\u00df", "hin\u00b7ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "so lange/ bi\u00df das Maa\u00df mag voll an Schrifften seyn;", "tokens": ["so", "lan\u00b7ge", "/", "bi\u00df", "das", "Maa\u00df", "mag", "voll", "an", "Schriff\u00b7ten", "seyn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "APPR", "ART", "NN", "VMFIN", "ADJD", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Dann nehmt ihr wieder\u00fcm heraus die vollen Zeilen", "tokens": ["Dann", "nehmt", "ihr", "wie\u00b7de\u00b7r\u00fcm", "he\u00b7raus", "die", "vol\u00b7len", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.250": {"text": "und setzt sie auff ein Bredt/ die ihr dann pflegt zu theilen", "tokens": ["und", "setzt", "sie", "auff", "ein", "Bredt", "/", "die", "ihr", "dann", "pflegt", "zu", "thei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "PRELS", "PPER", "ADV", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.251": {"text": "In gantze Bl\u00e4tter aus/ bi\u00df eine Form ist voll/", "tokens": ["In", "gant\u00b7ze", "Bl\u00e4t\u00b7ter", "aus", "/", "bi\u00df", "ei\u00b7ne", "Form", "ist", "voll", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$(", "APPR", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Dann legt ihr Rahmen dr\u00fcm und/ wie ein Dr\u00fccker soll/", "tokens": ["Dann", "legt", "ihr", "Rah\u00b7men", "dr\u00fcm", "und", "/", "wie", "ein", "Dr\u00fc\u00b7cker", "soll", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "KON", "$(", "KOKOM", "ART", "NN", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Schlie\u00dft ihr die Forme zu/ da\u00df ihr sie k\u00f6nnet tragen", "tokens": ["Schlie\u00dft", "ihr", "die", "For\u00b7me", "zu", "/", "da\u00df", "ihr", "sie", "k\u00f6n\u00b7net", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKZU", "$(", "KOUS", "PPER", "PPER", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "zur Pressen unverr\u00fcckt nach eurem Wohlbehagen;", "tokens": ["zur", "Pres\u00b7sen", "un\u00b7ver\u00b7r\u00fcckt", "nach", "eu\u00b7rem", "Wohl\u00b7be\u00b7ha\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.255": {"text": "Setzt sie auff festen Grund/ tragt Farben alsobald", "tokens": ["Setzt", "sie", "auff", "fes\u00b7ten", "Grund", "/", "tragt", "Far\u00b7ben", "al\u00b7so\u00b7bald"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$(", "VVFIN", "NN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Mit zweyen Ballen auff/ treckt zweymal mit Gewalt", "tokens": ["Mit", "zwe\u00b7yen", "Bal\u00b7len", "auff", "/", "treckt", "zwey\u00b7mal", "mit", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "NN", "APPR", "$(", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.257": {"text": "Den Bengel zu euch zu/ und wann der erste Bogen/", "tokens": ["Den", "Ben\u00b7gel", "zu", "euch", "zu", "/", "und", "wann", "der", "ers\u00b7te", "Bo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKZU", "$(", "KON", "PWAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.258": {"text": "So Sch\u00f6ndruck wird genennt/ einmahl ist abgezogen/", "tokens": ["So", "Sch\u00f6n\u00b7druck", "wird", "ge\u00b7nennt", "/", "ein\u00b7mahl", "ist", "ab\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "VVPP", "$(", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.259": {"text": "Macht ihr den Wieder-Druck und \u00e4ndert was versetzt/", "tokens": ["Macht", "ihr", "den", "Wie\u00b7der\u00b7Druck", "und", "\u00e4n\u00b7dert", "was", "ver\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "KON", "VVFIN", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "Auch sonst nicht richtig ist; Drauff nehmet ihr zuletzt", "tokens": ["Auch", "sonst", "nicht", "rich\u00b7tig", "ist", ";", "Drauff", "neh\u00b7met", "ihr", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "VAFIN", "$.", "PAV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "Papier/ so schon gefeucht/ damit es Farbe fangen", "tokens": ["Pa\u00b7pier", "/", "so", "schon", "ge\u00b7feucht", "/", "da\u00b7mit", "es", "Far\u00b7be", "fan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "ADV", "ADV", "VVPP", "$(", "KOUS", "PPER", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.262": {"text": "und an sich nehmen kan; Eh nun ein Tag vergangen/", "tokens": ["und", "an", "sich", "neh\u00b7men", "kan", ";", "Eh", "nun", "ein", "Tag", "ver\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRF", "VVINF", "VMFIN", "$.", "NN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.263": {"text": "Habt tausend Bogen ihr ja mehr schon abgedr\u00fcckt/", "tokens": ["Habt", "tau\u00b7send", "Bo\u00b7gen", "ihr", "ja", "mehr", "schon", "ab\u00b7ge\u00b7dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "Die werden auffgeh\u00e4ngt/ getrucknet und geschickt", "tokens": ["Die", "wer\u00b7den", "auff\u00b7ge\u00b7h\u00e4ngt", "/", "ge\u00b7truck\u00b7net", "und", "ge\u00b7schickt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "VVPP", "$(", "VVPP", "KON", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "Zu dem/ der sie verlegt; der ihren Nutzen sp\u00fcret/", "tokens": ["Zu", "dem", "/", "der", "sie", "ver\u00b7legt", ";", "der", "ih\u00b7ren", "Nut\u00b7zen", "sp\u00fc\u00b7ret", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PRELS", "PPER", "VVPP", "$.", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "Wenn er sie durch die Welt in manche L\u00e4nder f\u00fchret:", "tokens": ["Wenn", "er", "sie", "durch", "die", "Welt", "in", "man\u00b7che", "L\u00e4n\u00b7der", "f\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.267": {"text": "Room lieset gantz best\u00fcrtzt/ was nun zu Wittenberg", "tokens": ["Room", "lie\u00b7set", "gantz", "be\u00b7st\u00fcrtzt", "/", "was", "nun", "zu", "Wit\u00b7ten\u00b7berg"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "VVPP", "$(", "PWS", "ADV", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.268": {"text": "Zum meisten wird gedr\u00fcckt/ das edle Himmels-Werck.", "tokens": ["Zum", "meis\u00b7ten", "wird", "ge\u00b7dr\u00fcckt", "/", "das", "ed\u00b7le", "Him\u00b7mels\u00b7\u00b7Werck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "VAFIN", "VVPP", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.269": {"text": "Die Biblien seyn nun verdeutschet und gedr\u00fccket/", "tokens": ["Die", "Bib\u00b7li\u00b7en", "seyn", "nun", "ver\u00b7deut\u00b7schet", "und", "ge\u00b7dr\u00fc\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADV", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.270": {"text": "Daraus die Himmels-Lehr uns offenbahr anblicket/", "tokens": ["Da\u00b7raus", "die", "Him\u00b7mels\u00b7Lehr", "uns", "of\u00b7fen\u00b7bahr", "an\u00b7bli\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "So vor verborgen lag/ man wuste nichts von ihr", "tokens": ["So", "vor", "ver\u00b7bor\u00b7gen", "lag", "/", "man", "wus\u00b7te", "nichts", "von", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "VVPP", "VVFIN", "$(", "PIS", "VVFIN", "PIS", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.272": {"text": "Bi\u00df endlich Luther kam und brachte sie herf\u00fcr.", "tokens": ["Bi\u00df", "end\u00b7lich", "Lu\u00b7ther", "kam", "und", "brach\u00b7te", "sie", "her\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "NE", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.273": {"text": "Die B\u00fccher brechen aus/ die vor verschwiegen lagen/", "tokens": ["Die", "B\u00fc\u00b7cher", "bre\u00b7chen", "aus", "/", "die", "vor", "ver\u00b7schwie\u00b7gen", "la\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "ART", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.274": {"text": "Durch unsre Dr\u00fcckerey; Sie ist der rechte Wagen/", "tokens": ["Durch", "uns\u00b7re", "Dr\u00fc\u00b7cke\u00b7rey", ";", "Sie", "ist", "der", "rech\u00b7te", "Wa\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.275": {"text": "Der aus der Sterbligkeit die edlen Geister f\u00fchrt", "tokens": ["Der", "aus", "der", "Ster\u00b7blig\u00b7keit", "die", "ed\u00b7len", "Geis\u00b7ter", "f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.276": {"text": "Dahin/ wo niemand stirbt; wo man die Sternen r\u00fchrt", "tokens": ["Da\u00b7hin", "/", "wo", "nie\u00b7mand", "stirbt", ";", "wo", "man", "die", "Ster\u00b7nen", "r\u00fchrt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "$(", "PWAV", "PIS", "VVFIN", "$.", "PWAV", "PIS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.277": {"text": "und ewig ist bekant. Es kan nunmehr nicht t\u00f6dten", "tokens": ["und", "e\u00b7wig", "ist", "be\u00b7kant", ".", "Es", "kan", "nun\u00b7mehr", "nicht", "t\u00f6d\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "ADJD", "$.", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.278": {"text": "Das ungl\u00fcck dieser Zeit die Edelen Poeten/", "tokens": ["Das", "un\u00b7gl\u00fcck", "die\u00b7ser", "Zeit", "die", "E\u00b7de\u00b7len", "Po\u00b7et\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Ihr Nahme wird ber\u00fchmt und bleibet nun dabey/", "tokens": ["Ihr", "Nah\u00b7me", "wird", "be\u00b7r\u00fchmt", "und", "blei\u00b7bet", "nun", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "VVFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.280": {"text": "Da\u00df keiner untergeht/ so lange Dr\u00fcckerey", "tokens": ["Da\u00df", "kei\u00b7ner", "un\u00b7ter\u00b7geht", "/", "so", "lan\u00b7ge", "Dr\u00fc\u00b7cke\u00b7rey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "$(", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.281": {"text": "Der edlen Tugend meldt. Da\u00df in so kurtzen Zeiten", "tokens": ["Der", "ed\u00b7len", "Tu\u00b7gend", "meldt", ".", "Da\u00df", "in", "so", "kurt\u00b7zen", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "KOUS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.282": {"text": "Die Deutsche Poesie erschallt auff allen Seiten/", "tokens": ["Die", "Deut\u00b7sche", "Poe\u00b7sie", "er\u00b7schallt", "auff", "al\u00b7len", "Sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.283": {"text": "Das macht die Dr\u00fcckerey/ die erstlich ausgebracht/", "tokens": ["Das", "macht", "die", "Dr\u00fc\u00b7cke\u00b7rey", "/", "die", "erst\u00b7lich", "aus\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.284": {"text": "Was Opitz unsre Zier mit kluger Hand gemacht.", "tokens": ["Was", "O\u00b7pitz", "uns\u00b7re", "Zier", "mit", "klu\u00b7ger", "Hand", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.285": {"text": "Gantz Deutschland ist bem\u00fcht/ auch in den gr\u00f6sten Kriegen/", "tokens": ["Gantz", "Deutschland", "ist", "be\u00b7m\u00fcht", "/", "auch", "in", "den", "gr\u00f6s\u00b7ten", "Krie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "VVPP", "$(", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.286": {"text": "Wie Wunder ist doch das! den andern abzusiegen/", "tokens": ["Wie", "Wun\u00b7der", "ist", "doch", "das", "!", "den", "an\u00b7dern", "ab\u00b7zu\u00b7sie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "ADV", "ART", "$.", "ART", "ADJA", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Die Griechen stehn best\u00fcrtzt/ Homerus gantz erbleicht/", "tokens": ["Die", "Grie\u00b7chen", "stehn", "be\u00b7st\u00fcrtzt", "/", "Ho\u00b7me\u00b7rus", "gantz", "er\u00b7bleicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVPP", "$(", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.288": {"text": "Horatius erblasst und Maro selbst entweicht", "tokens": ["Ho\u00b7ra\u00b7ti\u00b7us", "er\u00b7blasst", "und", "Ma\u00b7ro", "selbst", "ent\u00b7weicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "NE", "ADV", "VVFIN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.289": {"text": "Vor unsrer Poesie; Die nun so hoch sich schwinget/", "tokens": ["Vor", "uns\u00b7rer", "Poe\u00b7sie", ";", "Die", "nun", "so", "hoch", "sich", "schwin\u00b7get", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ART", "ADV", "ADV", "ADJD", "PRF", "VVFIN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.290": {"text": "Da\u00df Wiesen/ Berg und Thal vor Freuden wieder klinget:", "tokens": ["Da\u00df", "Wie\u00b7sen", "/", "Berg", "und", "Thal", "vor", "Freu\u00b7den", "wie\u00b7der", "klin\u00b7get", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "NN", "KON", "NN", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.291": {"text": "Die Arten eurer Vers' ihr Griechen allzumahl", "tokens": ["Die", "Ar\u00b7ten", "eu\u00b7rer", "Ver\u00b7s'", "ihr", "Grie\u00b7chen", "all\u00b7zu\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "PPOSAT", "NN", "ADV"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.292": {"text": "und Ihr aus Latien/ seyn nicht so viel an Zahl/", "tokens": ["und", "Ihr", "aus", "La\u00b7ti\u00b7en", "/", "seyn", "nicht", "so", "viel", "an", "Zahl", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NE", "$(", "VAINF", "PTKNEG", "ADV", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.293": {"text": "Als ich im Deutschen nur aus Jamben und Troch\u00e4en", "tokens": ["Als", "ich", "im", "Deut\u00b7schen", "nur", "aus", "Jam\u00b7ben", "und", "Troc\u00b7h\u00e4\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.294": {"text": "Alleine machen kan: Ihr m\u00fcsst es selbst gestehen/", "tokens": ["Al\u00b7lei\u00b7ne", "ma\u00b7chen", "kan", ":", "Ihr", "m\u00fcsst", "es", "selbst", "ge\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.295": {"text": "Da\u00df wir so sch\u00f6n als Ihr die Anap\u00e4sten auch", "tokens": ["Da\u00df", "wir", "so", "sch\u00f6n", "als", "Ihr", "die", "A\u00b7na\u00b7p\u00e4s\u00b7ten", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "KOKOM", "PPER", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.296": {"text": "Itzt haben auffgebracht/ da\u00df nunmehr seyn im Brauch/", "tokens": ["Itzt", "ha\u00b7ben", "auff\u00b7ge\u00b7bracht", "/", "da\u00df", "nun\u00b7mehr", "seyn", "im", "Brauch", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$(", "KOUS", "ADV", "VAINF", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "Wann wir die Arten all' in unsren Versen z\u00e4hlen/", "tokens": ["Wann", "wir", "die", "Ar\u00b7ten", "all'", "in", "un\u00b7sren", "Ver\u00b7sen", "z\u00e4h\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PIS", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.298": {"text": "Wohl funfftzig/ ja noch mehr/ daraus wir eine w\u00e4hlen", "tokens": ["Wohl", "funfft\u00b7zig", "/", "ja", "noch", "mehr", "/", "da\u00b7raus", "wir", "ei\u00b7ne", "w\u00e4h\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "$(", "ADV", "ADV", "ADV", "$(", "PAV", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.299": {"text": "Nach Lust/ und schreiben dann was unser Hertze will/", "tokens": ["Nach", "Lust", "/", "und", "schrei\u00b7ben", "dann", "was", "un\u00b7ser", "Hert\u00b7ze", "will", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "KON", "VVFIN", "ADV", "PWS", "PPER", "VVFIN", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.300": {"text": "Bald di\u00df bald jenes Lied; Die Helden schweigen still", "tokens": ["Bald", "di\u00df", "bald", "je\u00b7nes", "Lied", ";", "Die", "Hel\u00b7den", "schwei\u00b7gen", "still"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "ADV", "PDAT", "NN", "$.", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.301": {"text": "und h\u00f6ren selbsten zu; Der Helm mu\u00df niederliegen/", "tokens": ["und", "h\u00f6\u00b7ren", "selbs\u00b7ten", "zu", ";", "Der", "Helm", "mu\u00df", "nie\u00b7der\u00b7lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.302": {"text": "Der Harnisch ruht inde\u00df/ wann unsre Verse siegen/", "tokens": ["Der", "Har\u00b7nisch", "ruht", "in\u00b7de\u00df", "/", "wann", "uns\u00b7re", "Ver\u00b7se", "sie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "PWAV", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.303": {"text": "Sie werden so entz\u00fcckt/ da\u00df mancher WERTHER Held", "tokens": ["Sie", "wer\u00b7den", "so", "ent\u00b7z\u00fcckt", "/", "da\u00df", "man\u00b7cher", "WeRT\u00b7HER", "Held"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$(", "KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.304": {"text": "Die Waffen nichts mehr acht/ sucht vor das Krieges-Zelt", "tokens": ["Die", "Waf\u00b7fen", "nichts", "mehr", "acht", "/", "sucht", "vor", "das", "Krie\u00b7ge\u00b7sZelt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIS", "ADV", "CARD", "$(", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.305": {"text": "Den edlen Helicon. Der Fortgang und das Steigen", "tokens": ["Den", "ed\u00b7len", "He\u00b7li\u00b7con", ".", "Der", "Fort\u00b7gang", "und", "das", "Stei\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "Der Deutschen Poesie ist/ k\u00fcrtzlich anzuzeigen/", "tokens": ["Der", "Deut\u00b7schen", "Poe\u00b7sie", "ist", "/", "k\u00fcrtz\u00b7lich", "an\u00b7zu\u00b7zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "ADJD", "VVIZU", "$("], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.307": {"text": "Durch unsre Dr\u00fcckerey so eilend fortgebracht/", "tokens": ["Durch", "uns\u00b7re", "Dr\u00fc\u00b7cke\u00b7rey", "so", "ei\u00b7lend", "fort\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "Da\u00df itzt fast jederman ein Deutsch Getichte macht.", "tokens": ["Da\u00df", "itzt", "fast", "je\u00b7der\u00b7man", "ein", "Deutsch", "Ge\u00b7tich\u00b7te", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIS", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.309": {"text": "O edle Dr\u00fcckerey! Wo wolte man die Stunden", "tokens": ["O", "ed\u00b7le", "Dr\u00fc\u00b7cke\u00b7rey", "!", "Wo", "wol\u00b7te", "man", "die", "Stun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "PWAV", "VMFIN", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.310": {"text": "Nur immer bringen zu/ wenn du nicht werst erfunden:", "tokens": ["Nur", "im\u00b7mer", "brin\u00b7gen", "zu", "/", "wenn", "du", "nicht", "werst", "er\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "PTKZU", "$(", "KOUS", "PPER", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.311": {"text": "Da\u00df itzt so manches Buch ein jeder lesen mag/", "tokens": ["Da\u00df", "itzt", "so", "man\u00b7ches", "Buch", "ein", "je\u00b7der", "le\u00b7sen", "mag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIAT", "NN", "ART", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.312": {"text": "Das vor verborgen war und schaute nicht den Tag/", "tokens": ["Das", "vor", "ver\u00b7bor\u00b7gen", "war", "und", "schau\u00b7te", "nicht", "den", "Tag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "VVPP", "VAFIN", "KON", "VVFIN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.313": {"text": "Das k\u00f6mmet her von dier. Nun kan ein jeder lesen/", "tokens": ["Das", "k\u00f6m\u00b7met", "her", "von", "dier", ".", "Nun", "kan", "ein", "je\u00b7der", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PDAT", "$.", "ADV", "VMFIN", "ART", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Was Aristoteles und Tullius gewesen/", "tokens": ["Was", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "und", "Tul\u00b7li\u00b7us", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.315": {"text": "Wie weise Plato sey und was er uns gelehrt/", "tokens": ["Wie", "wei\u00b7se", "Pla\u00b7to", "sey", "und", "was", "er", "uns", "ge\u00b7lehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "VAFIN", "KON", "PWS", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.316": {"text": "Wie sehr Severus auch den Flaccus hat geehrt", "tokens": ["Wie", "sehr", "Se\u00b7ve\u00b7rus", "auch", "den", "Flac\u00b7cus", "hat", "ge\u00b7ehrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NE", "ADV", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.317": {"text": "und sich vor ihm gef\u00fcrcht: Wie hoch Trajan erhoben", "tokens": ["und", "sich", "vor", "ihm", "ge\u00b7f\u00fcrcht", ":", "Wie", "hoch", "Tra\u00b7jan", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "PPER", "VVPP", "$.", "PWAV", "ADJD", "NN", "VVPP"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.318": {"text": "Den jungen Plinius; Was dieser pflegt zu loben", "tokens": ["Den", "jun\u00b7gen", "Pli\u00b7nius", ";", "Was", "die\u00b7ser", "pflegt", "zu", "lo\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "$.", "PWS", "PDS", "VVFIN", "PTKZU", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.319": {"text": "und jener strafft und schilt. Die edle Wissenschafft", "tokens": ["und", "je\u00b7ner", "strafft", "und", "schilt", ".", "Die", "ed\u00b7le", "Wis\u00b7sen\u00b7schafft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "KON", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.320": {"text": "Der Weisen von Athen/ so l\u00e4ngsten hingerafft/", "tokens": ["Der", "Wei\u00b7sen", "von", "A\u00b7then", "/", "so", "l\u00e4ngs\u00b7ten", "hin\u00b7ge\u00b7rafft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$(", "ADV", "ADJA", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.321": {"text": "Die lebet noch durch Dich/ und wird auch nun wohl bleiben/", "tokens": ["Die", "le\u00b7bet", "noch", "durch", "Dich", "/", "und", "wird", "auch", "nun", "wohl", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PPER", "$(", "KON", "VAFIN", "ADV", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.322": {"text": "So lange du bestehst. Was wir noch itzo schreiben/", "tokens": ["So", "lan\u00b7ge", "du", "be\u00b7stehst", ".", "Was", "wir", "noch", "it\u00b7zo", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "$.", "PWS", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.323": {"text": "Das wird den untergang auch niemahls sehen nicht/", "tokens": ["Das", "wird", "den", "un\u00b7ter\u00b7gang", "auch", "nie\u00b7mahls", "se\u00b7hen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "ADV", "VVINF", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.324": {"text": "So lange Dr\u00fcckerey/ der Tugend Glantz und Licht/", "tokens": ["So", "lan\u00b7ge", "Dr\u00fc\u00b7cke\u00b7rey", "/", "der", "Tu\u00b7gend", "Glantz", "und", "Licht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$(", "ART", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.325": {"text": "Noch funckelt auff der Welt. Ein Pferd siht bald von fernen/", "tokens": ["Noch", "fun\u00b7ckelt", "auff", "der", "Welt", ".", "Ein", "Pferd", "siht", "bald", "von", "fer\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$.", "ART", "NN", "VVFIN", "ADV", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.326": {"text": "Den Feind und reisst hindurch; so reisst sich zu den Sternen/", "tokens": ["Den", "Feind", "und", "reisst", "hin\u00b7durch", ";", "so", "reisst", "sich", "zu", "den", "Ster\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PAV", "$.", "ADV", "VVFIN", "PRF", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.327": {"text": "Durch alle Sterbligkeit mit uns die Dr\u00fcckerey/", "tokens": ["Durch", "al\u00b7le", "Ster\u00b7blig\u00b7keit", "mit", "uns", "die", "Dr\u00fc\u00b7cke\u00b7rey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.328": {"text": "Macht unsern Nahmen gro\u00df und steht den K\u00fcnsten bey.", "tokens": ["Macht", "un\u00b7sern", "Nah\u00b7men", "gro\u00df", "und", "steht", "den", "K\u00fcns\u00b7ten", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADJD", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.329": {"text": "Ein Adler/ wann er sich bey k\u00fchler Lufft geschwungen", "tokens": ["Ein", "Ad\u00b7ler", "/", "wann", "er", "sich", "bey", "k\u00fch\u00b7ler", "Lufft", "ge\u00b7schwun\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PWAV", "PPER", "PRF", "APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.330": {"text": "Zur rothen Sonnen hin/ tr\u00e4gt nachmahls seine Jungen", "tokens": ["Zur", "ro\u00b7then", "Son\u00b7nen", "hin", "/", "tr\u00e4gt", "nach\u00b7mahls", "sei\u00b7ne", "Jun\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$(", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.331": {"text": "Auch eben so hinauff/ zu sch\u00e4rffen ihr Gesicht/", "tokens": ["Auch", "e\u00b7ben", "so", "hin\u00b7auff", "/", "zu", "sch\u00e4rf\u00b7fen", "ihr", "Ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "$(", "PTKZU", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.332": {"text": "Da\u00df sie gantz unverwandt das klare Wolcken-Licht", "tokens": ["Da\u00df", "sie", "gantz", "un\u00b7ver\u00b7wandt", "das", "kla\u00b7re", "Wol\u00b7cken\u00b7Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.333": {"text": "Auch k\u00f6nten schauen an: So werden wir getragen", "tokens": ["Auch", "k\u00f6n\u00b7ten", "schau\u00b7en", "an", ":", "So", "wer\u00b7den", "wir", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "VVINF", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.334": {"text": "Auch durch die Dr\u00fccker-Kunst nach unserm Wohlbehagen/", "tokens": ["Auch", "durch", "die", "Dr\u00fc\u00b7cker\u00b7Kunst", "nach", "un\u00b7serm", "Wohl\u00b7be\u00b7ha\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.335": {"text": "Wo Ph\u00f6bus uns bestrahlt/ zur blancken Himmels-Bahn;", "tokens": ["Wo", "Ph\u00f6\u00b7bus", "uns", "be\u00b7strahlt", "/", "zur", "blan\u00b7cken", "Him\u00b7mels\u00b7Bahn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PPER", "VVFIN", "$(", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.336": {"text": "Sie schwinget sich ermpor/ nimmt Adlers Fl\u00fcgel an", "tokens": ["Sie", "schwin\u00b7get", "sich", "erm\u00b7por", "/", "nimmt", "Ad\u00b7lers", "Fl\u00fc\u00b7gel", "an"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$(", "VVFIN", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.337": {"text": "und f\u00fchrt uns aus der Nacht. Die sehr-verborgnen Sachen/", "tokens": ["und", "f\u00fchrt", "uns", "aus", "der", "Nacht", ".", "Die", "sehr\u00b7ver\u00b7bor\u00b7gnen", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.338": {"text": "Die manchem Freud' und Lust bey schwerem unmuth machen/", "tokens": ["Die", "man\u00b7chem", "Freud'", "und", "Lust", "bey", "schwe\u00b7rem", "un\u00b7muth", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.339": {"text": "Die lieset man durch Sie. Die Albern werden klug/", "tokens": ["Die", "lie\u00b7set", "man", "durch", "Sie", ".", "Die", "Al\u00b7bern", "wer\u00b7den", "klug", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "PPER", "$.", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.340": {"text": "Die Blinden sehen nun den schrecklichsten Betrug.", "tokens": ["Die", "Blin\u00b7den", "se\u00b7hen", "nun", "den", "schreck\u00b7lichs\u00b7ten", "Be\u00b7trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.341": {"text": "Dr\u00fcm soll man ehren die/ die unsre Dr\u00fcckereyen", "tokens": ["Dr\u00fcm", "soll", "man", "eh\u00b7ren", "die", "/", "die", "uns\u00b7re", "Dr\u00fc\u00b7cke\u00b7re\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "VVFIN", "ART", "$(", "ART", "PPOSAT", "NN"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.342": {"text": "Bef\u00f6rdern noch itzund/ auff die sich manche freuen;", "tokens": ["Be\u00b7f\u00f6r\u00b7dern", "noch", "it\u00b7zund", "/", "auff", "die", "sich", "man\u00b7che", "freu\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "$(", "APPR", "PRELS", "PRF", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.343": {"text": "Die aus der Niedrigkeit gedencken da hinan/", "tokens": ["Die", "aus", "der", "Nied\u00b7rig\u00b7keit", "ge\u00b7den\u00b7cken", "da", "hi\u00b7nan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.344": {"text": "Wo man betreten kan die Sternen-liechte Bahn", "tokens": ["Wo", "man", "be\u00b7tre\u00b7ten", "kan", "die", "Ster\u00b7nen\u00b7liech\u00b7te", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVINF", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.345": {"text": "Der unverg\u00e4ngligkeit. Man solte dier zu Ehren/", "tokens": ["Der", "un\u00b7ver\u00b7g\u00e4n\u00b7glig\u00b7keit", ".", "Man", "sol\u00b7te", "dier", "zu", "Eh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PIS", "VMFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.346": {"text": "Du edler Guttenberg/ dein edles Werck vermehren/", "tokens": ["Du", "ed\u00b7ler", "Gut\u00b7ten\u00b7berg", "/", "dein", "ed\u00b7les", "Werck", "ver\u00b7meh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "PPOSAT", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.347": {"text": "Man solte noch itzund mit Gold in Demant-Stein", "tokens": ["Man", "sol\u00b7te", "noch", "it\u00b7zund", "mit", "Gold", "in", "De\u00b7mant\u00b7Stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "APPR", "NN", "APPR", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.348": {"text": "Dein Lob und deine Kunst/ wie billich/ schreiben ein.", "tokens": ["Dein", "Lob", "und", "dei\u00b7ne", "Kunst", "/", "wie", "bil\u00b7lich", "/", "schrei\u00b7ben", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$(", "PWAV", "ADJD", "$(", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.349": {"text": "Wo ist dein Denckmahl dann? Wo ist die Ehren-Seule?", "tokens": ["Wo", "ist", "dein", "Denck\u00b7mahl", "dann", "?", "Wo", "ist", "die", "Eh\u00b7ren\u00b7Seu\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADV", "$.", "PWAV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.350": {"text": "Wo ist die Ehren-Schrifft? Ich sehe keine Zeile/", "tokens": ["Wo", "ist", "die", "Eh\u00b7ren\u00b7Schrifft", "?", "Ich", "se\u00b7he", "kei\u00b7ne", "Zei\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$.", "PPER", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.351": {"text": "Kein Denck-Mahl ist auch hier/ kein Zeichen seh ich nicht/", "tokens": ["Kein", "Den\u00b7ck\u00b7Mahl", "ist", "auch", "hier", "/", "kein", "Zei\u00b7chen", "seh", "ich", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "$(", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.352": {"text": "Das dier ein eintzig Mensch zu Ehren auffgericht/", "tokens": ["Das", "dier", "ein", "eint\u00b7zig", "Mensch", "zu", "Eh\u00b7ren", "auff\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJD", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.353": {"text": "Wann einer diese Kunst gezeigt vor vielen Jahren/", "tokens": ["Wann", "ei\u00b7ner", "die\u00b7se", "Kunst", "ge\u00b7zeigt", "vor", "vie\u00b7len", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PDAT", "NN", "VVPP", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.354": {"text": "Da noch Athen und Room in vollem Wachsthum waren/", "tokens": ["Da", "noch", "A\u00b7then", "und", "Room", "in", "vol\u00b7lem", "Wach\u00b7sthum", "wa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "KON", "NE", "APPR", "ADJA", "NN", "VAFIN", "$("], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.355": {"text": "So h\u00e4tte man sein Bild wohl gar zum Gott gemacht", "tokens": ["So", "h\u00e4t\u00b7te", "man", "sein", "Bild", "wohl", "gar", "zum", "Gott", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "PPOSAT", "NN", "ADV", "ADV", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.356": {"text": "und zu dem Tempel hin mit Hertzens-Lust gebracht.", "tokens": ["und", "zu", "dem", "Tem\u00b7pel", "hin", "mit", "Hert\u00b7zens\u00b7Lust", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.357": {"text": "Wie h\u00e4tten diesen wohl die Sindier geehret/", "tokens": ["Wie", "h\u00e4t\u00b7ten", "die\u00b7sen", "wohl", "die", "Sin\u00b7dier", "ge\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDAT", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.358": {"text": "Der ihnen diese Kunst die Dr\u00fccker-Kunst gelehret?", "tokens": ["Der", "ih\u00b7nen", "die\u00b7se", "Kunst", "die", "Dr\u00fc\u00b7cker\u00b7Kunst", "ge\u00b7leh\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PDAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.359": {"text": "Sie h\u00e4tten ihm gewi\u00df was sonderlichs erdacht/", "tokens": ["Sie", "h\u00e4t\u00b7ten", "ihm", "ge\u00b7wi\u00df", "was", "son\u00b7der\u00b7lichs", "er\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PWS", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.360": {"text": "und bey der andern Welt ein ewigs Lob gemacht.", "tokens": ["und", "bey", "der", "an\u00b7dern", "Welt", "ein", "e\u00b7wigs", "Lob", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.361": {"text": "Was aber thut man dir? Nun ob dir gleich zu Ehren", "tokens": ["Was", "a\u00b7ber", "thut", "man", "dir", "?", "Nun", "ob", "dir", "gleich", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PIS", "PPER", "$.", "ADV", "KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.362": {"text": "Di\u00df alles nicht geschehn/ so kan man doch noch h\u00f6ren", "tokens": ["Di\u00df", "al\u00b7les", "nicht", "ge\u00b7schehn", "/", "so", "kan", "man", "doch", "noch", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "PTKNEG", "VVINF", "$(", "ADV", "VMFIN", "PIS", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.363": {"text": "Dein Lob in aller Welt/ da\u00df du ein G\u00f6ttlich Werck", "tokens": ["Dein", "Lob", "in", "al\u00b7ler", "Welt", "/", "da\u00df", "du", "ein", "G\u00f6tt\u00b7lich", "Werck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "NN", "$(", "KOUS", "PPER", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.364": {"text": "uns habest auffgebracht/ du edler Guttenberg.", "tokens": ["uns", "ha\u00b7best", "auff\u00b7ge\u00b7bracht", "/", "du", "ed\u00b7ler", "Gut\u00b7ten\u00b7berg", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.365": {"text": "Es wird auch wol dein Lob/ weil Menschen seyn/ bekleiben/", "tokens": ["Es", "wird", "auch", "wol", "dein", "Lob", "/", "weil", "Men\u00b7schen", "seyn", "/", "be\u00b7klei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPOSAT", "NN", "$(", "KOUS", "NN", "VAINF", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.366": {"text": "Dein Nahme nicht vergehn/ so lange man wird schreiben/", "tokens": ["Dein", "Nah\u00b7me", "nicht", "ver\u00b7gehn", "/", "so", "lan\u00b7ge", "man", "wird", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$(", "ADV", "ADV", "PIS", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.367": {"text": "So lang' uns ein Magnet die Zeit und Stunde sagt/", "tokens": ["So", "lang'", "uns", "ein", "Mag\u00b7net", "die", "Zeit", "und", "Stun\u00b7de", "sagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.368": {"text": "und zeigt wo Wind und Fluth das schwache Schiff hinjagt/", "tokens": ["und", "zeigt", "wo", "Wind", "und", "Fluth", "das", "schwa\u00b7che", "Schiff", "hin\u00b7jagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWAV", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.369": {"text": "Auch wohl bey finstrer Nacht. Man wird an dich gedencken/", "tokens": ["Auch", "wohl", "bey", "finst\u00b7rer", "Nacht", ".", "Man", "wird", "an", "dich", "ge\u00b7den\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "$.", "PIS", "VAFIN", "APPR", "PPER", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.370": {"text": "So offt man alle M\u00fch und Sorgen wird versencken", "tokens": ["So", "offt", "man", "al\u00b7le", "M\u00fch", "und", "Sor\u00b7gen", "wird", "ver\u00b7sen\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "PIAT", "NN", "KON", "NN", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.371": {"text": "In manches sch\u00f6nes Buch/ so lang' in vollem Schein", "tokens": ["In", "man\u00b7ches", "sch\u00f6\u00b7nes", "Buch", "/", "so", "lang'", "in", "vol\u00b7lem", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$(", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.372": {"text": "die g\u00fcldne Sonne steht/ wird deine Kunst auch seyn.", "tokens": ["die", "g\u00fcld\u00b7ne", "Son\u00b7ne", "steht", "/", "wird", "dei\u00b7ne", "Kunst", "auch", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "VAFIN", "PPOSAT", "NN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.373": {"text": "Nun weil mein schwaches Schiff den sichern Hafen sihet/", "tokens": ["Nun", "weil", "mein", "schwa\u00b7ches", "Schiff", "den", "si\u00b7chern", "Ha\u00b7fen", "si\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.374": {"text": "So werff ich Ancker ein und bin itzund bem\u00fchet", "tokens": ["So", "werff", "ich", "An\u00b7cker", "ein", "und", "bin", "it\u00b7zund", "be\u00b7m\u00fc\u00b7het"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "KON", "VAFIN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.375": {"text": "Zu enden mein Gedicht auff dessen Nahmens Ehr/", "tokens": ["Zu", "en\u00b7den", "mein", "Ge\u00b7dicht", "auff", "des\u00b7sen", "Nah\u00b7mens", "Ehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "APPR", "PRELAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.376": {"text": "Der uns gef\u00fchret hat und f\u00fchrt je mehr und mehr.", "tokens": ["Der", "uns", "ge\u00b7f\u00fch\u00b7ret", "hat", "und", "f\u00fchrt", "je", "mehr", "und", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "KON", "VVFIN", "ADV", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.377": {"text": "Hier denck ich auff dein Lob und dieses zu beschreiben/", "tokens": ["Hier", "denck", "ich", "auff", "dein", "Lob", "und", "die\u00b7ses", "zu", "be\u00b7schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "PDS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.378": {"text": "Soll itzt und immerfort mein Geist bem\u00fchet bleiben/", "tokens": ["Soll", "itzt", "und", "im\u00b7mer\u00b7fort", "mein", "Geist", "be\u00b7m\u00fc\u00b7het", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "KON", "ADV", "PPOSAT", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.379": {"text": "O Gott du Quell der Kunst; du Gnaden-Vater Du/", "tokens": ["O", "Gott", "du", "Quell", "der", "Kunst", ";", "du", "Gna\u00b7den\u00b7Va\u00b7ter", "Du", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "NN", "ART", "NN", "$.", "PPER", "NN", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.380": {"text": "Dir dancken wir anitzt und loben immerzu", "tokens": ["Dir", "dan\u00b7cken", "wir", "a\u00b7nitzt", "und", "lo\u00b7ben", "im\u00b7mer\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.381": {"text": "Dein gro\u00dfes Gnaden-Werck; da\u00df Du uns hast gewiesen", "tokens": ["Dein", "gro\u00b7\u00dfes", "Gna\u00b7den\u00b7\u00b7Werck", ";", "da\u00df", "Du", "uns", "hast", "ge\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "KOUS", "PPER", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.382": {"text": "Die edle Dr\u00fccker-Kunst/ die noch nicht gnug gepriesen", "tokens": ["Die", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "die", "noch", "nicht", "gnug", "ge\u00b7prie\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADV", "PTKNEG", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.383": {"text": "So als sie w\u00fcrdig ist: Hast sie zweyhundert Jahr", "tokens": ["So", "als", "sie", "w\u00fcr\u00b7dig", "ist", ":", "Hast", "sie", "zwey\u00b7hun\u00b7dert", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VAFIN", "$.", "VAFIN", "PPER", "CARD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.384": {"text": "Erhalten und gemehrt/ Du hast uns hell und klar", "tokens": ["Er\u00b7hal\u00b7ten", "und", "ge\u00b7mehrt", "/", "Du", "hast", "uns", "hell", "und", "klar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "$(", "PPER", "VAFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.385": {"text": "Durch sie dein Wort geschenckt. Ach! Vater/ la\u00df doch scheinen", "tokens": ["Durch", "sie", "dein", "Wort", "ge\u00b7schenckt", ".", "Ach", "!", "Va\u00b7ter", "/", "la\u00df", "doch", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "PPOSAT", "NN", "VVPP", "$.", "ITJ", "$.", "NN", "$(", "VVIMP", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.386": {"text": "Die Fackel deines Worts; Erhalte sie den Deinen", "tokens": ["Die", "Fa\u00b7ckel", "dei\u00b7nes", "Worts", ";", "Er\u00b7hal\u00b7te", "sie", "den", "Dei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "ART", "PPOSAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.387": {"text": "Noch ferner hell und klar. Erzeig' uns deine Gunst/", "tokens": ["Noch", "fer\u00b7ner", "hell", "und", "klar", ".", "Er\u00b7zeig'", "uns", "dei\u00b7ne", "Gunst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADJD", "$.", "NN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.388": {"text": "La\u00df bl\u00fchen f\u00fcr und f\u00fcr die edle Dr\u00fccker-Kunst.", "tokens": ["La\u00df", "bl\u00fc\u00b7hen", "f\u00fcr", "und", "f\u00fcr", "die", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "APPR", "KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.389": {"text": "Ach! gib uns doch einmahl den lang-gew\u00fcntschten Frieden/", "tokens": ["Ach", "!", "gib", "uns", "doch", "ein\u00b7mahl", "den", "lang\u00b7ge\u00b7w\u00fcntschten", "Frie\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVIMP", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.390": {"text": "Ach! Vater bistu dann/ Ach! bistu dann geschieden", "tokens": ["Ach", "!", "Va\u00b7ter", "bis\u00b7tu", "dann", "/", "Ach", "!", "bis\u00b7tu", "dann", "ge\u00b7schie\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$.", "NN", "ADV", "ADV", "$(", "ITJ", "$.", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.391": {"text": "Von deiner Christenheit? Ach! h\u00f6restu denn nicht/", "tokens": ["Von", "dei\u00b7ner", "Chris\u00b7ten\u00b7heit", "?", "Ach", "!", "h\u00f6\u00b7res\u00b7tu", "denn", "nicht", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ITJ", "$.", "VVFIN", "ADV", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.392": {"text": "Was itzt dein liebes Volck in letzten Z\u00fcgen spricht?", "tokens": ["Was", "itzt", "dein", "lie\u00b7bes", "Volck", "in", "letz\u00b7ten", "Z\u00fc\u00b7gen", "spricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.393": {"text": "Ach! h\u00f6re/ h\u00f6re doch/ und la\u00df uns einmahl blicken", "tokens": ["Ach", "!", "h\u00f6\u00b7re", "/", "h\u00f6\u00b7re", "doch", "/", "und", "la\u00df", "uns", "ein\u00b7mahl", "bli\u00b7cken"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VVFIN", "$(", "VVFIN", "ADV", "$(", "KON", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.394": {"text": "Dein Gnaden-Angesicht/ da\u00df wir uns auch erquicken", "tokens": ["Dein", "Gna\u00b7den\u00b7An\u00b7ge\u00b7sicht", "/", "da\u00df", "wir", "uns", "auch", "er\u00b7qui\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "KOUS", "PPER", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.395": {"text": "und loben Dich daf\u00fcr/ Ach! nim das schwere Joch", "tokens": ["und", "lo\u00b7ben", "Dich", "da\u00b7f\u00fcr", "/", "Ach", "!", "nim", "das", "schwe\u00b7re", "Joch"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PAV", "$(", "ITJ", "$.", "VVIMP", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.396": {"text": "Von unsern Achseln hin: Ach! h\u00f6re/ h\u00f6re doch!", "tokens": ["Von", "un\u00b7sern", "Ach\u00b7seln", "hin", ":", "Ach", "!", "h\u00f6\u00b7re", "/", "h\u00f6\u00b7re", "doch", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$.", "ITJ", "$.", "VVFIN", "$(", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich der ich fl\u00fcgen lie\u00df vor zweyen Jahres-Zeiten", "tokens": ["Ich", "der", "ich", "fl\u00fc\u00b7gen", "lie\u00df", "vor", "zwe\u00b7yen", "Jah\u00b7res\u00b7Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "PPER", "VVINF", "VVFIN", "APPR", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Feder in dein Lob und r\u00fchmte dich von weiten/", "tokens": ["Die", "Fe\u00b7der", "in", "dein", "Lob", "und", "r\u00fchm\u00b7te", "dich", "von", "wei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du edle Dr\u00fccker-Kunst/ bin itzund auch bedacht/", "tokens": ["Du", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "bin", "it\u00b7zund", "auch", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie doch dein ursprung nur werd' offenbahr gemacht:", "tokens": ["Wie", "doch", "dein", "ur\u00b7sprung", "nur", "werd'", "of\u00b7fen\u00b7bahr", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "ADV", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wil durch diesen Mund die bl\u00f6den Menschen lehren/", "tokens": ["Ich", "wil", "durch", "die\u00b7sen", "Mund", "die", "bl\u00f6\u00b7den", "Men\u00b7schen", "leh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PDAT", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die noch nicht Menschen sind/ wie sie dich sollen ehren;", "tokens": ["Die", "noch", "nicht", "Men\u00b7schen", "sind", "/", "wie", "sie", "dich", "sol\u00b7len", "eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "NN", "VAFIN", "$(", "PWAV", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch diesen meinen Mund der sich was schwach befindt/", "tokens": ["Durch", "die\u00b7sen", "mei\u00b7nen", "Mund", "der", "sich", "was", "schwach", "be\u00b7findt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PPOSAT", "NN", "ART", "PRF", "PWS", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dr\u00fcm/ Clio/ ruff' ich dier/ du sch\u00f6nes Musen-Kind/", "tokens": ["Dr\u00fcm", "/", "Clio", "/", "ruff'", "ich", "dier", "/", "du", "sch\u00f6\u00b7nes", "Mu\u00b7sen\u00b7Kind", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "VVFIN", "PPER", "PPER", "$(", "PPER", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Komm/ komm und hilff mir auff; flicht aus die g\u00fcldnen Z\u00f6pffe/", "tokens": ["Komm", "/", "komm", "und", "hilff", "mir", "auff", ";", "flicht", "aus", "die", "g\u00fcld\u00b7nen", "Z\u00f6pf\u00b7fe", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "KON", "NN", "PPER", "PTKVZ", "$.", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df Zephyr spielen mag und ich die Kr\u00e4ffte sch\u00f6pffe;", "tokens": ["Da\u00df", "Ze\u00b7phyr", "spie\u00b7len", "mag", "und", "ich", "die", "Kr\u00e4ff\u00b7te", "sch\u00f6pf\u00b7fe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "VMFIN", "KON", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wenn er von dier auff mich den feuchten Nectar weht/", "tokens": ["Wenn", "er", "von", "dier", "auff", "mich", "den", "feuch\u00b7ten", "Nec\u00b7tar", "weht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So wei\u00df ich da\u00df es mier gew\u00fcndscht von statten geht.", "tokens": ["So", "wei\u00df", "ich", "da\u00df", "es", "mier", "ge\u00b7w\u00fcnd\u00b7scht", "von", "stat\u00b7ten", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PPER", "PPER", "VVPP", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Komm balde/ denn ich wil von solchen Sachen reden/", "tokens": ["Komm", "bal\u00b7de", "/", "denn", "ich", "wil", "von", "sol\u00b7chen", "Sa\u00b7chen", "re\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "KON", "PPER", "VMFIN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die h\u00f6her seyn als hoch; nicht wie uns Arme Bl\u00f6den", "tokens": ["Die", "h\u00f6\u00b7her", "seyn", "als", "hoch", ";", "nicht", "wie", "uns", "Ar\u00b7me", "Bl\u00f6\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VAINF", "KOKOM", "ADJD", "$.", "PTKNEG", "PWAV", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der kleine Hertzen-Sch\u00fctz aus Paphos f\u00e4llen kann;", "tokens": ["Der", "klei\u00b7ne", "Hert\u00b7zen\u00b7Sch\u00fctz", "aus", "Pa\u00b7phos", "f\u00e4l\u00b7len", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Nicht wie Callicrates der Kunst-erfahrne Mann", "tokens": ["Nicht", "wie", "Cal\u00b7li\u00b7cra\u00b7tes", "der", "Kunst\u00b7er\u00b7fahr\u00b7ne", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "KOKOM", "NE", "ART", "NN", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "Sein Wunder-schiff gemacht; Wil nicht den Ruhm erlangen", "tokens": ["Sein", "Wun\u00b7der\u00b7schiff", "ge\u00b7macht", ";", "Wil", "nicht", "den", "Ruhm", "er\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP", "$.", "VMFIN", "PTKNEG", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Venus Bild/ das einst Apelles angefangen/", "tokens": ["Der", "Ve\u00b7nus", "Bild", "/", "das", "einst", "A\u00b7pel\u00b7les", "an\u00b7ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "PDS", "ADV", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Nach ihm zu mahlen aus; Es soll Hymettus nicht/", "tokens": ["Nach", "ihm", "zu", "mah\u00b7len", "aus", ";", "Es", "soll", "Hy\u00b7met\u00b7tus", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "PTKVZ", "$.", "PPER", "VMFIN", "NE", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Noch seine sch\u00f6nste Lust hier werden mein Gedicht;", "tokens": ["Noch", "sei\u00b7ne", "sch\u00f6ns\u00b7te", "Lust", "hier", "wer\u00b7den", "mein", "Ge\u00b7dicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zumahl weil Maro sie mit seiner scharffen Zungen", "tokens": ["Zu\u00b7mahl", "weil", "Ma\u00b7ro", "sie", "mit", "sei\u00b7ner", "scharf\u00b7fen", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NE", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "An Minces ufer schon hat zweymahl hergesungen:", "tokens": ["An", "Min\u00b7ces", "u\u00b7fer", "schon", "hat", "zwey\u00b7mahl", "her\u00b7ge\u00b7sun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ich wil auch sagen nicht von Cocos aus Zebuth/", "tokens": ["Ich", "wil", "auch", "sa\u00b7gen", "nicht", "von", "Co\u00b7cos", "aus", "Ze\u00b7buth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "PTKNEG", "APPR", "NE", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dem Wunder-Baum und Stamm/ von dem man Rebenblut/", "tokens": ["Dem", "Wun\u00b7der\u00b7Baum", "und", "Stamm", "/", "von", "dem", "man", "Re\u00b7ben\u00b7blut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$(", "APPR", "PRELS", "PIS", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Oehl/ Butter/ Linnewand und Essig kan geniessen/", "tokens": ["O\u00b7ehl", "/", "But\u00b7ter", "/", "Lin\u00b7ne\u00b7wand", "und", "Es\u00b7sig", "kan", "ge\u00b7nies\u00b7sen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NE", "KON", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.26": {"text": "Ja Zucker noch dazu: Auch wil ich nicht vergiessen", "tokens": ["Ja", "Zu\u00b7cker", "noch", "da\u00b7zu", ":", "Auch", "wil", "ich", "nicht", "ver\u00b7gies\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "NN", "ADV", "PAV", "$.", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die Thr\u00e4nen \u00fcber dich/ du edles Vater-Land/", "tokens": ["Die", "Thr\u00e4\u00b7nen", "\u00fc\u00b7ber", "dich", "/", "du", "ed\u00b7les", "Va\u00b7ter\u00b7Land", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Das von sich selbsten itzt fast nicht mehr wird erkant/", "tokens": ["Das", "von", "sich", "selbs\u00b7ten", "itzt", "fast", "nicht", "mehr", "wird", "er\u00b7kant", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PRF", "VVFIN", "ADV", "ADV", "PTKNEG", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So als es \u00f6de steht. Di\u00df alles bleibt verschwiegen", "tokens": ["So", "als", "es", "\u00f6\u00b7de", "steht", ".", "Di\u00df", "al\u00b7les", "bleibt", "ver\u00b7schwie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVFIN", "$.", "PDS", "PIS", "VVFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Von mir auff dieses mahl; Ich la\u00dfe mir gen\u00fcgen/", "tokens": ["Von", "mir", "auff", "die\u00b7ses", "mahl", ";", "Ich", "la\u00b7\u00dfe", "mir", "ge\u00b7n\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "PDAT", "ADV", "$.", "PPER", "VVFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wenn ich nur reden mag nach Zierligkeit von Dier/", "tokens": ["Wenn", "ich", "nur", "re\u00b7den", "mag", "nach", "Zier\u00b7lig\u00b7keit", "von", "Dier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "APPR", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Du edle Dr\u00fccker-Kunst. Dr\u00fcm/ Clio/ meine Zier/", "tokens": ["Du", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", ".", "Dr\u00fcm", "/", "Clio", "/", "mei\u00b7ne", "Zier", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$.", "NN", "$(", "NE", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.33": {"text": "Geruhe doch Entsatz und Worte zu zuschicken/", "tokens": ["Ge\u00b7ru\u00b7he", "doch", "Ent\u00b7satz", "und", "Wor\u00b7te", "zu", "zu\u00b7schi\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "KON", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Wann mir der Mund besteht: Ach! la\u00df mich doch erblicken", "tokens": ["Wann", "mir", "der", "Mund", "be\u00b7steht", ":", "Ach", "!", "la\u00df", "mich", "doch", "er\u00b7bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$.", "ITJ", "$.", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Dein G\u00f6ttlich Angesicht; Dier fleh ich noch einmahl", "tokens": ["Dein", "G\u00f6tt\u00b7lich", "An\u00b7ge\u00b7sicht", ";", "Dier", "fleh", "ich", "noch", "ein\u00b7mahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "$.", "PDS", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Gib/ da\u00df ich zieren mag mit Reden diesen Saal.", "tokens": ["Gib", "/", "da\u00df", "ich", "zie\u00b7ren", "mag", "mit", "Re\u00b7den", "die\u00b7sen", "Saal", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$(", "KOUS", "PPER", "VVINF", "VMFIN", "APPR", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Komt auch und h\u00f6rt mir zu/ Ihr tr\u00e4fflichen Elbinnen/", "tokens": ["Komt", "auch", "und", "h\u00f6rt", "mir", "zu", "/", "Ihr", "tr\u00e4ff\u00b7li\u00b7chen", "El\u00b7bin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "PPER", "PTKZU", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Komm Hamburg/ komm heran und h\u00f6re mein Beginnen/", "tokens": ["Komm", "Ham\u00b7burg", "/", "komm", "he\u00b7ran", "und", "h\u00f6\u00b7re", "mein", "Be\u00b7gin\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "La\u00df deine Schiffe stehn am blancken Elben-Stroom/", "tokens": ["La\u00df", "dei\u00b7ne", "Schif\u00b7fe", "stehn", "am", "blan\u00b7cken", "El\u00b7ben\u00b7Stroom", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "VVFIN", "APPRART", "ADJA", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "So lange/ bi\u00df ich das/ was noch Athen und Room/", "tokens": ["So", "lan\u00b7ge", "/", "bi\u00df", "ich", "das", "/", "was", "noch", "A\u00b7then", "und", "Room", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "KOUS", "PPER", "ART", "$(", "PWS", "ADV", "NE", "KON", "NE", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.41": {"text": "Wie hoch sie fl\u00fcgen/ trotzt/ urspr\u00fcnglich dier entdecket/", "tokens": ["Wie", "hoch", "sie", "fl\u00fc\u00b7gen", "/", "trotzt", "/", "ur\u00b7spr\u00fcng\u00b7lich", "dier", "ent\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVINF", "$(", "VVFIN", "$(", "ADJD", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Die edle Dr\u00fccker-Kunst/ vor der der Pabst erschrecket", "tokens": ["Die", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "vor", "der", "der", "Pabst", "er\u00b7schre\u00b7cket"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "APPR", "ART", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Auff seiner Siebenburg: La\u00dft eurer Presse Ruh/", "tokens": ["Auff", "sei\u00b7ner", "Sie\u00b7ben\u00b7burg", ":", "La\u00dft", "eu\u00b7rer", "Pres\u00b7se", "Ruh", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "VVIMP", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Ihr edlen Drucker Ihr und h\u00f6rt ein wenig zu/", "tokens": ["Ihr", "ed\u00b7len", "Dru\u00b7cker", "Ihr", "und", "h\u00f6rt", "ein", "we\u00b7nig", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "KON", "VVFIN", "ART", "PIS", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Merckt/ merckt auff meine Wort/ weil ich vornemlich preise:", "tokens": ["Merckt", "/", "merckt", "auff", "mei\u00b7ne", "Wort", "/", "weil", "ich", "vor\u00b7nem\u00b7lich", "prei\u00b7se", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Die G\u00f6tter-gleiche Kunst und ihren Ursprung weise;", "tokens": ["Die", "G\u00f6t\u00b7ter\u00b7glei\u00b7che", "Kunst", "und", "ih\u00b7ren", "Ur\u00b7sprung", "wei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Die euch zu Ehren setzt/ die euch ber\u00fchmet macht/", "tokens": ["Die", "euch", "zu", "Eh\u00b7ren", "setzt", "/", "die", "euch", "be\u00b7r\u00fch\u00b7met", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$(", "PRELS", "PPER", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Die alle K\u00fcnstler trotzt und reisst hin aus der Nacht", "tokens": ["Die", "al\u00b7le", "K\u00fcnst\u00b7ler", "trotzt", "und", "reisst", "hin", "aus", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVFIN", "KON", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Zur grauen Ewigkeit. Di\u00df Lob la\u00dft euch gefallen/", "tokens": ["Zur", "grau\u00b7en", "E\u00b7wig\u00b7keit", ".", "Di\u00df", "Lob", "la\u00dft", "euch", "ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$.", "PDS", "NN", "VVFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Das durch das Deutsche Reich anitzo wird erschallen/", "tokens": ["Das", "durch", "das", "Deut\u00b7sche", "Reich", "a\u00b7nit\u00b7zo", "wird", "er\u00b7schal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "ADV", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "und das \u00fcm desto mehr/ weil keiner di\u00df gethan", "tokens": ["und", "das", "\u00fcm", "des\u00b7to", "mehr", "/", "weil", "kei\u00b7ner", "di\u00df", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "ADV", "$(", "KOUS", "PIS", "PDS", "VVPP"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.52": {"text": "Vor mir in dieser Stadt/ merckt auff/ nun fang' ich an.", "tokens": ["Vor", "mir", "in", "die\u00b7ser", "Stadt", "/", "merckt", "auff", "/", "nun", "fang'", "ich", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "PDAT", "NN", "$(", "VVFIN", "APPR", "$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Als vierzehn hundert Jahr und viertzig war verflossen", "tokens": ["Als", "vier\u00b7zehn", "hun\u00b7dert", "Jahr", "und", "viert\u00b7zig", "war", "ver\u00b7flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "CARD", "CARD", "NN", "KON", "CARD", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Nach unser Christ-Geburt/ war Gott der Herr entschlossen", "tokens": ["Nach", "un\u00b7ser", "Christ\u00b7Ge\u00b7burt", "/", "war", "Gott", "der", "Herr", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NE", "$(", "VAFIN", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Sein Wort zu breiten aus: Es war fast auff der Bahn/", "tokens": ["Sein", "Wort", "zu", "brei\u00b7ten", "aus", ":", "Es", "war", "fast", "auff", "der", "Bahn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Den Hu\u00df im Geiste sah/ der theure Wunder-Schwaan.", "tokens": ["Den", "Hu\u00df", "im", "Geis\u00b7te", "sah", "/", "der", "theu\u00b7re", "Wun\u00b7der\u00b7Schwaan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Der Keyser Albrecht starb der Ander so genennet/", "tokens": ["Der", "Key\u00b7ser", "Al\u00b7brecht", "starb", "der", "An\u00b7der", "so", "ge\u00b7nen\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Drauff Friederich der Dritt' als Keyser ward erkennet;", "tokens": ["Drauff", "Frie\u00b7de\u00b7rich", "der", "Dritt'", "als", "Key\u00b7ser", "ward", "er\u00b7ken\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "ART", "NN", "KOUS", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Im ebenselben Jahr ward uns die Dr\u00fcckerey", "tokens": ["Im", "e\u00b7ben\u00b7sel\u00b7ben", "Jahr", "ward", "uns", "die", "Dr\u00fc\u00b7cke\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Von Gott geschenckt/ da\u00df sie der K\u00fcnste Mutter sey.", "tokens": ["Von", "Gott", "ge\u00b7schenckt", "/", "da\u00df", "sie", "der", "K\u00fcns\u00b7te", "Mut\u00b7ter", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$(", "KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "O F\u00fcrstin aller Kunst/ Du aller Lehrer Amme/", "tokens": ["O", "F\u00fcrs\u00b7tin", "al\u00b7ler", "Kunst", "/", "Du", "al\u00b7ler", "Leh\u00b7rer", "Am\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PIAT", "NN", "$(", "PPER", "PIAT", "NN", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Durch dich hat Gott gezeigt im Dunckeln seine Flamme/", "tokens": ["Durch", "dich", "hat", "Gott", "ge\u00b7zeigt", "im", "Dun\u00b7ckeln", "sei\u00b7ne", "Flam\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "NN", "VVPP", "APPRART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Die Fackel seines Worts. Wer hat dich dann erdacht?", "tokens": ["Die", "Fa\u00b7ckel", "sei\u00b7nes", "Worts", ".", "Wer", "hat", "dich", "dann", "er\u00b7dacht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Wer hat ein solches Werck mit kluger Hand gemacht?", "tokens": ["Wer", "hat", "ein", "sol\u00b7ches", "Werck", "mit", "klu\u00b7ger", "Hand", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "PIAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Und wo ist das geschehn? Ists Phidias gewesen", "tokens": ["Und", "wo", "ist", "das", "ge\u00b7schehn", "?", "Ists", "Phi\u00b7di\u00b7as", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "VAFIN", "PDS", "VVINF", "$.", "NE", "NE", "VAPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Der K\u00fcnstler von Athen? von dem man noch kan lesen/", "tokens": ["Der", "K\u00fcnst\u00b7ler", "von", "A\u00b7then", "?", "von", "dem", "man", "noch", "kan", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$.", "APPR", "PRELS", "PIS", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.67": {"text": "Da\u00df er Minerven Bild neun Klafftern hoch gemacht", "tokens": ["Da\u00df", "er", "Mi\u00b7ner\u00b7ven", "Bild", "neun", "Klaff\u00b7tern", "hoch", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "NN", "CARD", "NN", "ADJD", "VVPP"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.68": {"text": "Au\u00df Gold und Helffenbein und in das Schild die Schlacht", "tokens": ["Au\u00df", "Gold", "und", "Helf\u00b7fen\u00b7bein", "und", "in", "das", "Schild", "die", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Der Amazonen grub? Sol man es dier zumessen/", "tokens": ["Der", "A\u00b7maz\u00b7o\u00b7nen", "grub", "?", "Sol", "man", "es", "dier", "zu\u00b7mes\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VMFIN", "PIS", "PPER", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Lysippus/ weil nur dir dein K\u00f6nig ist gesessen", "tokens": ["Ly\u00b7sip\u00b7pus", "/", "weil", "nur", "dir", "dein", "K\u00f6\u00b7nig", "ist", "ge\u00b7ses\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "KOUS", "ADV", "PPER", "PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Sein Bild zu bilden ab? Praxiteles vielleicht/", "tokens": ["Sein", "Bild", "zu", "bil\u00b7den", "ab", "?", "Pra\u00b7xi\u00b7te\u00b7les", "viel\u00b7leicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "PTKVZ", "$.", "NE", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "In dessen Venus sich/ dem keines sonsten gleicht/", "tokens": ["In", "des\u00b7sen", "Ve\u00b7nus", "sich", "/", "dem", "kei\u00b7nes", "sons\u00b7ten", "gleicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PRF", "$(", "ART", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Ein J\u00fcngling hat verliebt? Hats Daedalus erfunden?", "tokens": ["Ein", "J\u00fcng\u00b7ling", "hat", "ver\u00b7liebt", "?", "Hats", "Dae\u00b7da\u00b7lus", "er\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "NE", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Der sonst das Labyrinth zur ungl\u00fcckhafften Stunden", "tokens": ["Der", "sonst", "das", "La\u00b7by\u00b7rinth", "zur", "un\u00b7gl\u00fcck\u00b7haff\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Ihm selbst und seinem Sohn' in Creta hat gemacht/", "tokens": ["Ihm", "selbst", "und", "sei\u00b7nem", "Sohn'", "in", "Cre\u00b7ta", "hat", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "PPOSAT", "NN", "APPR", "NE", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Daraus er wieder\u00fcm mit Fl\u00fcgeln ward gebracht/", "tokens": ["Da\u00b7raus", "er", "wie\u00b7de\u00b7r\u00fcm", "mit", "Fl\u00fc\u00b7geln", "ward", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Die Kunst ihm angesetzt? Hastu es dann ersonnen/", "tokens": ["Die", "Kunst", "ihm", "an\u00b7ge\u00b7setzt", "?", "Has\u00b7tu", "es", "dann", "er\u00b7son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "$.", "NE", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Perillus? oder wie? hat sich von dir entsponnen/", "tokens": ["Pe\u00b7ril\u00b7lus", "?", "o\u00b7der", "wie", "?", "hat", "sich", "von", "dir", "ent\u00b7spon\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KON", "PWAV", "$.", "VAFIN", "PRF", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.79": {"text": "Epeus/ diese Kunst? Ists Alcman ein Poet/", "tokens": ["E\u00b7peus", "/", "die\u00b7se", "Kunst", "?", "Ists", "A\u00b7lcman", "ein", "Po\u00b7et", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PDAT", "NN", "$.", "NE", "NE", "ART", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.80": {"text": "Der erste/ der ein Lied von Liebes-Lust anf\u00e4ht?", "tokens": ["Der", "ers\u00b7te", "/", "der", "ein", "Lied", "von", "Lie\u00b7bes\u00b7Lust", "an\u00b7f\u00e4ht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ART", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Dem man so emsig folgt? Sol Palamedes lehren", "tokens": ["Dem", "man", "so", "em\u00b7sig", "folgt", "?", "Sol", "Pa\u00b7la\u00b7me\u00b7des", "leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "ADJD", "VVFIN", "$.", "VMFIN", "NN", "VVINF"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.82": {"text": "Die sch\u00f6ne Dr\u00fccker-Kunst/ von dem wir sehn und h\u00f6ren/", "tokens": ["Die", "sch\u00f6\u00b7ne", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "von", "dem", "wir", "sehn", "und", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "APPR", "PRELS", "PPER", "VVINF", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Da\u00df er das Abece geordnet auff ein Schild?", "tokens": ["Da\u00df", "er", "das", "A\u00b7be\u00b7ce", "ge\u00b7ord\u00b7net", "auff", "ein", "Schild", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Ists dann Pyrgoteles/ der Alexanders Bild", "tokens": ["Ists", "dann", "Pyr\u00b7go\u00b7te\u00b7les", "/", "der", "A\u00b7lex\u00b7an\u00b7ders", "Bild"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NE", "$(", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "In Perlen graben mag? Nein/ nein! hier ist es keiner/", "tokens": ["In", "Per\u00b7len", "gra\u00b7ben", "mag", "?", "Nein", "/", "nein", "!", "hier", "ist", "es", "kei\u00b7ner", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VMFIN", "$.", "PTKANT", "$(", "PTKANT", "$.", "ADV", "VAFIN", "PPER", "PIS", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Die Deutschen \u00fcbergehn die Griechen und Lateiner.", "tokens": ["Die", "Deut\u00b7schen", "\u00fc\u00b7ber\u00b7gehn", "die", "Grie\u00b7chen", "und", "La\u00b7tei\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Schweig/ Anagallis/ still/ die du dein Ebenbild/", "tokens": ["Schweig", "/", "A\u00b7na\u00b7gal\u00b7lis", "/", "still", "/", "die", "du", "dein", "E\u00b7ben\u00b7bild", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "ADJD", "$(", "PRELS", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Das Ballen-Spiel erdacht: Ertichte was du wilt/", "tokens": ["Das", "Bal\u00b7len\u00b7Spiel", "er\u00b7dacht", ":", "Er\u00b7tich\u00b7te", "was", "du", "wilt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "VVFIN", "PWS", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Du frische Thymele; Den Deutschen m\u00fcsst ihr weichen", "tokens": ["Du", "fri\u00b7sche", "Thy\u00b7me\u00b7le", ";", "Den", "Deut\u00b7schen", "m\u00fcsst", "ihr", "wei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$.", "ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Ihr K\u00fcnstler von Athen/ Ihr Griechen m\u00fcsst verbleichen;", "tokens": ["Ihr", "K\u00fcnst\u00b7ler", "von", "A\u00b7then", "/", "Ihr", "Grie\u00b7chen", "m\u00fcsst", "ver\u00b7blei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "$(", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.91": {"text": "Du gro\u00dfes China du/ du r\u00fchmest dich \u00fcmsunst/", "tokens": ["Du", "gro\u00b7\u00dfes", "Chi\u00b7na", "du", "/", "du", "r\u00fch\u00b7mest", "dich", "\u00fcm\u00b7sunst", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NE", "NE", "$(", "PPER", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Auch hast du/ Franckreich/ nicht erfunden diese Kunst.", "tokens": ["Auch", "hast", "du", "/", "Fran\u00b7ck\u00b7reich", "/", "nicht", "er\u00b7fun\u00b7den", "die\u00b7se", "Kunst", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "NE", "$(", "PTKNEG", "VVPP", "PDAT", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.93": {"text": "Ihr Niederl\u00e4nder ihr la\u00dft euer Harlem schweigen/", "tokens": ["Ihr", "Nie\u00b7der\u00b7l\u00e4n\u00b7der", "ihr", "la\u00dft", "eu\u00b7er", "Har\u00b7lem", "schwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Auch Welschland kan uns nicht den urerfinder zeigen.", "tokens": ["Auch", "Wel\u00b7schland", "kan", "uns", "nicht", "den", "ur\u00b7er\u00b7fin\u00b7der", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "PPER", "PTKNEG", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Kommt/ nehmt uns dieses Lob: Johannes Guttenberg/", "tokens": ["Kommt", "/", "nehmt", "uns", "die\u00b7ses", "Lob", ":", "Jo\u00b7han\u00b7nes", "Gut\u00b7ten\u00b7berg", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "PPER", "PDAT", "NN", "$.", "NE", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Ein Mann von edlem Stamm bringt auff das Drucker-Werck/", "tokens": ["Ein", "Mann", "von", "ed\u00b7lem", "Stamm", "bringt", "auff", "das", "Dru\u00b7cke\u00b7r\u00b7Werck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.97": {"text": "Zu Meyntz im Deutschen Reich; Er hilft mit scharffen Sinnen", "tokens": ["Zu", "Meyntz", "im", "Deut\u00b7schen", "Reich", ";", "Er", "hilft", "mit", "scharf\u00b7fen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPRART", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Was Peter Sch\u00f6fer hier und Faust zu erst beginnen;", "tokens": ["Was", "Pe\u00b7ter", "Sch\u00f6\u00b7fer", "hier", "und", "Faust", "zu", "erst", "be\u00b7gin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NE", "ADV", "KON", "NN", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Was sonst Hans M\u00e4ntelin zu Stra\u00dfburg hat erdacht", "tokens": ["Was", "sonst", "Hans", "M\u00e4n\u00b7te\u00b7lin", "zu", "Stra\u00df\u00b7burg", "hat", "er\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "NE", "NE", "APPR", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "und (wie man wil) von dar Hans Gense-Fleisch gebracht", "tokens": ["und", "(", "wie", "man", "wil", ")", "von", "dar", "Hans", "Gen\u00b7se\u00b7Fleisch", "ge\u00b7bracht"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "PWAV", "PIS", "VMFIN", "$(", "APPR", "NE", "NE", "NE", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "An vorermeldten Ort/ Den billich wir erkennen", "tokens": ["An", "vor\u00b7er\u00b7meld\u00b7ten", "Ort", "/", "Den", "bil\u00b7lich", "wir", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$(", "ART", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Vor unsre Schreiber-Stadt und Kirjath-Sepher nennen/", "tokens": ["Vor", "uns\u00b7re", "Schrei\u00b7ber\u00b7Stadt", "und", "Kir\u00b7ja\u00b7th\u00b7Se\u00b7pher", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+--", "measure": "unknown.measure.hexa"}, "line.103": {"text": "Weil da der erste Pfeil aus Dinten ward gemacht/", "tokens": ["Weil", "da", "der", "ers\u00b7te", "Pfeil", "aus", "Din\u00b7ten", "ward", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Weil Sie die Dr\u00fccker-Kunst zum ersten ausgebracht/", "tokens": ["Weil", "Sie", "die", "Dr\u00fc\u00b7cker\u00b7Kunst", "zum", "ers\u00b7ten", "aus\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "ADJA", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Da\u00df sie nunmehr bey uns so sch\u00f6n und herrlich bl\u00fchet;", "tokens": ["Da\u00df", "sie", "nun\u00b7mehr", "bey", "uns", "so", "sch\u00f6n", "und", "herr\u00b7lich", "bl\u00fc\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Da Guttenberg sich erst so trefflich hat bem\u00fchet;", "tokens": ["Da", "Gut\u00b7ten\u00b7berg", "sich", "erst", "so", "treff\u00b7lich", "hat", "be\u00b7m\u00fc\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "ADV", "ADV", "ADJD", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Er macht' erst breite Schrifft und bracht es auch so weit/", "tokens": ["Er", "macht'", "erst", "brei\u00b7te", "Schrifft", "und", "bracht", "es", "auch", "so", "weit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "KON", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Da\u00df mit Verwunderung man drauff in kurtzer Zeit", "tokens": ["Da\u00df", "mit", "Ver\u00b7wun\u00b7de\u00b7rung", "man", "drauff", "in", "kurt\u00b7zer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "PIS", "PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Gedruckte Schrifften la\u00df. Nun werden tausend Bogen", "tokens": ["Ge\u00b7druck\u00b7te", "Schriff\u00b7ten", "la\u00df", ".", "Nun", "wer\u00b7den", "tau\u00b7send", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "PTKVZ", "$.", "ADV", "VAFIN", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "In einer Tages-Frist auch eher abgezogen/", "tokens": ["In", "ei\u00b7ner", "Ta\u00b7ges\u00b7Frist", "auch", "e\u00b7her", "ab\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Wenn nur die Schrifft gesetzt. Ging deine Schreiberey", "tokens": ["Wenn", "nur", "die", "Schrifft", "ge\u00b7setzt", ".", "Ging", "dei\u00b7ne", "Schrei\u00b7be\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "VVPP", "$.", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Athen und Room so fort? da du in Wachs und Bley", "tokens": ["A\u00b7then", "und", "Room", "so", "fort", "?", "da", "du", "in", "Wachs", "und", "Bley"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NE", "ADV", "PTKVZ", "$.", "KOUS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.113": {"text": "Annoch die Zeit verderbt? Gings auch so wol von statten/", "tokens": ["An\u00b7noch", "die", "Zeit", "ver\u00b7derbt", "?", "Gings", "auch", "so", "wol", "von", "stat\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$.", "NE", "ADV", "ADV", "ADV", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Ihr Alten/ wann ihr schriebt/ was euch gelehret hatten", "tokens": ["Ihr", "Al\u00b7ten", "/", "wann", "ihr", "schriebt", "/", "was", "euch", "ge\u00b7leh\u00b7ret", "hat\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PWAV", "PPER", "VVFIN", "$(", "PWS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Die Weisen von Athen? was Cicero/ Lucan/", "tokens": ["Die", "Wei\u00b7sen", "von", "A\u00b7then", "?", "was", "Ci\u00b7ce\u00b7ro", "/", "Lu\u00b7can", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$.", "PWS", "NN", "$(", "NE", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.116": {"text": "Was Aristoteles/ der Mantuaner Schwan", "tokens": ["Was", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "/", "der", "Man\u00b7tu\u00b7a\u00b7ner", "Schwan"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NE", "$(", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "und der von Sulm euch lehrt? O nein! ihr stoltzen Griechen/", "tokens": ["und", "der", "von", "Sulm", "euch", "lehrt", "?", "O", "nein", "!", "ihr", "stolt\u00b7zen", "Grie\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NE", "PPER", "VVFIN", "$.", "NE", "PTKANT", "$.", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Wie weis' ihr immer seyd/ nun m\u00f6cht ihr euch verkriechen:", "tokens": ["Wie", "weis'", "ihr", "im\u00b7mer", "seyd", "/", "nun", "m\u00f6cht", "ihr", "euch", "ver\u00b7krie\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "VAFIN", "$(", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Seht/ seht der Deutsche schreibt so viel auff einen Tag/", "tokens": ["Seht", "/", "seht", "der", "Deut\u00b7sche", "schreibt", "so", "viel", "auff", "ei\u00b7nen", "Tag", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Als einer unter euch im Jahre schreiben mag.", "tokens": ["Als", "ei\u00b7ner", "un\u00b7ter", "euch", "im", "Jah\u00b7re", "schrei\u00b7ben", "mag."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "ART", "APPR", "PPER", "APPRART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.121": {"text": "Wie elend war es nur: Ihr schriebt auff Wachs und Rinden/", "tokens": ["Wie", "e\u00b7lend", "war", "es", "nur", ":", "Ihr", "schriebt", "auff", "Wachs", "und", "Rin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Bis endlich einer kam und wies' euch armen Blinden", "tokens": ["Bis", "end\u00b7lich", "ei\u00b7ner", "kam", "und", "wies'", "euch", "ar\u00b7men", "Blin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIS", "VVFIN", "KON", "VVFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Papier und Pergamen. Der Reiche kont' allein", "tokens": ["Pa\u00b7pier", "und", "Per\u00b7ga\u00b7men", ".", "Der", "Rei\u00b7che", "kont'", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$.", "ART", "NE", "VMFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Was lernen dazumahl und B\u00fccher kauffen ein", "tokens": ["Was", "ler\u00b7nen", "da\u00b7zu\u00b7mahl", "und", "B\u00fc\u00b7cher", "kauf\u00b7fen", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "KON", "NN", "VVFIN", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "\u00fcm einen solchen Werth; Wer solt' itzt wol bezahlen/", "tokens": ["\u00fcm", "ei\u00b7nen", "sol\u00b7chen", "Werth", ";", "Wer", "solt'", "itzt", "wol", "be\u00b7zah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIAT", "NN", "$.", "PWS", "VMFIN", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Dier Triphon deinen Kraam/ nun darffstu nicht mehr pralen", "tokens": ["Dier", "Tri\u00b7phon", "dei\u00b7nen", "Kraam", "/", "nun", "darffs\u00b7tu", "nicht", "mehr", "pra\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "PPOSAT", "NN", "$(", "ADV", "PAV", "PTKNEG", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Du gro\u00dfer Gordian/ du Tullius und Du", "tokens": ["Du", "gro\u00b7\u00dfer", "Gor\u00b7di\u00b7an", "/", "du", "Tul\u00b7li\u00b7us", "und", "Du"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NE", "$(", "PPER", "NN", "KON", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Tyrannion schleu\u00df nur die B\u00fccher-Schr\u00e4ncke zu.", "tokens": ["Ty\u00b7ran\u00b7ni\u00b7on", "schleu\u00df", "nur", "die", "B\u00fc\u00b7cher\u00b7Schr\u00e4n\u00b7cke", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Was war zu Heidelberg? wie viel geschriebne Sachen/", "tokens": ["Was", "war", "zu", "Hei\u00b7del\u00b7berg", "?", "wie", "viel", "ge\u00b7schrieb\u00b7ne", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "NE", "$.", "PWAV", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Was B\u00fccher waren da? die manchen traurig machen", "tokens": ["Was", "B\u00fc\u00b7cher", "wa\u00b7ren", "da", "?", "die", "man\u00b7chen", "trau\u00b7rig", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "NN", "VAFIN", "ADV", "$.", "ART", "PIAT", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Durch ihren untergang? der Wald der Wei\u00dfheit weicht", "tokens": ["Durch", "ih\u00b7ren", "un\u00b7ter\u00b7gang", "?", "der", "Wald", "der", "Wei\u00df\u00b7heit", "weicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "In Constantinus Stadt: Alphonsus auch verbleicht.", "tokens": ["In", "Con\u00b7stan\u00b7ti\u00b7nus", "Stadt", ":", "Al\u00b7phon\u00b7sus", "auch", "ver\u00b7bleicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$.", "NE", "ADV", "VVPP", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.133": {"text": "Der Deutsche zeigt itzt mehr durch sein so sch\u00f6nes Dr\u00fccken/", "tokens": ["Der", "Deut\u00b7sche", "zeigt", "itzt", "mehr", "durch", "sein", "so", "sch\u00f6\u00b7nes", "Dr\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Das ihm gegeben ward durch Gottes hohes Schicken;", "tokens": ["Das", "ihm", "ge\u00b7ge\u00b7ben", "ward", "durch", "Got\u00b7tes", "ho\u00b7hes", "Schi\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Die B\u00fccher werden mehr. Die edle Dr\u00fcckerey", "tokens": ["Die", "B\u00fc\u00b7cher", "wer\u00b7den", "mehr", ".", "Die", "ed\u00b7le", "Dr\u00fc\u00b7cke\u00b7rey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Geht nun durch alle Welt und steht den K\u00fcnsten bey.", "tokens": ["Geht", "nun", "durch", "al\u00b7le", "Welt", "und", "steht", "den", "K\u00fcns\u00b7ten", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PIAT", "NN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Room weis itzt auch davon/ dahin sie mit sich f\u00fchrte", "tokens": ["Room", "weis", "itzt", "auch", "da\u00b7von", "/", "da\u00b7hin", "sie", "mit", "sich", "f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "ADV", "ADV", "PAV", "$(", "PAV", "PPER", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Zum ersten Ulrich Hahn und ihren Nutzen sp\u00fcrte.", "tokens": ["Zum", "ers\u00b7ten", "Ul\u00b7rich", "Hahn", "und", "ih\u00b7ren", "Nut\u00b7zen", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "NE", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "In Franckreich hat zu erst Sixt R\u00fcssinger gedr\u00fcckt;", "tokens": ["In", "Fran\u00b7ck\u00b7reich", "hat", "zu", "erst", "Sixt", "R\u00fcs\u00b7sin\u00b7ger", "ge\u00b7dr\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "APPR", "ADV", "NE", "NE", "VVPP", "$."], "meter": "-+--+-+-++--+", "measure": "iambic.hexa.relaxed"}, "line.140": {"text": "Ist also diese Kunst in kurtzen fortger\u00fcckt.", "tokens": ["Ist", "al\u00b7so", "die\u00b7se", "Kunst", "in", "kurt\u00b7zen", "fort\u00b7ge\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "NN", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Viel F\u00fcrsten haben sie so sehr und hoch geliebet", "tokens": ["Viel", "F\u00fcrs\u00b7ten", "ha\u00b7ben", "sie", "so", "sehr", "und", "hoch", "ge\u00b7lie\u00b7bet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "KON", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "und diese sch\u00f6ne Kunst mit eigner Hand ge\u00fcbet:", "tokens": ["und", "die\u00b7se", "sch\u00f6\u00b7ne", "Kunst", "mit", "eig\u00b7ner", "Hand", "ge\u00b7\u00fc\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Es hat sie Friederich der Dritte so erh\u00f6ht/", "tokens": ["Es", "hat", "sie", "Frie\u00b7de\u00b7rich", "der", "Drit\u00b7te", "so", "er\u00b7h\u00f6ht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NE", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Da\u00df auch der Dr\u00fccker-Stand fast gleich dem Adel steht,", "tokens": ["Da\u00df", "auch", "der", "Dr\u00fc\u00b7cker\u00b7Stand", "fast", "gleich", "dem", "A\u00b7del", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Er l\u00e4sset ihnen zu vor andern Gold zu tragen/", "tokens": ["Er", "l\u00e4s\u00b7set", "ih\u00b7nen", "zu", "vor", "an\u00b7dern", "Gold", "zu", "tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKZU", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Begnadigt sie so sehr und setzt sie auff den Wagen", "tokens": ["Be\u00b7gna\u00b7digt", "sie", "so", "sehr", "und", "setzt", "sie", "auff", "den", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Des adlichen Triumffs/ wie irgend einen Held/", "tokens": ["Des", "ad\u00b7li\u00b7chen", "Tri\u00b7umffs", "/", "wie", "ir\u00b7gend", "ei\u00b7nen", "Held", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KOKOM", "ADV", "ART", "NN", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.148": {"text": "Der seinen starcken Feind mit Ehr und R\u00fchm gef\u00e4llt;", "tokens": ["Der", "sei\u00b7nen", "star\u00b7cken", "Feind", "mit", "Ehr", "und", "R\u00fchm", "ge\u00b7f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Gibt ihnen freye Macht den offnen Helm zu f\u00fchren/", "tokens": ["Gibt", "ih\u00b7nen", "frey\u00b7e", "Macht", "den", "off\u00b7nen", "Helm", "zu", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Ein Adler mu\u00df zur Pracht des Setzers Wapen zieren/", "tokens": ["Ein", "Ad\u00b7ler", "mu\u00df", "zur", "Pracht", "des", "Set\u00b7zers", "Wa\u00b7pen", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPRART", "NN", "ART", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Weil er sich schwingt empor/ nimmt Adlers-Fl\u00fcgel an", "tokens": ["Weil", "er", "sich", "schwingt", "em\u00b7por", "/", "nimmt", "Ad\u00b7ler\u00b7sF\u00b7l\u00fc\u00b7gel", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "PTKVZ", "$(", "VVFIN", "NN", "APPR"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.152": {"text": "und fleucht mit mancher Schrifft zur grauen Lebens-bahn", "tokens": ["und", "fleucht", "mit", "man\u00b7cher", "Schrifft", "zur", "grau\u00b7en", "Le\u00b7bens\u00b7bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Der Unverg\u00e4ngligkeit. Dem Drucker ist gegeben", "tokens": ["Der", "Un\u00b7ver\u00b7g\u00e4n\u00b7glig\u00b7keit", ".", "Dem", "Dru\u00b7cker", "ist", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Der nimmerschwache Greyff/ und dann ein Ball darneben/", "tokens": ["Der", "nim\u00b7mer\u00b7schwa\u00b7che", "Greyff", "/", "und", "dann", "ein", "Ball", "dar\u00b7ne\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "ADV", "ART", "NN", "PAV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Den er nach Druckers-Art in seinen Klauen f\u00fchrt", "tokens": ["Den", "er", "nach", "Dru\u00b7cker\u00b7sArt", "in", "sei\u00b7nen", "Klau\u00b7en", "f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "und so gantz adelich die Wapen-Felder ziert.", "tokens": ["und", "so", "gantz", "a\u00b7de\u00b7lich", "die", "Wa\u00b7pen\u00b7Fel\u00b7der", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "So wird ihr Stand verehrt. Sie werden von den Alten", "tokens": ["So", "wird", "ihr", "Stand", "ver\u00b7ehrt", ".", "Sie", "wer\u00b7den", "von", "den", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$.", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Wie von den Jungen auch sehr lieb und wehrt gehalten/", "tokens": ["Wie", "von", "den", "Jun\u00b7gen", "auch", "sehr", "lieb", "und", "wehrt", "ge\u00b7hal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Des Dr\u00fcckers Haus und Hoff ist frey in mancher Stadt", "tokens": ["Des", "Dr\u00fc\u00b7ckers", "Haus", "und", "Hoff", "ist", "frey", "in", "man\u00b7cher", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "VVFIN", "VAFIN", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Da\u00df mit gelehrten er offt gleiche Freyheit hat.", "tokens": ["Da\u00df", "mit", "ge\u00b7lehr\u00b7ten", "er", "offt", "glei\u00b7che", "Frey\u00b7heit", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "PPER", "ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Di\u00df hat das Heupt der Welt vor zweymahl hundert Jahren", "tokens": ["Di\u00df", "hat", "das", "Heupt", "der", "Welt", "vor", "zwey\u00b7mahl", "hun\u00b7dert", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "APPR", "ADV", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Aus lauter Gnad und Gunst euch la\u00dfen wiederfahren;", "tokens": ["Aus", "lau\u00b7ter", "Gnad", "und", "Gunst", "euch", "la\u00b7\u00dfen", "wie\u00b7der\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "PPER", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "F\u00fcrst Friedrich Wilhelm auch von Sachsen hielt euch werth/", "tokens": ["F\u00fcrst", "Fried\u00b7rich", "Wil\u00b7helm", "auch", "von", "Sach\u00b7sen", "hielt", "euch", "werth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "ADV", "APPR", "NE", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Ein' eigne Dr\u00fcckerey zu haben Er begehrt:", "tokens": ["Ein'", "eig\u00b7ne", "Dr\u00fc\u00b7cke\u00b7rey", "zu", "ha\u00b7ben", "Er", "be\u00b7gehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VAINF", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Nam Drucker auff sein Schlo\u00df/ lie\u00df sch\u00f6ne Schrifften giessen", "tokens": ["Nam", "Dru\u00b7cker", "auff", "sein", "Schlo\u00df", "/", "lie\u00df", "sch\u00f6\u00b7ne", "Schriff\u00b7ten", "gies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "PPOSAT", "NN", "$(", "VVFIN", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "und seine Gnad' und Gunst den Druckern auch geniessen.", "tokens": ["und", "sei\u00b7ne", "Gnad'", "und", "Gunst", "den", "Dru\u00b7ckern", "auch", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Viel F\u00fcrsten wolten sehn/ was Faust und Guttenberg", "tokens": ["Viel", "F\u00fcrs\u00b7ten", "wol\u00b7ten", "sehn", "/", "was", "Faust", "und", "Gut\u00b7ten\u00b7berg"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$(", "PWS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Vor eine sch\u00f6ne Kunst und k\u00fcnstlich Wunder-Werck", "tokens": ["Vor", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Kunst", "und", "k\u00fcnst\u00b7lich", "Wun\u00b7der\u00b7\u00b7Werck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Zu Meyntz herf\u00fcr gebracht. Der Pabst auch selbst erstarrte", "tokens": ["Zu", "Meyntz", "her\u00b7f\u00fcr", "ge\u00b7bracht", ".", "Der", "Pabst", "auch", "selbst", "er\u00b7starr\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADV", "VVPP", "$.", "ART", "NN", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Vor diesem Feder-Kiel/ f\u00fcrnemlich da er knarrte", "tokens": ["Vor", "die\u00b7sem", "Fe\u00b7der\u00b7Kiel", "/", "f\u00fcr\u00b7nem\u00b7lich", "da", "er", "knarr\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$(", "ADV", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.171": {"text": "In Luthers Schrifft so sehr/ da\u00df auch gantz Room erschrack", "tokens": ["In", "Lu\u00b7thers", "Schrifft", "so", "sehr", "/", "da\u00df", "auch", "gantz", "Room", "er\u00b7schrack"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "ADV", "ADV", "$(", "KOUS", "ADV", "ADV", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "und h\u00f6rte seinen Knall. O seelig ist der Tag/", "tokens": ["und", "h\u00f6r\u00b7te", "sei\u00b7nen", "Knall", ".", "O", "see\u00b7lig", "ist", "der", "Tag", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "NE", "ADJD", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Da diese Schreiberey zum ersten ist erfunden!", "tokens": ["Da", "die\u00b7se", "Schrei\u00b7be\u00b7rey", "zum", "ers\u00b7ten", "ist", "er\u00b7fun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPRART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Die Wunder-Feder die! o seelig seyn die Stunden/", "tokens": ["Die", "Wun\u00b7der\u00b7Fe\u00b7der", "die", "!", "o", "see\u00b7lig", "seyn", "die", "Stun\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "$.", "FM", "ADJD", "VAINF", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Da Faust und Guttenberg zum ersten mahl gedacht", "tokens": ["Da", "Faust", "und", "Gut\u00b7ten\u00b7berg", "zum", "ers\u00b7ten", "mahl", "ge\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "APPRART", "ADJA", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Auff diese Schreibe-Kunst! o seelig ist die Nacht/", "tokens": ["Auff", "die\u00b7se", "Schrei\u00b7be\u00b7Kunst", "!", "o", "see\u00b7lig", "ist", "die", "Nacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$.", "FM", "ADJD", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Die Schlafflo\u00df ging vorbey. Es muste so geschehen/", "tokens": ["Die", "Schlaf\u00b7flo\u00df", "ging", "vor\u00b7bey", ".", "Es", "mus\u00b7te", "so", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "VMFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Weil Gott es l\u00e4ngst zuvor der Wunder-Gott versehen;", "tokens": ["Weil", "Gott", "es", "l\u00e4ngst", "zu\u00b7vor", "der", "Wun\u00b7der\u00b7Gott", "ver\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Es solte Luthers Lehr in aller Welt ausgehn", "tokens": ["Es", "sol\u00b7te", "Lu\u00b7thers", "Lehr", "in", "al\u00b7ler", "Welt", "aus\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NE", "NN", "APPR", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Durch diese sch\u00f6ne Kunst und voll im bl\u00fchen stehn.", "tokens": ["Durch", "die\u00b7se", "sch\u00f6\u00b7ne", "Kunst", "und", "voll", "im", "bl\u00fc\u00b7hen", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "KON", "ADJD", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Halt Clio/ meine Zier/ halt doch ein wenig inne/", "tokens": ["Halt", "Clio", "/", "mei\u00b7ne", "Zier", "/", "halt", "doch", "ein", "we\u00b7nig", "in\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$(", "PPOSAT", "NN", "$(", "VVFIN", "ADV", "ART", "PIS", "PTKVZ", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.182": {"text": "Damit ich auff ihr Thun und Wesen mich besinne.", "tokens": ["Da\u00b7mit", "ich", "auff", "ihr", "Thun", "und", "We\u00b7sen", "mich", "be\u00b7sin\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Wie geht es bey euch zu? Was habt ihr Dr\u00fccker dann", "tokens": ["Wie", "geht", "es", "bey", "euch", "zu", "?", "Was", "habt", "ihr", "Dr\u00fc\u00b7cker", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$.", "PWS", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "In eurer Dr\u00fcckerey/ da\u00df itzt ein jedermann", "tokens": ["In", "eu\u00b7rer", "Dr\u00fc\u00b7cke\u00b7rey", "/", "da\u00df", "itzt", "ein", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "KOUS", "ADV", "ART", "PIS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Mit Wunder schaut und siht? Was habet ihr vor Sachen/", "tokens": ["Mit", "Wun\u00b7der", "schaut", "und", "siht", "?", "Was", "ha\u00b7bet", "ihr", "vor", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "VVFIN", "$.", "PWS", "VAFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Da\u00df in so kurtzer Zeit ihr k\u00f6nnet B\u00fccher machen?", "tokens": ["Da\u00df", "in", "so", "kurt\u00b7zer", "Zeit", "ihr", "k\u00f6n\u00b7net", "B\u00fc\u00b7cher", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADV", "ADJA", "NN", "PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Vors erste seh' ich hier Buchstaben die von Bley", "tokens": ["Vors", "ers\u00b7te", "seh'", "ich", "hier", "Buch\u00b7sta\u00b7ben", "die", "von", "Bley"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "ADV", "NN", "ART", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Der Schrifften-Giesser macht/ so viel und mancherley", "tokens": ["Der", "Schriff\u00b7ten\u00b7Gies\u00b7ser", "macht", "/", "so", "viel", "und", "man\u00b7cher\u00b7ley"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$(", "ADV", "ADV", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "In kleinen F\u00e4chern stehn. Da ligt bey gro\u00dfen Lasten", "tokens": ["In", "klei\u00b7nen", "F\u00e4\u00b7chern", "stehn", ".", "Da", "ligt", "bey", "gro\u00b7\u00dfen", "Las\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$.", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Die allergr\u00f6bste Schrifft in ihrem eignen Kasten:", "tokens": ["Die", "al\u00b7ler\u00b7gr\u00f6bs\u00b7te", "Schrifft", "in", "ih\u00b7rem", "eig\u00b7nen", "Kas\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Hier ligt Canon Versal/ Missal Antiqua dort/", "tokens": ["Hier", "ligt", "Ca\u00b7non", "Ver\u00b7sal", "/", "Mis\u00b7sal", "An\u00b7ti\u00b7qua", "dort", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NN", "$(", "NE", "NE", "ADV", "$("], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.192": {"text": "Roman-Antiqua dann an einem andern Ort.", "tokens": ["Ro\u00b7man\u00b7An\u00b7ti\u00b7qua", "dann", "an", "ei\u00b7nem", "an\u00b7dern", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.193": {"text": "Bey Parion Cursiv k\u00f6mmt Parion die Alte/", "tokens": ["Bey", "Pa\u00b7ri\u00b7on", "Cur\u00b7siv", "k\u00f6mmt", "Pa\u00b7ri\u00b7on", "die", "Al\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.194": {"text": "Die wohl beysammen stehn in einer Zeil und Spalte/", "tokens": ["Die", "wohl", "bey\u00b7sam\u00b7men", "stehn", "in", "ei\u00b7ner", "Zeil", "und", "Spal\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVINF", "VVFIN", "APPR", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Die dritt' Antiqua folgt und Tertia Cursiv;", "tokens": ["Die", "dritt'", "An\u00b7ti\u00b7qua", "folgt", "und", "Ter\u00b7tia", "Cur\u00b7siv", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "VVFIN", "KON", "NE", "NE", "$."], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.196": {"text": "Dann bey der Mittel-Schrifft/ die etwas kr\u00fcmmer lieff/", "tokens": ["Dann", "bey", "der", "Mit\u00b7tel\u00b7Schrifft", "/", "die", "et\u00b7was", "kr\u00fcm\u00b7mer", "lieff", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$(", "ART", "PIAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Antiqua Mittel steht. Nun komm' ich zu den beyden/", "tokens": ["An\u00b7ti\u00b7qua", "Mit\u00b7tel", "steht", ".", "Nun", "komm'", "ich", "zu", "den", "bey\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "APPR", "ART", "PIAT", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.198": {"text": "In welchen Guttenberg den Cicero mit Freuden", "tokens": ["In", "wel\u00b7chen", "Gut\u00b7ten\u00b7berg", "den", "Ci\u00b7ce\u00b7ro", "mit", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Zum ersten hat gesetzt/ dr\u00fcm sie auch heissen so", "tokens": ["Zum", "ers\u00b7ten", "hat", "ge\u00b7setzt", "/", "dr\u00fcm", "sie", "auch", "heis\u00b7sen", "so"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN", "VVPP", "$(", "VVFIN", "PPER", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Nach ihm/ die Alte nun und Schieffe Cicero.", "tokens": ["Nach", "ihm", "/", "die", "Al\u00b7te", "nun", "und", "Schief\u00b7fe", "Ci\u00b7ce\u00b7ro", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$(", "ART", "NN", "ADV", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Seh' ich mich weiter \u00fcm/ so seh' ich eben liegen", "tokens": ["Seh'", "ich", "mich", "wei\u00b7ter", "\u00fcm", "/", "so", "seh'", "ich", "e\u00b7ben", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADJD", "$(", "ADV", "VVFIN", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Garmuth-Antiqua dort zu der man pflegt zu f\u00fcgen", "tokens": ["Gar\u00b7muth\u00b7An\u00b7ti\u00b7qua", "dort", "zu", "der", "man", "pflegt", "zu", "f\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "PIS", "VVFIN", "PTKZU", "VVINF"], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.203": {"text": "Cursiv/ doch nicht \u00fcmsonst. Was kleinre nun betrifft/", "tokens": ["Cur\u00b7siv", "/", "doch", "nicht", "\u00fcm\u00b7sonst", ".", "Was", "klein\u00b7re", "nun", "be\u00b7tr\u00b7ifft", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADV", "PTKNEG", "ADV", "$.", "PWS", "VVFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.204": {"text": "Findt man die neue schieff- und alte Jungferschrifft.", "tokens": ["Findt", "man", "die", "neu\u00b7e", "schief\u00b7f", "und", "al\u00b7te", "Jung\u00b7fer\u00b7schrifft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.205": {"text": "Di\u00df seyn die Schrifften nun/ damit man pflegt zu dr\u00fccken", "tokens": ["Di\u00df", "seyn", "die", "Schriff\u00b7ten", "nun", "/", "da\u00b7mit", "man", "pflegt", "zu", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$(", "KOUS", "PIS", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Welsch/ Ungrisch und Latein/ zu denen sie sich schicken.", "tokens": ["Welsch", "/", "Un\u00b7grisch", "und", "La\u00b7tein", "/", "zu", "de\u00b7nen", "sie", "sich", "schi\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "KON", "NN", "$(", "APPR", "PRELS", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.207": {"text": "Nun fahr' ich weiter fort und setz' auch ordentlich", "tokens": ["Nun", "fahr'", "ich", "wei\u00b7ter", "fort", "und", "setz'", "auch", "or\u00b7dent\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "Dieselbe/ die gar sch\u00f6n zum Griechschen schicket sich.", "tokens": ["Die\u00b7sel\u00b7be", "/", "die", "gar", "sch\u00f6n", "zum", "Griech\u00b7schen", "schi\u00b7cket", "sich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "$(", "ART", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Da pflegt man auch zu erst die grobe Schrifft zu haben/", "tokens": ["Da", "pflegt", "man", "auch", "zu", "erst", "die", "gro\u00b7be", "Schrifft", "zu", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "ADV", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "Darnach die Cicero/ die etwas schmaal gegraben;", "tokens": ["Dar\u00b7nach", "die", "Ci\u00b7ce\u00b7ro", "/", "die", "et\u00b7was", "schmaal", "ge\u00b7gra\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$(", "ART", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Dann auch das Corpus folgt/ so Garmuth sonst genennt/", "tokens": ["Dann", "auch", "das", "Cor\u00b7pus", "folgt", "/", "so", "Gar\u00b7muth", "sonst", "ge\u00b7nennt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$(", "ADV", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "und/ weil sie kleiner ist/ gar leichtlich wird erkennt.", "tokens": ["und", "/", "weil", "sie", "klei\u00b7ner", "ist", "/", "gar", "leicht\u00b7lich", "wird", "er\u00b7kennt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PPER", "ADJD", "VAFIN", "$(", "ADV", "ADJD", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Auch hat man eure Schrifft und Puncten ihr Hebr\u00e4er/", "tokens": ["Auch", "hat", "man", "eu\u00b7re", "Schrifft", "und", "Punc\u00b7ten", "ihr", "Heb\u00b7r\u00e4\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PPOSAT", "NN", "KON", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.214": {"text": "Die etwas schwerer ist/ dieweil im andern eher", "tokens": ["Die", "et\u00b7was", "schwe\u00b7rer", "ist", "/", "die\u00b7weil", "im", "an\u00b7dern", "e\u00b7her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "ADJA", "VAFIN", "$(", "ADV", "APPRART", "ADJA", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Drey Bl\u00e4tter seyn gesetzt/ als hier ein eintzig Blat/", "tokens": ["Drey", "Bl\u00e4t\u00b7ter", "seyn", "ge\u00b7setzt", "/", "als", "hier", "ein", "eint\u00b7zig", "Blat", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PPOSAT", "VVPP", "$(", "KOKOM", "ADV", "ART", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "Denn sie was sonderlichs vor andern Sprachen hat.", "tokens": ["Denn", "sie", "was", "son\u00b7der\u00b7lichs", "vor", "an\u00b7dern", "Spra\u00b7chen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PWS", "PIS", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Wie auch das Syrische; der T\u00fcrcken Schrifft ingleichen;", "tokens": ["Wie", "auch", "das", "Sy\u00b7ri\u00b7sche", ";", "der", "T\u00fcr\u00b7cken", "Schrifft", "in\u00b7glei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "$.", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Hier k\u00f6nnen wir auch sehn der Memphen Schreibe-Zeichen", "tokens": ["Hier", "k\u00f6n\u00b7nen", "wir", "auch", "sehn", "der", "Mem\u00b7phen", "Schrei\u00b7be\u00b7Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.219": {"text": "Die gleich den Bildern seyn: Arabisch und so fort", "tokens": ["Die", "gleich", "den", "Bil\u00b7dern", "seyn", ":", "A\u00b7ra\u00b7bisch", "und", "so", "fort"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "VAINF", "$.", "NN", "KON", "ADV", "PTKVZ"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.220": {"text": "Chald\u00e4isch dr\u00fccket man und was an jenem Ort/", "tokens": ["Chal\u00b7d\u00e4isch", "dr\u00fc\u00b7cket", "man", "und", "was", "an", "je\u00b7nem", "Ort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "KON", "PWS", "APPR", "PDAT", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.221": {"text": "Da sich zu fr\u00fcher Zeit des Himmels Buhlschafft schm\u00fccket", "tokens": ["Da", "sich", "zu", "fr\u00fc\u00b7her", "Zeit", "des", "Him\u00b7mels", "Buhl\u00b7schafft", "schm\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PTKA", "ADJD", "NN", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "und aus dem Schlaaff-Gemach zum ersten mahle blicket/", "tokens": ["und", "aus", "dem", "Schlaaff\u00b7Ge\u00b7mach", "zum", "ers\u00b7ten", "mah\u00b7le", "bli\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Noch mehr vor Sprachen seyn; ja was der Welt bewust/", "tokens": ["Noch", "mehr", "vor", "Spra\u00b7chen", "seyn", ";", "ja", "was", "der", "Welt", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VAINF", "$.", "ADV", "PWS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Das k\u00f6nnen alles wir im Drucke sehn mit Lust.", "tokens": ["Das", "k\u00f6n\u00b7nen", "al\u00b7les", "wir", "im", "Dru\u00b7cke", "sehn", "mit", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "PPER", "APPRART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Zuletzt la\u00dft uns die Schrifft der Deutschen auch ber\u00fchren/", "tokens": ["Zu\u00b7letzt", "la\u00dft", "uns", "die", "Schrifft", "der", "Deut\u00b7schen", "auch", "be\u00b7r\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Die/ weil sie immer steigt/ viel neue Schrifften f\u00fchren.", "tokens": ["Die", "/", "weil", "sie", "im\u00b7mer", "steigt", "/", "viel", "neu\u00b7e", "Schriff\u00b7ten", "f\u00fch\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "KOUS", "PPER", "ADV", "VVFIN", "$(", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Erst findet man Canon gar zierlich grob und klein", "tokens": ["Erst", "fin\u00b7det", "man", "Ca\u00b7non", "gar", "zier\u00b7lich", "grob", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "NE", "ADV", "ADJD", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Darnach ist Teuerdanck und Fibelschrifft gemein/", "tokens": ["Dar\u00b7nach", "ist", "Teu\u00b7er\u00b7danck", "und", "Fi\u00b7bel\u00b7schrifft", "ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "NN", "KON", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Wie auch gebrochne Schrifft/ so man die Dritte nennet/", "tokens": ["Wie", "auch", "ge\u00b7broch\u00b7ne", "Schrifft", "/", "so", "man", "die", "Drit\u00b7te", "nen\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJA", "NN", "$(", "ADV", "PIS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Mit Tertia Fractur/ so leichtlich wird erkennet;", "tokens": ["Mit", "Ter\u00b7tia", "Frac\u00b7tur", "/", "so", "leicht\u00b7lich", "wird", "er\u00b7ken\u00b7net", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$(", "ADV", "ADJD", "VAFIN", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.231": {"text": "Die Grobe Mittel auch/ Schwabacher/ welche mann", "tokens": ["Die", "Gro\u00b7be", "Mit\u00b7tel", "auch", "/", "Schwab\u00b7a\u00b7cher", "/", "wel\u00b7che", "mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "NN", "$(", "PWAT", "NN"], "meter": "-+-+-+++-+-+", "measure": "unknown.measure.septa"}, "line.232": {"text": "Postillen Schrifft sonst heist und wol gebrauchen kann", "tokens": ["Pos\u00b7til\u00b7len", "Schrifft", "sonst", "heist", "und", "wol", "ge\u00b7brau\u00b7chen", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "ADJD", "KON", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "Zur Mittel Schrifft Fractur: Hiern\u00e4chst ist auch zu finden", "tokens": ["Zur", "Mit\u00b7tel", "Schrifft", "Frac\u00b7tur", ":", "Hier\u00b7n\u00e4chst", "ist", "auch", "zu", "fin\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NN", "NN", "$.", "ADV", "VAFIN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "Schwabacher Cicero und bleibet nicht dahinden;", "tokens": ["Schwab\u00b7a\u00b7cher", "Ci\u00b7ce\u00b7ro", "und", "blei\u00b7bet", "nicht", "da\u00b7hin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "VVFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Bald Cicero Fractur/ so Gabon auch sonst heist/", "tokens": ["Bald", "Ci\u00b7ce\u00b7ro", "Frac\u00b7tur", "/", "so", "Ga\u00b7bon", "auch", "sonst", "heist", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "NN", "$(", "ADV", "NE", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "Vielleicht von dem der sie zum ersten mahl abreisst.", "tokens": ["Viel\u00b7leicht", "von", "dem", "der", "sie", "zum", "ers\u00b7ten", "mahl", "ab\u00b7reisst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "PRELS", "PPER", "APPRART", "ADJA", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.237": {"text": "Hier siht man auch mit Lust Schwabacher Corpus liegen", "tokens": ["Hier", "siht", "man", "auch", "mit", "Lust", "Schwab\u00b7a\u00b7cher", "Cor\u00b7pus", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "NN", "NE", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.238": {"text": "und Corpus von Fractur so sch\u00f6n zusammen f\u00fcgen;", "tokens": ["und", "Cor\u00b7pus", "von", "Frac\u00b7tur", "so", "sch\u00f6n", "zu\u00b7sam\u00b7men", "f\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "NN", "ADV", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Zuletzt die Jungferschrifft Fractur und was uns mehr/", "tokens": ["Zu\u00b7letzt", "die", "Jung\u00b7fer\u00b7schrifft", "Frac\u00b7tur", "und", "was", "uns", "mehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "KON", "PWS", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Die sch\u00f6ne Nomperell/ Ihr Dr\u00fccker/ wundert sehr/", "tokens": ["Die", "sch\u00f6\u00b7ne", "Nom\u00b7pe\u00b7rell", "/", "Ihr", "Dr\u00fc\u00b7cker", "/", "wun\u00b7dert", "sehr", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PPOSAT", "NN", "$(", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Die Zieffern/ R\u00f6selein/ die gro\u00df- und kleine Noten/", "tokens": ["Die", "Zief\u00b7fern", "/", "R\u00f6\u00b7se\u00b7lein", "/", "die", "gro\u00df", "und", "klei\u00b7ne", "No\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "$(", "ART", "TRUNC", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Die Leisten/ Z\u00fcg' und St\u00f6ck/ einfache Strich und Knoten/", "tokens": ["Die", "Leis\u00b7ten", "/", "Z\u00fcg'", "und", "St\u00f6ck", "/", "ein\u00b7fa\u00b7che", "Strich", "und", "Kno\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "KON", "NN", "$(", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Figuren allerhand auff Kupffer Holtz und Bley", "tokens": ["Fi\u00b7gu\u00b7ren", "al\u00b7ler\u00b7hand", "auff", "Kupf\u00b7fer", "Holtz", "und", "Bley"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "APPR", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "und was man alles siht in dieser Schreyberey.", "tokens": ["und", "was", "man", "al\u00b7les", "siht", "in", "die\u00b7ser", "Schrey\u00b7be\u00b7rey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PIS", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Di\u00df seyn die Schrifften nun/ die aus den F\u00e4chern langet/", "tokens": ["Di\u00df", "seyn", "die", "Schriff\u00b7ten", "nun", "/", "die", "aus", "den", "F\u00e4\u00b7chern", "lan\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.246": {"text": "Ihr s\u00e4tzer alsobald/ wenn ihr ein Werck anfanget", "tokens": ["Ihr", "s\u00e4t\u00b7zer", "al\u00b7so\u00b7bald", "/", "wenn", "ihr", "ein", "Werck", "an\u00b7fan\u00b7get"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.247": {"text": "und setzt sie ordentlich ins Winckel-Maa\u00df hinein/", "tokens": ["und", "setzt", "sie", "or\u00b7dent\u00b7lich", "ins", "Win\u00b7ckel\u00b7Maa\u00df", "hin\u00b7ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "so lange/ bi\u00df das Maa\u00df mag voll an Schrifften seyn;", "tokens": ["so", "lan\u00b7ge", "/", "bi\u00df", "das", "Maa\u00df", "mag", "voll", "an", "Schriff\u00b7ten", "seyn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "APPR", "ART", "NN", "VMFIN", "ADJD", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Dann nehmt ihr wieder\u00fcm heraus die vollen Zeilen", "tokens": ["Dann", "nehmt", "ihr", "wie\u00b7de\u00b7r\u00fcm", "he\u00b7raus", "die", "vol\u00b7len", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.250": {"text": "und setzt sie auff ein Bredt/ die ihr dann pflegt zu theilen", "tokens": ["und", "setzt", "sie", "auff", "ein", "Bredt", "/", "die", "ihr", "dann", "pflegt", "zu", "thei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "PRELS", "PPER", "ADV", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.251": {"text": "In gantze Bl\u00e4tter aus/ bi\u00df eine Form ist voll/", "tokens": ["In", "gant\u00b7ze", "Bl\u00e4t\u00b7ter", "aus", "/", "bi\u00df", "ei\u00b7ne", "Form", "ist", "voll", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$(", "APPR", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Dann legt ihr Rahmen dr\u00fcm und/ wie ein Dr\u00fccker soll/", "tokens": ["Dann", "legt", "ihr", "Rah\u00b7men", "dr\u00fcm", "und", "/", "wie", "ein", "Dr\u00fc\u00b7cker", "soll", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "KON", "$(", "KOKOM", "ART", "NN", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Schlie\u00dft ihr die Forme zu/ da\u00df ihr sie k\u00f6nnet tragen", "tokens": ["Schlie\u00dft", "ihr", "die", "For\u00b7me", "zu", "/", "da\u00df", "ihr", "sie", "k\u00f6n\u00b7net", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKZU", "$(", "KOUS", "PPER", "PPER", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "zur Pressen unverr\u00fcckt nach eurem Wohlbehagen;", "tokens": ["zur", "Pres\u00b7sen", "un\u00b7ver\u00b7r\u00fcckt", "nach", "eu\u00b7rem", "Wohl\u00b7be\u00b7ha\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.255": {"text": "Setzt sie auff festen Grund/ tragt Farben alsobald", "tokens": ["Setzt", "sie", "auff", "fes\u00b7ten", "Grund", "/", "tragt", "Far\u00b7ben", "al\u00b7so\u00b7bald"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$(", "VVFIN", "NN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Mit zweyen Ballen auff/ treckt zweymal mit Gewalt", "tokens": ["Mit", "zwe\u00b7yen", "Bal\u00b7len", "auff", "/", "treckt", "zwey\u00b7mal", "mit", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "NN", "APPR", "$(", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.257": {"text": "Den Bengel zu euch zu/ und wann der erste Bogen/", "tokens": ["Den", "Ben\u00b7gel", "zu", "euch", "zu", "/", "und", "wann", "der", "ers\u00b7te", "Bo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKZU", "$(", "KON", "PWAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.258": {"text": "So Sch\u00f6ndruck wird genennt/ einmahl ist abgezogen/", "tokens": ["So", "Sch\u00f6n\u00b7druck", "wird", "ge\u00b7nennt", "/", "ein\u00b7mahl", "ist", "ab\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "VVPP", "$(", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.259": {"text": "Macht ihr den Wieder-Druck und \u00e4ndert was versetzt/", "tokens": ["Macht", "ihr", "den", "Wie\u00b7der\u00b7Druck", "und", "\u00e4n\u00b7dert", "was", "ver\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "KON", "VVFIN", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "Auch sonst nicht richtig ist; Drauff nehmet ihr zuletzt", "tokens": ["Auch", "sonst", "nicht", "rich\u00b7tig", "ist", ";", "Drauff", "neh\u00b7met", "ihr", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "VAFIN", "$.", "PAV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "Papier/ so schon gefeucht/ damit es Farbe fangen", "tokens": ["Pa\u00b7pier", "/", "so", "schon", "ge\u00b7feucht", "/", "da\u00b7mit", "es", "Far\u00b7be", "fan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "ADV", "ADV", "VVPP", "$(", "KOUS", "PPER", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.262": {"text": "und an sich nehmen kan; Eh nun ein Tag vergangen/", "tokens": ["und", "an", "sich", "neh\u00b7men", "kan", ";", "Eh", "nun", "ein", "Tag", "ver\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRF", "VVINF", "VMFIN", "$.", "NN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.263": {"text": "Habt tausend Bogen ihr ja mehr schon abgedr\u00fcckt/", "tokens": ["Habt", "tau\u00b7send", "Bo\u00b7gen", "ihr", "ja", "mehr", "schon", "ab\u00b7ge\u00b7dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "Die werden auffgeh\u00e4ngt/ getrucknet und geschickt", "tokens": ["Die", "wer\u00b7den", "auff\u00b7ge\u00b7h\u00e4ngt", "/", "ge\u00b7truck\u00b7net", "und", "ge\u00b7schickt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "VVPP", "$(", "VVPP", "KON", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "Zu dem/ der sie verlegt; der ihren Nutzen sp\u00fcret/", "tokens": ["Zu", "dem", "/", "der", "sie", "ver\u00b7legt", ";", "der", "ih\u00b7ren", "Nut\u00b7zen", "sp\u00fc\u00b7ret", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PRELS", "PPER", "VVPP", "$.", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "Wenn er sie durch die Welt in manche L\u00e4nder f\u00fchret:", "tokens": ["Wenn", "er", "sie", "durch", "die", "Welt", "in", "man\u00b7che", "L\u00e4n\u00b7der", "f\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.267": {"text": "Room lieset gantz best\u00fcrtzt/ was nun zu Wittenberg", "tokens": ["Room", "lie\u00b7set", "gantz", "be\u00b7st\u00fcrtzt", "/", "was", "nun", "zu", "Wit\u00b7ten\u00b7berg"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "VVPP", "$(", "PWS", "ADV", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.268": {"text": "Zum meisten wird gedr\u00fcckt/ das edle Himmels-Werck.", "tokens": ["Zum", "meis\u00b7ten", "wird", "ge\u00b7dr\u00fcckt", "/", "das", "ed\u00b7le", "Him\u00b7mels\u00b7\u00b7Werck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "VAFIN", "VVPP", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.269": {"text": "Die Biblien seyn nun verdeutschet und gedr\u00fccket/", "tokens": ["Die", "Bib\u00b7li\u00b7en", "seyn", "nun", "ver\u00b7deut\u00b7schet", "und", "ge\u00b7dr\u00fc\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADV", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.270": {"text": "Daraus die Himmels-Lehr uns offenbahr anblicket/", "tokens": ["Da\u00b7raus", "die", "Him\u00b7mels\u00b7Lehr", "uns", "of\u00b7fen\u00b7bahr", "an\u00b7bli\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "So vor verborgen lag/ man wuste nichts von ihr", "tokens": ["So", "vor", "ver\u00b7bor\u00b7gen", "lag", "/", "man", "wus\u00b7te", "nichts", "von", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "VVPP", "VVFIN", "$(", "PIS", "VVFIN", "PIS", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.272": {"text": "Bi\u00df endlich Luther kam und brachte sie herf\u00fcr.", "tokens": ["Bi\u00df", "end\u00b7lich", "Lu\u00b7ther", "kam", "und", "brach\u00b7te", "sie", "her\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "NE", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.273": {"text": "Die B\u00fccher brechen aus/ die vor verschwiegen lagen/", "tokens": ["Die", "B\u00fc\u00b7cher", "bre\u00b7chen", "aus", "/", "die", "vor", "ver\u00b7schwie\u00b7gen", "la\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "ART", "APPR", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.274": {"text": "Durch unsre Dr\u00fcckerey; Sie ist der rechte Wagen/", "tokens": ["Durch", "uns\u00b7re", "Dr\u00fc\u00b7cke\u00b7rey", ";", "Sie", "ist", "der", "rech\u00b7te", "Wa\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.275": {"text": "Der aus der Sterbligkeit die edlen Geister f\u00fchrt", "tokens": ["Der", "aus", "der", "Ster\u00b7blig\u00b7keit", "die", "ed\u00b7len", "Geis\u00b7ter", "f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.276": {"text": "Dahin/ wo niemand stirbt; wo man die Sternen r\u00fchrt", "tokens": ["Da\u00b7hin", "/", "wo", "nie\u00b7mand", "stirbt", ";", "wo", "man", "die", "Ster\u00b7nen", "r\u00fchrt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "$(", "PWAV", "PIS", "VVFIN", "$.", "PWAV", "PIS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.277": {"text": "und ewig ist bekant. Es kan nunmehr nicht t\u00f6dten", "tokens": ["und", "e\u00b7wig", "ist", "be\u00b7kant", ".", "Es", "kan", "nun\u00b7mehr", "nicht", "t\u00f6d\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "ADJD", "$.", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.278": {"text": "Das ungl\u00fcck dieser Zeit die Edelen Poeten/", "tokens": ["Das", "un\u00b7gl\u00fcck", "die\u00b7ser", "Zeit", "die", "E\u00b7de\u00b7len", "Po\u00b7et\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Ihr Nahme wird ber\u00fchmt und bleibet nun dabey/", "tokens": ["Ihr", "Nah\u00b7me", "wird", "be\u00b7r\u00fchmt", "und", "blei\u00b7bet", "nun", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "VVFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.280": {"text": "Da\u00df keiner untergeht/ so lange Dr\u00fcckerey", "tokens": ["Da\u00df", "kei\u00b7ner", "un\u00b7ter\u00b7geht", "/", "so", "lan\u00b7ge", "Dr\u00fc\u00b7cke\u00b7rey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "$(", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.281": {"text": "Der edlen Tugend meldt. Da\u00df in so kurtzen Zeiten", "tokens": ["Der", "ed\u00b7len", "Tu\u00b7gend", "meldt", ".", "Da\u00df", "in", "so", "kurt\u00b7zen", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "KOUS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.282": {"text": "Die Deutsche Poesie erschallt auff allen Seiten/", "tokens": ["Die", "Deut\u00b7sche", "Poe\u00b7sie", "er\u00b7schallt", "auff", "al\u00b7len", "Sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.283": {"text": "Das macht die Dr\u00fcckerey/ die erstlich ausgebracht/", "tokens": ["Das", "macht", "die", "Dr\u00fc\u00b7cke\u00b7rey", "/", "die", "erst\u00b7lich", "aus\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.284": {"text": "Was Opitz unsre Zier mit kluger Hand gemacht.", "tokens": ["Was", "O\u00b7pitz", "uns\u00b7re", "Zier", "mit", "klu\u00b7ger", "Hand", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.285": {"text": "Gantz Deutschland ist bem\u00fcht/ auch in den gr\u00f6sten Kriegen/", "tokens": ["Gantz", "Deutschland", "ist", "be\u00b7m\u00fcht", "/", "auch", "in", "den", "gr\u00f6s\u00b7ten", "Krie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "VVPP", "$(", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.286": {"text": "Wie Wunder ist doch das! den andern abzusiegen/", "tokens": ["Wie", "Wun\u00b7der", "ist", "doch", "das", "!", "den", "an\u00b7dern", "ab\u00b7zu\u00b7sie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "ADV", "ART", "$.", "ART", "ADJA", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Die Griechen stehn best\u00fcrtzt/ Homerus gantz erbleicht/", "tokens": ["Die", "Grie\u00b7chen", "stehn", "be\u00b7st\u00fcrtzt", "/", "Ho\u00b7me\u00b7rus", "gantz", "er\u00b7bleicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVPP", "$(", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.288": {"text": "Horatius erblasst und Maro selbst entweicht", "tokens": ["Ho\u00b7ra\u00b7ti\u00b7us", "er\u00b7blasst", "und", "Ma\u00b7ro", "selbst", "ent\u00b7weicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "NE", "ADV", "VVFIN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.289": {"text": "Vor unsrer Poesie; Die nun so hoch sich schwinget/", "tokens": ["Vor", "uns\u00b7rer", "Poe\u00b7sie", ";", "Die", "nun", "so", "hoch", "sich", "schwin\u00b7get", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ART", "ADV", "ADV", "ADJD", "PRF", "VVFIN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.290": {"text": "Da\u00df Wiesen/ Berg und Thal vor Freuden wieder klinget:", "tokens": ["Da\u00df", "Wie\u00b7sen", "/", "Berg", "und", "Thal", "vor", "Freu\u00b7den", "wie\u00b7der", "klin\u00b7get", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "NN", "KON", "NN", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.291": {"text": "Die Arten eurer Vers' ihr Griechen allzumahl", "tokens": ["Die", "Ar\u00b7ten", "eu\u00b7rer", "Ver\u00b7s'", "ihr", "Grie\u00b7chen", "all\u00b7zu\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "PPOSAT", "NN", "ADV"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.292": {"text": "und Ihr aus Latien/ seyn nicht so viel an Zahl/", "tokens": ["und", "Ihr", "aus", "La\u00b7ti\u00b7en", "/", "seyn", "nicht", "so", "viel", "an", "Zahl", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NE", "$(", "VAINF", "PTKNEG", "ADV", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.293": {"text": "Als ich im Deutschen nur aus Jamben und Troch\u00e4en", "tokens": ["Als", "ich", "im", "Deut\u00b7schen", "nur", "aus", "Jam\u00b7ben", "und", "Troc\u00b7h\u00e4\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.294": {"text": "Alleine machen kan: Ihr m\u00fcsst es selbst gestehen/", "tokens": ["Al\u00b7lei\u00b7ne", "ma\u00b7chen", "kan", ":", "Ihr", "m\u00fcsst", "es", "selbst", "ge\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.295": {"text": "Da\u00df wir so sch\u00f6n als Ihr die Anap\u00e4sten auch", "tokens": ["Da\u00df", "wir", "so", "sch\u00f6n", "als", "Ihr", "die", "A\u00b7na\u00b7p\u00e4s\u00b7ten", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "KOKOM", "PPER", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.296": {"text": "Itzt haben auffgebracht/ da\u00df nunmehr seyn im Brauch/", "tokens": ["Itzt", "ha\u00b7ben", "auff\u00b7ge\u00b7bracht", "/", "da\u00df", "nun\u00b7mehr", "seyn", "im", "Brauch", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$(", "KOUS", "ADV", "VAINF", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "Wann wir die Arten all' in unsren Versen z\u00e4hlen/", "tokens": ["Wann", "wir", "die", "Ar\u00b7ten", "all'", "in", "un\u00b7sren", "Ver\u00b7sen", "z\u00e4h\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PIS", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.298": {"text": "Wohl funfftzig/ ja noch mehr/ daraus wir eine w\u00e4hlen", "tokens": ["Wohl", "funfft\u00b7zig", "/", "ja", "noch", "mehr", "/", "da\u00b7raus", "wir", "ei\u00b7ne", "w\u00e4h\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "$(", "ADV", "ADV", "ADV", "$(", "PAV", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.299": {"text": "Nach Lust/ und schreiben dann was unser Hertze will/", "tokens": ["Nach", "Lust", "/", "und", "schrei\u00b7ben", "dann", "was", "un\u00b7ser", "Hert\u00b7ze", "will", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "KON", "VVFIN", "ADV", "PWS", "PPER", "VVFIN", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.300": {"text": "Bald di\u00df bald jenes Lied; Die Helden schweigen still", "tokens": ["Bald", "di\u00df", "bald", "je\u00b7nes", "Lied", ";", "Die", "Hel\u00b7den", "schwei\u00b7gen", "still"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "ADV", "PDAT", "NN", "$.", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.301": {"text": "und h\u00f6ren selbsten zu; Der Helm mu\u00df niederliegen/", "tokens": ["und", "h\u00f6\u00b7ren", "selbs\u00b7ten", "zu", ";", "Der", "Helm", "mu\u00df", "nie\u00b7der\u00b7lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.302": {"text": "Der Harnisch ruht inde\u00df/ wann unsre Verse siegen/", "tokens": ["Der", "Har\u00b7nisch", "ruht", "in\u00b7de\u00df", "/", "wann", "uns\u00b7re", "Ver\u00b7se", "sie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "PWAV", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.303": {"text": "Sie werden so entz\u00fcckt/ da\u00df mancher WERTHER Held", "tokens": ["Sie", "wer\u00b7den", "so", "ent\u00b7z\u00fcckt", "/", "da\u00df", "man\u00b7cher", "WeRT\u00b7HER", "Held"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$(", "KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.304": {"text": "Die Waffen nichts mehr acht/ sucht vor das Krieges-Zelt", "tokens": ["Die", "Waf\u00b7fen", "nichts", "mehr", "acht", "/", "sucht", "vor", "das", "Krie\u00b7ge\u00b7sZelt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIS", "ADV", "CARD", "$(", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.305": {"text": "Den edlen Helicon. Der Fortgang und das Steigen", "tokens": ["Den", "ed\u00b7len", "He\u00b7li\u00b7con", ".", "Der", "Fort\u00b7gang", "und", "das", "Stei\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "Der Deutschen Poesie ist/ k\u00fcrtzlich anzuzeigen/", "tokens": ["Der", "Deut\u00b7schen", "Poe\u00b7sie", "ist", "/", "k\u00fcrtz\u00b7lich", "an\u00b7zu\u00b7zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "ADJD", "VVIZU", "$("], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.307": {"text": "Durch unsre Dr\u00fcckerey so eilend fortgebracht/", "tokens": ["Durch", "uns\u00b7re", "Dr\u00fc\u00b7cke\u00b7rey", "so", "ei\u00b7lend", "fort\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "Da\u00df itzt fast jederman ein Deutsch Getichte macht.", "tokens": ["Da\u00df", "itzt", "fast", "je\u00b7der\u00b7man", "ein", "Deutsch", "Ge\u00b7tich\u00b7te", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIS", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.309": {"text": "O edle Dr\u00fcckerey! Wo wolte man die Stunden", "tokens": ["O", "ed\u00b7le", "Dr\u00fc\u00b7cke\u00b7rey", "!", "Wo", "wol\u00b7te", "man", "die", "Stun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "PWAV", "VMFIN", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.310": {"text": "Nur immer bringen zu/ wenn du nicht werst erfunden:", "tokens": ["Nur", "im\u00b7mer", "brin\u00b7gen", "zu", "/", "wenn", "du", "nicht", "werst", "er\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "PTKZU", "$(", "KOUS", "PPER", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.311": {"text": "Da\u00df itzt so manches Buch ein jeder lesen mag/", "tokens": ["Da\u00df", "itzt", "so", "man\u00b7ches", "Buch", "ein", "je\u00b7der", "le\u00b7sen", "mag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIAT", "NN", "ART", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.312": {"text": "Das vor verborgen war und schaute nicht den Tag/", "tokens": ["Das", "vor", "ver\u00b7bor\u00b7gen", "war", "und", "schau\u00b7te", "nicht", "den", "Tag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "VVPP", "VAFIN", "KON", "VVFIN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.313": {"text": "Das k\u00f6mmet her von dier. Nun kan ein jeder lesen/", "tokens": ["Das", "k\u00f6m\u00b7met", "her", "von", "dier", ".", "Nun", "kan", "ein", "je\u00b7der", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PDAT", "$.", "ADV", "VMFIN", "ART", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Was Aristoteles und Tullius gewesen/", "tokens": ["Was", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "und", "Tul\u00b7li\u00b7us", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.315": {"text": "Wie weise Plato sey und was er uns gelehrt/", "tokens": ["Wie", "wei\u00b7se", "Pla\u00b7to", "sey", "und", "was", "er", "uns", "ge\u00b7lehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "VAFIN", "KON", "PWS", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.316": {"text": "Wie sehr Severus auch den Flaccus hat geehrt", "tokens": ["Wie", "sehr", "Se\u00b7ve\u00b7rus", "auch", "den", "Flac\u00b7cus", "hat", "ge\u00b7ehrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NE", "ADV", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.317": {"text": "und sich vor ihm gef\u00fcrcht: Wie hoch Trajan erhoben", "tokens": ["und", "sich", "vor", "ihm", "ge\u00b7f\u00fcrcht", ":", "Wie", "hoch", "Tra\u00b7jan", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "PPER", "VVPP", "$.", "PWAV", "ADJD", "NN", "VVPP"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.318": {"text": "Den jungen Plinius; Was dieser pflegt zu loben", "tokens": ["Den", "jun\u00b7gen", "Pli\u00b7nius", ";", "Was", "die\u00b7ser", "pflegt", "zu", "lo\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "$.", "PWS", "PDS", "VVFIN", "PTKZU", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.319": {"text": "und jener strafft und schilt. Die edle Wissenschafft", "tokens": ["und", "je\u00b7ner", "strafft", "und", "schilt", ".", "Die", "ed\u00b7le", "Wis\u00b7sen\u00b7schafft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "KON", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.320": {"text": "Der Weisen von Athen/ so l\u00e4ngsten hingerafft/", "tokens": ["Der", "Wei\u00b7sen", "von", "A\u00b7then", "/", "so", "l\u00e4ngs\u00b7ten", "hin\u00b7ge\u00b7rafft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$(", "ADV", "ADJA", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.321": {"text": "Die lebet noch durch Dich/ und wird auch nun wohl bleiben/", "tokens": ["Die", "le\u00b7bet", "noch", "durch", "Dich", "/", "und", "wird", "auch", "nun", "wohl", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PPER", "$(", "KON", "VAFIN", "ADV", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.322": {"text": "So lange du bestehst. Was wir noch itzo schreiben/", "tokens": ["So", "lan\u00b7ge", "du", "be\u00b7stehst", ".", "Was", "wir", "noch", "it\u00b7zo", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "$.", "PWS", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.323": {"text": "Das wird den untergang auch niemahls sehen nicht/", "tokens": ["Das", "wird", "den", "un\u00b7ter\u00b7gang", "auch", "nie\u00b7mahls", "se\u00b7hen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "ADV", "VVINF", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.324": {"text": "So lange Dr\u00fcckerey/ der Tugend Glantz und Licht/", "tokens": ["So", "lan\u00b7ge", "Dr\u00fc\u00b7cke\u00b7rey", "/", "der", "Tu\u00b7gend", "Glantz", "und", "Licht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$(", "ART", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.325": {"text": "Noch funckelt auff der Welt. Ein Pferd siht bald von fernen/", "tokens": ["Noch", "fun\u00b7ckelt", "auff", "der", "Welt", ".", "Ein", "Pferd", "siht", "bald", "von", "fer\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$.", "ART", "NN", "VVFIN", "ADV", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.326": {"text": "Den Feind und reisst hindurch; so reisst sich zu den Sternen/", "tokens": ["Den", "Feind", "und", "reisst", "hin\u00b7durch", ";", "so", "reisst", "sich", "zu", "den", "Ster\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PAV", "$.", "ADV", "VVFIN", "PRF", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.327": {"text": "Durch alle Sterbligkeit mit uns die Dr\u00fcckerey/", "tokens": ["Durch", "al\u00b7le", "Ster\u00b7blig\u00b7keit", "mit", "uns", "die", "Dr\u00fc\u00b7cke\u00b7rey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.328": {"text": "Macht unsern Nahmen gro\u00df und steht den K\u00fcnsten bey.", "tokens": ["Macht", "un\u00b7sern", "Nah\u00b7men", "gro\u00df", "und", "steht", "den", "K\u00fcns\u00b7ten", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADJD", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.329": {"text": "Ein Adler/ wann er sich bey k\u00fchler Lufft geschwungen", "tokens": ["Ein", "Ad\u00b7ler", "/", "wann", "er", "sich", "bey", "k\u00fch\u00b7ler", "Lufft", "ge\u00b7schwun\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PWAV", "PPER", "PRF", "APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.330": {"text": "Zur rothen Sonnen hin/ tr\u00e4gt nachmahls seine Jungen", "tokens": ["Zur", "ro\u00b7then", "Son\u00b7nen", "hin", "/", "tr\u00e4gt", "nach\u00b7mahls", "sei\u00b7ne", "Jun\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$(", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.331": {"text": "Auch eben so hinauff/ zu sch\u00e4rffen ihr Gesicht/", "tokens": ["Auch", "e\u00b7ben", "so", "hin\u00b7auff", "/", "zu", "sch\u00e4rf\u00b7fen", "ihr", "Ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "$(", "PTKZU", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.332": {"text": "Da\u00df sie gantz unverwandt das klare Wolcken-Licht", "tokens": ["Da\u00df", "sie", "gantz", "un\u00b7ver\u00b7wandt", "das", "kla\u00b7re", "Wol\u00b7cken\u00b7Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.333": {"text": "Auch k\u00f6nten schauen an: So werden wir getragen", "tokens": ["Auch", "k\u00f6n\u00b7ten", "schau\u00b7en", "an", ":", "So", "wer\u00b7den", "wir", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "VVINF", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.334": {"text": "Auch durch die Dr\u00fccker-Kunst nach unserm Wohlbehagen/", "tokens": ["Auch", "durch", "die", "Dr\u00fc\u00b7cker\u00b7Kunst", "nach", "un\u00b7serm", "Wohl\u00b7be\u00b7ha\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.335": {"text": "Wo Ph\u00f6bus uns bestrahlt/ zur blancken Himmels-Bahn;", "tokens": ["Wo", "Ph\u00f6\u00b7bus", "uns", "be\u00b7strahlt", "/", "zur", "blan\u00b7cken", "Him\u00b7mels\u00b7Bahn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PPER", "VVFIN", "$(", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.336": {"text": "Sie schwinget sich ermpor/ nimmt Adlers Fl\u00fcgel an", "tokens": ["Sie", "schwin\u00b7get", "sich", "erm\u00b7por", "/", "nimmt", "Ad\u00b7lers", "Fl\u00fc\u00b7gel", "an"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$(", "VVFIN", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.337": {"text": "und f\u00fchrt uns aus der Nacht. Die sehr-verborgnen Sachen/", "tokens": ["und", "f\u00fchrt", "uns", "aus", "der", "Nacht", ".", "Die", "sehr\u00b7ver\u00b7bor\u00b7gnen", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.338": {"text": "Die manchem Freud' und Lust bey schwerem unmuth machen/", "tokens": ["Die", "man\u00b7chem", "Freud'", "und", "Lust", "bey", "schwe\u00b7rem", "un\u00b7muth", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.339": {"text": "Die lieset man durch Sie. Die Albern werden klug/", "tokens": ["Die", "lie\u00b7set", "man", "durch", "Sie", ".", "Die", "Al\u00b7bern", "wer\u00b7den", "klug", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "PPER", "$.", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.340": {"text": "Die Blinden sehen nun den schrecklichsten Betrug.", "tokens": ["Die", "Blin\u00b7den", "se\u00b7hen", "nun", "den", "schreck\u00b7lichs\u00b7ten", "Be\u00b7trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.341": {"text": "Dr\u00fcm soll man ehren die/ die unsre Dr\u00fcckereyen", "tokens": ["Dr\u00fcm", "soll", "man", "eh\u00b7ren", "die", "/", "die", "uns\u00b7re", "Dr\u00fc\u00b7cke\u00b7re\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "VVFIN", "ART", "$(", "ART", "PPOSAT", "NN"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.342": {"text": "Bef\u00f6rdern noch itzund/ auff die sich manche freuen;", "tokens": ["Be\u00b7f\u00f6r\u00b7dern", "noch", "it\u00b7zund", "/", "auff", "die", "sich", "man\u00b7che", "freu\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "$(", "APPR", "PRELS", "PRF", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.343": {"text": "Die aus der Niedrigkeit gedencken da hinan/", "tokens": ["Die", "aus", "der", "Nied\u00b7rig\u00b7keit", "ge\u00b7den\u00b7cken", "da", "hi\u00b7nan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.344": {"text": "Wo man betreten kan die Sternen-liechte Bahn", "tokens": ["Wo", "man", "be\u00b7tre\u00b7ten", "kan", "die", "Ster\u00b7nen\u00b7liech\u00b7te", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVINF", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.345": {"text": "Der unverg\u00e4ngligkeit. Man solte dier zu Ehren/", "tokens": ["Der", "un\u00b7ver\u00b7g\u00e4n\u00b7glig\u00b7keit", ".", "Man", "sol\u00b7te", "dier", "zu", "Eh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PIS", "VMFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.346": {"text": "Du edler Guttenberg/ dein edles Werck vermehren/", "tokens": ["Du", "ed\u00b7ler", "Gut\u00b7ten\u00b7berg", "/", "dein", "ed\u00b7les", "Werck", "ver\u00b7meh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "PPOSAT", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.347": {"text": "Man solte noch itzund mit Gold in Demant-Stein", "tokens": ["Man", "sol\u00b7te", "noch", "it\u00b7zund", "mit", "Gold", "in", "De\u00b7mant\u00b7Stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "APPR", "NN", "APPR", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.348": {"text": "Dein Lob und deine Kunst/ wie billich/ schreiben ein.", "tokens": ["Dein", "Lob", "und", "dei\u00b7ne", "Kunst", "/", "wie", "bil\u00b7lich", "/", "schrei\u00b7ben", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$(", "PWAV", "ADJD", "$(", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.349": {"text": "Wo ist dein Denckmahl dann? Wo ist die Ehren-Seule?", "tokens": ["Wo", "ist", "dein", "Denck\u00b7mahl", "dann", "?", "Wo", "ist", "die", "Eh\u00b7ren\u00b7Seu\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADV", "$.", "PWAV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.350": {"text": "Wo ist die Ehren-Schrifft? Ich sehe keine Zeile/", "tokens": ["Wo", "ist", "die", "Eh\u00b7ren\u00b7Schrifft", "?", "Ich", "se\u00b7he", "kei\u00b7ne", "Zei\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$.", "PPER", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.351": {"text": "Kein Denck-Mahl ist auch hier/ kein Zeichen seh ich nicht/", "tokens": ["Kein", "Den\u00b7ck\u00b7Mahl", "ist", "auch", "hier", "/", "kein", "Zei\u00b7chen", "seh", "ich", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "$(", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.352": {"text": "Das dier ein eintzig Mensch zu Ehren auffgericht/", "tokens": ["Das", "dier", "ein", "eint\u00b7zig", "Mensch", "zu", "Eh\u00b7ren", "auff\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJD", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.353": {"text": "Wann einer diese Kunst gezeigt vor vielen Jahren/", "tokens": ["Wann", "ei\u00b7ner", "die\u00b7se", "Kunst", "ge\u00b7zeigt", "vor", "vie\u00b7len", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PDAT", "NN", "VVPP", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.354": {"text": "Da noch Athen und Room in vollem Wachsthum waren/", "tokens": ["Da", "noch", "A\u00b7then", "und", "Room", "in", "vol\u00b7lem", "Wach\u00b7sthum", "wa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "KON", "NE", "APPR", "ADJA", "NN", "VAFIN", "$("], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.355": {"text": "So h\u00e4tte man sein Bild wohl gar zum Gott gemacht", "tokens": ["So", "h\u00e4t\u00b7te", "man", "sein", "Bild", "wohl", "gar", "zum", "Gott", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "PPOSAT", "NN", "ADV", "ADV", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.356": {"text": "und zu dem Tempel hin mit Hertzens-Lust gebracht.", "tokens": ["und", "zu", "dem", "Tem\u00b7pel", "hin", "mit", "Hert\u00b7zens\u00b7Lust", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.357": {"text": "Wie h\u00e4tten diesen wohl die Sindier geehret/", "tokens": ["Wie", "h\u00e4t\u00b7ten", "die\u00b7sen", "wohl", "die", "Sin\u00b7dier", "ge\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDAT", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.358": {"text": "Der ihnen diese Kunst die Dr\u00fccker-Kunst gelehret?", "tokens": ["Der", "ih\u00b7nen", "die\u00b7se", "Kunst", "die", "Dr\u00fc\u00b7cker\u00b7Kunst", "ge\u00b7leh\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PDAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.359": {"text": "Sie h\u00e4tten ihm gewi\u00df was sonderlichs erdacht/", "tokens": ["Sie", "h\u00e4t\u00b7ten", "ihm", "ge\u00b7wi\u00df", "was", "son\u00b7der\u00b7lichs", "er\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PWS", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.360": {"text": "und bey der andern Welt ein ewigs Lob gemacht.", "tokens": ["und", "bey", "der", "an\u00b7dern", "Welt", "ein", "e\u00b7wigs", "Lob", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.361": {"text": "Was aber thut man dir? Nun ob dir gleich zu Ehren", "tokens": ["Was", "a\u00b7ber", "thut", "man", "dir", "?", "Nun", "ob", "dir", "gleich", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PIS", "PPER", "$.", "ADV", "KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.362": {"text": "Di\u00df alles nicht geschehn/ so kan man doch noch h\u00f6ren", "tokens": ["Di\u00df", "al\u00b7les", "nicht", "ge\u00b7schehn", "/", "so", "kan", "man", "doch", "noch", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "PTKNEG", "VVINF", "$(", "ADV", "VMFIN", "PIS", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.363": {"text": "Dein Lob in aller Welt/ da\u00df du ein G\u00f6ttlich Werck", "tokens": ["Dein", "Lob", "in", "al\u00b7ler", "Welt", "/", "da\u00df", "du", "ein", "G\u00f6tt\u00b7lich", "Werck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "NN", "$(", "KOUS", "PPER", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.364": {"text": "uns habest auffgebracht/ du edler Guttenberg.", "tokens": ["uns", "ha\u00b7best", "auff\u00b7ge\u00b7bracht", "/", "du", "ed\u00b7ler", "Gut\u00b7ten\u00b7berg", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.365": {"text": "Es wird auch wol dein Lob/ weil Menschen seyn/ bekleiben/", "tokens": ["Es", "wird", "auch", "wol", "dein", "Lob", "/", "weil", "Men\u00b7schen", "seyn", "/", "be\u00b7klei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPOSAT", "NN", "$(", "KOUS", "NN", "VAINF", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.366": {"text": "Dein Nahme nicht vergehn/ so lange man wird schreiben/", "tokens": ["Dein", "Nah\u00b7me", "nicht", "ver\u00b7gehn", "/", "so", "lan\u00b7ge", "man", "wird", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$(", "ADV", "ADV", "PIS", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.367": {"text": "So lang' uns ein Magnet die Zeit und Stunde sagt/", "tokens": ["So", "lang'", "uns", "ein", "Mag\u00b7net", "die", "Zeit", "und", "Stun\u00b7de", "sagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.368": {"text": "und zeigt wo Wind und Fluth das schwache Schiff hinjagt/", "tokens": ["und", "zeigt", "wo", "Wind", "und", "Fluth", "das", "schwa\u00b7che", "Schiff", "hin\u00b7jagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWAV", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.369": {"text": "Auch wohl bey finstrer Nacht. Man wird an dich gedencken/", "tokens": ["Auch", "wohl", "bey", "finst\u00b7rer", "Nacht", ".", "Man", "wird", "an", "dich", "ge\u00b7den\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "$.", "PIS", "VAFIN", "APPR", "PPER", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.370": {"text": "So offt man alle M\u00fch und Sorgen wird versencken", "tokens": ["So", "offt", "man", "al\u00b7le", "M\u00fch", "und", "Sor\u00b7gen", "wird", "ver\u00b7sen\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "PIAT", "NN", "KON", "NN", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.371": {"text": "In manches sch\u00f6nes Buch/ so lang' in vollem Schein", "tokens": ["In", "man\u00b7ches", "sch\u00f6\u00b7nes", "Buch", "/", "so", "lang'", "in", "vol\u00b7lem", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$(", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.372": {"text": "die g\u00fcldne Sonne steht/ wird deine Kunst auch seyn.", "tokens": ["die", "g\u00fcld\u00b7ne", "Son\u00b7ne", "steht", "/", "wird", "dei\u00b7ne", "Kunst", "auch", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "VAFIN", "PPOSAT", "NN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.373": {"text": "Nun weil mein schwaches Schiff den sichern Hafen sihet/", "tokens": ["Nun", "weil", "mein", "schwa\u00b7ches", "Schiff", "den", "si\u00b7chern", "Ha\u00b7fen", "si\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.374": {"text": "So werff ich Ancker ein und bin itzund bem\u00fchet", "tokens": ["So", "werff", "ich", "An\u00b7cker", "ein", "und", "bin", "it\u00b7zund", "be\u00b7m\u00fc\u00b7het"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "KON", "VAFIN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.375": {"text": "Zu enden mein Gedicht auff dessen Nahmens Ehr/", "tokens": ["Zu", "en\u00b7den", "mein", "Ge\u00b7dicht", "auff", "des\u00b7sen", "Nah\u00b7mens", "Ehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "APPR", "PRELAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.376": {"text": "Der uns gef\u00fchret hat und f\u00fchrt je mehr und mehr.", "tokens": ["Der", "uns", "ge\u00b7f\u00fch\u00b7ret", "hat", "und", "f\u00fchrt", "je", "mehr", "und", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "KON", "VVFIN", "ADV", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.377": {"text": "Hier denck ich auff dein Lob und dieses zu beschreiben/", "tokens": ["Hier", "denck", "ich", "auff", "dein", "Lob", "und", "die\u00b7ses", "zu", "be\u00b7schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "PDS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.378": {"text": "Soll itzt und immerfort mein Geist bem\u00fchet bleiben/", "tokens": ["Soll", "itzt", "und", "im\u00b7mer\u00b7fort", "mein", "Geist", "be\u00b7m\u00fc\u00b7het", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "KON", "ADV", "PPOSAT", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.379": {"text": "O Gott du Quell der Kunst; du Gnaden-Vater Du/", "tokens": ["O", "Gott", "du", "Quell", "der", "Kunst", ";", "du", "Gna\u00b7den\u00b7Va\u00b7ter", "Du", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "NN", "ART", "NN", "$.", "PPER", "NN", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.380": {"text": "Dir dancken wir anitzt und loben immerzu", "tokens": ["Dir", "dan\u00b7cken", "wir", "a\u00b7nitzt", "und", "lo\u00b7ben", "im\u00b7mer\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.381": {"text": "Dein gro\u00dfes Gnaden-Werck; da\u00df Du uns hast gewiesen", "tokens": ["Dein", "gro\u00b7\u00dfes", "Gna\u00b7den\u00b7\u00b7Werck", ";", "da\u00df", "Du", "uns", "hast", "ge\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "KOUS", "PPER", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.382": {"text": "Die edle Dr\u00fccker-Kunst/ die noch nicht gnug gepriesen", "tokens": ["Die", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "/", "die", "noch", "nicht", "gnug", "ge\u00b7prie\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADV", "PTKNEG", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.383": {"text": "So als sie w\u00fcrdig ist: Hast sie zweyhundert Jahr", "tokens": ["So", "als", "sie", "w\u00fcr\u00b7dig", "ist", ":", "Hast", "sie", "zwey\u00b7hun\u00b7dert", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VAFIN", "$.", "VAFIN", "PPER", "CARD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.384": {"text": "Erhalten und gemehrt/ Du hast uns hell und klar", "tokens": ["Er\u00b7hal\u00b7ten", "und", "ge\u00b7mehrt", "/", "Du", "hast", "uns", "hell", "und", "klar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "$(", "PPER", "VAFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.385": {"text": "Durch sie dein Wort geschenckt. Ach! Vater/ la\u00df doch scheinen", "tokens": ["Durch", "sie", "dein", "Wort", "ge\u00b7schenckt", ".", "Ach", "!", "Va\u00b7ter", "/", "la\u00df", "doch", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "PPOSAT", "NN", "VVPP", "$.", "ITJ", "$.", "NN", "$(", "VVIMP", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.386": {"text": "Die Fackel deines Worts; Erhalte sie den Deinen", "tokens": ["Die", "Fa\u00b7ckel", "dei\u00b7nes", "Worts", ";", "Er\u00b7hal\u00b7te", "sie", "den", "Dei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "ART", "PPOSAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.387": {"text": "Noch ferner hell und klar. Erzeig' uns deine Gunst/", "tokens": ["Noch", "fer\u00b7ner", "hell", "und", "klar", ".", "Er\u00b7zeig'", "uns", "dei\u00b7ne", "Gunst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADJD", "$.", "NN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.388": {"text": "La\u00df bl\u00fchen f\u00fcr und f\u00fcr die edle Dr\u00fccker-Kunst.", "tokens": ["La\u00df", "bl\u00fc\u00b7hen", "f\u00fcr", "und", "f\u00fcr", "die", "ed\u00b7le", "Dr\u00fc\u00b7cker\u00b7Kunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "APPR", "KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.389": {"text": "Ach! gib uns doch einmahl den lang-gew\u00fcntschten Frieden/", "tokens": ["Ach", "!", "gib", "uns", "doch", "ein\u00b7mahl", "den", "lang\u00b7ge\u00b7w\u00fcntschten", "Frie\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVIMP", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.390": {"text": "Ach! Vater bistu dann/ Ach! bistu dann geschieden", "tokens": ["Ach", "!", "Va\u00b7ter", "bis\u00b7tu", "dann", "/", "Ach", "!", "bis\u00b7tu", "dann", "ge\u00b7schie\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$.", "NN", "ADV", "ADV", "$(", "ITJ", "$.", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.391": {"text": "Von deiner Christenheit? Ach! h\u00f6restu denn nicht/", "tokens": ["Von", "dei\u00b7ner", "Chris\u00b7ten\u00b7heit", "?", "Ach", "!", "h\u00f6\u00b7res\u00b7tu", "denn", "nicht", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ITJ", "$.", "VVFIN", "ADV", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.392": {"text": "Was itzt dein liebes Volck in letzten Z\u00fcgen spricht?", "tokens": ["Was", "itzt", "dein", "lie\u00b7bes", "Volck", "in", "letz\u00b7ten", "Z\u00fc\u00b7gen", "spricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.393": {"text": "Ach! h\u00f6re/ h\u00f6re doch/ und la\u00df uns einmahl blicken", "tokens": ["Ach", "!", "h\u00f6\u00b7re", "/", "h\u00f6\u00b7re", "doch", "/", "und", "la\u00df", "uns", "ein\u00b7mahl", "bli\u00b7cken"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VVFIN", "$(", "VVFIN", "ADV", "$(", "KON", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.394": {"text": "Dein Gnaden-Angesicht/ da\u00df wir uns auch erquicken", "tokens": ["Dein", "Gna\u00b7den\u00b7An\u00b7ge\u00b7sicht", "/", "da\u00df", "wir", "uns", "auch", "er\u00b7qui\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "KOUS", "PPER", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.395": {"text": "und loben Dich daf\u00fcr/ Ach! nim das schwere Joch", "tokens": ["und", "lo\u00b7ben", "Dich", "da\u00b7f\u00fcr", "/", "Ach", "!", "nim", "das", "schwe\u00b7re", "Joch"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PAV", "$(", "ITJ", "$.", "VVIMP", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.396": {"text": "Von unsern Achseln hin: Ach! h\u00f6re/ h\u00f6re doch!", "tokens": ["Von", "un\u00b7sern", "Ach\u00b7seln", "hin", ":", "Ach", "!", "h\u00f6\u00b7re", "/", "h\u00f6\u00b7re", "doch", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$.", "ITJ", "$.", "VVFIN", "$(", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}