{"textgrid.poem.44950": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Reise nach dem Johannisberg", "genre": "verse", "period": "N.A.", "pub_year": 1831, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du gro\u00dfer Staatsmann, weide dich", "tokens": ["Du", "gro\u00b7\u00dfer", "Staats\u00b7mann", ",", "wei\u00b7de", "dich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An dem befreiten Rhein,", "tokens": ["An", "dem", "be\u00b7frei\u00b7ten", "Rhein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch machtest du die Donau frei,", "tokens": ["Doch", "mach\u00b7test", "du", "die", "Do\u00b7nau", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es sollt uns lieber sein.", "tokens": ["Es", "sollt", "uns", "lie\u00b7ber", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Auch witzig war dein gro\u00dfer Ahn,", "tokens": ["Auch", "wit\u00b7zig", "war", "dein", "gro\u00b7\u00dfer", "Ahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie jeder wei\u00df und kennt;", "tokens": ["Wie", "je\u00b7der", "wei\u00df", "und", "kennt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O h\u00fcte dich, da\u00df etwa nicht", "tokens": ["O", "h\u00fc\u00b7te", "dich", ",", "da\u00df", "et\u00b7wa", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$,", "KOUS", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du gro\u00dfer Staatsmann, weide dich", "tokens": ["Du", "gro\u00b7\u00dfer", "Staats\u00b7mann", ",", "wei\u00b7de", "dich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An dem befreiten Rhein,", "tokens": ["An", "dem", "be\u00b7frei\u00b7ten", "Rhein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch machtest du die Donau frei,", "tokens": ["Doch", "mach\u00b7test", "du", "die", "Do\u00b7nau", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es sollt uns lieber sein.", "tokens": ["Es", "sollt", "uns", "lie\u00b7ber", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Auch witzig war dein gro\u00dfer Ahn,", "tokens": ["Auch", "wit\u00b7zig", "war", "dein", "gro\u00b7\u00dfer", "Ahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie jeder wei\u00df und kennt;", "tokens": ["Wie", "je\u00b7der", "wei\u00df", "und", "kennt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O h\u00fcte dich, da\u00df etwa nicht", "tokens": ["O", "h\u00fc\u00b7te", "dich", ",", "da\u00df", "et\u00b7wa", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$,", "KOUS", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}