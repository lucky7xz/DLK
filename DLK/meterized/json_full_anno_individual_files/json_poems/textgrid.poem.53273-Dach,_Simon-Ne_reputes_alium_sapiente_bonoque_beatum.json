{"textgrid.poem.53273": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Ne reputes alium sapiente bonoque beatum", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer die Wei\u00dfheit jhm erkohren,", "tokens": ["Wer", "die", "Wei\u00df\u00b7heit", "jhm", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd der Tugend hat geschworen,", "tokens": ["Vnd", "der", "Tu\u00b7gend", "hat", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sein vngez\u00e4mbter Flei\u00df", "tokens": ["Da\u00df", "sein", "vn\u00b7ge\u00b7z\u00e4mb\u00b7ter", "Flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihre Sch\u00e4tze kan ergr\u00fcnden,", "tokens": ["Ih\u00b7re", "Sch\u00e4t\u00b7ze", "kan", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sol vnd mu\u00df zuletzt empfinden,", "tokens": ["Sol", "vnd", "mu\u00df", "zu\u00b7letzt", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "VMFIN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df sie wol zu lohnen wei\u00df.", "tokens": ["Da\u00df", "sie", "wol", "zu", "loh\u00b7nen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Er wird sich in sich nur kehren", "tokens": ["Er", "wird", "sich", "in", "sich", "nur", "keh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "PRF", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Vnd von aussen nichts begehren,", "tokens": ["Vnd", "von", "aus\u00b7sen", "nichts", "be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein Gem\u00fct ist Reichthums voll,", "tokens": ["Sein", "Ge\u00b7m\u00fct", "ist", "Reicht\u00b7hums", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist ein Vorraht aller Sachen,", "tokens": ["Ist", "ein", "Vor\u00b7raht", "al\u00b7ler", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die vns gn\u00fcghafft k\u00f6nnen machen", "tokens": ["Die", "vns", "gn\u00fcg\u00b7hafft", "k\u00f6n\u00b7nen", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd ein Mensch jhm w\u00fcnschen soll.", "tokens": ["Vnd", "ein", "Mensch", "jhm", "w\u00fcn\u00b7schen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Niemand wird jhn leichtlich sehen", "tokens": ["Nie\u00b7mand", "wird", "jhn", "leicht\u00b7lich", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dem verwehnten Gl\u00fccke flehen,", "tokens": ["Dem", "ver\u00b7wehn\u00b7ten", "Gl\u00fc\u00b7cke", "fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ein ander betteln mu\u00df", "tokens": ["Was", "ein", "an\u00b7der", "bet\u00b7teln", "mu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJD", "VVINF", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd doch kaum wei\u00df zu erlangen,", "tokens": ["Vnd", "doch", "kaum", "wei\u00df", "zu", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Reichthum, Ehre, Pracht vnd Prangen", "tokens": ["Reicht\u00b7hum", ",", "Eh\u00b7re", ",", "Pracht", "vnd", "Pran\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Trit er vnter seinen Fu\u00df.", "tokens": ["Trit", "er", "vn\u00b7ter", "sei\u00b7nen", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sich im Gl\u00fccke nicht erheben", "tokens": ["Sich", "im", "Gl\u00fc\u00b7cke", "nicht", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPRART", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd durch Vngl\u00fcck nicht begeben", "tokens": ["Vnd", "durch", "Vn\u00b7gl\u00fcck", "nicht", "be\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist die Kunst, die er nur kan:", "tokens": ["Ist", "die", "Kunst", ",", "die", "er", "nur", "kan", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er wird alles Leid beg\u00fceten,", "tokens": ["Er", "wird", "al\u00b7les", "Leid", "be\u00b7g\u00fce\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was nicht stehet zu verh\u00fceten,", "tokens": ["Was", "nicht", "ste\u00b7het", "zu", "ver\u00b7h\u00fce\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nimmt er fein mit willen an.", "tokens": ["Nimmt", "er", "fein", "mit", "wil\u00b7len", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Nichts wird Ihm den Muth bewegen,", "tokens": ["Nichts", "wird", "Ihm", "den", "Muth", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fiel die Welt mit harten Schl\u00e4gen", "tokens": ["Fiel", "die", "Welt", "mit", "har\u00b7ten", "Schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleich auff seinen Schedel hin:", "tokens": ["Gleich", "auff", "sei\u00b7nen", "Sche\u00b7del", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd was hat er zu erschrecken?", "tokens": ["Vnd", "was", "hat", "er", "zu", "er\u00b7schre\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was jhn sicher kan verdecken", "tokens": ["Was", "jhn", "si\u00b7cher", "kan", "ver\u00b7de\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADJD", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist sein L\u00f6wen-starker Sinn.", "tokens": ["Ist", "sein", "L\u00f6\u00b7wen\u00b7star\u00b7ker", "Sinn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Trotz euch allen, die Ihr meinet,", "tokens": ["Trotz", "euch", "al\u00b7len", ",", "die", "Ihr", "mei\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gold, vnd was von aussen scheinet,", "tokens": ["Gold", ",", "vnd", "was", "von", "aus\u00b7sen", "schei\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PWS", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sey, worauff man fussen kan!", "tokens": ["Sey", ",", "wo\u00b7rauff", "man", "fus\u00b7sen", "kan", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ist Stand, Gebl\u00fct vnd G\u00fctter?", "tokens": ["Was", "ist", "Stand", ",", "Ge\u00b7bl\u00fct", "vnd", "G\u00fct\u00b7ter", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach! ein Fallstrick der Gem\u00fcter,", "tokens": ["Ach", "!", "ein", "Fall\u00b7strick", "der", "Ge\u00b7m\u00fc\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Rauch vnd Schatten vmb vnd an.", "tokens": ["Rauch", "vnd", "Schat\u00b7ten", "vmb", "vnd", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Nein, Gott ehre mir die Tugend,", "tokens": ["Nein", ",", "Gott", "eh\u00b7re", "mir", "die", "Tu\u00b7gend", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ein sch\u00f6ner Schmuck der Jugend", "tokens": ["Die", "ein", "sch\u00f6\u00b7ner", "Schmuck", "der", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd ein Stab dem Alter ist:", "tokens": ["Vnd", "ein", "Stab", "dem", "Al\u00b7ter", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich vnser nicht wird sch\u00e4men,", "tokens": ["Die", "sich", "vn\u00b7ser", "nicht", "wird", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "PTKNEG", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn du, Gl\u00fcck, rei\u00dfaus must nehmen,", "tokens": ["Wenn", "du", ",", "Gl\u00fcck", ",", "rei\u00df\u00b7aus", "must", "neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd vor allen Teuffel bist!", "tokens": ["Vnd", "vor", "al\u00b7len", "Teuf\u00b7fel", "bist", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wer die Wei\u00dfheit jhm erkohren,", "tokens": ["Wer", "die", "Wei\u00df\u00b7heit", "jhm", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd der Tugend hat geschworen,", "tokens": ["Vnd", "der", "Tu\u00b7gend", "hat", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sein vngez\u00e4mbter Flei\u00df", "tokens": ["Da\u00df", "sein", "vn\u00b7ge\u00b7z\u00e4mb\u00b7ter", "Flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihre Sch\u00e4tze kan ergr\u00fcnden,", "tokens": ["Ih\u00b7re", "Sch\u00e4t\u00b7ze", "kan", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sol vnd mu\u00df zuletzt empfinden,", "tokens": ["Sol", "vnd", "mu\u00df", "zu\u00b7letzt", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "VMFIN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df sie wol zu lohnen wei\u00df.", "tokens": ["Da\u00df", "sie", "wol", "zu", "loh\u00b7nen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Er wird sich in sich nur kehren", "tokens": ["Er", "wird", "sich", "in", "sich", "nur", "keh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "PRF", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Vnd von aussen nichts begehren,", "tokens": ["Vnd", "von", "aus\u00b7sen", "nichts", "be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein Gem\u00fct ist Reichthums voll,", "tokens": ["Sein", "Ge\u00b7m\u00fct", "ist", "Reicht\u00b7hums", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist ein Vorraht aller Sachen,", "tokens": ["Ist", "ein", "Vor\u00b7raht", "al\u00b7ler", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die vns gn\u00fcghafft k\u00f6nnen machen", "tokens": ["Die", "vns", "gn\u00fcg\u00b7hafft", "k\u00f6n\u00b7nen", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd ein Mensch jhm w\u00fcnschen soll.", "tokens": ["Vnd", "ein", "Mensch", "jhm", "w\u00fcn\u00b7schen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Niemand wird jhn leichtlich sehen", "tokens": ["Nie\u00b7mand", "wird", "jhn", "leicht\u00b7lich", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dem verwehnten Gl\u00fccke flehen,", "tokens": ["Dem", "ver\u00b7wehn\u00b7ten", "Gl\u00fc\u00b7cke", "fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ein ander betteln mu\u00df", "tokens": ["Was", "ein", "an\u00b7der", "bet\u00b7teln", "mu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJD", "VVINF", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd doch kaum wei\u00df zu erlangen,", "tokens": ["Vnd", "doch", "kaum", "wei\u00df", "zu", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Reichthum, Ehre, Pracht vnd Prangen", "tokens": ["Reicht\u00b7hum", ",", "Eh\u00b7re", ",", "Pracht", "vnd", "Pran\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Trit er vnter seinen Fu\u00df.", "tokens": ["Trit", "er", "vn\u00b7ter", "sei\u00b7nen", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Sich im Gl\u00fccke nicht erheben", "tokens": ["Sich", "im", "Gl\u00fc\u00b7cke", "nicht", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPRART", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd durch Vngl\u00fcck nicht begeben", "tokens": ["Vnd", "durch", "Vn\u00b7gl\u00fcck", "nicht", "be\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist die Kunst, die er nur kan:", "tokens": ["Ist", "die", "Kunst", ",", "die", "er", "nur", "kan", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er wird alles Leid beg\u00fceten,", "tokens": ["Er", "wird", "al\u00b7les", "Leid", "be\u00b7g\u00fce\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was nicht stehet zu verh\u00fceten,", "tokens": ["Was", "nicht", "ste\u00b7het", "zu", "ver\u00b7h\u00fce\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nimmt er fein mit willen an.", "tokens": ["Nimmt", "er", "fein", "mit", "wil\u00b7len", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Nichts wird Ihm den Muth bewegen,", "tokens": ["Nichts", "wird", "Ihm", "den", "Muth", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fiel die Welt mit harten Schl\u00e4gen", "tokens": ["Fiel", "die", "Welt", "mit", "har\u00b7ten", "Schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleich auff seinen Schedel hin:", "tokens": ["Gleich", "auff", "sei\u00b7nen", "Sche\u00b7del", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd was hat er zu erschrecken?", "tokens": ["Vnd", "was", "hat", "er", "zu", "er\u00b7schre\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was jhn sicher kan verdecken", "tokens": ["Was", "jhn", "si\u00b7cher", "kan", "ver\u00b7de\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADJD", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist sein L\u00f6wen-starker Sinn.", "tokens": ["Ist", "sein", "L\u00f6\u00b7wen\u00b7star\u00b7ker", "Sinn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Trotz euch allen, die Ihr meinet,", "tokens": ["Trotz", "euch", "al\u00b7len", ",", "die", "Ihr", "mei\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gold, vnd was von aussen scheinet,", "tokens": ["Gold", ",", "vnd", "was", "von", "aus\u00b7sen", "schei\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PWS", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sey, worauff man fussen kan!", "tokens": ["Sey", ",", "wo\u00b7rauff", "man", "fus\u00b7sen", "kan", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ist Stand, Gebl\u00fct vnd G\u00fctter?", "tokens": ["Was", "ist", "Stand", ",", "Ge\u00b7bl\u00fct", "vnd", "G\u00fct\u00b7ter", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach! ein Fallstrick der Gem\u00fcter,", "tokens": ["Ach", "!", "ein", "Fall\u00b7strick", "der", "Ge\u00b7m\u00fc\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Rauch vnd Schatten vmb vnd an.", "tokens": ["Rauch", "vnd", "Schat\u00b7ten", "vmb", "vnd", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Nein, Gott ehre mir die Tugend,", "tokens": ["Nein", ",", "Gott", "eh\u00b7re", "mir", "die", "Tu\u00b7gend", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ein sch\u00f6ner Schmuck der Jugend", "tokens": ["Die", "ein", "sch\u00f6\u00b7ner", "Schmuck", "der", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd ein Stab dem Alter ist:", "tokens": ["Vnd", "ein", "Stab", "dem", "Al\u00b7ter", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich vnser nicht wird sch\u00e4men,", "tokens": ["Die", "sich", "vn\u00b7ser", "nicht", "wird", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "PTKNEG", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn du, Gl\u00fcck, rei\u00dfaus must nehmen,", "tokens": ["Wenn", "du", ",", "Gl\u00fcck", ",", "rei\u00df\u00b7aus", "must", "neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd vor allen Teuffel bist!", "tokens": ["Vnd", "vor", "al\u00b7len", "Teuf\u00b7fel", "bist", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}