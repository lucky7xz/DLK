{"textgrid.poem.53270": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Parcere non didicit Mors ulli, est omnibus \u00e6qua", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Raffet auch der Tod die greisen Haare,", "tokens": ["Raf\u00b7fet", "auch", "der", "Tod", "die", "grei\u00b7sen", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Hilfft nicht alle Wei\u00dfheit vieler Jahre,", "tokens": ["Hilfft", "nicht", "al\u00b7le", "Wei\u00df\u00b7heit", "vie\u00b7ler", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PIAT", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Was kan denn stehen,", "tokens": ["Was", "kan", "denn", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Oder seiner grossen Macht entgehen?", "tokens": ["O\u00b7der", "sei\u00b7ner", "gros\u00b7sen", "Macht", "ent\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Wo ist Salomon der weyse blieben?", "tokens": ["Wo", "ist", "Sa\u00b7lo\u00b7mon", "der", "wey\u00b7se", "blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ist er durch den Tod nicht auffgerieben?", "tokens": ["Ist", "er", "durch", "den", "Tod", "nicht", "auff\u00b7ge\u00b7rie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Was soll die Jugend,", "tokens": ["Was", "soll", "die", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vnd der zarten Jahre frische Tugendt?", "tokens": ["Vnd", "der", "zar\u00b7ten", "Jah\u00b7re", "fri\u00b7sche", "Tu\u00b7gendt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Trotzt jhr Reichen nur auff ewre Sch\u00e4tze;", "tokens": ["Trotzt", "jhr", "Rei\u00b7chen", "nur", "auff", "ew\u00b7re", "Sch\u00e4t\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "K\u00f6nnt jhr auch entgehn des Todes Netze?", "tokens": ["K\u00f6nnt", "jhr", "auch", "ent\u00b7gehn", "des", "To\u00b7des", "Net\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Er wird nicht h\u00f6ren,", "tokens": ["Er", "wird", "nicht", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Sitzt jhr auch dazu in grossen Ehren.", "tokens": ["Sitzt", "jhr", "auch", "da\u00b7zu", "in", "gros\u00b7sen", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PAV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Hat er nicht auch an den starcken Riesen", "tokens": ["Hat", "er", "nicht", "auch", "an", "den", "star\u00b7cken", "Rie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Seines Zorns vnd Eifers Macht bewiesen?", "tokens": ["Sei\u00b7nes", "Zorns", "vnd", "Ei\u00b7fers", "Macht", "be\u00b7wie\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Was pocht jhr Helden!", "tokens": ["Was", "pocht", "jhr", "Hel\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Schawt! Der Tod wil euch das End' anmelden.", "tokens": ["Schawt", "!", "Der", "Tod", "wil", "euch", "das", "End'", "an\u00b7mel\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Darumb lasst vns all' in allen f\u00e4llen", "tokens": ["Da\u00b7rumb", "lasst", "vns", "all'", "in", "al\u00b7len", "f\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PIS", "APPR", "PIS", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Stets des Todes Bild vor Augen stellen!", "tokens": ["Stets", "des", "To\u00b7des", "Bild", "vor", "Au\u00b7gen", "stel\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Auch stehn vnd wachen,", "tokens": ["Auch", "stehn", "vnd", "wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vns in Christo von der Welt zu machen!", "tokens": ["Vns", "in", "Chris\u00b7to", "von", "der", "Welt", "zu", "ma\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Raffet auch der Tod die greisen Haare,", "tokens": ["Raf\u00b7fet", "auch", "der", "Tod", "die", "grei\u00b7sen", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Hilfft nicht alle Wei\u00dfheit vieler Jahre,", "tokens": ["Hilfft", "nicht", "al\u00b7le", "Wei\u00df\u00b7heit", "vie\u00b7ler", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PIAT", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Was kan denn stehen,", "tokens": ["Was", "kan", "denn", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Oder seiner grossen Macht entgehen?", "tokens": ["O\u00b7der", "sei\u00b7ner", "gros\u00b7sen", "Macht", "ent\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Wo ist Salomon der weyse blieben?", "tokens": ["Wo", "ist", "Sa\u00b7lo\u00b7mon", "der", "wey\u00b7se", "blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ist er durch den Tod nicht auffgerieben?", "tokens": ["Ist", "er", "durch", "den", "Tod", "nicht", "auff\u00b7ge\u00b7rie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Was soll die Jugend,", "tokens": ["Was", "soll", "die", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vnd der zarten Jahre frische Tugendt?", "tokens": ["Vnd", "der", "zar\u00b7ten", "Jah\u00b7re", "fri\u00b7sche", "Tu\u00b7gendt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Trotzt jhr Reichen nur auff ewre Sch\u00e4tze;", "tokens": ["Trotzt", "jhr", "Rei\u00b7chen", "nur", "auff", "ew\u00b7re", "Sch\u00e4t\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "K\u00f6nnt jhr auch entgehn des Todes Netze?", "tokens": ["K\u00f6nnt", "jhr", "auch", "ent\u00b7gehn", "des", "To\u00b7des", "Net\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Er wird nicht h\u00f6ren,", "tokens": ["Er", "wird", "nicht", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Sitzt jhr auch dazu in grossen Ehren.", "tokens": ["Sitzt", "jhr", "auch", "da\u00b7zu", "in", "gros\u00b7sen", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PAV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Hat er nicht auch an den starcken Riesen", "tokens": ["Hat", "er", "nicht", "auch", "an", "den", "star\u00b7cken", "Rie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Seines Zorns vnd Eifers Macht bewiesen?", "tokens": ["Sei\u00b7nes", "Zorns", "vnd", "Ei\u00b7fers", "Macht", "be\u00b7wie\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Was pocht jhr Helden!", "tokens": ["Was", "pocht", "jhr", "Hel\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Schawt! Der Tod wil euch das End' anmelden.", "tokens": ["Schawt", "!", "Der", "Tod", "wil", "euch", "das", "End'", "an\u00b7mel\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Darumb lasst vns all' in allen f\u00e4llen", "tokens": ["Da\u00b7rumb", "lasst", "vns", "all'", "in", "al\u00b7len", "f\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PIS", "APPR", "PIS", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Stets des Todes Bild vor Augen stellen!", "tokens": ["Stets", "des", "To\u00b7des", "Bild", "vor", "Au\u00b7gen", "stel\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Auch stehn vnd wachen,", "tokens": ["Auch", "stehn", "vnd", "wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vns in Christo von der Welt zu machen!", "tokens": ["Vns", "in", "Chris\u00b7to", "von", "der", "Welt", "zu", "ma\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}