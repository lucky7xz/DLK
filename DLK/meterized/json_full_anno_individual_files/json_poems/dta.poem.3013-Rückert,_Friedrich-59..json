{"dta.poem.3013": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "59.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es ist ein sch\u00f6ner Traum, im Anfang der Natur", "tokens": ["Es", "ist", "ein", "sch\u00f6\u00b7ner", "Traum", ",", "im", "An\u00b7fang", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sei alles Lebende gewesen harmlos nur.", "tokens": ["Sei", "al\u00b7les", "Le\u00b7ben\u00b7de", "ge\u00b7we\u00b7sen", "harm\u00b7los", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VAPP", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Und mit der Geister erst, oder des Menschen Falle,", "tokens": ["Und", "mit", "der", "Geis\u00b7ter", "erst", ",", "o\u00b7der", "des", "Men\u00b7schen", "Fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "$,", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hab' auch hervorgekehrt die Sch\u00f6pfung Klau' und Kralle.", "tokens": ["Hab'", "auch", "her\u00b7vor\u00b7ge\u00b7kehrt", "die", "Sch\u00f6p\u00b7fung", "Klau'", "und", "Kral\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Erst friedlich wandelten Hirsch, Elefant und Stier,", "tokens": ["Erst", "fried\u00b7lich", "wan\u00b7del\u00b7ten", "Hirsch", ",", "E\u00b7le\u00b7fant", "und", "Stier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Kamel und anderes unschuldiges Gethier.", "tokens": ["Ka\u00b7mel", "und", "an\u00b7de\u00b7res", "un\u00b7schul\u00b7di\u00b7ges", "Ge\u00b7thier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "ADJA", "NN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}}, "stanza.4": {"line.1": {"text": "Hervorgesprungen dann sei sp\u00e4ter L\u00f6w' und Tieger,", "tokens": ["Her\u00b7vor\u00b7ge\u00b7sprun\u00b7gen", "dann", "sei", "sp\u00e4\u00b7ter", "L\u00f6\u00b7w'", "und", "Tie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+---+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie aus der Menschheit Schoo\u00df der M\u00f6rder und der Krieger;", "tokens": ["Wie", "aus", "der", "Menschheit", "Schoo\u00df", "der", "M\u00f6r\u00b7der", "und", "der", "Krie\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Die nun von Blut und Raub sich ihrer Br\u00fcder n\u00e4hren,", "tokens": ["Die", "nun", "von", "Blut", "und", "Raub", "sich", "ih\u00b7rer", "Br\u00fc\u00b7der", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "KON", "NN", "PRF", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da jene sich mit Laub und Gras begn\u00fcgt und Aehren.", "tokens": ["Da", "je\u00b7ne", "sich", "mit", "Laub", "und", "Gras", "be\u00b7gn\u00fcgt", "und", "A\u00b7eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PRF", "APPR", "NN", "KON", "NN", "VVPP", "KON", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Die goldne Zeit wird neu, wann seinen Fra\u00df vergi\u00dft", "tokens": ["Die", "gold\u00b7ne", "Zeit", "wird", "neu", ",", "wann", "sei\u00b7nen", "Fra\u00df", "ver\u00b7gi\u00dft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Leu einmal und Heu alswie der Ochse fri\u00dft.", "tokens": ["Der", "Leu", "ein\u00b7mal", "und", "Heu", "als\u00b7wie", "der", "O\u00b7chse", "fri\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KON", "NN", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "War eine Unschuld das, zu essen Pflanzenspeise?", "tokens": ["War", "ei\u00b7ne", "Un\u00b7schuld", "das", ",", "zu", "es\u00b7sen", "Pflan\u00b7zen\u00b7spei\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PDS", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch eine Unschuld war es nur vergleichungsweise.", "tokens": ["Doch", "ei\u00b7ne", "Un\u00b7schuld", "war", "es", "nur", "ver\u00b7glei\u00b7chungs\u00b7wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Alsob nur Leben sei, wo Athem ist und Hauch!", "tokens": ["Al\u00b7sob", "nur", "Le\u00b7ben", "sei", ",", "wo", "A\u00b7them", "ist", "und", "Hauch", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VAFIN", "$,", "PWAV", "NN", "VAFIN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Thiere nicht allein, die Pflanzen athmen auch.", "tokens": ["Die", "Thie\u00b7re", "nicht", "al\u00b7lein", ",", "die", "Pflan\u00b7zen", "ath\u00b7men", "auch", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "$,", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Einst hatten desto mehr die armen aufzusch\u00fcsseln", "tokens": ["Einst", "hat\u00b7ten", "des\u00b7to", "mehr", "die", "ar\u00b7men", "auf\u00b7zu\u00b7sch\u00fcs\u00b7seln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den uranf\u00e4nglichen mit ungeheuern R\u00fcsseln.", "tokens": ["Den", "u\u00b7ran\u00b7f\u00e4ng\u00b7li\u00b7chen", "mit", "un\u00b7ge\u00b7heu\u00b7ern", "R\u00fcs\u00b7seln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Und wo ein Lebendes noch hat der Nahrung Noth,", "tokens": ["Und", "wo", "ein", "Le\u00b7ben\u00b7des", "noch", "hat", "der", "Nah\u00b7rung", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da mit dem Leben ist gegeben auch der Tod.", "tokens": ["Da", "mit", "dem", "Le\u00b7ben", "ist", "ge\u00b7ge\u00b7ben", "auch", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "VVPP", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Der Schmetterling allein, der fr\u00e4\u00df'gen Raup' entstammt,", "tokens": ["Der", "Schmet\u00b7ter\u00b7ling", "al\u00b7lein", ",", "der", "fr\u00e4\u00df'\u00b7gen", "Raup'", "ent\u00b7stammt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "I\u00dft Duft nur und besch\u00e4mt die andern allesammt.", "tokens": ["I\u00dft", "Duft", "nur", "und", "be\u00b7sch\u00e4mt", "die", "an\u00b7dern", "al\u00b7le\u00b7sammt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "KON", "ADJD", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ein Vorbild ist er drum des Menschen h\u00f6herm Streben,", "tokens": ["Ein", "Vor\u00b7bild", "ist", "er", "drum", "des", "Men\u00b7schen", "h\u00f6\u00b7herm", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PAV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn aus dem Raupenstand er einst sich wird erheben.", "tokens": ["Wenn", "aus", "dem", "Rau\u00b7pen\u00b7stand", "er", "einst", "sich", "wird", "er\u00b7he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "ADV", "PRF", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Inzwischen steht er hier, wie er vom Anfang stand,", "tokens": ["I\u00b7nzwi\u00b7schen", "steht", "er", "hier", ",", "wie", "er", "vom", "An\u00b7fang", "stand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Thiere beider Art zu recht- und linker Hand.", "tokens": ["Die", "Thie\u00b7re", "bei\u00b7der", "Art", "zu", "recht", "und", "lin\u00b7ker", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "APPR", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Die edlen R\u00e4uber hier, und dort die Pflanzenfresser;", "tokens": ["Die", "ed\u00b7len", "R\u00e4u\u00b7ber", "hier", ",", "und", "dort", "die", "Pflan\u00b7zen\u00b7fres\u00b7ser", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$,", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er thut es beiden gleich, und Niemand kann es besser.", "tokens": ["Er", "thut", "es", "bei\u00b7den", "gleich", ",", "und", "Nie\u00b7mand", "kann", "es", "bes\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "ADV", "$,", "KON", "PIS", "VMFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Dazu sind ihm verliehn die beiderart'gen Z\u00e4hne,", "tokens": ["Da\u00b7zu", "sind", "ihm", "ver\u00b7liehn", "die", "bei\u00b7der\u00b7art'\u00b7gen", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die einen von dem Lamm, die andern der Hy\u00e4ne.", "tokens": ["Die", "ei\u00b7nen", "von", "dem", "Lamm", ",", "die", "an\u00b7dern", "der", "Hy\u00b7\u00e4\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "APPR", "ART", "NN", "$,", "PRELS", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Er kann, nach Zeit und Ort, mehr die, mehr jene brauchen,", "tokens": ["Er", "kann", ",", "nach", "Zeit", "und", "Ort", ",", "mehr", "die", ",", "mehr", "je\u00b7ne", "brau\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "APPR", "NN", "KON", "NN", "$,", "ADV", "ART", "$,", "ADV", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ins irdisch schwere sich mehr oder minder tauchen.", "tokens": ["Ins", "ir\u00b7disch", "schwe\u00b7re", "sich", "mehr", "o\u00b7der", "min\u00b7der", "tau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJD", "VVFIN", "PRF", "ADV", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Unschuld'ger machet ihn unschuld'ge Pflanzenspeise,", "tokens": ["Un\u00b7schuld'\u00b7ger", "ma\u00b7chet", "ihn", "un\u00b7schuld'\u00b7ge", "Pflan\u00b7zen\u00b7spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Doch diese Unschuld auch ist nur vergleichungsweise.", "tokens": ["Doch", "die\u00b7se", "Un\u00b7schuld", "auch", "ist", "nur", "ver\u00b7glei\u00b7chungs\u00b7wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}