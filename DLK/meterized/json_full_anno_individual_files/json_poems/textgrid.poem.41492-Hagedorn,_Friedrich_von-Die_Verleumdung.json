{"textgrid.poem.41492": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Die Verleumdung", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Stolzer Sch\u00f6nen Grausamkeiten", "tokens": ["Stol\u00b7zer", "Sch\u00f6\u00b7nen", "Grau\u00b7sam\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind noch immer ungemein.", "tokens": ["Sind", "noch", "im\u00b7mer", "un\u00b7ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch die Spr\u00f6den unsrer Zeiten", "tokens": ["Auch", "die", "Spr\u00f6\u00b7den", "uns\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nnen ewig spr\u00f6de sein.", "tokens": ["K\u00f6n\u00b7nen", "e\u00b7wig", "spr\u00f6\u00b7de", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VVFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Unempfindlichkeit und Tugend", "tokens": ["Un\u00b7emp\u00b7find\u00b7lich\u00b7keit", "und", "Tu\u00b7gend"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind der Doris Eigenthum;", "tokens": ["Sind", "der", "Do\u00b7ris", "Ei\u00b7gen\u00b7thum", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Beide schm\u00fccken ihre Jugend", "tokens": ["Bei\u00b7de", "schm\u00fc\u00b7cken", "ih\u00b7re", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Jugend ihren Ruhm.", "tokens": ["Und", "die", "Ju\u00b7gend", "ih\u00b7ren", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Dieser Vorzug lautrer Ehre,", "tokens": ["Die\u00b7ser", "Vor\u00b7zug", "laut\u00b7rer", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese Strenge, diese Zucht", "tokens": ["Die\u00b7se", "Stren\u00b7ge", ",", "die\u00b7se", "Zucht"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stammen aus der Mutter Lehre,", "tokens": ["Stam\u00b7men", "aus", "der", "Mut\u00b7ter", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind nur ihres Beispiels Frucht.", "tokens": ["Sind", "nur", "ih\u00b7res", "Bei\u00b7spiels", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Redet nicht von Scherz und K\u00fcssen,", "tokens": ["Re\u00b7det", "nicht", "von", "Scherz", "und", "K\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo ihr Martha kommen seht:", "tokens": ["Wo", "ihr", "Mar\u00b7tha", "kom\u00b7men", "seht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NE", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr empfindliches Gewissen", "tokens": ["Ihr", "emp\u00b7find\u00b7li\u00b7ches", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hasset, was so weltlich steht.", "tokens": ["Has\u00b7set", ",", "was", "so", "welt\u00b7lich", "steht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Liebe kann zwar Huld erwerben;", "tokens": ["Lie\u00b7be", "kann", "zwar", "Huld", "er\u00b7wer\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber bei Mirenen nicht:", "tokens": ["A\u00b7ber", "bei", "Mi\u00b7re\u00b7nen", "nicht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil sie nimmer ohn' Entf\u00e4rben", "tokens": ["Weil", "sie", "nim\u00b7mer", "ohn'", "Ent\u00b7f\u00e4r\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von verliebten Dingen spricht.", "tokens": ["Von", "ver\u00b7lieb\u00b7ten", "Din\u00b7gen", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sylvia wird hoch gepriesen:", "tokens": ["Syl\u00b7via", "wird", "hoch", "ge\u00b7prie\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Denn sie hat in kurzer Zeit", "tokens": ["Denn", "sie", "hat", "in", "kur\u00b7zer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zehn Verehrer abgewiesen,", "tokens": ["Zehn", "Ver\u00b7eh\u00b7rer", "ab\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und den eilften hart bedr\u00e4ut.", "tokens": ["Und", "den", "eilf\u00b7ten", "hart", "be\u00b7dr\u00e4ut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Edle Freiheit, mein Vergn\u00fcgen!", "tokens": ["Ed\u00b7le", "Frei\u00b7heit", ",", "mein", "Ver\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Singet Chloris tausendmal;", "tokens": ["Sin\u00b7get", "Chlo\u00b7ris", "tau\u00b7send\u00b7mal", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es ist, sie zu besiegen,", "tokens": ["Und", "es", "ist", ",", "sie", "zu", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwerer als die Kaiserwahl.", "tokens": ["Schwe\u00b7rer", "als", "die", "Kai\u00b7ser\u00b7wahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Tiefgesuchte Weisheitschl\u00fcsse", "tokens": ["Tief\u00b7ge\u00b7such\u00b7te", "Weis\u00b7heitsc\u00b7hl\u00fcs\u00b7se"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind Elmirens Zeitvertreib.", "tokens": ["Sind", "El\u00b7mi\u00b7rens", "Zeit\u00b7ver\u00b7treib", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Begriff gemeiner K\u00fcsse", "tokens": ["Der", "Be\u00b7griff", "ge\u00b7mei\u00b7ner", "K\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Reizen kein gelehrtes Weib.", "tokens": ["Rei\u00b7zen", "kein", "ge\u00b7lehr\u00b7tes", "Weib", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Iris t\u00e4ndelt, scherzt und singet,", "tokens": ["I\u00b7ris", "t\u00e4n\u00b7delt", ",", "scherzt", "und", "sin\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6hnt und lacht der Leidenschaft.", "tokens": ["H\u00f6hnt", "und", "lacht", "der", "Lei\u00b7den\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was auch sonst ein Herz bezwinget,", "tokens": ["Was", "auch", "sonst", "ein", "Herz", "be\u00b7zwin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat an ihrem keine Kraft.", "tokens": ["Hat", "an", "ih\u00b7rem", "kei\u00b7ne", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Flavia will nichts gestatten,", "tokens": ["Fla\u00b7via", "will", "nichts", "ge\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIS", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Was den Schein des Paarens hat;", "tokens": ["Was", "den", "Schein", "des", "Paa\u00b7rens", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sie z\u00fcrnt auf ihren Schatten,", "tokens": ["Und", "sie", "z\u00fcrnt", "auf", "ih\u00b7ren", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil er ihr zu sehr sich naht.", "tokens": ["Weil", "er", "ihr", "zu", "sehr", "sich", "naht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKA", "ADV", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "O die Welt k\u00f6mmt auf die Neige!", "tokens": ["O", "die", "Welt", "k\u00f6mmt", "auf", "die", "Nei\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch der Unschuld schont man nicht:", "tokens": ["Auch", "der", "Un\u00b7schuld", "schont", "man", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil der Unschuld oft ein Zeuge", "tokens": ["Weil", "der", "Un\u00b7schuld", "oft", "ein", "Zeu\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihrer Lauterkeit gebricht.", "tokens": ["Ih\u00b7rer", "Lau\u00b7ter\u00b7keit", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Stolzer Sch\u00f6nen Grausamkeiten", "tokens": ["Stol\u00b7zer", "Sch\u00f6\u00b7nen", "Grau\u00b7sam\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind noch immer ungemein.", "tokens": ["Sind", "noch", "im\u00b7mer", "un\u00b7ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch die Spr\u00f6den unsrer Zeiten", "tokens": ["Auch", "die", "Spr\u00f6\u00b7den", "uns\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nnen ewig spr\u00f6de sein.", "tokens": ["K\u00f6n\u00b7nen", "e\u00b7wig", "spr\u00f6\u00b7de", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VVFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Unempfindlichkeit und Tugend", "tokens": ["Un\u00b7emp\u00b7find\u00b7lich\u00b7keit", "und", "Tu\u00b7gend"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind der Doris Eigenthum;", "tokens": ["Sind", "der", "Do\u00b7ris", "Ei\u00b7gen\u00b7thum", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Beide schm\u00fccken ihre Jugend", "tokens": ["Bei\u00b7de", "schm\u00fc\u00b7cken", "ih\u00b7re", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Jugend ihren Ruhm.", "tokens": ["Und", "die", "Ju\u00b7gend", "ih\u00b7ren", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Dieser Vorzug lautrer Ehre,", "tokens": ["Die\u00b7ser", "Vor\u00b7zug", "laut\u00b7rer", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese Strenge, diese Zucht", "tokens": ["Die\u00b7se", "Stren\u00b7ge", ",", "die\u00b7se", "Zucht"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stammen aus der Mutter Lehre,", "tokens": ["Stam\u00b7men", "aus", "der", "Mut\u00b7ter", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind nur ihres Beispiels Frucht.", "tokens": ["Sind", "nur", "ih\u00b7res", "Bei\u00b7spiels", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Redet nicht von Scherz und K\u00fcssen,", "tokens": ["Re\u00b7det", "nicht", "von", "Scherz", "und", "K\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo ihr Martha kommen seht:", "tokens": ["Wo", "ihr", "Mar\u00b7tha", "kom\u00b7men", "seht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NE", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr empfindliches Gewissen", "tokens": ["Ihr", "emp\u00b7find\u00b7li\u00b7ches", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hasset, was so weltlich steht.", "tokens": ["Has\u00b7set", ",", "was", "so", "welt\u00b7lich", "steht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Liebe kann zwar Huld erwerben;", "tokens": ["Lie\u00b7be", "kann", "zwar", "Huld", "er\u00b7wer\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber bei Mirenen nicht:", "tokens": ["A\u00b7ber", "bei", "Mi\u00b7re\u00b7nen", "nicht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil sie nimmer ohn' Entf\u00e4rben", "tokens": ["Weil", "sie", "nim\u00b7mer", "ohn'", "Ent\u00b7f\u00e4r\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von verliebten Dingen spricht.", "tokens": ["Von", "ver\u00b7lieb\u00b7ten", "Din\u00b7gen", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Sylvia wird hoch gepriesen:", "tokens": ["Syl\u00b7via", "wird", "hoch", "ge\u00b7prie\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Denn sie hat in kurzer Zeit", "tokens": ["Denn", "sie", "hat", "in", "kur\u00b7zer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zehn Verehrer abgewiesen,", "tokens": ["Zehn", "Ver\u00b7eh\u00b7rer", "ab\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und den eilften hart bedr\u00e4ut.", "tokens": ["Und", "den", "eilf\u00b7ten", "hart", "be\u00b7dr\u00e4ut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Edle Freiheit, mein Vergn\u00fcgen!", "tokens": ["Ed\u00b7le", "Frei\u00b7heit", ",", "mein", "Ver\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Singet Chloris tausendmal;", "tokens": ["Sin\u00b7get", "Chlo\u00b7ris", "tau\u00b7send\u00b7mal", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es ist, sie zu besiegen,", "tokens": ["Und", "es", "ist", ",", "sie", "zu", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwerer als die Kaiserwahl.", "tokens": ["Schwe\u00b7rer", "als", "die", "Kai\u00b7ser\u00b7wahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Tiefgesuchte Weisheitschl\u00fcsse", "tokens": ["Tief\u00b7ge\u00b7such\u00b7te", "Weis\u00b7heitsc\u00b7hl\u00fcs\u00b7se"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind Elmirens Zeitvertreib.", "tokens": ["Sind", "El\u00b7mi\u00b7rens", "Zeit\u00b7ver\u00b7treib", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Begriff gemeiner K\u00fcsse", "tokens": ["Der", "Be\u00b7griff", "ge\u00b7mei\u00b7ner", "K\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Reizen kein gelehrtes Weib.", "tokens": ["Rei\u00b7zen", "kein", "ge\u00b7lehr\u00b7tes", "Weib", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Iris t\u00e4ndelt, scherzt und singet,", "tokens": ["I\u00b7ris", "t\u00e4n\u00b7delt", ",", "scherzt", "und", "sin\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6hnt und lacht der Leidenschaft.", "tokens": ["H\u00f6hnt", "und", "lacht", "der", "Lei\u00b7den\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was auch sonst ein Herz bezwinget,", "tokens": ["Was", "auch", "sonst", "ein", "Herz", "be\u00b7zwin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat an ihrem keine Kraft.", "tokens": ["Hat", "an", "ih\u00b7rem", "kei\u00b7ne", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Flavia will nichts gestatten,", "tokens": ["Fla\u00b7via", "will", "nichts", "ge\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIS", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Was den Schein des Paarens hat;", "tokens": ["Was", "den", "Schein", "des", "Paa\u00b7rens", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sie z\u00fcrnt auf ihren Schatten,", "tokens": ["Und", "sie", "z\u00fcrnt", "auf", "ih\u00b7ren", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil er ihr zu sehr sich naht.", "tokens": ["Weil", "er", "ihr", "zu", "sehr", "sich", "naht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKA", "ADV", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "O die Welt k\u00f6mmt auf die Neige!", "tokens": ["O", "die", "Welt", "k\u00f6mmt", "auf", "die", "Nei\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch der Unschuld schont man nicht:", "tokens": ["Auch", "der", "Un\u00b7schuld", "schont", "man", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil der Unschuld oft ein Zeuge", "tokens": ["Weil", "der", "Un\u00b7schuld", "oft", "ein", "Zeu\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihrer Lauterkeit gebricht.", "tokens": ["Ih\u00b7rer", "Lau\u00b7ter\u00b7keit", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dennoch sagt und glaubet man,", "tokens": ["Den\u00b7noch", "sagt", "und", "glau\u00b7bet", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df man sie erbitten kann.", "tokens": ["Da\u00df", "man", "sie", "er\u00b7bit\u00b7ten", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}