{"textgrid.poem.52393": {"metadata": {"author": {"name": "Reuter, Fritz", "birth": "N.A.", "death": "N.A."}, "title": "43. Wat ut en Scheper warden kann", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.85", "sv:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Oll Mutter Knaksch, de hadd en Jungen,", "tokens": ["Oll", "Mut\u00b7ter", "Knaksch", ",", "de", "hadd", "en", "Jun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man einen hadd s', doch dese ein,", "tokens": ["Man", "ei\u00b7nen", "hadd", "s'", ",", "doch", "de\u00b7se", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "NE", "$,", "KON", "PDS", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "De was dorf\u00f6r ok gaud gelungen \u2013", "tokens": ["De", "was", "dor\u00b7f\u00f6r", "ok", "gaud", "ge\u00b7lun\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So'n Schapskopp hadd de Welt nich seihn;", "tokens": ["So'n", "Schaps\u00b7kopp", "hadd", "de", "Welt", "nich", "seihn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch Mutter Knaksch, de gl\u00f6wt nich dran,", "tokens": ["Doch", "Mut\u00b7ter", "Knaksch", ",", "de", "gl\u00f6wt", "nich", "dran", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "$,", "NE", "VVFIN", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dat ehr leiw J\u00fcnging dumm s\u00fcll sin,", "tokens": ["Dat", "ehr", "leiw", "J\u00fcn\u00b7ging", "dumm", "s\u00fcll", "sin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sei kek in ehren S\u00e4hn Jehann", "tokens": ["Sei", "kek", "in", "eh\u00b7ren", "S\u00e4hn", "Je\u00b7hann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "APPR", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "As in en gollen B\u00e4ker rin.", "tokens": ["As", "in", "en", "gol\u00b7len", "B\u00e4\u00b7ker", "rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Jehann, de m\u00fc\u00dft nu Scheper warden,", "tokens": ["Je\u00b7hann", ",", "de", "m\u00fc\u00dft", "nu", "Sche\u00b7per", "war\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "VMFIN", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Un wenn sei em taum Naren hadden,", "tokens": ["Un", "wenn", "sei", "em", "taum", "Na\u00b7ren", "had\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "FM", "FM", "FM", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Denn tr\u00f6st em Mutter: \u00bbDu b\u00fcst kl\u00e4uker;", "tokens": ["Denn", "tr\u00f6st", "em", "Mut\u00b7ter", ":", "\u00bb", "Du", "b\u00fcst", "kl\u00e4u\u00b7ker", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "$.", "$(", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ut'n Scheper\u00ab, s\u00e4d se, \u00bbun Aptheiker,", "tokens": ["Ut'n", "Sche\u00b7per", "\u00ab", ",", "s\u00e4d", "se", ",", "\u00bb", "un", "A\u00b7pthei\u00b7ker", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$(", "$,", "FM", "FM", "$,", "$(", "FM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Min S\u00e4hning, dor kann allens warden.\u00ab", "tokens": ["Min", "S\u00e4h\u00b7ning", ",", "dor", "kann", "al\u00b7lens", "war\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VMFIN", "ADV", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Na, 't kamm ok so. \u2013 De Tid kamm 'ranne,", "tokens": ["Na", ",", "'t", "kamm", "ok", "so", ".", "\u2013", "De", "Tid", "kamm", "'ran\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NE", "VVFIN", "ADV", "ADV", "$.", "$(", "NE", "NE", "VVFIN", "NE", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dunn was't v\u00f6rbi mit L\u00e4mmergripen,", "tokens": ["Dunn", "was't", "v\u00f6r\u00b7bi", "mit", "L\u00e4m\u00b7mer\u00b7gri\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dunn los't uns' leiw l\u00fctt Knaken Hanne", "tokens": ["Dunn", "los't", "un\u00b7s'", "leiw", "l\u00fctt", "Kna\u00b7ken", "Han\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sick fast un m\u00fc\u00dft von Hahnen-Liepen", "tokens": ["Sick", "fast", "un", "m\u00fc\u00dft", "von", "Hah\u00b7nen\u00b7Lie\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "FM", "VMFIN", "APPR", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Hen nah Swerin tau de Soldaten.", "tokens": ["Hen", "nah", "Swe\u00b7rin", "tau", "de", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "NE", "NE", "NE", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Dor st\u00fcnn hei v\u00f6r de Kummischon.", "tokens": ["Dor", "st\u00fcnn", "hei", "v\u00f6r", "de", "Kum\u00b7mi\u00b7schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "\u00bbfor Grenadier zu kurz geraten,", "tokens": ["\u00bb", "for", "Gre\u00b7na\u00b7di\u00b7er", "zu", "kurz", "ge\u00b7ra\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "PTKA", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "For J\u00e4ger nich von Proportschon,", "tokens": ["For", "J\u00e4\u00b7ger", "nich", "von", "Pro\u00b7port\u00b7schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "For di Dreiguner im Ges\u00e4\u00df zu eng,", "tokens": ["For", "di", "Drei\u00b7gu\u00b7ner", "im", "Ge\u00b7s\u00e4\u00df", "zu", "eng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "APPRART", "NN", "PTKA", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.10": {"text": "Zu brauchen blo\u00df bei die Kanon,", "tokens": ["Zu", "brau\u00b7chen", "blo\u00df", "bei", "die", "Ka\u00b7non", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Un geht's nich da, bei's schwer Gedr\u00e4nk.\u00ab", "tokens": ["Un", "geht's", "nich", "da", ",", "bei's", "schwer", "Ge\u00b7dr\u00e4nk", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "PTKNEG", "ADV", "$,", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Un kamm nu tau'r Attolleri.", "tokens": ["Un", "kamm", "nu", "tau'r", "At\u00b7tol\u00b7le\u00b7ri", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.13": {"text": "Dor m\u00fc\u00dft hei nu von morgens fr\u00fch", "tokens": ["Dor", "m\u00fc\u00dft", "hei", "nu", "von", "mor\u00b7gens", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "NE", "ADV", "APPR", "ADV", "ADJD"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.14": {"text": "Bet's abends mit den Wischer stahn", "tokens": ["Bet's", "a\u00b7bends", "mit", "den", "Wi\u00b7scher", "stahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Un mit de Lunt up't Z\u00fcndlock slahn", "tokens": ["Un", "mit", "de", "Lunt", "up't", "Z\u00fcnd\u00b7lock", "slahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Un mit de Handspeik r\u00fcm handtieren,", "tokens": ["Un", "mit", "de", "Hand\u00b7speik", "r\u00fcm", "hand\u00b7tie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "NE", "NE", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.17": {"text": "Dat Riden un dat F\u00fchren lihren", "tokens": ["Dat", "Ri\u00b7den", "un", "dat", "F\u00fch\u00b7ren", "lih\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "FM", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Un \u00fcmmer Proppen \u00e4wer Proppen", "tokens": ["Un", "\u00fcm\u00b7mer", "Prop\u00b7pen", "\u00e4\u00b7wer", "Prop\u00b7pen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "In de Kanon herinne stoppen.", "tokens": ["In", "de", "Ka\u00b7non", "he\u00b7rin\u00b7ne", "stop\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Na, dorbi stellt sick uns' Jehann", "tokens": ["Na", ",", "dor\u00b7bi", "stellt", "sick", "un\u00b7s'", "Je\u00b7hann"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "Denn ganz gef\u00e4hrlich abellsch an,", "tokens": ["Denn", "ganz", "ge\u00b7f\u00e4hr\u00b7lich", "a\u00b7bell\u00b7sch", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Un knapp man hett hei't richtig truffen.", "tokens": ["Un", "knapp", "man", "hett", "hei't", "rich\u00b7tig", "truf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "VAFIN", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Un wat sin Unt'roffzier ded wesen,", "tokens": ["Un", "wat", "sin", "Unt'\u00b7roff\u00b7zier", "ded", "we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "De w\u00fcrd em heimlich \u00fcmmer knuffen,", "tokens": ["De", "w\u00fcrd", "em", "heim\u00b7lich", "\u00fcm\u00b7mer", "knuf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJA", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Wil't \u00f6ffentlich verbaden wir.", "tokens": ["Wil't", "\u00f6f\u00b7fent\u00b7lich", "ver\u00b7ba\u00b7den", "wir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVFIN", "PPER", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Na, einmal w\u00fcrd de Unt'roffzier", "tokens": ["Na", ",", "ein\u00b7mal", "w\u00fcrd", "de", "Unt'\u00b7roff\u00b7zier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Abends Instrukschonen lesen,", "tokens": ["Des", "A\u00b7bends", "Inst\u00b7ruk\u00b7scho\u00b7nen", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Utf\u00fchrlich sihr un sihr gelihrt.", "tokens": ["Ut\u00b7f\u00fchr\u00b7lich", "sihr", "un", "sihr", "ge\u00b7lihrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "FM", "FM", "FM", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "\u00bbwir\u00ab, s\u00e4d'e, \u00bbKinder, s\u00fcnd Soldaten,", "tokens": ["\u00bb", "wir", "\u00ab", ",", "s\u00e4d'e", ",", "\u00bb", "Kin\u00b7der", ",", "s\u00fcnd", "Sol\u00b7da\u00b7ten", ","], "token_info": ["punct", "word", "punct", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "$(", "$,", "VVFIN", "$,", "$(", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf uns beruhn die Heldentaten,", "tokens": ["Auf", "uns", "be\u00b7ruhn", "die", "Hel\u00b7den\u00b7ta\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vor allen auf Attolleri,", "tokens": ["Vor", "al\u00b7len", "auf", "At\u00b7tol\u00b7le\u00b7ri", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Un nidertr\u00e4chtig, Jungens, wir't,", "tokens": ["Un", "ni\u00b7der\u00b7tr\u00e4ch\u00b7tig", ",", "Jun\u00b7gens", ",", "wir't", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADJD", "$,", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn einer von der Kumpani", "tokens": ["Wenn", "ei\u00b7ner", "von", "der", "Kum\u00b7pa\u00b7ni"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das nicht zu jeder Stunde w\u00fc\u00dft", "tokens": ["Das", "nicht", "zu", "je\u00b7der", "Stun\u00b7de", "w\u00fc\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und es im Busen in sich tr\u00e4gt:", "tokens": ["Und", "es", "im", "Bu\u00b7sen", "in", "sich", "tr\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Gottlob! Ich b\u00fcn Attollerist. \u2013", "tokens": ["Gott\u00b7lob", "!", "Ich", "b\u00fcn", "At\u00b7tol\u00b7le\u00b7rist", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Nu antwurt, Knak der zweite\u00ab, rep'e,", "tokens": ["Nu", "ant\u00b7wurt", ",", "Knak", "der", "zwei\u00b7te", "\u00ab", ",", "rep'e", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "NN", "ART", "ADJA", "$(", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbwas b\u00fcst du, wenn dich einer fr\u00e4gt?\u00ab", "tokens": ["\u00bb", "was", "b\u00fcst", "du", ",", "wenn", "dich", "ei\u00b7ner", "fr\u00e4gt", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbick\u00ab, seggt Jehann, \u00bbick b\u00fcn en Scheper.\u00ab", "tokens": ["\u00bb", "ick", "\u00ab", ",", "seggt", "Je\u00b7hann", ",", "\u00bb", "ick", "b\u00fcn", "en", "Sche\u00b7per", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$(", "$,", "VVFIN", "NE", "$,", "$(", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "As slaten is de Instrukschon,", "tokens": ["As", "sla\u00b7ten", "is", "de", "Inst\u00b7ruk\u00b7schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Dunn lett de Unt'roffzier de annern", "tokens": ["Dunn", "lett", "de", "Unt'\u00b7roff\u00b7zier", "de", "an\u00b7nern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Herute gahn un seggt tau Hannern:", "tokens": ["He\u00b7ru\u00b7te", "gahn", "un", "seggt", "tau", "Han\u00b7nern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "\u00bboh, bleib ein bi\u00dfchen hier, mein Sohn.\u00ab", "tokens": ["\u00bb", "oh", ",", "bleib", "ein", "bi\u00df\u00b7chen", "hier", ",", "mein", "Sohn", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "$,", "VVFIN", "ART", "PIS", "ADV", "$,", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Un kriggt em fat't un knufft un pufft", "tokens": ["Un", "kriggt", "em", "fat't", "un", "knufft", "un", "pufft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.20": {"text": "Up Hannern in. \u00bbWas b\u00fcst du, Schuft?", "tokens": ["Up", "Han\u00b7nern", "in", ".", "\u00bb", "Was", "b\u00fcst", "du", ",", "Schuft", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["FM.xy", "FM.xy", "FM.xy", "$.", "$(", "PWS", "VVFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "En Scheper b\u00fcst du? \u2013 Na, da soll doch ein", "tokens": ["En", "Sche\u00b7per", "b\u00fcst", "du", "?", "\u2013", "Na", ",", "da", "soll", "doch", "ein"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "VVFIN", "PPER", "$.", "$(", "ITJ", "$,", "ADV", "VMFIN", "ADV", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Zehntausend Donnerwetter schlagen", "tokens": ["Zehn\u00b7tau\u00b7send", "Don\u00b7ner\u00b7wet\u00b7ter", "schla\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Zehn Klafter in die Erd hinein!", "tokens": ["Zehn", "Klaf\u00b7ter", "in", "die", "Erd", "hin\u00b7ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Ihr Kreuzschockschweren\u00f6ters m\u00fc\u00dft", "tokens": ["Ihr", "Kreuz\u00b7schock\u00b7schwe\u00b7re\u00b7n\u00f6\u00b7ters", "m\u00fc\u00dft"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Das Hochgef\u00fchl im Busen tragen:", "tokens": ["Das", "Hoch\u00b7ge\u00b7f\u00fchl", "im", "Bu\u00b7sen", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Gottlob! Ich bin Attolerist.\u00ab", "tokens": ["Gott\u00b7lob", "!", "Ich", "bin", "At\u00b7to\u00b7le\u00b7rist", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Un predigt so up Hannern in", "tokens": ["Un", "pre\u00b7digt", "so", "up", "Han\u00b7nern", "in"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Un makt dat Hochgef\u00e4uhl em klor,", "tokens": ["Un", "makt", "dat", "Hoch\u00b7ge\u00b7f\u00e4uhl", "em", "klor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.29": {"text": "Dat't ein noch nah en Virteljohr", "tokens": ["Dat't", "ein", "noch", "nah", "en", "Vir\u00b7tel\u00b7johr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Em von den Puckel lesen k\u00fcnn.", "tokens": ["Em", "von", "den", "Pu\u00b7ckel", "le\u00b7sen", "k\u00fcnn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Jehann, de schriwwt en schrewen Breiw", "tokens": ["Je\u00b7hann", ",", "de", "schriwwt", "en", "schre\u00b7wen", "Breiw"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "FM", "FM", "FM", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Muttern hen nah Hahnen-Liepen:", "tokens": ["An", "Mut\u00b7tern", "hen", "nah", "Hah\u00b7nen\u00b7Lie\u00b7pen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sin Lewen wir em doch tau leiw;", "tokens": ["Sin", "Le\u00b7wen", "wir", "em", "doch", "tau", "leiw", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Hei m\u00fcggt woll wedder L\u00e4mmer gripen,", "tokens": ["Hei", "m\u00fcggt", "woll", "wed\u00b7der", "L\u00e4m\u00b7mer", "gri\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "KON", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Hei m\u00fcggt woll wedder Hanschen kn\u00fctten", "tokens": ["Hei", "m\u00fcggt", "woll", "wed\u00b7der", "Han\u00b7schen", "kn\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KON", "NN", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Un achter'n Durenr\u00e4mel sitten,", "tokens": ["Un", "ach\u00b7ter'n", "Du\u00b7ren\u00b7r\u00e4\u00b7mel", "sit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hei m\u00fcggt woll wedder Hamel h\u00e4uden", "tokens": ["Hei", "m\u00fcggt", "woll", "wed\u00b7der", "Ha\u00b7mel", "h\u00e4u\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KON", "NN", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Un wull sin Sch\u00fcten nich mihr slahn,", "tokens": ["Un", "wull", "sin", "Sch\u00fc\u00b7ten", "nich", "mihr", "slahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Hei w\u00fc\u00dft nu, wo't em s\u00fclwen dahn.", "tokens": ["Hei", "w\u00fc\u00dft", "nu", ",", "wo't", "em", "s\u00fcl\u00b7wen", "dahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Un all de velen Scheper-Leiden,", "tokens": ["Un", "all", "de", "ve\u00b7len", "Sche\u00b7per\u00b7Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "De d\u00fcchten jitzt em Kleinigkeit,", "tokens": ["De", "d\u00fcch\u00b7ten", "jitzt", "em", "Klei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Un ok de Schap ehr Upsternatschigkeit,", "tokens": ["Un", "ok", "de", "Schap", "ehr", "U\u00b7pster\u00b7nat\u00b7schig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "De h\u00f6ll hei jitzt man v\u00f6r Pl\u00e4sier,", "tokens": ["De", "h\u00f6ll", "hei", "jitzt", "man", "v\u00f6r", "Pl\u00e4\u00b7sier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Denn't upsternatschte Veih up Irden wir", "tokens": ["Denn't", "ups\u00b7ter\u00b7natschte", "Veih", "up", "Ir\u00b7den", "wir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Sin grot Kanon un de Herr Unt'roffzier.", "tokens": ["Sin", "grot", "Ka\u00b7non", "un", "de", "Herr", "Unt'\u00b7roff\u00b7zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Na, Mutter Knaksch, de durt't denn sihr", "tokens": ["Na", ",", "Mut\u00b7ter", "Knaksch", ",", "de", "durt't", "denn", "sihr"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "NN", "NN", "$,", "NE", "VVPP", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un makt sick endlich up de Bein,", "tokens": ["Un", "makt", "sick", "end\u00b7lich", "up", "de", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADV", "NE", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Will doch mal dor taum Rechten seihn", "tokens": ["Will", "doch", "mal", "dor", "taum", "Rech\u00b7ten", "seihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "ADV", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Un fr\u00f6ggt sick ruppe nach Swerin", "tokens": ["Un", "fr\u00f6ggt", "sick", "rup\u00b7pe", "nach", "Swe\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "VVFIN", "APPR", "NE"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Un fr\u00f6ggt dor \u00fcmmer nah den Herrn", "tokens": ["Un", "fr\u00f6ggt", "dor", "\u00fcm\u00b7mer", "nah", "den", "Herrn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Attolleristen Hanne Knaken.", "tokens": ["At\u00b7tol\u00b7le\u00b7ris\u00b7ten", "Han\u00b7ne", "Kna\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sei wisen ehr nah de Kasern,", "tokens": ["Sei", "wi\u00b7sen", "ehr", "nah", "de", "Ka\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADJD", "NE", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Un as sei dor von Hannern spraken,", "tokens": ["Un", "as", "sei", "dor", "von", "Han\u00b7nern", "spra\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Dunn wisen s' ehr en En'nlang wider.", "tokens": ["Dunn", "wi\u00b7sen", "s'", "ehr", "en", "En'\u00b7nlang", "wi\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Dor stunn denn nu de Unt'roffzierer", "tokens": ["Dor", "stunn", "denn", "nu", "de", "Unt'\u00b7roff\u00b7zie\u00b7rer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Un hadd uns' Hannern in de Mak", "tokens": ["Un", "hadd", "un\u00b7s'", "Han\u00b7nern", "in", "de", "Mak"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "APPR", "NE", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Un knufft un pufft up Hannern in.", "tokens": ["Un", "knufft", "un", "pufft", "up", "Han\u00b7nern", "in", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.13": {"text": "Dunn ward uns' Mutter falsch tau Sinn,", "tokens": ["Dunn", "ward", "un\u00b7s'", "Mut\u00b7ter", "falsch", "tau", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "ADJD", "CARD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "K\u00fcmmt ran un seggt: \u00bbIs dat 'ne Sak?", "tokens": ["K\u00fcmmt", "ran", "un", "seggt", ":", "\u00bb", "Is", "dat", "'ne", "Sak", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "$.", "$(", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Wat hett Em min l\u00fctt Hanning dahn?", "tokens": ["Wat", "hett", "Em", "min", "l\u00fctt", "Han\u00b7ning", "dahn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wo kann Hei mi dat Kind hir slahn?", "tokens": ["Wo", "kann", "Hei", "mi", "dat", "Kind", "hir", "slahn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NE", "NE", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.17": {"text": "Wat st\u00f6tt Hei im dat J\u00fcnging?\u00ab seggt s',", "tokens": ["Wat", "st\u00f6tt", "Hei", "im", "dat", "J\u00fcn\u00b7ging", "?", "\u00ab", "seggt", "s'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$(", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "\u00bbkann Hei nich seggen: Hanning, so,", "tokens": ["\u00bb", "kann", "Hei", "nich", "seg\u00b7gen", ":", "Han\u00b7ning", ",", "so", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VMFIN", "NN", "PTKNEG", "VVINF", "$.", "NE", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Un dreih di links un dreih di rechts \u2013", "tokens": ["Un", "dreih", "di", "links", "un", "dreih", "di", "rechts", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Denn deiht dat leiwe Kind dat jo.", "tokens": ["Denn", "deiht", "dat", "lei\u00b7we", "Kind", "dat", "jo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "T\u00e4uw! Ick ward nah'n Gro\u00dfherzog gahn.\u00ab", "tokens": ["T\u00e4uw", "!", "Ick", "ward", "nah'n", "Gro\u00df\u00b7her\u00b7zog", "gahn", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "PPER", "VAFIN", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Na, dat is gaud! Geseggt, gedahn.", "tokens": ["Na", ",", "dat", "is", "gaud", "!", "Ge\u00b7seggt", ",", "ge\u00b7dahn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "FM.nl", "FM.nl", "FM.nl", "$.", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sei geiht glik an de richt'ge Sm\u00e4d';", "tokens": ["Sei", "geiht", "glik", "an", "de", "richt'\u00b7ge", "Sm\u00e4d'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "NN", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Paul Friedrich was't, de dunn regiert,", "tokens": ["Paul", "Fried\u00b7rich", "was't", ",", "de", "dunn", "re\u00b7giert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "De h\u00fcrt up jeden sine Red',", "tokens": ["De", "h\u00fcrt", "up", "je\u00b7den", "si\u00b7ne", "Red'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Un einen gauden Herren wir't", "tokens": ["Un", "ei\u00b7nen", "gau\u00b7den", "Her\u00b7ren", "wir't"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Un sihr f\u00f6r den gemeinen Mann.", "tokens": ["Un", "sihr", "f\u00f6r", "den", "ge\u00b7mei\u00b7nen", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Hei h\u00fcrt oll Knaksch ok fr\u00fcndlich an,", "tokens": ["Hei", "h\u00fcrt", "oll", "Knaksch", "ok", "fr\u00fcnd\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Doch endlich seggt hei: \u00bbMutter, nein!", "tokens": ["Doch", "end\u00b7lich", "seggt", "hei", ":", "\u00bb", "Mut\u00b7ter", ",", "nein", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKVZ", "$.", "$(", "NN", "$,", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Loslassen? Nein, das kann nicht sein!\u00ab", "tokens": ["Los\u00b7las\u00b7sen", "?", "Nein", ",", "das", "kann", "nicht", "sein", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "PTKANT", "$,", "PDS", "VMFIN", "PTKNEG", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Doch Mutter lett nich af mit Qu\u00e4len,", "tokens": ["Doch", "Mut\u00b7ter", "lett", "nich", "af", "mit", "Qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "PTKNEG", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Hei s\u00fcll ehr doch den Jungen laten.", "tokens": ["Hei", "s\u00fcll", "ehr", "doch", "den", "Jun\u00b7gen", "la\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.12": {"text": "\u00bbdas\u00ab, seggt hei, \u00bbkann ich nicht befehlen,", "tokens": ["\u00bb", "das", "\u00ab", ",", "seggt", "hei", ",", "\u00bb", "kann", "ich", "nicht", "be\u00b7feh\u00b7len", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "$(", "$,", "VVFIN", "PTKVZ", "$,", "$(", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wer's einmal ist, der bleibt Soldat;", "tokens": ["Wer's", "ein\u00b7mal", "ist", ",", "der", "bleibt", "Sol\u00b7dat", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VAFIN", "$,", "PRELS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und wer den bunten Rock anhat,", "tokens": ["Und", "wer", "den", "bun\u00b7ten", "Rock", "an\u00b7hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der wird auch t\u00fcchtig exerziert.\u00ab", "tokens": ["Der", "wird", "auch", "t\u00fcch\u00b7tig", "ex\u00b7er\u00b7ziert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Un wull de Ollsch en Daler schenken,", "tokens": ["Un", "wull", "de", "Ollsch", "en", "Da\u00b7ler", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "NE", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Wil dat ehr Bidden em doch r\u00fchrt,", "tokens": ["Wil", "dat", "ehr", "Bid\u00b7den", "em", "doch", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "ADJA", "ADV", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.18": {"text": "Un in de Tasch herinne grep'e.", "tokens": ["Un", "in", "de", "Tasch", "he\u00b7rin\u00b7ne", "grep'", "e."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "\u00bbje\u00ab, seggt de Ollsch, \u00bbSei m\u00f6ten ok bedenken,", "tokens": ["\u00bb", "je", "\u00ab", ",", "seggt", "de", "Ollsch", ",", "\u00bb", "Sei", "m\u00f6\u00b7ten", "ok", "be\u00b7den\u00b7ken", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "NE", "NE", "$,", "$(", "VAFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.20": {"text": "Ehr Ort, de hett ok s\u00fcs nicks lihrt,", "tokens": ["Ehr", "Ort", ",", "de", "hett", "ok", "s\u00fcs", "nicks", "lihrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Un min Jehann, dat is en Scheper.\u00ab", "tokens": ["Un", "min", "Je\u00b7hann", ",", "dat", "is", "en", "Sche\u00b7per", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "ART", "FM", "FM", "NN", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.22": {"text": "Ick denk, Paul Friedrich lacht sick scheiw.", "tokens": ["Ick", "denk", ",", "Paul", "Fried\u00b7rich", "lacht", "sick", "scheiw", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "NE", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "\u00bbna, hest den Jung'n doch woll tau leiw?\u00ab", "tokens": ["\u00bb", "na", ",", "hest", "den", "Jung'n", "doch", "woll", "tau", "leiw", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "ADJD", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "Seggt hei, \u00bbick will in desen Dagen", "tokens": ["Seggt", "hei", ",", "\u00bb", "ick", "will", "in", "de\u00b7sen", "Da\u00b7gen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "$(", "PPER", "VMFIN", "APPR", "PRELAT", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.25": {"text": "De Sak mi ganz genau befragen,", "tokens": ["De", "Sak", "mi", "ganz", "ge\u00b7nau", "be\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Un wenn dat jichtens passen deiht,", "tokens": ["Un", "wenn", "dat", "jich\u00b7tens", "pas\u00b7sen", "deiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.27": {"text": "Denn sall hei mit di t'r\u00fcgg nah Liepen", "tokens": ["Denn", "sall", "hei", "mit", "di", "t'\u00b7r\u00fcgg", "nah", "Lie\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "FM", "FM", "APPR", "NE", "NE", "ADJD", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.28": {"text": "Un sall dor wedder L\u00e4mmer gripen.\u00ab", "tokens": ["Un", "sall", "dor", "wed\u00b7der", "L\u00e4m\u00b7mer", "gri\u00b7pen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "NE", "KON", "NN", "VVINF", "$.", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.7": {"line.1": {"text": "Oll Knaksch bedankt sick denn un geiht", "tokens": ["Oll", "Knaksch", "be\u00b7dankt", "sick", "denn", "un", "geiht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "NE", "KON", "FM", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un k\u00fcmmt so nah de Wach hendal,", "tokens": ["Un", "k\u00fcmmt", "so", "nah", "de", "Wach", "hen\u00b7dal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Hanning h\u00fct taum irstenmal", "tokens": ["Wo", "Han\u00b7ning", "h\u00fct", "taum", "irs\u00b7ten\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In vullen Stat as Posten steiht.", "tokens": ["In", "vul\u00b7len", "Stat", "as", "Pos\u00b7ten", "steiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbjehanning\u00ab, seggt s', \u00bbnu k\u00fcmmst du fri,", "tokens": ["\u00bb", "je\u00b7han\u00b7ning", "\u00ab", ",", "seggt", "s'", ",", "\u00bb", "nu", "k\u00fcmmst", "du", "fri", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "$(", "$,", "VVFIN", "NE", "$,", "$(", "ADV", "VVFIN", "PPER", "NE", "$,"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "Nu is de Knufferi v\u00f6rbi,", "tokens": ["Nu", "is", "de", "Knuf\u00b7fe\u00b7ri", "v\u00f6r\u00b7bi", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ick b\u00fcn bi den Gro\u00dfherzog wesen,", "tokens": ["Ick", "b\u00fcn", "bi", "den", "Gro\u00df\u00b7her\u00b7zog", "we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "De ward den Kirl Leviten lesen.", "tokens": ["De", "ward", "den", "Kirl", "Le\u00b7vi\u00b7ten", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Doch wat hest du hir r\u00fcm tau stahn,", "tokens": ["Doch", "wat", "hest", "du", "hir", "r\u00fcm", "tau", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Kannst du nich in de Stuw' rin gahn?\u00ab", "tokens": ["Kannst", "du", "nich", "in", "de", "Stu\u00b7w'", "rin", "gahn", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "APPR", "NE", "NE", "ADV", "VVFIN", "$.", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Uns' Hanne kickt sick \u00e4ngstlich \u00fcm,", "tokens": ["Un\u00b7s'", "Han\u00b7ne", "kickt", "sick", "\u00e4ngst\u00b7lich", "\u00fcm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Ob em ok wer woll reden s\u00fcht,", "tokens": ["Ob", "em", "ok", "wer", "woll", "re\u00b7den", "s\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "PWS", "VMFIN", "VVINF", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Un flustert sacht mit halwe Stimm:", "tokens": ["Un", "flus\u00b7tert", "sacht", "mit", "hal\u00b7we", "Stimm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbh\u00fct is min Ihrendag, leiw Mutting; h\u00fct", "tokens": ["\u00bb", "h\u00fct", "is", "min", "Ih\u00b7ren\u00b7dag", ",", "leiw", "Mut\u00b7ting", ";", "h\u00fct"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["$(", "FM.la", "FM.la", "FM.la", "FM.la", "$,", "ADJD", "NN", "$.", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "B\u00fcn ick en hellisch grotes Dird", "tokens": ["B\u00fcn", "ick", "en", "hel\u00b7lisch", "gro\u00b7tes", "Dird"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM", "FM", "FM", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Un de dat Ganze kummandiert.\u00ab", "tokens": ["Un", "de", "dat", "Gan\u00b7ze", "kum\u00b7man\u00b7diert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.17": {"text": "\u00bbih wo?\u00ab seggt Mutter, \u00bbspa\u00df ok man!\u00ab", "tokens": ["\u00bb", "ih", "wo", "?", "\u00ab", "seggt", "Mut\u00b7ter", ",", "\u00bb", "spa\u00df", "ok", "man", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "PWAV", "$.", "$(", "VVFIN", "NN", "$,", "$(", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "\u00bbdat will'ck di wisen\u00ab, seggt Jehann", "tokens": ["\u00bb", "dat", "will'ck", "di", "wi\u00b7sen", "\u00ab", ",", "seggt", "Je\u00b7hann"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ART", "NN", "NE", "VVINF", "$(", "$,", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Un treckt sin Kes'metz stramm heran", "tokens": ["Un", "treckt", "sin", "Kes'\u00b7metz", "stramm", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "VVFIN", "PTKVZ"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.20": {"text": "Un br\u00f6llt nu m\u00e4glich: \u00bbWach heraus!\u00ab", "tokens": ["Un", "br\u00f6llt", "nu", "m\u00e4g\u00b7lich", ":", "\u00bb", "Wach", "he\u00b7raus", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "$.", "$(", "VVIMP", "PTKVZ", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Un Unt'roffzier un Attolleristen", "tokens": ["Un", "Unt'\u00b7roff\u00b7zier", "un", "At\u00b7tol\u00b7le\u00b7ris\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "FM", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Un Leutnant, allens st\u00f6rt herut.", "tokens": ["Un", "Leut\u00b7nant", ",", "al\u00b7lens", "st\u00f6rt", "he\u00b7rut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "De Leutnant fr\u00f6ggt: \u00bbWas ist denn los?", "tokens": ["De", "Leut\u00b7nant", "fr\u00f6ggt", ":", "\u00bb", "Was", "ist", "denn", "los", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "PWS", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Schildwache, wie? Was gibt's? Was ist denn?\u00ab", "tokens": ["Schild\u00b7wa\u00b7che", ",", "wie", "?", "Was", "gibt's", "?", "Was", "ist", "denn", "?", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PWAV", "$.", "PWS", "VVFIN", "$.", "PWS", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.25": {"text": "Un Hanning s\u00fcht so fr\u00fcndlich ut", "tokens": ["Un", "Han\u00b7ning", "s\u00fcht", "so", "fr\u00fcnd\u00b7lich", "ut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ADV", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Un seggt: \u00bbNe, hir is nicks gescheihn.", "tokens": ["Un", "seggt", ":", "\u00bb", "Ne", ",", "hir", "is", "nicks", "ge\u00b7scheihn", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "$(", "ART", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.27": {"text": "Herr Leutnant, ne, ick rep man blo\u00df,", "tokens": ["Herr", "Leut\u00b7nant", ",", "ne", ",", "ick", "rep", "man", "blo\u00df", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "NE", "$,", "PPER", "VVFIN", "PIS", "ADV", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.28": {"text": "Min Mutting wull't doch ok mal seihn.\u00ab", "tokens": ["Min", "Mut\u00b7ting", "wull't", "doch", "ok", "mal", "seihn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Na, nu geiht denn de Leutnant los,", "tokens": ["Na", ",", "nu", "geiht", "denn", "de", "Leut\u00b7nant", "los", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVPP", "KON", "NE", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un wenn so'n Leutnant richtig schellt:", "tokens": ["Un", "wenn", "so'n", "Leut\u00b7nant", "rich\u00b7tig", "schellt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "\u00bbein Himmel Donnerwetter Kreuz", "tokens": ["\u00bb", "ein", "Him\u00b7mel", "Don\u00b7ner\u00b7wet\u00b7ter", "Kreuz"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Millionen heilig Schwerenot!\u00ab,", "tokens": ["Mil\u00b7lion\u00b7en", "hei\u00b7lig", "Schwe\u00b7re\u00b7not", "!", "\u00ab", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADJD", "NN", "$.", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn b\u00e4wert unner em de Welt,", "tokens": ["Denn", "b\u00e4\u00b7wert", "un\u00b7ner", "em", "de", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Un knicken, knacken, knastern deiht s'!", "tokens": ["Un", "kni\u00b7cken", ",", "kna\u00b7cken", ",", "knas\u00b7tern", "deiht", "s'", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.7": {"text": "Acht Wochen lang bi Water un bi Brod", "tokens": ["Acht", "Wo\u00b7chen", "lang", "bi", "Wa\u00b7ter", "un", "bi", "Brod"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADJD", "FM", "FM", "FM", "FM", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Un Standrecht, Kugel, streng' Arrest", "tokens": ["Un", "Stand\u00b7recht", ",", "Ku\u00b7gel", ",", "streng'", "Ar\u00b7rest"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "NN", "$,", "VVFIN", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.9": {"text": "Un teihn Johr Festung s\u00fcnd dat best,", "tokens": ["Un", "teihn", "Johr", "Fes\u00b7tung", "s\u00fcnd", "dat", "best", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NN", "ADJD", "PAV", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "Wat uns' l\u00fctt Hanning kriggt tau h\u00fcren.", "tokens": ["Wat", "un\u00b7s'", "l\u00fctt", "Han\u00b7ning", "kriggt", "tau", "h\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Taum Gl\u00fccken \u00e4werst m\u00fc\u00dft't passieren,", "tokens": ["Taum", "Gl\u00fc\u00b7cken", "\u00e4\u00b7werst", "m\u00fc\u00dft't", "pas\u00b7sie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Dat de Gro\u00dfherzog dortau kem.", "tokens": ["Dat", "de", "Gro\u00df\u00b7her\u00b7zog", "dor\u00b7tau", "kem", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "\u00bbwas gibt es denn, von Donnerstr\u00f6m?\u00ab", "tokens": ["\u00bb", "was", "gibt", "es", "denn", ",", "von", "Don\u00b7ner\u00b7str\u00f6m", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ADV", "$,", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "De Leutnant nu, in vullen Iwer,", "tokens": ["De", "Leut\u00b7nant", "nu", ",", "in", "vul\u00b7len", "I\u00b7wer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Vertellt dat St\u00fcck von Hanne Knaken", "tokens": ["Ver\u00b7tellt", "dat", "St\u00fcck", "von", "Han\u00b7ne", "Kna\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Un wat hei Gruglichs hadd verbraken.", "tokens": ["Un", "wat", "hei", "Grug\u00b7lichs", "hadd", "ver\u00b7bra\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.17": {"text": "Dunn f\u00e4ngt Paul Friedrich an tau lachen", "tokens": ["Dunn", "f\u00e4ngt", "Paul", "Fried\u00b7rich", "an", "tau", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "NE", "NE", "APPR", "NE", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Un seggt tau em: \u00bbHier lernen Sie, mein Lieber,", "tokens": ["Un", "seggt", "tau", "em", ":", "\u00bb", "Hier", "ler\u00b7nen", "Sie", ",", "mein", "Lie\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$.", "$(", "ADV", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.19": {"text": "Aus jedem Holz ist ein Apoll zu schnitzen,", "tokens": ["Aus", "je\u00b7dem", "Holz", "ist", "ein", "A\u00b7poll", "zu", "schnit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Aus jedem ist ein Held zu machen,", "tokens": ["Aus", "je\u00b7dem", "ist", "ein", "Held", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Ein jeder Stand hat seinen alten Fritzen", "tokens": ["Ein", "je\u00b7der", "Stand", "hat", "sei\u00b7nen", "al\u00b7ten", "Frit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Und C\u00e4sar und Napoleon;", "tokens": ["Und", "C\u00e4\u00b7sar", "und", "Na\u00b7po\u00b7le\u00b7on", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Selbst aus'm Schneider hat man schon", "tokens": ["Selbst", "aus'm", "Schnei\u00b7der", "hat", "man", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NE", "VAFIN", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Den Helden sich entpuppen sehn,", "tokens": ["Den", "Hel\u00b7den", "sich", "ent\u00b7pup\u00b7pen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Wie es zu Fehrbellin geschehn \u2013", "tokens": ["Wie", "es", "zu", "Fehr\u00b7bel\u00b7lin", "ge\u00b7schehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Doch wat en Scheper is, dat bliwwt en Scheper.\u00ab", "tokens": ["Doch", "wat", "en", "Sche\u00b7per", "is", ",", "dat", "bliwwt", "en", "Sche\u00b7per", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Un Hanne Knaken ranne rep'e:", "tokens": ["Un", "Han\u00b7ne", "Kna\u00b7ken", "ran\u00b7ne", "rep'e", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "\u00bbgah man taur\u00fcgg nah Hahnen-Liepen,", "tokens": ["\u00bb", "gah", "man", "tau\u00b7r\u00fcgg", "nah", "Hah\u00b7nen\u00b7Lie\u00b7pen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "ADV", "ADJD", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.29": {"text": "Du kannst dor wedder L\u00e4mmer gripen.\u00ab", "tokens": ["Du", "kannst", "dor", "wed\u00b7der", "L\u00e4m\u00b7mer", "gri\u00b7pen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "NE", "KON", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Oll Mutter Knaksch, de hadd en Jungen,", "tokens": ["Oll", "Mut\u00b7ter", "Knaksch", ",", "de", "hadd", "en", "Jun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "NN", "$,", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man einen hadd s', doch dese ein,", "tokens": ["Man", "ei\u00b7nen", "hadd", "s'", ",", "doch", "de\u00b7se", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "NE", "$,", "KON", "PDS", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "De was dorf\u00f6r ok gaud gelungen \u2013", "tokens": ["De", "was", "dor\u00b7f\u00f6r", "ok", "gaud", "ge\u00b7lun\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So'n Schapskopp hadd de Welt nich seihn;", "tokens": ["So'n", "Schaps\u00b7kopp", "hadd", "de", "Welt", "nich", "seihn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch Mutter Knaksch, de gl\u00f6wt nich dran,", "tokens": ["Doch", "Mut\u00b7ter", "Knaksch", ",", "de", "gl\u00f6wt", "nich", "dran", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "$,", "NE", "VVFIN", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dat ehr leiw J\u00fcnging dumm s\u00fcll sin,", "tokens": ["Dat", "ehr", "leiw", "J\u00fcn\u00b7ging", "dumm", "s\u00fcll", "sin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sei kek in ehren S\u00e4hn Jehann", "tokens": ["Sei", "kek", "in", "eh\u00b7ren", "S\u00e4hn", "Je\u00b7hann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "APPR", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "As in en gollen B\u00e4ker rin.", "tokens": ["As", "in", "en", "gol\u00b7len", "B\u00e4\u00b7ker", "rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Jehann, de m\u00fc\u00dft nu Scheper warden,", "tokens": ["Je\u00b7hann", ",", "de", "m\u00fc\u00dft", "nu", "Sche\u00b7per", "war\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "VMFIN", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Un wenn sei em taum Naren hadden,", "tokens": ["Un", "wenn", "sei", "em", "taum", "Na\u00b7ren", "had\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "FM", "FM", "FM", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Denn tr\u00f6st em Mutter: \u00bbDu b\u00fcst kl\u00e4uker;", "tokens": ["Denn", "tr\u00f6st", "em", "Mut\u00b7ter", ":", "\u00bb", "Du", "b\u00fcst", "kl\u00e4u\u00b7ker", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "$.", "$(", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ut'n Scheper\u00ab, s\u00e4d se, \u00bbun Aptheiker,", "tokens": ["Ut'n", "Sche\u00b7per", "\u00ab", ",", "s\u00e4d", "se", ",", "\u00bb", "un", "A\u00b7pthei\u00b7ker", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$(", "$,", "FM", "FM", "$,", "$(", "FM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Min S\u00e4hning, dor kann allens warden.\u00ab", "tokens": ["Min", "S\u00e4h\u00b7ning", ",", "dor", "kann", "al\u00b7lens", "war\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VMFIN", "ADV", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Na, 't kamm ok so. \u2013 De Tid kamm 'ranne,", "tokens": ["Na", ",", "'t", "kamm", "ok", "so", ".", "\u2013", "De", "Tid", "kamm", "'ran\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NE", "VVFIN", "ADV", "ADV", "$.", "$(", "NE", "NE", "VVFIN", "NE", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dunn was't v\u00f6rbi mit L\u00e4mmergripen,", "tokens": ["Dunn", "was't", "v\u00f6r\u00b7bi", "mit", "L\u00e4m\u00b7mer\u00b7gri\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dunn los't uns' leiw l\u00fctt Knaken Hanne", "tokens": ["Dunn", "los't", "un\u00b7s'", "leiw", "l\u00fctt", "Kna\u00b7ken", "Han\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sick fast un m\u00fc\u00dft von Hahnen-Liepen", "tokens": ["Sick", "fast", "un", "m\u00fc\u00dft", "von", "Hah\u00b7nen\u00b7Lie\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "FM", "VMFIN", "APPR", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Hen nah Swerin tau de Soldaten.", "tokens": ["Hen", "nah", "Swe\u00b7rin", "tau", "de", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "NE", "NE", "NE", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Dor st\u00fcnn hei v\u00f6r de Kummischon.", "tokens": ["Dor", "st\u00fcnn", "hei", "v\u00f6r", "de", "Kum\u00b7mi\u00b7schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "\u00bbfor Grenadier zu kurz geraten,", "tokens": ["\u00bb", "for", "Gre\u00b7na\u00b7di\u00b7er", "zu", "kurz", "ge\u00b7ra\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "PTKA", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "For J\u00e4ger nich von Proportschon,", "tokens": ["For", "J\u00e4\u00b7ger", "nich", "von", "Pro\u00b7port\u00b7schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "For di Dreiguner im Ges\u00e4\u00df zu eng,", "tokens": ["For", "di", "Drei\u00b7gu\u00b7ner", "im", "Ge\u00b7s\u00e4\u00df", "zu", "eng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "APPRART", "NN", "PTKA", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.10": {"text": "Zu brauchen blo\u00df bei die Kanon,", "tokens": ["Zu", "brau\u00b7chen", "blo\u00df", "bei", "die", "Ka\u00b7non", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Un geht's nich da, bei's schwer Gedr\u00e4nk.\u00ab", "tokens": ["Un", "geht's", "nich", "da", ",", "bei's", "schwer", "Ge\u00b7dr\u00e4nk", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "PTKNEG", "ADV", "$,", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Un kamm nu tau'r Attolleri.", "tokens": ["Un", "kamm", "nu", "tau'r", "At\u00b7tol\u00b7le\u00b7ri", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.13": {"text": "Dor m\u00fc\u00dft hei nu von morgens fr\u00fch", "tokens": ["Dor", "m\u00fc\u00dft", "hei", "nu", "von", "mor\u00b7gens", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "NE", "ADV", "APPR", "ADV", "ADJD"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.14": {"text": "Bet's abends mit den Wischer stahn", "tokens": ["Bet's", "a\u00b7bends", "mit", "den", "Wi\u00b7scher", "stahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Un mit de Lunt up't Z\u00fcndlock slahn", "tokens": ["Un", "mit", "de", "Lunt", "up't", "Z\u00fcnd\u00b7lock", "slahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Un mit de Handspeik r\u00fcm handtieren,", "tokens": ["Un", "mit", "de", "Hand\u00b7speik", "r\u00fcm", "hand\u00b7tie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "NE", "NE", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.17": {"text": "Dat Riden un dat F\u00fchren lihren", "tokens": ["Dat", "Ri\u00b7den", "un", "dat", "F\u00fch\u00b7ren", "lih\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "FM", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Un \u00fcmmer Proppen \u00e4wer Proppen", "tokens": ["Un", "\u00fcm\u00b7mer", "Prop\u00b7pen", "\u00e4\u00b7wer", "Prop\u00b7pen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "In de Kanon herinne stoppen.", "tokens": ["In", "de", "Ka\u00b7non", "he\u00b7rin\u00b7ne", "stop\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Na, dorbi stellt sick uns' Jehann", "tokens": ["Na", ",", "dor\u00b7bi", "stellt", "sick", "un\u00b7s'", "Je\u00b7hann"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "Denn ganz gef\u00e4hrlich abellsch an,", "tokens": ["Denn", "ganz", "ge\u00b7f\u00e4hr\u00b7lich", "a\u00b7bell\u00b7sch", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Un knapp man hett hei't richtig truffen.", "tokens": ["Un", "knapp", "man", "hett", "hei't", "rich\u00b7tig", "truf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "VAFIN", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Un wat sin Unt'roffzier ded wesen,", "tokens": ["Un", "wat", "sin", "Unt'\u00b7roff\u00b7zier", "ded", "we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "De w\u00fcrd em heimlich \u00fcmmer knuffen,", "tokens": ["De", "w\u00fcrd", "em", "heim\u00b7lich", "\u00fcm\u00b7mer", "knuf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJA", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Wil't \u00f6ffentlich verbaden wir.", "tokens": ["Wil't", "\u00f6f\u00b7fent\u00b7lich", "ver\u00b7ba\u00b7den", "wir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVFIN", "PPER", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.11": {"line.1": {"text": "Na, einmal w\u00fcrd de Unt'roffzier", "tokens": ["Na", ",", "ein\u00b7mal", "w\u00fcrd", "de", "Unt'\u00b7roff\u00b7zier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Abends Instrukschonen lesen,", "tokens": ["Des", "A\u00b7bends", "Inst\u00b7ruk\u00b7scho\u00b7nen", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Utf\u00fchrlich sihr un sihr gelihrt.", "tokens": ["Ut\u00b7f\u00fchr\u00b7lich", "sihr", "un", "sihr", "ge\u00b7lihrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "FM", "FM", "FM", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "\u00bbwir\u00ab, s\u00e4d'e, \u00bbKinder, s\u00fcnd Soldaten,", "tokens": ["\u00bb", "wir", "\u00ab", ",", "s\u00e4d'e", ",", "\u00bb", "Kin\u00b7der", ",", "s\u00fcnd", "Sol\u00b7da\u00b7ten", ","], "token_info": ["punct", "word", "punct", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "$(", "$,", "VVFIN", "$,", "$(", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf uns beruhn die Heldentaten,", "tokens": ["Auf", "uns", "be\u00b7ruhn", "die", "Hel\u00b7den\u00b7ta\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vor allen auf Attolleri,", "tokens": ["Vor", "al\u00b7len", "auf", "At\u00b7tol\u00b7le\u00b7ri", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Un nidertr\u00e4chtig, Jungens, wir't,", "tokens": ["Un", "ni\u00b7der\u00b7tr\u00e4ch\u00b7tig", ",", "Jun\u00b7gens", ",", "wir't", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADJD", "$,", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn einer von der Kumpani", "tokens": ["Wenn", "ei\u00b7ner", "von", "der", "Kum\u00b7pa\u00b7ni"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das nicht zu jeder Stunde w\u00fc\u00dft", "tokens": ["Das", "nicht", "zu", "je\u00b7der", "Stun\u00b7de", "w\u00fc\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und es im Busen in sich tr\u00e4gt:", "tokens": ["Und", "es", "im", "Bu\u00b7sen", "in", "sich", "tr\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Gottlob! Ich b\u00fcn Attollerist. \u2013", "tokens": ["Gott\u00b7lob", "!", "Ich", "b\u00fcn", "At\u00b7tol\u00b7le\u00b7rist", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Nu antwurt, Knak der zweite\u00ab, rep'e,", "tokens": ["Nu", "ant\u00b7wurt", ",", "Knak", "der", "zwei\u00b7te", "\u00ab", ",", "rep'e", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "NN", "ART", "ADJA", "$(", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbwas b\u00fcst du, wenn dich einer fr\u00e4gt?\u00ab", "tokens": ["\u00bb", "was", "b\u00fcst", "du", ",", "wenn", "dich", "ei\u00b7ner", "fr\u00e4gt", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbick\u00ab, seggt Jehann, \u00bbick b\u00fcn en Scheper.\u00ab", "tokens": ["\u00bb", "ick", "\u00ab", ",", "seggt", "Je\u00b7hann", ",", "\u00bb", "ick", "b\u00fcn", "en", "Sche\u00b7per", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$(", "$,", "VVFIN", "NE", "$,", "$(", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "As slaten is de Instrukschon,", "tokens": ["As", "sla\u00b7ten", "is", "de", "Inst\u00b7ruk\u00b7schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Dunn lett de Unt'roffzier de annern", "tokens": ["Dunn", "lett", "de", "Unt'\u00b7roff\u00b7zier", "de", "an\u00b7nern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Herute gahn un seggt tau Hannern:", "tokens": ["He\u00b7ru\u00b7te", "gahn", "un", "seggt", "tau", "Han\u00b7nern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "\u00bboh, bleib ein bi\u00dfchen hier, mein Sohn.\u00ab", "tokens": ["\u00bb", "oh", ",", "bleib", "ein", "bi\u00df\u00b7chen", "hier", ",", "mein", "Sohn", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "$,", "VVFIN", "ART", "PIS", "ADV", "$,", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Un kriggt em fat't un knufft un pufft", "tokens": ["Un", "kriggt", "em", "fat't", "un", "knufft", "un", "pufft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.20": {"text": "Up Hannern in. \u00bbWas b\u00fcst du, Schuft?", "tokens": ["Up", "Han\u00b7nern", "in", ".", "\u00bb", "Was", "b\u00fcst", "du", ",", "Schuft", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["FM.xy", "FM.xy", "FM.xy", "$.", "$(", "PWS", "VVFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "En Scheper b\u00fcst du? \u2013 Na, da soll doch ein", "tokens": ["En", "Sche\u00b7per", "b\u00fcst", "du", "?", "\u2013", "Na", ",", "da", "soll", "doch", "ein"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "VVFIN", "PPER", "$.", "$(", "ITJ", "$,", "ADV", "VMFIN", "ADV", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Zehntausend Donnerwetter schlagen", "tokens": ["Zehn\u00b7tau\u00b7send", "Don\u00b7ner\u00b7wet\u00b7ter", "schla\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Zehn Klafter in die Erd hinein!", "tokens": ["Zehn", "Klaf\u00b7ter", "in", "die", "Erd", "hin\u00b7ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Ihr Kreuzschockschweren\u00f6ters m\u00fc\u00dft", "tokens": ["Ihr", "Kreuz\u00b7schock\u00b7schwe\u00b7re\u00b7n\u00f6\u00b7ters", "m\u00fc\u00dft"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Das Hochgef\u00fchl im Busen tragen:", "tokens": ["Das", "Hoch\u00b7ge\u00b7f\u00fchl", "im", "Bu\u00b7sen", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Gottlob! Ich bin Attolerist.\u00ab", "tokens": ["Gott\u00b7lob", "!", "Ich", "bin", "At\u00b7to\u00b7le\u00b7rist", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Un predigt so up Hannern in", "tokens": ["Un", "pre\u00b7digt", "so", "up", "Han\u00b7nern", "in"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Un makt dat Hochgef\u00e4uhl em klor,", "tokens": ["Un", "makt", "dat", "Hoch\u00b7ge\u00b7f\u00e4uhl", "em", "klor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.29": {"text": "Dat't ein noch nah en Virteljohr", "tokens": ["Dat't", "ein", "noch", "nah", "en", "Vir\u00b7tel\u00b7johr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Em von den Puckel lesen k\u00fcnn.", "tokens": ["Em", "von", "den", "Pu\u00b7ckel", "le\u00b7sen", "k\u00fcnn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Jehann, de schriwwt en schrewen Breiw", "tokens": ["Je\u00b7hann", ",", "de", "schriwwt", "en", "schre\u00b7wen", "Breiw"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "FM", "FM", "FM", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Muttern hen nah Hahnen-Liepen:", "tokens": ["An", "Mut\u00b7tern", "hen", "nah", "Hah\u00b7nen\u00b7Lie\u00b7pen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sin Lewen wir em doch tau leiw;", "tokens": ["Sin", "Le\u00b7wen", "wir", "em", "doch", "tau", "leiw", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Hei m\u00fcggt woll wedder L\u00e4mmer gripen,", "tokens": ["Hei", "m\u00fcggt", "woll", "wed\u00b7der", "L\u00e4m\u00b7mer", "gri\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "KON", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Hei m\u00fcggt woll wedder Hanschen kn\u00fctten", "tokens": ["Hei", "m\u00fcggt", "woll", "wed\u00b7der", "Han\u00b7schen", "kn\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KON", "NN", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Un achter'n Durenr\u00e4mel sitten,", "tokens": ["Un", "ach\u00b7ter'n", "Du\u00b7ren\u00b7r\u00e4\u00b7mel", "sit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hei m\u00fcggt woll wedder Hamel h\u00e4uden", "tokens": ["Hei", "m\u00fcggt", "woll", "wed\u00b7der", "Ha\u00b7mel", "h\u00e4u\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KON", "NN", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Un wull sin Sch\u00fcten nich mihr slahn,", "tokens": ["Un", "wull", "sin", "Sch\u00fc\u00b7ten", "nich", "mihr", "slahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Hei w\u00fc\u00dft nu, wo't em s\u00fclwen dahn.", "tokens": ["Hei", "w\u00fc\u00dft", "nu", ",", "wo't", "em", "s\u00fcl\u00b7wen", "dahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Un all de velen Scheper-Leiden,", "tokens": ["Un", "all", "de", "ve\u00b7len", "Sche\u00b7per\u00b7Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "De d\u00fcchten jitzt em Kleinigkeit,", "tokens": ["De", "d\u00fcch\u00b7ten", "jitzt", "em", "Klei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Un ok de Schap ehr Upsternatschigkeit,", "tokens": ["Un", "ok", "de", "Schap", "ehr", "U\u00b7pster\u00b7nat\u00b7schig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "De h\u00f6ll hei jitzt man v\u00f6r Pl\u00e4sier,", "tokens": ["De", "h\u00f6ll", "hei", "jitzt", "man", "v\u00f6r", "Pl\u00e4\u00b7sier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Denn't upsternatschte Veih up Irden wir", "tokens": ["Denn't", "ups\u00b7ter\u00b7natschte", "Veih", "up", "Ir\u00b7den", "wir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Sin grot Kanon un de Herr Unt'roffzier.", "tokens": ["Sin", "grot", "Ka\u00b7non", "un", "de", "Herr", "Unt'\u00b7roff\u00b7zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.13": {"line.1": {"text": "Na, Mutter Knaksch, de durt't denn sihr", "tokens": ["Na", ",", "Mut\u00b7ter", "Knaksch", ",", "de", "durt't", "denn", "sihr"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "NN", "NN", "$,", "NE", "VVPP", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un makt sick endlich up de Bein,", "tokens": ["Un", "makt", "sick", "end\u00b7lich", "up", "de", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADV", "NE", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Will doch mal dor taum Rechten seihn", "tokens": ["Will", "doch", "mal", "dor", "taum", "Rech\u00b7ten", "seihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "ADV", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Un fr\u00f6ggt sick ruppe nach Swerin", "tokens": ["Un", "fr\u00f6ggt", "sick", "rup\u00b7pe", "nach", "Swe\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "VVFIN", "APPR", "NE"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Un fr\u00f6ggt dor \u00fcmmer nah den Herrn", "tokens": ["Un", "fr\u00f6ggt", "dor", "\u00fcm\u00b7mer", "nah", "den", "Herrn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Attolleristen Hanne Knaken.", "tokens": ["At\u00b7tol\u00b7le\u00b7ris\u00b7ten", "Han\u00b7ne", "Kna\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sei wisen ehr nah de Kasern,", "tokens": ["Sei", "wi\u00b7sen", "ehr", "nah", "de", "Ka\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADJD", "NE", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Un as sei dor von Hannern spraken,", "tokens": ["Un", "as", "sei", "dor", "von", "Han\u00b7nern", "spra\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Dunn wisen s' ehr en En'nlang wider.", "tokens": ["Dunn", "wi\u00b7sen", "s'", "ehr", "en", "En'\u00b7nlang", "wi\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Dor stunn denn nu de Unt'roffzierer", "tokens": ["Dor", "stunn", "denn", "nu", "de", "Unt'\u00b7roff\u00b7zie\u00b7rer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Un hadd uns' Hannern in de Mak", "tokens": ["Un", "hadd", "un\u00b7s'", "Han\u00b7nern", "in", "de", "Mak"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "APPR", "NE", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Un knufft un pufft up Hannern in.", "tokens": ["Un", "knufft", "un", "pufft", "up", "Han\u00b7nern", "in", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.13": {"text": "Dunn ward uns' Mutter falsch tau Sinn,", "tokens": ["Dunn", "ward", "un\u00b7s'", "Mut\u00b7ter", "falsch", "tau", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "ADJD", "CARD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "K\u00fcmmt ran un seggt: \u00bbIs dat 'ne Sak?", "tokens": ["K\u00fcmmt", "ran", "un", "seggt", ":", "\u00bb", "Is", "dat", "'ne", "Sak", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "$.", "$(", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Wat hett Em min l\u00fctt Hanning dahn?", "tokens": ["Wat", "hett", "Em", "min", "l\u00fctt", "Han\u00b7ning", "dahn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wo kann Hei mi dat Kind hir slahn?", "tokens": ["Wo", "kann", "Hei", "mi", "dat", "Kind", "hir", "slahn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NE", "NE", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.17": {"text": "Wat st\u00f6tt Hei im dat J\u00fcnging?\u00ab seggt s',", "tokens": ["Wat", "st\u00f6tt", "Hei", "im", "dat", "J\u00fcn\u00b7ging", "?", "\u00ab", "seggt", "s'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$(", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "\u00bbkann Hei nich seggen: Hanning, so,", "tokens": ["\u00bb", "kann", "Hei", "nich", "seg\u00b7gen", ":", "Han\u00b7ning", ",", "so", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VMFIN", "NN", "PTKNEG", "VVINF", "$.", "NE", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Un dreih di links un dreih di rechts \u2013", "tokens": ["Un", "dreih", "di", "links", "un", "dreih", "di", "rechts", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Denn deiht dat leiwe Kind dat jo.", "tokens": ["Denn", "deiht", "dat", "lei\u00b7we", "Kind", "dat", "jo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "T\u00e4uw! Ick ward nah'n Gro\u00dfherzog gahn.\u00ab", "tokens": ["T\u00e4uw", "!", "Ick", "ward", "nah'n", "Gro\u00df\u00b7her\u00b7zog", "gahn", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "PPER", "VAFIN", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "Na, dat is gaud! Geseggt, gedahn.", "tokens": ["Na", ",", "dat", "is", "gaud", "!", "Ge\u00b7seggt", ",", "ge\u00b7dahn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "FM.nl", "FM.nl", "FM.nl", "$.", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sei geiht glik an de richt'ge Sm\u00e4d';", "tokens": ["Sei", "geiht", "glik", "an", "de", "richt'\u00b7ge", "Sm\u00e4d'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "NN", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Paul Friedrich was't, de dunn regiert,", "tokens": ["Paul", "Fried\u00b7rich", "was't", ",", "de", "dunn", "re\u00b7giert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "De h\u00fcrt up jeden sine Red',", "tokens": ["De", "h\u00fcrt", "up", "je\u00b7den", "si\u00b7ne", "Red'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Un einen gauden Herren wir't", "tokens": ["Un", "ei\u00b7nen", "gau\u00b7den", "Her\u00b7ren", "wir't"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Un sihr f\u00f6r den gemeinen Mann.", "tokens": ["Un", "sihr", "f\u00f6r", "den", "ge\u00b7mei\u00b7nen", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Hei h\u00fcrt oll Knaksch ok fr\u00fcndlich an,", "tokens": ["Hei", "h\u00fcrt", "oll", "Knaksch", "ok", "fr\u00fcnd\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Doch endlich seggt hei: \u00bbMutter, nein!", "tokens": ["Doch", "end\u00b7lich", "seggt", "hei", ":", "\u00bb", "Mut\u00b7ter", ",", "nein", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKVZ", "$.", "$(", "NN", "$,", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Loslassen? Nein, das kann nicht sein!\u00ab", "tokens": ["Los\u00b7las\u00b7sen", "?", "Nein", ",", "das", "kann", "nicht", "sein", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "PTKANT", "$,", "PDS", "VMFIN", "PTKNEG", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Doch Mutter lett nich af mit Qu\u00e4len,", "tokens": ["Doch", "Mut\u00b7ter", "lett", "nich", "af", "mit", "Qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "PTKNEG", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Hei s\u00fcll ehr doch den Jungen laten.", "tokens": ["Hei", "s\u00fcll", "ehr", "doch", "den", "Jun\u00b7gen", "la\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.12": {"text": "\u00bbdas\u00ab, seggt hei, \u00bbkann ich nicht befehlen,", "tokens": ["\u00bb", "das", "\u00ab", ",", "seggt", "hei", ",", "\u00bb", "kann", "ich", "nicht", "be\u00b7feh\u00b7len", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "$(", "$,", "VVFIN", "PTKVZ", "$,", "$(", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wer's einmal ist, der bleibt Soldat;", "tokens": ["Wer's", "ein\u00b7mal", "ist", ",", "der", "bleibt", "Sol\u00b7dat", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VAFIN", "$,", "PRELS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und wer den bunten Rock anhat,", "tokens": ["Und", "wer", "den", "bun\u00b7ten", "Rock", "an\u00b7hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der wird auch t\u00fcchtig exerziert.\u00ab", "tokens": ["Der", "wird", "auch", "t\u00fcch\u00b7tig", "ex\u00b7er\u00b7ziert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Un wull de Ollsch en Daler schenken,", "tokens": ["Un", "wull", "de", "Ollsch", "en", "Da\u00b7ler", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "NE", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Wil dat ehr Bidden em doch r\u00fchrt,", "tokens": ["Wil", "dat", "ehr", "Bid\u00b7den", "em", "doch", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "ADJA", "ADV", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.18": {"text": "Un in de Tasch herinne grep'e.", "tokens": ["Un", "in", "de", "Tasch", "he\u00b7rin\u00b7ne", "grep'", "e."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "\u00bbje\u00ab, seggt de Ollsch, \u00bbSei m\u00f6ten ok bedenken,", "tokens": ["\u00bb", "je", "\u00ab", ",", "seggt", "de", "Ollsch", ",", "\u00bb", "Sei", "m\u00f6\u00b7ten", "ok", "be\u00b7den\u00b7ken", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "NE", "NE", "$,", "$(", "VAFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.20": {"text": "Ehr Ort, de hett ok s\u00fcs nicks lihrt,", "tokens": ["Ehr", "Ort", ",", "de", "hett", "ok", "s\u00fcs", "nicks", "lihrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Un min Jehann, dat is en Scheper.\u00ab", "tokens": ["Un", "min", "Je\u00b7hann", ",", "dat", "is", "en", "Sche\u00b7per", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "ART", "FM", "FM", "NN", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.22": {"text": "Ick denk, Paul Friedrich lacht sick scheiw.", "tokens": ["Ick", "denk", ",", "Paul", "Fried\u00b7rich", "lacht", "sick", "scheiw", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "NE", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "\u00bbna, hest den Jung'n doch woll tau leiw?\u00ab", "tokens": ["\u00bb", "na", ",", "hest", "den", "Jung'n", "doch", "woll", "tau", "leiw", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "ADJD", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "Seggt hei, \u00bbick will in desen Dagen", "tokens": ["Seggt", "hei", ",", "\u00bb", "ick", "will", "in", "de\u00b7sen", "Da\u00b7gen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "$(", "PPER", "VMFIN", "APPR", "PRELAT", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.25": {"text": "De Sak mi ganz genau befragen,", "tokens": ["De", "Sak", "mi", "ganz", "ge\u00b7nau", "be\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Un wenn dat jichtens passen deiht,", "tokens": ["Un", "wenn", "dat", "jich\u00b7tens", "pas\u00b7sen", "deiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.27": {"text": "Denn sall hei mit di t'r\u00fcgg nah Liepen", "tokens": ["Denn", "sall", "hei", "mit", "di", "t'\u00b7r\u00fcgg", "nah", "Lie\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "FM", "FM", "APPR", "NE", "NE", "ADJD", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.28": {"text": "Un sall dor wedder L\u00e4mmer gripen.\u00ab", "tokens": ["Un", "sall", "dor", "wed\u00b7der", "L\u00e4m\u00b7mer", "gri\u00b7pen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "NE", "KON", "NN", "VVINF", "$.", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.15": {"line.1": {"text": "Oll Knaksch bedankt sick denn un geiht", "tokens": ["Oll", "Knaksch", "be\u00b7dankt", "sick", "denn", "un", "geiht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "NE", "KON", "FM", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un k\u00fcmmt so nah de Wach hendal,", "tokens": ["Un", "k\u00fcmmt", "so", "nah", "de", "Wach", "hen\u00b7dal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Hanning h\u00fct taum irstenmal", "tokens": ["Wo", "Han\u00b7ning", "h\u00fct", "taum", "irs\u00b7ten\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In vullen Stat as Posten steiht.", "tokens": ["In", "vul\u00b7len", "Stat", "as", "Pos\u00b7ten", "steiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbjehanning\u00ab, seggt s', \u00bbnu k\u00fcmmst du fri,", "tokens": ["\u00bb", "je\u00b7han\u00b7ning", "\u00ab", ",", "seggt", "s'", ",", "\u00bb", "nu", "k\u00fcmmst", "du", "fri", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "$(", "$,", "VVFIN", "NE", "$,", "$(", "ADV", "VVFIN", "PPER", "NE", "$,"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "Nu is de Knufferi v\u00f6rbi,", "tokens": ["Nu", "is", "de", "Knuf\u00b7fe\u00b7ri", "v\u00f6r\u00b7bi", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ick b\u00fcn bi den Gro\u00dfherzog wesen,", "tokens": ["Ick", "b\u00fcn", "bi", "den", "Gro\u00df\u00b7her\u00b7zog", "we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "De ward den Kirl Leviten lesen.", "tokens": ["De", "ward", "den", "Kirl", "Le\u00b7vi\u00b7ten", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Doch wat hest du hir r\u00fcm tau stahn,", "tokens": ["Doch", "wat", "hest", "du", "hir", "r\u00fcm", "tau", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Kannst du nich in de Stuw' rin gahn?\u00ab", "tokens": ["Kannst", "du", "nich", "in", "de", "Stu\u00b7w'", "rin", "gahn", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "APPR", "NE", "NE", "ADV", "VVFIN", "$.", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Uns' Hanne kickt sick \u00e4ngstlich \u00fcm,", "tokens": ["Un\u00b7s'", "Han\u00b7ne", "kickt", "sick", "\u00e4ngst\u00b7lich", "\u00fcm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Ob em ok wer woll reden s\u00fcht,", "tokens": ["Ob", "em", "ok", "wer", "woll", "re\u00b7den", "s\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "PWS", "VMFIN", "VVINF", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Un flustert sacht mit halwe Stimm:", "tokens": ["Un", "flus\u00b7tert", "sacht", "mit", "hal\u00b7we", "Stimm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbh\u00fct is min Ihrendag, leiw Mutting; h\u00fct", "tokens": ["\u00bb", "h\u00fct", "is", "min", "Ih\u00b7ren\u00b7dag", ",", "leiw", "Mut\u00b7ting", ";", "h\u00fct"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["$(", "FM.la", "FM.la", "FM.la", "FM.la", "$,", "ADJD", "NN", "$.", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "B\u00fcn ick en hellisch grotes Dird", "tokens": ["B\u00fcn", "ick", "en", "hel\u00b7lisch", "gro\u00b7tes", "Dird"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM", "FM", "FM", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Un de dat Ganze kummandiert.\u00ab", "tokens": ["Un", "de", "dat", "Gan\u00b7ze", "kum\u00b7man\u00b7diert", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.17": {"text": "\u00bbih wo?\u00ab seggt Mutter, \u00bbspa\u00df ok man!\u00ab", "tokens": ["\u00bb", "ih", "wo", "?", "\u00ab", "seggt", "Mut\u00b7ter", ",", "\u00bb", "spa\u00df", "ok", "man", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "PWAV", "$.", "$(", "VVFIN", "NN", "$,", "$(", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "\u00bbdat will'ck di wisen\u00ab, seggt Jehann", "tokens": ["\u00bb", "dat", "will'ck", "di", "wi\u00b7sen", "\u00ab", ",", "seggt", "Je\u00b7hann"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ART", "NN", "NE", "VVINF", "$(", "$,", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Un treckt sin Kes'metz stramm heran", "tokens": ["Un", "treckt", "sin", "Kes'\u00b7metz", "stramm", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "VVFIN", "PTKVZ"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.20": {"text": "Un br\u00f6llt nu m\u00e4glich: \u00bbWach heraus!\u00ab", "tokens": ["Un", "br\u00f6llt", "nu", "m\u00e4g\u00b7lich", ":", "\u00bb", "Wach", "he\u00b7raus", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "$.", "$(", "VVIMP", "PTKVZ", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Un Unt'roffzier un Attolleristen", "tokens": ["Un", "Unt'\u00b7roff\u00b7zier", "un", "At\u00b7tol\u00b7le\u00b7ris\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "FM", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Un Leutnant, allens st\u00f6rt herut.", "tokens": ["Un", "Leut\u00b7nant", ",", "al\u00b7lens", "st\u00f6rt", "he\u00b7rut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "De Leutnant fr\u00f6ggt: \u00bbWas ist denn los?", "tokens": ["De", "Leut\u00b7nant", "fr\u00f6ggt", ":", "\u00bb", "Was", "ist", "denn", "los", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "PWS", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Schildwache, wie? Was gibt's? Was ist denn?\u00ab", "tokens": ["Schild\u00b7wa\u00b7che", ",", "wie", "?", "Was", "gibt's", "?", "Was", "ist", "denn", "?", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PWAV", "$.", "PWS", "VVFIN", "$.", "PWS", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.25": {"text": "Un Hanning s\u00fcht so fr\u00fcndlich ut", "tokens": ["Un", "Han\u00b7ning", "s\u00fcht", "so", "fr\u00fcnd\u00b7lich", "ut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ADV", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Un seggt: \u00bbNe, hir is nicks gescheihn.", "tokens": ["Un", "seggt", ":", "\u00bb", "Ne", ",", "hir", "is", "nicks", "ge\u00b7scheihn", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "$(", "ART", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.27": {"text": "Herr Leutnant, ne, ick rep man blo\u00df,", "tokens": ["Herr", "Leut\u00b7nant", ",", "ne", ",", "ick", "rep", "man", "blo\u00df", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "NE", "$,", "PPER", "VVFIN", "PIS", "ADV", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.28": {"text": "Min Mutting wull't doch ok mal seihn.\u00ab", "tokens": ["Min", "Mut\u00b7ting", "wull't", "doch", "ok", "mal", "seihn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Na, nu geiht denn de Leutnant los,", "tokens": ["Na", ",", "nu", "geiht", "denn", "de", "Leut\u00b7nant", "los", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVPP", "KON", "NE", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Un wenn so'n Leutnant richtig schellt:", "tokens": ["Un", "wenn", "so'n", "Leut\u00b7nant", "rich\u00b7tig", "schellt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "\u00bbein Himmel Donnerwetter Kreuz", "tokens": ["\u00bb", "ein", "Him\u00b7mel", "Don\u00b7ner\u00b7wet\u00b7ter", "Kreuz"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Millionen heilig Schwerenot!\u00ab,", "tokens": ["Mil\u00b7lion\u00b7en", "hei\u00b7lig", "Schwe\u00b7re\u00b7not", "!", "\u00ab", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADJD", "NN", "$.", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn b\u00e4wert unner em de Welt,", "tokens": ["Denn", "b\u00e4\u00b7wert", "un\u00b7ner", "em", "de", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Un knicken, knacken, knastern deiht s'!", "tokens": ["Un", "kni\u00b7cken", ",", "kna\u00b7cken", ",", "knas\u00b7tern", "deiht", "s'", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.7": {"text": "Acht Wochen lang bi Water un bi Brod", "tokens": ["Acht", "Wo\u00b7chen", "lang", "bi", "Wa\u00b7ter", "un", "bi", "Brod"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADJD", "FM", "FM", "FM", "FM", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Un Standrecht, Kugel, streng' Arrest", "tokens": ["Un", "Stand\u00b7recht", ",", "Ku\u00b7gel", ",", "streng'", "Ar\u00b7rest"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "NN", "$,", "VVFIN", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.9": {"text": "Un teihn Johr Festung s\u00fcnd dat best,", "tokens": ["Un", "teihn", "Johr", "Fes\u00b7tung", "s\u00fcnd", "dat", "best", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NN", "ADJD", "PAV", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "Wat uns' l\u00fctt Hanning kriggt tau h\u00fcren.", "tokens": ["Wat", "un\u00b7s'", "l\u00fctt", "Han\u00b7ning", "kriggt", "tau", "h\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Taum Gl\u00fccken \u00e4werst m\u00fc\u00dft't passieren,", "tokens": ["Taum", "Gl\u00fc\u00b7cken", "\u00e4\u00b7werst", "m\u00fc\u00dft't", "pas\u00b7sie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Dat de Gro\u00dfherzog dortau kem.", "tokens": ["Dat", "de", "Gro\u00df\u00b7her\u00b7zog", "dor\u00b7tau", "kem", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "\u00bbwas gibt es denn, von Donnerstr\u00f6m?\u00ab", "tokens": ["\u00bb", "was", "gibt", "es", "denn", ",", "von", "Don\u00b7ner\u00b7str\u00f6m", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ADV", "$,", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "De Leutnant nu, in vullen Iwer,", "tokens": ["De", "Leut\u00b7nant", "nu", ",", "in", "vul\u00b7len", "I\u00b7wer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Vertellt dat St\u00fcck von Hanne Knaken", "tokens": ["Ver\u00b7tellt", "dat", "St\u00fcck", "von", "Han\u00b7ne", "Kna\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Un wat hei Gruglichs hadd verbraken.", "tokens": ["Un", "wat", "hei", "Grug\u00b7lichs", "hadd", "ver\u00b7bra\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.17": {"text": "Dunn f\u00e4ngt Paul Friedrich an tau lachen", "tokens": ["Dunn", "f\u00e4ngt", "Paul", "Fried\u00b7rich", "an", "tau", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "NE", "NE", "APPR", "NE", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Un seggt tau em: \u00bbHier lernen Sie, mein Lieber,", "tokens": ["Un", "seggt", "tau", "em", ":", "\u00bb", "Hier", "ler\u00b7nen", "Sie", ",", "mein", "Lie\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$.", "$(", "ADV", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.19": {"text": "Aus jedem Holz ist ein Apoll zu schnitzen,", "tokens": ["Aus", "je\u00b7dem", "Holz", "ist", "ein", "A\u00b7poll", "zu", "schnit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Aus jedem ist ein Held zu machen,", "tokens": ["Aus", "je\u00b7dem", "ist", "ein", "Held", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Ein jeder Stand hat seinen alten Fritzen", "tokens": ["Ein", "je\u00b7der", "Stand", "hat", "sei\u00b7nen", "al\u00b7ten", "Frit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Und C\u00e4sar und Napoleon;", "tokens": ["Und", "C\u00e4\u00b7sar", "und", "Na\u00b7po\u00b7le\u00b7on", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Selbst aus'm Schneider hat man schon", "tokens": ["Selbst", "aus'm", "Schnei\u00b7der", "hat", "man", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NE", "VAFIN", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Den Helden sich entpuppen sehn,", "tokens": ["Den", "Hel\u00b7den", "sich", "ent\u00b7pup\u00b7pen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Wie es zu Fehrbellin geschehn \u2013", "tokens": ["Wie", "es", "zu", "Fehr\u00b7bel\u00b7lin", "ge\u00b7schehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Doch wat en Scheper is, dat bliwwt en Scheper.\u00ab", "tokens": ["Doch", "wat", "en", "Sche\u00b7per", "is", ",", "dat", "bliwwt", "en", "Sche\u00b7per", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Un Hanne Knaken ranne rep'e:", "tokens": ["Un", "Han\u00b7ne", "Kna\u00b7ken", "ran\u00b7ne", "rep'e", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "\u00bbgah man taur\u00fcgg nah Hahnen-Liepen,", "tokens": ["\u00bb", "gah", "man", "tau\u00b7r\u00fcgg", "nah", "Hah\u00b7nen\u00b7Lie\u00b7pen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "ADV", "ADJD", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.29": {"text": "Du kannst dor wedder L\u00e4mmer gripen.\u00ab", "tokens": ["Du", "kannst", "dor", "wed\u00b7der", "L\u00e4m\u00b7mer", "gri\u00b7pen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "NE", "KON", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}