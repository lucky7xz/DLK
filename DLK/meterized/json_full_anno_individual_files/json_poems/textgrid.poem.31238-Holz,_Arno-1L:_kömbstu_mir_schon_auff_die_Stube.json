{"textgrid.poem.31238": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: k\u00f6mbstu mir schon auff die Stube/", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "k\u00f6mbstu mir schon auff die Stube/", "tokens": ["k\u00f6mbs\u00b7tu", "mir", "schon", "auff", "die", "Stu\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "s\u00e4lbst wenn ich beym Ocksen bin?", "tokens": ["s\u00e4lbst", "wenn", "ich", "beym", "Ock\u00b7sen", "bin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPRART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Marsch! Ich kann dich itzt nicht br\u00e4uchen/", "tokens": ["Marsch", "!", "Ich", "kann", "dich", "itzt", "nicht", "br\u00e4u\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "scheer dich draussen zu den Str\u00e4uchen/", "tokens": ["scheer", "dich", "draus\u00b7sen", "zu", "den", "Str\u00e4u\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "oder auch zu Fillis hin!", "tokens": ["o\u00b7der", "auch", "zu", "Fil\u00b7lis", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihren Sizz vollkommner L\u00fcste/", "tokens": ["Ih\u00b7ren", "Sizz", "voll\u00b7komm\u00b7ner", "L\u00fcs\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ihre Wunder-volle Br\u00fcste", "tokens": ["ih\u00b7re", "Wun\u00b7der\u00b7vol\u00b7le", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "lege einem Andren bey;", "tokens": ["le\u00b7ge", "ei\u00b7nem", "An\u00b7dren", "bey", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "mag sie schmollen oder lachen/", "tokens": ["mag", "sie", "schmol\u00b7len", "o\u00b7der", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "KON", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "oder auch mir H\u00f6rner machen \u2013", "tokens": ["o\u00b7der", "auch", "mir", "H\u00f6r\u00b7ner", "ma\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "dihses ist mir einerley!", "tokens": ["dih\u00b7ses", "ist", "mir", "ei\u00b7ner\u00b7ley", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Erst so sehn die M\u00e4ntscher au\u00df/", "tokens": ["Erst", "so", "sehn", "die", "M\u00e4nt\u00b7scher", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "al\u00df ob von dem s\u00e4lben Dau\u00df", "tokens": ["al\u00df", "ob", "von", "dem", "s\u00e4l\u00b7ben", "Dau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "mindestens die ", "tokens": ["min\u00b7des\u00b7tens", "die"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "bald so m\u00e4rckt man sie fast rund/", "tokens": ["bald", "so", "m\u00e4rckt", "man", "sie", "fast", "rund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PPER", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sind sie w\u00fcrcklich so gesund?", "tokens": ["sind", "sie", "w\u00fcrck\u00b7lich", "so", "ge\u00b7sund", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sp\u00e4hter werden sie dan Ammen.", "tokens": ["Sp\u00e4h\u00b7ter", "wer\u00b7den", "sie", "dan", "Am\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das B\u00fcrtzel-Spihl auff Sto\u00df und Stich", "tokens": ["Das", "B\u00fcrt\u00b7zel\u00b7Spihl", "auff", "Sto\u00df", "und", "Stich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "verstehn sie fast zu dapfferlich!", "tokens": ["ver\u00b7stehn", "sie", "fast", "zu", "dapf\u00b7fer\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Flammaris mit f\u00fcnfzehn Jahren", "tokens": ["Flam\u00b7ma\u00b7ris", "mit", "f\u00fcnf\u00b7zehn", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "dhut noch zihmlich unerfahren/", "tokens": ["dhut", "noch", "zihm\u00b7lich", "un\u00b7er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "doch schon ist das s\u00fcsse Wesen", "tokens": ["doch", "schon", "ist", "das", "s\u00fcs\u00b7se", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in ", "tokens": ["in"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "und schon offt hat ihr getraumt/", "tokens": ["und", "schon", "offt", "hat", "ihr", "ge\u00b7traumt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PPER", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df sie wem wa\u00df eyn-geraumt!", "tokens": ["da\u00df", "sie", "wem", "wa\u00df", "eyn\u00b7ge\u00b7raumt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Siebzehn-j\u00e4hricht", "tokens": ["Sieb\u00b7zehn\u00b7j\u00e4h\u00b7richt"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Stichel-h\u00e4hricht!", "tokens": ["Sti\u00b7chel\u00b7h\u00e4h\u00b7richt", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "K\u00fckkt man solcher auff das Mihder/", "tokens": ["K\u00fckkt", "man", "sol\u00b7cher", "auff", "das", "Mih\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIAT", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schl\u00e4gt sie nicht die Augen nihder!", "tokens": ["schl\u00e4gt", "sie", "nicht", "die", "Au\u00b7gen", "nih\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00e4drichins kan ich bloh\u00df leiden", "tokens": ["M\u00e4d\u00b7ri\u00b7chins", "kan", "ich", "bloh\u00df", "lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wohl-gesittet und bescheiden/", "tokens": ["wohl\u00b7ge\u00b7sit\u00b7tet", "und", "be\u00b7schei\u00b7den", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "D\u00f6rtgen/ das nach jedem schuhlt/", "tokens": ["D\u00f6rt\u00b7gen", "/", "das", "nach", "je\u00b7dem", "schuhlt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PDS", "APPR", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "scheint mir dr\u00fcmb schon abgebuhlt!", "tokens": ["scheint", "mir", "dr\u00fcmb", "schon", "ab\u00b7ge\u00b7buhlt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Bambrette wird mir schon zu breit/", "tokens": ["Bam\u00b7bret\u00b7te", "wird", "mir", "schon", "zu", "breit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie stammt noch au\u00df der Schweden-Zeit;", "tokens": ["sie", "stammt", "noch", "au\u00df", "der", "Schwe\u00b7den\u00b7Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "dr\u00fcmb legt sie auch so ohnverdrossen", "tokens": ["dr\u00fcmb", "legt", "sie", "auch", "so", "ohn\u00b7ver\u00b7dros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sich Frosch-Laich auff die Sommer-Sprossen.", "tokens": ["sich", "FroschLaich", "auff", "die", "Som\u00b7mer\u00b7Spros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "F\u00fcr ihren au\u00df-gestopfften Busen", "tokens": ["F\u00fcr", "ih\u00b7ren", "au\u00df\u00b7ge\u00b7stopff\u00b7ten", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "verh\u00fcllen schaudrend sich die Musen;", "tokens": ["ver\u00b7h\u00fcl\u00b7len", "schaud\u00b7rend", "sich", "die", "Mu\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "der Himmel sch\u00e4nck ihr einen Mann/", "tokens": ["der", "Him\u00b7mel", "sch\u00e4n\u00b7ck", "ihr", "ei\u00b7nen", "Mann", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ihr kommen sonst die Schaben dran!", "tokens": ["ihr", "kom\u00b7men", "sonst", "die", "Scha\u00b7ben", "dran", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Barbettgen ist sogar schon bartig/", "tokens": ["Bar\u00b7bett\u00b7gen", "ist", "so\u00b7gar", "schon", "bar\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wenn man sie k\u00fcsst/ so wird man schartig/", "tokens": ["wenn", "man", "sie", "k\u00fcsst", "/", "so", "wird", "man", "schar\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$(", "ADV", "VAFIN", "PIS", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "au\u00df ihrer Elen-langen Nase", "tokens": ["au\u00df", "ih\u00b7rer", "E\u00b7len\u00b7lan\u00b7gen", "Na\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "droppts wie au\u00df einer Wasser-Blase.", "tokens": ["droppts", "wie", "au\u00df", "ei\u00b7ner", "Was\u00b7ser\u00b7Bla\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Maul von angenehmer Bl\u00e4ue", "tokens": ["Ihr", "Maul", "von", "an\u00b7ge\u00b7neh\u00b7mer", "Bl\u00e4u\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "gleicht mehr schon einer Vogel-Sch\u00e4ue;", "tokens": ["gleicht", "mehr", "schon", "ei\u00b7ner", "Vo\u00b7gel\u00b7Sch\u00e4ue", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "darbey so kan sie kaum noch buhsten/", "tokens": ["dar\u00b7bey", "so", "kan", "sie", "kaum", "noch", "buhs\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "sie blagt ein heischrer Kr\u00fcchel-Husten.", "tokens": ["sie", "blagt", "ein", "heisc\u00b7hrer", "Kr\u00fc\u00b7chel\u00b7Hus\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ein Andrer suche ihr nach ihr Fl\u00f6hen", "tokens": ["Ein", "A\u00b7ndrer", "su\u00b7che", "ihr", "nach", "ihr", "Fl\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "auff den belihbten Busen-H\u00f6hen/", "tokens": ["auff", "den", "be\u00b7lihb\u00b7ten", "Bu\u00b7sen\u00b7H\u00f6\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "mein Hertz erzittert schon und bebt/", "tokens": ["mein", "Hertz", "er\u00b7zit\u00b7tert", "schon", "und", "bebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "KON", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "sorbald sich bloh\u00df ihr D\u00fcnn-Tuch hebt!", "tokens": ["sor\u00b7bald", "sich", "bloh\u00df", "ihr", "D\u00fcnn\u00b7Tuch", "hebt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Dringen ist for mir zu simpel.", "tokens": ["Drin\u00b7gen", "ist", "for", "mir", "zu", "sim\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "APPR", "NE", "$."], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ich gl\u00e4ube gar/ sie k\u00fcsst bloh\u00df Gimpel.", "tokens": ["Ich", "gl\u00e4u\u00b7be", "gar", "/", "sie", "k\u00fcsst", "bloh\u00df", "Gim\u00b7pel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PPER", "VVFIN", "ADV", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man siht es ihr nicht an vom Weitem/", "tokens": ["Man", "siht", "es", "ihr", "nicht", "an", "vom", "Wei\u00b7tem", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PPER", "PTKNEG", "APPR", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch hat sie sch\u00f6ne Einzelheiten.", "tokens": ["doch", "hat", "sie", "sch\u00f6\u00b7ne", "Ein\u00b7zel\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich so g\u00e4b sie jeden Falls", "tokens": ["Ich", "so", "g\u00e4b", "sie", "je\u00b7den", "Falls"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "for ein Qw\u00e4ntgen Attisch Saltz;", "tokens": ["for", "ein", "Qw\u00e4nt\u00b7gen", "At\u00b7tisch", "Saltz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "bloh\u00df zu Fleisch und bloh\u00df zu Bein", "tokens": ["bloh\u00df", "zu", "Fleisch", "und", "bloh\u00df", "zu", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "kan ich nicht r\u00e4cht z\u00e4hrtlig seyn!", "tokens": ["kan", "ich", "nicht", "r\u00e4cht", "z\u00e4hrt\u00b7lig", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Celinde \u00fcmb ihr bi\u00dfgen Waden", "tokens": ["Ce\u00b7lin\u00b7de", "\u00fcmb", "ihr", "bi\u00df\u00b7gen", "Wa\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "helt sich zu schade for die Maden.", "tokens": ["helt", "sich", "zu", "scha\u00b7de", "for", "die", "Ma\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKA", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Seit Kloridan sich ihr entrissen/", "tokens": ["Seit", "Klo\u00b7ri\u00b7dan", "sich", "ihr", "ent\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PRF", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "will sie von keinem mehr wa\u00df wissen.", "tokens": ["will", "sie", "von", "kei\u00b7nem", "mehr", "wa\u00df", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PIS", "ADV", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Nur Eins kan sie von all den Nympffen/", "tokens": ["Nur", "Eins", "kan", "sie", "von", "all", "den", "Nympf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "PPER", "APPR", "PIAT", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ihr Maul bi\u00df auff den Absazz r\u00fcmpffen.", "tokens": ["ihr", "Maul", "bi\u00df", "auff", "den", "Ab\u00b7sazz", "r\u00fcmpf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Zeit fehlt mir und Bappihr/", "tokens": ["Zeit", "fehlt", "mir", "und", "Bap\u00b7pihr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "KON", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "sonst schrihb ich ihr!", "tokens": ["sonst", "schrihb", "ich", "ihr", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Dihses scheint mir gantz gewi\u00df/", "tokens": ["Dih\u00b7ses", "scheint", "mir", "gantz", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ein Luder ist auch Lysilis!", "tokens": ["ein", "Lu\u00b7der", "ist", "auch", "Ly\u00b7si\u00b7lis", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zwar hat sie schr\u00f6kklich vihl Erfahrung/", "tokens": ["Zwar", "hat", "sie", "schr\u00f6kk\u00b7lich", "vihl", "Er\u00b7fah\u00b7rung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch fliht sie \u00fcmmer noch die Paarung.", "tokens": ["doch", "fliht", "sie", "\u00fcm\u00b7mer", "noch", "die", "Paa\u00b7rung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Inssonderlich uns Dheologen", "tokens": ["Ins\u00b7son\u00b7der\u00b7lich", "uns", "Dheo\u00b7lo\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPER", "NN"], "meter": "-+--+++-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "zeigt sie sich eusserst ohngewogen;", "tokens": ["zeigt", "sie", "sich", "eus\u00b7serst", "ohn\u00b7ge\u00b7wo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "ich gl\u00e4ub/ sie geht auff Lug und Drug/", "tokens": ["ich", "gl\u00e4ub", "/", "sie", "geht", "auff", "Lug", "und", "Drug", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "APPR", "NE", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "sie dhut mir nicht modest genug!", "tokens": ["sie", "dhut", "mir", "nicht", "mo\u00b7dest", "ge\u00b7nug", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADJD", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.10": {"line.1": {"text": "Floris/ dihses schlaue Biest/", "tokens": ["Flo\u00b7ris", "/", "dih\u00b7ses", "schlau\u00b7e", "Biest", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PDAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fast am mehrsten mich verdriesst.", "tokens": ["fast", "am", "mehrs\u00b7ten", "mich", "ver\u00b7driesst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kan schon einer von ihr sagen/", "tokens": ["Kan", "schon", "ei\u00b7ner", "von", "ihr", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "APPR", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df sie ihm wa\u00df ab-geschlagen?", "tokens": ["da\u00df", "sie", "ihm", "wa\u00df", "ab\u00b7ge\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kaum so hat sie wen allein/", "tokens": ["Kaum", "so", "hat", "sie", "wen", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "g\u00f6nnt sie's ihm vergn\u00fcgt zu seyn;", "tokens": ["g\u00f6nnt", "sie's", "ihm", "ver\u00b7gn\u00fcgt", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVPP", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "gleich so nimbt sie weich und warm/", "tokens": ["gleich", "so", "nimbt", "sie", "weich", "und", "warm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "ihn in ihren Schwahnen-Arm!", "tokens": ["ihn", "in", "ih\u00b7ren", "Schwahnen\u00b7Arm", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "Mechthildgen geht auff schwehren F\u00fc\u00dfen/", "tokens": ["Mecht\u00b7hild\u00b7gen", "geht", "auff", "schweh\u00b7ren", "F\u00fc\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "sie mu\u00df ihr Freundlich-seyn itzt b\u00fc\u00dfen.", "tokens": ["sie", "mu\u00df", "ihr", "Freund\u00b7lich\u00b7seyn", "itzt", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von jedem Bawian und Holuncken", "tokens": ["Von", "je\u00b7dem", "Ba\u00b7wi\u00b7an", "und", "Ho\u00b7lun\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "lih\u00df sie sich in die Br\u00fche tuncken;", "tokens": ["lih\u00df", "sie", "sich", "in", "die", "Br\u00fc\u00b7he", "tun\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "bey solcher zeig ich wenig Eyffer \u2013", "tokens": ["bey", "sol\u00b7cher", "zeig", "ich", "we\u00b7nig", "Eyf\u00b7fer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "fy Teix/ da ligt noch frembder Geiffer!", "tokens": ["fy", "Teix", "/", "da", "ligt", "noch", "fremb\u00b7der", "Geif\u00b7fer", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "ADV", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wo auff des ", "tokens": ["Wo", "auff", "des"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "die geneundte Schwestern sizzen/", "tokens": ["die", "ge\u00b7neund\u00b7te", "Schwes\u00b7tern", "siz\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "kan ich mir itzt kaum vergeben", "tokens": ["kan", "ich", "mir", "itzt", "kaum", "ver\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mein verfluchtes Buhler-Leben!", "tokens": ["mein", "ver\u00b7fluch\u00b7tes", "Buh\u00b7ler\u00b7Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meine vor gemachte Lieder", "tokens": ["Mei\u00b7ne", "vor", "ge\u00b7mach\u00b7te", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind mir gantz und gar zurwihder;", "tokens": ["sind", "mir", "gantz", "und", "gar", "zur\u00b7wih\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "KON", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ein Knaster-Pfeiffgen/ ein Coffee", "tokens": ["ein", "Knas\u00b7ter\u00b7Pfeiff\u00b7gen", "/", "ein", "Cof\u00b7fee"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "sind mir mein eintzges ", "tokens": ["sind", "mir", "mein", "eintz\u00b7ges"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "ADJA"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Meine annoch gr\u00fcne Jugend/", "tokens": ["Mei\u00b7ne", "an\u00b7noch", "gr\u00fc\u00b7ne", "Ju\u00b7gend", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "g\u00f6nn ich fortab bloh\u00df der Dugend;", "tokens": ["g\u00f6nn", "ich", "for\u00b7tab", "bloh\u00df", "der", "Du\u00b7gend", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "darfor so kr\u00f6hnt einst mein Gebein", "tokens": ["dar\u00b7for", "so", "kr\u00b7\u00f6hnt", "einst", "mein", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "ein zubespizzter Marmol-Stein!", "tokens": ["ein", "zu\u00b7be\u00b7spizz\u00b7ter", "Mar\u00b7mol\u00b7Stein", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "k\u00f6mbstu mir schon auff die Stube/", "tokens": ["k\u00f6mbs\u00b7tu", "mir", "schon", "auff", "die", "Stu\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "s\u00e4lbst wenn ich beym Ocksen bin?", "tokens": ["s\u00e4lbst", "wenn", "ich", "beym", "Ock\u00b7sen", "bin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPRART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Marsch! Ich kann dich itzt nicht br\u00e4uchen/", "tokens": ["Marsch", "!", "Ich", "kann", "dich", "itzt", "nicht", "br\u00e4u\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "scheer dich draussen zu den Str\u00e4uchen/", "tokens": ["scheer", "dich", "draus\u00b7sen", "zu", "den", "Str\u00e4u\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "oder auch zu Fillis hin!", "tokens": ["o\u00b7der", "auch", "zu", "Fil\u00b7lis", "hin", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihren Sizz vollkommner L\u00fcste/", "tokens": ["Ih\u00b7ren", "Sizz", "voll\u00b7komm\u00b7ner", "L\u00fcs\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ihre Wunder-volle Br\u00fcste", "tokens": ["ih\u00b7re", "Wun\u00b7der\u00b7vol\u00b7le", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "lege einem Andren bey;", "tokens": ["le\u00b7ge", "ei\u00b7nem", "An\u00b7dren", "bey", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "mag sie schmollen oder lachen/", "tokens": ["mag", "sie", "schmol\u00b7len", "o\u00b7der", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "KON", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "oder auch mir H\u00f6rner machen \u2013", "tokens": ["o\u00b7der", "auch", "mir", "H\u00f6r\u00b7ner", "ma\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "dihses ist mir einerley!", "tokens": ["dih\u00b7ses", "ist", "mir", "ei\u00b7ner\u00b7ley", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Erst so sehn die M\u00e4ntscher au\u00df/", "tokens": ["Erst", "so", "sehn", "die", "M\u00e4nt\u00b7scher", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "al\u00df ob von dem s\u00e4lben Dau\u00df", "tokens": ["al\u00df", "ob", "von", "dem", "s\u00e4l\u00b7ben", "Dau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "mindestens die ", "tokens": ["min\u00b7des\u00b7tens", "die"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "bald so m\u00e4rckt man sie fast rund/", "tokens": ["bald", "so", "m\u00e4rckt", "man", "sie", "fast", "rund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PPER", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sind sie w\u00fcrcklich so gesund?", "tokens": ["sind", "sie", "w\u00fcrck\u00b7lich", "so", "ge\u00b7sund", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sp\u00e4hter werden sie dan Ammen.", "tokens": ["Sp\u00e4h\u00b7ter", "wer\u00b7den", "sie", "dan", "Am\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das B\u00fcrtzel-Spihl auff Sto\u00df und Stich", "tokens": ["Das", "B\u00fcrt\u00b7zel\u00b7Spihl", "auff", "Sto\u00df", "und", "Stich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "verstehn sie fast zu dapfferlich!", "tokens": ["ver\u00b7stehn", "sie", "fast", "zu", "dapf\u00b7fer\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Flammaris mit f\u00fcnfzehn Jahren", "tokens": ["Flam\u00b7ma\u00b7ris", "mit", "f\u00fcnf\u00b7zehn", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "dhut noch zihmlich unerfahren/", "tokens": ["dhut", "noch", "zihm\u00b7lich", "un\u00b7er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "doch schon ist das s\u00fcsse Wesen", "tokens": ["doch", "schon", "ist", "das", "s\u00fcs\u00b7se", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in ", "tokens": ["in"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "und schon offt hat ihr getraumt/", "tokens": ["und", "schon", "offt", "hat", "ihr", "ge\u00b7traumt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PPER", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df sie wem wa\u00df eyn-geraumt!", "tokens": ["da\u00df", "sie", "wem", "wa\u00df", "eyn\u00b7ge\u00b7raumt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Siebzehn-j\u00e4hricht", "tokens": ["Sieb\u00b7zehn\u00b7j\u00e4h\u00b7richt"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Stichel-h\u00e4hricht!", "tokens": ["Sti\u00b7chel\u00b7h\u00e4h\u00b7richt", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "K\u00fckkt man solcher auff das Mihder/", "tokens": ["K\u00fckkt", "man", "sol\u00b7cher", "auff", "das", "Mih\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIAT", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schl\u00e4gt sie nicht die Augen nihder!", "tokens": ["schl\u00e4gt", "sie", "nicht", "die", "Au\u00b7gen", "nih\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00e4drichins kan ich bloh\u00df leiden", "tokens": ["M\u00e4d\u00b7ri\u00b7chins", "kan", "ich", "bloh\u00df", "lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wohl-gesittet und bescheiden/", "tokens": ["wohl\u00b7ge\u00b7sit\u00b7tet", "und", "be\u00b7schei\u00b7den", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "D\u00f6rtgen/ das nach jedem schuhlt/", "tokens": ["D\u00f6rt\u00b7gen", "/", "das", "nach", "je\u00b7dem", "schuhlt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PDS", "APPR", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "scheint mir dr\u00fcmb schon abgebuhlt!", "tokens": ["scheint", "mir", "dr\u00fcmb", "schon", "ab\u00b7ge\u00b7buhlt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Bambrette wird mir schon zu breit/", "tokens": ["Bam\u00b7bret\u00b7te", "wird", "mir", "schon", "zu", "breit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie stammt noch au\u00df der Schweden-Zeit;", "tokens": ["sie", "stammt", "noch", "au\u00df", "der", "Schwe\u00b7den\u00b7Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "dr\u00fcmb legt sie auch so ohnverdrossen", "tokens": ["dr\u00fcmb", "legt", "sie", "auch", "so", "ohn\u00b7ver\u00b7dros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sich Frosch-Laich auff die Sommer-Sprossen.", "tokens": ["sich", "FroschLaich", "auff", "die", "Som\u00b7mer\u00b7Spros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "F\u00fcr ihren au\u00df-gestopfften Busen", "tokens": ["F\u00fcr", "ih\u00b7ren", "au\u00df\u00b7ge\u00b7stopff\u00b7ten", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "verh\u00fcllen schaudrend sich die Musen;", "tokens": ["ver\u00b7h\u00fcl\u00b7len", "schaud\u00b7rend", "sich", "die", "Mu\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "der Himmel sch\u00e4nck ihr einen Mann/", "tokens": ["der", "Him\u00b7mel", "sch\u00e4n\u00b7ck", "ihr", "ei\u00b7nen", "Mann", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ihr kommen sonst die Schaben dran!", "tokens": ["ihr", "kom\u00b7men", "sonst", "die", "Scha\u00b7ben", "dran", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Barbettgen ist sogar schon bartig/", "tokens": ["Bar\u00b7bett\u00b7gen", "ist", "so\u00b7gar", "schon", "bar\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wenn man sie k\u00fcsst/ so wird man schartig/", "tokens": ["wenn", "man", "sie", "k\u00fcsst", "/", "so", "wird", "man", "schar\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$(", "ADV", "VAFIN", "PIS", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "au\u00df ihrer Elen-langen Nase", "tokens": ["au\u00df", "ih\u00b7rer", "E\u00b7len\u00b7lan\u00b7gen", "Na\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "droppts wie au\u00df einer Wasser-Blase.", "tokens": ["droppts", "wie", "au\u00df", "ei\u00b7ner", "Was\u00b7ser\u00b7Bla\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Maul von angenehmer Bl\u00e4ue", "tokens": ["Ihr", "Maul", "von", "an\u00b7ge\u00b7neh\u00b7mer", "Bl\u00e4u\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "gleicht mehr schon einer Vogel-Sch\u00e4ue;", "tokens": ["gleicht", "mehr", "schon", "ei\u00b7ner", "Vo\u00b7gel\u00b7Sch\u00e4ue", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "darbey so kan sie kaum noch buhsten/", "tokens": ["dar\u00b7bey", "so", "kan", "sie", "kaum", "noch", "buhs\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "sie blagt ein heischrer Kr\u00fcchel-Husten.", "tokens": ["sie", "blagt", "ein", "heisc\u00b7hrer", "Kr\u00fc\u00b7chel\u00b7Hus\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ein Andrer suche ihr nach ihr Fl\u00f6hen", "tokens": ["Ein", "A\u00b7ndrer", "su\u00b7che", "ihr", "nach", "ihr", "Fl\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "auff den belihbten Busen-H\u00f6hen/", "tokens": ["auff", "den", "be\u00b7lihb\u00b7ten", "Bu\u00b7sen\u00b7H\u00f6\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "mein Hertz erzittert schon und bebt/", "tokens": ["mein", "Hertz", "er\u00b7zit\u00b7tert", "schon", "und", "bebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "KON", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "sorbald sich bloh\u00df ihr D\u00fcnn-Tuch hebt!", "tokens": ["sor\u00b7bald", "sich", "bloh\u00df", "ihr", "D\u00fcnn\u00b7Tuch", "hebt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.19": {"line.1": {"text": "Dringen ist for mir zu simpel.", "tokens": ["Drin\u00b7gen", "ist", "for", "mir", "zu", "sim\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "APPR", "NE", "$."], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ich gl\u00e4ube gar/ sie k\u00fcsst bloh\u00df Gimpel.", "tokens": ["Ich", "gl\u00e4u\u00b7be", "gar", "/", "sie", "k\u00fcsst", "bloh\u00df", "Gim\u00b7pel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PPER", "VVFIN", "ADV", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man siht es ihr nicht an vom Weitem/", "tokens": ["Man", "siht", "es", "ihr", "nicht", "an", "vom", "Wei\u00b7tem", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PPER", "PTKNEG", "APPR", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch hat sie sch\u00f6ne Einzelheiten.", "tokens": ["doch", "hat", "sie", "sch\u00f6\u00b7ne", "Ein\u00b7zel\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich so g\u00e4b sie jeden Falls", "tokens": ["Ich", "so", "g\u00e4b", "sie", "je\u00b7den", "Falls"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "for ein Qw\u00e4ntgen Attisch Saltz;", "tokens": ["for", "ein", "Qw\u00e4nt\u00b7gen", "At\u00b7tisch", "Saltz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "bloh\u00df zu Fleisch und bloh\u00df zu Bein", "tokens": ["bloh\u00df", "zu", "Fleisch", "und", "bloh\u00df", "zu", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "kan ich nicht r\u00e4cht z\u00e4hrtlig seyn!", "tokens": ["kan", "ich", "nicht", "r\u00e4cht", "z\u00e4hrt\u00b7lig", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Celinde \u00fcmb ihr bi\u00dfgen Waden", "tokens": ["Ce\u00b7lin\u00b7de", "\u00fcmb", "ihr", "bi\u00df\u00b7gen", "Wa\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "helt sich zu schade for die Maden.", "tokens": ["helt", "sich", "zu", "scha\u00b7de", "for", "die", "Ma\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKA", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Seit Kloridan sich ihr entrissen/", "tokens": ["Seit", "Klo\u00b7ri\u00b7dan", "sich", "ihr", "ent\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PRF", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "will sie von keinem mehr wa\u00df wissen.", "tokens": ["will", "sie", "von", "kei\u00b7nem", "mehr", "wa\u00df", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PIS", "ADV", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Nur Eins kan sie von all den Nympffen/", "tokens": ["Nur", "Eins", "kan", "sie", "von", "all", "den", "Nympf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "PPER", "APPR", "PIAT", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ihr Maul bi\u00df auff den Absazz r\u00fcmpffen.", "tokens": ["ihr", "Maul", "bi\u00df", "auff", "den", "Ab\u00b7sazz", "r\u00fcmpf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Zeit fehlt mir und Bappihr/", "tokens": ["Zeit", "fehlt", "mir", "und", "Bap\u00b7pihr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "KON", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "sonst schrihb ich ihr!", "tokens": ["sonst", "schrihb", "ich", "ihr", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.21": {"line.1": {"text": "Dihses scheint mir gantz gewi\u00df/", "tokens": ["Dih\u00b7ses", "scheint", "mir", "gantz", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ein Luder ist auch Lysilis!", "tokens": ["ein", "Lu\u00b7der", "ist", "auch", "Ly\u00b7si\u00b7lis", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zwar hat sie schr\u00f6kklich vihl Erfahrung/", "tokens": ["Zwar", "hat", "sie", "schr\u00f6kk\u00b7lich", "vihl", "Er\u00b7fah\u00b7rung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch fliht sie \u00fcmmer noch die Paarung.", "tokens": ["doch", "fliht", "sie", "\u00fcm\u00b7mer", "noch", "die", "Paa\u00b7rung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Inssonderlich uns Dheologen", "tokens": ["Ins\u00b7son\u00b7der\u00b7lich", "uns", "Dheo\u00b7lo\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPER", "NN"], "meter": "-+--+++-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "zeigt sie sich eusserst ohngewogen;", "tokens": ["zeigt", "sie", "sich", "eus\u00b7serst", "ohn\u00b7ge\u00b7wo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "ich gl\u00e4ub/ sie geht auff Lug und Drug/", "tokens": ["ich", "gl\u00e4ub", "/", "sie", "geht", "auff", "Lug", "und", "Drug", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "APPR", "NE", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "sie dhut mir nicht modest genug!", "tokens": ["sie", "dhut", "mir", "nicht", "mo\u00b7dest", "ge\u00b7nug", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADJD", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.22": {"line.1": {"text": "Floris/ dihses schlaue Biest/", "tokens": ["Flo\u00b7ris", "/", "dih\u00b7ses", "schlau\u00b7e", "Biest", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PDAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "fast am mehrsten mich verdriesst.", "tokens": ["fast", "am", "mehrs\u00b7ten", "mich", "ver\u00b7driesst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kan schon einer von ihr sagen/", "tokens": ["Kan", "schon", "ei\u00b7ner", "von", "ihr", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "APPR", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df sie ihm wa\u00df ab-geschlagen?", "tokens": ["da\u00df", "sie", "ihm", "wa\u00df", "ab\u00b7ge\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kaum so hat sie wen allein/", "tokens": ["Kaum", "so", "hat", "sie", "wen", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "g\u00f6nnt sie's ihm vergn\u00fcgt zu seyn;", "tokens": ["g\u00f6nnt", "sie's", "ihm", "ver\u00b7gn\u00fcgt", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVPP", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "gleich so nimbt sie weich und warm/", "tokens": ["gleich", "so", "nimbt", "sie", "weich", "und", "warm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "ihn in ihren Schwahnen-Arm!", "tokens": ["ihn", "in", "ih\u00b7ren", "Schwahnen\u00b7Arm", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.23": {"line.1": {"text": "Mechthildgen geht auff schwehren F\u00fc\u00dfen/", "tokens": ["Mecht\u00b7hild\u00b7gen", "geht", "auff", "schweh\u00b7ren", "F\u00fc\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "sie mu\u00df ihr Freundlich-seyn itzt b\u00fc\u00dfen.", "tokens": ["sie", "mu\u00df", "ihr", "Freund\u00b7lich\u00b7seyn", "itzt", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von jedem Bawian und Holuncken", "tokens": ["Von", "je\u00b7dem", "Ba\u00b7wi\u00b7an", "und", "Ho\u00b7lun\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "lih\u00df sie sich in die Br\u00fche tuncken;", "tokens": ["lih\u00df", "sie", "sich", "in", "die", "Br\u00fc\u00b7he", "tun\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "bey solcher zeig ich wenig Eyffer \u2013", "tokens": ["bey", "sol\u00b7cher", "zeig", "ich", "we\u00b7nig", "Eyf\u00b7fer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "fy Teix/ da ligt noch frembder Geiffer!", "tokens": ["fy", "Teix", "/", "da", "ligt", "noch", "fremb\u00b7der", "Geif\u00b7fer", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "ADV", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Wo auff des ", "tokens": ["Wo", "auff", "des"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "die geneundte Schwestern sizzen/", "tokens": ["die", "ge\u00b7neund\u00b7te", "Schwes\u00b7tern", "siz\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "kan ich mir itzt kaum vergeben", "tokens": ["kan", "ich", "mir", "itzt", "kaum", "ver\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mein verfluchtes Buhler-Leben!", "tokens": ["mein", "ver\u00b7fluch\u00b7tes", "Buh\u00b7ler\u00b7Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meine vor gemachte Lieder", "tokens": ["Mei\u00b7ne", "vor", "ge\u00b7mach\u00b7te", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind mir gantz und gar zurwihder;", "tokens": ["sind", "mir", "gantz", "und", "gar", "zur\u00b7wih\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "KON", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ein Knaster-Pfeiffgen/ ein Coffee", "tokens": ["ein", "Knas\u00b7ter\u00b7Pfeiff\u00b7gen", "/", "ein", "Cof\u00b7fee"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "sind mir mein eintzges ", "tokens": ["sind", "mir", "mein", "eintz\u00b7ges"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "ADJA"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Meine annoch gr\u00fcne Jugend/", "tokens": ["Mei\u00b7ne", "an\u00b7noch", "gr\u00fc\u00b7ne", "Ju\u00b7gend", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "g\u00f6nn ich fortab bloh\u00df der Dugend;", "tokens": ["g\u00f6nn", "ich", "for\u00b7tab", "bloh\u00df", "der", "Du\u00b7gend", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "darfor so kr\u00f6hnt einst mein Gebein", "tokens": ["dar\u00b7for", "so", "kr\u00b7\u00f6hnt", "einst", "mein", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "ein zubespizzter Marmol-Stein!", "tokens": ["ein", "zu\u00b7be\u00b7spizz\u00b7ter", "Mar\u00b7mol\u00b7Stein", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}