{"textgrid.poem.53180": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "[herr, da\u00df \u00fcberschickte Thier]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herr, da\u00df \u00fcberschickte Thier", "tokens": ["Herr", ",", "da\u00df", "\u00fc\u00b7bersc\u00b7hick\u00b7te", "Thier"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hab ich schon erw\u00fcrgt allhier", "tokens": ["Hab", "ich", "schon", "er\u00b7w\u00fcrgt", "all\u00b7hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd es gut befunden,", "tokens": ["Vnd", "es", "gut", "be\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "So viel Tropffen Bluts es hegt,", "tokens": ["So", "viel", "Tropf\u00b7fen", "Bluts", "es", "hegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "NN", "PPER", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "So viel sey dir zugelegt", "tokens": ["So", "viel", "sey", "dir", "zu\u00b7ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hievor gutter Stunden.", "tokens": ["Hie\u00b7vor", "gut\u00b7ter", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Aber da\u00df geh\u00f6rnte Wort", "tokens": ["A\u00b7ber", "da\u00df", "ge\u00b7h\u00f6rn\u00b7te", "Wort"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wa\u00df kompt es mir stets an Bort?", "tokens": ["Wa\u00df", "kompt", "es", "mir", "stets", "an", "Bort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ADV", "APPR", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Vnd wa\u00df h\u00f6r ich sagen?", "tokens": ["Vnd", "wa\u00df", "h\u00f6r", "ich", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00f6rner stehen mir nicht an,", "tokens": ["H\u00f6r\u00b7ner", "ste\u00b7hen", "mir", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df sie lieben, wer sie kan", "tokens": ["La\u00df", "sie", "lie\u00b7ben", ",", "wer", "sie", "kan"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "PWS", "PPER", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd, wer wil, sie tragen.", "tokens": ["Vnd", ",", "wer", "wil", ",", "sie", "tra\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "VMFIN", "$,", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Ist vorhin mein Kopff den leer?", "tokens": ["Ist", "vor\u00b7hin", "mein", "Kopff", "den", "leer", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ART", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nicht vorhin von Reimen schwer,", "tokens": ["Nicht", "vor\u00b7hin", "von", "Rei\u00b7men", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich m\u00f6cht erliegen?", "tokens": ["Da\u00df", "ich", "m\u00f6cht", "er\u00b7lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Verse machen offt mich toll", "tokens": ["Ver\u00b7se", "ma\u00b7chen", "offt", "mich", "toll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "PPER", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd so grillisch, da\u00df ich woll", "tokens": ["Vnd", "so", "gril\u00b7lisch", ",", "da\u00df", "ich", "woll"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$,", "KOUS", "PPER", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "M\u00f6chte H\u00f6rner kriegen.", "tokens": ["M\u00f6ch\u00b7te", "H\u00f6r\u00b7ner", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Sonst enth\u00f6rn ich mannigmahl", "tokens": ["Sonst", "ent\u00b7h\u00f6rn", "ich", "man\u00b7nig\u00b7mahl"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Bacchanten grosse Zahl,", "tokens": ["Der", "Bac\u00b7chan\u00b7ten", "gros\u00b7se", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht wie jener eben,", "tokens": ["Nicht", "wie", "je\u00b7ner", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOKOM", "PDS", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der vom Sohn die H\u00f6rner bracht", "tokens": ["Der", "vom", "Sohn", "die", "H\u00f6r\u00b7ner", "bracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd dem Vater sie die Nacht", "tokens": ["Vnd", "dem", "Va\u00b7ter", "sie", "die", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder pflag zu geben.", "tokens": ["Wie\u00b7der", "pflag", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Geb ich aber endlich auch", "tokens": ["Geb", "ich", "a\u00b7ber", "end\u00b7lich", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wieder Willen, Muht vnd Brauch", "tokens": ["Wie\u00b7der", "Wil\u00b7len", ",", "Muht", "vnd", "Brauch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Horngenossen,", "tokens": ["Ei\u00b7nen", "Horn\u00b7ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wol, tragt aber meiner Schew,", "tokens": ["Wol", ",", "tragt", "a\u00b7ber", "mei\u00b7ner", "Schew", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Warumb da\u00df? mein Horn hat Hew", "tokens": ["Wa\u00b7rumb", "da\u00df", "?", "mein", "Horn", "hat", "Hew"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "KOUS", "$.", "PPOSAT", "NN", "VAFIN", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Vnd kan hefftig stossen.", "tokens": ["Vnd", "kan", "heff\u00b7tig", "stos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.6": {"line.1": {"text": "Niemand, raht ich, reitze mich,", "tokens": ["Nie\u00b7mand", ",", "raht", "ich", ",", "reit\u00b7ze", "mich", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Man mach an die Kefer sich", "tokens": ["Man", "mach", "an", "die", "Ke\u00b7fer", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "PRF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eh als an Poeten,", "tokens": ["Eh", "als", "an", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "APPR", "NN", "$,"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.4": {"text": "Weh dem \u00fcber alle ma\u00df,", "tokens": ["Weh", "dem", "\u00fc\u00b7ber", "al\u00b7le", "ma\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Den ich auff die H\u00f6rner fa\u00df,", "tokens": ["Den", "ich", "auff", "die", "H\u00f6r\u00b7ner", "fa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Er hat Trost von n\u00f6hten.", "tokens": ["Er", "hat", "Trost", "von", "n\u00f6h\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Und wa\u00df solten in gemein", "tokens": ["Und", "wa\u00df", "sol\u00b7ten", "in", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6rner einem schimpfflich seyn?", "tokens": ["H\u00f6r\u00b7ner", "ei\u00b7nem", "schimpf\u00b7flich", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bacchus, recht zu sagen,", "tokens": ["Bac\u00b7chus", ",", "recht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der bi\u00df durch den Ganges drang,", "tokens": ["Der", "bi\u00df", "durch", "den", "Gan\u00b7ges", "drang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Al\u00df er Indien bezwang,", "tokens": ["Al\u00df", "er", "In\u00b7di\u00b7en", "be\u00b7zwang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Hat sie selbst getragen.", "tokens": ["Hat", "sie", "selbst", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Wa\u00df? Philippus grosser Sohn", "tokens": ["Wa\u00df", "?", "Phil\u00b7ip\u00b7pus", "gros\u00b7ser", "Sohn"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "NE", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hielte sie erst f\u00fcr den Lohn", "tokens": ["Hiel\u00b7te", "sie", "erst", "f\u00fcr", "den", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner strengen Thaten,", "tokens": ["Sei\u00b7ner", "stren\u00b7gen", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Lie\u00df sich Jovis Ammons Kind", "tokens": ["Lie\u00df", "sich", "Jo\u00b7vis", "Am\u00b7mons", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "NE", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nennen von dem Hoffgesind", "tokens": ["Nen\u00b7nen", "von", "dem", "Hoff\u00b7ge\u00b7sind"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd von den Soldaten.", "tokens": ["Vnd", "von", "den", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Mehr, die Junckerh\u00f6ff allhier", "tokens": ["Mehr", ",", "die", "Jun\u00b7cker\u00b7h\u00f6ff", "all\u00b7hier"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "ART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wollen gern das schwartze Bier", "tokens": ["Wol\u00b7len", "gern", "das", "schwart\u00b7ze", "Bier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur aus H\u00f6rnern leeren:", "tokens": ["Nur", "aus", "H\u00f6r\u00b7nern", "lee\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ob nun mancher auch dabey", "tokens": ["Ob", "nun", "man\u00b7cher", "auch", "da\u00b7bey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIS", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein geh\u00f6rntes Thierchen sey,", "tokens": ["Ein", "ge\u00b7h\u00f6rn\u00b7tes", "Thier\u00b7chen", "sey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kan ich nicht bewehren.", "tokens": ["Kan", "ich", "nicht", "be\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Lach, Herr Hauptmann, nicht zu viel,", "tokens": ["Lach", ",", "Herr", "Haupt\u00b7mann", ",", "nicht", "zu", "viel", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "NN", "$,", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6rner sind kein Kinderspiel,", "tokens": ["H\u00f6r\u00b7ner", "sind", "kein", "Kin\u00b7der\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sie nicht kan meiden,", "tokens": ["Wer", "sie", "nicht", "kan", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nun, was hat der arme Schuld,", "tokens": ["Nun", ",", "was", "hat", "der", "ar\u00b7me", "Schuld", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sein Verbrechen ist Gedult,", "tokens": ["Sein", "Ver\u00b7bre\u00b7chen", "ist", "Ge\u00b7dult", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hierumb mu\u00df er leiden.", "tokens": ["Hie\u00b7rumb", "mu\u00df", "er", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.11": {"line.1": {"text": "Eines ist nach meinem Sinn", "tokens": ["Ei\u00b7nes", "ist", "nach", "mei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch sein Vortheil vnd Gewinn,", "tokens": ["Noch", "sein", "Vor\u00b7theil", "vnd", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er sich kan frewen,", "tokens": ["Da\u00df", "er", "sich", "kan", "fre\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df ohn seine M\u00fch vnd Krafft", "tokens": ["Da\u00df", "ohn", "sei\u00b7ne", "M\u00fch", "vnd", "Krafft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er zu mancher Schw\u00e4gerschafft", "tokens": ["Er", "zu", "man\u00b7cher", "Schw\u00e4\u00b7ger\u00b7schafft"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hiedurch kan gedeyen.", "tokens": ["Hie\u00b7durch", "kan", "ge\u00b7de\u00b7yen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "VVINF", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.12": {"line.1": {"text": "Ich vergesse mich beynah,", "tokens": ["Ich", "ver\u00b7ges\u00b7se", "mich", "bey\u00b7nah", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Horn mir hie vnd Horn mir da,", "tokens": ["Horn", "mir", "hie", "vnd", "Horn", "mir", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "KON", "NN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zahlt die\u00df meine Schulden?", "tokens": ["Zahlt", "die\u00df", "mei\u00b7ne", "Schul\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Herr, soll mir es besser seyn,", "tokens": ["Herr", ",", "soll", "mir", "es", "bes\u00b7ser", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VMFIN", "PPER", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schick auff den Befehl mir ein", "tokens": ["Schick", "auff", "den", "Be\u00b7fehl", "mir", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "PPER", "ART"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die vierhundert Gulden.", "tokens": ["Die", "vier\u00b7hun\u00b7dert", "Gul\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.13": {"line.1": {"text": "Herr, da\u00df \u00fcberschickte Thier", "tokens": ["Herr", ",", "da\u00df", "\u00fc\u00b7bersc\u00b7hick\u00b7te", "Thier"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hab ich schon erw\u00fcrgt allhier", "tokens": ["Hab", "ich", "schon", "er\u00b7w\u00fcrgt", "all\u00b7hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd es gut befunden,", "tokens": ["Vnd", "es", "gut", "be\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "So viel Tropffen Bluts es hegt,", "tokens": ["So", "viel", "Tropf\u00b7fen", "Bluts", "es", "hegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "NN", "PPER", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "So viel sey dir zugelegt", "tokens": ["So", "viel", "sey", "dir", "zu\u00b7ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hievor gutter Stunden.", "tokens": ["Hie\u00b7vor", "gut\u00b7ter", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Aber da\u00df geh\u00f6rnte Wort", "tokens": ["A\u00b7ber", "da\u00df", "ge\u00b7h\u00f6rn\u00b7te", "Wort"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wa\u00df kompt es mir stets an Bort?", "tokens": ["Wa\u00df", "kompt", "es", "mir", "stets", "an", "Bort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ADV", "APPR", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Vnd wa\u00df h\u00f6r ich sagen?", "tokens": ["Vnd", "wa\u00df", "h\u00f6r", "ich", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00f6rner stehen mir nicht an,", "tokens": ["H\u00f6r\u00b7ner", "ste\u00b7hen", "mir", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00df sie lieben, wer sie kan", "tokens": ["La\u00df", "sie", "lie\u00b7ben", ",", "wer", "sie", "kan"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "PWS", "PPER", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd, wer wil, sie tragen.", "tokens": ["Vnd", ",", "wer", "wil", ",", "sie", "tra\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "VMFIN", "$,", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Ist vorhin mein Kopff den leer?", "tokens": ["Ist", "vor\u00b7hin", "mein", "Kopff", "den", "leer", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ART", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nicht vorhin von Reimen schwer,", "tokens": ["Nicht", "vor\u00b7hin", "von", "Rei\u00b7men", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich m\u00f6cht erliegen?", "tokens": ["Da\u00df", "ich", "m\u00f6cht", "er\u00b7lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Verse machen offt mich toll", "tokens": ["Ver\u00b7se", "ma\u00b7chen", "offt", "mich", "toll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "PPER", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd so grillisch, da\u00df ich woll", "tokens": ["Vnd", "so", "gril\u00b7lisch", ",", "da\u00df", "ich", "woll"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$,", "KOUS", "PPER", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "M\u00f6chte H\u00f6rner kriegen.", "tokens": ["M\u00f6ch\u00b7te", "H\u00f6r\u00b7ner", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Sonst enth\u00f6rn ich mannigmahl", "tokens": ["Sonst", "ent\u00b7h\u00f6rn", "ich", "man\u00b7nig\u00b7mahl"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Bacchanten grosse Zahl,", "tokens": ["Der", "Bac\u00b7chan\u00b7ten", "gros\u00b7se", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht wie jener eben,", "tokens": ["Nicht", "wie", "je\u00b7ner", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOKOM", "PDS", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der vom Sohn die H\u00f6rner bracht", "tokens": ["Der", "vom", "Sohn", "die", "H\u00f6r\u00b7ner", "bracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd dem Vater sie die Nacht", "tokens": ["Vnd", "dem", "Va\u00b7ter", "sie", "die", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder pflag zu geben.", "tokens": ["Wie\u00b7der", "pflag", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Geb ich aber endlich auch", "tokens": ["Geb", "ich", "a\u00b7ber", "end\u00b7lich", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wieder Willen, Muht vnd Brauch", "tokens": ["Wie\u00b7der", "Wil\u00b7len", ",", "Muht", "vnd", "Brauch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Horngenossen,", "tokens": ["Ei\u00b7nen", "Horn\u00b7ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wol, tragt aber meiner Schew,", "tokens": ["Wol", ",", "tragt", "a\u00b7ber", "mei\u00b7ner", "Schew", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Warumb da\u00df? mein Horn hat Hew", "tokens": ["Wa\u00b7rumb", "da\u00df", "?", "mein", "Horn", "hat", "Hew"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "KOUS", "$.", "PPOSAT", "NN", "VAFIN", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Vnd kan hefftig stossen.", "tokens": ["Vnd", "kan", "heff\u00b7tig", "stos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.18": {"line.1": {"text": "Niemand, raht ich, reitze mich,", "tokens": ["Nie\u00b7mand", ",", "raht", "ich", ",", "reit\u00b7ze", "mich", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Man mach an die Kefer sich", "tokens": ["Man", "mach", "an", "die", "Ke\u00b7fer", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "PRF"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eh als an Poeten,", "tokens": ["Eh", "als", "an", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "APPR", "NN", "$,"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.4": {"text": "Weh dem \u00fcber alle ma\u00df,", "tokens": ["Weh", "dem", "\u00fc\u00b7ber", "al\u00b7le", "ma\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Den ich auff die H\u00f6rner fa\u00df,", "tokens": ["Den", "ich", "auff", "die", "H\u00f6r\u00b7ner", "fa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Er hat Trost von n\u00f6hten.", "tokens": ["Er", "hat", "Trost", "von", "n\u00f6h\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Und wa\u00df solten in gemein", "tokens": ["Und", "wa\u00df", "sol\u00b7ten", "in", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6rner einem schimpfflich seyn?", "tokens": ["H\u00f6r\u00b7ner", "ei\u00b7nem", "schimpf\u00b7flich", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bacchus, recht zu sagen,", "tokens": ["Bac\u00b7chus", ",", "recht", "zu", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der bi\u00df durch den Ganges drang,", "tokens": ["Der", "bi\u00df", "durch", "den", "Gan\u00b7ges", "drang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Al\u00df er Indien bezwang,", "tokens": ["Al\u00df", "er", "In\u00b7di\u00b7en", "be\u00b7zwang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Hat sie selbst getragen.", "tokens": ["Hat", "sie", "selbst", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Wa\u00df? Philippus grosser Sohn", "tokens": ["Wa\u00df", "?", "Phil\u00b7ip\u00b7pus", "gros\u00b7ser", "Sohn"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "NE", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hielte sie erst f\u00fcr den Lohn", "tokens": ["Hiel\u00b7te", "sie", "erst", "f\u00fcr", "den", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner strengen Thaten,", "tokens": ["Sei\u00b7ner", "stren\u00b7gen", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Lie\u00df sich Jovis Ammons Kind", "tokens": ["Lie\u00df", "sich", "Jo\u00b7vis", "Am\u00b7mons", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "NE", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nennen von dem Hoffgesind", "tokens": ["Nen\u00b7nen", "von", "dem", "Hoff\u00b7ge\u00b7sind"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd von den Soldaten.", "tokens": ["Vnd", "von", "den", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Mehr, die Junckerh\u00f6ff allhier", "tokens": ["Mehr", ",", "die", "Jun\u00b7cker\u00b7h\u00f6ff", "all\u00b7hier"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "ART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wollen gern das schwartze Bier", "tokens": ["Wol\u00b7len", "gern", "das", "schwart\u00b7ze", "Bier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur aus H\u00f6rnern leeren:", "tokens": ["Nur", "aus", "H\u00f6r\u00b7nern", "lee\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ob nun mancher auch dabey", "tokens": ["Ob", "nun", "man\u00b7cher", "auch", "da\u00b7bey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIS", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein geh\u00f6rntes Thierchen sey,", "tokens": ["Ein", "ge\u00b7h\u00f6rn\u00b7tes", "Thier\u00b7chen", "sey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kan ich nicht bewehren.", "tokens": ["Kan", "ich", "nicht", "be\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Lach, Herr Hauptmann, nicht zu viel,", "tokens": ["Lach", ",", "Herr", "Haupt\u00b7mann", ",", "nicht", "zu", "viel", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "NN", "$,", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6rner sind kein Kinderspiel,", "tokens": ["H\u00f6r\u00b7ner", "sind", "kein", "Kin\u00b7der\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sie nicht kan meiden,", "tokens": ["Wer", "sie", "nicht", "kan", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nun, was hat der arme Schuld,", "tokens": ["Nun", ",", "was", "hat", "der", "ar\u00b7me", "Schuld", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sein Verbrechen ist Gedult,", "tokens": ["Sein", "Ver\u00b7bre\u00b7chen", "ist", "Ge\u00b7dult", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hierumb mu\u00df er leiden.", "tokens": ["Hie\u00b7rumb", "mu\u00df", "er", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.23": {"line.1": {"text": "Eines ist nach meinem Sinn", "tokens": ["Ei\u00b7nes", "ist", "nach", "mei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch sein Vortheil vnd Gewinn,", "tokens": ["Noch", "sein", "Vor\u00b7theil", "vnd", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er sich kan frewen,", "tokens": ["Da\u00df", "er", "sich", "kan", "fre\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df ohn seine M\u00fch vnd Krafft", "tokens": ["Da\u00df", "ohn", "sei\u00b7ne", "M\u00fch", "vnd", "Krafft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er zu mancher Schw\u00e4gerschafft", "tokens": ["Er", "zu", "man\u00b7cher", "Schw\u00e4\u00b7ger\u00b7schafft"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hiedurch kan gedeyen.", "tokens": ["Hie\u00b7durch", "kan", "ge\u00b7de\u00b7yen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "VVINF", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.24": {"line.1": {"text": "Ich vergesse mich beynah,", "tokens": ["Ich", "ver\u00b7ges\u00b7se", "mich", "bey\u00b7nah", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Horn mir hie vnd Horn mir da,", "tokens": ["Horn", "mir", "hie", "vnd", "Horn", "mir", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "KON", "NN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zahlt die\u00df meine Schulden?", "tokens": ["Zahlt", "die\u00df", "mei\u00b7ne", "Schul\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Herr, soll mir es besser seyn,", "tokens": ["Herr", ",", "soll", "mir", "es", "bes\u00b7ser", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VMFIN", "PPER", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schick auff den Befehl mir ein", "tokens": ["Schick", "auff", "den", "Be\u00b7fehl", "mir", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "PPER", "ART"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die vierhundert Gulden.", "tokens": ["Die", "vier\u00b7hun\u00b7dert", "Gul\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}