{"textgrid.poem.42849": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mir ist wieder manches begegnet.", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.85", "da:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mir ist wieder manches begegnet.", "tokens": ["Mir", "ist", "wie\u00b7der", "man\u00b7ches", "be\u00b7geg\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Es hat Bindfaden geregnet.", "tokens": ["Es", "hat", "Bind\u00b7fa\u00b7den", "ge\u00b7reg\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das Wasser bepinkelte Stra\u00dfen und Gassen,", "tokens": ["Das", "Was\u00b7ser", "be\u00b7pin\u00b7kel\u00b7te", "Stra\u00b7\u00dfen", "und", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Und ein verregneter Sprengwagenlenker", "tokens": ["Und", "ein", "ver\u00b7reg\u00b7ne\u00b7ter", "Spreng\u00b7wa\u00b7gen\u00b7len\u00b7ker"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Fluchte den Regenmacher zum Henker.", "tokens": ["Fluch\u00b7te", "den", "Re\u00b7gen\u00b7ma\u00b7cher", "zum", "Hen\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das sollte ein Sprengwagenlenker", "tokens": ["Das", "soll\u00b7te", "ein", "Spreng\u00b7wa\u00b7gen\u00b7len\u00b7ker"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Doch lieber unterlassen.", "tokens": ["Doch", "lie\u00b7ber", "un\u00b7ter\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Vor einer gr\u00fcngekleideten Maid", "tokens": ["Vor", "ei\u00b7ner", "gr\u00fcn\u00b7ge\u00b7klei\u00b7de\u00b7ten", "Maid"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Blieb ich begeistert stehn.", "tokens": ["Blieb", "ich", "be\u00b7geis\u00b7tert", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie sagte: Ich m\u00f6chte weitergehn.", "tokens": ["Sie", "sag\u00b7te", ":", "Ich", "m\u00f6ch\u00b7te", "wei\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das tat ich.", "tokens": ["Das", "tat", "ich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ob Mann, ob Frau, im gr\u00fcnen Kleid", "tokens": ["Ob", "Mann", ",", "ob", "Frau", ",", "im", "gr\u00fc\u00b7nen", "Kleid"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sind beide stets sympathisch.", "tokens": ["Sind", "bei\u00b7de", "stets", "sym\u00b7pa\u00b7thisch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Im zweiten Fall war ich sehr k\u00fchl,", "tokens": ["Im", "zwei\u00b7ten", "Fall", "war", "ich", "sehr", "k\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Denn ich entscheide nach Gef\u00fchl,", "tokens": ["Denn", "ich", "ent\u00b7schei\u00b7de", "nach", "Ge\u00b7f\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und mit einer Frau mit konkaven", "tokens": ["Und", "mit", "ei\u00b7ner", "Frau", "mit", "kon\u00b7ka\u00b7ven"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Popo", "tokens": ["Po\u00b7po"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Geh ich nun einmal nicht schlafen,", "tokens": ["Geh", "ich", "nun", "ein\u00b7mal", "nicht", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "No, no!", "tokens": ["No", ",", "no", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["FM", "$,", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.3": {"line.1": {"text": "Mir ist wieder manches begegnet.", "tokens": ["Mir", "ist", "wie\u00b7der", "man\u00b7ches", "be\u00b7geg\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Es hat Bindfaden geregnet.", "tokens": ["Es", "hat", "Bind\u00b7fa\u00b7den", "ge\u00b7reg\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das Wasser bepinkelte Stra\u00dfen und Gassen,", "tokens": ["Das", "Was\u00b7ser", "be\u00b7pin\u00b7kel\u00b7te", "Stra\u00b7\u00dfen", "und", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Und ein verregneter Sprengwagenlenker", "tokens": ["Und", "ein", "ver\u00b7reg\u00b7ne\u00b7ter", "Spreng\u00b7wa\u00b7gen\u00b7len\u00b7ker"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Fluchte den Regenmacher zum Henker.", "tokens": ["Fluch\u00b7te", "den", "Re\u00b7gen\u00b7ma\u00b7cher", "zum", "Hen\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das sollte ein Sprengwagenlenker", "tokens": ["Das", "soll\u00b7te", "ein", "Spreng\u00b7wa\u00b7gen\u00b7len\u00b7ker"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Doch lieber unterlassen.", "tokens": ["Doch", "lie\u00b7ber", "un\u00b7ter\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Vor einer gr\u00fcngekleideten Maid", "tokens": ["Vor", "ei\u00b7ner", "gr\u00fcn\u00b7ge\u00b7klei\u00b7de\u00b7ten", "Maid"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Blieb ich begeistert stehn.", "tokens": ["Blieb", "ich", "be\u00b7geis\u00b7tert", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie sagte: Ich m\u00f6chte weitergehn.", "tokens": ["Sie", "sag\u00b7te", ":", "Ich", "m\u00f6ch\u00b7te", "wei\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das tat ich.", "tokens": ["Das", "tat", "ich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ob Mann, ob Frau, im gr\u00fcnen Kleid", "tokens": ["Ob", "Mann", ",", "ob", "Frau", ",", "im", "gr\u00fc\u00b7nen", "Kleid"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sind beide stets sympathisch.", "tokens": ["Sind", "bei\u00b7de", "stets", "sym\u00b7pa\u00b7thisch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Im zweiten Fall war ich sehr k\u00fchl,", "tokens": ["Im", "zwei\u00b7ten", "Fall", "war", "ich", "sehr", "k\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Denn ich entscheide nach Gef\u00fchl,", "tokens": ["Denn", "ich", "ent\u00b7schei\u00b7de", "nach", "Ge\u00b7f\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und mit einer Frau mit konkaven", "tokens": ["Und", "mit", "ei\u00b7ner", "Frau", "mit", "kon\u00b7ka\u00b7ven"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Popo", "tokens": ["Po\u00b7po"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Geh ich nun einmal nicht schlafen,", "tokens": ["Geh", "ich", "nun", "ein\u00b7mal", "nicht", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "No, no!", "tokens": ["No", ",", "no", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["FM", "$,", "NE", "$."], "meter": "-+", "measure": "iambic.single"}}}}}