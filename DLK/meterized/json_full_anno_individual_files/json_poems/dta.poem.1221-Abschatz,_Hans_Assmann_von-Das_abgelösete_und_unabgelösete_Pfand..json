{"dta.poem.1221": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Das abgel\u00f6sete und unabgel\u00f6sete  \n Pfand.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Nimphe/ von der zarten Hand", "tokens": ["Nim\u00b7phe", "/", "von", "der", "zar\u00b7ten", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "APPR", "ART", "ADJA", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Wird mir wieder zugesandt/", "tokens": ["Wird", "mir", "wie\u00b7der", "zu\u00b7ge\u00b7sandt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ich mich/ durch Ungel\u00fccke", "tokens": ["Was", "ich", "mich", "/", "durch", "Un\u00b7ge\u00b7l\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "PRF", "$(", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weg zu geben/ schuldig fand.", "tokens": ["Weg", "zu", "ge\u00b7ben", "/", "schul\u00b7dig", "fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$(", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber deiner Augen Blicke", "tokens": ["A\u00b7ber", "dei\u00b7ner", "Au\u00b7gen", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Haben mir noch was entwandt/", "tokens": ["Ha\u00b7ben", "mir", "noch", "was", "ent\u00b7wandt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIS", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Das nicht wieder kehrt zur\u00fccke/", "tokens": ["Das", "nicht", "wie\u00b7der", "kehrt", "zu\u00b7r\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "ADV", "VVFIN", "PTKVZ", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wie di\u00df abgel\u00f6ste Pfand.", "tokens": ["Wie", "di\u00df", "ab\u00b7ge\u00b7l\u00f6s\u00b7te", "Pfand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Deine Tugend/ deine Zier", "tokens": ["Dei\u00b7ne", "Tu\u00b7gend", "/", "dei\u00b7ne", "Zier"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nahm mein Hertz/ und schenckt es dir/", "tokens": ["Nahm", "mein", "Hertz", "/", "und", "schenckt", "es", "dir", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PPER", "PPER", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lie\u00df mich nichts daf\u00fcr empfangen;", "tokens": ["Lie\u00df", "mich", "nichts", "da\u00b7f\u00fcr", "emp\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "PAV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seit es abgereist von hier", "tokens": ["Seit", "es", "ab\u00b7ge\u00b7reist", "von", "hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "APPR", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hats ihm wunderlich gegangen:", "tokens": ["Hats", "ihm", "wun\u00b7der\u00b7lich", "ge\u00b7gan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Es mu\u00df brennen f\u00fcr und f\u00fcr/", "tokens": ["Es", "mu\u00df", "bren\u00b7nen", "f\u00fcr", "und", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "KON", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Tr\u00e4gt doch aber kein Verlangen", "tokens": ["Tr\u00e4gt", "doch", "a\u00b7ber", "kein", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wiederum zu seyn bey mir.", "tokens": ["Wie\u00b7de\u00b7rum", "zu", "seyn", "bey", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKZU", "VAINF", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Nun es bleibe wo es kan!", "tokens": ["Nun", "es", "blei\u00b7be", "wo", "es", "kan", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Findt es sein Vergn\u00fcgen dran/", "tokens": ["Findt", "es", "sein", "Ver\u00b7gn\u00fc\u00b7gen", "dran", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PAV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich will mich nicht widersetzen:", "tokens": ["Ich", "will", "mich", "nicht", "wi\u00b7der\u00b7set\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sch\u00e4tz und Hertzen/ die der Wahn", "tokens": ["Sch\u00e4tz", "und", "Hert\u00b7zen", "/", "die", "der", "Wahn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$(", "PRELS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vor so k\u00f6stlich pflegt zu sch\u00e4tzen/", "tokens": ["Vor", "so", "k\u00f6st\u00b7lich", "pflegt", "zu", "sch\u00e4t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wollen seyn geleget an/", "tokens": ["Wol\u00b7len", "seyn", "ge\u00b7le\u00b7get", "an", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAINF", "VVFIN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn sie anders solln erg\u00f6tzen/", "tokens": ["Wenn", "sie", "an\u00b7ders", "solln", "er\u00b7g\u00f6t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und auff Wucher ausgethan.", "tokens": ["Und", "auff", "Wu\u00b7cher", "aus\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}