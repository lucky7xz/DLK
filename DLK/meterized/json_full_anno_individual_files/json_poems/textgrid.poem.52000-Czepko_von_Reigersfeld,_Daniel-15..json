{"textgrid.poem.52000": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "15.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist mit mir ja schlecht, als wie du siehst, bestallt,", "tokens": ["Es", "ist", "mit", "mir", "ja", "schlecht", ",", "als", "wie", "du", "siehst", ",", "be\u00b7stallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "ADJD", "$,", "KOUS", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil meine G\u00fctter gantz in Staub und Asche liegen,", "tokens": ["Weil", "mei\u00b7ne", "G\u00fct\u00b7ter", "gantz", "in", "Staub", "und", "A\u00b7sche", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch hab ich freyen Muth und kan mich hoch vergn\u00fcgen,", "tokens": ["Doch", "hab", "ich", "frey\u00b7en", "Muth", "und", "kan", "mich", "hoch", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJA", "NN", "KON", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Fama meinen Ruhm auff deutschen Cymbeln schallt.", "tokens": ["Da\u00df", "Fa\u00b7ma", "mei\u00b7nen", "Ruhm", "auff", "deut\u00b7schen", "Cym\u00b7beln", "schallt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Du aber handelst starck: Die Fuhrleut umb und an,", "tokens": ["Du", "a\u00b7ber", "han\u00b7delst", "starck", ":", "Die", "Fuhr\u00b7leut", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKVZ", "$.", "ART", "NN", "APPR", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fchrn deinen Glauben her in Centner schweren S\u00e4cken,", "tokens": ["F\u00fchrn", "dei\u00b7nen", "Glau\u00b7ben", "her", "in", "Cent\u00b7ner", "schwe\u00b7ren", "S\u00e4\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APZR", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Wechsel m\u00fc\u00dfen sich durch gantz Europa strecken,", "tokens": ["Die", "Wech\u00b7sel", "m\u00fc\u00b7\u00dfen", "sich", "durch", "gantz", "Eu\u00b7ro\u00b7pa", "stre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "APPR", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Geld wird Viertel Wei\u00df in seinen Ort gethan.", "tokens": ["Das", "Geld", "wird", "Vier\u00b7tel", "Wei\u00df", "in", "sei\u00b7nen", "Ort", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "NE", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dis bistu: jenes ich: wie treffen wir denn ein,", "tokens": ["Dis", "bis\u00b7tu", ":", "je\u00b7nes", "ich", ":", "wie", "tref\u00b7fen", "wir", "denn", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "PDAT", "PPER", "$.", "PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich sol zu Fu\u00dfe gehn, du f\u00e4hrst mit sch\u00f6nen Pferden,", "tokens": ["Ich", "sol", "zu", "Fu\u00b7\u00dfe", "gehn", ",", "du", "f\u00e4hrst", "mit", "sch\u00f6\u00b7nen", "Pfer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF", "$,", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch glaub es, was ich bin, das kanstu nimmer werden:", "tokens": ["Doch", "glaub", "es", ",", "was", "ich", "bin", ",", "das", "kans\u00b7tu", "nim\u00b7mer", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$,", "PDS", "VMFIN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was du bist, dieses kan mein Knecht und mehr noch seyn.", "tokens": ["Was", "du", "bist", ",", "die\u00b7ses", "kan", "mein", "Knecht", "und", "mehr", "noch", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "PDS", "VMFIN", "PPOSAT", "NN", "KON", "ADV", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Es ist mit mir ja schlecht, als wie du siehst, bestallt,", "tokens": ["Es", "ist", "mit", "mir", "ja", "schlecht", ",", "als", "wie", "du", "siehst", ",", "be\u00b7stallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "ADJD", "$,", "KOUS", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil meine G\u00fctter gantz in Staub und Asche liegen,", "tokens": ["Weil", "mei\u00b7ne", "G\u00fct\u00b7ter", "gantz", "in", "Staub", "und", "A\u00b7sche", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch hab ich freyen Muth und kan mich hoch vergn\u00fcgen,", "tokens": ["Doch", "hab", "ich", "frey\u00b7en", "Muth", "und", "kan", "mich", "hoch", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJA", "NN", "KON", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Fama meinen Ruhm auff deutschen Cymbeln schallt.", "tokens": ["Da\u00df", "Fa\u00b7ma", "mei\u00b7nen", "Ruhm", "auff", "deut\u00b7schen", "Cym\u00b7beln", "schallt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Du aber handelst starck: Die Fuhrleut umb und an,", "tokens": ["Du", "a\u00b7ber", "han\u00b7delst", "starck", ":", "Die", "Fuhr\u00b7leut", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKVZ", "$.", "ART", "NN", "APPR", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fchrn deinen Glauben her in Centner schweren S\u00e4cken,", "tokens": ["F\u00fchrn", "dei\u00b7nen", "Glau\u00b7ben", "her", "in", "Cent\u00b7ner", "schwe\u00b7ren", "S\u00e4\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APZR", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Wechsel m\u00fc\u00dfen sich durch gantz Europa strecken,", "tokens": ["Die", "Wech\u00b7sel", "m\u00fc\u00b7\u00dfen", "sich", "durch", "gantz", "Eu\u00b7ro\u00b7pa", "stre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "APPR", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Geld wird Viertel Wei\u00df in seinen Ort gethan.", "tokens": ["Das", "Geld", "wird", "Vier\u00b7tel", "Wei\u00df", "in", "sei\u00b7nen", "Ort", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "NE", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Dis bistu: jenes ich: wie treffen wir denn ein,", "tokens": ["Dis", "bis\u00b7tu", ":", "je\u00b7nes", "ich", ":", "wie", "tref\u00b7fen", "wir", "denn", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "PDAT", "PPER", "$.", "PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich sol zu Fu\u00dfe gehn, du f\u00e4hrst mit sch\u00f6nen Pferden,", "tokens": ["Ich", "sol", "zu", "Fu\u00b7\u00dfe", "gehn", ",", "du", "f\u00e4hrst", "mit", "sch\u00f6\u00b7nen", "Pfer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF", "$,", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch glaub es, was ich bin, das kanstu nimmer werden:", "tokens": ["Doch", "glaub", "es", ",", "was", "ich", "bin", ",", "das", "kans\u00b7tu", "nim\u00b7mer", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$,", "PDS", "VMFIN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was du bist, dieses kan mein Knecht und mehr noch seyn.", "tokens": ["Was", "du", "bist", ",", "die\u00b7ses", "kan", "mein", "Knecht", "und", "mehr", "noch", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "PDS", "VMFIN", "PPOSAT", "NN", "KON", "ADV", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}