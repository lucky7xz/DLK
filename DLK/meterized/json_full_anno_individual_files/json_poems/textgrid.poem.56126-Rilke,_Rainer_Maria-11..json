{"textgrid.poem.56126": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "11.", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sieh den Himmel. Hei\u00dft kein Sternbild \u203aReiter\u2039?", "tokens": ["Sieh", "den", "Him\u00b7mel", ".", "Hei\u00dft", "kein", "Stern\u00b7bild", "\u203a", "Rei\u00b7ter", "\u2039", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "ART", "NN", "$.", "VVFIN", "PIAT", "NN", "$(", "NE", "$(", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Denn dies ist uns seltsam eingepr\u00e4gt:", "tokens": ["Denn", "dies", "ist", "uns", "selt\u00b7sam", "ein\u00b7ge\u00b7pr\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "dieser Stolz aus Erde. Und ein Zweiter,", "tokens": ["die\u00b7ser", "Stolz", "aus", "Er\u00b7de", ".", "Und", "ein", "Zwei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "NN", "$.", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "der ihn treibt und h\u00e4lt und den er tragt.", "tokens": ["der", "ihn", "treibt", "und", "h\u00e4lt", "und", "den", "er", "tragt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "VVFIN", "KON", "ART", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Ist nicht so, gejagt und dann geb\u00e4ndigt,", "tokens": ["Ist", "nicht", "so", ",", "ge\u00b7jagt", "und", "dann", "ge\u00b7b\u00e4n\u00b7digt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "$,", "VVPP", "KON", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "diese sehnige Natur des Seins?", "tokens": ["die\u00b7se", "seh\u00b7ni\u00b7ge", "Na\u00b7tur", "des", "Seins", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Weg und Wendung. Doch ein Druck verst\u00e4ndigt.", "tokens": ["Weg", "und", "Wen\u00b7dung", ".", "Doch", "ein", "Druck", "ver\u00b7st\u00e4n\u00b7digt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "KON", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Neue Weite. Und die zwei sind eins.", "tokens": ["Neu\u00b7e", "Wei\u00b7te", ".", "Und", "die", "zwei", "sind", "eins", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "KON", "ART", "CARD", "VAFIN", "PIS", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Aber ", "tokens": ["A\u00b7ber"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "nicht den Weg, den sie zusammen tun?", "tokens": ["nicht", "den", "Weg", ",", "den", "sie", "zu\u00b7sam\u00b7men", "tun", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Namenlos schon trennt sie Tisch und Weide.", "tokens": ["Na\u00b7men\u00b7los", "schon", "trennt", "sie", "Tisch", "und", "Wei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Auch die sternische Verbindung tr\u00fcgt.", "tokens": ["Auch", "die", "ster\u00b7ni\u00b7sche", "Ver\u00b7bin\u00b7dung", "tr\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Doch uns freue eine Weile nun", "tokens": ["Doch", "uns", "freu\u00b7e", "ei\u00b7ne", "Wei\u00b7le", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "der Figur zu glauben. Das gen\u00fcgt.", "tokens": ["der", "Fi\u00b7gur", "zu", "glau\u00b7ben", ".", "Das", "ge\u00b7n\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$.", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Sieh den Himmel. Hei\u00dft kein Sternbild \u203aReiter\u2039?", "tokens": ["Sieh", "den", "Him\u00b7mel", ".", "Hei\u00dft", "kein", "Stern\u00b7bild", "\u203a", "Rei\u00b7ter", "\u2039", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "ART", "NN", "$.", "VVFIN", "PIAT", "NN", "$(", "NE", "$(", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Denn dies ist uns seltsam eingepr\u00e4gt:", "tokens": ["Denn", "dies", "ist", "uns", "selt\u00b7sam", "ein\u00b7ge\u00b7pr\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "dieser Stolz aus Erde. Und ein Zweiter,", "tokens": ["die\u00b7ser", "Stolz", "aus", "Er\u00b7de", ".", "Und", "ein", "Zwei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "NN", "$.", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "der ihn treibt und h\u00e4lt und den er tragt.", "tokens": ["der", "ihn", "treibt", "und", "h\u00e4lt", "und", "den", "er", "tragt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "VVFIN", "KON", "ART", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Ist nicht so, gejagt und dann geb\u00e4ndigt,", "tokens": ["Ist", "nicht", "so", ",", "ge\u00b7jagt", "und", "dann", "ge\u00b7b\u00e4n\u00b7digt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "$,", "VVPP", "KON", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "diese sehnige Natur des Seins?", "tokens": ["die\u00b7se", "seh\u00b7ni\u00b7ge", "Na\u00b7tur", "des", "Seins", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Weg und Wendung. Doch ein Druck verst\u00e4ndigt.", "tokens": ["Weg", "und", "Wen\u00b7dung", ".", "Doch", "ein", "Druck", "ver\u00b7st\u00e4n\u00b7digt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "KON", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Neue Weite. Und die zwei sind eins.", "tokens": ["Neu\u00b7e", "Wei\u00b7te", ".", "Und", "die", "zwei", "sind", "eins", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "KON", "ART", "CARD", "VAFIN", "PIS", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Aber ", "tokens": ["A\u00b7ber"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "nicht den Weg, den sie zusammen tun?", "tokens": ["nicht", "den", "Weg", ",", "den", "sie", "zu\u00b7sam\u00b7men", "tun", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Namenlos schon trennt sie Tisch und Weide.", "tokens": ["Na\u00b7men\u00b7los", "schon", "trennt", "sie", "Tisch", "und", "Wei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Auch die sternische Verbindung tr\u00fcgt.", "tokens": ["Auch", "die", "ster\u00b7ni\u00b7sche", "Ver\u00b7bin\u00b7dung", "tr\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Doch uns freue eine Weile nun", "tokens": ["Doch", "uns", "freu\u00b7e", "ei\u00b7ne", "Wei\u00b7le", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "der Figur zu glauben. Das gen\u00fcgt.", "tokens": ["der", "Fi\u00b7gur", "zu", "glau\u00b7ben", ".", "Das", "ge\u00b7n\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$.", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}