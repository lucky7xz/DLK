{"textgrid.poem.66878": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Berlin, das gro\u00dfe Ungeheuer,", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Berlin, das gro\u00dfe Ungeheuer,", "tokens": ["Ber\u00b7lin", ",", "das", "gro\u00b7\u00dfe", "Un\u00b7ge\u00b7heu\u00b7er", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sperrt auf den Schlund voll Dampf und Feuer,", "tokens": ["Sperrt", "auf", "den", "Schlund", "voll", "Dampf", "und", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Indes es noch sein Futter schlingt,", "tokens": ["In\u00b7des", "es", "noch", "sein", "Fut\u00b7ter", "schlingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schnalzt und singt:", "tokens": ["Und", "schnalzt", "und", "singt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "\u00bbwelch Fra\u00df! Mein Bauch wird immer breiter.", "tokens": ["\u00bb", "welch", "Fra\u00df", "!", "Mein", "Bauch", "wird", "im\u00b7mer", "brei\u00b7ter", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAT", "NN", "$.", "PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Solch fette Mahlzeit stimmt mich heiter.", "tokens": ["Solch", "fet\u00b7te", "Mahl\u00b7zeit", "stimmt", "mich", "hei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Um frische Beute kr\u00fcmmt im Kranz", "tokens": ["Um", "fri\u00b7sche", "Beu\u00b7te", "kr\u00fcmmt", "im", "Kranz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ADJA", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich schon mein Schwanz.", "tokens": ["Sich", "schon", "mein", "Schwanz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "O himmlisch, was ich alles schnappe!", "tokens": ["O", "himm\u00b7lisch", ",", "was", "ich", "al\u00b7les", "schnap\u00b7pe", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "PWS", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Solch Jungfernfleisch ist nicht von Pappe.", "tokens": ["Solch", "Jung\u00b7fern\u00b7fleisch", "ist", "nicht", "von", "Pap\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zehntausend Jungfraun von dem Land \u2013", "tokens": ["Zehn\u00b7tau\u00b7send", "Jung\u00b7fraun", "von", "dem", "Land", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "'s ist Zuckerkand!", "tokens": ["'s", "ist", "Zu\u00b7cker\u00b7kand", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Die Unschuld mundet mir am besten,", "tokens": ["Die", "Un\u00b7schuld", "mun\u00b7det", "mir", "am", "bes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie dient aus dem Effeff zum M\u00e4sten,", "tokens": ["Sie", "dient", "aus", "dem", "E\u00b7ffeff", "zum", "M\u00e4s\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Halbhalb mit einem feisten Faun \u2013", "tokens": ["Halb\u00b7halb", "mit", "ei\u00b7nem", "feis\u00b7ten", "Faun", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "'s schmeckt wie Kapaun.", "tokens": ["'s", "schmeckt", "wie", "Ka\u00b7paun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Mit Wonne kost' ich Kupplerinnen,", "tokens": ["Mit", "Won\u00b7ne", "kost'", "ich", "Kupp\u00b7le\u00b7rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil sie aus Keuschfleisch Gold gewinnen,", "tokens": ["Weil", "sie", "aus", "Keuschfleisch", "Gold", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit Kind und W\u00fcstling gibt's ", "tokens": ["Mit", "Kind", "und", "W\u00fcst\u00b7ling", "gibt's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Schmuck spuck' ich aus.", "tokens": ["Schmuck", "spuck'", "ich", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Ich mu\u00df zwar Talmi fa\u00dfweis schlucken,", "tokens": ["Ich", "mu\u00df", "zwar", "Tal\u00b7mi", "fa\u00df\u00b7weis", "schlu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "FM", "FM", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es geht nicht ", "tokens": ["Es", "geht", "nicht"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Sonst w\u00fcrd' ich bald so d\u00fcnne sein", "tokens": ["Sonst", "w\u00fcrd'", "ich", "bald", "so", "d\u00fcn\u00b7ne", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "VVFIN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie'n Blindschleichlein.", "tokens": ["Wie'n", "Blind\u00b7schleich\u00b7lein", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Heut fra\u00df ich neunundneunzig Schwindler,", "tokens": ["Heut", "fra\u00df", "ich", "neun\u00b7und\u00b7neun\u00b7zig", "Schwind\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Hundertsten gab ich an Spindler", "tokens": ["Den", "Hun\u00b7derts\u00b7ten", "gab", "ich", "an", "Spind\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zum Reinigen \u2013 weil darmverschlingt,", "tokens": ["Zum", "Rei\u00b7ni\u00b7gen", "\u2013", "weil", "darm\u00b7ver\u00b7schlingt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "KOUS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}}, "stanza.8": {"line.1": {"text": "Ein Louis ist 'ne Koryph\u00e4e \u2013", "tokens": ["Ein", "Lou\u00b7is", "ist", "'ne", "Ko\u00b7ry\u00b7ph\u00e4e", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blo\u00df das Ballonm\u00fctzlein schmeckt z\u00e4he \u2013", "tokens": ["Blo\u00df", "das", "Bal\u00b7lon\u00b7m\u00fctz\u00b7lein", "schmeckt", "z\u00e4\u00b7he", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "VVFIN", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und schleppt er Meuchelopfer mit:", "tokens": ["Und", "schleppt", "er", "Meu\u00b7chel\u00b7op\u00b7fer", "mit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bon Appetit!!", "tokens": ["Bon", "Ap\u00b7pe\u00b7tit", "!!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "J\u00fcngst blieb zu meinem argen Schrecken", "tokens": ["J\u00fcngst", "blieb", "zu", "mei\u00b7nem", "ar\u00b7gen", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Spitzel schier im Hals mir stecken,", "tokens": ["Ein", "Spit\u00b7zel", "schier", "im", "Hals", "mir", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das roch nach Schmiere, ", "tokens": ["Das", "roch", "nach", "Schmie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Welch Hochgenu\u00df! ...", "tokens": ["Welch", "Hoch\u00b7ge\u00b7nu\u00df", "!", "..."], "token_info": ["word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Ich bin ein internationaler", "tokens": ["Ich", "bin", "ein", "in\u00b7ter\u00b7na\u00b7ti\u00b7o\u00b7na\u00b7ler"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Spreedrach, und zehn Millionen Taler", "tokens": ["Spree\u00b7drach", ",", "und", "zehn", "Mil\u00b7lion\u00b7en", "Ta\u00b7ler"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "CARD", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Weis' ich dem Konkurrenzdrach an,", "tokens": ["Weis'", "ich", "dem", "Kon\u00b7kur\u00b7renz\u00b7drach", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der so viel kann!\u00ab", "tokens": ["Der", "so", "viel", "kann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADV", "VMFIN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.11": {"line.1": {"text": "Berlin, das gro\u00dfe Ungeheuer,", "tokens": ["Ber\u00b7lin", ",", "das", "gro\u00b7\u00dfe", "Un\u00b7ge\u00b7heu\u00b7er", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sperrt auf den Schlund voll Dampf und Feuer,", "tokens": ["Sperrt", "auf", "den", "Schlund", "voll", "Dampf", "und", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Indes es noch sein Futter schlingt,", "tokens": ["In\u00b7des", "es", "noch", "sein", "Fut\u00b7ter", "schlingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schnalzt und singt:", "tokens": ["Und", "schnalzt", "und", "singt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "\u00bbwelch Fra\u00df! Mein Bauch wird immer breiter.", "tokens": ["\u00bb", "welch", "Fra\u00df", "!", "Mein", "Bauch", "wird", "im\u00b7mer", "brei\u00b7ter", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAT", "NN", "$.", "PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Solch fette Mahlzeit stimmt mich heiter.", "tokens": ["Solch", "fet\u00b7te", "Mahl\u00b7zeit", "stimmt", "mich", "hei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Um frische Beute kr\u00fcmmt im Kranz", "tokens": ["Um", "fri\u00b7sche", "Beu\u00b7te", "kr\u00fcmmt", "im", "Kranz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ADJA", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich schon mein Schwanz.", "tokens": ["Sich", "schon", "mein", "Schwanz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.13": {"line.1": {"text": "O himmlisch, was ich alles schnappe!", "tokens": ["O", "himm\u00b7lisch", ",", "was", "ich", "al\u00b7les", "schnap\u00b7pe", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "PWS", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Solch Jungfernfleisch ist nicht von Pappe.", "tokens": ["Solch", "Jung\u00b7fern\u00b7fleisch", "ist", "nicht", "von", "Pap\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zehntausend Jungfraun von dem Land \u2013", "tokens": ["Zehn\u00b7tau\u00b7send", "Jung\u00b7fraun", "von", "dem", "Land", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "'s ist Zuckerkand!", "tokens": ["'s", "ist", "Zu\u00b7cker\u00b7kand", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Die Unschuld mundet mir am besten,", "tokens": ["Die", "Un\u00b7schuld", "mun\u00b7det", "mir", "am", "bes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie dient aus dem Effeff zum M\u00e4sten,", "tokens": ["Sie", "dient", "aus", "dem", "E\u00b7ffeff", "zum", "M\u00e4s\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Halbhalb mit einem feisten Faun \u2013", "tokens": ["Halb\u00b7halb", "mit", "ei\u00b7nem", "feis\u00b7ten", "Faun", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "'s schmeckt wie Kapaun.", "tokens": ["'s", "schmeckt", "wie", "Ka\u00b7paun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.15": {"line.1": {"text": "Mit Wonne kost' ich Kupplerinnen,", "tokens": ["Mit", "Won\u00b7ne", "kost'", "ich", "Kupp\u00b7le\u00b7rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil sie aus Keuschfleisch Gold gewinnen,", "tokens": ["Weil", "sie", "aus", "Keuschfleisch", "Gold", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit Kind und W\u00fcstling gibt's ", "tokens": ["Mit", "Kind", "und", "W\u00fcst\u00b7ling", "gibt's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Schmuck spuck' ich aus.", "tokens": ["Schmuck", "spuck'", "ich", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.16": {"line.1": {"text": "Ich mu\u00df zwar Talmi fa\u00dfweis schlucken,", "tokens": ["Ich", "mu\u00df", "zwar", "Tal\u00b7mi", "fa\u00df\u00b7weis", "schlu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "FM", "FM", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es geht nicht ", "tokens": ["Es", "geht", "nicht"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Sonst w\u00fcrd' ich bald so d\u00fcnne sein", "tokens": ["Sonst", "w\u00fcrd'", "ich", "bald", "so", "d\u00fcn\u00b7ne", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "VVFIN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie'n Blindschleichlein.", "tokens": ["Wie'n", "Blind\u00b7schleich\u00b7lein", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.17": {"line.1": {"text": "Heut fra\u00df ich neunundneunzig Schwindler,", "tokens": ["Heut", "fra\u00df", "ich", "neun\u00b7und\u00b7neun\u00b7zig", "Schwind\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Hundertsten gab ich an Spindler", "tokens": ["Den", "Hun\u00b7derts\u00b7ten", "gab", "ich", "an", "Spind\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zum Reinigen \u2013 weil darmverschlingt,", "tokens": ["Zum", "Rei\u00b7ni\u00b7gen", "\u2013", "weil", "darm\u00b7ver\u00b7schlingt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "KOUS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}}, "stanza.18": {"line.1": {"text": "Ein Louis ist 'ne Koryph\u00e4e \u2013", "tokens": ["Ein", "Lou\u00b7is", "ist", "'ne", "Ko\u00b7ry\u00b7ph\u00e4e", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blo\u00df das Ballonm\u00fctzlein schmeckt z\u00e4he \u2013", "tokens": ["Blo\u00df", "das", "Bal\u00b7lon\u00b7m\u00fctz\u00b7lein", "schmeckt", "z\u00e4\u00b7he", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "VVFIN", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und schleppt er Meuchelopfer mit:", "tokens": ["Und", "schleppt", "er", "Meu\u00b7chel\u00b7op\u00b7fer", "mit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bon Appetit!!", "tokens": ["Bon", "Ap\u00b7pe\u00b7tit", "!!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.19": {"line.1": {"text": "J\u00fcngst blieb zu meinem argen Schrecken", "tokens": ["J\u00fcngst", "blieb", "zu", "mei\u00b7nem", "ar\u00b7gen", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Spitzel schier im Hals mir stecken,", "tokens": ["Ein", "Spit\u00b7zel", "schier", "im", "Hals", "mir", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das roch nach Schmiere, ", "tokens": ["Das", "roch", "nach", "Schmie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Welch Hochgenu\u00df! ...", "tokens": ["Welch", "Hoch\u00b7ge\u00b7nu\u00df", "!", "..."], "token_info": ["word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.20": {"line.1": {"text": "Ich bin ein internationaler", "tokens": ["Ich", "bin", "ein", "in\u00b7ter\u00b7na\u00b7ti\u00b7o\u00b7na\u00b7ler"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Spreedrach, und zehn Millionen Taler", "tokens": ["Spree\u00b7drach", ",", "und", "zehn", "Mil\u00b7lion\u00b7en", "Ta\u00b7ler"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "CARD", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Weis' ich dem Konkurrenzdrach an,", "tokens": ["Weis'", "ich", "dem", "Kon\u00b7kur\u00b7renz\u00b7drach", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der so viel kann!\u00ab", "tokens": ["Der", "so", "viel", "kann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADV", "VMFIN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}}}}}