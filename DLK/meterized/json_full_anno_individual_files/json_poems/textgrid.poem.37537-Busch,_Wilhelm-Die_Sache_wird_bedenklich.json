{"textgrid.poem.37537": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Die Sache wird bedenklich", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.85", "da:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sokrates, der alte Greis,", "tokens": ["Sok\u00b7ra\u00b7tes", ",", "der", "al\u00b7te", "Greis", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagte oft in tiefen Sorgen:", "tokens": ["Sag\u00b7te", "oft", "in", "tie\u00b7fen", "Sor\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbach, wie viel ist doch verborgen,", "tokens": ["\u00bb", "ach", ",", "wie", "viel", "ist", "doch", "ver\u00b7bor\u00b7gen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PWAV", "PIS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was man immer noch nicht wei\u00df.\u00ab", "tokens": ["Was", "man", "im\u00b7mer", "noch", "nicht", "wei\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "PTKNEG", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und so ist es. \u2013 Doch indessen", "tokens": ["Und", "so", "ist", "es", ".", "\u2013", "Doch", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "$.", "$(", "KON", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Darf man eines nicht vergessen:", "tokens": ["Darf", "man", "ei\u00b7nes", "nicht", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eines wei\u00df man doch hienieden,", "tokens": ["Ei\u00b7nes", "wei\u00df", "man", "doch", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "N\u00e4mlich, wenn man unzufrieden. \u2013", "tokens": ["N\u00e4m\u00b7lich", ",", "wenn", "man", "un\u00b7zu\u00b7frie\u00b7den", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "ADJD", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Dies ist auch Tobias Knopp,", "tokens": ["Dies", "ist", "auch", "To\u00b7bias", "Knopp", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und er \u00e4rgert sich darob.", "tokens": ["Und", "er", "\u00e4r\u00b7gert", "sich", "da\u00b7rob", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Seine zwei Kanarienv\u00f6gel", "tokens": ["Sei\u00b7ne", "zwei", "Ka\u00b7na\u00b7ri\u00b7en\u00b7v\u00f6\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "CARD", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Die sind immer froh und kregel,", "tokens": ["Die", "sind", "im\u00b7mer", "froh", "und", "kre\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend ihn so manches qu\u00e4lt,", "tokens": ["W\u00e4h\u00b7rend", "ihn", "so", "man\u00b7ches", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil es ihm bis dato fehlt.", "tokens": ["Weil", "es", "ihm", "bis", "da\u00b7to", "fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Ja, die Zeit entfliehet schnell;", "tokens": ["Ja", ",", "die", "Zeit", "ent\u00b7flie\u00b7het", "schnell", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Knopp, du bist noch Junggesell! \u2013", "tokens": ["Knopp", ",", "du", "bist", "noch", "Jung\u00b7ge\u00b7sell", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar f\u00fcr Stiefel, Bett, Kaffee", "tokens": ["Zwar", "f\u00fcr", "Stie\u00b7fel", ",", "Bett", ",", "Kaf\u00b7fee"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sorgt die gute Dorothee;", "tokens": ["Sorgt", "die", "gu\u00b7te", "Do\u00b7ro\u00b7thee", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und auch, wenn er dann und wann", "tokens": ["Und", "auch", ",", "wenn", "er", "dann", "und", "wann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "ADV", "KON", "PWAV"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Etwas nicht alleine kann,", "tokens": ["Et\u00b7was", "nicht", "al\u00b7lei\u00b7ne", "kann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ist sie gleich darauf bedacht,", "tokens": ["Ist", "sie", "gleich", "da\u00b7rauf", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PAV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie es zurechte macht.", "tokens": ["Da\u00df", "sie", "es", "zu\u00b7rech\u00b7te", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch ihm fehlt Zufriedenheit. \u2013", "tokens": ["Doch", "ihm", "fehlt", "Zu\u00b7frie\u00b7den\u00b7heit", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur mit gro\u00dfer Traurigkeit", "tokens": ["Nur", "mit", "gro\u00b7\u00dfer", "Trau\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Bleibt er vor dem Spiegel stehn,", "tokens": ["Bleibt", "er", "vor", "dem", "Spie\u00b7gel", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Um sein Bildnis zu besehn.", "tokens": ["Um", "sein", "Bild\u00b7nis", "zu", "be\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vornerum ist alles blank;", "tokens": ["Vor\u00b7ne\u00b7rum", "ist", "al\u00b7les", "blank", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber hinten, gottseidank,", "tokens": ["A\u00b7ber", "hin\u00b7ten", ",", "gott\u00b7sei\u00b7dank", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADJD", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Denkt er sich mit frohem Hoffen,", "tokens": ["Denkt", "er", "sich", "mit", "fro\u00b7hem", "Hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird noch manches angetroffen.", "tokens": ["Wird", "noch", "man\u00b7ches", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Oh, wie ist der Schreck so gro\u00df!", "tokens": ["Oh", ",", "wie", "ist", "der", "Schreck", "so", "gro\u00df", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinten ist erst recht nichts los;", "tokens": ["Hin\u00b7ten", "ist", "erst", "recht", "nichts", "los", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und auch hier tritt ohne Frage", "tokens": ["Und", "auch", "hier", "tritt", "oh\u00b7ne", "Fra\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur der pure Kopf zutage. \u2013", "tokens": ["Nur", "der", "pu\u00b7re", "Kopf", "zu\u00b7ta\u00b7ge", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Auch bemerkt er au\u00dferdem,", "tokens": ["Auch", "be\u00b7merkt", "er", "au\u00b7\u00dfer\u00b7dem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ihm gar nicht recht bequem,", "tokens": ["Was", "ihm", "gar", "nicht", "recht", "be\u00b7quem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er um des Leibes Mitten", "tokens": ["Da\u00df", "er", "um", "des", "Lei\u00b7bes", "Mit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4ngst die W\u00f6lbung \u00fcberschritten,", "tokens": ["L\u00e4ngst", "die", "W\u00f6l\u00b7bung", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche f\u00fcr den Speiseschlauch,", "tokens": ["Wel\u00b7che", "f\u00fcr", "den", "Spei\u00b7se\u00b7schlauch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bei nat\u00fcrlichem Gebrauch,", "tokens": ["Bei", "na\u00b7t\u00fcr\u00b7li\u00b7chem", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wie zum Trinken, so zum Essen,", "tokens": ["Wie", "zum", "Trin\u00b7ken", ",", "so", "zum", "Es\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Festgesetzt und abgemessen. \u2013", "tokens": ["Fest\u00b7ge\u00b7setzt", "und", "ab\u00b7ge\u00b7mes\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Doch es bietet die Natur", "tokens": ["Doch", "es", "bie\u00b7tet", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Hierf\u00fcr eine sanfte Kur.", "tokens": ["Hier\u00b7f\u00fcr", "ei\u00b7ne", "sanf\u00b7te", "Kur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Drau\u00dfen, wo die Blumen sprie\u00dfen,", "tokens": ["Drau\u00b7\u00dfen", ",", "wo", "die", "Blu\u00b7men", "sprie\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Karrelsbader Salz genie\u00dfen", "tokens": ["Kar\u00b7rels\u00b7ba\u00b7der", "Salz", "ge\u00b7nie\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Und melodisch sich bewegen,", "tokens": ["Und", "me\u00b7lo\u00b7disch", "sich", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Ist ein rechter Himmelssegen;", "tokens": ["Ist", "ein", "rech\u00b7ter", "Him\u00b7mels\u00b7se\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Und es steigert noch die Lust,", "tokens": ["Und", "es", "stei\u00b7gert", "noch", "die", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Wenn man immer sagt: du mu\u00dft.", "tokens": ["Wenn", "man", "im\u00b7mer", "sagt", ":", "du", "mu\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVFIN", "$.", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Knopp, der sich dazu entschlossen,", "tokens": ["Knopp", ",", "der", "sich", "da\u00b7zu", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PRF", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wandelt treu und unverdrossen.", "tokens": ["Wan\u00b7delt", "treu", "und", "un\u00b7ver\u00b7dros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Manchmal bleibt er sinnend stehn,", "tokens": ["Manch\u00b7mal", "bleibt", "er", "sin\u00b7nend", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Manchmal kann ihn keiner sehn.", "tokens": ["Manch\u00b7mal", "kann", "ihn", "kei\u00b7ner", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Aber bald so geht er wieder", "tokens": ["A\u00b7ber", "bald", "so", "geht", "er", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Treubeflissen auf und nieder. \u2013", "tokens": ["Treu\u00b7be\u00b7flis\u00b7sen", "auf", "und", "nie\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKVZ", "KON", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Dieses treibt er vierzehn Tage;", "tokens": ["Die\u00b7ses", "treibt", "er", "vier\u00b7zehn", "Ta\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Darnach steigt er auf die Waage,", "tokens": ["Dar\u00b7nach", "steigt", "er", "auf", "die", "Waa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und da wird es freudig kund:", "tokens": ["Und", "da", "wird", "es", "freu\u00b7dig", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hei\u00dfa, minus zwanzig Pfund!", "tokens": ["Hei\u00b7\u00dfa", ",", "mi\u00b7nus", "zwan\u00b7zig", "Pfund", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "XY", "CARD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wieder schwinden vierzehn Tage,", "tokens": ["Wie\u00b7der", "schwin\u00b7den", "vier\u00b7zehn", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder sitzt er auf der Waage,", "tokens": ["Wie\u00b7der", "sitzt", "er", "auf", "der", "Waa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Autsch, nun ist ja offenbar", "tokens": ["Autsch", ",", "nun", "ist", "ja", "of\u00b7fen\u00b7bar"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Alles wieder, wie es war.", "tokens": ["Al\u00b7les", "wie\u00b7der", ",", "wie", "es", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ach, so denkt er, diese Welt", "tokens": ["Ach", ",", "so", "denkt", "er", ",", "die\u00b7se", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "$,", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat doch viel, was nicht gef\u00e4llt.", "tokens": ["Hat", "doch", "viel", ",", "was", "nicht", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "$,", "PRELS", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rosen, Tanten, Basen, Nelken", "tokens": ["Ro\u00b7sen", ",", "Tan\u00b7ten", ",", "Ba\u00b7sen", ",", "Nel\u00b7ken"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind gen\u00f6tigt zu verwelken;", "tokens": ["Sind", "ge\u00b7n\u00f6\u00b7tigt", "zu", "ver\u00b7wel\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach \u2013 und endlich auch durch mich", "tokens": ["Ach", "\u2013", "und", "end\u00b7lich", "auch", "durch", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$(", "KON", "ADV", "ADV", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht man einen dicken Strich.", "tokens": ["Macht", "man", "ei\u00b7nen", "di\u00b7cken", "Strich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Auch von mir wird man es lesen:", "tokens": ["Auch", "von", "mir", "wird", "man", "es", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VAFIN", "PIS", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Knopp war da und ist gewesen.", "tokens": ["Knopp", "war", "da", "und", "ist", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "KON", "VAFIN", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ach, und keine Tr\u00e4ne flie\u00dft", "tokens": ["Ach", ",", "und", "kei\u00b7ne", "Tr\u00e4\u00b7ne", "flie\u00dft"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KON", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Aus dem Auge, was es liest;", "tokens": ["Aus", "dem", "Au\u00b7ge", ",", "was", "es", "liest", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Keiner wird, wenn ich begraben,", "tokens": ["Kei\u00b7ner", "wird", ",", "wenn", "ich", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Unbequemlichkeiten haben;", "tokens": ["Un\u00b7be\u00b7quem\u00b7lich\u00b7kei\u00b7ten", "ha\u00b7ben", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Keine Seele wird geniert,", "tokens": ["Kei\u00b7ne", "See\u00b7le", "wird", "ge\u00b7niert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Weil man keinen Kummer sp\u00fcrt.", "tokens": ["Weil", "man", "kei\u00b7nen", "Kum\u00b7mer", "sp\u00fcrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Dahingegen spricht man dann:", "tokens": ["Da\u00b7hin\u00b7ge\u00b7gen", "spricht", "man", "dann", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Was geht dieser Knopp uns an?", "tokens": ["Was", "geht", "die\u00b7ser", "Knopp", "uns", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDAT", "NN", "PPER", "PTKVZ", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.18": {"line.1": {"text": "Dies mag aber Knopp nicht leiden.", "tokens": ["Dies", "mag", "a\u00b7ber", "Knopp", "nicht", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NN", "PTKNEG", "VVINF", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Beim Gedanken, so zu scheiden", "tokens": ["Beim", "Ge\u00b7dan\u00b7ken", ",", "so", "zu", "schei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In ein unverziertes Grab,", "tokens": ["In", "ein", "un\u00b7ver\u00b7zier\u00b7tes", "Grab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dr\u00fcckt er eine Tr\u00e4ne ab.", "tokens": ["Dr\u00fcckt", "er", "ei\u00b7ne", "Tr\u00e4\u00b7ne", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Sie liegt da, wo er gesessen,", "tokens": ["Sie", "liegt", "da", ",", "wo", "er", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Seinem Schmerze angemessen.", "tokens": ["Sei\u00b7nem", "Schmer\u00b7ze", "an\u00b7ge\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Dieses ist ja f\u00fcrchterlich.", "tokens": ["Die\u00b7ses", "ist", "ja", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Also, Knopp, verm\u00e4hle dich.", "tokens": ["Al\u00b7so", ",", "Knopp", ",", "ver\u00b7m\u00e4h\u00b7le", "dich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mach dich auf und sieh dich um,", "tokens": ["Mach", "dich", "auf", "und", "sieh", "dich", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVIMP", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Reise mal 'n bissel rum.", "tokens": ["Rei\u00b7se", "mal", "'n", "bis\u00b7sel", "rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NE", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sieh mal dies und sieh mal das,", "tokens": ["Sieh", "mal", "dies", "und", "sieh", "mal", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PDS", "KON", "VVIMP", "ADV", "PDS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und pa\u00df auf, du findest was.", "tokens": ["Und", "pa\u00df", "auf", ",", "du", "fin\u00b7dest", "was", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PTKVZ", "$,", "PPER", "VVFIN", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Einfach ist f\u00fcr seine Zwecke", "tokens": ["Ein\u00b7fach", "ist", "f\u00fcr", "sei\u00b7ne", "Zwe\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das ben\u00f6tigte Gep\u00e4cke;", "tokens": ["Das", "be\u00b7n\u00f6\u00b7tig\u00b7te", "Ge\u00b7p\u00e4\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Und die brave Dorothee", "tokens": ["Und", "die", "bra\u00b7ve", "Do\u00b7ro\u00b7thee"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Ruft: \u00bbHerr Knopp, nanu adjeh!\u00ab", "tokens": ["Ruft", ":", "\u00bb", "Herr", "Knopp", ",", "na\u00b7nu", "ad\u00b7jeh", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "NN", "NE", "$,", "ITJ", "ITJ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Sokrates, der alte Greis,", "tokens": ["Sok\u00b7ra\u00b7tes", ",", "der", "al\u00b7te", "Greis", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagte oft in tiefen Sorgen:", "tokens": ["Sag\u00b7te", "oft", "in", "tie\u00b7fen", "Sor\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbach, wie viel ist doch verborgen,", "tokens": ["\u00bb", "ach", ",", "wie", "viel", "ist", "doch", "ver\u00b7bor\u00b7gen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PWAV", "PIS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was man immer noch nicht wei\u00df.\u00ab", "tokens": ["Was", "man", "im\u00b7mer", "noch", "nicht", "wei\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "PTKNEG", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Und so ist es. \u2013 Doch indessen", "tokens": ["Und", "so", "ist", "es", ".", "\u2013", "Doch", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "$.", "$(", "KON", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Darf man eines nicht vergessen:", "tokens": ["Darf", "man", "ei\u00b7nes", "nicht", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eines wei\u00df man doch hienieden,", "tokens": ["Ei\u00b7nes", "wei\u00df", "man", "doch", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "N\u00e4mlich, wenn man unzufrieden. \u2013", "tokens": ["N\u00e4m\u00b7lich", ",", "wenn", "man", "un\u00b7zu\u00b7frie\u00b7den", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "ADJD", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Dies ist auch Tobias Knopp,", "tokens": ["Dies", "ist", "auch", "To\u00b7bias", "Knopp", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und er \u00e4rgert sich darob.", "tokens": ["Und", "er", "\u00e4r\u00b7gert", "sich", "da\u00b7rob", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Seine zwei Kanarienv\u00f6gel", "tokens": ["Sei\u00b7ne", "zwei", "Ka\u00b7na\u00b7ri\u00b7en\u00b7v\u00f6\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "CARD", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Die sind immer froh und kregel,", "tokens": ["Die", "sind", "im\u00b7mer", "froh", "und", "kre\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend ihn so manches qu\u00e4lt,", "tokens": ["W\u00e4h\u00b7rend", "ihn", "so", "man\u00b7ches", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil es ihm bis dato fehlt.", "tokens": ["Weil", "es", "ihm", "bis", "da\u00b7to", "fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.27": {"line.1": {"text": "Ja, die Zeit entfliehet schnell;", "tokens": ["Ja", ",", "die", "Zeit", "ent\u00b7flie\u00b7het", "schnell", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Knopp, du bist noch Junggesell! \u2013", "tokens": ["Knopp", ",", "du", "bist", "noch", "Jung\u00b7ge\u00b7sell", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Zwar f\u00fcr Stiefel, Bett, Kaffee", "tokens": ["Zwar", "f\u00fcr", "Stie\u00b7fel", ",", "Bett", ",", "Kaf\u00b7fee"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sorgt die gute Dorothee;", "tokens": ["Sorgt", "die", "gu\u00b7te", "Do\u00b7ro\u00b7thee", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und auch, wenn er dann und wann", "tokens": ["Und", "auch", ",", "wenn", "er", "dann", "und", "wann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "ADV", "KON", "PWAV"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Etwas nicht alleine kann,", "tokens": ["Et\u00b7was", "nicht", "al\u00b7lei\u00b7ne", "kann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Ist sie gleich darauf bedacht,", "tokens": ["Ist", "sie", "gleich", "da\u00b7rauf", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PAV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie es zurechte macht.", "tokens": ["Da\u00df", "sie", "es", "zu\u00b7rech\u00b7te", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch ihm fehlt Zufriedenheit. \u2013", "tokens": ["Doch", "ihm", "fehlt", "Zu\u00b7frie\u00b7den\u00b7heit", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur mit gro\u00dfer Traurigkeit", "tokens": ["Nur", "mit", "gro\u00b7\u00dfer", "Trau\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Bleibt er vor dem Spiegel stehn,", "tokens": ["Bleibt", "er", "vor", "dem", "Spie\u00b7gel", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Um sein Bildnis zu besehn.", "tokens": ["Um", "sein", "Bild\u00b7nis", "zu", "be\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vornerum ist alles blank;", "tokens": ["Vor\u00b7ne\u00b7rum", "ist", "al\u00b7les", "blank", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber hinten, gottseidank,", "tokens": ["A\u00b7ber", "hin\u00b7ten", ",", "gott\u00b7sei\u00b7dank", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADJD", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Denkt er sich mit frohem Hoffen,", "tokens": ["Denkt", "er", "sich", "mit", "fro\u00b7hem", "Hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird noch manches angetroffen.", "tokens": ["Wird", "noch", "man\u00b7ches", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Oh, wie ist der Schreck so gro\u00df!", "tokens": ["Oh", ",", "wie", "ist", "der", "Schreck", "so", "gro\u00df", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinten ist erst recht nichts los;", "tokens": ["Hin\u00b7ten", "ist", "erst", "recht", "nichts", "los", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und auch hier tritt ohne Frage", "tokens": ["Und", "auch", "hier", "tritt", "oh\u00b7ne", "Fra\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur der pure Kopf zutage. \u2013", "tokens": ["Nur", "der", "pu\u00b7re", "Kopf", "zu\u00b7ta\u00b7ge", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Auch bemerkt er au\u00dferdem,", "tokens": ["Auch", "be\u00b7merkt", "er", "au\u00b7\u00dfer\u00b7dem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ihm gar nicht recht bequem,", "tokens": ["Was", "ihm", "gar", "nicht", "recht", "be\u00b7quem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er um des Leibes Mitten", "tokens": ["Da\u00df", "er", "um", "des", "Lei\u00b7bes", "Mit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4ngst die W\u00f6lbung \u00fcberschritten,", "tokens": ["L\u00e4ngst", "die", "W\u00f6l\u00b7bung", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche f\u00fcr den Speiseschlauch,", "tokens": ["Wel\u00b7che", "f\u00fcr", "den", "Spei\u00b7se\u00b7schlauch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bei nat\u00fcrlichem Gebrauch,", "tokens": ["Bei", "na\u00b7t\u00fcr\u00b7li\u00b7chem", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wie zum Trinken, so zum Essen,", "tokens": ["Wie", "zum", "Trin\u00b7ken", ",", "so", "zum", "Es\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Festgesetzt und abgemessen. \u2013", "tokens": ["Fest\u00b7ge\u00b7setzt", "und", "ab\u00b7ge\u00b7mes\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Doch es bietet die Natur", "tokens": ["Doch", "es", "bie\u00b7tet", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Hierf\u00fcr eine sanfte Kur.", "tokens": ["Hier\u00b7f\u00fcr", "ei\u00b7ne", "sanf\u00b7te", "Kur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Drau\u00dfen, wo die Blumen sprie\u00dfen,", "tokens": ["Drau\u00b7\u00dfen", ",", "wo", "die", "Blu\u00b7men", "sprie\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Karrelsbader Salz genie\u00dfen", "tokens": ["Kar\u00b7rels\u00b7ba\u00b7der", "Salz", "ge\u00b7nie\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Und melodisch sich bewegen,", "tokens": ["Und", "me\u00b7lo\u00b7disch", "sich", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Ist ein rechter Himmelssegen;", "tokens": ["Ist", "ein", "rech\u00b7ter", "Him\u00b7mels\u00b7se\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Und es steigert noch die Lust,", "tokens": ["Und", "es", "stei\u00b7gert", "noch", "die", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Wenn man immer sagt: du mu\u00dft.", "tokens": ["Wenn", "man", "im\u00b7mer", "sagt", ":", "du", "mu\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVFIN", "$.", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Knopp, der sich dazu entschlossen,", "tokens": ["Knopp", ",", "der", "sich", "da\u00b7zu", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PRF", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Wandelt treu und unverdrossen.", "tokens": ["Wan\u00b7delt", "treu", "und", "un\u00b7ver\u00b7dros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Manchmal bleibt er sinnend stehn,", "tokens": ["Manch\u00b7mal", "bleibt", "er", "sin\u00b7nend", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Manchmal kann ihn keiner sehn.", "tokens": ["Manch\u00b7mal", "kann", "ihn", "kei\u00b7ner", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Aber bald so geht er wieder", "tokens": ["A\u00b7ber", "bald", "so", "geht", "er", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Treubeflissen auf und nieder. \u2013", "tokens": ["Treu\u00b7be\u00b7flis\u00b7sen", "auf", "und", "nie\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKVZ", "KON", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Dieses treibt er vierzehn Tage;", "tokens": ["Die\u00b7ses", "treibt", "er", "vier\u00b7zehn", "Ta\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Darnach steigt er auf die Waage,", "tokens": ["Dar\u00b7nach", "steigt", "er", "auf", "die", "Waa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und da wird es freudig kund:", "tokens": ["Und", "da", "wird", "es", "freu\u00b7dig", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hei\u00dfa, minus zwanzig Pfund!", "tokens": ["Hei\u00b7\u00dfa", ",", "mi\u00b7nus", "zwan\u00b7zig", "Pfund", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "XY", "CARD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wieder schwinden vierzehn Tage,", "tokens": ["Wie\u00b7der", "schwin\u00b7den", "vier\u00b7zehn", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder sitzt er auf der Waage,", "tokens": ["Wie\u00b7der", "sitzt", "er", "auf", "der", "Waa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Autsch, nun ist ja offenbar", "tokens": ["Autsch", ",", "nun", "ist", "ja", "of\u00b7fen\u00b7bar"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Alles wieder, wie es war.", "tokens": ["Al\u00b7les", "wie\u00b7der", ",", "wie", "es", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Ach, so denkt er, diese Welt", "tokens": ["Ach", ",", "so", "denkt", "er", ",", "die\u00b7se", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "$,", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat doch viel, was nicht gef\u00e4llt.", "tokens": ["Hat", "doch", "viel", ",", "was", "nicht", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "$,", "PRELS", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rosen, Tanten, Basen, Nelken", "tokens": ["Ro\u00b7sen", ",", "Tan\u00b7ten", ",", "Ba\u00b7sen", ",", "Nel\u00b7ken"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind gen\u00f6tigt zu verwelken;", "tokens": ["Sind", "ge\u00b7n\u00f6\u00b7tigt", "zu", "ver\u00b7wel\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach \u2013 und endlich auch durch mich", "tokens": ["Ach", "\u2013", "und", "end\u00b7lich", "auch", "durch", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$(", "KON", "ADV", "ADV", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht man einen dicken Strich.", "tokens": ["Macht", "man", "ei\u00b7nen", "di\u00b7cken", "Strich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Auch von mir wird man es lesen:", "tokens": ["Auch", "von", "mir", "wird", "man", "es", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VAFIN", "PIS", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Knopp war da und ist gewesen.", "tokens": ["Knopp", "war", "da", "und", "ist", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "KON", "VAFIN", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ach, und keine Tr\u00e4ne flie\u00dft", "tokens": ["Ach", ",", "und", "kei\u00b7ne", "Tr\u00e4\u00b7ne", "flie\u00dft"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KON", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Aus dem Auge, was es liest;", "tokens": ["Aus", "dem", "Au\u00b7ge", ",", "was", "es", "liest", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Keiner wird, wenn ich begraben,", "tokens": ["Kei\u00b7ner", "wird", ",", "wenn", "ich", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Unbequemlichkeiten haben;", "tokens": ["Un\u00b7be\u00b7quem\u00b7lich\u00b7kei\u00b7ten", "ha\u00b7ben", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Keine Seele wird geniert,", "tokens": ["Kei\u00b7ne", "See\u00b7le", "wird", "ge\u00b7niert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Weil man keinen Kummer sp\u00fcrt.", "tokens": ["Weil", "man", "kei\u00b7nen", "Kum\u00b7mer", "sp\u00fcrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Dahingegen spricht man dann:", "tokens": ["Da\u00b7hin\u00b7ge\u00b7gen", "spricht", "man", "dann", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Was geht dieser Knopp uns an?", "tokens": ["Was", "geht", "die\u00b7ser", "Knopp", "uns", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDAT", "NN", "PPER", "PTKVZ", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.40": {"line.1": {"text": "Dies mag aber Knopp nicht leiden.", "tokens": ["Dies", "mag", "a\u00b7ber", "Knopp", "nicht", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NN", "PTKNEG", "VVINF", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Beim Gedanken, so zu scheiden", "tokens": ["Beim", "Ge\u00b7dan\u00b7ken", ",", "so", "zu", "schei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In ein unverziertes Grab,", "tokens": ["In", "ein", "un\u00b7ver\u00b7zier\u00b7tes", "Grab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dr\u00fcckt er eine Tr\u00e4ne ab.", "tokens": ["Dr\u00fcckt", "er", "ei\u00b7ne", "Tr\u00e4\u00b7ne", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Sie liegt da, wo er gesessen,", "tokens": ["Sie", "liegt", "da", ",", "wo", "er", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Seinem Schmerze angemessen.", "tokens": ["Sei\u00b7nem", "Schmer\u00b7ze", "an\u00b7ge\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Dieses ist ja f\u00fcrchterlich.", "tokens": ["Die\u00b7ses", "ist", "ja", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Also, Knopp, verm\u00e4hle dich.", "tokens": ["Al\u00b7so", ",", "Knopp", ",", "ver\u00b7m\u00e4h\u00b7le", "dich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mach dich auf und sieh dich um,", "tokens": ["Mach", "dich", "auf", "und", "sieh", "dich", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVIMP", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Reise mal 'n bissel rum.", "tokens": ["Rei\u00b7se", "mal", "'n", "bis\u00b7sel", "rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NE", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sieh mal dies und sieh mal das,", "tokens": ["Sieh", "mal", "dies", "und", "sieh", "mal", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PDS", "KON", "VVIMP", "ADV", "PDS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und pa\u00df auf, du findest was.", "tokens": ["Und", "pa\u00df", "auf", ",", "du", "fin\u00b7dest", "was", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PTKVZ", "$,", "PPER", "VVFIN", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Einfach ist f\u00fcr seine Zwecke", "tokens": ["Ein\u00b7fach", "ist", "f\u00fcr", "sei\u00b7ne", "Zwe\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das ben\u00f6tigte Gep\u00e4cke;", "tokens": ["Das", "be\u00b7n\u00f6\u00b7tig\u00b7te", "Ge\u00b7p\u00e4\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Und die brave Dorothee", "tokens": ["Und", "die", "bra\u00b7ve", "Do\u00b7ro\u00b7thee"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Ruft: \u00bbHerr Knopp, nanu adjeh!\u00ab", "tokens": ["Ruft", ":", "\u00bb", "Herr", "Knopp", ",", "na\u00b7nu", "ad\u00b7jeh", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "NN", "NE", "$,", "ITJ", "ITJ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}