{"textgrid.poem.36307": {"metadata": {"author": {"name": "Schlegel, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbder ist zu schwer, der andre f\u00e4llt ins Leichte,", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbder ist zu schwer, der andre f\u00e4llt ins Leichte,", "tokens": ["\u00bb", "der", "ist", "zu", "schwer", ",", "der", "and\u00b7re", "f\u00e4llt", "ins", "Leich\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "VAFIN", "PTKA", "ADJD", "$,", "PRELS", "PIS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den strengen Ernst hier m\u00fc\u00dfte man noch w\u00fcrzen,", "tokens": ["Den", "stren\u00b7gen", "Ernst", "hier", "m\u00fc\u00df\u00b7te", "man", "noch", "w\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Anmut F\u00fclle dort sodann verk\u00fcrzen,", "tokens": ["Der", "An\u00b7mut", "F\u00fcl\u00b7le", "dort", "so\u00b7dann", "ver\u00b7k\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bald ist der Grund zu tief und bald zu seichte.\u00ab", "tokens": ["Bald", "ist", "der", "Grund", "zu", "tief", "und", "bald", "zu", "seich\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKA", "ADJD", "KON", "ADV", "PTKZU", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So steht die Kunst dem Ideal zur Beichte,", "tokens": ["So", "steht", "die", "Kunst", "dem", "I\u00b7deal", "zur", "Beich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und kann den Knoten nie ganz richtig sch\u00fcrzen;", "tokens": ["Und", "kann", "den", "Kno\u00b7ten", "nie", "ganz", "rich\u00b7tig", "sch\u00fcr\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es mu\u00df der Mensch auf eine Seite st\u00fcrzen,", "tokens": ["Es", "mu\u00df", "der", "Mensch", "auf", "ei\u00b7ne", "Sei\u00b7te", "st\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie flei\u00dfig er sich auch zur Bildung zeigte.", "tokens": ["Wie", "flei\u00b7\u00dfig", "er", "sich", "auch", "zur", "Bil\u00b7dung", "zeig\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "In jeder Kunst, im Leben, ja im Wissen,", "tokens": ["In", "je\u00b7der", "Kunst", ",", "im", "Le\u00b7ben", ",", "ja", "im", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPRART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist auch das Beste falsch, die ferne Scheibe", "tokens": ["Ist", "auch", "das", "Bes\u00b7te", "falsch", ",", "die", "fer\u00b7ne", "Schei\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Scheint unerreicht die Sch\u00fctzen nur zu \u00e4ffen;", "tokens": ["Scheint", "un\u00b7er\u00b7reicht", "die", "Sch\u00fct\u00b7zen", "nur", "zu", "\u00e4f\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wir k\u00f6nnen nicht heraus aus unserm Leibe,", "tokens": ["Wir", "k\u00f6n\u00b7nen", "nicht", "he\u00b7raus", "aus", "un\u00b7serm", "Lei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "An allen wird der Kenner etwas missen,", "tokens": ["An", "al\u00b7len", "wird", "der", "Ken\u00b7ner", "et\u00b7was", "mis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und einer kann den kleinen Punkt nur treffen.", "tokens": ["Und", "ei\u00b7ner", "kann", "den", "klei\u00b7nen", "Punkt", "nur", "tref\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Nur das Ganze, mein Freund, wie es lebt und im Leben sich spiegelt;", "tokens": ["Nur", "das", "Gan\u00b7ze", ",", "mein", "Freund", ",", "wie", "es", "lebt", "und", "im", "Le\u00b7ben", "sich", "spie\u00b7gelt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VVFIN", "KON", "APPRART", "NN", "PRF", "VVFIN", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Das sei dein Ideal, frei von der Formel Gespenst.", "tokens": ["Das", "sei", "dein", "I\u00b7deal", ",", "frei", "von", "der", "For\u00b7mel", "Ge\u00b7spenst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00bbder ist zu schwer, der andre f\u00e4llt ins Leichte,", "tokens": ["\u00bb", "der", "ist", "zu", "schwer", ",", "der", "and\u00b7re", "f\u00e4llt", "ins", "Leich\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "VAFIN", "PTKA", "ADJD", "$,", "PRELS", "PIS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den strengen Ernst hier m\u00fc\u00dfte man noch w\u00fcrzen,", "tokens": ["Den", "stren\u00b7gen", "Ernst", "hier", "m\u00fc\u00df\u00b7te", "man", "noch", "w\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Anmut F\u00fclle dort sodann verk\u00fcrzen,", "tokens": ["Der", "An\u00b7mut", "F\u00fcl\u00b7le", "dort", "so\u00b7dann", "ver\u00b7k\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bald ist der Grund zu tief und bald zu seichte.\u00ab", "tokens": ["Bald", "ist", "der", "Grund", "zu", "tief", "und", "bald", "zu", "seich\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKA", "ADJD", "KON", "ADV", "PTKZU", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "So steht die Kunst dem Ideal zur Beichte,", "tokens": ["So", "steht", "die", "Kunst", "dem", "I\u00b7deal", "zur", "Beich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und kann den Knoten nie ganz richtig sch\u00fcrzen;", "tokens": ["Und", "kann", "den", "Kno\u00b7ten", "nie", "ganz", "rich\u00b7tig", "sch\u00fcr\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es mu\u00df der Mensch auf eine Seite st\u00fcrzen,", "tokens": ["Es", "mu\u00df", "der", "Mensch", "auf", "ei\u00b7ne", "Sei\u00b7te", "st\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie flei\u00dfig er sich auch zur Bildung zeigte.", "tokens": ["Wie", "flei\u00b7\u00dfig", "er", "sich", "auch", "zur", "Bil\u00b7dung", "zeig\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "In jeder Kunst, im Leben, ja im Wissen,", "tokens": ["In", "je\u00b7der", "Kunst", ",", "im", "Le\u00b7ben", ",", "ja", "im", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPRART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist auch das Beste falsch, die ferne Scheibe", "tokens": ["Ist", "auch", "das", "Bes\u00b7te", "falsch", ",", "die", "fer\u00b7ne", "Schei\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Scheint unerreicht die Sch\u00fctzen nur zu \u00e4ffen;", "tokens": ["Scheint", "un\u00b7er\u00b7reicht", "die", "Sch\u00fct\u00b7zen", "nur", "zu", "\u00e4f\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Wir k\u00f6nnen nicht heraus aus unserm Leibe,", "tokens": ["Wir", "k\u00f6n\u00b7nen", "nicht", "he\u00b7raus", "aus", "un\u00b7serm", "Lei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "An allen wird der Kenner etwas missen,", "tokens": ["An", "al\u00b7len", "wird", "der", "Ken\u00b7ner", "et\u00b7was", "mis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und einer kann den kleinen Punkt nur treffen.", "tokens": ["Und", "ei\u00b7ner", "kann", "den", "klei\u00b7nen", "Punkt", "nur", "tref\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Nur das Ganze, mein Freund, wie es lebt und im Leben sich spiegelt;", "tokens": ["Nur", "das", "Gan\u00b7ze", ",", "mein", "Freund", ",", "wie", "es", "lebt", "und", "im", "Le\u00b7ben", "sich", "spie\u00b7gelt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VVFIN", "KON", "APPRART", "NN", "PRF", "VVFIN", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Das sei dein Ideal, frei von der Formel Gespenst.", "tokens": ["Das", "sei", "dein", "I\u00b7deal", ",", "frei", "von", "der", "For\u00b7mel", "Ge\u00b7spenst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$,", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}}}}