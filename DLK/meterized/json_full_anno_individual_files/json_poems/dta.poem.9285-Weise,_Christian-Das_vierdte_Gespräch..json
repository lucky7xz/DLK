{"dta.poem.9285": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das vierdte Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Jst di\u00df nicht wunderlich/", "tokens": ["Ist", "di\u00df", "nicht", "wun\u00b7der\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das gl\u00fccke setzt an mich", "tokens": ["Das", "gl\u00fc\u00b7cke", "setzt", "an", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als w\u00e4r mirs noch so sehr gewogen:", "tokens": ["Als", "w\u00e4r", "mirs", "noch", "so", "sehr", "ge\u00b7wo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NE", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jedoch wenn ich das ziel", "tokens": ["Je\u00b7doch", "wenn", "ich", "das", "ziel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Mit ernst anhalten will", "tokens": ["Mit", "ernst", "an\u00b7hal\u00b7ten", "will"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "So find ich mich gar weit betrogen/", "tokens": ["So", "find", "ich", "mich", "gar", "weit", "be\u00b7tro\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Weil ihre zunge gleichsam spricht;", "tokens": ["Weil", "ih\u00b7re", "zun\u00b7ge", "gleich\u00b7sam", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du siehst mich zwar. Doch du bek\u00f6mmst mich nicht.", "tokens": ["Du", "siehst", "mich", "zwar", ".", "Doch", "du", "be\u00b7k\u00f6mmst", "mich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "2. Es ist ja wol geschehn/", "tokens": ["Es", "ist", "ja", "wol", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ich habe dich gesehn", "tokens": ["Ich", "ha\u00b7be", "dich", "ge\u00b7sehn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und sonderlich in acht genommen:", "tokens": ["Und", "son\u00b7der\u00b7lich", "in", "acht", "ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "CARD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch was vor einen lohn", "tokens": ["Doch", "was", "vor", "ei\u00b7nen", "lohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Hab ich nunmehr davon", "tokens": ["Hab", "ich", "nun\u00b7mehr", "da\u00b7von"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PAV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wo denck ich weiter fortzukommen/", "tokens": ["Wo", "denck", "ich", "wei\u00b7ter", "fort\u00b7zu\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVIMP", "PPER", "ADV", "VVIZU", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wofern ich dich du s\u00fcsser Pol", "tokens": ["Wo\u00b7fern", "ich", "dich", "du", "s\u00fcs\u00b7ser", "Pol"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Jm hertzen und in augen haben soll.", "tokens": ["Jm", "hert\u00b7zen", "und", "in", "au\u00b7gen", "ha\u00b7ben", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "3. Die G\u00f6tter werden zwar", "tokens": ["Die", "G\u00f6t\u00b7ter", "wer\u00b7den", "zwar"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Uns selten offenbar/", "tokens": ["Uns", "sel\u00b7ten", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ob sie gleich unsre seufftzer h\u00f6ren:", "tokens": ["Ob", "sie", "gleich", "uns\u00b7re", "seufft\u00b7zer", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wer gleich in der that", "tokens": ["Und", "wer", "gleich", "in", "der", "that"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "APPR", "ART", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie gantz zu freunden hat/", "tokens": ["Sie", "gantz", "zu", "freun\u00b7den", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Der kan sie niemals sichtbar ehren.", "tokens": ["Der", "kan", "sie", "nie\u00b7mals", "sicht\u00b7bar", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Denn ein gemeines angesicht", "tokens": ["Denn", "ein", "ge\u00b7mei\u00b7nes", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ertr\u00e4gt den glantz und ihre sch\u00f6nheit nicht.", "tokens": ["Er\u00b7tr\u00e4gt", "den", "glantz", "und", "ih\u00b7re", "sch\u00f6n\u00b7heit", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "4. Doch h\u00e4tt ich hier gedacht/", "tokens": ["Doch", "h\u00e4tt", "ich", "hier", "ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ich w\u00fcrde deinen pracht", "tokens": ["Ich", "w\u00fcr\u00b7de", "dei\u00b7nen", "pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In sch\u00f6ner gegenwart geniessen:", "tokens": ["In", "sch\u00f6\u00b7ner", "ge\u00b7gen\u00b7wart", "ge\u00b7nies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das gl\u00fccke zeigte sich/", "tokens": ["Das", "gl\u00fc\u00b7cke", "zeig\u00b7te", "sich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nun aber denckstu mich", "tokens": ["Nun", "a\u00b7ber", "dencks\u00b7tu", "mich"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Nur allzeit weiter auszuschliessen:", "tokens": ["Nur", "all\u00b7zeit", "wei\u00b7ter", "aus\u00b7zu\u00b7schlies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Derhalben mustu nach dem schein/", "tokens": ["Der\u00b7hal\u00b7ben", "mus\u00b7tu", "nach", "dem", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein himmels-kind und eine G\u00f6ttin seyn.", "tokens": ["Ein", "him\u00b7mels\u00b7kind", "und", "ei\u00b7ne", "G\u00f6t\u00b7tin", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "5. Astr\u00e4a meine zier/", "tokens": ["A\u00b7str\u00e4a", "mei\u00b7ne", "zier", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Komm und verzeihe mir/", "tokens": ["Komm", "und", "ver\u00b7zei\u00b7he", "mir", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "PPER", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Da\u00df ich mich dieses unterstanden.", "tokens": ["Da\u00df", "ich", "mich", "die\u00b7ses", "un\u00b7ter\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PDAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wilstu vers\u00f6hnet seyn/", "tokens": ["Wils\u00b7tu", "ver\u00b7s\u00f6h\u00b7net", "seyn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVPP", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So ist bey mir allein", "tokens": ["So", "ist", "bey", "mir", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ein unverf\u00e4lschtes hertz verhanden.", "tokens": ["Ein", "un\u00b7ver\u00b7f\u00e4lschtes", "hertz", "ver\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Wo di\u00df die schuld verb\u00fcssen kan/", "tokens": ["Wo", "di\u00df", "die", "schuld", "ver\u00b7b\u00fcs\u00b7sen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "ART", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So nimm es gantz zum gnaden-opffer an.", "tokens": ["So", "nimm", "es", "gantz", "zum", "gna\u00b7den\u00b7opf\u00b7fer", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}