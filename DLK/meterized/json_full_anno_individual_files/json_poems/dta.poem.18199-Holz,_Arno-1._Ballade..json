{"dta.poem.18199": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1.  \n  Ballade.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1886", "urn": "urn:nbn:de:kobv:b4-200905192665", "language": ["de:0.99"], "booktitle": "Holz, Arno: Das Buch der Zeit. Lieder eines Modernen. Z\u00fcrich, 1886."}, "poem": {"stanza.1": {"line.1": {"text": "Vom heilgen Hain zu Singapur?", "tokens": ["Vom", "heil\u00b7gen", "Hain", "zu", "Sin\u00b7ga\u00b7pur", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort sitzt ein alter Eremit", "tokens": ["Dort", "sitzt", "ein", "al\u00b7ter", "E\u00b7re\u00b7mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kaut an seiner Nabelschnur.", "tokens": ["Und", "kaut", "an", "sei\u00b7ner", "Na\u00b7bel\u00b7schnur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Er kaut tagaus, er kaut tagein", "tokens": ["Er", "kaut", "ta\u00b7gaus", ",", "er", "kaut", "ta\u00b7gein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und n\u00e4hrt sich k\u00e4rglich nur und knapp,", "tokens": ["Und", "n\u00e4hrt", "sich", "k\u00e4rg\u00b7lich", "nur", "und", "knapp", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn ach, er ist ein gro\u00dfes Schwein", "tokens": ["Denn", "ach", ",", "er", "ist", "ein", "gro\u00b7\u00dfes", "Schwein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nie fault ihm sein Luder ab.", "tokens": ["Und", "nie", "fault", "ihm", "sein", "Lu\u00b7der", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Rings um ihn wie das liebe Vieh", "tokens": ["Rings", "um", "ihn", "wie", "das", "lie\u00b7be", "Vieh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4lzt sich zerknirscht ganz Singapur", "tokens": ["W\u00e4lzt", "sich", "zer\u00b7knirscht", "ganz", "Sin\u00b7ga\u00b7pur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u201eGott erhalte\u201c singen sie", "tokens": ["Und", "\u201e", "Gott", "er\u00b7hal\u00b7te", "\u201c", "sin\u00b7gen", "sie"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$(", "NN", "VVFIN", "$(", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201enoch lange seine Nabelschnur!\u201c", "tokens": ["\u201e", "noch", "lan\u00b7ge", "sei\u00b7ne", "Na\u00b7bel\u00b7schnur", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn also geht im Volk die M\u00e4hr", "tokens": ["Denn", "al\u00b7so", "geht", "im", "Volk", "die", "M\u00e4hr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und also lehrt auch dies Gedicht:", "tokens": ["Und", "al\u00b7so", "lehrt", "auch", "dies", "Ge\u00b7dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PDS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn jene Nabelschnur nicht w\u00e4r,", "tokens": ["Wenn", "je\u00b7ne", "Na\u00b7bel\u00b7schnur", "nicht", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "PTKNEG", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dann w\u00e4r auch manches Andre nicht.", "tokens": ["Dann", "w\u00e4r", "auch", "man\u00b7ches", "And\u00b7re", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PIS", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Dann h\u00e4tte beispielsweise Lingg", "tokens": ["Dann", "h\u00e4t\u00b7te", "bei\u00b7spiels\u00b7wei\u00b7se", "Lingg"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nie v\u00f6lkerwandernd sich verrannt", "tokens": ["Nie", "v\u00f6l\u00b7ker\u00b7wan\u00b7dernd", "sich", "ver\u00b7rannt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PRF", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Wagners Nibelungenring", "tokens": ["Und", "Wag\u00b7ners", "Ni\u00b7be\u00b7lun\u00b7gen\u00b7ring"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4g noch vergn\u00fcgt im Pfefferland.", "tokens": ["L\u00e4g", "noch", "ver\u00b7gn\u00fcgt", "im", "Pfef\u00b7fer\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Uns h\u00e4tte nie Professor Dahn", "tokens": ["Uns", "h\u00e4t\u00b7te", "nie", "Pro\u00b7fes\u00b7sor", "Dahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Urdeutsch dozirt von A bis Z", "tokens": ["Ur\u00b7deutsch", "do\u00b7zirt", "von", "A", "bis", "Z"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVPP", "APPR", "NE", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kein aegyptischer Roman", "tokens": ["Und", "kein", "a\u00b7e\u00b7gypt\u00b7i\u00b7scher", "Ro\u00b7man"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verzierte unser B\u00fccherbrett.", "tokens": ["Ver\u00b7zier\u00b7te", "un\u00b7ser", "B\u00fc\u00b7cher\u00b7brett", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wolffs Heijerleispoeterei,", "tokens": ["Wolffs", "Hei\u00b7jer\u00b7lei\u00b7spo\u00b7e\u00b7te\u00b7rei", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Baumbach w\u00e4r ihr nachgetatscht,", "tokens": ["Kein", "Baum\u00b7bach", "w\u00e4r", "ihr", "nach\u00b7ge\u00b7tatscht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Mirzas Reimklangklingelei", "tokens": ["Und", "Mir\u00b7zas", "Reim\u00b7klang\u00b7klin\u00b7ge\u00b7lei"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dann schl\u00fcge endlich unsrer Zeit", "tokens": ["Dann", "schl\u00fc\u00b7ge", "end\u00b7lich", "uns\u00b7rer", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Herz ans Herz der Poesie,", "tokens": ["Das", "Herz", "ans", "Herz", "der", "Poe\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das R\u00fctli schw\u00fcre seinen Eid", "tokens": ["Das", "R\u00fct\u00b7li", "schw\u00fc\u00b7re", "sei\u00b7nen", "Eid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und unser Tell w\u00e4r das Genie.", "tokens": ["Und", "un\u00b7ser", "Tell", "w\u00e4r", "das", "Ge\u00b7nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "So aber so \u2014 frei, fromm und frisch", "tokens": ["So", "a\u00b7ber", "so", "frei", ",", "fromm", "und", "frisch"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$(", "ADJD", "$,", "ADJD", "KON", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Kaut weiter jener Nimmersatt;", "tokens": ["Kaut", "wei\u00b7ter", "je\u00b7ner", "Nim\u00b7mer\u00b7satt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein eigner Schmeerbauch ist sein Tisch,", "tokens": ["Sein", "eig\u00b7ner", "Schmeer\u00b7bauch", "ist", "sein", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein \u2014 wisch ein Bananenblatt.", "tokens": ["Sein", "wisch", "ein", "Ba\u00b7na\u00b7nen\u00b7blatt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "ADJD", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Und um ihn wie das liebe Vieh", "tokens": ["Und", "um", "ihn", "wie", "das", "lie\u00b7be", "Vieh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUI", "PPER", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4lzt sich zerknirscht ganz Singapur", "tokens": ["W\u00e4lzt", "sich", "zer\u00b7knirscht", "ganz", "Sin\u00b7ga\u00b7pur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u201eGott erhalte\u201c singen sie", "tokens": ["Und", "\u201e", "Gott", "er\u00b7hal\u00b7te", "\u201c", "sin\u00b7gen", "sie"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$(", "NN", "VVFIN", "$(", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201enoch lange seine Nabelschnur!\u201c", "tokens": ["\u201e", "noch", "lan\u00b7ge", "sei\u00b7ne", "Na\u00b7bel\u00b7schnur", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}