{"dta.poem.20798": {"metadata": {"author": {"name": "Candidus, Karl", "birth": "N.A.", "death": "N.A."}, "title": "Canzone   VII .", "genre": "Epos", "period": "N.A.", "pub_year": "1854", "urn": "urn:nbn:de:kobv:b4-20090519783", "language": ["de:0.99"], "booktitle": "Candidus, Karl: Der deutsche Christus. F\u00fcnfzehn Canzonen. Leipzig, 1844."}, "poem": {"stanza.1": {"line.1": {"text": "Freut euch! aus allem Nacht- und Licht-Umsto\u00dfnen", "tokens": ["Freut", "euch", "!", "aus", "al\u00b7lem", "Nacht", "und", "Licht\u00b7Um\u00b7sto\u00df\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "APPR", "PIS", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "R\u00fcckstralet Himmelshuld euch Aufmerksamen.", "tokens": ["R\u00fcck\u00b7stra\u00b7let", "Him\u00b7mels\u00b7huld", "euch", "Auf\u00b7merk\u00b7sa\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Kann euch doch Jegliches zum Mittler werden!", "tokens": ["Kann", "euch", "doch", "Jeg\u00b7li\u00b7ches", "zum", "Mitt\u00b7ler", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und lernt ihr dann begreifen jenen Namen", "tokens": ["Und", "lernt", "ihr", "dann", "be\u00b7grei\u00b7fen", "je\u00b7nen", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "VVINF", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und jenes Bild des freventlich Versto\u00dfnen,", "tokens": ["Und", "je\u00b7nes", "Bild", "des", "fre\u00b7vent\u00b7lich", "Ver\u00b7sto\u00df\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Mitte der Vermittlung ward auf Erden,", "tokens": ["Der", "Mit\u00b7te", "der", "Ver\u00b7mitt\u00b7lung", "ward", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Dann auf den Opferherden", "tokens": ["Dann", "auf", "den", "Op\u00b7fer\u00b7her\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Der Gottesmenschheit flammt auch ", "tokens": ["Der", "Got\u00b7tes\u00b7menschheit", "flammt", "auch"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Dem wird zum Mittler Weltger\u00e4usch, Dem Schweigen,", "tokens": ["Dem", "wird", "zum", "Mitt\u00b7ler", "Welt\u00b7ge\u00b7r\u00e4usch", ",", "Dem", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "NN", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Dem der Gestirne Reigen,", "tokens": ["Dem", "der", "Ge\u00b7stir\u00b7ne", "Rei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Dem irgendwer, Dem Schmerz an einem Grabe,", "tokens": ["Dem", "ir\u00b7gend\u00b7wer", ",", "Dem", "Schmerz", "an", "ei\u00b7nem", "Gra\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und Jenem schauert Heilgef\u00fchlserregung", "tokens": ["Und", "Je\u00b7nem", "schau\u00b7ert", "Heil\u00b7ge\u00b7f\u00fchl\u00b7ser\u00b7re\u00b7gung"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Aus reinen Denkens hoher Selbstbewegung.", "tokens": ["Aus", "rei\u00b7nen", "Den\u00b7kens", "ho\u00b7her", "Selbst\u00b7be\u00b7we\u00b7gung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wo immer ich, mein Heiland, dich mag schauen,", "tokens": ["Wo", "im\u00b7mer", "ich", ",", "mein", "Hei\u00b7land", ",", "dich", "mag", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "$,", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In Schrift und Kunst, in mir und auf der Stra\u00dfen.", "tokens": ["In", "Schrift", "und", "Kunst", ",", "in", "mir", "und", "auf", "der", "Stra\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "PPER", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erscheinst du mir als Flie\u00dfendes und Vieles", "tokens": ["Er\u00b7scheinst", "du", "mir", "als", "Flie\u00b7\u00dfen\u00b7des", "und", "Vie\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und auch als Eins und Vestes gleicherma\u00dfen", "tokens": ["Und", "auch", "als", "Eins", "und", "Ves\u00b7tes", "glei\u00b7cher\u00b7ma\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KOUS", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie Einheit wol in heil'gem M\u00fcnsterbauen", "tokens": ["Wie", "Ein\u00b7heit", "wol", "in", "heil'\u00b7gem", "M\u00fcns\u00b7ter\u00b7bau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Benebst Vielartigkeit des Arbeitspieles.", "tokens": ["Be\u00b7nebst", "Viel\u00b7ar\u00b7tig\u00b7keit", "des", "Ar\u00b7beit\u00b7spie\u00b7les", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "La\u00df Jeden seines Zieles", "tokens": ["La\u00df", "Je\u00b7den", "sei\u00b7nes", "Zie\u00b7les"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Besonderheit, o Herr, stets klarer fassen", "tokens": ["Be\u00b7son\u00b7der\u00b7heit", ",", "o", "Herr", ",", "stets", "kla\u00b7rer", "fas\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "FM", "NN", "$,", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und kr\u00e4ftiger erstreben, auf da\u00df alle", "tokens": ["Und", "kr\u00e4f\u00b7ti\u00b7ger", "er\u00b7stre\u00b7ben", ",", "auf", "da\u00df", "al\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "VVPP", "$,", "APPR", "KOUS", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Werkleute sich im Schwalle", "tokens": ["Wer\u00b7kleu\u00b7te", "sich", "im", "Schwal\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Des Bildens dahin stellen wo sie bassen,", "tokens": ["Des", "Bil\u00b7dens", "da\u00b7hin", "stel\u00b7len", "wo", "sie", "bas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVINF", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und Allen la\u00df im einzeln Thun Bewu\u00dftsein", "tokens": ["Und", "Al\u00b7len", "la\u00df", "im", "ein\u00b7zeln", "Thun", "Be\u00b7wu\u00df\u00b7tsein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "APPRART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Des gro\u00dfen Ganzen stets die h\u00f6chste Lust sein.", "tokens": ["Des", "gro\u00b7\u00dfen", "Gan\u00b7zen", "stets", "die", "h\u00f6chs\u00b7te", "Lust", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Denn nichts und ewig auch die Menschheit kann nicht", "tokens": ["Denn", "nichts", "und", "e\u00b7wig", "auch", "die", "Menschheit", "kann", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "KON", "ADJD", "ADV", "ART", "NN", "VMFIN", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Aus sich heraus, kann im Verh\u00e4ltni\u00df stehen", "tokens": ["Aus", "sich", "he\u00b7raus", ",", "kann", "im", "Ver\u00b7h\u00e4lt\u00b7ni\u00df", "ste\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "PTKVZ", "$,", "VMFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zu nichts das nicht zugleich ihr angeh\u00f6rig,", "tokens": ["Zu", "nichts", "das", "nicht", "zu\u00b7gleich", "ihr", "an\u00b7ge\u00b7h\u00f6\u00b7rig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PDS", "PTKNEG", "ADV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sei's Wollen, F\u00fchlen, Ahnen, sei's Verstehen,", "tokens": ["Sei's", "Wol\u00b7len", ",", "F\u00fch\u00b7len", ",", "Ah\u00b7nen", ",", "sei's", "Ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Selbst dann, wenn sie von Grenzen spricht, selbst dann nicht,", "tokens": ["Selbst", "dann", ",", "wenn", "sie", "von", "Gren\u00b7zen", "spricht", ",", "selbst", "dann", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,", "ADV", "ADV", "PTKNEG", "$,"], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und Gott trennt man, Natur von Menschheit th\u00f6rig.", "tokens": ["Und", "Gott", "trennt", "man", ",", "Na\u00b7tur", "von", "Menschheit", "th\u00f6\u00b7rig", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "$,", "NN", "APPR", "NN", "ADJD", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Mag s\u00e4uselndes Ger\u00f6hrig", "tokens": ["Mag", "s\u00e4u\u00b7seln\u00b7des", "Ge\u00b7r\u00f6h\u00b7rig"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wol als ein Fremdes anseh'n Strom und Flur sich?", "tokens": ["Wol", "als", "ein", "Frem\u00b7des", "an\u00b7seh'n", "Strom", "und", "Flur", "sich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "ADJA", "NN", "KON", "NN", "PRF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "Horcht ihm! es wird sein Credo euch verk\u00fcnden.", "tokens": ["Horcht", "ihm", "!", "es", "wird", "sein", "Cre\u00b7do", "euch", "ver\u00b7k\u00fcn\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Dem Geiste mu\u00df verb\u00fcnden", "tokens": ["Dem", "Geis\u00b7te", "mu\u00df", "ver\u00b7b\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Als Geist sich alles Sein, und als Natur sich", "tokens": ["Als", "Geist", "sich", "al\u00b7les", "Sein", ",", "und", "als", "Na\u00b7tur", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "PRF", "PIS", "PPOSAT", "$,", "KON", "KOUS", "NN", "PRF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Nat\u00fcrlichem. Du aber, Bild der Reinheit,", "tokens": ["Na\u00b7t\u00fcr\u00b7li\u00b7chem", ".", "Du", "a\u00b7ber", ",", "Bild", "der", "Rein\u00b7heit", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "ADV", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Bist Geist und bist Natur als h\u00f6chste Einheit.", "tokens": ["Bist", "Geist", "und", "bist", "Na\u00b7tur", "als", "h\u00f6chs\u00b7te", "Ein\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "VAFIN", "NN", "KOUS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Du bist das k\u00f6nigliche Allgemeine,", "tokens": ["Du", "bist", "das", "k\u00f6\u00b7nig\u00b7li\u00b7che", "All\u00b7ge\u00b7mei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bist das Unendliche, die ew'ge Freiheit,", "tokens": ["Bist", "das", "Un\u00b7end\u00b7li\u00b7che", ",", "die", "ew'\u00b7ge", "Frei\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bist selbstbewu\u00dftes All, in Gott aussagbar,", "tokens": ["Bist", "selbst\u00b7be\u00b7wu\u00df\u00b7tes", "All", ",", "in", "Gott", "aus\u00b7sag\u00b7bar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$,", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Und dennoch bist du nicht die Einerleiheit,", "tokens": ["Und", "den\u00b7noch", "bist", "du", "nicht", "die", "Ei\u00b7ner\u00b7lei\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nein, das Hocheigenth\u00fcmliche, weil deine", "tokens": ["Nein", ",", "das", "Hoch\u00b7ei\u00b7gent\u00b7h\u00fcm\u00b7li\u00b7che", ",", "weil", "dei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "$,", "KOUS", "PPOSAT"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Freiheit bei Selbstbeschr\u00e4nkung ist erfragbar.", "tokens": ["Frei\u00b7heit", "bei", "Selbst\u00b7be\u00b7schr\u00e4n\u00b7kung", "ist", "er\u00b7frag\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VAFIN", "ADJD", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "Der unser Aller Tag war,", "tokens": ["Der", "un\u00b7ser", "Al\u00b7ler", "Tag", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ist als das fleischgewordne Wort so Alles", "tokens": ["Ist", "als", "das", "fleischge\u00b7word\u00b7ne", "Wort", "so", "Al\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "NN", "ADV", "PIS"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "In Allem wie er Alles ist im ", "tokens": ["In", "Al\u00b7lem", "wie", "er", "Al\u00b7les", "ist", "im"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "KOKOM", "PPER", "PIS", "VAFIN", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Charakterbild, dem reinen,", "tokens": ["Cha\u00b7rak\u00b7ter\u00b7bild", ",", "dem", "rei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Das Eckstein ward des ird'schen Tempelwalles.", "tokens": ["Das", "E\u00b7ckstein", "ward", "des", "ird'\u00b7schen", "Tem\u00b7pel\u00b7wal\u00b7les", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und wir auch, die belebten Steine, fassen", "tokens": ["Und", "wir", "auch", ",", "die", "be\u00b7leb\u00b7ten", "Stei\u00b7ne", ",", "fas\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "ADV", "$,", "ART", "ADJA", "NN", "$,", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "In's Ganze uns nach eignen Gottesma\u00dfen.", "tokens": ["In's", "Gan\u00b7ze", "uns", "nach", "eig\u00b7nen", "Got\u00b7tes\u00b7ma\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "In dir sind alle Bildungen der Gattung", "tokens": ["In", "dir", "sind", "al\u00b7le", "Bil\u00b7dun\u00b7gen", "der", "Gat\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VAFIN", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie sie in Raum und Zeit vertheilt erscheinen.", "tokens": ["Wie", "sie", "in", "Raum", "und", "Zeit", "ver\u00b7theilt", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "KON", "NN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Stets bist, als Einzler, Ganzes du geblieben,", "tokens": ["Stets", "bist", ",", "als", "Einz\u00b7ler", ",", "Gan\u00b7zes", "du", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "NN", "$,", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht zwar als ob du Buntestes vereinen", "tokens": ["Nicht", "zwar", "als", "ob", "du", "Bun\u00b7tes\u00b7tes", "ver\u00b7ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "KOKOM", "KOUS", "PPER", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Im Einzeln m\u00f6chtest, dir in Vollausstattung", "tokens": ["Im", "Ein\u00b7zeln", "m\u00f6ch\u00b7test", ",", "dir", "in", "Vol\u00b7laus\u00b7stat\u00b7tung"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "$,", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Nein, durch dein hohes Lieben", "tokens": ["Nein", ",", "durch", "dein", "ho\u00b7hes", "Lie\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "Wodurch du, was als Einzlem dir nicht reifte,", "tokens": ["Wo\u00b7durch", "du", ",", "was", "als", "Einz\u00b7lem", "dir", "nicht", "reif\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "PRELS", "KOUS", "PIS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "In Andern reif siehst und als dein, aus Gnaden,", "tokens": ["In", "An\u00b7dern", "reif", "siehst", "und", "als", "dein", ",", "aus", "Gna\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJD", "VVFIN", "KON", "KOUS", "PPOSAT", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Der Einzel-Myriaden", "tokens": ["Der", "Ein\u00b7zel\u00b7My\u00b7ri\u00b7a\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Urspr\u00fcngliche Entwickelungsverl\u00e4ufte.", "tokens": ["Ur\u00b7spr\u00fcng\u00b7li\u00b7che", "Ent\u00b7wi\u00b7cke\u00b7lungs\u00b7ver\u00b7l\u00e4uf\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Denn Alle hat der Vater dir gegeben,", "tokens": ["Denn", "Al\u00b7le", "hat", "der", "Va\u00b7ter", "dir", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Da\u00df sie mit dir in Eins vollendet leben.", "tokens": ["Da\u00df", "sie", "mit", "dir", "in", "Eins", "voll\u00b7en\u00b7det", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "APPR", "NN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Es ist das Sch\u00f6ne stets das Allgemeine", "tokens": ["Es", "ist", "das", "Sch\u00f6\u00b7ne", "stets", "das", "All\u00b7ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In hochbestimmter Form. Du aber bist ja", "tokens": ["In", "hoch\u00b7bes\u00b7timm\u00b7ter", "Form", ".", "Du", "a\u00b7ber", "bist", "ja"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "ADV", "VAFIN", "ADV"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Des Sch\u00f6nen voller Inbegriff zu nennen", "tokens": ["Des", "Sch\u00f6\u00b7nen", "vol\u00b7ler", "In\u00b7be\u00b7griff", "zu", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und anders nicht erschaut dich jeder Christ ja.", "tokens": ["Und", "an\u00b7ders", "nicht", "er\u00b7schaut", "dich", "je\u00b7der", "Christ", "ja", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "VVFIN", "PPER", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Zum Musterbild fromm aufblickt die Gemeine", "tokens": ["Zum", "Mus\u00b7ter\u00b7bild", "fromm", "auf\u00b7blickt", "die", "Ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Weil Jedem Sinn und Liebe da entbrennen.", "tokens": ["Weil", "Je\u00b7dem", "Sinn", "und", "Lie\u00b7be", "da", "ent\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "KON", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So mu\u00df er bald erkennen", "tokens": ["So", "mu\u00df", "er", "bald", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "In sich und Andern eigenes Gestalten.", "tokens": ["In", "sich", "und", "An\u00b7dern", "ei\u00b7ge\u00b7nes", "Ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Denn gleichwie in der Kunst so ist im Leben", "tokens": ["Denn", "gleich\u00b7wie", "in", "der", "Kunst", "so", "ist", "im", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KON", "APPR", "ART", "NN", "ADV", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Nie knechtisches Ankleben", "tokens": ["Nie", "knech\u00b7ti\u00b7sches", "An\u00b7kle\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der Nachahmung gedeihliches Entfalten.", "tokens": ["Der", "Nac\u00b7hah\u00b7mung", "ge\u00b7deih\u00b7li\u00b7ches", "Ent\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "An reiner Eigenth\u00fcmlichkeit entz\u00fcnde", "tokens": ["An", "rei\u00b7ner", "Ei\u00b7gent\u00b7h\u00fcm\u00b7lich\u00b7keit", "ent\u00b7z\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sich andere Befreiung von der S\u00fcnde.", "tokens": ["Sich", "an\u00b7de\u00b7re", "Be\u00b7frei\u00b7ung", "von", "der", "S\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wo sich der Gottgesalbte mag erzeigen,", "tokens": ["Wo", "sich", "der", "Gott\u00b7ge\u00b7salb\u00b7te", "mag", "er\u00b7zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil er ja Alles uns in Allem sein mu\u00df,", "tokens": ["Weil", "er", "ja", "Al\u00b7les", "uns", "in", "Al\u00b7lem", "sein", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "PRF", "APPR", "PIS", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In Menschen und vermenschheiteten Dingen,", "tokens": ["In", "Men\u00b7schen", "und", "ver\u00b7menschhei\u00b7te\u00b7ten", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist's das Unendliche das er verleih'n mu\u00df,", "tokens": ["Ist's", "das", "Un\u00b7end\u00b7li\u00b7che", "das", "er", "ver\u00b7leih'n", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+--+---+-+-", "measure": "dactylic.di.plus"}, "line.5": {"text": "Doch endliche Bestimmtheit, neu und eigen,", "tokens": ["Doch", "end\u00b7li\u00b7che", "Be\u00b7stimm\u00b7theit", ",", "neu", "und", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mu\u00df er nicht minder, wo er aufstralt, bringen.", "tokens": ["Mu\u00df", "er", "nicht", "min\u00b7der", ",", "wo", "er", "auf\u00b7stralt", ",", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wo irgend sind die Schwingen", "tokens": ["Wo", "ir\u00b7gend", "sind", "die", "Schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Der Jordanstaube \u00fcber Hochgebilden", "tokens": ["Der", "Jor\u00b7dans\u00b7tau\u00b7be", "\u00fc\u00b7ber", "Hoch\u00b7ge\u00b7bil\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Gespannt, wird Gottes Liebling eigenth\u00fcmlich", "tokens": ["Ge\u00b7spannt", ",", "wird", "Got\u00b7tes", "Lieb\u00b7ling", "ei\u00b7gent\u00b7h\u00fcm\u00b7lich"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "VAFIN", "NN", "NN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Neu sein wie als er r\u00fchmlich", "tokens": ["Neu", "sein", "wie", "als", "er", "r\u00fchm\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VAINF", "KOKOM", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Und wird in Andern Anderes anregen", "tokens": ["Und", "wird", "in", "An\u00b7dern", "An\u00b7de\u00b7res", "an\u00b7re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "PIS", "VVINF"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Und ewig selbst sein jeglich Selbstbewegen.", "tokens": ["Und", "e\u00b7wig", "selbst", "sein", "jeg\u00b7lich", "Selbst\u00b7be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "PPOSAT", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Und V\u00f6lker so wie Einzle werden allzeit,", "tokens": ["Und", "V\u00f6l\u00b7ker", "so", "wie", "Einz\u00b7le", "wer\u00b7den", "all\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "KOKOM", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Wenn selbstbeschr\u00e4nkend Einzles sie erlesen,", "tokens": ["Wenn", "selbst\u00b7be\u00b7schr\u00e4n\u00b7kend", "Einz\u00b7les", "sie", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als Glieder sich des gro\u00dfen Ganzen wissen.", "tokens": ["Als", "Glie\u00b7der", "sich", "des", "gro\u00b7\u00dfen", "Gan\u00b7zen", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Seht da des Sprachthums Heiligkeit und Wesen!", "tokens": ["Seht", "da", "des", "Spracht\u00b7hums", "Hei\u00b7lig\u00b7keit", "und", "We\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Uns vor dem Fluche g\u00e4nzlicher Verfallzeit", "tokens": ["Uns", "vor", "dem", "Flu\u00b7che", "g\u00e4nz\u00b7li\u00b7cher", "Ver\u00b7fall\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zu retten ist das ew'ge Wort beflissen.", "tokens": ["Zu", "ret\u00b7ten", "ist", "das", "ew'\u00b7ge", "Wort", "be\u00b7flis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "O in den Finsternissen", "tokens": ["O", "in", "den", "Fins\u00b7ter\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "Der Jetztwelt haltet fest an solchem Horte!", "tokens": ["Der", "Jetzt\u00b7welt", "hal\u00b7tet", "fest", "an", "sol\u00b7chem", "Hor\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mag mehr und mehr die Gegenwart verrotten", "tokens": ["Mag", "mehr", "und", "mehr", "die", "Ge\u00b7gen\u00b7wart", "ver\u00b7rot\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "KON", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und mag der Fremde spotten,", "tokens": ["Und", "mag", "der", "Frem\u00b7de", "spot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Die deutsche Zukunft bl\u00fcht im deutschen Worte.", "tokens": ["Die", "deut\u00b7sche", "Zu\u00b7kunft", "bl\u00fcht", "im", "deut\u00b7schen", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Hat Luthers Hammer denn schon ausgewuchtet?", "tokens": ["Hat", "Lu\u00b7thers", "Ham\u00b7mer", "denn", "schon", "aus\u00b7ge\u00b7wuch\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Noch hat ja deutscher Geist nicht ausgefruchtet.", "tokens": ["Noch", "hat", "ja", "deut\u00b7scher", "Geist", "nicht", "aus\u00b7ge\u00b7fruch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJA", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Wie spielst du wechselreich und vielgestaltig.", "tokens": ["Wie", "spielst", "du", "wech\u00b7sel\u00b7reich", "und", "viel\u00b7ge\u00b7stal\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "O Herr, allstets derselbe und ein andrer,", "tokens": ["O", "Herr", ",", "alls\u00b7tets", "der\u00b7sel\u00b7be", "und", "ein", "an\u00b7drer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "PDAT", "KON", "ART", "ADJA", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Im Menschen vor mir und im Menschenwerke!", "tokens": ["Im", "Men\u00b7schen", "vor", "mir", "und", "im", "Men\u00b7schen\u00b7wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein erdgebildet hoher Himmelswandrer,", "tokens": ["Ein", "erd\u00b7ge\u00b7bil\u00b7det", "ho\u00b7her", "Him\u00b7mels\u00b7wand\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Als Theil beschr\u00e4nkt, als Ganzes frei-gewaltig,", "tokens": ["Als", "Theil", "be\u00b7schr\u00e4nkt", ",", "als", "Gan\u00b7zes", "frei\u00b7ge\u00b7wal\u00b7tig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "$,", "KOUS", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ein schwaches Rohr stets wie ein Gott der St\u00e4rke!", "tokens": ["Ein", "schwa\u00b7ches", "Rohr", "stets", "wie", "ein", "Gott", "der", "St\u00e4r\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "KOKOM", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Doch wo ich dich vermerke,", "tokens": ["Doch", "wo", "ich", "dich", "ver\u00b7mer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Allmittler! schmilzt mir alles dein Erscheinen", "tokens": ["All\u00b7mitt\u00b7ler", "!", "schmilzt", "mir", "al\u00b7les", "dein", "Er\u00b7schei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "VVFIN", "PPER", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Am liebsten stets in jenes Bild zur\u00fccke,", "tokens": ["Am", "liebs\u00b7ten", "stets", "in", "je\u00b7nes", "Bild", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "ADV", "APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Das wir in Schmerz und Gl\u00fccke", "tokens": ["Das", "wir", "in", "Schmerz", "und", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Am Fu\u00df des Kreuzes dankerf\u00fcllt beweinen.", "tokens": ["Am", "Fu\u00df", "des", "Kreu\u00b7zes", "dan\u00b7ker\u00b7f\u00fcllt", "be\u00b7wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Vom Kreuz auf Golgatha kommt uns das Leben,", "tokens": ["Vom", "Kreuz", "auf", "Gol\u00b7ga\u00b7tha", "kommt", "uns", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Wie mannigfaltig du es mochtest geben.", "tokens": ["Wie", "man\u00b7nig\u00b7fal\u00b7tig", "du", "es", "moch\u00b7test", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Dein Kreuz ist Mittelpunkt uns der Geschichte,", "tokens": ["Dein", "Kreuz", "ist", "Mit\u00b7tel\u00b7punkt", "uns", "der", "Ge\u00b7schich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und jene deine Knechtsgestalt bleibt allen", "tokens": ["Und", "je\u00b7ne", "dei\u00b7ne", "Knechts\u00b7ge\u00b7stalt", "bleibt", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "PPOSAT", "NN", "VVFIN", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zeitaltern ew'ger Huld erh\u00f6htes Zeichen,", "tokens": ["Zei\u00b7tal\u00b7tern", "ew'\u00b7ger", "Huld", "er\u00b7h\u00f6h\u00b7tes", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ob stets neue Namen heilig schallen,", "tokens": ["Und", "ob", "stets", "neu\u00b7e", "Na\u00b7men", "hei\u00b7lig", "schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ADJA", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dein erster ird'scher Name bleibt im Lichte", "tokens": ["Dein", "ers\u00b7ter", "ird'\u00b7scher", "Na\u00b7me", "bleibt", "im", "Lich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bis alle Erdensprachen einst erbleichen.", "tokens": ["Bis", "al\u00b7le", "Er\u00b7den\u00b7spra\u00b7chen", "einst", "er\u00b7blei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Es sind im ganzen reichen", "tokens": ["Es", "sind", "im", "gan\u00b7zen", "rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sprachschatz der Menschheit keinerlei Juwelen", "tokens": ["Sprach\u00b7schatz", "der", "Menschheit", "kei\u00b7ner\u00b7lei", "Ju\u00b7we\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PIAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Bedeutender als diese deines Lebens", "tokens": ["Be\u00b7deu\u00b7ten\u00b7der", "als", "die\u00b7se", "dei\u00b7nes", "Le\u00b7bens"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "PDS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und Todes und Aufstrebens", "tokens": ["Und", "To\u00b7des", "und", "Auf\u00b7stre\u00b7bens"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Bezeugungen an alle Menschenseelen,", "tokens": ["Be\u00b7zeu\u00b7gun\u00b7gen", "an", "al\u00b7le", "Men\u00b7schen\u00b7see\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und, eingefasset in die Sacramente,", "tokens": ["Und", ",", "ein\u00b7ge\u00b7fas\u00b7set", "in", "die", "Sa\u00b7cra\u00b7men\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Sind sie des h\u00f6chsten Styls Grundelemente.", "tokens": ["Sind", "sie", "des", "h\u00f6chs\u00b7ten", "Styls", "Grun\u00b7de\u00b7le\u00b7men\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Vor jenem Kreuze mu\u00df die Erde k\u00fcssen", "tokens": ["Vor", "je\u00b7nem", "Kreu\u00b7ze", "mu\u00df", "die", "Er\u00b7de", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Dagon derer die nach Weisheit fragen,", "tokens": ["Der", "Da\u00b7gon", "de\u00b7rer", "die", "nach", "Weis\u00b7heit", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PDS", "ART", "APPR", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Un\u00e4chter Weisheit, welche nichts mag w\u00fcrzen.", "tokens": ["Un\u00b7\u00e4ch\u00b7ter", "Weis\u00b7heit", ",", "wel\u00b7che", "nichts", "mag", "w\u00fcr\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PIS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vor jener Knechtsgestalt, die wir umklagen,", "tokens": ["Vor", "je\u00b7ner", "Knechts\u00b7ge\u00b7stalt", ",", "die", "wir", "um\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Vor jener herrlichen, erhabnen, m\u00fcssen", "tokens": ["Vor", "je\u00b7ner", "herr\u00b7li\u00b7chen", ",", "er\u00b7hab\u00b7nen", ",", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "PDAT", "ADJA", "$,", "VVFIN", "$,", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In Staub hin alle falschen Heil'gen st\u00fcrzen.", "tokens": ["In", "Staub", "hin", "al\u00b7le", "fal\u00b7schen", "Heil'\u00b7gen", "st\u00fcr\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "In jenem Namen sch\u00fcrzen", "tokens": ["In", "je\u00b7nem", "Na\u00b7men", "sch\u00fcr\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sendboten sich, beseligende Kunde", "tokens": ["Send\u00b7bo\u00b7ten", "sich", ",", "be\u00b7se\u00b7li\u00b7gen\u00b7de", "Kun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PRF", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Zu k\u00fcnden, und versteh'n sich die da glauben.", "tokens": ["Zu", "k\u00fcn\u00b7den", ",", "und", "ver\u00b7steh'n", "sich", "die", "da", "glau\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "KON", "VVFIN", "PRF", "ART", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ein solch Palladium rauben", "tokens": ["Ein", "solch", "Pal\u00b7la\u00b7di\u00b7um", "rau\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "L\u00e4\u00dft sich die Gottmenschheit zu keiner Stunde.", "tokens": ["L\u00e4\u00dft", "sich", "die", "Gott\u00b7menschheit", "zu", "kei\u00b7ner", "Stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.12": {"text": "Wie m\u00f6chte sie? Es thun nur, was sie sollen,", "tokens": ["Wie", "m\u00f6ch\u00b7te", "sie", "?", "Es", "thun", "nur", ",", "was", "sie", "sol\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "$.", "PPER", "VVFIN", "ADV", "$,", "PRELS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Die Glieder, und dem Haubt geb\u00fchrt das Wollen.", "tokens": ["Die", "Glie\u00b7der", ",", "und", "dem", "Haubt", "ge\u00b7b\u00fchrt", "das", "Wol\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Und ist dereinst der letzte Feind bezwungen,", "tokens": ["Und", "ist", "de\u00b7reinst", "der", "letz\u00b7te", "Feind", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn jemals in der Zeit dies ganz gescheh'n soll,", "tokens": ["Wenn", "je\u00b7mals", "in", "der", "Zeit", "dies", "ganz", "ge\u00b7scheh'n", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "PDS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ist der Tod durchaus zu Grund gerichtet,", "tokens": ["Und", "ist", "der", "Tod", "durc\u00b7haus", "zu", "Grund", "ge\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil \u00fcberall der Geist des Grundes weh'n soll,", "tokens": ["Weil", "\u00fc\u00b7be\u00b7rall", "der", "Geist", "des", "Grun\u00b7des", "weh'n", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und ist dein Leben allw\u00e4rts durchgedrungen", "tokens": ["Und", "ist", "dein", "Le\u00b7ben", "all\u00b7w\u00e4rts", "durch\u00b7ge\u00b7drun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und Unform wie Verbildung ganz vernichtet,", "tokens": ["Und", "Un\u00b7form", "wie", "Ver\u00b7bil\u00b7dung", "ganz", "ver\u00b7nich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KOKOM", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und \u00fcberall gelichtet", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "ge\u00b7lich\u00b7tet"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die Aussicht in's Unendliche, da\u00df Alles", "tokens": ["Die", "Aus\u00b7sicht", "in's", "Un\u00b7end\u00b7li\u00b7che", ",", "da\u00df", "Al\u00b7les"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "KOUS", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Gott ist in Allem, Alles Wort der Worte", "tokens": ["Gott", "ist", "in", "Al\u00b7lem", ",", "Al\u00b7les", "Wort", "der", "Wor\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "PIS", "$,", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und Alles Himmelspforte", "tokens": ["Und", "Al\u00b7les", "Him\u00b7mel\u00b7spfor\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "F\u00fcr Alle, wird bis zu des Erdenballes", "tokens": ["F\u00fcr", "Al\u00b7le", ",", "wird", "bis", "zu", "des", "Er\u00b7den\u00b7bal\u00b7les"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "$,", "VAFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Sturz doch der Erdgeist seiner Wiege denken", "tokens": ["Sturz", "doch", "der", "Erd\u00b7geist", "sei\u00b7ner", "Wie\u00b7ge", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "PPOSAT", "NN", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.13": {"text": "Und jenem Kripplein fromme Liebe schenken.", "tokens": ["Und", "je\u00b7nem", "Krip\u00b7plein", "from\u00b7me", "Lie\u00b7be", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Unendlich-Endliches, Wort aller Worte,", "tokens": ["Un\u00b7end\u00b7lich\u00b7End\u00b7li\u00b7ches", ",", "Wort", "al\u00b7ler", "Wor\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "NN", "PIAT", "NN", "$,"], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie andre Welten doch dich m\u00f6gen nennen,", "tokens": ["Wie", "and\u00b7re", "Wel\u00b7ten", "doch", "dich", "m\u00f6\u00b7gen", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Besitzen, f\u00fchlen, wissen und gestalten,", "tokens": ["Be\u00b7sit\u00b7zen", ",", "f\u00fch\u00b7len", ",", "wis\u00b7sen", "und", "ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gedenk' ich oftmals, wenn erfunkelnd brennen", "tokens": ["Ge\u00b7denk'", "ich", "oft\u00b7mals", ",", "wenn", "er\u00b7fun\u00b7kelnd", "bren\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "$,", "KOUS", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Nacht Gestirne. Doch an jedem Orte", "tokens": ["Der", "Nacht", "Ge\u00b7stir\u00b7ne", ".", "Doch", "an", "je\u00b7dem", "Or\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$.", "KON", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ist dir, wie unterschiedlich du magst walten,", "tokens": ["Ist", "dir", ",", "wie", "un\u00b7ter\u00b7schied\u00b7lich", "du", "magst", "wal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "PWAV", "ADJD", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die Selbigkeit erhalten", "tokens": ["Die", "Sel\u00b7big\u00b7keit", "er\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Im Vater, im Unendlichen, im Einen,", "tokens": ["Im", "Va\u00b7ter", ",", "im", "Un\u00b7end\u00b7li\u00b7chen", ",", "im", "Ei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und jauchzend taucht sich in den Hochgedanken", "tokens": ["Und", "jauch\u00b7zend", "taucht", "sich", "in", "den", "Hoch\u00b7ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Mein Herz, da\u00df keine Schranken", "tokens": ["Mein", "Herz", ",", "da\u00df", "kei\u00b7ne", "Schran\u00b7ken"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Gesetzt dem eigenth\u00fcmlichen Erscheinen.", "tokens": ["Ge\u00b7setzt", "dem", "ei\u00b7gent\u00b7h\u00fcm\u00b7li\u00b7chen", "Er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Ja wahrlich, wer nur \u201ef\u00fchlt\u201c! Ein ", "tokens": ["Ja", "wahr\u00b7lich", ",", "wer", "nur", "\u201e", "f\u00fchlt", "\u201c", "!", "Ein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "word"], "pos": ["PTKANT", "ADV", "$,", "PWS", "ADV", "$(", "VVFIN", "$(", "$.", "ART"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.13": {"text": "Mir \u201eNamen\u201c, ", "tokens": ["Mir", "\u201e", "Na\u00b7men", "\u201c", ","], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["NE", "$(", "NN", "$(", "$,"], "meter": "-+-", "measure": "amphibrach.single"}}}}}