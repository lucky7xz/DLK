{"textgrid.poem.40009": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Des Firmaments entw\u00f6lckte B\u00fchne,", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des Firmaments entw\u00f6lckte B\u00fchne,", "tokens": ["Des", "Fir\u00b7ma\u00b7ments", "ent\u00b7w\u00f6lck\u00b7te", "B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War voller Strahlen, Glantz und Schein:", "tokens": ["War", "vol\u00b7ler", "Strah\u00b7len", ",", "Glantz", "und", "Schein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Quell' des Lichts, die g\u00fcld'ne Sonne, schiene", "tokens": ["Die", "Quell'", "des", "Lichts", ",", "die", "g\u00fcld'\u00b7ne", "Son\u00b7ne", ",", "schie\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Himmels Mittel-Punct zu seyn.", "tokens": ["Des", "Him\u00b7mels", "Mit\u00b7tel\u00b7Punct", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von oben fiel ihr gantz gerader Strahl,", "tokens": ["Von", "o\u00b7ben", "fiel", "ihr", "gantz", "ge\u00b7ra\u00b7der", "Strahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Erhellt' und f\u00fcllete, mit einem strengen Licht',", "tokens": ["Er\u00b7hellt'", "und", "f\u00fcl\u00b7le\u00b7te", ",", "mit", "ei\u00b7nem", "stren\u00b7gen", "Licht'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das sonst best\u00e4ndig k\u00fchl- von Schatten schwartze Thal.", "tokens": ["Das", "sonst", "be\u00b7st\u00e4n\u00b7dig", "k\u00fchl", "von", "Schat\u00b7ten", "schwart\u00b7ze", "Thal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "TRUNC", "APPR", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Luft-Kreis glimmt' und kocht', es lechzte Gras und Laub.", "tokens": ["Der", "Luft\u00b7Kreis", "glimmt'", "und", "kocht'", ",", "es", "lechz\u00b7te", "Gras", "und", "Laub", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,", "PPER", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Silvanders Heerde konnte nicht,", "tokens": ["Sil\u00b7van\u00b7ders", "Heer\u00b7de", "konn\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VMFIN", "PTKNEG", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "In denen fast versengten Heiden,", "tokens": ["In", "de\u00b7nen", "fast", "ver\u00b7seng\u00b7ten", "Hei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "F\u00fcr Mattigkeit und Hitze, l\u00e4nger weiden.", "tokens": ["F\u00fcr", "Mat\u00b7tig\u00b7keit", "und", "Hit\u00b7ze", ",", "l\u00e4n\u00b7ger", "wei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Die Schafe streckten sich in den verbrannten Staub.", "tokens": ["Die", "Scha\u00b7fe", "streck\u00b7ten", "sich", "in", "den", "ver\u00b7brann\u00b7ten", "Staub", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Drum er sie Seiten-w\u00e4rts in einen dicken Wald,", "tokens": ["Drum", "er", "sie", "Sei\u00b7ten\u00b7w\u00e4rts", "in", "ei\u00b7nen", "di\u00b7cken", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der holden K\u00fchlung Sitz, der Schatten Aufenthalt,", "tokens": ["Der", "hol\u00b7den", "K\u00fch\u00b7lung", "Sitz", ",", "der", "Schat\u00b7ten", "Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dem frisches Gras den Grund, und Laub den Wipfel zierte,", "tokens": ["Dem", "fri\u00b7sches", "Gras", "den", "Grund", ",", "und", "Laub", "den", "Wip\u00b7fel", "zier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mit sanften Schritten fl\u00f6tend f\u00fchrte.", "tokens": ["Mit", "sanf\u00b7ten", "Schrit\u00b7ten", "fl\u00f6\u00b7tend", "f\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Zumahlen er, in den beb\u00fcschten Gr\u00fcnden,", "tokens": ["Zu\u00b7mah\u00b7len", "er", ",", "in", "den", "be\u00b7b\u00fcschten", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Beraldo, seinen Freund, verhoffte vorzufinden,", "tokens": ["Be\u00b7ral\u00b7do", ",", "sei\u00b7nen", "Freund", ",", "ver\u00b7hoff\u00b7te", "vor\u00b7zu\u00b7fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der mehrentheils, im Schatten dichter B\u00e4ume,", "tokens": ["Der", "meh\u00b7ren\u00b7theils", ",", "im", "Schat\u00b7ten", "dich\u00b7ter", "B\u00e4u\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Die Schafe weidete; wo er, durch s\u00fcsse Reime,", "tokens": ["Die", "Scha\u00b7fe", "wei\u00b7de\u00b7te", ";", "wo", "er", ",", "durch", "s\u00fcs\u00b7se", "Rei\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWAV", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die Gottheit, die mit Klee und Gras", "tokens": ["Die", "Got\u00b7theit", ",", "die", "mit", "Klee", "und", "Gras"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Die Wiesen, und mit Laub die duncklen W\u00e4lder, schm\u00fccket,", "tokens": ["Die", "Wie\u00b7sen", ",", "und", "mit", "Laub", "die", "dunck\u00b7len", "W\u00e4l\u00b7der", ",", "schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "APPR", "NN", "ART", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Der uns, zu rechter Zeit, ein heilsam Na\u00df,", "tokens": ["Der", "uns", ",", "zu", "rech\u00b7ter", "Zeit", ",", "ein", "heil\u00b7sam", "Na\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Im k\u00fchlen Thau und Regen, schicket,", "tokens": ["Im", "k\u00fch\u00b7len", "Thau", "und", "Re\u00b7gen", ",", "schi\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "KON", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Wodurch die Wollen-reichen Heerden", "tokens": ["Wo\u00b7durch", "die", "Wol\u00b7len\u00b7rei\u00b7chen", "Heer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Getr\u00e4ncket und gen\u00e4hret werden;", "tokens": ["Ge\u00b7tr\u00e4n\u00b7cket", "und", "ge\u00b7n\u00e4h\u00b7ret", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Das Wesen, Dem daf\u00fcr von allen Hirten Ehre,", "tokens": ["Das", "We\u00b7sen", ",", "Dem", "da\u00b7f\u00fcr", "von", "al\u00b7len", "Hir\u00b7ten", "Eh\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "PAV", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Als einem solchen ", "tokens": ["Als", "ei\u00b7nem", "sol\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "PIAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.29": {"text": "Der aller Welt und Sonnen Heere,", "tokens": ["Der", "al\u00b7ler", "Welt", "und", "Son\u00b7nen", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Als eine Heerde Schafe, f\u00fchrt)", "tokens": ["Als", "ei\u00b7ne", "Heer\u00b7de", "Scha\u00b7fe", ",", "f\u00fchrt", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "In mancherley Beschreibungen besang,", "tokens": ["In", "man\u00b7cher\u00b7ley", "Be\u00b7schrei\u00b7bun\u00b7gen", "be\u00b7sang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.32": {"text": "Da\u00df Berg und Thal davon erklang.", "tokens": ["Da\u00df", "Berg", "und", "Thal", "da\u00b7von", "er\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Um ihm ein sch\u00f6n Gedicht, auf ein geschmiedet Eisen,", "tokens": ["Um", "ihm", "ein", "sch\u00f6n", "Ge\u00b7dicht", ",", "auf", "ein", "ge\u00b7schmie\u00b7det", "Ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ART", "ADJD", "NN", "$,", "APPR", "ART", "VVPP", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So er den Vormittag verfertiget, zu weisen.", "tokens": ["So", "er", "den", "Vor\u00b7mit\u00b7tag", "ver\u00b7fer\u00b7ti\u00b7get", ",", "zu", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ihr bester Zeit-Vertreib war eben die\u00df:", "tokens": ["Ihr", "bes\u00b7ter", "Zeit\u00b7Ver\u00b7treib", "war", "e\u00b7ben", "die\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df einer seines Geistes Fr\u00fcchte,", "tokens": ["Da\u00df", "ei\u00b7ner", "sei\u00b7nes", "Geis\u00b7tes", "Fr\u00fcch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die in der Einsamkeit erfundenen Gedichte,", "tokens": ["Die", "in", "der", "Ein\u00b7sam\u00b7keit", "er\u00b7fun\u00b7de\u00b7nen", "Ge\u00b7dich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu beyder Nutz, zu beyder Lust,", "tokens": ["Zu", "bey\u00b7der", "Nutz", ",", "zu", "bey\u00b7der", "Lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da keiner was vom Neid und bittrer Scheel-Sucht wust',", "tokens": ["Da", "kei\u00b7ner", "was", "vom", "Neid", "und", "bit\u00b7trer", "Scheel\u00b7Sucht", "wust'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PWS", "APPRART", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "(ein Stand, bey Dichtern rar) dem andern sehen lie\u00df.", "tokens": ["(", "ein", "Stand", ",", "bey", "Dich\u00b7tern", "rar", ")", "dem", "an\u00b7dern", "se\u00b7hen", "lie\u00df", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "APPR", "NN", "ADJD", "$(", "ART", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Er traf ihn aber nicht, wohl aber Damon, an,", "tokens": ["Er", "traf", "ihn", "a\u00b7ber", "nicht", ",", "wohl", "a\u00b7ber", "Da\u00b7mon", ",", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "ADV", "ADV", "NE", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der ihm berichtete:", "tokens": ["Der", "ihm", "be\u00b7rich\u00b7te\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Beraldo w\u00e4r', in fr\u00fcher Morgen-Stunde,", "tokens": ["Be\u00b7ral\u00b7do", "w\u00e4r'", ",", "in", "fr\u00fc\u00b7her", "Mor\u00b7gen\u00b7Stun\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schon aus dem Schatten-reichen Grunde,", "tokens": ["Schon", "aus", "dem", "Schat\u00b7ten\u00b7rei\u00b7chen", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Auf jenes Berges steile H\u00f6h',", "tokens": ["Auf", "je\u00b7nes", "Ber\u00b7ges", "stei\u00b7le", "H\u00f6h'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Wipfel man,", "tokens": ["Des", "Wip\u00b7fel", "man", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "F\u00fcr Wolcken, nicht von unten sehen kann,", "tokens": ["F\u00fcr", "Wol\u00b7cken", ",", "nicht", "von", "un\u00b7ten", "se\u00b7hen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PTKNEG", "APPR", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Nachdem er seine Heerd' ihm anvertraut, gestiegen.", "tokens": ["Nach\u00b7dem", "er", "sei\u00b7ne", "He\u00b7erd'", "ihm", "an\u00b7ver\u00b7traut", ",", "ge\u00b7stie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Silvander bat hierauf, so bald er die\u00df geh\u00f6rt,", "tokens": ["Sil\u00b7van\u00b7der", "bat", "hier\u00b7auf", ",", "so", "bald", "er", "die\u00df", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "$,", "ADV", "ADV", "PPER", "PDS", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da\u00df Damon seine Schaf', absonderlich die Ziegen,", "tokens": ["Da\u00df", "Da\u00b7mon", "sei\u00b7ne", "Schaf'", ",", "ab\u00b7son\u00b7der\u00b7lich", "die", "Zie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPOSAT", "NN", "$,", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch mit beachten m\u00f6cht', und eilte, voll Verlangen,", "tokens": ["Auch", "mit", "be\u00b7ach\u00b7ten", "m\u00f6cht'", ",", "und", "eil\u00b7te", ",", "voll", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVINF", "VMFIN", "$,", "KON", "VVFIN", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beraldo wieder zu umfangen,", "tokens": ["Be\u00b7ral\u00b7do", "wie\u00b7der", "zu", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm nach, und gleich den Berg hinan:", "tokens": ["Ihm", "nach", ",", "und", "gleich", "den", "Berg", "hi\u00b7nan", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "KON", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nachdem er eine Flasche,", "tokens": ["Nach\u00b7dem", "er", "ei\u00b7ne", "Fla\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Voll frischer Milch, in seine bunte Tasche,", "tokens": ["Voll", "fri\u00b7scher", "Milch", ",", "in", "sei\u00b7ne", "bun\u00b7te", "Ta\u00b7sche", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Zum Labsal, eingestecket.", "tokens": ["Zum", "Lab\u00b7sal", ",", "ein\u00b7ge\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Das rauhe Hartz-Geb\u00fcrg' erstrecket,", "tokens": ["Das", "rau\u00b7he", "Hartz\u00b7Ge\u00b7b\u00fcr\u00b7g'", "er\u00b7stre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Erhebt und th\u00fcrmet sich", "tokens": ["Er\u00b7hebt", "und", "th\u00fcr\u00b7met", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Fast unersteiglich, schroff und g\u00e4he,", "tokens": ["Fast", "un\u00b7er\u00b7steig\u00b7lich", ",", "schroff", "und", "g\u00e4\u00b7he", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Allhier zu einer solchen H\u00f6he,", "tokens": ["All\u00b7hier", "zu", "ei\u00b7ner", "sol\u00b7chen", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die selbst dem Blick fast f\u00fcrchterlich.", "tokens": ["Die", "selbst", "dem", "Blick", "fast", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch lie\u00df er sich die Schwierigkeit nicht hindern,", "tokens": ["Doch", "lie\u00df", "er", "sich", "die", "Schwie\u00b7rig\u00b7keit", "nicht", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Noch die ihn treibende Begier dadurch vermindern.", "tokens": ["Noch", "die", "ihn", "trei\u00b7ben\u00b7de", "Be\u00b7gier", "da\u00b7durch", "ver\u00b7min\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "ADJA", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er trat die rauhe Bahn", "tokens": ["Er", "trat", "die", "rau\u00b7he", "Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Mit fohen Schritten an.", "tokens": ["Mit", "fo\u00b7hen", "Schrit\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Und, weil ein Fu\u00df-Steig ihm nicht unbekannt;", "tokens": ["Und", ",", "weil", "ein", "Fu\u00df\u00b7Steig", "ihm", "nicht", "un\u00b7be\u00b7kannt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Verk\u00fcrtzt' er seinen Weg, so, da\u00df, in kurtzer Zeit,", "tokens": ["Ver\u00b7k\u00fcrtzt'", "er", "sei\u00b7nen", "Weg", ",", "so", ",", "da\u00df", ",", "in", "kurt\u00b7zer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "ADV", "$,", "KOUS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Trotz des Geb\u00fcrges Rauhigkeit,", "tokens": ["Trotz", "des", "Ge\u00b7b\u00fcr\u00b7ges", "Rau\u00b7hig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Er oben auf des Berges Spitzen,", "tokens": ["Er", "o\u00b7ben", "auf", "des", "Ber\u00b7ges", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Mit m\u00fcden zwar, doch frohen F\u00fcssen, stand.", "tokens": ["Mit", "m\u00fc\u00b7den", "zwar", ",", "doch", "fro\u00b7hen", "F\u00fcs\u00b7sen", ",", "stand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "ADV", "$,", "ADV", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Hieselbst sah er, auf einem grossen Stein,", "tokens": ["Hie\u00b7selbst", "sah", "er", ",", "auf", "ei\u00b7nem", "gros\u00b7sen", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Steinen gantz umringt, Beraldo gantz allein", "tokens": ["Mit", "Stei\u00b7nen", "gantz", "um\u00b7ringt", ",", "Be\u00b7ral\u00b7do", "gantz", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "VVPP", "$,", "NE", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vertieft im Dencken, schreibend sitzen.", "tokens": ["Ver\u00b7tieft", "im", "Den\u00b7cken", ",", "schrei\u00b7bend", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Indessen da\u00df, von seiner Hand,", "tokens": ["In\u00b7des\u00b7sen", "da\u00df", ",", "von", "sei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er ein beschrieben Bl\u00e4ttchen fand,", "tokens": ["Er", "ein", "be\u00b7schrie\u00b7ben", "Bl\u00e4tt\u00b7chen", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So ihm der Wind entf\u00fchrt. Er hub's begierig auf,", "tokens": ["So", "ihm", "der", "Wind", "ent\u00b7f\u00fchrt", ".", "Er", "hub's", "be\u00b7gie\u00b7rig", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "VVPP", "$.", "PPER", "NE", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und lase diese Worte drauf:", "tokens": ["Und", "la\u00b7se", "die\u00b7se", "Wor\u00b7te", "drauf", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbindem das Feld mit Schnee der dunckle Winter decket,", "tokens": ["\u00bb", "in\u00b7dem", "das", "Feld", "mit", "Schnee", "der", "dunck\u00b7le", "Win\u00b7ter", "de\u00b7cket", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "NN", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und scharfes Eis die Fluth verstecket,", "tokens": ["Und", "schar\u00b7fes", "Eis", "die", "Fluth", "ver\u00b7ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sitz' ich allhier,", "tokens": ["Sitz'", "ich", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Wo ich, vergn\u00fcgt, mir selber lebe,", "tokens": ["Wo", "ich", ",", "ver\u00b7gn\u00fcgt", ",", "mir", "sel\u00b7ber", "le\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "VVPP", "$,", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und von der eitelen Begier", "tokens": ["Und", "von", "der", "ei\u00b7te\u00b7len", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich zu entfernen, mich bestrebe,", "tokens": ["Mich", "zu", "ent\u00b7fer\u00b7nen", ",", "mich", "be\u00b7stre\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bey einem frohen Feur, befreyt vom Neid und Zancken.", "tokens": ["Bey", "ei\u00b7nem", "fro\u00b7hen", "Feur", ",", "be\u00b7freyt", "vom", "Neid", "und", "Zan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "VVPP", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald schreibt mein reger Kiel,", "tokens": ["Bald", "schreibt", "mein", "re\u00b7ger", "Kiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Bald sing' ich, bald erklingt mein Saiten-Spiel.", "tokens": ["Bald", "sing'", "ich", ",", "bald", "er\u00b7klingt", "mein", "Sai\u00b7ten\u00b7Spiel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und, wenn, voll Ehr-Suchts-Dunst, sich schleichende Gedancken", "tokens": ["Und", ",", "wenn", ",", "voll", "Ehr\u00b7Suchts\u00b7Dunst", ",", "sich", "schlei\u00b7chen\u00b7de", "Ge\u00b7dan\u00b7cken"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "$,", "ADJD", "NN", "$,", "PRF", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Von neuem etwan meine Sinnen", "tokens": ["Von", "neu\u00b7em", "et\u00b7wan", "mei\u00b7ne", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Zu f\u00fcllen unterstehn; treibt die Erinnerung,", "tokens": ["Zu", "f\u00fcl\u00b7len", "un\u00b7ter\u00b7stehn", ";", "treibt", "die", "E\u00b7rin\u00b7ne\u00b7rung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVINF", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+++-+--", "measure": "unknown.measure.hexa"}, "line.13": {"text": "Die mich zur Vorsicht bringt, dieselben schnell von hinnen.", "tokens": ["Die", "mich", "zur", "Vor\u00b7sicht", "bringt", ",", "die\u00b7sel\u00b7ben", "schnell", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "$,", "PDAT", "ADJD", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Pracht, Hoheit, Titel, Geld, Ruhm, Reichthum, Ehre, W\u00fcrde!", "tokens": ["Pracht", ",", "Ho\u00b7heit", ",", "Ti\u00b7tel", ",", "Geld", ",", "Ruhm", ",", "Reicht\u00b7hum", ",", "Eh\u00b7re", ",", "W\u00fcr\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "VAFIN", "$."], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Was seyd ihr eigentlich?", "tokens": ["Was", "seyd", "ihr", "ei\u00b7gent\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df eurentwegen sich", "tokens": ["Da\u00df", "eu\u00b7rent\u00b7we\u00b7gen", "sich"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPOSAT", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die Menschen so zerfoltern? Eine B\u00fcrde,", "tokens": ["Die", "Men\u00b7schen", "so", "zer\u00b7fol\u00b7tern", "?", "Ei\u00b7ne", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die, ohn' Ergetzen, dr\u00fcckt; ein \u00fcberzuckert Gift,", "tokens": ["Die", ",", "ohn'", "Er\u00b7get\u00b7zen", ",", "dr\u00fcckt", ";", "ein", "\u00fc\u00b7ber\u00b7zu\u00b7ckert", "Gift", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "NN", "$,", "VVFIN", "$.", "ART", "VVPP", "NN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "Ein' unbest\u00e4nd'ge Lust, ein daurhaft Unvergn\u00fcgen.", "tokens": ["Ein'", "un\u00b7be\u00b7st\u00e4n\u00b7d'\u00b7ge", "Lust", ",", "ein", "daur\u00b7haft", "Un\u00b7ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Ich fieng auch ehmahls an, vermessentlich,", "tokens": ["Ich", "fi\u00b7eng", "auch", "eh\u00b7mahls", "an", ",", "ver\u00b7mes\u00b7sent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "Wie Icarus, empor zu fliegen.", "tokens": ["Wie", "I\u00b7ca\u00b7rus", ",", "em\u00b7por", "zu", "flie\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Jetzt aber sitz' ich hier, und lache mich,", "tokens": ["Jetzt", "a\u00b7ber", "sitz'", "ich", "hier", ",", "und", "la\u00b7che", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Samt meiner Thorheit, aus.\u00ab Ja, fieng Silvander an,", "tokens": ["Samt", "mei\u00b7ner", "Thor\u00b7heit", ",", "aus", ".", "\u00ab", "Ja", ",", "fi\u00b7eng", "Sil\u00b7van\u00b7der", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PTKVZ", "$.", "$(", "PTKANT", "$,", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Beraldo, du hast recht: wie wohl hast du gedacht!", "tokens": ["Be\u00b7ral\u00b7do", ",", "du", "hast", "recht", ":", "wie", "wohl", "hast", "du", "ge\u00b7dacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADJD", "$.", "PWAV", "ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie gl\u00fccklich ist, der es so weit gebracht!", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", ",", "der", "es", "so", "weit", "ge\u00b7bracht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "PRELS", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Wie gl\u00fccklich ist, der also dencken kann!", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", ",", "der", "al\u00b7so", "den\u00b7cken", "kann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "PRELS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Er fand darauf annoch an einem andern Orte,", "tokens": ["Er", "fand", "da\u00b7rauf", "an\u00b7noch", "an", "ei\u00b7nem", "an\u00b7dern", "Or\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf einem Zettul, diese Worte:", "tokens": ["Auf", "ei\u00b7nem", "Zet\u00b7tul", ",", "die\u00b7se", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er lachte,", "tokens": ["Er", "lach\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wie er auf die Vergleichung dachte.", "tokens": ["Wie", "er", "auf", "die", "Ver\u00b7glei\u00b7chung", "dach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Drauf n\u00e4hert' er sich ihm, doch in geheim, und schlich", "tokens": ["Drauf", "n\u00e4\u00b7hert'", "er", "sich", "ihm", ",", "doch", "in", "ge\u00b7heim", ",", "und", "schlich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "PPER", "$,", "ADV", "APPR", "ADJD", "$,", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gemach zu ihm hinan.", "tokens": ["Ge\u00b7mach", "zu", "ihm", "hi\u00b7nan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Doch, da ein d\u00fcrrer Ast, zertreten, brach und krachte,", "tokens": ["Doch", ",", "da", "ein", "d\u00fcr\u00b7rer", "Ast", ",", "zer\u00b7tre\u00b7ten", ",", "brach", "und", "krach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Fuhr jener, durch's Ger\u00e4usch erschreckt, so stark in sich,", "tokens": ["Fuhr", "je\u00b7ner", ",", "durch's", "Ge\u00b7r\u00e4usch", "er\u00b7schreckt", ",", "so", "stark", "in", "sich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "$,", "APPRART", "NN", "VVPP", "$,", "ADV", "ADJD", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df, von der regen Hand, die von der Stelle flog,", "tokens": ["Da\u00df", ",", "von", "der", "re\u00b7gen", "Hand", ",", "die", "von", "der", "Stel\u00b7le", "flog", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Ein schneller langer Strich", "tokens": ["Ein", "schnel\u00b7ler", "lan\u00b7ger", "Strich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Sich \u00fcber sein Papier, das er beschrieben, zog.", "tokens": ["Sich", "\u00fc\u00b7ber", "sein", "Pa\u00b7pier", ",", "das", "er", "be\u00b7schrie\u00b7ben", ",", "zog", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Sie lachten hertzlich alle beyde,", "tokens": ["Sie", "lach\u00b7ten", "hertz\u00b7lich", "al\u00b7le", "bey\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PIAT", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bezeugten Wechsels-weis' einander ihre Freude,", "tokens": ["Be\u00b7zeug\u00b7ten", "Wech\u00b7sels\u00b7weis'", "ein\u00b7an\u00b7der", "ih\u00b7re", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und, wie sie mit der Milch den Durst, den beyde f\u00fchlten,", "tokens": ["Und", ",", "wie", "sie", "mit", "der", "Milch", "den", "Durst", ",", "den", "bey\u00b7de", "f\u00fchl\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nachdem sie sie vorhin in einer Quelle k\u00fchlten,", "tokens": ["Nach\u00b7dem", "sie", "sie", "vor\u00b7hin", "in", "ei\u00b7ner", "Quel\u00b7le", "k\u00fchl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nicht ohne Lust gestillt, sich beyde niedersetzten,", "tokens": ["Nicht", "oh\u00b7ne", "Lust", "ge\u00b7stillt", ",", "sich", "bey\u00b7de", "nie\u00b7der\u00b7setz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VVPP", "$,", "PRF", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und an der bunten Pracht", "tokens": ["Und", "an", "der", "bun\u00b7ten", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Der Landschaft sich ergetzten;", "tokens": ["Der", "Land\u00b7schaft", "sich", "er\u00b7getz\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Lie\u00df das, womit sein Kiel besch\u00e4fftiget gewesen,", "tokens": ["Lie\u00df", "das", ",", "wo\u00b7mit", "sein", "Kiel", "be\u00b7sch\u00e4ff\u00b7ti\u00b7get", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Beraldo, seinen Freund, auf sein Verlangen, lesen.", "tokens": ["Be\u00b7ral\u00b7do", ",", "sei\u00b7nen", "Freund", ",", "auf", "sein", "Ver\u00b7lan\u00b7gen", ",", "le\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Des rauhen Hartzes rauhe Pracht", "tokens": ["Des", "rau\u00b7hen", "Hart\u00b7zes", "rau\u00b7he", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hatt' er, durch seine Pflicht getrieben,", "tokens": ["Hatt'", "er", ",", "durch", "sei\u00b7ne", "Pflicht", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zu Ehren dem, der ihn zum Schatz-Behalter macht,", "tokens": ["Zu", "Eh\u00b7ren", "dem", ",", "der", "ihn", "zum", "Schatz\u00b7Be\u00b7hal\u00b7ter", "macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Fast mehr geschildert, als beschrieben.", "tokens": ["Fast", "mehr", "ge\u00b7schil\u00b7dert", ",", "als", "be\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "KOUS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Absonderlich hatt' er des glatten Marmors Prangen,", "tokens": ["Ab\u00b7son\u00b7der\u00b7lich", "hatt'", "er", "des", "glat\u00b7ten", "Mar\u00b7mors", "Pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Den Blanckenburgs Geb\u00fcrg' uns hier,", "tokens": ["Den", "Blan\u00b7cken\u00b7burgs", "Ge\u00b7b\u00fcr\u00b7g'", "uns", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "In einer tausendfach gef\u00e4rbten Zier,", "tokens": ["In", "ei\u00b7ner", "tau\u00b7send\u00b7fach", "ge\u00b7f\u00e4rb\u00b7ten", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Zu einem Wunder bringt, zu bilden angefangen.", "tokens": ["Zu", "ei\u00b7nem", "Wun\u00b7der", "bringt", ",", "zu", "bil\u00b7den", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Es wiederholete der Wiederhall,", "tokens": ["Es", "wie\u00b7der\u00b7ho\u00b7le\u00b7te", "der", "Wie\u00b7der\u00b7hall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit einem sanften Schall,", "tokens": ["Mit", "ei\u00b7nem", "sanf\u00b7ten", "Schall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Aus mancher Kluft, von mehr, als einem Orte,", "tokens": ["Aus", "man\u00b7cher", "Kluft", ",", "von", "mehr", ",", "als", "ei\u00b7nem", "Or\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "ADV", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als er, wie folget, las', fast alle Worte:", "tokens": ["Als", "er", ",", "wie", "fol\u00b7get", ",", "las'", ",", "fast", "al\u00b7le", "Wor\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "VVFIN", "$,", "VVFIN", "$,", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Welch eine Last von Stein! Welch eine Felsen-Welt", "tokens": ["Welch", "ei\u00b7ne", "Last", "von", "Stein", "!", "Welch", "ei\u00b7ne", "Fel\u00b7sen\u00b7Welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "APPR", "NN", "$.", "PIAT", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wird meinem starren Blick' hier vorgestellt!", "tokens": ["Wird", "mei\u00b7nem", "star\u00b7ren", "Blick'", "hier", "vor\u00b7ge\u00b7stellt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Fast alles, was allhier die Augen schauen,", "tokens": ["Fast", "al\u00b7les", ",", "was", "all\u00b7hier", "die", "Au\u00b7gen", "schau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gebieret Furcht, sucht ein geheimes Schrecken", "tokens": ["Ge\u00b7bie\u00b7ret", "Furcht", ",", "sucht", "ein", "ge\u00b7hei\u00b7mes", "Schre\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "NN", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auch dem, der sonst nicht bange, zu erwecken.", "tokens": ["Auch", "dem", ",", "der", "sonst", "nicht", "ban\u00b7ge", ",", "zu", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ADV", "PTKNEG", "ADJD", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Es hauchet Wiedrigkeit und Grauen,", "tokens": ["Es", "hau\u00b7chet", "Wied\u00b7rig\u00b7keit", "und", "Grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An diesem Ort, fast jeder Vorwurf aus.", "tokens": ["An", "die\u00b7sem", "Ort", ",", "fast", "je\u00b7der", "Vor\u00b7wurf", "aus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es sehn zugleich die scheuch- und starren Blicke", "tokens": ["Es", "sehn", "zu\u00b7gleich", "die", "scheuch", "und", "star\u00b7ren", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hier ungeheure Felsen-St\u00fccke,", "tokens": ["Hier", "un\u00b7ge\u00b7heu\u00b7re", "Fel\u00b7sen\u00b7St\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bald fest und gantz, und bald zerbrochen und zerspalten:", "tokens": ["Bald", "fest", "und", "gantz", ",", "und", "bald", "zer\u00b7bro\u00b7chen", "und", "zer\u00b7spal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "ADV", "$,", "KON", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald Abgr\u00fcnd', H\u00f6len, Moo\u00df und Graus.", "tokens": ["Bald", "Ab\u00b7gr\u00fcnd'", ",", "H\u00f6\u00b7len", ",", "Moo\u00df", "und", "Graus", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein gantz verwirrt Gemisch von allerley Gestalten,", "tokens": ["Ein", "gantz", "ver\u00b7wirrt", "Ge\u00b7misch", "von", "al\u00b7ler\u00b7ley", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Materien und Farben, stellet hier", "tokens": ["Ma\u00b7te\u00b7ri\u00b7en", "und", "Far\u00b7ben", ",", "stel\u00b7let", "hier"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "KON", "NN", "$,", "VVFIN", "ADV"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.9": {"text": "Uns gleichsam recht ein Chaos f\u00fcr.", "tokens": ["Uns", "gleich\u00b7sam", "recht", "ein", "Chaos", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Leim- Marmor- Kiesel-Berg', unordentlich vermengt,", "tokens": ["Leim", "Mar\u00b7mor", "Kie\u00b7sel\u00b7Ber\u00b7g'", ",", "un\u00b7or\u00b7dent\u00b7lich", "ver\u00b7mengt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["TRUNC", "TRUNC", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Unordentlich erh\u00f6ht, unordentlich zerbrochen,", "tokens": ["Un\u00b7or\u00b7dent\u00b7lich", "er\u00b7h\u00f6ht", ",", "un\u00b7or\u00b7dent\u00b7lich", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Als w\u00e4ren sie, durch ungefehren Fall,", "tokens": ["Als", "w\u00e4\u00b7ren", "sie", ",", "durch", "un\u00b7ge\u00b7feh\u00b7ren", "Fall", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So wunderlich in sich gedrengt,", "tokens": ["So", "wun\u00b7der\u00b7lich", "in", "sich", "ge\u00b7drengt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erblickt man \u00fcberall.", "tokens": ["Er\u00b7blickt", "man", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Von erst geschmoltznem Schnee kommt hier ein tr\u00e4ger Bach,", "tokens": ["Von", "erst", "ge\u00b7schmoltz\u00b7nem", "Schnee", "kommt", "hier", "ein", "tr\u00e4\u00b7ger", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vermischt mit Schlamm und faulem Moo\u00df,", "tokens": ["Ver\u00b7mischt", "mit", "Schlamm", "und", "fau\u00b7lem", "Moo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus kleinen Oeffnungen gekrochen:", "tokens": ["Aus", "klei\u00b7nen", "Oeff\u00b7nun\u00b7gen", "ge\u00b7kro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vermehrt sich aber allgemach,", "tokens": ["Ver\u00b7mehrt", "sich", "a\u00b7ber", "all\u00b7ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird, eh man sich's versiehet, gro\u00df,", "tokens": ["Wird", ",", "eh", "man", "sich's", "ver\u00b7sie\u00b7het", ",", "gro\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erz\u00fcrnt sich, sch\u00e4umt und braust, und was erst kaum geflossen,", "tokens": ["Er\u00b7z\u00fcrnt", "sich", ",", "sch\u00e4umt", "und", "braust", ",", "und", "was", "erst", "kaum", "ge\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "VVFIN", "KON", "VVFIN", "$,", "KON", "PWS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kommt, \u00fcber schroffe Stein', erbost herab geschossen,", "tokens": ["Kommt", ",", "\u00fc\u00b7ber", "schrof\u00b7fe", "Stein'", ",", "er\u00b7bost", "her\u00b7ab", "ge\u00b7schos\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Reisst selbst den Boden mit, st\u00fcrtzt, mit besch\u00e4umtem Grimm,", "tokens": ["Reisst", "selbst", "den", "Bo\u00b7den", "mit", ",", "st\u00fcrtzt", ",", "mit", "be\u00b7sch\u00e4um\u00b7tem", "Grimm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,", "VVFIN", "$,", "APPR", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bejahrte dicke B\u00e4um' und schwere Felsen \u00fcm.", "tokens": ["Be\u00b7jahr\u00b7te", "di\u00b7cke", "B\u00e4um'", "und", "schwe\u00b7re", "Fel\u00b7sen", "\u00fcm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "An manchem Orte sind der Berge rauhe H\u00f6h'n", "tokens": ["An", "man\u00b7chem", "Or\u00b7te", "sind", "der", "Ber\u00b7ge", "rau\u00b7he", "H\u00f6h'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Recht ungeheuer sch\u00f6n.", "tokens": ["Recht", "un\u00b7ge\u00b7heu\u00b7er", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Gr\u00f6sse kann uns Lust und Schrecken", "tokens": ["Die", "Gr\u00f6s\u00b7se", "kann", "uns", "Lust", "und", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zugleich erwecken.", "tokens": ["Zu\u00b7gleich", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Entsetzlich ist der Klippen H\u00f6h' und Dicke:", "tokens": ["Ent\u00b7setz\u00b7lich", "ist", "der", "Klip\u00b7pen", "H\u00f6h'", "und", "Di\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Entsetzlich gro\u00df sind abgerollte St\u00fccke:", "tokens": ["Ent\u00b7setz\u00b7lich", "gro\u00df", "sind", "ab\u00b7ge\u00b7roll\u00b7te", "St\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Entsetzlich schwartz sind aufgespalt'ne Kl\u00fcfte:", "tokens": ["Ent\u00b7setz\u00b7lich", "schwartz", "sind", "auf\u00b7ge\u00b7spalt'\u00b7ne", "Kl\u00fcf\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Entsetzlich tief, wie Rachen, hohle Gr\u00fcfte:", "tokens": ["Ent\u00b7setz\u00b7lich", "tief", ",", "wie", "Ra\u00b7chen", ",", "hoh\u00b7le", "Gr\u00fcf\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "PWAV", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die mehrentheils verwirrte Dornen-Hecken,", "tokens": ["Die", "meh\u00b7ren\u00b7theils", "ver\u00b7wirr\u00b7te", "Dor\u00b7nen\u00b7He\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Die voller Furcht und Grauen stecken,", "tokens": ["Die", "vol\u00b7ler", "Furcht", "und", "Grau\u00b7en", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Mit Klauen-gleichen Stacheln decken.", "tokens": ["Mit", "Klau\u00b7en\u00b7glei\u00b7chen", "Sta\u00b7cheln", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Die Gegenden sind meistens w\u00fcst' und wild,", "tokens": ["Die", "Ge\u00b7gen\u00b7den", "sind", "meis\u00b7tens", "w\u00fcst'", "und", "wild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit steter D\u00e4mmerung und Schatten angef\u00fcllt.", "tokens": ["Mit", "ste\u00b7ter", "D\u00e4m\u00b7me\u00b7rung", "und", "Schat\u00b7ten", "an\u00b7ge\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Einsamkeit allein", "tokens": ["Die", "Ein\u00b7sam\u00b7keit", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Scheint hier Bewohnerinn zu seyn.", "tokens": ["Scheint", "hier", "Be\u00b7woh\u00b7ne\u00b7rinn", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Jedoch, erstarrter Sinn, begreife dich!", "tokens": ["Je\u00b7doch", ",", "er\u00b7starr\u00b7ter", "Sinn", ",", "be\u00b7grei\u00b7fe", "dich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die furchtbare Gestalt ist nicht so f\u00fcrchterlich.", "tokens": ["Die", "furcht\u00b7ba\u00b7re", "Ge\u00b7stalt", "ist", "nicht", "so", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sieh nicht allein der Berge wildes Wesen,", "tokens": ["Sieh", "nicht", "al\u00b7lein", "der", "Ber\u00b7ge", "wil\u00b7des", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sieh auch derselben Schmuck, zusamt dem Nutzen, an!", "tokens": ["Sieh", "auch", "der\u00b7sel\u00b7ben", "Schmuck", ",", "zu\u00b7samt", "dem", "Nut\u00b7zen", ",", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "PDAT", "NN", "$,", "APPR", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du kannst hier mehr, als man leicht sonsten kann,", "tokens": ["Du", "kannst", "hier", "mehr", ",", "als", "man", "leicht", "sons\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "$,", "KOUS", "PIS", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Des Sch\u00f6pfers Huld und Macht, aus ihrer Anmuth, lesen.", "tokens": ["Des", "Sch\u00f6p\u00b7fers", "Huld", "und", "Macht", ",", "aus", "ih\u00b7rer", "An\u00b7muth", ",", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es wird kein Mensch die Vortheil' alle nennen,", "tokens": ["Es", "wird", "kein", "Mensch", "die", "Vort\u00b7heil'", "al\u00b7le", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "ART", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die ein Geb\u00fcrg' uns bringt, noch sie beschreiben k\u00f6nnen.", "tokens": ["Die", "ein", "Ge\u00b7b\u00fcr\u00b7g'", "uns", "bringt", ",", "noch", "sie", "be\u00b7schrei\u00b7ben", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "VVFIN", "$,", "ADV", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "Es stecken kostbare Metallen,", "tokens": ["Es", "ste\u00b7cken", "kost\u00b7ba\u00b7re", "Me\u00b7tal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es stecken klare Berg-Crystallen,", "tokens": ["Es", "ste\u00b7cken", "kla\u00b7re", "Ber\u00b7gCry\u00b7stal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Samt Silber, Gold, der Menschen Lust,", "tokens": ["Samt", "Sil\u00b7ber", ",", "Gold", ",", "der", "Men\u00b7schen", "Lust", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ihrer finstern Brust.", "tokens": ["In", "ih\u00b7rer", "fins\u00b7tern", "Brust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Wasser, das von ihren Gipfeln f\u00e4llt,", "tokens": ["Das", "Was\u00b7ser", ",", "das", "von", "ih\u00b7ren", "Gip\u00b7feln", "f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Bestr\u00f6mt und tr\u00e4nckt die d\u00fcrre Welt.", "tokens": ["Be\u00b7str\u00f6mt", "und", "tr\u00e4nckt", "die", "d\u00fcr\u00b7re", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ja, selbst die Rauhigkeit, die wir an vielen sehn,", "tokens": ["Ja", ",", "selbst", "die", "Rau\u00b7hig\u00b7keit", ",", "die", "wir", "an", "vie\u00b7len", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kann andrer Lieblichkeit und Anmuth noch erh\u00f6hn,", "tokens": ["Kann", "an\u00b7drer", "Lieb\u00b7lich\u00b7keit", "und", "An\u00b7muth", "noch", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Durch ihren Gegensatz. Wie manchen H\u00fcgel schm\u00fccket", "tokens": ["Durch", "ih\u00b7ren", "Ge\u00b7gen\u00b7satz", ".", "Wie", "man\u00b7chen", "H\u00fc\u00b7gel", "schm\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PWAV", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Des Grases gr\u00fcner Sammt, der sch\u00f6nsten Kr\u00e4uter Pracht!", "tokens": ["Des", "Gra\u00b7ses", "gr\u00fc\u00b7ner", "Sammt", ",", "der", "sch\u00f6ns\u00b7ten", "Kr\u00e4u\u00b7ter", "Pracht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie manche gr\u00fcn- und holde Nacht", "tokens": ["Wie", "man\u00b7che", "gr\u00fcn", "und", "hol\u00b7de", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wird hier, im dichten Busch', erblicket!", "tokens": ["Wird", "hier", ",", "im", "dich\u00b7ten", "Busch'", ",", "er\u00b7bli\u00b7cket", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "APPRART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wann dort, bald an der Berge Gipfel,", "tokens": ["Wann", "dort", ",", "bald", "an", "der", "Ber\u00b7ge", "Gip\u00b7fel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Bald an der hohen B\u00e4ume Wipfel,", "tokens": ["Bald", "an", "der", "ho\u00b7hen", "B\u00e4u\u00b7me", "Wip\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ein schnelles Licht, ein heller Strahl", "tokens": ["Ein", "schnel\u00b7les", "Licht", ",", "ein", "hel\u00b7ler", "Strahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit frohem Schimmer f\u00e4llt; wird im beb\u00fcschten Thal,", "tokens": ["Mit", "fro\u00b7hem", "Schim\u00b7mer", "f\u00e4llt", ";", "wird", "im", "be\u00b7b\u00fcschten", "Thal", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "VAFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.17": {"text": "Auch selber in den Mittags-Stunden,", "tokens": ["Auch", "sel\u00b7ber", "in", "den", "Mit\u00b7tags\u00b7Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Ein angenehme K\u00fchl- und sanfte D\u00e4mmerung,", "tokens": ["Ein", "an\u00b7ge\u00b7neh\u00b7me", "K\u00fchl", "und", "sanf\u00b7te", "D\u00e4m\u00b7me\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.19": {"text": "Oft in der Nachbarschaft desselben Strahls, gefunden.", "tokens": ["Oft", "in", "der", "Nach\u00b7bar\u00b7schaft", "des\u00b7sel\u00b7ben", "Strahls", ",", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PDAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Es \u00e4ndern, wechseln, trennen, gatten,", "tokens": ["Es", "\u00e4n\u00b7dern", ",", "wech\u00b7seln", ",", "tren\u00b7nen", ",", "gat\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vermischen, f\u00e4rben, bilden sich", "tokens": ["Ver\u00b7mi\u00b7schen", ",", "f\u00e4r\u00b7ben", ",", "bil\u00b7den", "sich"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel tausend Lichter, tausend Schatten,", "tokens": ["Viel", "tau\u00b7send", "Lich\u00b7ter", ",", "tau\u00b7send", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$,", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So lieblich, als verwunderlich.", "tokens": ["So", "lieb\u00b7lich", ",", "als", "ver\u00b7wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Es zeigen hier der Berge rauhe R\u00fccken,", "tokens": ["Es", "zei\u00b7gen", "hier", "der", "Ber\u00b7ge", "rau\u00b7he", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf welchen oft, statt Kr\u00e4uter, Gras und Klee,", "tokens": ["Auf", "wel\u00b7chen", "oft", ",", "statt", "Kr\u00e4u\u00b7ter", ",", "Gras", "und", "Klee", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "ADV", "$,", "KOUI", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein graues Eis, bejahrter Schnee,", "tokens": ["Ein", "grau\u00b7es", "Eis", ",", "be\u00b7jahr\u00b7ter", "Schnee", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die schroff- und rauhen H\u00e4upter dr\u00fccken,", "tokens": ["Die", "schroff", "und", "rau\u00b7hen", "H\u00e4up\u00b7ter", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den Winter: wann, zu gleicher Zeit,", "tokens": ["Den", "Win\u00b7ter", ":", "wann", ",", "zu", "glei\u00b7cher", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PWAV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit gr\u00fcn bebl\u00fchmter Lieblichkeit", "tokens": ["Mit", "gr\u00fcn", "be\u00b7bl\u00fchm\u00b7ter", "Lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Viel H\u00fcgel, wie im Herbst, dort andre, wie im Lentzen,", "tokens": ["Viel", "H\u00fc\u00b7gel", ",", "wie", "im", "Herbst", ",", "dort", "and\u00b7re", ",", "wie", "im", "Lent\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "APPRART", "NN", "$,", "ADV", "PIS", "$,", "PWAV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und hier verschied'ne, recht als wie im Sommer, gl\u00e4ntzen.", "tokens": ["Und", "hier", "ver\u00b7schie\u00b7d'\u00b7ne", ",", "recht", "als", "wie", "im", "Som\u00b7mer", ",", "gl\u00e4nt\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "ADV", "KOUS", "KOKOM", "APPRART", "NN", "$,", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "So, da\u00df man hier nicht nur die Tages-Zeiten; gar", "tokens": ["So", ",", "da\u00df", "man", "hier", "nicht", "nur", "die", "Ta\u00b7ges\u00b7Zei\u00b7ten", ";", "gar"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "KOUS", "PIS", "ADV", "PTKNEG", "ADV", "ART", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Jahres-Zeiten auch zugleich, und zwar", "tokens": ["Die", "Jah\u00b7res\u00b7Zei\u00b7ten", "auch", "zu\u00b7gleich", ",", "und", "zwar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "$,", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Auf einmahl, f\u00fchlt und sieht.", "tokens": ["Auf", "ein\u00b7mahl", ",", "f\u00fchlt", "und", "sieht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Erwege die\u00df mit Lust und Andacht, mein Gem\u00fcth!", "tokens": ["Er\u00b7we\u00b7ge", "die\u00df", "mit", "Lust", "und", "An\u00b7dacht", ",", "mein", "Ge\u00b7m\u00fcth", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "APPR", "NN", "KON", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es lassen des Geb\u00fcrgs so rauh- als sch\u00f6ne H\u00f6hen", "tokens": ["Es", "las\u00b7sen", "des", "Ge\u00b7b\u00fcrgs", "so", "rauh", "als", "sch\u00f6\u00b7ne", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Bild von irdischen Verwirrungen uns sehen:", "tokens": ["Ein", "Bild", "von", "ir\u00b7di\u00b7schen", "Ver\u00b7wir\u00b7run\u00b7gen", "uns", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Indem ja Freud' und Leid, und Schertz und Schmertz auf Erden,", "tokens": ["In\u00b7dem", "ja", "Freud'", "und", "Leid", ",", "und", "Schertz", "und", "Schmertz", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KON", "NN", "$,", "KON", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie Lust und Grauen hier, vereint gefunden werden.", "tokens": ["Wie", "Lust", "und", "Grau\u00b7en", "hier", ",", "ver\u00b7eint", "ge\u00b7fun\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "$,", "VVPP", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Allein, was seh' ich ferner hier", "tokens": ["Al\u00b7lein", ",", "was", "seh'", "ich", "fer\u00b7ner", "hier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey dieses Berges rauher Zier?", "tokens": ["Bey", "die\u00b7ses", "Ber\u00b7ges", "rau\u00b7her", "Zier", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was m\u00fcssen nicht f\u00fcr Reichthum, welchen Segen", "tokens": ["Was", "m\u00fcs\u00b7sen", "nicht", "f\u00fcr", "Reicht\u00b7hum", ",", "wel\u00b7chen", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VMFIN", "PTKNEG", "APPR", "NN", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von Marmor und Metall", "tokens": ["Von", "Mar\u00b7mor", "und", "Me\u00b7tall"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Berge B\u00e4uche hegen!", "tokens": ["Der", "Ber\u00b7ge", "B\u00e4u\u00b7che", "he\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Kann ich doch \u00fcberall", "tokens": ["Kann", "ich", "doch", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Den sch\u00f6nsten Marmor-Stein, in grossen St\u00fccken,", "tokens": ["Den", "sch\u00f6ns\u00b7ten", "Mar\u00b7mor\u00b7Stein", ",", "in", "gros\u00b7sen", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "So gar schon auf der Fl\u00e4ch', erblicken!", "tokens": ["So", "gar", "schon", "auf", "der", "Fl\u00e4ch'", ",", "er\u00b7bli\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "ART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wie gl\u00e4ntzet dieser hier, als w\u00e4r' er schon polirt!", "tokens": ["Wie", "gl\u00e4nt\u00b7zet", "die\u00b7ser", "hier", ",", "als", "w\u00e4r'", "er", "schon", "po\u00b7lirt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PDS", "ADV", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie bunt ist jener dort! Ich kann mich nicht enthalten,", "tokens": ["Wie", "bunt", "ist", "je\u00b7ner", "dort", "!", "Ich", "kann", "mich", "nicht", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PDS", "ADV", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der unterschiedlichen unz\u00e4hligen Gestalten", "tokens": ["Der", "un\u00b7ter\u00b7schied\u00b7li\u00b7chen", "un\u00b7z\u00e4h\u00b7li\u00b7gen", "Ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und Farben Meng' im Marmor zu besehn,", "tokens": ["Und", "Far\u00b7ben", "Meng'", "im", "Mar\u00b7mor", "zu", "be\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und, in der drob versp\u00fcrten Augen-Lust,", "tokens": ["Und", ",", "in", "der", "drob", "ver\u00b7sp\u00fcr\u00b7ten", "Au\u00b7gen\u00b7Lust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Mit inniglich dadurch ger\u00fchrter Brust,", "tokens": ["Mit", "in\u00b7nig\u00b7lich", "da\u00b7durch", "ge\u00b7r\u00fchr\u00b7ter", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Ein all-erschaffendes allm\u00e4cht'ges Wunder-Wesen,", "tokens": ["Ein", "all\u00b7er\u00b7schaf\u00b7fen\u00b7des", "all\u00b7m\u00e4cht'\u00b7ges", "Wun\u00b7der\u00b7We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ohn' Dem nichts ist, was ist, bewundernd zu erh\u00f6hn.", "tokens": ["Ohn'", "Dem", "nichts", "ist", ",", "was", "ist", ",", "be\u00b7wun\u00b7dernd", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "VAFIN", "$,", "PWS", "VAFIN", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Man kann allhier, sowohl vermischt, als eintzeln, sch\u00f6n,", "tokens": ["Man", "kann", "all\u00b7hier", ",", "so\u00b7wohl", "ver\u00b7mischt", ",", "als", "eint\u00b7zeln", ",", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "$,", "KON", "VVPP", "$,", "KOUS", "VVINF", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(ob wir gleich von der Schrift den Inhalt nicht verstehn)", "tokens": ["(", "ob", "wir", "gleich", "von", "der", "Schrift", "den", "In\u00b7halt", "nicht", "ver\u00b7stehn", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch in gebrochnen Lettern lesen,", "tokens": ["Auch", "in", "ge\u00b7broch\u00b7nen", "Let\u00b7tern", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df, was geschrieben, sey, den Sch\u00f6pfer anzuweisen,", "tokens": ["Da\u00df", ",", "was", "ge\u00b7schrie\u00b7ben", ",", "sey", ",", "den", "Sch\u00f6p\u00b7fer", "an\u00b7zu\u00b7wei\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "VVPP", "$,", "VAFIN", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Um auch, im Marmor-Stein, sein Wunder-Werck zu preisen.", "tokens": ["Um", "auch", ",", "im", "Mar\u00b7mor\u00b7Stein", ",", "sein", "Wun\u00b7der\u00b7\u00b7Werck", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "$,", "APPRART", "NN", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man kann, in tausendfach ver\u00e4nderlichen Z\u00fcgen,", "tokens": ["Man", "kann", ",", "in", "tau\u00b7send\u00b7fach", "ver\u00b7\u00e4n\u00b7der\u00b7li\u00b7chen", "Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die sich bald trennen und bald f\u00fcgen,", "tokens": ["Die", "sich", "bald", "tren\u00b7nen", "und", "bald", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "VVINF", "KON", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Allhier ein tausendfach vermischtes Etwas sehn,", "tokens": ["All\u00b7hier", "ein", "tau\u00b7send\u00b7fach", "ver\u00b7mischtes", "Et\u00b7was", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "ADJA", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Worin die spielende gesch\u00e4fftige Natur", "tokens": ["Wo\u00b7rin", "die", "spie\u00b7len\u00b7de", "ge\u00b7sch\u00e4ff\u00b7ti\u00b7ge", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So manche Bildungs-Art, und seltsame Figur,", "tokens": ["So", "man\u00b7che", "Bil\u00b7dungs\u00b7Art", ",", "und", "selt\u00b7sa\u00b7me", "Fi\u00b7gur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die in dem bunten Stein, zwar wunderlich, doch sch\u00f6n", "tokens": ["Die", "in", "dem", "bun\u00b7ten", "Stein", ",", "zwar", "wun\u00b7der\u00b7lich", ",", "doch", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Verstreuet und vereint, so durch einander gehn,", "tokens": ["Ver\u00b7streu\u00b7et", "und", "ver\u00b7eint", ",", "so", "durch", "ein\u00b7an\u00b7der", "gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "$,", "ADV", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da\u00df es das Aug' ergetzt; den Augen vorgestellt.", "tokens": ["Da\u00df", "es", "das", "Aug'", "er\u00b7getzt", ";", "den", "Au\u00b7gen", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$.", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Es sind so viel verworrene Figuren", "tokens": ["Es", "sind", "so", "viel", "ver\u00b7wor\u00b7re\u00b7ne", "Fi\u00b7gu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Theils halb-theils gantzer Creaturen,", "tokens": ["Theils", "halb\u00b7theils", "gant\u00b7zer", "Crea\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "So viele Mischungen von klein- und grossen St\u00fccken,", "tokens": ["So", "vie\u00b7le", "Misc\u00b7hun\u00b7gen", "von", "klein", "und", "gros\u00b7sen", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vereint und nicht vereint, im Marmor zu erblicken;", "tokens": ["Ver\u00b7eint", "und", "nicht", "ver\u00b7eint", ",", "im", "Mar\u00b7mor", "zu", "er\u00b7bli\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "PTKNEG", "VVPP", "$,", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df, so von Form als Farb', auch er ein Chaos scheint,", "tokens": ["Da\u00df", ",", "so", "von", "Form", "als", "Fa\u00b7rb'", ",", "auch", "er", "ein", "Chaos", "scheint", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "APPR", "NN", "KOUS", "NN", "$,", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das etwan auf einmahl erstarrt sey und versteint.", "tokens": ["Das", "et\u00b7wan", "auf", "ein\u00b7mahl", "er\u00b7starrt", "sey", "und", "ver\u00b7steint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ADV", "VVPP", "VAFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Hier sieht man stille Wirbel sich,", "tokens": ["Hier", "sieht", "man", "stil\u00b7le", "Wir\u00b7bel", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort trockne Strudel gleichsam regen.", "tokens": ["Dort", "trock\u00b7ne", "Stru\u00b7del", "gleich\u00b7sam", "re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hier scheinen sich die Wellen eigentlich,", "tokens": ["Hier", "schei\u00b7nen", "sich", "die", "Wel\u00b7len", "ei\u00b7gent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ohn' da\u00df sie sich bewegen, zu bewegen.", "tokens": ["Ohn'", "da\u00df", "sie", "sich", "be\u00b7we\u00b7gen", ",", "zu", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PRF", "VVINF", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Bald stellt der Marmor B\u00e4um' und Thier',", "tokens": ["Bald", "stellt", "der", "Mar\u00b7mor", "B\u00e4um'", "und", "Thier'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und bald gebrochne Stein' und Ertz nat\u00fcrlich f\u00fcr.", "tokens": ["Und", "bald", "ge\u00b7broch\u00b7ne", "Stein'", "und", "Ertz", "na\u00b7t\u00fcr\u00b7lich", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "KON", "NN", "ADV", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Oft scheint ein rother Marmor-Stein", "tokens": ["Oft", "scheint", "ein", "ro\u00b7ther", "Mar\u00b7mor\u00b7Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zu Stein geword'nes Fleisch zu seyn.", "tokens": ["Zu", "Stein", "ge\u00b7word'\u00b7nes", "Fleisch", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Viel grosse Adern sind mit kleinern oft durchkrochen,", "tokens": ["Viel", "gros\u00b7se", "A\u00b7dern", "sind", "mit", "klei\u00b7nern", "oft", "durch\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "APPR", "ADJA", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die, eintzeln bald, und bald mit Haufen,", "tokens": ["Die", ",", "eint\u00b7zeln", "bald", ",", "und", "bald", "mit", "Hau\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVFIN", "ADV", "$,", "KON", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Bald an- und in-, bald durch einander laufen,", "tokens": ["Bald", "an", "und", "in", ",", "bald", "durch", "ein\u00b7an\u00b7der", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "KON", "TRUNC", "$,", "ADV", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Woraus so mancherley Figur und Form entsteht.", "tokens": ["Wo\u00b7raus", "so", "man\u00b7cher\u00b7ley", "Fi\u00b7gur", "und", "Form", "ent\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die sch\u00f6nen Farben sind auf tausend Art gebrochen,", "tokens": ["Die", "sch\u00f6\u00b7nen", "Far\u00b7ben", "sind", "auf", "tau\u00b7send", "Art", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auf tausend Art gemischt, vertiefet und erh\u00f6ht,", "tokens": ["Auf", "tau\u00b7send", "Art", "ge\u00b7mischt", ",", "ver\u00b7tie\u00b7fet", "und", "er\u00b7h\u00f6ht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVPP", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bald hell und bald ged\u00e4mpft, bald feurig und bald matt.", "tokens": ["Bald", "hell", "und", "bald", "ge\u00b7d\u00e4mpft", ",", "bald", "feu\u00b7rig", "und", "bald", "matt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "VVPP", "$,", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Es sind sowohl die Meng', als Graden nicht zu z\u00e4hlen.", "tokens": ["Es", "sind", "so\u00b7wohl", "die", "Meng'", ",", "als", "Gra\u00b7den", "nicht", "zu", "z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "ART", "NN", "$,", "KOUS", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch wird es ihnen nie an einem Firni\u00df fehlen,", "tokens": ["Auch", "wird", "es", "ih\u00b7nen", "nie", "an", "ei\u00b7nem", "Fir\u00b7ni\u00df", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als der mit ihnen w\u00e4chst, und der ihm einverleibt.", "tokens": ["Als", "der", "mit", "ih\u00b7nen", "w\u00e4chst", ",", "und", "der", "ihm", "ein\u00b7ver\u00b7leibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPER", "VVFIN", "$,", "KON", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn, eben da\u00df er glatt,", "tokens": ["Denn", ",", "e\u00b7ben", "da\u00df", "er", "glatt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "KOUS", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Vermehret seinen Werth, erhebet seinen Preis.", "tokens": ["Ver\u00b7meh\u00b7ret", "sei\u00b7nen", "Werth", ",", "er\u00b7he\u00b7bet", "sei\u00b7nen", "Preis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "So bald man nur das rauhe von ihm reibt,", "tokens": ["So", "bald", "man", "nur", "das", "rau\u00b7he", "von", "ihm", "reibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ADV", "ART", "ADJA", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie solches hier des K\u00fcnstlers Flei\u00df", "tokens": ["Wie", "sol\u00b7ches", "hier", "des", "K\u00fcnst\u00b7lers", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Recht k\u00fcnstlich zu verrichten weis;", "tokens": ["Recht", "k\u00fcnst\u00b7lich", "zu", "ver\u00b7rich\u00b7ten", "weis", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So ist kein Spiegel-Glas so gl\u00e4ntzend und so rein,", "tokens": ["So", "ist", "kein", "Spie\u00b7gel\u00b7Glas", "so", "gl\u00e4nt\u00b7zend", "und", "so", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als wie, in Blanckenburgs polirtem Marmor-Stein,", "tokens": ["Als", "wie", ",", "in", "Blan\u00b7cken\u00b7burgs", "po\u00b7lir\u00b7tem", "Mar\u00b7mor\u00b7Stein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "$,", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die abgeschliff'nen Fl\u00e4chen seyn.", "tokens": ["Die", "ab\u00b7ge\u00b7schliff'\u00b7nen", "Fl\u00e4\u00b7chen", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Wie oft hab ich in ihm, als wie im reinsten Spiegel,", "tokens": ["Wie", "oft", "hab", "ich", "in", "ihm", ",", "als", "wie", "im", "reins\u00b7ten", "Spie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "APPR", "PPER", "$,", "KOUS", "KOKOM", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Geb\u00fcsche, Feld und Wald, und Thal, und Berg' und H\u00fcgel,", "tokens": ["Ge\u00b7b\u00fc\u00b7sche", ",", "Feld", "und", "Wald", ",", "und", "Thal", ",", "und", "Ber\u00b7g'", "und", "H\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ja gar, mit inniglichen Freuden,", "tokens": ["Ja", "gar", ",", "mit", "in\u00b7nig\u00b7li\u00b7chen", "Freu\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Bald im verwachs'nen Thal, bald auf den steilen H\u00f6h'n,", "tokens": ["Bald", "im", "ver\u00b7wachs'\u00b7nen", "Thal", ",", "bald", "auf", "den", "stei\u00b7len", "H\u00f6h'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch meine liebste Heerde weiden,", "tokens": ["Auch", "mei\u00b7ne", "liebs\u00b7te", "Heer\u00b7de", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und meine Ziegen klettern sehn.", "tokens": ["Und", "mei\u00b7ne", "Zie\u00b7gen", "klet\u00b7tern", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Man kann, in Blanckenburgs Geb\u00fcrg- und ihren Gr\u00fcnden,", "tokens": ["Man", "kann", ",", "in", "Blan\u00b7cken\u00b7burgs", "Ge\u00b7b\u00fcr\u00b7g", "und", "ih\u00b7ren", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,", "APPR", "NE", "TRUNC", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von allen Farben Marmor finden,", "tokens": ["Von", "al\u00b7len", "Far\u00b7ben", "Mar\u00b7mor", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So wie man ihn verlangt:", "tokens": ["So", "wie", "man", "ihn", "ver\u00b7langt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da bald ein helles Wei\u00df im rothen Grunde prangt;", "tokens": ["Da", "bald", "ein", "hel\u00b7les", "Wei\u00df", "im", "ro\u00b7then", "Grun\u00b7de", "prangt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da er bald braun, bald schwartz, vermischt mit wei\u00df und grau,", "tokens": ["Da", "er", "bald", "braun", ",", "bald", "schwartz", ",", "ver\u00b7mischt", "mit", "wei\u00df", "und", "grau", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "VVFIN", "APPR", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald gelb und gr\u00fcn so gar,", "tokens": ["Bald", "gelb", "und", "gr\u00fcn", "so", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "(das, selbst in Griechenland und Welschland, Wunderrar)", "tokens": ["(", "das", ",", "selbst", "in", "Grie\u00b7chen\u00b7land", "und", "Wel\u00b7schland", ",", "Wun\u00b7der\u00b7rar", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PDS", "$,", "ADV", "APPR", "NE", "KON", "NN", "$,", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald bunt gesprenget ist, mit roth, mit gr\u00fcn und blau.", "tokens": ["Bald", "bunt", "ge\u00b7spren\u00b7get", "ist", ",", "mit", "roth", ",", "mit", "gr\u00fcn", "und", "blau", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "$,", "APPR", "ADJD", "$,", "APPR", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Wer bildet nun des Marmors bunte Pracht?", "tokens": ["Wer", "bil\u00b7det", "nun", "des", "Mar\u00b7mors", "bun\u00b7te", "Pracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer hat die Felsen selbst so sch\u00f6n, so glatt gemacht?", "tokens": ["Wer", "hat", "die", "Fel\u00b7sen", "selbst", "so", "sch\u00f6n", ",", "so", "glatt", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Derselbe, der der bunten Bluhmen Zier", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "der", "bun\u00b7ten", "Bluh\u00b7men", "Zier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So Wunder-w\u00fcrdig f\u00e4rbt, der f\u00e4rbet gleichfalls hier,", "tokens": ["So", "Wun\u00b7der\u00b7w\u00fcr\u00b7dig", "f\u00e4rbt", ",", "der", "f\u00e4r\u00b7bet", "gleich\u00b7falls", "hier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu unsrer Augen-Lust, den Sand, und schm\u00fcckt den Stein", "tokens": ["Zu", "uns\u00b7rer", "Au\u00b7gen\u00b7Lust", ",", "den", "Sand", ",", "und", "schm\u00fcckt", "den", "Stein"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit tausend-f\u00e4rbigen Figuren, Glantz und Schein.", "tokens": ["Mit", "tau\u00b7sen\u00b7df\u00e4r\u00b7bi\u00b7gen", "Fi\u00b7gu\u00b7ren", ",", "Glantz", "und", "Schein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und eben Der verlieh' auch uns den Witz,", "tokens": ["Und", "e\u00b7ben", "Der", "ver\u00b7lieh'", "auch", "uns", "den", "Witz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "VVFIN", "ADV", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denselbigen so k\u00fcnstlich zu poliren,", "tokens": ["Den\u00b7sel\u00b7bi\u00b7gen", "so", "k\u00fcnst\u00b7lich", "zu", "po\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+--", "measure": "anapaest.tri.plus"}, "line.9": {"text": "Da er ja sonsten uns zu nichtes n\u00fctz'.", "tokens": ["Da", "er", "ja", "sons\u00b7ten", "uns", "zu", "nich\u00b7tes", "n\u00fctz'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "PPER", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wie sollte denn auch daf\u00fcr nicht", "tokens": ["Wie", "soll\u00b7te", "denn", "auch", "da\u00b7f\u00fcr", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ADV", "ADV", "PAV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der Allmacht, ohne die nichts, was geschicht, geschicht,", "tokens": ["Der", "All\u00b7macht", ",", "oh\u00b7ne", "die", "nichts", ",", "was", "ge\u00b7schicht", ",", "ge\u00b7schicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUI", "ART", "PIS", "$,", "PRELS", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Erkenntlichkeit und Danck geb\u00fchren?", "tokens": ["Er\u00b7kennt\u00b7lich\u00b7keit", "und", "Danck", "ge\u00b7b\u00fch\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Wir sollten billig nie den Blick", "tokens": ["Wir", "soll\u00b7ten", "bil\u00b7lig", "nie", "den", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf den so sch\u00f6n- und bunten Marmor lencken;", "tokens": ["Auf", "den", "so", "sch\u00f6n", "und", "bun\u00b7ten", "Mar\u00b7mor", "len\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "TRUNC", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ohn' auf die Kraft, die ihn formirt, zur\u00fcck,", "tokens": ["Ohn'", "auf", "die", "Kraft", ",", "die", "ihn", "for\u00b7mirt", ",", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "PTKVZ", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Bey unsrer Augen-Lust, zu dencken.", "tokens": ["Bey", "uns\u00b7rer", "Au\u00b7gen\u00b7Lust", ",", "zu", "den\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "O! welch ein Schatz demnach, der nicht zu sch\u00e4tzen,", "tokens": ["O", "!", "welch", "ein", "Schatz", "dem\u00b7nach", ",", "der", "nicht", "zu", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAT", "ART", "NN", "PAV", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So wohl zum Nutzen als Ergetzen,", "tokens": ["So", "wohl", "zum", "Nut\u00b7zen", "als", "Er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "KOUS", "NN", "$,"], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zur Zier und mancherley Gebrauch,", "tokens": ["Zur", "Zier", "und", "man\u00b7cher\u00b7ley", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Liegt hier in dieses Berges Bauch!", "tokens": ["Liegt", "hier", "in", "die\u00b7ses", "Ber\u00b7ges", "Bauch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer wird doch alle Dinge nennen,", "tokens": ["Wer", "wird", "doch", "al\u00b7le", "Din\u00b7ge", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Beschreiben und erz\u00e4hlen k\u00f6nnen,", "tokens": ["Be\u00b7schrei\u00b7ben", "und", "er\u00b7z\u00e4h\u00b7len", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die man, so wohl zur Dauer, als zur Pracht,", "tokens": ["Die", "man", ",", "so", "wohl", "zur", "Dau\u00b7er", ",", "als", "zur", "Pracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "ADV", "ADV", "APPRART", "NN", "$,", "KOUS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Aus Blanckenburgs polirtem Marmor macht!", "tokens": ["Aus", "Blan\u00b7cken\u00b7burgs", "po\u00b7lir\u00b7tem", "Mar\u00b7mor", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Der Himmel solchen Schatz gesenckt,", "tokens": ["Der", "Him\u00b7mel", "sol\u00b7chen", "Schatz", "ge\u00b7senckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und solchen Marmor dir geschenckt,", "tokens": ["Und", "sol\u00b7chen", "Mar\u00b7mor", "dir", "ge\u00b7schenckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich in Welschland selbst nicht seines gleichen finde,", "tokens": ["Da\u00df", "ich", "in", "Wel\u00b7schland", "selbst", "nicht", "sei\u00b7nes", "glei\u00b7chen", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "PTKNEG", "PPOSAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Selbst der, den Paros zeugt, kann ihm, an Glantz, nicht gleichen,", "tokens": ["Selbst", "der", ",", "den", "Pa\u00b7ros", "zeugt", ",", "kann", "ihm", ",", "an", "Glantz", ",", "nicht", "glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "ART", "NN", "VVFIN", "$,", "VMFIN", "PPER", "$,", "APPR", "NN", "$,", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und der, aus Tenarus, mu\u00df ihm, an Farben, weichen:", "tokens": ["Und", "der", ",", "aus", "Ten\u00b7a\u00b7rus", ",", "mu\u00df", "ihm", ",", "an", "Far\u00b7ben", ",", "wei\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "$,", "APPR", "NE", "$,", "VMFIN", "PPER", "$,", "APPR", "NN", "$,", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Da er, von Jaspis hier, und dorten von Achat,", "tokens": ["Da", "er", ",", "von", "Jas\u00b7pis", "hier", ",", "und", "dor\u00b7ten", "von", "A\u00b7chat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "NE", "ADV", "$,", "KON", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den Glantz, die Farb' und Adern hat.", "tokens": ["Den", "Glantz", ",", "die", "Fa\u00b7rb'", "und", "A\u00b7dern", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Was sag' ich? ja bey dem, da er so sch\u00f6n geziert,", "tokens": ["Was", "sag'", "ich", "?", "ja", "bey", "dem", ",", "da", "er", "so", "sch\u00f6n", "ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "ADV", "APPR", "ART", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "So Jaspis, als Achat selbst seinen Preis verliert.", "tokens": ["So", "Jas\u00b7pis", ",", "als", "A\u00b7chat", "selbst", "sei\u00b7nen", "Preis", "ver\u00b7liert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "KOUS", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Dein ietziger Beherrscher ist es werth,", "tokens": ["Dein", "iet\u00b7zi\u00b7ger", "Be\u00b7herr\u00b7scher", "ist", "es", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "(ich sag' es ohne Schmeicheley)", "tokens": ["(", "ich", "sag'", "es", "oh\u00b7ne", "Schmei\u00b7che\u00b7ley", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Ihm ein solches Land beschert,", "tokens": ["Da\u00df", "Ihm", "ein", "sol\u00b7ches", "Land", "be\u00b7schert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Woselbst, um Sein Verdienst (das nie genug zu sch\u00e4tzen)", "tokens": ["Wo\u00b7selbst", ",", "um", "Sein", "Ver\u00b7dienst", "(", "das", "nie", "ge\u00b7nug", "zu", "sch\u00e4t\u00b7zen", ")"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUI", "PPOSAT", "NN", "$(", "PDS", "ADV", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In festen Marmor einzu\u00e4tzen,", "tokens": ["In", "fes\u00b7ten", "Mar\u00b7mor", "ein\u00b7zu\u00b7\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "An Marmor kein Gebrechen sey.", "tokens": ["An", "Mar\u00b7mor", "kein", "Ge\u00b7bre\u00b7chen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Ist ehedem ein Berg, wie ich einmahl gelesen,", "tokens": ["Ist", "e\u00b7he\u00b7dem", "ein", "Berg", ",", "wie", "ich", "ein\u00b7mahl", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zur Bild-Seul' einem Helden dort,", "tokens": ["Zur", "Bild\u00b7Seul'", "ei\u00b7nem", "Hel\u00b7den", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Nachruhm, zugedacht gewesen;", "tokens": ["Zum", "Nach\u00b7ruhm", ",", "zu\u00b7ge\u00b7dacht", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So ist ja wohl kein bess'rer Ort,", "tokens": ["So", "ist", "ja", "wohl", "kein", "bess'\u00b7rer", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Um diesem Herrn ein Ehren-Mahl zu bauen,", "tokens": ["Um", "die\u00b7sem", "Herrn", "ein", "Eh\u00b7ren\u00b7Mahl", "zu", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als jenen Marmor-Berg, den wir dort vor uns schauen,", "tokens": ["Als", "je\u00b7nen", "Mar\u00b7mor\u00b7Berg", ",", "den", "wir", "dort", "vor", "uns", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "PRELS", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Der Seine Wohnung tr\u00e4gt, f\u00fcr Ihn zurecht zu hauen.", "tokens": ["Der", "Sei\u00b7ne", "Woh\u00b7nung", "tr\u00e4gt", ",", "f\u00fcr", "Ihn", "zu\u00b7recht", "zu", "hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,", "APPR", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Wie wenig F\u00fcrsten sind auf Erden,", "tokens": ["Wie", "we\u00b7nig", "F\u00fcrs\u00b7ten", "sind", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die von den Unterthanen mehr", "tokens": ["Die", "von", "den", "Un\u00b7ter\u00b7tha\u00b7nen", "mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geliebet, als gef\u00fcrchtet werden!", "tokens": ["Ge\u00b7lie\u00b7bet", ",", "als", "ge\u00b7f\u00fcrch\u00b7tet", "wer\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie wenig sind geschickt, ein Krieges-Heer", "tokens": ["Wie", "we\u00b7nig", "sind", "ge\u00b7schickt", ",", "ein", "Krie\u00b7ge\u00b7sHeer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PIS", "VAFIN", "VVPP", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mit eig'nem Vorgang anzuf\u00fchren!", "tokens": ["Mit", "eig'\u00b7nem", "Vor\u00b7gang", "an\u00b7zu\u00b7f\u00fch\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie wenig F\u00fcrsten sind, die selbst regieren!", "tokens": ["Wie", "we\u00b7nig", "F\u00fcrs\u00b7ten", "sind", ",", "die", "selbst", "re\u00b7gie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "$,", "PRELS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Bey denen Fr\u00f6mmigkeit sich mit der Staats-Kunst paart", "tokens": ["Bey", "de\u00b7nen", "Fr\u00f6m\u00b7mig\u00b7keit", "sich", "mit", "der", "Staats\u00b7Kunst", "paart"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "NN", "PRF", "APPR", "ART", "NN", "NE"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Wie selten ist ein F\u00fcrst, der im Gelehrten Orden,", "tokens": ["Wie", "sel\u00b7ten", "ist", "ein", "F\u00fcrst", ",", "der", "im", "Ge\u00b7lehr\u00b7ten", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Auf Schwartzburgs G\u00fcnthers Art,", "tokens": ["Auf", "Schwartz\u00b7burgs", "G\u00fcn\u00b7thers", "Art", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Zum Mitglied nicht allein, zum Wunder worden,", "tokens": ["Zum", "Mit\u00b7glied", "nicht", "al\u00b7lein", ",", "zum", "Wun\u00b7der", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKNEG", "ADV", "$,", "APPRART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.12": {"text": "Den selbst der Sechste ", "tokens": ["Den", "selbst", "der", "Sechs\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.39": {"line.1": {"text": "Wer z\u00e4hlt die Tugenden, die gleichfalls sonder Zahl,", "tokens": ["Wer", "z\u00e4hlt", "die", "Tu\u00b7gen\u00b7den", ",", "die", "gleich\u00b7falls", "son\u00b7der", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An Dessen w\u00fcrd'gem Eh-Gemahl,", "tokens": ["An", "Des\u00b7sen", "w\u00fcrd'\u00b7gem", "Eh\u00b7Ge\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der theuersten ", "tokens": ["Der", "theu\u00b7ers\u00b7ten"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Die so, wie Er den F\u00fcrsten, den F\u00fcrstinnen", "tokens": ["Die", "so", ",", "wie", "Er", "den", "F\u00fcrs\u00b7ten", ",", "den", "F\u00fcrs\u00b7tin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADV", "$,", "PWAV", "PPER", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Von je her sich mit Recht zu einem Muster wiese;", "tokens": ["Von", "je", "her", "sich", "mit", "Recht", "zu", "ei\u00b7nem", "Mus\u00b7ter", "wie\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "PRF", "APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und die, nicht nur ihr Unterthan,", "tokens": ["Und", "die", ",", "nicht", "nur", "ihr", "Un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PTKNEG", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein jeder, er sey fern und nah,", "tokens": ["Ein", "je\u00b7der", ",", "er", "sey", "fern", "und", "nah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "PPER", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Der Sie nur einmahl sah,", "tokens": ["Der", "Sie", "nur", "ein\u00b7mahl", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Mit Ehrfurchts-voller Lieb', als unvergleichlich, priese.", "tokens": ["Mit", "Ehr\u00b7furchts\u00b7vol\u00b7ler", "Lieb'", ",", "als", "un\u00b7ver\u00b7gleich\u00b7lich", ",", "prie\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "KOUS", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was hab' ich nicht, eh' ich den Hof verlassen,", "tokens": ["Was", "hab'", "ich", "nicht", ",", "eh'", "ich", "den", "Hof", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Um mit dem Hirten-Stab die Ruh' hier zu umfassen,", "tokens": ["Um", "mit", "dem", "Hir\u00b7ten\u00b7Stab", "die", "Ruh'", "hier", "zu", "um\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von Ihrem Hohen Geist gesehen und geh\u00f6rt!", "tokens": ["Von", "Ih\u00b7rem", "Ho\u00b7hen", "Geist", "ge\u00b7se\u00b7hen", "und", "ge\u00b7h\u00f6rt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was hat Sie nicht, durch Gro\u00dfmuth angetrieben,", "tokens": ["Was", "hat", "Sie", "nicht", ",", "durch", "Gro\u00df\u00b7muth", "an\u00b7ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Zum Heil des Teutschen Reichs, mit eig'ner Hand geschrieben!", "tokens": ["Zum", "Heil", "des", "Teut\u00b7schen", "Reichs", ",", "mit", "eig'\u00b7ner", "Hand", "ge\u00b7schrie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Wie wird nicht dieses Paar in Ost und West geehrt!", "tokens": ["Wie", "wird", "nicht", "die\u00b7ses", "Paar", "in", "Ost", "und", "West", "ge\u00b7ehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PTKNEG", "PDAT", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht Teutschland nur, Europa w\u00fcnschet ihnen,", "tokens": ["Nicht", "Teutschland", "nur", ",", "Eu\u00b7ro\u00b7pa", "w\u00fcn\u00b7schet", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "ADV", "$,", "NE", "VVFIN", "PPER", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Absonderlich f\u00fcr die so sch\u00f6ne Kaiserinn,", "tokens": ["Ab\u00b7son\u00b7der\u00b7lich", "f\u00fcr", "die", "so", "sch\u00f6\u00b7ne", "Kai\u00b7se\u00b7rinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So Sie der Welt geschenckt, aus Danck-erf\u00fclltem Sinn,", "tokens": ["So", "Sie", "der", "Welt", "ge\u00b7schenckt", ",", "aus", "Dan\u00b7ck\u00b7er\u00b7f\u00fcll\u00b7tem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Damit sie lange noch in stetem Gl\u00fccke gr\u00fcnen:", "tokens": ["Da\u00b7mit", "sie", "lan\u00b7ge", "noch", "in", "ste\u00b7tem", "Gl\u00fc\u00b7cke", "gr\u00fc\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Himmel, la\u00df es doch geschehn,", "tokens": ["Him\u00b7mel", ",", "la\u00df", "es", "doch", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df Ihr f\u00fcrstlich Wohlergehn,", "tokens": ["Da\u00df", "Ihr", "f\u00fcrst\u00b7lich", "Woh\u00b7ler\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An der Dauer, Marmor gleiche!", "tokens": ["An", "der", "Dau\u00b7er", ",", "Mar\u00b7mor", "glei\u00b7che", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df die\u00df theure F\u00fcrsten-Paar", "tokens": ["Da\u00df", "die\u00df", "theu\u00b7re", "F\u00fcrs\u00b7ten\u00b7Paar"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PDS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Noch ein oft vervielfacht Jahr,", "tokens": ["Noch", "ein", "oft", "ver\u00b7viel\u00b7facht", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADV", "VVPP", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ja das sp\u00e4tste Ziel erreiche,", "tokens": ["Ja", "das", "sp\u00e4ts\u00b7te", "Ziel", "er\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "So allhier, in diesem Leben", "tokens": ["So", "all\u00b7hier", ",", "in", "die\u00b7sem", "Le\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "APPR", "PDAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Einem Sterblichen gegeben!", "tokens": ["Ei\u00b7nem", "Sterb\u00b7li\u00b7chen", "ge\u00b7ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Kaum kam Beraldo mit dem Lesen", "tokens": ["Kaum", "kam", "Be\u00b7ral\u00b7do", "mit", "dem", "Le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So weit; als ihn Silvander unterbrach,", "tokens": ["So", "weit", ";", "als", "ihn", "Sil\u00b7van\u00b7der", "un\u00b7ter\u00b7brach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und, voller Freuden, rief und sprach:", "tokens": ["Und", ",", "vol\u00b7ler", "Freu\u00b7den", ",", "rief", "und", "sprach", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJA", "NN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie lieb, Beraldo, ist es mir,", "tokens": ["Wie", "lieb", ",", "Be\u00b7ral\u00b7do", ",", "ist", "es", "mir", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "NE", "$,", "VAFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Teutschlands Ehre, Ruhm und Zier,", "tokens": ["Da\u00df", "Teutschlands", "Eh\u00b7re", ",", "Ruhm", "und", "Zier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fcrst, ", "tokens": ["F\u00fcrst", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Ein Vorwurf deines Kiels gewesen!", "tokens": ["Ein", "Vor\u00b7wurf", "dei\u00b7nes", "Kiels", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auch ich hab' gestern Nachmittag,", "tokens": ["Auch", "ich", "hab'", "ge\u00b7stern", "Nach\u00b7mit\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "(indem ich es mir l\u00e4ngstens vorgenommen)", "tokens": ["(", "in\u00b7dem", "ich", "es", "mir", "l\u00e4ngs\u00b7tens", "vor\u00b7ge\u00b7nom\u00b7men", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "In einem Liede viel von Seinem Ruhm erz\u00e4hlt,", "tokens": ["In", "ei\u00b7nem", "Lie\u00b7de", "viel", "von", "Sei\u00b7nem", "Ruhm", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So ich dir zeigen will, wann wir zur\u00fcck gekommen.", "tokens": ["So", "ich", "dir", "zei\u00b7gen", "will", ",", "wann", "wir", "zu\u00b7r\u00fcck", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPER", "VVINF", "VMFIN", "$,", "PWAV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und, weil daran nichts, als der Schlu\u00df, noch fehlt,", "tokens": ["Und", ",", "weil", "da\u00b7ran", "nichts", ",", "als", "der", "Schlu\u00df", ",", "noch", "fehlt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PAV", "PIS", "$,", "KOUS", "ART", "NN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So wirst du, auf mein Bitten,", "tokens": ["So", "wirst", "du", ",", "auf", "mein", "Bit\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "In meiner Schatten-reichen H\u00fctten,", "tokens": ["In", "mei\u00b7ner", "Schat\u00b7ten\u00b7rei\u00b7chen", "H\u00fct\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "F\u00fcr Sein lang daurendes Vergn\u00fcgen,", "tokens": ["F\u00fcr", "Sein", "lang", "dau\u00b7ren\u00b7des", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Auch deinen Wunsch zu meinem f\u00fcgen.", "tokens": ["Auch", "dei\u00b7nen", "Wunsch", "zu", "mei\u00b7nem", "f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Sodann, und eher nicht, will ich, was auf das Eisen", "tokens": ["So\u00b7dann", ",", "und", "e\u00b7her", "nicht", ",", "will", "ich", ",", "was", "auf", "das", "Ei\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KON", "ADV", "PTKNEG", "$,", "VMFIN", "PPER", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von mir verfertigt ward, unausgesetzt dir weisen.", "tokens": ["Von", "mir", "ver\u00b7fer\u00b7tigt", "ward", ",", "un\u00b7aus\u00b7ge\u00b7setzt", "dir", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$,", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Ja! rief ", "tokens": ["Ja", "!", "rief"], "token_info": ["word", "punct", "word"], "pos": ["PTKANT", "$.", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Und zwar um desto mehr zu dieser Zeit,", "tokens": ["Und", "zwar", "um", "des\u00b7to", "mehr", "zu", "die\u00b7ser", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da mich ein ungewohnt- und froher Trieb will zwingen,", "tokens": ["Da", "mich", "ein", "un\u00b7ge\u00b7wohnt", "und", "fro\u00b7her", "Trieb", "will", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "TRUNC", "KON", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was k\u00fcnftiges, schon zum voraus, zu singen,", "tokens": ["Was", "k\u00fcnf\u00b7ti\u00b7ges", ",", "schon", "zum", "vo\u00b7raus", ",", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJA", "$,", "ADV", "APPRART", "PTKVZ", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie ich wohl eh' gethan:", "tokens": ["Wie", "ich", "wohl", "eh'", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Des Firmaments entw\u00f6lckte B\u00fchne,", "tokens": ["Des", "Fir\u00b7ma\u00b7ments", "ent\u00b7w\u00f6lck\u00b7te", "B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War voller Strahlen, Glantz und Schein:", "tokens": ["War", "vol\u00b7ler", "Strah\u00b7len", ",", "Glantz", "und", "Schein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Quell' des Lichts, die g\u00fcld'ne Sonne, schiene", "tokens": ["Die", "Quell'", "des", "Lichts", ",", "die", "g\u00fcld'\u00b7ne", "Son\u00b7ne", ",", "schie\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Himmels Mittel-Punct zu seyn.", "tokens": ["Des", "Him\u00b7mels", "Mit\u00b7tel\u00b7Punct", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von oben fiel ihr gantz gerader Strahl,", "tokens": ["Von", "o\u00b7ben", "fiel", "ihr", "gantz", "ge\u00b7ra\u00b7der", "Strahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Erhellt' und f\u00fcllete, mit einem strengen Licht',", "tokens": ["Er\u00b7hellt'", "und", "f\u00fcl\u00b7le\u00b7te", ",", "mit", "ei\u00b7nem", "stren\u00b7gen", "Licht'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das sonst best\u00e4ndig k\u00fchl- von Schatten schwartze Thal.", "tokens": ["Das", "sonst", "be\u00b7st\u00e4n\u00b7dig", "k\u00fchl", "von", "Schat\u00b7ten", "schwart\u00b7ze", "Thal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "TRUNC", "APPR", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Luft-Kreis glimmt' und kocht', es lechzte Gras und Laub.", "tokens": ["Der", "Luft\u00b7Kreis", "glimmt'", "und", "kocht'", ",", "es", "lechz\u00b7te", "Gras", "und", "Laub", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,", "PPER", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Silvanders Heerde konnte nicht,", "tokens": ["Sil\u00b7van\u00b7ders", "Heer\u00b7de", "konn\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VMFIN", "PTKNEG", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "In denen fast versengten Heiden,", "tokens": ["In", "de\u00b7nen", "fast", "ver\u00b7seng\u00b7ten", "Hei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "F\u00fcr Mattigkeit und Hitze, l\u00e4nger weiden.", "tokens": ["F\u00fcr", "Mat\u00b7tig\u00b7keit", "und", "Hit\u00b7ze", ",", "l\u00e4n\u00b7ger", "wei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Die Schafe streckten sich in den verbrannten Staub.", "tokens": ["Die", "Scha\u00b7fe", "streck\u00b7ten", "sich", "in", "den", "ver\u00b7brann\u00b7ten", "Staub", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Drum er sie Seiten-w\u00e4rts in einen dicken Wald,", "tokens": ["Drum", "er", "sie", "Sei\u00b7ten\u00b7w\u00e4rts", "in", "ei\u00b7nen", "di\u00b7cken", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der holden K\u00fchlung Sitz, der Schatten Aufenthalt,", "tokens": ["Der", "hol\u00b7den", "K\u00fch\u00b7lung", "Sitz", ",", "der", "Schat\u00b7ten", "Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dem frisches Gras den Grund, und Laub den Wipfel zierte,", "tokens": ["Dem", "fri\u00b7sches", "Gras", "den", "Grund", ",", "und", "Laub", "den", "Wip\u00b7fel", "zier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mit sanften Schritten fl\u00f6tend f\u00fchrte.", "tokens": ["Mit", "sanf\u00b7ten", "Schrit\u00b7ten", "fl\u00f6\u00b7tend", "f\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Zumahlen er, in den beb\u00fcschten Gr\u00fcnden,", "tokens": ["Zu\u00b7mah\u00b7len", "er", ",", "in", "den", "be\u00b7b\u00fcschten", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Beraldo, seinen Freund, verhoffte vorzufinden,", "tokens": ["Be\u00b7ral\u00b7do", ",", "sei\u00b7nen", "Freund", ",", "ver\u00b7hoff\u00b7te", "vor\u00b7zu\u00b7fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der mehrentheils, im Schatten dichter B\u00e4ume,", "tokens": ["Der", "meh\u00b7ren\u00b7theils", ",", "im", "Schat\u00b7ten", "dich\u00b7ter", "B\u00e4u\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Die Schafe weidete; wo er, durch s\u00fcsse Reime,", "tokens": ["Die", "Scha\u00b7fe", "wei\u00b7de\u00b7te", ";", "wo", "er", ",", "durch", "s\u00fcs\u00b7se", "Rei\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWAV", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die Gottheit, die mit Klee und Gras", "tokens": ["Die", "Got\u00b7theit", ",", "die", "mit", "Klee", "und", "Gras"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Die Wiesen, und mit Laub die duncklen W\u00e4lder, schm\u00fccket,", "tokens": ["Die", "Wie\u00b7sen", ",", "und", "mit", "Laub", "die", "dunck\u00b7len", "W\u00e4l\u00b7der", ",", "schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "APPR", "NN", "ART", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Der uns, zu rechter Zeit, ein heilsam Na\u00df,", "tokens": ["Der", "uns", ",", "zu", "rech\u00b7ter", "Zeit", ",", "ein", "heil\u00b7sam", "Na\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Im k\u00fchlen Thau und Regen, schicket,", "tokens": ["Im", "k\u00fch\u00b7len", "Thau", "und", "Re\u00b7gen", ",", "schi\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "KON", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Wodurch die Wollen-reichen Heerden", "tokens": ["Wo\u00b7durch", "die", "Wol\u00b7len\u00b7rei\u00b7chen", "Heer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Getr\u00e4ncket und gen\u00e4hret werden;", "tokens": ["Ge\u00b7tr\u00e4n\u00b7cket", "und", "ge\u00b7n\u00e4h\u00b7ret", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Das Wesen, Dem daf\u00fcr von allen Hirten Ehre,", "tokens": ["Das", "We\u00b7sen", ",", "Dem", "da\u00b7f\u00fcr", "von", "al\u00b7len", "Hir\u00b7ten", "Eh\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "PAV", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Als einem solchen ", "tokens": ["Als", "ei\u00b7nem", "sol\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "PIAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.29": {"text": "Der aller Welt und Sonnen Heere,", "tokens": ["Der", "al\u00b7ler", "Welt", "und", "Son\u00b7nen", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Als eine Heerde Schafe, f\u00fchrt)", "tokens": ["Als", "ei\u00b7ne", "Heer\u00b7de", "Scha\u00b7fe", ",", "f\u00fchrt", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "In mancherley Beschreibungen besang,", "tokens": ["In", "man\u00b7cher\u00b7ley", "Be\u00b7schrei\u00b7bun\u00b7gen", "be\u00b7sang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.32": {"text": "Da\u00df Berg und Thal davon erklang.", "tokens": ["Da\u00df", "Berg", "und", "Thal", "da\u00b7von", "er\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Um ihm ein sch\u00f6n Gedicht, auf ein geschmiedet Eisen,", "tokens": ["Um", "ihm", "ein", "sch\u00f6n", "Ge\u00b7dicht", ",", "auf", "ein", "ge\u00b7schmie\u00b7det", "Ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ART", "ADJD", "NN", "$,", "APPR", "ART", "VVPP", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So er den Vormittag verfertiget, zu weisen.", "tokens": ["So", "er", "den", "Vor\u00b7mit\u00b7tag", "ver\u00b7fer\u00b7ti\u00b7get", ",", "zu", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Ihr bester Zeit-Vertreib war eben die\u00df:", "tokens": ["Ihr", "bes\u00b7ter", "Zeit\u00b7Ver\u00b7treib", "war", "e\u00b7ben", "die\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df einer seines Geistes Fr\u00fcchte,", "tokens": ["Da\u00df", "ei\u00b7ner", "sei\u00b7nes", "Geis\u00b7tes", "Fr\u00fcch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die in der Einsamkeit erfundenen Gedichte,", "tokens": ["Die", "in", "der", "Ein\u00b7sam\u00b7keit", "er\u00b7fun\u00b7de\u00b7nen", "Ge\u00b7dich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu beyder Nutz, zu beyder Lust,", "tokens": ["Zu", "bey\u00b7der", "Nutz", ",", "zu", "bey\u00b7der", "Lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da keiner was vom Neid und bittrer Scheel-Sucht wust',", "tokens": ["Da", "kei\u00b7ner", "was", "vom", "Neid", "und", "bit\u00b7trer", "Scheel\u00b7Sucht", "wust'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PWS", "APPRART", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "(ein Stand, bey Dichtern rar) dem andern sehen lie\u00df.", "tokens": ["(", "ein", "Stand", ",", "bey", "Dich\u00b7tern", "rar", ")", "dem", "an\u00b7dern", "se\u00b7hen", "lie\u00df", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "APPR", "NN", "ADJD", "$(", "ART", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Er traf ihn aber nicht, wohl aber Damon, an,", "tokens": ["Er", "traf", "ihn", "a\u00b7ber", "nicht", ",", "wohl", "a\u00b7ber", "Da\u00b7mon", ",", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "ADV", "ADV", "NE", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der ihm berichtete:", "tokens": ["Der", "ihm", "be\u00b7rich\u00b7te\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Beraldo w\u00e4r', in fr\u00fcher Morgen-Stunde,", "tokens": ["Be\u00b7ral\u00b7do", "w\u00e4r'", ",", "in", "fr\u00fc\u00b7her", "Mor\u00b7gen\u00b7Stun\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schon aus dem Schatten-reichen Grunde,", "tokens": ["Schon", "aus", "dem", "Schat\u00b7ten\u00b7rei\u00b7chen", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Auf jenes Berges steile H\u00f6h',", "tokens": ["Auf", "je\u00b7nes", "Ber\u00b7ges", "stei\u00b7le", "H\u00f6h'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Wipfel man,", "tokens": ["Des", "Wip\u00b7fel", "man", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "F\u00fcr Wolcken, nicht von unten sehen kann,", "tokens": ["F\u00fcr", "Wol\u00b7cken", ",", "nicht", "von", "un\u00b7ten", "se\u00b7hen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PTKNEG", "APPR", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Nachdem er seine Heerd' ihm anvertraut, gestiegen.", "tokens": ["Nach\u00b7dem", "er", "sei\u00b7ne", "He\u00b7erd'", "ihm", "an\u00b7ver\u00b7traut", ",", "ge\u00b7stie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.47": {"line.1": {"text": "Silvander bat hierauf, so bald er die\u00df geh\u00f6rt,", "tokens": ["Sil\u00b7van\u00b7der", "bat", "hier\u00b7auf", ",", "so", "bald", "er", "die\u00df", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "$,", "ADV", "ADV", "PPER", "PDS", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da\u00df Damon seine Schaf', absonderlich die Ziegen,", "tokens": ["Da\u00df", "Da\u00b7mon", "sei\u00b7ne", "Schaf'", ",", "ab\u00b7son\u00b7der\u00b7lich", "die", "Zie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPOSAT", "NN", "$,", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch mit beachten m\u00f6cht', und eilte, voll Verlangen,", "tokens": ["Auch", "mit", "be\u00b7ach\u00b7ten", "m\u00f6cht'", ",", "und", "eil\u00b7te", ",", "voll", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVINF", "VMFIN", "$,", "KON", "VVFIN", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beraldo wieder zu umfangen,", "tokens": ["Be\u00b7ral\u00b7do", "wie\u00b7der", "zu", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm nach, und gleich den Berg hinan:", "tokens": ["Ihm", "nach", ",", "und", "gleich", "den", "Berg", "hi\u00b7nan", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "KON", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nachdem er eine Flasche,", "tokens": ["Nach\u00b7dem", "er", "ei\u00b7ne", "Fla\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Voll frischer Milch, in seine bunte Tasche,", "tokens": ["Voll", "fri\u00b7scher", "Milch", ",", "in", "sei\u00b7ne", "bun\u00b7te", "Ta\u00b7sche", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Zum Labsal, eingestecket.", "tokens": ["Zum", "Lab\u00b7sal", ",", "ein\u00b7ge\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Das rauhe Hartz-Geb\u00fcrg' erstrecket,", "tokens": ["Das", "rau\u00b7he", "Hartz\u00b7Ge\u00b7b\u00fcr\u00b7g'", "er\u00b7stre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Erhebt und th\u00fcrmet sich", "tokens": ["Er\u00b7hebt", "und", "th\u00fcr\u00b7met", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Fast unersteiglich, schroff und g\u00e4he,", "tokens": ["Fast", "un\u00b7er\u00b7steig\u00b7lich", ",", "schroff", "und", "g\u00e4\u00b7he", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Allhier zu einer solchen H\u00f6he,", "tokens": ["All\u00b7hier", "zu", "ei\u00b7ner", "sol\u00b7chen", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die selbst dem Blick fast f\u00fcrchterlich.", "tokens": ["Die", "selbst", "dem", "Blick", "fast", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch lie\u00df er sich die Schwierigkeit nicht hindern,", "tokens": ["Doch", "lie\u00df", "er", "sich", "die", "Schwie\u00b7rig\u00b7keit", "nicht", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Noch die ihn treibende Begier dadurch vermindern.", "tokens": ["Noch", "die", "ihn", "trei\u00b7ben\u00b7de", "Be\u00b7gier", "da\u00b7durch", "ver\u00b7min\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "ADJA", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er trat die rauhe Bahn", "tokens": ["Er", "trat", "die", "rau\u00b7he", "Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Mit fohen Schritten an.", "tokens": ["Mit", "fo\u00b7hen", "Schrit\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Und, weil ein Fu\u00df-Steig ihm nicht unbekannt;", "tokens": ["Und", ",", "weil", "ein", "Fu\u00df\u00b7Steig", "ihm", "nicht", "un\u00b7be\u00b7kannt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Verk\u00fcrtzt' er seinen Weg, so, da\u00df, in kurtzer Zeit,", "tokens": ["Ver\u00b7k\u00fcrtzt'", "er", "sei\u00b7nen", "Weg", ",", "so", ",", "da\u00df", ",", "in", "kurt\u00b7zer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "ADV", "$,", "KOUS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Trotz des Geb\u00fcrges Rauhigkeit,", "tokens": ["Trotz", "des", "Ge\u00b7b\u00fcr\u00b7ges", "Rau\u00b7hig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Er oben auf des Berges Spitzen,", "tokens": ["Er", "o\u00b7ben", "auf", "des", "Ber\u00b7ges", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Mit m\u00fcden zwar, doch frohen F\u00fcssen, stand.", "tokens": ["Mit", "m\u00fc\u00b7den", "zwar", ",", "doch", "fro\u00b7hen", "F\u00fcs\u00b7sen", ",", "stand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "ADV", "$,", "ADV", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Hieselbst sah er, auf einem grossen Stein,", "tokens": ["Hie\u00b7selbst", "sah", "er", ",", "auf", "ei\u00b7nem", "gros\u00b7sen", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Steinen gantz umringt, Beraldo gantz allein", "tokens": ["Mit", "Stei\u00b7nen", "gantz", "um\u00b7ringt", ",", "Be\u00b7ral\u00b7do", "gantz", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "VVPP", "$,", "NE", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vertieft im Dencken, schreibend sitzen.", "tokens": ["Ver\u00b7tieft", "im", "Den\u00b7cken", ",", "schrei\u00b7bend", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Indessen da\u00df, von seiner Hand,", "tokens": ["In\u00b7des\u00b7sen", "da\u00df", ",", "von", "sei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er ein beschrieben Bl\u00e4ttchen fand,", "tokens": ["Er", "ein", "be\u00b7schrie\u00b7ben", "Bl\u00e4tt\u00b7chen", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So ihm der Wind entf\u00fchrt. Er hub's begierig auf,", "tokens": ["So", "ihm", "der", "Wind", "ent\u00b7f\u00fchrt", ".", "Er", "hub's", "be\u00b7gie\u00b7rig", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "VVPP", "$.", "PPER", "NE", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und lase diese Worte drauf:", "tokens": ["Und", "la\u00b7se", "die\u00b7se", "Wor\u00b7te", "drauf", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "\u00bbindem das Feld mit Schnee der dunckle Winter decket,", "tokens": ["\u00bb", "in\u00b7dem", "das", "Feld", "mit", "Schnee", "der", "dunck\u00b7le", "Win\u00b7ter", "de\u00b7cket", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "NN", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und scharfes Eis die Fluth verstecket,", "tokens": ["Und", "schar\u00b7fes", "Eis", "die", "Fluth", "ver\u00b7ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sitz' ich allhier,", "tokens": ["Sitz'", "ich", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Wo ich, vergn\u00fcgt, mir selber lebe,", "tokens": ["Wo", "ich", ",", "ver\u00b7gn\u00fcgt", ",", "mir", "sel\u00b7ber", "le\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "VVPP", "$,", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und von der eitelen Begier", "tokens": ["Und", "von", "der", "ei\u00b7te\u00b7len", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich zu entfernen, mich bestrebe,", "tokens": ["Mich", "zu", "ent\u00b7fer\u00b7nen", ",", "mich", "be\u00b7stre\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bey einem frohen Feur, befreyt vom Neid und Zancken.", "tokens": ["Bey", "ei\u00b7nem", "fro\u00b7hen", "Feur", ",", "be\u00b7freyt", "vom", "Neid", "und", "Zan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "VVPP", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald schreibt mein reger Kiel,", "tokens": ["Bald", "schreibt", "mein", "re\u00b7ger", "Kiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Bald sing' ich, bald erklingt mein Saiten-Spiel.", "tokens": ["Bald", "sing'", "ich", ",", "bald", "er\u00b7klingt", "mein", "Sai\u00b7ten\u00b7Spiel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und, wenn, voll Ehr-Suchts-Dunst, sich schleichende Gedancken", "tokens": ["Und", ",", "wenn", ",", "voll", "Ehr\u00b7Suchts\u00b7Dunst", ",", "sich", "schlei\u00b7chen\u00b7de", "Ge\u00b7dan\u00b7cken"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "$,", "ADJD", "NN", "$,", "PRF", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Von neuem etwan meine Sinnen", "tokens": ["Von", "neu\u00b7em", "et\u00b7wan", "mei\u00b7ne", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Zu f\u00fcllen unterstehn; treibt die Erinnerung,", "tokens": ["Zu", "f\u00fcl\u00b7len", "un\u00b7ter\u00b7stehn", ";", "treibt", "die", "E\u00b7rin\u00b7ne\u00b7rung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVINF", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+++-+--", "measure": "unknown.measure.hexa"}, "line.13": {"text": "Die mich zur Vorsicht bringt, dieselben schnell von hinnen.", "tokens": ["Die", "mich", "zur", "Vor\u00b7sicht", "bringt", ",", "die\u00b7sel\u00b7ben", "schnell", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "$,", "PDAT", "ADJD", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Pracht, Hoheit, Titel, Geld, Ruhm, Reichthum, Ehre, W\u00fcrde!", "tokens": ["Pracht", ",", "Ho\u00b7heit", ",", "Ti\u00b7tel", ",", "Geld", ",", "Ruhm", ",", "Reicht\u00b7hum", ",", "Eh\u00b7re", ",", "W\u00fcr\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "VAFIN", "$."], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Was seyd ihr eigentlich?", "tokens": ["Was", "seyd", "ihr", "ei\u00b7gent\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df eurentwegen sich", "tokens": ["Da\u00df", "eu\u00b7rent\u00b7we\u00b7gen", "sich"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPOSAT", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die Menschen so zerfoltern? Eine B\u00fcrde,", "tokens": ["Die", "Men\u00b7schen", "so", "zer\u00b7fol\u00b7tern", "?", "Ei\u00b7ne", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die, ohn' Ergetzen, dr\u00fcckt; ein \u00fcberzuckert Gift,", "tokens": ["Die", ",", "ohn'", "Er\u00b7get\u00b7zen", ",", "dr\u00fcckt", ";", "ein", "\u00fc\u00b7ber\u00b7zu\u00b7ckert", "Gift", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "NN", "$,", "VVFIN", "$.", "ART", "VVPP", "NN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "Ein' unbest\u00e4nd'ge Lust, ein daurhaft Unvergn\u00fcgen.", "tokens": ["Ein'", "un\u00b7be\u00b7st\u00e4n\u00b7d'\u00b7ge", "Lust", ",", "ein", "daur\u00b7haft", "Un\u00b7ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Ich fieng auch ehmahls an, vermessentlich,", "tokens": ["Ich", "fi\u00b7eng", "auch", "eh\u00b7mahls", "an", ",", "ver\u00b7mes\u00b7sent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "Wie Icarus, empor zu fliegen.", "tokens": ["Wie", "I\u00b7ca\u00b7rus", ",", "em\u00b7por", "zu", "flie\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Jetzt aber sitz' ich hier, und lache mich,", "tokens": ["Jetzt", "a\u00b7ber", "sitz'", "ich", "hier", ",", "und", "la\u00b7che", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Samt meiner Thorheit, aus.\u00ab Ja, fieng Silvander an,", "tokens": ["Samt", "mei\u00b7ner", "Thor\u00b7heit", ",", "aus", ".", "\u00ab", "Ja", ",", "fi\u00b7eng", "Sil\u00b7van\u00b7der", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "PTKVZ", "$.", "$(", "PTKANT", "$,", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Beraldo, du hast recht: wie wohl hast du gedacht!", "tokens": ["Be\u00b7ral\u00b7do", ",", "du", "hast", "recht", ":", "wie", "wohl", "hast", "du", "ge\u00b7dacht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADJD", "$.", "PWAV", "ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie gl\u00fccklich ist, der es so weit gebracht!", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", ",", "der", "es", "so", "weit", "ge\u00b7bracht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "PRELS", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Wie gl\u00fccklich ist, der also dencken kann!", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", ",", "der", "al\u00b7so", "den\u00b7cken", "kann", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "PRELS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.52": {"line.1": {"text": "Er fand darauf annoch an einem andern Orte,", "tokens": ["Er", "fand", "da\u00b7rauf", "an\u00b7noch", "an", "ei\u00b7nem", "an\u00b7dern", "Or\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf einem Zettul, diese Worte:", "tokens": ["Auf", "ei\u00b7nem", "Zet\u00b7tul", ",", "die\u00b7se", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er lachte,", "tokens": ["Er", "lach\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wie er auf die Vergleichung dachte.", "tokens": ["Wie", "er", "auf", "die", "Ver\u00b7glei\u00b7chung", "dach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Drauf n\u00e4hert' er sich ihm, doch in geheim, und schlich", "tokens": ["Drauf", "n\u00e4\u00b7hert'", "er", "sich", "ihm", ",", "doch", "in", "ge\u00b7heim", ",", "und", "schlich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "PPER", "$,", "ADV", "APPR", "ADJD", "$,", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gemach zu ihm hinan.", "tokens": ["Ge\u00b7mach", "zu", "ihm", "hi\u00b7nan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Doch, da ein d\u00fcrrer Ast, zertreten, brach und krachte,", "tokens": ["Doch", ",", "da", "ein", "d\u00fcr\u00b7rer", "Ast", ",", "zer\u00b7tre\u00b7ten", ",", "brach", "und", "krach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Fuhr jener, durch's Ger\u00e4usch erschreckt, so stark in sich,", "tokens": ["Fuhr", "je\u00b7ner", ",", "durch's", "Ge\u00b7r\u00e4usch", "er\u00b7schreckt", ",", "so", "stark", "in", "sich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "$,", "APPRART", "NN", "VVPP", "$,", "ADV", "ADJD", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df, von der regen Hand, die von der Stelle flog,", "tokens": ["Da\u00df", ",", "von", "der", "re\u00b7gen", "Hand", ",", "die", "von", "der", "Stel\u00b7le", "flog", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Ein schneller langer Strich", "tokens": ["Ein", "schnel\u00b7ler", "lan\u00b7ger", "Strich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Sich \u00fcber sein Papier, das er beschrieben, zog.", "tokens": ["Sich", "\u00fc\u00b7ber", "sein", "Pa\u00b7pier", ",", "das", "er", "be\u00b7schrie\u00b7ben", ",", "zog", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Sie lachten hertzlich alle beyde,", "tokens": ["Sie", "lach\u00b7ten", "hertz\u00b7lich", "al\u00b7le", "bey\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PIAT", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bezeugten Wechsels-weis' einander ihre Freude,", "tokens": ["Be\u00b7zeug\u00b7ten", "Wech\u00b7sels\u00b7weis'", "ein\u00b7an\u00b7der", "ih\u00b7re", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und, wie sie mit der Milch den Durst, den beyde f\u00fchlten,", "tokens": ["Und", ",", "wie", "sie", "mit", "der", "Milch", "den", "Durst", ",", "den", "bey\u00b7de", "f\u00fchl\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nachdem sie sie vorhin in einer Quelle k\u00fchlten,", "tokens": ["Nach\u00b7dem", "sie", "sie", "vor\u00b7hin", "in", "ei\u00b7ner", "Quel\u00b7le", "k\u00fchl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nicht ohne Lust gestillt, sich beyde niedersetzten,", "tokens": ["Nicht", "oh\u00b7ne", "Lust", "ge\u00b7stillt", ",", "sich", "bey\u00b7de", "nie\u00b7der\u00b7setz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VVPP", "$,", "PRF", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und an der bunten Pracht", "tokens": ["Und", "an", "der", "bun\u00b7ten", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Der Landschaft sich ergetzten;", "tokens": ["Der", "Land\u00b7schaft", "sich", "er\u00b7getz\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Lie\u00df das, womit sein Kiel besch\u00e4fftiget gewesen,", "tokens": ["Lie\u00df", "das", ",", "wo\u00b7mit", "sein", "Kiel", "be\u00b7sch\u00e4ff\u00b7ti\u00b7get", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "$,", "PWAV", "PPOSAT", "NN", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Beraldo, seinen Freund, auf sein Verlangen, lesen.", "tokens": ["Be\u00b7ral\u00b7do", ",", "sei\u00b7nen", "Freund", ",", "auf", "sein", "Ver\u00b7lan\u00b7gen", ",", "le\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Des rauhen Hartzes rauhe Pracht", "tokens": ["Des", "rau\u00b7hen", "Hart\u00b7zes", "rau\u00b7he", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hatt' er, durch seine Pflicht getrieben,", "tokens": ["Hatt'", "er", ",", "durch", "sei\u00b7ne", "Pflicht", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zu Ehren dem, der ihn zum Schatz-Behalter macht,", "tokens": ["Zu", "Eh\u00b7ren", "dem", ",", "der", "ihn", "zum", "Schatz\u00b7Be\u00b7hal\u00b7ter", "macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Fast mehr geschildert, als beschrieben.", "tokens": ["Fast", "mehr", "ge\u00b7schil\u00b7dert", ",", "als", "be\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "KOUS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Absonderlich hatt' er des glatten Marmors Prangen,", "tokens": ["Ab\u00b7son\u00b7der\u00b7lich", "hatt'", "er", "des", "glat\u00b7ten", "Mar\u00b7mors", "Pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Den Blanckenburgs Geb\u00fcrg' uns hier,", "tokens": ["Den", "Blan\u00b7cken\u00b7burgs", "Ge\u00b7b\u00fcr\u00b7g'", "uns", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "In einer tausendfach gef\u00e4rbten Zier,", "tokens": ["In", "ei\u00b7ner", "tau\u00b7send\u00b7fach", "ge\u00b7f\u00e4rb\u00b7ten", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Zu einem Wunder bringt, zu bilden angefangen.", "tokens": ["Zu", "ei\u00b7nem", "Wun\u00b7der", "bringt", ",", "zu", "bil\u00b7den", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Es wiederholete der Wiederhall,", "tokens": ["Es", "wie\u00b7der\u00b7ho\u00b7le\u00b7te", "der", "Wie\u00b7der\u00b7hall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit einem sanften Schall,", "tokens": ["Mit", "ei\u00b7nem", "sanf\u00b7ten", "Schall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Aus mancher Kluft, von mehr, als einem Orte,", "tokens": ["Aus", "man\u00b7cher", "Kluft", ",", "von", "mehr", ",", "als", "ei\u00b7nem", "Or\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "ADV", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als er, wie folget, las', fast alle Worte:", "tokens": ["Als", "er", ",", "wie", "fol\u00b7get", ",", "las'", ",", "fast", "al\u00b7le", "Wor\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "VVFIN", "$,", "VVFIN", "$,", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.56": {"line.1": {"text": "Welch eine Last von Stein! Welch eine Felsen-Welt", "tokens": ["Welch", "ei\u00b7ne", "Last", "von", "Stein", "!", "Welch", "ei\u00b7ne", "Fel\u00b7sen\u00b7Welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "APPR", "NN", "$.", "PIAT", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wird meinem starren Blick' hier vorgestellt!", "tokens": ["Wird", "mei\u00b7nem", "star\u00b7ren", "Blick'", "hier", "vor\u00b7ge\u00b7stellt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Fast alles, was allhier die Augen schauen,", "tokens": ["Fast", "al\u00b7les", ",", "was", "all\u00b7hier", "die", "Au\u00b7gen", "schau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gebieret Furcht, sucht ein geheimes Schrecken", "tokens": ["Ge\u00b7bie\u00b7ret", "Furcht", ",", "sucht", "ein", "ge\u00b7hei\u00b7mes", "Schre\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "NN", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auch dem, der sonst nicht bange, zu erwecken.", "tokens": ["Auch", "dem", ",", "der", "sonst", "nicht", "ban\u00b7ge", ",", "zu", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ADV", "PTKNEG", "ADJD", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "Es hauchet Wiedrigkeit und Grauen,", "tokens": ["Es", "hau\u00b7chet", "Wied\u00b7rig\u00b7keit", "und", "Grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An diesem Ort, fast jeder Vorwurf aus.", "tokens": ["An", "die\u00b7sem", "Ort", ",", "fast", "je\u00b7der", "Vor\u00b7wurf", "aus", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es sehn zugleich die scheuch- und starren Blicke", "tokens": ["Es", "sehn", "zu\u00b7gleich", "die", "scheuch", "und", "star\u00b7ren", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hier ungeheure Felsen-St\u00fccke,", "tokens": ["Hier", "un\u00b7ge\u00b7heu\u00b7re", "Fel\u00b7sen\u00b7St\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bald fest und gantz, und bald zerbrochen und zerspalten:", "tokens": ["Bald", "fest", "und", "gantz", ",", "und", "bald", "zer\u00b7bro\u00b7chen", "und", "zer\u00b7spal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "ADV", "$,", "KON", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald Abgr\u00fcnd', H\u00f6len, Moo\u00df und Graus.", "tokens": ["Bald", "Ab\u00b7gr\u00fcnd'", ",", "H\u00f6\u00b7len", ",", "Moo\u00df", "und", "Graus", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein gantz verwirrt Gemisch von allerley Gestalten,", "tokens": ["Ein", "gantz", "ver\u00b7wirrt", "Ge\u00b7misch", "von", "al\u00b7ler\u00b7ley", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Materien und Farben, stellet hier", "tokens": ["Ma\u00b7te\u00b7ri\u00b7en", "und", "Far\u00b7ben", ",", "stel\u00b7let", "hier"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "KON", "NN", "$,", "VVFIN", "ADV"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.9": {"text": "Uns gleichsam recht ein Chaos f\u00fcr.", "tokens": ["Uns", "gleich\u00b7sam", "recht", "ein", "Chaos", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.58": {"line.1": {"text": "Leim- Marmor- Kiesel-Berg', unordentlich vermengt,", "tokens": ["Leim", "Mar\u00b7mor", "Kie\u00b7sel\u00b7Ber\u00b7g'", ",", "un\u00b7or\u00b7dent\u00b7lich", "ver\u00b7mengt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["TRUNC", "TRUNC", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Unordentlich erh\u00f6ht, unordentlich zerbrochen,", "tokens": ["Un\u00b7or\u00b7dent\u00b7lich", "er\u00b7h\u00f6ht", ",", "un\u00b7or\u00b7dent\u00b7lich", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Als w\u00e4ren sie, durch ungefehren Fall,", "tokens": ["Als", "w\u00e4\u00b7ren", "sie", ",", "durch", "un\u00b7ge\u00b7feh\u00b7ren", "Fall", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So wunderlich in sich gedrengt,", "tokens": ["So", "wun\u00b7der\u00b7lich", "in", "sich", "ge\u00b7drengt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erblickt man \u00fcberall.", "tokens": ["Er\u00b7blickt", "man", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.59": {"line.1": {"text": "Von erst geschmoltznem Schnee kommt hier ein tr\u00e4ger Bach,", "tokens": ["Von", "erst", "ge\u00b7schmoltz\u00b7nem", "Schnee", "kommt", "hier", "ein", "tr\u00e4\u00b7ger", "Bach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vermischt mit Schlamm und faulem Moo\u00df,", "tokens": ["Ver\u00b7mischt", "mit", "Schlamm", "und", "fau\u00b7lem", "Moo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus kleinen Oeffnungen gekrochen:", "tokens": ["Aus", "klei\u00b7nen", "Oeff\u00b7nun\u00b7gen", "ge\u00b7kro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vermehrt sich aber allgemach,", "tokens": ["Ver\u00b7mehrt", "sich", "a\u00b7ber", "all\u00b7ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird, eh man sich's versiehet, gro\u00df,", "tokens": ["Wird", ",", "eh", "man", "sich's", "ver\u00b7sie\u00b7het", ",", "gro\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erz\u00fcrnt sich, sch\u00e4umt und braust, und was erst kaum geflossen,", "tokens": ["Er\u00b7z\u00fcrnt", "sich", ",", "sch\u00e4umt", "und", "braust", ",", "und", "was", "erst", "kaum", "ge\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "VVFIN", "KON", "VVFIN", "$,", "KON", "PWS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kommt, \u00fcber schroffe Stein', erbost herab geschossen,", "tokens": ["Kommt", ",", "\u00fc\u00b7ber", "schrof\u00b7fe", "Stein'", ",", "er\u00b7bost", "her\u00b7ab", "ge\u00b7schos\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Reisst selbst den Boden mit, st\u00fcrtzt, mit besch\u00e4umtem Grimm,", "tokens": ["Reisst", "selbst", "den", "Bo\u00b7den", "mit", ",", "st\u00fcrtzt", ",", "mit", "be\u00b7sch\u00e4um\u00b7tem", "Grimm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,", "VVFIN", "$,", "APPR", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bejahrte dicke B\u00e4um' und schwere Felsen \u00fcm.", "tokens": ["Be\u00b7jahr\u00b7te", "di\u00b7cke", "B\u00e4um'", "und", "schwe\u00b7re", "Fel\u00b7sen", "\u00fcm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.60": {"line.1": {"text": "An manchem Orte sind der Berge rauhe H\u00f6h'n", "tokens": ["An", "man\u00b7chem", "Or\u00b7te", "sind", "der", "Ber\u00b7ge", "rau\u00b7he", "H\u00f6h'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Recht ungeheuer sch\u00f6n.", "tokens": ["Recht", "un\u00b7ge\u00b7heu\u00b7er", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Gr\u00f6sse kann uns Lust und Schrecken", "tokens": ["Die", "Gr\u00f6s\u00b7se", "kann", "uns", "Lust", "und", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zugleich erwecken.", "tokens": ["Zu\u00b7gleich", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Entsetzlich ist der Klippen H\u00f6h' und Dicke:", "tokens": ["Ent\u00b7setz\u00b7lich", "ist", "der", "Klip\u00b7pen", "H\u00f6h'", "und", "Di\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Entsetzlich gro\u00df sind abgerollte St\u00fccke:", "tokens": ["Ent\u00b7setz\u00b7lich", "gro\u00df", "sind", "ab\u00b7ge\u00b7roll\u00b7te", "St\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Entsetzlich schwartz sind aufgespalt'ne Kl\u00fcfte:", "tokens": ["Ent\u00b7setz\u00b7lich", "schwartz", "sind", "auf\u00b7ge\u00b7spalt'\u00b7ne", "Kl\u00fcf\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Entsetzlich tief, wie Rachen, hohle Gr\u00fcfte:", "tokens": ["Ent\u00b7setz\u00b7lich", "tief", ",", "wie", "Ra\u00b7chen", ",", "hoh\u00b7le", "Gr\u00fcf\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "PWAV", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die mehrentheils verwirrte Dornen-Hecken,", "tokens": ["Die", "meh\u00b7ren\u00b7theils", "ver\u00b7wirr\u00b7te", "Dor\u00b7nen\u00b7He\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Die voller Furcht und Grauen stecken,", "tokens": ["Die", "vol\u00b7ler", "Furcht", "und", "Grau\u00b7en", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Mit Klauen-gleichen Stacheln decken.", "tokens": ["Mit", "Klau\u00b7en\u00b7glei\u00b7chen", "Sta\u00b7cheln", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Die Gegenden sind meistens w\u00fcst' und wild,", "tokens": ["Die", "Ge\u00b7gen\u00b7den", "sind", "meis\u00b7tens", "w\u00fcst'", "und", "wild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit steter D\u00e4mmerung und Schatten angef\u00fcllt.", "tokens": ["Mit", "ste\u00b7ter", "D\u00e4m\u00b7me\u00b7rung", "und", "Schat\u00b7ten", "an\u00b7ge\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Einsamkeit allein", "tokens": ["Die", "Ein\u00b7sam\u00b7keit", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Scheint hier Bewohnerinn zu seyn.", "tokens": ["Scheint", "hier", "Be\u00b7woh\u00b7ne\u00b7rinn", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Jedoch, erstarrter Sinn, begreife dich!", "tokens": ["Je\u00b7doch", ",", "er\u00b7starr\u00b7ter", "Sinn", ",", "be\u00b7grei\u00b7fe", "dich", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die furchtbare Gestalt ist nicht so f\u00fcrchterlich.", "tokens": ["Die", "furcht\u00b7ba\u00b7re", "Ge\u00b7stalt", "ist", "nicht", "so", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sieh nicht allein der Berge wildes Wesen,", "tokens": ["Sieh", "nicht", "al\u00b7lein", "der", "Ber\u00b7ge", "wil\u00b7des", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sieh auch derselben Schmuck, zusamt dem Nutzen, an!", "tokens": ["Sieh", "auch", "der\u00b7sel\u00b7ben", "Schmuck", ",", "zu\u00b7samt", "dem", "Nut\u00b7zen", ",", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "PDAT", "NN", "$,", "APPR", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du kannst hier mehr, als man leicht sonsten kann,", "tokens": ["Du", "kannst", "hier", "mehr", ",", "als", "man", "leicht", "sons\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "$,", "KOUS", "PIS", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Des Sch\u00f6pfers Huld und Macht, aus ihrer Anmuth, lesen.", "tokens": ["Des", "Sch\u00f6p\u00b7fers", "Huld", "und", "Macht", ",", "aus", "ih\u00b7rer", "An\u00b7muth", ",", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es wird kein Mensch die Vortheil' alle nennen,", "tokens": ["Es", "wird", "kein", "Mensch", "die", "Vort\u00b7heil'", "al\u00b7le", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "ART", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die ein Geb\u00fcrg' uns bringt, noch sie beschreiben k\u00f6nnen.", "tokens": ["Die", "ein", "Ge\u00b7b\u00fcr\u00b7g'", "uns", "bringt", ",", "noch", "sie", "be\u00b7schrei\u00b7ben", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "VVFIN", "$,", "ADV", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.63": {"line.1": {"text": "Es stecken kostbare Metallen,", "tokens": ["Es", "ste\u00b7cken", "kost\u00b7ba\u00b7re", "Me\u00b7tal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es stecken klare Berg-Crystallen,", "tokens": ["Es", "ste\u00b7cken", "kla\u00b7re", "Ber\u00b7gCry\u00b7stal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Samt Silber, Gold, der Menschen Lust,", "tokens": ["Samt", "Sil\u00b7ber", ",", "Gold", ",", "der", "Men\u00b7schen", "Lust", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ihrer finstern Brust.", "tokens": ["In", "ih\u00b7rer", "fins\u00b7tern", "Brust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Wasser, das von ihren Gipfeln f\u00e4llt,", "tokens": ["Das", "Was\u00b7ser", ",", "das", "von", "ih\u00b7ren", "Gip\u00b7feln", "f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Bestr\u00f6mt und tr\u00e4nckt die d\u00fcrre Welt.", "tokens": ["Be\u00b7str\u00f6mt", "und", "tr\u00e4nckt", "die", "d\u00fcr\u00b7re", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ja, selbst die Rauhigkeit, die wir an vielen sehn,", "tokens": ["Ja", ",", "selbst", "die", "Rau\u00b7hig\u00b7keit", ",", "die", "wir", "an", "vie\u00b7len", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kann andrer Lieblichkeit und Anmuth noch erh\u00f6hn,", "tokens": ["Kann", "an\u00b7drer", "Lieb\u00b7lich\u00b7keit", "und", "An\u00b7muth", "noch", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Durch ihren Gegensatz. Wie manchen H\u00fcgel schm\u00fccket", "tokens": ["Durch", "ih\u00b7ren", "Ge\u00b7gen\u00b7satz", ".", "Wie", "man\u00b7chen", "H\u00fc\u00b7gel", "schm\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PWAV", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Des Grases gr\u00fcner Sammt, der sch\u00f6nsten Kr\u00e4uter Pracht!", "tokens": ["Des", "Gra\u00b7ses", "gr\u00fc\u00b7ner", "Sammt", ",", "der", "sch\u00f6ns\u00b7ten", "Kr\u00e4u\u00b7ter", "Pracht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie manche gr\u00fcn- und holde Nacht", "tokens": ["Wie", "man\u00b7che", "gr\u00fcn", "und", "hol\u00b7de", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wird hier, im dichten Busch', erblicket!", "tokens": ["Wird", "hier", ",", "im", "dich\u00b7ten", "Busch'", ",", "er\u00b7bli\u00b7cket", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "APPRART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wann dort, bald an der Berge Gipfel,", "tokens": ["Wann", "dort", ",", "bald", "an", "der", "Ber\u00b7ge", "Gip\u00b7fel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Bald an der hohen B\u00e4ume Wipfel,", "tokens": ["Bald", "an", "der", "ho\u00b7hen", "B\u00e4u\u00b7me", "Wip\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ein schnelles Licht, ein heller Strahl", "tokens": ["Ein", "schnel\u00b7les", "Licht", ",", "ein", "hel\u00b7ler", "Strahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit frohem Schimmer f\u00e4llt; wird im beb\u00fcschten Thal,", "tokens": ["Mit", "fro\u00b7hem", "Schim\u00b7mer", "f\u00e4llt", ";", "wird", "im", "be\u00b7b\u00fcschten", "Thal", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "VAFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.17": {"text": "Auch selber in den Mittags-Stunden,", "tokens": ["Auch", "sel\u00b7ber", "in", "den", "Mit\u00b7tags\u00b7Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Ein angenehme K\u00fchl- und sanfte D\u00e4mmerung,", "tokens": ["Ein", "an\u00b7ge\u00b7neh\u00b7me", "K\u00fchl", "und", "sanf\u00b7te", "D\u00e4m\u00b7me\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.19": {"text": "Oft in der Nachbarschaft desselben Strahls, gefunden.", "tokens": ["Oft", "in", "der", "Nach\u00b7bar\u00b7schaft", "des\u00b7sel\u00b7ben", "Strahls", ",", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PDAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.64": {"line.1": {"text": "Es \u00e4ndern, wechseln, trennen, gatten,", "tokens": ["Es", "\u00e4n\u00b7dern", ",", "wech\u00b7seln", ",", "tren\u00b7nen", ",", "gat\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vermischen, f\u00e4rben, bilden sich", "tokens": ["Ver\u00b7mi\u00b7schen", ",", "f\u00e4r\u00b7ben", ",", "bil\u00b7den", "sich"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel tausend Lichter, tausend Schatten,", "tokens": ["Viel", "tau\u00b7send", "Lich\u00b7ter", ",", "tau\u00b7send", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$,", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So lieblich, als verwunderlich.", "tokens": ["So", "lieb\u00b7lich", ",", "als", "ver\u00b7wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Es zeigen hier der Berge rauhe R\u00fccken,", "tokens": ["Es", "zei\u00b7gen", "hier", "der", "Ber\u00b7ge", "rau\u00b7he", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf welchen oft, statt Kr\u00e4uter, Gras und Klee,", "tokens": ["Auf", "wel\u00b7chen", "oft", ",", "statt", "Kr\u00e4u\u00b7ter", ",", "Gras", "und", "Klee", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "ADV", "$,", "KOUI", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein graues Eis, bejahrter Schnee,", "tokens": ["Ein", "grau\u00b7es", "Eis", ",", "be\u00b7jahr\u00b7ter", "Schnee", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die schroff- und rauhen H\u00e4upter dr\u00fccken,", "tokens": ["Die", "schroff", "und", "rau\u00b7hen", "H\u00e4up\u00b7ter", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den Winter: wann, zu gleicher Zeit,", "tokens": ["Den", "Win\u00b7ter", ":", "wann", ",", "zu", "glei\u00b7cher", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PWAV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit gr\u00fcn bebl\u00fchmter Lieblichkeit", "tokens": ["Mit", "gr\u00fcn", "be\u00b7bl\u00fchm\u00b7ter", "Lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Viel H\u00fcgel, wie im Herbst, dort andre, wie im Lentzen,", "tokens": ["Viel", "H\u00fc\u00b7gel", ",", "wie", "im", "Herbst", ",", "dort", "and\u00b7re", ",", "wie", "im", "Lent\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "APPRART", "NN", "$,", "ADV", "PIS", "$,", "PWAV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und hier verschied'ne, recht als wie im Sommer, gl\u00e4ntzen.", "tokens": ["Und", "hier", "ver\u00b7schie\u00b7d'\u00b7ne", ",", "recht", "als", "wie", "im", "Som\u00b7mer", ",", "gl\u00e4nt\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "ADV", "KOUS", "KOKOM", "APPRART", "NN", "$,", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "So, da\u00df man hier nicht nur die Tages-Zeiten; gar", "tokens": ["So", ",", "da\u00df", "man", "hier", "nicht", "nur", "die", "Ta\u00b7ges\u00b7Zei\u00b7ten", ";", "gar"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "KOUS", "PIS", "ADV", "PTKNEG", "ADV", "ART", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Jahres-Zeiten auch zugleich, und zwar", "tokens": ["Die", "Jah\u00b7res\u00b7Zei\u00b7ten", "auch", "zu\u00b7gleich", ",", "und", "zwar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "$,", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Auf einmahl, f\u00fchlt und sieht.", "tokens": ["Auf", "ein\u00b7mahl", ",", "f\u00fchlt", "und", "sieht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.66": {"line.1": {"text": "Erwege die\u00df mit Lust und Andacht, mein Gem\u00fcth!", "tokens": ["Er\u00b7we\u00b7ge", "die\u00df", "mit", "Lust", "und", "An\u00b7dacht", ",", "mein", "Ge\u00b7m\u00fcth", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "APPR", "NN", "KON", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es lassen des Geb\u00fcrgs so rauh- als sch\u00f6ne H\u00f6hen", "tokens": ["Es", "las\u00b7sen", "des", "Ge\u00b7b\u00fcrgs", "so", "rauh", "als", "sch\u00f6\u00b7ne", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Bild von irdischen Verwirrungen uns sehen:", "tokens": ["Ein", "Bild", "von", "ir\u00b7di\u00b7schen", "Ver\u00b7wir\u00b7run\u00b7gen", "uns", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Indem ja Freud' und Leid, und Schertz und Schmertz auf Erden,", "tokens": ["In\u00b7dem", "ja", "Freud'", "und", "Leid", ",", "und", "Schertz", "und", "Schmertz", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KON", "NN", "$,", "KON", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie Lust und Grauen hier, vereint gefunden werden.", "tokens": ["Wie", "Lust", "und", "Grau\u00b7en", "hier", ",", "ver\u00b7eint", "ge\u00b7fun\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "$,", "VVPP", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.67": {"line.1": {"text": "Allein, was seh' ich ferner hier", "tokens": ["Al\u00b7lein", ",", "was", "seh'", "ich", "fer\u00b7ner", "hier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey dieses Berges rauher Zier?", "tokens": ["Bey", "die\u00b7ses", "Ber\u00b7ges", "rau\u00b7her", "Zier", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was m\u00fcssen nicht f\u00fcr Reichthum, welchen Segen", "tokens": ["Was", "m\u00fcs\u00b7sen", "nicht", "f\u00fcr", "Reicht\u00b7hum", ",", "wel\u00b7chen", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VMFIN", "PTKNEG", "APPR", "NN", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von Marmor und Metall", "tokens": ["Von", "Mar\u00b7mor", "und", "Me\u00b7tall"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Berge B\u00e4uche hegen!", "tokens": ["Der", "Ber\u00b7ge", "B\u00e4u\u00b7che", "he\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Kann ich doch \u00fcberall", "tokens": ["Kann", "ich", "doch", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Den sch\u00f6nsten Marmor-Stein, in grossen St\u00fccken,", "tokens": ["Den", "sch\u00f6ns\u00b7ten", "Mar\u00b7mor\u00b7Stein", ",", "in", "gros\u00b7sen", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "So gar schon auf der Fl\u00e4ch', erblicken!", "tokens": ["So", "gar", "schon", "auf", "der", "Fl\u00e4ch'", ",", "er\u00b7bli\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "ART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wie gl\u00e4ntzet dieser hier, als w\u00e4r' er schon polirt!", "tokens": ["Wie", "gl\u00e4nt\u00b7zet", "die\u00b7ser", "hier", ",", "als", "w\u00e4r'", "er", "schon", "po\u00b7lirt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PDS", "ADV", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie bunt ist jener dort! Ich kann mich nicht enthalten,", "tokens": ["Wie", "bunt", "ist", "je\u00b7ner", "dort", "!", "Ich", "kann", "mich", "nicht", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PDS", "ADV", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der unterschiedlichen unz\u00e4hligen Gestalten", "tokens": ["Der", "un\u00b7ter\u00b7schied\u00b7li\u00b7chen", "un\u00b7z\u00e4h\u00b7li\u00b7gen", "Ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und Farben Meng' im Marmor zu besehn,", "tokens": ["Und", "Far\u00b7ben", "Meng'", "im", "Mar\u00b7mor", "zu", "be\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und, in der drob versp\u00fcrten Augen-Lust,", "tokens": ["Und", ",", "in", "der", "drob", "ver\u00b7sp\u00fcr\u00b7ten", "Au\u00b7gen\u00b7Lust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Mit inniglich dadurch ger\u00fchrter Brust,", "tokens": ["Mit", "in\u00b7nig\u00b7lich", "da\u00b7durch", "ge\u00b7r\u00fchr\u00b7ter", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Ein all-erschaffendes allm\u00e4cht'ges Wunder-Wesen,", "tokens": ["Ein", "all\u00b7er\u00b7schaf\u00b7fen\u00b7des", "all\u00b7m\u00e4cht'\u00b7ges", "Wun\u00b7der\u00b7We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ohn' Dem nichts ist, was ist, bewundernd zu erh\u00f6hn.", "tokens": ["Ohn'", "Dem", "nichts", "ist", ",", "was", "ist", ",", "be\u00b7wun\u00b7dernd", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "VAFIN", "$,", "PWS", "VAFIN", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.68": {"line.1": {"text": "Man kann allhier, sowohl vermischt, als eintzeln, sch\u00f6n,", "tokens": ["Man", "kann", "all\u00b7hier", ",", "so\u00b7wohl", "ver\u00b7mischt", ",", "als", "eint\u00b7zeln", ",", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "$,", "KON", "VVPP", "$,", "KOUS", "VVINF", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(ob wir gleich von der Schrift den Inhalt nicht verstehn)", "tokens": ["(", "ob", "wir", "gleich", "von", "der", "Schrift", "den", "In\u00b7halt", "nicht", "ver\u00b7stehn", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch in gebrochnen Lettern lesen,", "tokens": ["Auch", "in", "ge\u00b7broch\u00b7nen", "Let\u00b7tern", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df, was geschrieben, sey, den Sch\u00f6pfer anzuweisen,", "tokens": ["Da\u00df", ",", "was", "ge\u00b7schrie\u00b7ben", ",", "sey", ",", "den", "Sch\u00f6p\u00b7fer", "an\u00b7zu\u00b7wei\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "VVPP", "$,", "VAFIN", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Um auch, im Marmor-Stein, sein Wunder-Werck zu preisen.", "tokens": ["Um", "auch", ",", "im", "Mar\u00b7mor\u00b7Stein", ",", "sein", "Wun\u00b7der\u00b7\u00b7Werck", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "$,", "APPRART", "NN", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man kann, in tausendfach ver\u00e4nderlichen Z\u00fcgen,", "tokens": ["Man", "kann", ",", "in", "tau\u00b7send\u00b7fach", "ver\u00b7\u00e4n\u00b7der\u00b7li\u00b7chen", "Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die sich bald trennen und bald f\u00fcgen,", "tokens": ["Die", "sich", "bald", "tren\u00b7nen", "und", "bald", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "VVINF", "KON", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Allhier ein tausendfach vermischtes Etwas sehn,", "tokens": ["All\u00b7hier", "ein", "tau\u00b7send\u00b7fach", "ver\u00b7mischtes", "Et\u00b7was", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "ADJA", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Worin die spielende gesch\u00e4fftige Natur", "tokens": ["Wo\u00b7rin", "die", "spie\u00b7len\u00b7de", "ge\u00b7sch\u00e4ff\u00b7ti\u00b7ge", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So manche Bildungs-Art, und seltsame Figur,", "tokens": ["So", "man\u00b7che", "Bil\u00b7dungs\u00b7Art", ",", "und", "selt\u00b7sa\u00b7me", "Fi\u00b7gur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die in dem bunten Stein, zwar wunderlich, doch sch\u00f6n", "tokens": ["Die", "in", "dem", "bun\u00b7ten", "Stein", ",", "zwar", "wun\u00b7der\u00b7lich", ",", "doch", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Verstreuet und vereint, so durch einander gehn,", "tokens": ["Ver\u00b7streu\u00b7et", "und", "ver\u00b7eint", ",", "so", "durch", "ein\u00b7an\u00b7der", "gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "$,", "ADV", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da\u00df es das Aug' ergetzt; den Augen vorgestellt.", "tokens": ["Da\u00df", "es", "das", "Aug'", "er\u00b7getzt", ";", "den", "Au\u00b7gen", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$.", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.69": {"line.1": {"text": "Es sind so viel verworrene Figuren", "tokens": ["Es", "sind", "so", "viel", "ver\u00b7wor\u00b7re\u00b7ne", "Fi\u00b7gu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Theils halb-theils gantzer Creaturen,", "tokens": ["Theils", "halb\u00b7theils", "gant\u00b7zer", "Crea\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "So viele Mischungen von klein- und grossen St\u00fccken,", "tokens": ["So", "vie\u00b7le", "Misc\u00b7hun\u00b7gen", "von", "klein", "und", "gros\u00b7sen", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vereint und nicht vereint, im Marmor zu erblicken;", "tokens": ["Ver\u00b7eint", "und", "nicht", "ver\u00b7eint", ",", "im", "Mar\u00b7mor", "zu", "er\u00b7bli\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "PTKNEG", "VVPP", "$,", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df, so von Form als Farb', auch er ein Chaos scheint,", "tokens": ["Da\u00df", ",", "so", "von", "Form", "als", "Fa\u00b7rb'", ",", "auch", "er", "ein", "Chaos", "scheint", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "APPR", "NN", "KOUS", "NN", "$,", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das etwan auf einmahl erstarrt sey und versteint.", "tokens": ["Das", "et\u00b7wan", "auf", "ein\u00b7mahl", "er\u00b7starrt", "sey", "und", "ver\u00b7steint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ADV", "VVPP", "VAFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.70": {"line.1": {"text": "Hier sieht man stille Wirbel sich,", "tokens": ["Hier", "sieht", "man", "stil\u00b7le", "Wir\u00b7bel", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort trockne Strudel gleichsam regen.", "tokens": ["Dort", "trock\u00b7ne", "Stru\u00b7del", "gleich\u00b7sam", "re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hier scheinen sich die Wellen eigentlich,", "tokens": ["Hier", "schei\u00b7nen", "sich", "die", "Wel\u00b7len", "ei\u00b7gent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ohn' da\u00df sie sich bewegen, zu bewegen.", "tokens": ["Ohn'", "da\u00df", "sie", "sich", "be\u00b7we\u00b7gen", ",", "zu", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PRF", "VVINF", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Bald stellt der Marmor B\u00e4um' und Thier',", "tokens": ["Bald", "stellt", "der", "Mar\u00b7mor", "B\u00e4um'", "und", "Thier'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und bald gebrochne Stein' und Ertz nat\u00fcrlich f\u00fcr.", "tokens": ["Und", "bald", "ge\u00b7broch\u00b7ne", "Stein'", "und", "Ertz", "na\u00b7t\u00fcr\u00b7lich", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "KON", "NN", "ADV", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Oft scheint ein rother Marmor-Stein", "tokens": ["Oft", "scheint", "ein", "ro\u00b7ther", "Mar\u00b7mor\u00b7Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zu Stein geword'nes Fleisch zu seyn.", "tokens": ["Zu", "Stein", "ge\u00b7word'\u00b7nes", "Fleisch", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Viel grosse Adern sind mit kleinern oft durchkrochen,", "tokens": ["Viel", "gros\u00b7se", "A\u00b7dern", "sind", "mit", "klei\u00b7nern", "oft", "durch\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "APPR", "ADJA", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die, eintzeln bald, und bald mit Haufen,", "tokens": ["Die", ",", "eint\u00b7zeln", "bald", ",", "und", "bald", "mit", "Hau\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVFIN", "ADV", "$,", "KON", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Bald an- und in-, bald durch einander laufen,", "tokens": ["Bald", "an", "und", "in", ",", "bald", "durch", "ein\u00b7an\u00b7der", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "KON", "TRUNC", "$,", "ADV", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Woraus so mancherley Figur und Form entsteht.", "tokens": ["Wo\u00b7raus", "so", "man\u00b7cher\u00b7ley", "Fi\u00b7gur", "und", "Form", "ent\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die sch\u00f6nen Farben sind auf tausend Art gebrochen,", "tokens": ["Die", "sch\u00f6\u00b7nen", "Far\u00b7ben", "sind", "auf", "tau\u00b7send", "Art", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auf tausend Art gemischt, vertiefet und erh\u00f6ht,", "tokens": ["Auf", "tau\u00b7send", "Art", "ge\u00b7mischt", ",", "ver\u00b7tie\u00b7fet", "und", "er\u00b7h\u00f6ht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVPP", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bald hell und bald ged\u00e4mpft, bald feurig und bald matt.", "tokens": ["Bald", "hell", "und", "bald", "ge\u00b7d\u00e4mpft", ",", "bald", "feu\u00b7rig", "und", "bald", "matt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "VVPP", "$,", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.71": {"line.1": {"text": "Es sind sowohl die Meng', als Graden nicht zu z\u00e4hlen.", "tokens": ["Es", "sind", "so\u00b7wohl", "die", "Meng'", ",", "als", "Gra\u00b7den", "nicht", "zu", "z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "ART", "NN", "$,", "KOUS", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch wird es ihnen nie an einem Firni\u00df fehlen,", "tokens": ["Auch", "wird", "es", "ih\u00b7nen", "nie", "an", "ei\u00b7nem", "Fir\u00b7ni\u00df", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als der mit ihnen w\u00e4chst, und der ihm einverleibt.", "tokens": ["Als", "der", "mit", "ih\u00b7nen", "w\u00e4chst", ",", "und", "der", "ihm", "ein\u00b7ver\u00b7leibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPER", "VVFIN", "$,", "KON", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn, eben da\u00df er glatt,", "tokens": ["Denn", ",", "e\u00b7ben", "da\u00df", "er", "glatt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "KOUS", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Vermehret seinen Werth, erhebet seinen Preis.", "tokens": ["Ver\u00b7meh\u00b7ret", "sei\u00b7nen", "Werth", ",", "er\u00b7he\u00b7bet", "sei\u00b7nen", "Preis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.72": {"line.1": {"text": "So bald man nur das rauhe von ihm reibt,", "tokens": ["So", "bald", "man", "nur", "das", "rau\u00b7he", "von", "ihm", "reibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ADV", "ART", "ADJA", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie solches hier des K\u00fcnstlers Flei\u00df", "tokens": ["Wie", "sol\u00b7ches", "hier", "des", "K\u00fcnst\u00b7lers", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Recht k\u00fcnstlich zu verrichten weis;", "tokens": ["Recht", "k\u00fcnst\u00b7lich", "zu", "ver\u00b7rich\u00b7ten", "weis", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So ist kein Spiegel-Glas so gl\u00e4ntzend und so rein,", "tokens": ["So", "ist", "kein", "Spie\u00b7gel\u00b7Glas", "so", "gl\u00e4nt\u00b7zend", "und", "so", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als wie, in Blanckenburgs polirtem Marmor-Stein,", "tokens": ["Als", "wie", ",", "in", "Blan\u00b7cken\u00b7burgs", "po\u00b7lir\u00b7tem", "Mar\u00b7mor\u00b7Stein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "$,", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die abgeschliff'nen Fl\u00e4chen seyn.", "tokens": ["Die", "ab\u00b7ge\u00b7schliff'\u00b7nen", "Fl\u00e4\u00b7chen", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Wie oft hab ich in ihm, als wie im reinsten Spiegel,", "tokens": ["Wie", "oft", "hab", "ich", "in", "ihm", ",", "als", "wie", "im", "reins\u00b7ten", "Spie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "APPR", "PPER", "$,", "KOUS", "KOKOM", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Geb\u00fcsche, Feld und Wald, und Thal, und Berg' und H\u00fcgel,", "tokens": ["Ge\u00b7b\u00fc\u00b7sche", ",", "Feld", "und", "Wald", ",", "und", "Thal", ",", "und", "Ber\u00b7g'", "und", "H\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ja gar, mit inniglichen Freuden,", "tokens": ["Ja", "gar", ",", "mit", "in\u00b7nig\u00b7li\u00b7chen", "Freu\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Bald im verwachs'nen Thal, bald auf den steilen H\u00f6h'n,", "tokens": ["Bald", "im", "ver\u00b7wachs'\u00b7nen", "Thal", ",", "bald", "auf", "den", "stei\u00b7len", "H\u00f6h'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch meine liebste Heerde weiden,", "tokens": ["Auch", "mei\u00b7ne", "liebs\u00b7te", "Heer\u00b7de", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und meine Ziegen klettern sehn.", "tokens": ["Und", "mei\u00b7ne", "Zie\u00b7gen", "klet\u00b7tern", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Man kann, in Blanckenburgs Geb\u00fcrg- und ihren Gr\u00fcnden,", "tokens": ["Man", "kann", ",", "in", "Blan\u00b7cken\u00b7burgs", "Ge\u00b7b\u00fcr\u00b7g", "und", "ih\u00b7ren", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,", "APPR", "NE", "TRUNC", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von allen Farben Marmor finden,", "tokens": ["Von", "al\u00b7len", "Far\u00b7ben", "Mar\u00b7mor", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So wie man ihn verlangt:", "tokens": ["So", "wie", "man", "ihn", "ver\u00b7langt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da bald ein helles Wei\u00df im rothen Grunde prangt;", "tokens": ["Da", "bald", "ein", "hel\u00b7les", "Wei\u00df", "im", "ro\u00b7then", "Grun\u00b7de", "prangt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da er bald braun, bald schwartz, vermischt mit wei\u00df und grau,", "tokens": ["Da", "er", "bald", "braun", ",", "bald", "schwartz", ",", "ver\u00b7mischt", "mit", "wei\u00df", "und", "grau", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "VVFIN", "APPR", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald gelb und gr\u00fcn so gar,", "tokens": ["Bald", "gelb", "und", "gr\u00fcn", "so", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "(das, selbst in Griechenland und Welschland, Wunderrar)", "tokens": ["(", "das", ",", "selbst", "in", "Grie\u00b7chen\u00b7land", "und", "Wel\u00b7schland", ",", "Wun\u00b7der\u00b7rar", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PDS", "$,", "ADV", "APPR", "NE", "KON", "NN", "$,", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald bunt gesprenget ist, mit roth, mit gr\u00fcn und blau.", "tokens": ["Bald", "bunt", "ge\u00b7spren\u00b7get", "ist", ",", "mit", "roth", ",", "mit", "gr\u00fcn", "und", "blau", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "$,", "APPR", "ADJD", "$,", "APPR", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.75": {"line.1": {"text": "Wer bildet nun des Marmors bunte Pracht?", "tokens": ["Wer", "bil\u00b7det", "nun", "des", "Mar\u00b7mors", "bun\u00b7te", "Pracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer hat die Felsen selbst so sch\u00f6n, so glatt gemacht?", "tokens": ["Wer", "hat", "die", "Fel\u00b7sen", "selbst", "so", "sch\u00f6n", ",", "so", "glatt", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Derselbe, der der bunten Bluhmen Zier", "tokens": ["Der\u00b7sel\u00b7be", ",", "der", "der", "bun\u00b7ten", "Bluh\u00b7men", "Zier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So Wunder-w\u00fcrdig f\u00e4rbt, der f\u00e4rbet gleichfalls hier,", "tokens": ["So", "Wun\u00b7der\u00b7w\u00fcr\u00b7dig", "f\u00e4rbt", ",", "der", "f\u00e4r\u00b7bet", "gleich\u00b7falls", "hier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu unsrer Augen-Lust, den Sand, und schm\u00fcckt den Stein", "tokens": ["Zu", "uns\u00b7rer", "Au\u00b7gen\u00b7Lust", ",", "den", "Sand", ",", "und", "schm\u00fcckt", "den", "Stein"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit tausend-f\u00e4rbigen Figuren, Glantz und Schein.", "tokens": ["Mit", "tau\u00b7sen\u00b7df\u00e4r\u00b7bi\u00b7gen", "Fi\u00b7gu\u00b7ren", ",", "Glantz", "und", "Schein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und eben Der verlieh' auch uns den Witz,", "tokens": ["Und", "e\u00b7ben", "Der", "ver\u00b7lieh'", "auch", "uns", "den", "Witz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "VVFIN", "ADV", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Denselbigen so k\u00fcnstlich zu poliren,", "tokens": ["Den\u00b7sel\u00b7bi\u00b7gen", "so", "k\u00fcnst\u00b7lich", "zu", "po\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+--", "measure": "anapaest.tri.plus"}, "line.9": {"text": "Da er ja sonsten uns zu nichtes n\u00fctz'.", "tokens": ["Da", "er", "ja", "sons\u00b7ten", "uns", "zu", "nich\u00b7tes", "n\u00fctz'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "PPER", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wie sollte denn auch daf\u00fcr nicht", "tokens": ["Wie", "soll\u00b7te", "denn", "auch", "da\u00b7f\u00fcr", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ADV", "ADV", "PAV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der Allmacht, ohne die nichts, was geschicht, geschicht,", "tokens": ["Der", "All\u00b7macht", ",", "oh\u00b7ne", "die", "nichts", ",", "was", "ge\u00b7schicht", ",", "ge\u00b7schicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUI", "ART", "PIS", "$,", "PRELS", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Erkenntlichkeit und Danck geb\u00fchren?", "tokens": ["Er\u00b7kennt\u00b7lich\u00b7keit", "und", "Danck", "ge\u00b7b\u00fch\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "Wir sollten billig nie den Blick", "tokens": ["Wir", "soll\u00b7ten", "bil\u00b7lig", "nie", "den", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf den so sch\u00f6n- und bunten Marmor lencken;", "tokens": ["Auf", "den", "so", "sch\u00f6n", "und", "bun\u00b7ten", "Mar\u00b7mor", "len\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "TRUNC", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ohn' auf die Kraft, die ihn formirt, zur\u00fcck,", "tokens": ["Ohn'", "auf", "die", "Kraft", ",", "die", "ihn", "for\u00b7mirt", ",", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "PTKVZ", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Bey unsrer Augen-Lust, zu dencken.", "tokens": ["Bey", "uns\u00b7rer", "Au\u00b7gen\u00b7Lust", ",", "zu", "den\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "O! welch ein Schatz demnach, der nicht zu sch\u00e4tzen,", "tokens": ["O", "!", "welch", "ein", "Schatz", "dem\u00b7nach", ",", "der", "nicht", "zu", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAT", "ART", "NN", "PAV", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So wohl zum Nutzen als Ergetzen,", "tokens": ["So", "wohl", "zum", "Nut\u00b7zen", "als", "Er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "KOUS", "NN", "$,"], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zur Zier und mancherley Gebrauch,", "tokens": ["Zur", "Zier", "und", "man\u00b7cher\u00b7ley", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Liegt hier in dieses Berges Bauch!", "tokens": ["Liegt", "hier", "in", "die\u00b7ses", "Ber\u00b7ges", "Bauch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer wird doch alle Dinge nennen,", "tokens": ["Wer", "wird", "doch", "al\u00b7le", "Din\u00b7ge", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Beschreiben und erz\u00e4hlen k\u00f6nnen,", "tokens": ["Be\u00b7schrei\u00b7ben", "und", "er\u00b7z\u00e4h\u00b7len", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die man, so wohl zur Dauer, als zur Pracht,", "tokens": ["Die", "man", ",", "so", "wohl", "zur", "Dau\u00b7er", ",", "als", "zur", "Pracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "ADV", "ADV", "APPRART", "NN", "$,", "KOUS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Aus Blanckenburgs polirtem Marmor macht!", "tokens": ["Aus", "Blan\u00b7cken\u00b7burgs", "po\u00b7lir\u00b7tem", "Mar\u00b7mor", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.78": {"line.1": {"text": "Der Himmel solchen Schatz gesenckt,", "tokens": ["Der", "Him\u00b7mel", "sol\u00b7chen", "Schatz", "ge\u00b7senckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und solchen Marmor dir geschenckt,", "tokens": ["Und", "sol\u00b7chen", "Mar\u00b7mor", "dir", "ge\u00b7schenckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich in Welschland selbst nicht seines gleichen finde,", "tokens": ["Da\u00df", "ich", "in", "Wel\u00b7schland", "selbst", "nicht", "sei\u00b7nes", "glei\u00b7chen", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "PTKNEG", "PPOSAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Selbst der, den Paros zeugt, kann ihm, an Glantz, nicht gleichen,", "tokens": ["Selbst", "der", ",", "den", "Pa\u00b7ros", "zeugt", ",", "kann", "ihm", ",", "an", "Glantz", ",", "nicht", "glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "ART", "NN", "VVFIN", "$,", "VMFIN", "PPER", "$,", "APPR", "NN", "$,", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und der, aus Tenarus, mu\u00df ihm, an Farben, weichen:", "tokens": ["Und", "der", ",", "aus", "Ten\u00b7a\u00b7rus", ",", "mu\u00df", "ihm", ",", "an", "Far\u00b7ben", ",", "wei\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "$,", "APPR", "NE", "$,", "VMFIN", "PPER", "$,", "APPR", "NN", "$,", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Da er, von Jaspis hier, und dorten von Achat,", "tokens": ["Da", "er", ",", "von", "Jas\u00b7pis", "hier", ",", "und", "dor\u00b7ten", "von", "A\u00b7chat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "NE", "ADV", "$,", "KON", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den Glantz, die Farb' und Adern hat.", "tokens": ["Den", "Glantz", ",", "die", "Fa\u00b7rb'", "und", "A\u00b7dern", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Was sag' ich? ja bey dem, da er so sch\u00f6n geziert,", "tokens": ["Was", "sag'", "ich", "?", "ja", "bey", "dem", ",", "da", "er", "so", "sch\u00f6n", "ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "ADV", "APPR", "ART", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "So Jaspis, als Achat selbst seinen Preis verliert.", "tokens": ["So", "Jas\u00b7pis", ",", "als", "A\u00b7chat", "selbst", "sei\u00b7nen", "Preis", "ver\u00b7liert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "KOUS", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.79": {"line.1": {"text": "Dein ietziger Beherrscher ist es werth,", "tokens": ["Dein", "iet\u00b7zi\u00b7ger", "Be\u00b7herr\u00b7scher", "ist", "es", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "(ich sag' es ohne Schmeicheley)", "tokens": ["(", "ich", "sag'", "es", "oh\u00b7ne", "Schmei\u00b7che\u00b7ley", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Ihm ein solches Land beschert,", "tokens": ["Da\u00df", "Ihm", "ein", "sol\u00b7ches", "Land", "be\u00b7schert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Woselbst, um Sein Verdienst (das nie genug zu sch\u00e4tzen)", "tokens": ["Wo\u00b7selbst", ",", "um", "Sein", "Ver\u00b7dienst", "(", "das", "nie", "ge\u00b7nug", "zu", "sch\u00e4t\u00b7zen", ")"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUI", "PPOSAT", "NN", "$(", "PDS", "ADV", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In festen Marmor einzu\u00e4tzen,", "tokens": ["In", "fes\u00b7ten", "Mar\u00b7mor", "ein\u00b7zu\u00b7\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "An Marmor kein Gebrechen sey.", "tokens": ["An", "Mar\u00b7mor", "kein", "Ge\u00b7bre\u00b7chen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Ist ehedem ein Berg, wie ich einmahl gelesen,", "tokens": ["Ist", "e\u00b7he\u00b7dem", "ein", "Berg", ",", "wie", "ich", "ein\u00b7mahl", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zur Bild-Seul' einem Helden dort,", "tokens": ["Zur", "Bild\u00b7Seul'", "ei\u00b7nem", "Hel\u00b7den", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Nachruhm, zugedacht gewesen;", "tokens": ["Zum", "Nach\u00b7ruhm", ",", "zu\u00b7ge\u00b7dacht", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So ist ja wohl kein bess'rer Ort,", "tokens": ["So", "ist", "ja", "wohl", "kein", "bess'\u00b7rer", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Um diesem Herrn ein Ehren-Mahl zu bauen,", "tokens": ["Um", "die\u00b7sem", "Herrn", "ein", "Eh\u00b7ren\u00b7Mahl", "zu", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als jenen Marmor-Berg, den wir dort vor uns schauen,", "tokens": ["Als", "je\u00b7nen", "Mar\u00b7mor\u00b7Berg", ",", "den", "wir", "dort", "vor", "uns", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "PRELS", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Der Seine Wohnung tr\u00e4gt, f\u00fcr Ihn zurecht zu hauen.", "tokens": ["Der", "Sei\u00b7ne", "Woh\u00b7nung", "tr\u00e4gt", ",", "f\u00fcr", "Ihn", "zu\u00b7recht", "zu", "hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,", "APPR", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.81": {"line.1": {"text": "Wie wenig F\u00fcrsten sind auf Erden,", "tokens": ["Wie", "we\u00b7nig", "F\u00fcrs\u00b7ten", "sind", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die von den Unterthanen mehr", "tokens": ["Die", "von", "den", "Un\u00b7ter\u00b7tha\u00b7nen", "mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geliebet, als gef\u00fcrchtet werden!", "tokens": ["Ge\u00b7lie\u00b7bet", ",", "als", "ge\u00b7f\u00fcrch\u00b7tet", "wer\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie wenig sind geschickt, ein Krieges-Heer", "tokens": ["Wie", "we\u00b7nig", "sind", "ge\u00b7schickt", ",", "ein", "Krie\u00b7ge\u00b7sHeer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PIS", "VAFIN", "VVPP", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mit eig'nem Vorgang anzuf\u00fchren!", "tokens": ["Mit", "eig'\u00b7nem", "Vor\u00b7gang", "an\u00b7zu\u00b7f\u00fch\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie wenig F\u00fcrsten sind, die selbst regieren!", "tokens": ["Wie", "we\u00b7nig", "F\u00fcrs\u00b7ten", "sind", ",", "die", "selbst", "re\u00b7gie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "$,", "PRELS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Bey denen Fr\u00f6mmigkeit sich mit der Staats-Kunst paart", "tokens": ["Bey", "de\u00b7nen", "Fr\u00f6m\u00b7mig\u00b7keit", "sich", "mit", "der", "Staats\u00b7Kunst", "paart"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "NN", "PRF", "APPR", "ART", "NN", "NE"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Wie selten ist ein F\u00fcrst, der im Gelehrten Orden,", "tokens": ["Wie", "sel\u00b7ten", "ist", "ein", "F\u00fcrst", ",", "der", "im", "Ge\u00b7lehr\u00b7ten", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Auf Schwartzburgs G\u00fcnthers Art,", "tokens": ["Auf", "Schwartz\u00b7burgs", "G\u00fcn\u00b7thers", "Art", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Zum Mitglied nicht allein, zum Wunder worden,", "tokens": ["Zum", "Mit\u00b7glied", "nicht", "al\u00b7lein", ",", "zum", "Wun\u00b7der", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKNEG", "ADV", "$,", "APPRART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.12": {"text": "Den selbst der Sechste ", "tokens": ["Den", "selbst", "der", "Sechs\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.82": {"line.1": {"text": "Wer z\u00e4hlt die Tugenden, die gleichfalls sonder Zahl,", "tokens": ["Wer", "z\u00e4hlt", "die", "Tu\u00b7gen\u00b7den", ",", "die", "gleich\u00b7falls", "son\u00b7der", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An Dessen w\u00fcrd'gem Eh-Gemahl,", "tokens": ["An", "Des\u00b7sen", "w\u00fcrd'\u00b7gem", "Eh\u00b7Ge\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der theuersten ", "tokens": ["Der", "theu\u00b7ers\u00b7ten"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Die so, wie Er den F\u00fcrsten, den F\u00fcrstinnen", "tokens": ["Die", "so", ",", "wie", "Er", "den", "F\u00fcrs\u00b7ten", ",", "den", "F\u00fcrs\u00b7tin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADV", "$,", "PWAV", "PPER", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Von je her sich mit Recht zu einem Muster wiese;", "tokens": ["Von", "je", "her", "sich", "mit", "Recht", "zu", "ei\u00b7nem", "Mus\u00b7ter", "wie\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "PRF", "APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und die, nicht nur ihr Unterthan,", "tokens": ["Und", "die", ",", "nicht", "nur", "ihr", "Un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PTKNEG", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein jeder, er sey fern und nah,", "tokens": ["Ein", "je\u00b7der", ",", "er", "sey", "fern", "und", "nah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "PPER", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Der Sie nur einmahl sah,", "tokens": ["Der", "Sie", "nur", "ein\u00b7mahl", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Mit Ehrfurchts-voller Lieb', als unvergleichlich, priese.", "tokens": ["Mit", "Ehr\u00b7furchts\u00b7vol\u00b7ler", "Lieb'", ",", "als", "un\u00b7ver\u00b7gleich\u00b7lich", ",", "prie\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "KOUS", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was hab' ich nicht, eh' ich den Hof verlassen,", "tokens": ["Was", "hab'", "ich", "nicht", ",", "eh'", "ich", "den", "Hof", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Um mit dem Hirten-Stab die Ruh' hier zu umfassen,", "tokens": ["Um", "mit", "dem", "Hir\u00b7ten\u00b7Stab", "die", "Ruh'", "hier", "zu", "um\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von Ihrem Hohen Geist gesehen und geh\u00f6rt!", "tokens": ["Von", "Ih\u00b7rem", "Ho\u00b7hen", "Geist", "ge\u00b7se\u00b7hen", "und", "ge\u00b7h\u00f6rt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was hat Sie nicht, durch Gro\u00dfmuth angetrieben,", "tokens": ["Was", "hat", "Sie", "nicht", ",", "durch", "Gro\u00df\u00b7muth", "an\u00b7ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Zum Heil des Teutschen Reichs, mit eig'ner Hand geschrieben!", "tokens": ["Zum", "Heil", "des", "Teut\u00b7schen", "Reichs", ",", "mit", "eig'\u00b7ner", "Hand", "ge\u00b7schrie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.83": {"line.1": {"text": "Wie wird nicht dieses Paar in Ost und West geehrt!", "tokens": ["Wie", "wird", "nicht", "die\u00b7ses", "Paar", "in", "Ost", "und", "West", "ge\u00b7ehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PTKNEG", "PDAT", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht Teutschland nur, Europa w\u00fcnschet ihnen,", "tokens": ["Nicht", "Teutschland", "nur", ",", "Eu\u00b7ro\u00b7pa", "w\u00fcn\u00b7schet", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "ADV", "$,", "NE", "VVFIN", "PPER", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Absonderlich f\u00fcr die so sch\u00f6ne Kaiserinn,", "tokens": ["Ab\u00b7son\u00b7der\u00b7lich", "f\u00fcr", "die", "so", "sch\u00f6\u00b7ne", "Kai\u00b7se\u00b7rinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So Sie der Welt geschenckt, aus Danck-erf\u00fclltem Sinn,", "tokens": ["So", "Sie", "der", "Welt", "ge\u00b7schenckt", ",", "aus", "Dan\u00b7ck\u00b7er\u00b7f\u00fcll\u00b7tem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Damit sie lange noch in stetem Gl\u00fccke gr\u00fcnen:", "tokens": ["Da\u00b7mit", "sie", "lan\u00b7ge", "noch", "in", "ste\u00b7tem", "Gl\u00fc\u00b7cke", "gr\u00fc\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.84": {"line.1": {"text": "Himmel, la\u00df es doch geschehn,", "tokens": ["Him\u00b7mel", ",", "la\u00df", "es", "doch", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df Ihr f\u00fcrstlich Wohlergehn,", "tokens": ["Da\u00df", "Ihr", "f\u00fcrst\u00b7lich", "Woh\u00b7ler\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An der Dauer, Marmor gleiche!", "tokens": ["An", "der", "Dau\u00b7er", ",", "Mar\u00b7mor", "glei\u00b7che", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df die\u00df theure F\u00fcrsten-Paar", "tokens": ["Da\u00df", "die\u00df", "theu\u00b7re", "F\u00fcrs\u00b7ten\u00b7Paar"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PDS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Noch ein oft vervielfacht Jahr,", "tokens": ["Noch", "ein", "oft", "ver\u00b7viel\u00b7facht", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADV", "VVPP", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ja das sp\u00e4tste Ziel erreiche,", "tokens": ["Ja", "das", "sp\u00e4ts\u00b7te", "Ziel", "er\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "So allhier, in diesem Leben", "tokens": ["So", "all\u00b7hier", ",", "in", "die\u00b7sem", "Le\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "APPR", "PDAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Einem Sterblichen gegeben!", "tokens": ["Ei\u00b7nem", "Sterb\u00b7li\u00b7chen", "ge\u00b7ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.85": {"line.1": {"text": "Kaum kam Beraldo mit dem Lesen", "tokens": ["Kaum", "kam", "Be\u00b7ral\u00b7do", "mit", "dem", "Le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So weit; als ihn Silvander unterbrach,", "tokens": ["So", "weit", ";", "als", "ihn", "Sil\u00b7van\u00b7der", "un\u00b7ter\u00b7brach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und, voller Freuden, rief und sprach:", "tokens": ["Und", ",", "vol\u00b7ler", "Freu\u00b7den", ",", "rief", "und", "sprach", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJA", "NN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie lieb, Beraldo, ist es mir,", "tokens": ["Wie", "lieb", ",", "Be\u00b7ral\u00b7do", ",", "ist", "es", "mir", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "NE", "$,", "VAFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Teutschlands Ehre, Ruhm und Zier,", "tokens": ["Da\u00df", "Teutschlands", "Eh\u00b7re", ",", "Ruhm", "und", "Zier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fcrst, ", "tokens": ["F\u00fcrst", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Ein Vorwurf deines Kiels gewesen!", "tokens": ["Ein", "Vor\u00b7wurf", "dei\u00b7nes", "Kiels", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auch ich hab' gestern Nachmittag,", "tokens": ["Auch", "ich", "hab'", "ge\u00b7stern", "Nach\u00b7mit\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "(indem ich es mir l\u00e4ngstens vorgenommen)", "tokens": ["(", "in\u00b7dem", "ich", "es", "mir", "l\u00e4ngs\u00b7tens", "vor\u00b7ge\u00b7nom\u00b7men", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "In einem Liede viel von Seinem Ruhm erz\u00e4hlt,", "tokens": ["In", "ei\u00b7nem", "Lie\u00b7de", "viel", "von", "Sei\u00b7nem", "Ruhm", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So ich dir zeigen will, wann wir zur\u00fcck gekommen.", "tokens": ["So", "ich", "dir", "zei\u00b7gen", "will", ",", "wann", "wir", "zu\u00b7r\u00fcck", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPER", "VVINF", "VMFIN", "$,", "PWAV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und, weil daran nichts, als der Schlu\u00df, noch fehlt,", "tokens": ["Und", ",", "weil", "da\u00b7ran", "nichts", ",", "als", "der", "Schlu\u00df", ",", "noch", "fehlt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PAV", "PIS", "$,", "KOUS", "ART", "NN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So wirst du, auf mein Bitten,", "tokens": ["So", "wirst", "du", ",", "auf", "mein", "Bit\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "In meiner Schatten-reichen H\u00fctten,", "tokens": ["In", "mei\u00b7ner", "Schat\u00b7ten\u00b7rei\u00b7chen", "H\u00fct\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "F\u00fcr Sein lang daurendes Vergn\u00fcgen,", "tokens": ["F\u00fcr", "Sein", "lang", "dau\u00b7ren\u00b7des", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Auch deinen Wunsch zu meinem f\u00fcgen.", "tokens": ["Auch", "dei\u00b7nen", "Wunsch", "zu", "mei\u00b7nem", "f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Sodann, und eher nicht, will ich, was auf das Eisen", "tokens": ["So\u00b7dann", ",", "und", "e\u00b7her", "nicht", ",", "will", "ich", ",", "was", "auf", "das", "Ei\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KON", "ADV", "PTKNEG", "$,", "VMFIN", "PPER", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von mir verfertigt ward, unausgesetzt dir weisen.", "tokens": ["Von", "mir", "ver\u00b7fer\u00b7tigt", "ward", ",", "un\u00b7aus\u00b7ge\u00b7setzt", "dir", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$,", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.86": {"line.1": {"text": "Ja! rief ", "tokens": ["Ja", "!", "rief"], "token_info": ["word", "punct", "word"], "pos": ["PTKANT", "$.", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Und zwar um desto mehr zu dieser Zeit,", "tokens": ["Und", "zwar", "um", "des\u00b7to", "mehr", "zu", "die\u00b7ser", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da mich ein ungewohnt- und froher Trieb will zwingen,", "tokens": ["Da", "mich", "ein", "un\u00b7ge\u00b7wohnt", "und", "fro\u00b7her", "Trieb", "will", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "TRUNC", "KON", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was k\u00fcnftiges, schon zum voraus, zu singen,", "tokens": ["Was", "k\u00fcnf\u00b7ti\u00b7ges", ",", "schon", "zum", "vo\u00b7raus", ",", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJA", "$,", "ADV", "APPRART", "PTKVZ", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie ich wohl eh' gethan:", "tokens": ["Wie", "ich", "wohl", "eh'", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}