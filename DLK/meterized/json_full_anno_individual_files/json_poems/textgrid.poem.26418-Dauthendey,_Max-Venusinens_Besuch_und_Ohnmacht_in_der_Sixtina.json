{"textgrid.poem.26418": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Venusinens Besuch und Ohnmacht in der Sixtina", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbmu\u00df noch zur Sixtina,\u00ab", "tokens": ["\u00bb", "mu\u00df", "noch", "zur", "Six\u00b7ti\u00b7na", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "ADV", "APPRART", "NE", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Rief die Venus eilig.", "tokens": ["Rief", "die", "Ve\u00b7nus", "ei\u00b7lig", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbdiese ist besonders", "tokens": ["\u00bb", "die\u00b7se", "ist", "be\u00b7son\u00b7ders"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Meinem Herzen heilig.", "tokens": ["Mei\u00b7nem", "Her\u00b7zen", "hei\u00b7lig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "H\u00f6rte: es vergehen", "tokens": ["H\u00f6r\u00b7te", ":", "es", "ver\u00b7ge\u00b7hen"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dort die Christusbilder,", "tokens": ["Dort", "die", "Chris\u00b7tus\u00b7bil\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die schon lang bestehen.", "tokens": ["Die", "schon", "lang", "be\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Angelo, der Meister,", "tokens": ["An\u00b7ge\u00b7lo", ",", "der", "Meis\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Er kehrt niemals wieder,", "tokens": ["Er", "kehrt", "nie\u00b7mals", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und vor seinen Werken", "tokens": ["Und", "vor", "sei\u00b7nen", "Wer\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Knie auch ich gern nieder,", "tokens": ["Knie", "auch", "ich", "gern", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Lieb ihn, den das Nackte,", "tokens": ["Lieb", "ihn", ",", "den", "das", "Nack\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PRELS", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "M\u00e4chtig wie die G\u00f6tter,", "tokens": ["M\u00e4ch\u00b7tig", "wie", "die", "G\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stets von Grund aus packte.", "tokens": ["Stets", "von", "Grund", "aus", "pack\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Tat heut Nacht ersuchen", "tokens": ["Tat", "heut", "Nacht", "er\u00b7su\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Meinen Signor Teufel:", "tokens": ["Mei\u00b7nen", "Sig\u00b7nor", "Teu\u00b7fel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NE", "$."], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "\u203areparier' Sixtina!\u2039", "tokens": ["\u203a", "re\u00b7pa\u00b7rier'", "Six\u00b7ti\u00b7na", "!", "\u2039"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch er hegte Zweifel.", "tokens": ["Doch", "er", "heg\u00b7te", "Zwei\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Will mir's selbst ansehen,", "tokens": ["Will", "mir's", "selbst", "an\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ob er nachgeholfen.", "tokens": ["Ob", "er", "nach\u00b7ge\u00b7hol\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Etwas mu\u00df geschehen!\u00ab", "tokens": ["Et\u00b7was", "mu\u00df", "ge\u00b7sche\u00b7hen", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Zu dem Vatikane", "tokens": ["Zu", "dem", "Va\u00b7ti\u00b7ka\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mit besorgter Miene", "tokens": ["Mit", "be\u00b7sorg\u00b7ter", "Mie\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eilte kunstverst\u00e4ndig", "tokens": ["Eil\u00b7te", "kunst\u00b7ver\u00b7st\u00e4n\u00b7dig"], "token_info": ["word", "word"], "pos": ["VVFIN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Schleunigst Venusine", "tokens": ["Schleu\u00b7nigst", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "+--+--", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Durch die Schweizer Wachen,", "tokens": ["Durch", "die", "Schwei\u00b7zer", "Wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die der sch\u00f6nsten Dame", "tokens": ["Die", "der", "sch\u00f6ns\u00b7ten", "Da\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Liebeszeichen machen.", "tokens": ["Lie\u00b7bes\u00b7zei\u00b7chen", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Sie ersteigt die Treppen.", "tokens": ["Sie", "er\u00b7steigt", "die", "Trep\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Im Entr\u00e9 voll Farben", "tokens": ["Im", "Ent\u00b7r\u00e9", "voll", "Far\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Standen bleiche Leute,", "tokens": ["Stan\u00b7den", "blei\u00b7che", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Bleich, als ob sie starben,", "tokens": ["Bleich", ",", "als", "ob", "sie", "star\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Kopfsch\u00fctteln die K\u00f6pfe,", "tokens": ["Kopf\u00b7sch\u00fct\u00b7teln", "die", "K\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Schienen zu ersticken,", "tokens": ["Schie\u00b7nen", "zu", "er\u00b7sti\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kriegten beinah Kr\u00f6pfe.", "tokens": ["Krieg\u00b7ten", "bei\u00b7nah", "Kr\u00f6p\u00b7fe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Da kam auch der Teufel", "tokens": ["Da", "kam", "auch", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Venus schon entgegen.", "tokens": ["Ve\u00b7nus", "schon", "ent\u00b7ge\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Bat: \u00bbGeh nicht mehr weiter", "tokens": ["Bat", ":", "\u00bb", "Geh", "nicht", "mehr", "wei\u00b7ter"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "$(", "NE", "PTKNEG", "ADV", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der Sixtina wegen!\u00ab", "tokens": ["Der", "Six\u00b7ti\u00b7na", "we\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NE", "APPR", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.12": {"line.1": {"text": "War im Reiserocke", "tokens": ["War", "im", "Rei\u00b7se\u00b7ro\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie ein Operns\u00e4nger,", "tokens": ["Wie", "ein", "O\u00b7pern\u00b7s\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In der Stirn die Locke.", "tokens": ["In", "der", "Stirn", "die", "Lo\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Venus voll Erstaunen", "tokens": ["Ve\u00b7nus", "voll", "Er\u00b7stau\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJD", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Fragt: \u00bbWas ist geschehen?", "tokens": ["Fragt", ":", "\u00bb", "Was", "ist", "ge\u00b7sche\u00b7hen", "?"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "PWS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df die Leut wie Leichen", "tokens": ["Da\u00df", "die", "Leut", "wie", "Lei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KOKOM", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Hier im Vorsaal stehen?\u00ab", "tokens": ["Hier", "im", "Vor\u00b7saal", "ste\u00b7hen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPRART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Teufel konnt nicht sprechen.", "tokens": ["Teu\u00b7fel", "konnt", "nicht", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venus kurz entschlossen", "tokens": ["Ve\u00b7nus", "kurz", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJD", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mu\u00dfte Bahn sich brechen.", "tokens": ["Mu\u00df\u00b7te", "Bahn", "sich", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Greift der T\u00fcre Klinke,", "tokens": ["Greift", "der", "T\u00fc\u00b7re", "Klin\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Steht in der Kapelle.", "tokens": ["Steht", "in", "der", "Ka\u00b7pel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Pl\u00f6tzlich sinkt sie nieder", "tokens": ["Pl\u00f6tz\u00b7lich", "sinkt", "sie", "nie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ohnm\u00e4chtig zur Schwelle.", "tokens": ["Ohn\u00b7m\u00e4ch\u00b7tig", "zur", "Schwel\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbteufel,\u00ab ruft der Teufel,", "tokens": ["\u00bb", "teu\u00b7fel", ",", "\u00ab", "ruft", "der", "Teu\u00b7fel", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbich werd's reparieren!", "tokens": ["\u00bb", "ich", "werd's", "re\u00b7pa\u00b7rie\u00b7ren", "!"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Das ist ohne Zweifel.\u00ab", "tokens": ["Das", "ist", "oh\u00b7ne", "Zwei\u00b7fel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Leer in der Kapelle", "tokens": ["Leer", "in", "der", "Ka\u00b7pel\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Waren alle Fl\u00e4chen.", "tokens": ["Wa\u00b7ren", "al\u00b7le", "Fl\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leere \u00f6de Mauern \u2013", "tokens": ["Lee\u00b7re", "\u00f6\u00b7de", "Mau\u00b7ern", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "S'war zum Herzzerbrechen.", "tokens": ["S'\u00b7war", "zum", "Herz\u00b7zer\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Staub lag auf den Fliesen", "tokens": ["Staub", "lag", "auf", "den", "Flie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich, als hab ein Beben", "tokens": ["Gleich", ",", "als", "hab", "ein", "Be\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOKOM", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles umgeschmissen.", "tokens": ["Al\u00b7les", "um\u00b7ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "\u00bbvenus,\u00ab bat der Teufel", "tokens": ["\u00bb", "ve\u00b7nus", ",", "\u00ab", "bat", "der", "Teu\u00b7fel"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "FM.la", "$,", "$(", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kl\u00e4glich in der Miene.", "tokens": ["Kl\u00e4g\u00b7lich", "in", "der", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00fchrt sie fast gebrochen", "tokens": ["F\u00fchrt", "sie", "fast", "ge\u00b7bro\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fort aus der Sixtine.", "tokens": ["Fort", "aus", "der", "Six\u00b7ti\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+--+--", "measure": "dactylic.di.plus"}}, "stanza.20": {"line.1": {"text": "Hat sie fortgeschoben,", "tokens": ["Hat", "sie", "fort\u00b7ge\u00b7scho\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hie\u00df sie niedersitzen", "tokens": ["Hie\u00df", "sie", "nie\u00b7der\u00b7sit\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Erst in der Garderoben.", "tokens": ["Erst", "in", "der", "Gar\u00b7de\u00b7ro\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "++-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "\u00bbla\u00df mich hier erz\u00e4hlen,", "tokens": ["\u00bb", "la\u00df", "mich", "hier", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und Du sollst Dich fassen,\u00ab", "tokens": ["Und", "Du", "sollst", "Dich", "fas\u00b7sen", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Bat auf Knie'n der Teufel.", "tokens": ["Bat", "auf", "Knie'n", "der", "Teu\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "\u00bbals ich Dich verlassen", "tokens": ["\u00bb", "als", "ich", "Dich", "ver\u00b7las\u00b7sen"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "PRF", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Heut im Morgengrauen,", "tokens": ["Heut", "im", "Mor\u00b7gen\u00b7grau\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lief ich nicht gleich weiter", "tokens": ["Lief", "ich", "nicht", "gleich", "wei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu den andern Frauen.", "tokens": ["Zu", "den", "an\u00b7dern", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Eilte zur Sixtina \u2013", "tokens": ["Eil\u00b7te", "zur", "Six\u00b7ti\u00b7na", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NE", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Eifersucht macht Schmerzen,", "tokens": ["Ei\u00b7fer\u00b7sucht", "macht", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wollte nicht, da\u00df Deine", "tokens": ["Woll\u00b7te", "nicht", ",", "da\u00df", "Dei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VMFIN", "PTKNEG", "$,", "KOUS", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Augen Bilder herzen,", "tokens": ["Au\u00b7gen", "Bil\u00b7der", "her\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Jenen gro\u00dfen nackten", "tokens": ["Je\u00b7nen", "gro\u00b7\u00dfen", "nack\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Menschensohn im Bilde, \u2013", "tokens": ["Men\u00b7schen\u00b7sohn", "im", "Bil\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Qualen mich zerhackten.", "tokens": ["Qua\u00b7len", "mich", "zer\u00b7hack\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Jenen da, der richtend", "tokens": ["Je\u00b7nen", "da", ",", "der", "rich\u00b7tend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "ADV", "$,", "PRELS", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Aus den Wolken rannte,", "tokens": ["Aus", "den", "Wol\u00b7ken", "rann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "B\u00f6ses und auch Gutes", "tokens": ["B\u00f6\u00b7ses", "und", "auch", "Gu\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Viel zu ernst erkannte.", "tokens": ["Viel", "zu", "ernst", "er\u00b7kann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Jenen Sohn der N\u00f6te", "tokens": ["Je\u00b7nen", "Sohn", "der", "N\u00f6\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dacht ich zu zerst\u00f6ren,", "tokens": ["Dacht", "ich", "zu", "zer\u00b7st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn ich Kraft aufb\u00f6te.", "tokens": ["Wenn", "ich", "Kraft", "auf\u00b7b\u00f6\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "Tret' in die Sixtina,", "tokens": ["Tret'", "in", "die", "Six\u00b7ti\u00b7na", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Unter tiefstem Schauer,", "tokens": ["Un\u00b7ter", "tiefs\u00b7tem", "Schau\u00b7er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00d6ffne nicht die Lippe,", "tokens": ["\u00d6ff\u00b7ne", "nicht", "die", "Lip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Starre nur zur Mauer", "tokens": ["Star\u00b7re", "nur", "zur", "Mau\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Denkend: wie so m\u00e4chtig", "tokens": ["Den\u00b7kend", ":", "wie", "so", "m\u00e4ch\u00b7tig"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$.", "PWAV", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusin mich machte!", "tokens": ["Ve\u00b7nu\u00b7sin", "mich", "mach\u00b7te", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und war ganz and\u00e4chtig.", "tokens": ["Und", "war", "ganz", "an\u00b7d\u00e4ch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.29": {"line.1": {"text": "Mu\u00dfte niederknieen,", "tokens": ["Mu\u00df\u00b7te", "nie\u00b7der\u00b7kni\u00b7e\u00b7en", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Nicht vorm Kirchenbilde, \u2013", "tokens": ["Nicht", "vorm", "Kir\u00b7chen\u00b7bil\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Vor dem Blut im Herzen,", "tokens": ["Vor", "dem", "Blut", "im", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Das heut Nacht mich stillte;", "tokens": ["Das", "heut", "Nacht", "mich", "still\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.30": {"line.1": {"text": "Vor den kurzen Stunden,", "tokens": ["Vor", "den", "kur\u00b7zen", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da wir nichts mehr wu\u00dften", "tokens": ["Da", "wir", "nichts", "mehr", "wu\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und uns nackt gefunden.", "tokens": ["Und", "uns", "nackt", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.31": {"line.1": {"text": "Pl\u00f6tzlich war's wie Seufzen,", "tokens": ["Pl\u00f6tz\u00b7lich", "wa\u00b7r's", "wie", "Seuf\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "KOKOM", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Das sich um mich windet:", "tokens": ["Das", "sich", "um", "mich", "win\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von den Bilderw\u00e4nden", "tokens": ["Von", "den", "Bil\u00b7der\u00b7w\u00e4n\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "F\u00e4llt die Farb' und schwindet.", "tokens": ["F\u00e4llt", "die", "Fa\u00b7rb'", "und", "schwin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.32": {"line.1": {"text": "Alles, was die Mauer", "tokens": ["Al\u00b7les", ",", "was", "die", "Mau\u00b7er"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hielt, stob in die Winde,", "tokens": ["Hielt", ",", "stob", "in", "die", "Win\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Der Jahrhundert Dauer.\u00ab", "tokens": ["Der", "Jahr\u00b7hun\u00b7dert", "Dau\u00b7er", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.33": {"line.1": {"text": "Venusine staunte", "tokens": ["Ve\u00b7nu\u00b7si\u00b7ne", "staun\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Und war fast beklommen,", "tokens": ["Und", "war", "fast", "be\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Da\u00df der Teufel solche", "tokens": ["Da\u00df", "der", "Teu\u00b7fel", "sol\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PIAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Lieb f\u00fcr sie bekommen.", "tokens": ["Lieb", "f\u00fcr", "sie", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.34": {"line.1": {"text": "Dankte ihm; indessen", "tokens": ["Dank\u00b7te", "ihm", ";", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "$.", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Blieb sie doch inwendig", "tokens": ["Blieb", "sie", "doch", "in\u00b7wen\u00b7dig"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Etwas abgemessen.", "tokens": ["Et\u00b7was", "ab\u00b7ge\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.35": {"line.1": {"text": "Dachte: \u00bbWar des Menschen", "tokens": ["Dach\u00b7te", ":", "\u00bb", "War", "des", "Men\u00b7schen"], "token_info": ["word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "$(", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sohn nicht doch am Ende", "tokens": ["Sohn", "nicht", "doch", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sch\u00f6ner als der Teufel", "tokens": ["Sch\u00f6\u00b7ner", "als", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "An Sixtinas' W\u00e4nde,", "tokens": ["An", "Six\u00b7ti\u00b7nas'", "W\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.36": {"line.1": {"text": "Weil der Teufel wollte,", "tokens": ["Weil", "der", "Teu\u00b7fel", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VMFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df ich den nicht sehen", "tokens": ["Da\u00df", "ich", "den", "nicht", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "PTKNEG", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und nicht lieben sollte?\u00ab", "tokens": ["Und", "nicht", "lie\u00b7ben", "soll\u00b7te", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PTKNEG", "VVINF", "VMFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.37": {"line.1": {"text": "\u00bbja, so sind die Frauen,\u00ab", "tokens": ["\u00bb", "ja", ",", "so", "sind", "die", "Frau\u00b7en", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "ADV", "VAFIN", "ART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Rief gereizt der Teufel,", "tokens": ["Rief", "ge\u00b7reizt", "der", "Teu\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbsehen Angebote", "tokens": ["\u00bb", "se\u00b7hen", "An\u00b7ge\u00b7bo\u00b7te"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Immer an mit Zweifel.", "tokens": ["Im\u00b7mer", "an", "mit", "Zwei\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.38": {"line.1": {"text": "Lieber sind sie Diebe,", "tokens": ["Lie\u00b7ber", "sind", "sie", "Die\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als da\u00df sie die Treue", "tokens": ["Als", "da\u00df", "sie", "die", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sch\u00e4tzen in der Liebe.", "tokens": ["Sch\u00e4t\u00b7zen", "in", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.39": {"line.1": {"text": "Bin nicht stets der B\u00f6se,", "tokens": ["Bin", "nicht", "stets", "der", "B\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Du nicht stets die Gute.", "tokens": ["Du", "nicht", "stets", "die", "Gu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heut in n\u00e4chtger Stunde", "tokens": ["Heut", "in", "n\u00e4cht\u00b7ger", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mischten wir zwei Blute.", "tokens": ["Mischten", "wir", "zwei", "Blu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.40": {"line.1": {"text": "F\u00fchl mich jetzt wie aller", "tokens": ["F\u00fchl", "mich", "jetzt", "wie", "al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "KOKOM", "PIAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sch\u00f6pfung frohe Wesen", "tokens": ["Sch\u00f6p\u00b7fung", "fro\u00b7he", "We\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und doch nicht banaler.", "tokens": ["Und", "doch", "nicht", "ba\u00b7na\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.41": {"line.1": {"text": "Will an leere W\u00e4nde", "tokens": ["Will", "an", "lee\u00b7re", "W\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dir jetzt Christus malen,", "tokens": ["Dir", "jetzt", "Chris\u00b7tus", "ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NE", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leiden auch die H\u00e4nde", "tokens": ["Lei\u00b7den", "auch", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dr\u00fcber Folterqualen.", "tokens": ["Dr\u00fc\u00b7ber", "Fol\u00b7ter\u00b7qua\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.42": {"line.1": {"text": "Sollt's Ideal mal sehen,", "tokens": ["Sollt's", "I\u00b7deal", "mal", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Herrin Venusine,", "tokens": ["Her\u00b7rin", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nackt bis an die Zehen.\u00ab", "tokens": ["Nackt", "bis", "an", "die", "Ze\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.43": {"line.1": {"text": "Seine Stimme hallte", "tokens": ["Sei\u00b7ne", "Stim\u00b7me", "hall\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Donnernd aus dem Blauen.", "tokens": ["Don\u00b7nernd", "aus", "dem", "Blau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Christus den Asketen", "tokens": ["Chris\u00b7tus", "den", "As\u00b7ke\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Schildert er mit Grauen.", "tokens": ["Schil\u00b7dert", "er", "mit", "Grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.44": {"line.1": {"text": "Venus wehrt mit H\u00e4nden,", "tokens": ["Ve\u00b7nus", "wehrt", "mit", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weil die Lust des Blutes", "tokens": ["Weil", "die", "Lust", "des", "Blu\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schmerz wird ihren Lenden.", "tokens": ["Schmerz", "wird", "ih\u00b7ren", "Len\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.45": {"line.1": {"text": "Doch er malt ohn' Gnade,", "tokens": ["Doch", "er", "malt", "ohn'", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Malt mit klaren Z\u00fcgen", "tokens": ["Malt", "mit", "kla\u00b7ren", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Teuflisch 'ne Ballade,", "tokens": ["Teuf\u00b7lisch", "'ne", "Bal\u00b7la\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Schildert ohne L\u00fcgen;", "tokens": ["Schil\u00b7dert", "oh\u00b7ne", "L\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "Schildert den Rivalen,", "tokens": ["Schil\u00b7dert", "den", "Ri\u00b7va\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und sogar die Wahrheit", "tokens": ["Und", "so\u00b7gar", "die", "Wahr\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Macht ihm heut nicht Qualen.", "tokens": ["Macht", "ihm", "heut", "nicht", "Qua\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PTKNEG", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.47": {"line.1": {"text": "Venusin erschrocken,", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7schro\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "S' fing ihr Haar fast Flammen,", "tokens": ["S'", "fing", "ihr", "Haar", "fast", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Fl\u00fcchtet in der Erde", "tokens": ["Fl\u00fcch\u00b7tet", "in", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Herz und kriecht zusammen.", "tokens": ["Herz", "und", "kriecht", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.48": {"line.1": {"text": "Ist voll Angst entwichen,", "tokens": ["Ist", "voll", "Angst", "ent\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und der Teufel hat sich", "tokens": ["Und", "der", "Teu\u00b7fel", "hat", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PRF"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Stolz den Bart gestrichen.", "tokens": ["Stolz", "den", "Bart", "ge\u00b7stri\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.49": {"line.1": {"text": "Horcht jetzt was er sagte!", "tokens": ["Horcht", "jetzt", "was", "er", "sag\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PWS", "PPER", "VVFIN", "$."], "meter": "+++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Teuflisch war's ersonnen.", "tokens": ["Teuf\u00b7lisch", "wa\u00b7r's", "er\u00b7son\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur ein Gott so wagte", "tokens": ["Nur", "ein", "Gott", "so", "wag\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "G\u00f6tter zu entthronen.", "tokens": ["G\u00f6t\u00b7ter", "zu", "ent\u00b7thro\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.50": {"line.1": {"text": "Venus zu gewinnen,", "tokens": ["Ve\u00b7nus", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "----+-", "measure": "unknown.measure.single"}, "line.2": {"text": "Sprach sich selbst der Teufel", "tokens": ["Sprach", "sich", "selbst", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PRF", "ADV", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Heute ganz von Sinnen:", "tokens": ["Heu\u00b7te", "ganz", "von", "Sin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.51": {"line.1": {"text": "\u00bbmu\u00df noch zur Sixtina,\u00ab", "tokens": ["\u00bb", "mu\u00df", "noch", "zur", "Six\u00b7ti\u00b7na", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "ADV", "APPRART", "NE", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Rief die Venus eilig.", "tokens": ["Rief", "die", "Ve\u00b7nus", "ei\u00b7lig", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbdiese ist besonders", "tokens": ["\u00bb", "die\u00b7se", "ist", "be\u00b7son\u00b7ders"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Meinem Herzen heilig.", "tokens": ["Mei\u00b7nem", "Her\u00b7zen", "hei\u00b7lig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.52": {"line.1": {"text": "H\u00f6rte: es vergehen", "tokens": ["H\u00f6r\u00b7te", ":", "es", "ver\u00b7ge\u00b7hen"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dort die Christusbilder,", "tokens": ["Dort", "die", "Chris\u00b7tus\u00b7bil\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die schon lang bestehen.", "tokens": ["Die", "schon", "lang", "be\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.53": {"line.1": {"text": "Angelo, der Meister,", "tokens": ["An\u00b7ge\u00b7lo", ",", "der", "Meis\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Er kehrt niemals wieder,", "tokens": ["Er", "kehrt", "nie\u00b7mals", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und vor seinen Werken", "tokens": ["Und", "vor", "sei\u00b7nen", "Wer\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Knie auch ich gern nieder,", "tokens": ["Knie", "auch", "ich", "gern", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.54": {"line.1": {"text": "Lieb ihn, den das Nackte,", "tokens": ["Lieb", "ihn", ",", "den", "das", "Nack\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PRELS", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "M\u00e4chtig wie die G\u00f6tter,", "tokens": ["M\u00e4ch\u00b7tig", "wie", "die", "G\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stets von Grund aus packte.", "tokens": ["Stets", "von", "Grund", "aus", "pack\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.55": {"line.1": {"text": "Tat heut Nacht ersuchen", "tokens": ["Tat", "heut", "Nacht", "er\u00b7su\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Meinen Signor Teufel:", "tokens": ["Mei\u00b7nen", "Sig\u00b7nor", "Teu\u00b7fel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NE", "$."], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "\u203areparier' Sixtina!\u2039", "tokens": ["\u203a", "re\u00b7pa\u00b7rier'", "Six\u00b7ti\u00b7na", "!", "\u2039"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch er hegte Zweifel.", "tokens": ["Doch", "er", "heg\u00b7te", "Zwei\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.56": {"line.1": {"text": "Will mir's selbst ansehen,", "tokens": ["Will", "mir's", "selbst", "an\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ob er nachgeholfen.", "tokens": ["Ob", "er", "nach\u00b7ge\u00b7hol\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Etwas mu\u00df geschehen!\u00ab", "tokens": ["Et\u00b7was", "mu\u00df", "ge\u00b7sche\u00b7hen", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.57": {"line.1": {"text": "Zu dem Vatikane", "tokens": ["Zu", "dem", "Va\u00b7ti\u00b7ka\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mit besorgter Miene", "tokens": ["Mit", "be\u00b7sorg\u00b7ter", "Mie\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eilte kunstverst\u00e4ndig", "tokens": ["Eil\u00b7te", "kunst\u00b7ver\u00b7st\u00e4n\u00b7dig"], "token_info": ["word", "word"], "pos": ["VVFIN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Schleunigst Venusine", "tokens": ["Schleu\u00b7nigst", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "+--+--", "measure": "dactylic.di.plus"}}, "stanza.58": {"line.1": {"text": "Durch die Schweizer Wachen,", "tokens": ["Durch", "die", "Schwei\u00b7zer", "Wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die der sch\u00f6nsten Dame", "tokens": ["Die", "der", "sch\u00f6ns\u00b7ten", "Da\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Liebeszeichen machen.", "tokens": ["Lie\u00b7bes\u00b7zei\u00b7chen", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.59": {"line.1": {"text": "Sie ersteigt die Treppen.", "tokens": ["Sie", "er\u00b7steigt", "die", "Trep\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Im Entr\u00e9 voll Farben", "tokens": ["Im", "Ent\u00b7r\u00e9", "voll", "Far\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Standen bleiche Leute,", "tokens": ["Stan\u00b7den", "blei\u00b7che", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Bleich, als ob sie starben,", "tokens": ["Bleich", ",", "als", "ob", "sie", "star\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.60": {"line.1": {"text": "Kopfsch\u00fctteln die K\u00f6pfe,", "tokens": ["Kopf\u00b7sch\u00fct\u00b7teln", "die", "K\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Schienen zu ersticken,", "tokens": ["Schie\u00b7nen", "zu", "er\u00b7sti\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kriegten beinah Kr\u00f6pfe.", "tokens": ["Krieg\u00b7ten", "bei\u00b7nah", "Kr\u00f6p\u00b7fe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.61": {"line.1": {"text": "Da kam auch der Teufel", "tokens": ["Da", "kam", "auch", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Venus schon entgegen.", "tokens": ["Ve\u00b7nus", "schon", "ent\u00b7ge\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Bat: \u00bbGeh nicht mehr weiter", "tokens": ["Bat", ":", "\u00bb", "Geh", "nicht", "mehr", "wei\u00b7ter"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "$(", "NE", "PTKNEG", "ADV", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der Sixtina wegen!\u00ab", "tokens": ["Der", "Six\u00b7ti\u00b7na", "we\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NE", "APPR", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.62": {"line.1": {"text": "War im Reiserocke", "tokens": ["War", "im", "Rei\u00b7se\u00b7ro\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie ein Operns\u00e4nger,", "tokens": ["Wie", "ein", "O\u00b7pern\u00b7s\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In der Stirn die Locke.", "tokens": ["In", "der", "Stirn", "die", "Lo\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.63": {"line.1": {"text": "Venus voll Erstaunen", "tokens": ["Ve\u00b7nus", "voll", "Er\u00b7stau\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJD", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Fragt: \u00bbWas ist geschehen?", "tokens": ["Fragt", ":", "\u00bb", "Was", "ist", "ge\u00b7sche\u00b7hen", "?"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "PWS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df die Leut wie Leichen", "tokens": ["Da\u00df", "die", "Leut", "wie", "Lei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KOKOM", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Hier im Vorsaal stehen?\u00ab", "tokens": ["Hier", "im", "Vor\u00b7saal", "ste\u00b7hen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPRART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.64": {"line.1": {"text": "Teufel konnt nicht sprechen.", "tokens": ["Teu\u00b7fel", "konnt", "nicht", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venus kurz entschlossen", "tokens": ["Ve\u00b7nus", "kurz", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJD", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mu\u00dfte Bahn sich brechen.", "tokens": ["Mu\u00df\u00b7te", "Bahn", "sich", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.65": {"line.1": {"text": "Greift der T\u00fcre Klinke,", "tokens": ["Greift", "der", "T\u00fc\u00b7re", "Klin\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Steht in der Kapelle.", "tokens": ["Steht", "in", "der", "Ka\u00b7pel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Pl\u00f6tzlich sinkt sie nieder", "tokens": ["Pl\u00f6tz\u00b7lich", "sinkt", "sie", "nie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ohnm\u00e4chtig zur Schwelle.", "tokens": ["Ohn\u00b7m\u00e4ch\u00b7tig", "zur", "Schwel\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.66": {"line.1": {"text": "\u00bbteufel,\u00ab ruft der Teufel,", "tokens": ["\u00bb", "teu\u00b7fel", ",", "\u00ab", "ruft", "der", "Teu\u00b7fel", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbich werd's reparieren!", "tokens": ["\u00bb", "ich", "werd's", "re\u00b7pa\u00b7rie\u00b7ren", "!"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Das ist ohne Zweifel.\u00ab", "tokens": ["Das", "ist", "oh\u00b7ne", "Zwei\u00b7fel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.67": {"line.1": {"text": "Leer in der Kapelle", "tokens": ["Leer", "in", "der", "Ka\u00b7pel\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Waren alle Fl\u00e4chen.", "tokens": ["Wa\u00b7ren", "al\u00b7le", "Fl\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leere \u00f6de Mauern \u2013", "tokens": ["Lee\u00b7re", "\u00f6\u00b7de", "Mau\u00b7ern", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "S'war zum Herzzerbrechen.", "tokens": ["S'\u00b7war", "zum", "Herz\u00b7zer\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.68": {"line.1": {"text": "Staub lag auf den Fliesen", "tokens": ["Staub", "lag", "auf", "den", "Flie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich, als hab ein Beben", "tokens": ["Gleich", ",", "als", "hab", "ein", "Be\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOKOM", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles umgeschmissen.", "tokens": ["Al\u00b7les", "um\u00b7ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.69": {"line.1": {"text": "\u00bbvenus,\u00ab bat der Teufel", "tokens": ["\u00bb", "ve\u00b7nus", ",", "\u00ab", "bat", "der", "Teu\u00b7fel"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "FM.la", "$,", "$(", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kl\u00e4glich in der Miene.", "tokens": ["Kl\u00e4g\u00b7lich", "in", "der", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00fchrt sie fast gebrochen", "tokens": ["F\u00fchrt", "sie", "fast", "ge\u00b7bro\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fort aus der Sixtine.", "tokens": ["Fort", "aus", "der", "Six\u00b7ti\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+--+--", "measure": "dactylic.di.plus"}}, "stanza.70": {"line.1": {"text": "Hat sie fortgeschoben,", "tokens": ["Hat", "sie", "fort\u00b7ge\u00b7scho\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hie\u00df sie niedersitzen", "tokens": ["Hie\u00df", "sie", "nie\u00b7der\u00b7sit\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Erst in der Garderoben.", "tokens": ["Erst", "in", "der", "Gar\u00b7de\u00b7ro\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "++-+-+-", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "\u00bbla\u00df mich hier erz\u00e4hlen,", "tokens": ["\u00bb", "la\u00df", "mich", "hier", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und Du sollst Dich fassen,\u00ab", "tokens": ["Und", "Du", "sollst", "Dich", "fas\u00b7sen", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Bat auf Knie'n der Teufel.", "tokens": ["Bat", "auf", "Knie'n", "der", "Teu\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "\u00bbals ich Dich verlassen", "tokens": ["\u00bb", "als", "ich", "Dich", "ver\u00b7las\u00b7sen"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "PRF", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.72": {"line.1": {"text": "Heut im Morgengrauen,", "tokens": ["Heut", "im", "Mor\u00b7gen\u00b7grau\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lief ich nicht gleich weiter", "tokens": ["Lief", "ich", "nicht", "gleich", "wei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu den andern Frauen.", "tokens": ["Zu", "den", "an\u00b7dern", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.73": {"line.1": {"text": "Eilte zur Sixtina \u2013", "tokens": ["Eil\u00b7te", "zur", "Six\u00b7ti\u00b7na", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NE", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Eifersucht macht Schmerzen,", "tokens": ["Ei\u00b7fer\u00b7sucht", "macht", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wollte nicht, da\u00df Deine", "tokens": ["Woll\u00b7te", "nicht", ",", "da\u00df", "Dei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VMFIN", "PTKNEG", "$,", "KOUS", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Augen Bilder herzen,", "tokens": ["Au\u00b7gen", "Bil\u00b7der", "her\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.74": {"line.1": {"text": "Jenen gro\u00dfen nackten", "tokens": ["Je\u00b7nen", "gro\u00b7\u00dfen", "nack\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Menschensohn im Bilde, \u2013", "tokens": ["Men\u00b7schen\u00b7sohn", "im", "Bil\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Qualen mich zerhackten.", "tokens": ["Qua\u00b7len", "mich", "zer\u00b7hack\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.75": {"line.1": {"text": "Jenen da, der richtend", "tokens": ["Je\u00b7nen", "da", ",", "der", "rich\u00b7tend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "ADV", "$,", "PRELS", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Aus den Wolken rannte,", "tokens": ["Aus", "den", "Wol\u00b7ken", "rann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "B\u00f6ses und auch Gutes", "tokens": ["B\u00f6\u00b7ses", "und", "auch", "Gu\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Viel zu ernst erkannte.", "tokens": ["Viel", "zu", "ernst", "er\u00b7kann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.76": {"line.1": {"text": "Jenen Sohn der N\u00f6te", "tokens": ["Je\u00b7nen", "Sohn", "der", "N\u00f6\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dacht ich zu zerst\u00f6ren,", "tokens": ["Dacht", "ich", "zu", "zer\u00b7st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn ich Kraft aufb\u00f6te.", "tokens": ["Wenn", "ich", "Kraft", "auf\u00b7b\u00f6\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.77": {"line.1": {"text": "Tret' in die Sixtina,", "tokens": ["Tret'", "in", "die", "Six\u00b7ti\u00b7na", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Unter tiefstem Schauer,", "tokens": ["Un\u00b7ter", "tiefs\u00b7tem", "Schau\u00b7er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00d6ffne nicht die Lippe,", "tokens": ["\u00d6ff\u00b7ne", "nicht", "die", "Lip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Starre nur zur Mauer", "tokens": ["Star\u00b7re", "nur", "zur", "Mau\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.78": {"line.1": {"text": "Denkend: wie so m\u00e4chtig", "tokens": ["Den\u00b7kend", ":", "wie", "so", "m\u00e4ch\u00b7tig"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$.", "PWAV", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusin mich machte!", "tokens": ["Ve\u00b7nu\u00b7sin", "mich", "mach\u00b7te", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und war ganz and\u00e4chtig.", "tokens": ["Und", "war", "ganz", "an\u00b7d\u00e4ch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.79": {"line.1": {"text": "Mu\u00dfte niederknieen,", "tokens": ["Mu\u00df\u00b7te", "nie\u00b7der\u00b7kni\u00b7e\u00b7en", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Nicht vorm Kirchenbilde, \u2013", "tokens": ["Nicht", "vorm", "Kir\u00b7chen\u00b7bil\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Vor dem Blut im Herzen,", "tokens": ["Vor", "dem", "Blut", "im", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Das heut Nacht mich stillte;", "tokens": ["Das", "heut", "Nacht", "mich", "still\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.80": {"line.1": {"text": "Vor den kurzen Stunden,", "tokens": ["Vor", "den", "kur\u00b7zen", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da wir nichts mehr wu\u00dften", "tokens": ["Da", "wir", "nichts", "mehr", "wu\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und uns nackt gefunden.", "tokens": ["Und", "uns", "nackt", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.81": {"line.1": {"text": "Pl\u00f6tzlich war's wie Seufzen,", "tokens": ["Pl\u00f6tz\u00b7lich", "wa\u00b7r's", "wie", "Seuf\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "KOKOM", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Das sich um mich windet:", "tokens": ["Das", "sich", "um", "mich", "win\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von den Bilderw\u00e4nden", "tokens": ["Von", "den", "Bil\u00b7der\u00b7w\u00e4n\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "F\u00e4llt die Farb' und schwindet.", "tokens": ["F\u00e4llt", "die", "Fa\u00b7rb'", "und", "schwin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.82": {"line.1": {"text": "Alles, was die Mauer", "tokens": ["Al\u00b7les", ",", "was", "die", "Mau\u00b7er"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hielt, stob in die Winde,", "tokens": ["Hielt", ",", "stob", "in", "die", "Win\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Der Jahrhundert Dauer.\u00ab", "tokens": ["Der", "Jahr\u00b7hun\u00b7dert", "Dau\u00b7er", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.83": {"line.1": {"text": "Venusine staunte", "tokens": ["Ve\u00b7nu\u00b7si\u00b7ne", "staun\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Und war fast beklommen,", "tokens": ["Und", "war", "fast", "be\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Da\u00df der Teufel solche", "tokens": ["Da\u00df", "der", "Teu\u00b7fel", "sol\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PIAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Lieb f\u00fcr sie bekommen.", "tokens": ["Lieb", "f\u00fcr", "sie", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.84": {"line.1": {"text": "Dankte ihm; indessen", "tokens": ["Dank\u00b7te", "ihm", ";", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "$.", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Blieb sie doch inwendig", "tokens": ["Blieb", "sie", "doch", "in\u00b7wen\u00b7dig"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Etwas abgemessen.", "tokens": ["Et\u00b7was", "ab\u00b7ge\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.85": {"line.1": {"text": "Dachte: \u00bbWar des Menschen", "tokens": ["Dach\u00b7te", ":", "\u00bb", "War", "des", "Men\u00b7schen"], "token_info": ["word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "$(", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sohn nicht doch am Ende", "tokens": ["Sohn", "nicht", "doch", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sch\u00f6ner als der Teufel", "tokens": ["Sch\u00f6\u00b7ner", "als", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "An Sixtinas' W\u00e4nde,", "tokens": ["An", "Six\u00b7ti\u00b7nas'", "W\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.86": {"line.1": {"text": "Weil der Teufel wollte,", "tokens": ["Weil", "der", "Teu\u00b7fel", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VMFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df ich den nicht sehen", "tokens": ["Da\u00df", "ich", "den", "nicht", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "PTKNEG", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und nicht lieben sollte?\u00ab", "tokens": ["Und", "nicht", "lie\u00b7ben", "soll\u00b7te", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PTKNEG", "VVINF", "VMFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.87": {"line.1": {"text": "\u00bbja, so sind die Frauen,\u00ab", "tokens": ["\u00bb", "ja", ",", "so", "sind", "die", "Frau\u00b7en", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "ADV", "VAFIN", "ART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Rief gereizt der Teufel,", "tokens": ["Rief", "ge\u00b7reizt", "der", "Teu\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbsehen Angebote", "tokens": ["\u00bb", "se\u00b7hen", "An\u00b7ge\u00b7bo\u00b7te"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Immer an mit Zweifel.", "tokens": ["Im\u00b7mer", "an", "mit", "Zwei\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.88": {"line.1": {"text": "Lieber sind sie Diebe,", "tokens": ["Lie\u00b7ber", "sind", "sie", "Die\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als da\u00df sie die Treue", "tokens": ["Als", "da\u00df", "sie", "die", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sch\u00e4tzen in der Liebe.", "tokens": ["Sch\u00e4t\u00b7zen", "in", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.89": {"line.1": {"text": "Bin nicht stets der B\u00f6se,", "tokens": ["Bin", "nicht", "stets", "der", "B\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Du nicht stets die Gute.", "tokens": ["Du", "nicht", "stets", "die", "Gu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heut in n\u00e4chtger Stunde", "tokens": ["Heut", "in", "n\u00e4cht\u00b7ger", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mischten wir zwei Blute.", "tokens": ["Mischten", "wir", "zwei", "Blu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.90": {"line.1": {"text": "F\u00fchl mich jetzt wie aller", "tokens": ["F\u00fchl", "mich", "jetzt", "wie", "al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "KOKOM", "PIAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sch\u00f6pfung frohe Wesen", "tokens": ["Sch\u00f6p\u00b7fung", "fro\u00b7he", "We\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und doch nicht banaler.", "tokens": ["Und", "doch", "nicht", "ba\u00b7na\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.91": {"line.1": {"text": "Will an leere W\u00e4nde", "tokens": ["Will", "an", "lee\u00b7re", "W\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dir jetzt Christus malen,", "tokens": ["Dir", "jetzt", "Chris\u00b7tus", "ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NE", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leiden auch die H\u00e4nde", "tokens": ["Lei\u00b7den", "auch", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dr\u00fcber Folterqualen.", "tokens": ["Dr\u00fc\u00b7ber", "Fol\u00b7ter\u00b7qua\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.92": {"line.1": {"text": "Sollt's Ideal mal sehen,", "tokens": ["Sollt's", "I\u00b7deal", "mal", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Herrin Venusine,", "tokens": ["Her\u00b7rin", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nackt bis an die Zehen.\u00ab", "tokens": ["Nackt", "bis", "an", "die", "Ze\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.93": {"line.1": {"text": "Seine Stimme hallte", "tokens": ["Sei\u00b7ne", "Stim\u00b7me", "hall\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Donnernd aus dem Blauen.", "tokens": ["Don\u00b7nernd", "aus", "dem", "Blau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Christus den Asketen", "tokens": ["Chris\u00b7tus", "den", "As\u00b7ke\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Schildert er mit Grauen.", "tokens": ["Schil\u00b7dert", "er", "mit", "Grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.94": {"line.1": {"text": "Venus wehrt mit H\u00e4nden,", "tokens": ["Ve\u00b7nus", "wehrt", "mit", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weil die Lust des Blutes", "tokens": ["Weil", "die", "Lust", "des", "Blu\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schmerz wird ihren Lenden.", "tokens": ["Schmerz", "wird", "ih\u00b7ren", "Len\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.95": {"line.1": {"text": "Doch er malt ohn' Gnade,", "tokens": ["Doch", "er", "malt", "ohn'", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Malt mit klaren Z\u00fcgen", "tokens": ["Malt", "mit", "kla\u00b7ren", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Teuflisch 'ne Ballade,", "tokens": ["Teuf\u00b7lisch", "'ne", "Bal\u00b7la\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Schildert ohne L\u00fcgen;", "tokens": ["Schil\u00b7dert", "oh\u00b7ne", "L\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.96": {"line.1": {"text": "Schildert den Rivalen,", "tokens": ["Schil\u00b7dert", "den", "Ri\u00b7va\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und sogar die Wahrheit", "tokens": ["Und", "so\u00b7gar", "die", "Wahr\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Macht ihm heut nicht Qualen.", "tokens": ["Macht", "ihm", "heut", "nicht", "Qua\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PTKNEG", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.97": {"line.1": {"text": "Venusin erschrocken,", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7schro\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "S' fing ihr Haar fast Flammen,", "tokens": ["S'", "fing", "ihr", "Haar", "fast", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Fl\u00fcchtet in der Erde", "tokens": ["Fl\u00fcch\u00b7tet", "in", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Herz und kriecht zusammen.", "tokens": ["Herz", "und", "kriecht", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.98": {"line.1": {"text": "Ist voll Angst entwichen,", "tokens": ["Ist", "voll", "Angst", "ent\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und der Teufel hat sich", "tokens": ["Und", "der", "Teu\u00b7fel", "hat", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PRF"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Stolz den Bart gestrichen.", "tokens": ["Stolz", "den", "Bart", "ge\u00b7stri\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.99": {"line.1": {"text": "Horcht jetzt was er sagte!", "tokens": ["Horcht", "jetzt", "was", "er", "sag\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PWS", "PPER", "VVFIN", "$."], "meter": "+++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Teuflisch war's ersonnen.", "tokens": ["Teuf\u00b7lisch", "wa\u00b7r's", "er\u00b7son\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur ein Gott so wagte", "tokens": ["Nur", "ein", "Gott", "so", "wag\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "G\u00f6tter zu entthronen.", "tokens": ["G\u00f6t\u00b7ter", "zu", "ent\u00b7thro\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.100": {"line.1": {"text": "Venus zu gewinnen,", "tokens": ["Ve\u00b7nus", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "----+-", "measure": "unknown.measure.single"}, "line.2": {"text": "Sprach sich selbst der Teufel", "tokens": ["Sprach", "sich", "selbst", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PRF", "ADV", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Heute ganz von Sinnen:", "tokens": ["Heu\u00b7te", "ganz", "von", "Sin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}