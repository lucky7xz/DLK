{"textgrid.poem.51198": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nur diesen letzten Rocken", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nur diesen letzten Rocken", "tokens": ["Nur", "die\u00b7sen", "letz\u00b7ten", "Ro\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch spinnt der M\u00e4dchenflei\u00df,", "tokens": ["Noch", "spinnt", "der", "M\u00e4d\u00b7chen\u00b7flei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann schmiegt euch, meine Locken,", "tokens": ["Dann", "schmiegt", "euch", ",", "mei\u00b7ne", "Lo\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem gr\u00fcnen Myrtenreis!", "tokens": ["Dem", "gr\u00fc\u00b7nen", "Myr\u00b7ten\u00b7reis", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich habe lang gesponnen", "tokens": ["Ich", "ha\u00b7be", "lang", "ge\u00b7spon\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und lange mich gefreut:", "tokens": ["Und", "lan\u00b7ge", "mich", "ge\u00b7freut", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Zum Bleichen an der Sonnen", "tokens": ["Zum", "Blei\u00b7chen", "an", "der", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Liegt meine Jugendzeit.", "tokens": ["Liegt", "mei\u00b7ne", "Ju\u00b7gend\u00b7zeit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Mit treuem Mut getan?", "tokens": ["Mit", "treu\u00b7em", "Mut", "ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Betreten schon die ", "tokens": ["Be\u00b7tre\u00b7ten", "schon", "die"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADV", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Des Mannes Ehrenbahn?", "tokens": ["Des", "Man\u00b7nes", "Eh\u00b7ren\u00b7bahn", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Hat innig ", "tokens": ["Hat", "in\u00b7nig"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADJD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Die Arbeit seiner Zeit?", "tokens": ["Die", "Ar\u00b7beit", "sei\u00b7ner", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Zum letzten Kampf bereit?", "tokens": ["Zum", "letz\u00b7ten", "Kampf", "be\u00b7reit", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Weh ihm, wenn er nicht rechten", "tokens": ["Weh", "ihm", ",", "wenn", "er", "nicht", "rech\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "ADJA"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "F\u00fcr unsre Freiheit will!", "tokens": ["F\u00fcr", "uns\u00b7re", "Frei\u00b7heit", "will", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weh ihm, wenn er nicht fechten", "tokens": ["Weh", "ihm", ",", "wenn", "er", "nicht", "fech\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "F\u00fcr sein Gewissen will!", "tokens": ["F\u00fcr", "sein", "Ge\u00b7wis\u00b7sen", "will", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dann mag mein Liebster minnen", "tokens": ["Dann", "mag", "mein", "Liebs\u00b7ter", "min\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Nur auf und ab im Land,", "tokens": ["Nur", "auf", "und", "ab", "im", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und dies mein br\u00e4utlich Linnen", "tokens": ["Und", "dies", "mein", "br\u00e4ut\u00b7lich", "Lin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wird dann ein Grabgewand!", "tokens": ["Wird", "dann", "ein", "Grab\u00b7ge\u00b7wand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Nur diesen letzten Rocken", "tokens": ["Nur", "die\u00b7sen", "letz\u00b7ten", "Ro\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch spinnt der M\u00e4dchenflei\u00df,", "tokens": ["Noch", "spinnt", "der", "M\u00e4d\u00b7chen\u00b7flei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann schmiegt euch, meine Locken,", "tokens": ["Dann", "schmiegt", "euch", ",", "mei\u00b7ne", "Lo\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem gr\u00fcnen Myrtenreis!", "tokens": ["Dem", "gr\u00fc\u00b7nen", "Myr\u00b7ten\u00b7reis", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich habe lang gesponnen", "tokens": ["Ich", "ha\u00b7be", "lang", "ge\u00b7spon\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und lange mich gefreut:", "tokens": ["Und", "lan\u00b7ge", "mich", "ge\u00b7freut", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Zum Bleichen an der Sonnen", "tokens": ["Zum", "Blei\u00b7chen", "an", "der", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Liegt meine Jugendzeit.", "tokens": ["Liegt", "mei\u00b7ne", "Ju\u00b7gend\u00b7zeit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Mit treuem Mut getan?", "tokens": ["Mit", "treu\u00b7em", "Mut", "ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Betreten schon die ", "tokens": ["Be\u00b7tre\u00b7ten", "schon", "die"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADV", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Des Mannes Ehrenbahn?", "tokens": ["Des", "Man\u00b7nes", "Eh\u00b7ren\u00b7bahn", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Hat innig ", "tokens": ["Hat", "in\u00b7nig"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADJD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Die Arbeit seiner Zeit?", "tokens": ["Die", "Ar\u00b7beit", "sei\u00b7ner", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Zum letzten Kampf bereit?", "tokens": ["Zum", "letz\u00b7ten", "Kampf", "be\u00b7reit", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Weh ihm, wenn er nicht rechten", "tokens": ["Weh", "ihm", ",", "wenn", "er", "nicht", "rech\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "ADJA"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "F\u00fcr unsre Freiheit will!", "tokens": ["F\u00fcr", "uns\u00b7re", "Frei\u00b7heit", "will", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weh ihm, wenn er nicht fechten", "tokens": ["Weh", "ihm", ",", "wenn", "er", "nicht", "fech\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "F\u00fcr sein Gewissen will!", "tokens": ["F\u00fcr", "sein", "Ge\u00b7wis\u00b7sen", "will", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dann mag mein Liebster minnen", "tokens": ["Dann", "mag", "mein", "Liebs\u00b7ter", "min\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Nur auf und ab im Land,", "tokens": ["Nur", "auf", "und", "ab", "im", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und dies mein br\u00e4utlich Linnen", "tokens": ["Und", "dies", "mein", "br\u00e4ut\u00b7lich", "Lin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wird dann ein Grabgewand!", "tokens": ["Wird", "dann", "ein", "Grab\u00b7ge\u00b7wand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}