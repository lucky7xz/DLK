{"dta.poem.19753": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "W\u00e4chter h\u00fct dich bas .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es wohnet Lieb bey Liebe,               ", "tokens": ["Es", "woh\u00b7net", "Lieb", "bey", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dazu gro\u00df Herzeleid,", "tokens": ["Da\u00b7zu", "gro\u00df", "Her\u00b7ze\u00b7leid", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein edle Herzoginne,", "tokens": ["Ein", "ed\u00b7le", "Her\u00b7zo\u00b7gin\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Ritter hochgemayt,", "tokens": ["Ein", "Rit\u00b7ter", "hoch\u00b7ge\u00b7mayt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie h\u00e4tten einander von Herzen lieb,", "tokens": ["Sie", "h\u00e4t\u00b7ten", "ein\u00b7an\u00b7der", "von", "Her\u00b7zen", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Da\u00df sie vor grosser Hute", "tokens": ["Da\u00df", "sie", "vor", "gros\u00b7ser", "Hu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Zusammen kamen nie.", "tokens": ["Zu\u00b7sam\u00b7men", "ka\u00b7men", "nie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Jungfrau, die war edel,", "tokens": ["Die", "Jung\u00b7frau", ",", "die", "war", "e\u00b7del", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADJD", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Sie th\u00e4t ein Abendgang,", "tokens": ["Sie", "th\u00e4t", "ein", "A\u00b7bend\u00b7gang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie ging gar traurigliche,", "tokens": ["Sie", "ging", "gar", "trau\u00b7rig\u00b7li\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da sie den W\u00e4chter fand;", "tokens": ["Da", "sie", "den", "W\u00e4ch\u00b7ter", "fand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "O W\u00e4chter mein trit her zu mir,", "tokens": ["O", "W\u00e4ch\u00b7ter", "mein", "trit", "her", "zu", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "VVFIN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Selig will ich dich machen,", "tokens": ["Se\u00b7lig", "will", "ich", "dich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "D\u00fcrft ich vertrauen dir.", "tokens": ["D\u00fcrft", "ich", "ver\u00b7trau\u00b7en", "dir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ihr sollet mir vertrauen", "tokens": ["Ihr", "sol\u00b7let", "mir", "ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zart edle Jungfrau fein,", "tokens": ["Zart", "ed\u00b7le", "Jung\u00b7frau", "fein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch f\u00fcrcht ich nichts so sehre,", "tokens": ["Doch", "f\u00fcrcht", "ich", "nichts", "so", "seh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als eures Vaters Grim.", "tokens": ["Als", "eu\u00b7res", "Va\u00b7ters", "Grim", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich f\u00fcrchte eures Vaters Zorn,", "tokens": ["Ich", "f\u00fcrch\u00b7te", "eu\u00b7res", "Va\u00b7ters", "Zorn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo es mir misselungen,", "tokens": ["Wo", "es", "mir", "mis\u00b7se\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Mein Leib hab ich verlorn.", "tokens": ["Mein", "Leib", "hab", "ich", "ver\u00b7lorn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Es soll uns nicht mi\u00dflingen,", "tokens": ["Es", "soll", "uns", "nicht", "mi\u00df\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es soll uns wohl ergehn,", "tokens": ["Es", "soll", "uns", "wohl", "er\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ob ich entschlafen w\u00fcrde,", "tokens": ["Ob", "ich", "ent\u00b7schla\u00b7fen", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So weck mich mit Get\u00f6n,", "tokens": ["So", "weck", "mich", "mit", "Ge\u00b7t\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ob ich entschlafen w\u00e4r zu lang,", "tokens": ["Ob", "ich", "ent\u00b7schla\u00b7fen", "w\u00e4r", "zu", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "O W\u00e4chter, traut Geselle,", "tokens": ["O", "W\u00e4ch\u00b7ter", ",", "traut", "Ge\u00b7sel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "So weck mich mit Gesang.", "tokens": ["So", "weck", "mich", "mit", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Sie gab das Geld dem Alten,", "tokens": ["Sie", "gab", "das", "Geld", "dem", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Mantel an sein Arm.", "tokens": ["Den", "Man\u00b7tel", "an", "sein", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201efahrt hin mein sch\u00f6ne Jungfraue", "tokens": ["\u201e", "fahrt", "hin", "mein", "sch\u00f6\u00b7ne", "Jung\u00b7frau\u00b7e"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund da\u00df euch Gott bewahr,", "tokens": ["\u201e", "und", "da\u00df", "euch", "Gott", "be\u00b7wahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201eda\u00df er euch wohl beh\u00fct!\u201c", "tokens": ["\u201e", "da\u00df", "er", "euch", "wohl", "be\u00b7h\u00fct", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Es kr\u00e4nkt demselben W\u00e4chter", "tokens": ["Es", "kr\u00e4nkt", "dem\u00b7sel\u00b7ben", "W\u00e4ch\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sein Leben und Gem\u00fcth.", "tokens": ["Sein", "Le\u00b7ben", "und", "Ge\u00b7m\u00fcth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die Nacht, die war so finster,", "tokens": ["Die", "Nacht", ",", "die", "war", "so", "fins\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Mond gar l\u00fctzel scheint,", "tokens": ["Der", "Mond", "gar", "l\u00fct\u00b7zel", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Jungfrau, die war edel,", "tokens": ["Die", "Jung\u00b7frau", ",", "die", "war", "e\u00b7del", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADJD", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Sie kam zum hohlen Stein,", "tokens": ["Sie", "kam", "zum", "hoh\u00b7len", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Daraus da sprang ein Br\u00fcnnlein kalt,", "tokens": ["Da\u00b7raus", "da", "sprang", "ein", "Br\u00fcnn\u00b7lein", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf gr\u00fcner Linde dr\u00fcber", "tokens": ["Auf", "gr\u00fc\u00b7ner", "Lin\u00b7de", "dr\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Frau Nachtigal sa\u00df und sang.", "tokens": ["Frau", "Nach\u00b7ti\u00b7gal", "sa\u00df", "und", "sang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "\u201ewas singest du Frau Nachtigal,", "tokens": ["\u201e", "was", "sin\u00b7gest", "du", "Frau", "Nach\u00b7ti\u00b7gal", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edu kleines Waldv\u00f6gelein,", "tokens": ["\u201e", "du", "klei\u00b7nes", "Wald\u00b7v\u00f6\u00b7ge\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201ewoll mir ihn Gott beh\u00fcten,", "tokens": ["\u201e", "woll", "mir", "ihn", "Gott", "be\u00b7h\u00fc\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201eja da ich warte sein,", "tokens": ["\u201e", "ja", "da", "ich", "war\u00b7te", "sein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "KOUS", "PPER", "VVFIN", "VAINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201eso spar mir ihn auch Gott gesund,", "tokens": ["\u201e", "so", "spar", "mir", "ihn", "auch", "Gott", "ge\u00b7sund", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "PPER", "PPER", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eer hat zwey braune Augen,", "tokens": ["\u201e", "er", "hat", "zwey", "brau\u00b7ne", "Au\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u201edazu ein rothen Mund.\u201c", "tokens": ["\u201e", "da\u00b7zu", "ein", "ro\u00b7then", "Mund", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Das h\u00f6rt ein Zwerglein kleine,", "tokens": ["Das", "h\u00f6rt", "ein", "Zwerg\u00b7lein", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das in dem Walde sa\u00df,", "tokens": ["Das", "in", "dem", "Wal\u00b7de", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es lief mit schneller Eile", "tokens": ["Es", "lief", "mit", "schnel\u00b7ler", "Ei\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da es die Jungfrau fand.", "tokens": ["Da", "es", "die", "Jung\u00b7frau", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich bin ein Bot zu euch gesandt,", "tokens": ["Ich", "bin", "ein", "Bot", "zu", "euch", "ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit mir sollt ihr gleich gehen,", "tokens": ["Mit", "mir", "sollt", "ihr", "gleich", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "In meiner Mutter Land.", "tokens": ["In", "mei\u00b7ner", "Mut\u00b7ter", "Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Er nahm sie bey den H\u00e4nden,", "tokens": ["Er", "nahm", "sie", "bey", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bey der schneeweissen Hand,", "tokens": ["Bey", "der", "schnee\u00b7weis\u00b7sen", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Er f\u00fchrt sie an das Ende,", "tokens": ["Er", "f\u00fchrt", "sie", "an", "das", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo er sein Mutter fand.", "tokens": ["Wo", "er", "sein", "Mut\u00b7ter", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201eo Mutter, die ist mein allein,", "tokens": ["\u201e", "o", "Mut\u00b7ter", ",", "die", "ist", "mein", "al\u00b7lein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "PRELS", "VAFIN", "PPOSAT", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eich fand sie n\u00e4chten sp\u00e4t", "tokens": ["\u201e", "ich", "fand", "sie", "n\u00e4ch\u00b7ten", "sp\u00e4t"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "\u201ewohl bey dem hohlen Stein.", "tokens": ["\u201e", "wohl", "bey", "dem", "hoh\u00b7len", "Stein", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und da des Zwergleins Mutter", "tokens": ["Und", "da", "des", "Zwerg\u00b7leins", "Mut\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Jungfrau recht ansah:", "tokens": ["Die", "Jung\u00b7frau", "recht", "an\u00b7sah", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201egeh f\u00fchr sie wieder geschwinde,", "tokens": ["\u201e", "geh", "f\u00fchr", "sie", "wie\u00b7der", "ge\u00b7schwin\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "VVFIN", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201eda du sie funden hast.", "tokens": ["\u201e", "da", "du", "sie", "fun\u00b7den", "hast", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201edu schaffst gros Jammer und gros Noth,", "tokens": ["\u201e", "du", "schaffst", "gros", "Jam\u00b7mer", "und", "gros", "Noth", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eeh morgen der Tag hergehet,", "tokens": ["\u201e", "eh", "mor\u00b7gen", "der", "Tag", "her\u00b7ge\u00b7het", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "\u201eso sind drey Menschen todt.\u201c", "tokens": ["\u201e", "so", "sind", "drey", "Men\u00b7schen", "todt", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "CARD", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Er nahm sie bey den H\u00e4nden,", "tokens": ["Er", "nahm", "sie", "bey", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bey der schneeweissen Hand,", "tokens": ["Bey", "der", "schnee\u00b7weis\u00b7sen", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Er f\u00fchrt sie an das Ende,", "tokens": ["Er", "f\u00fchrt", "sie", "an", "das", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo er sie funden hat.", "tokens": ["Wo", "er", "sie", "fun\u00b7den", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da lag der Ritter verwundet in Tod,", "tokens": ["Da", "lag", "der", "Rit\u00b7ter", "ver\u00b7wun\u00b7det", "in", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da stand die sch\u00f6ne Jungfraue,", "tokens": ["Da", "stand", "die", "sch\u00f6\u00b7ne", "Jung\u00b7frau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr Herz litt grosse Noth.", "tokens": ["Ihr", "Herz", "litt", "gros\u00b7se", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Sie zog aus seinem Herzen", "tokens": ["Sie", "zog", "aus", "sei\u00b7nem", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Schwerdt und stie\u00df es in sich:", "tokens": ["Das", "Schwerdt", "und", "stie\u00df", "es", "in", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PPER", "APPR", "PRF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201eund hat es dich erstochen,", "tokens": ["\u201e", "und", "hat", "es", "dich", "er\u00b7sto\u00b7chen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201eso stech ichs auch in mich;", "tokens": ["\u201e", "so", "stech", "ichs", "auch", "in", "mich", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PIS", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201ees soll nun nimmer kein K\u00f6nigs Kind", "tokens": ["\u201e", "es", "soll", "nun", "nim\u00b7mer", "kein", "K\u00f6\u00b7nigs", "Kind"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADV", "ADV", "PIAT", "NN", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u201eum meinetwillen sterben,", "tokens": ["\u201e", "um", "mei\u00b7net\u00b7wil\u00b7len", "ster\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "KOUI", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u201esich morden mehr um mich.\u201c", "tokens": ["\u201e", "sich", "mor\u00b7den", "mehr", "um", "mich", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PRF", "ADV", "ADV", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Und da es morgen taget,", "tokens": ["Und", "da", "es", "mor\u00b7gen", "ta\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der W\u00e4chter hub an und sang:", "tokens": ["Der", "W\u00e4ch\u00b7ter", "hub", "an", "und", "sang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201eso ward mir nie kein Jahre,", "tokens": ["\u201e", "so", "ward", "mir", "nie", "kein", "Jah\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201ekein Nacht noch nie so lang,", "tokens": ["\u201e", "kein", "Nacht", "noch", "nie", "so", "lang", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201edenn diese Nacht wollt nicht vergehn.", "tokens": ["\u201e", "denn", "die\u00b7se", "Nacht", "wollt", "nicht", "ver\u00b7gehn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PDAT", "NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eo reicher Christ vom Himmel,", "tokens": ["\u201e", "o", "rei\u00b7cher", "Christ", "vom", "Him\u00b7mel", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "ADJD", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u201ewie wird es mir ergehn.\u201c", "tokens": ["\u201e", "wie", "wird", "es", "mir", "er\u00b7gehn", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Und das erh\u00f6rt die K\u00f6nigin,", "tokens": ["Und", "das", "er\u00b7h\u00f6rt", "die", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die auf dem Bette lag.", "tokens": ["Die", "auf", "dem", "Bet\u00b7te", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eo h\u00f6ret edler Herre,", "tokens": ["\u201e", "o", "h\u00f6\u00b7ret", "ed\u00b7ler", "Her\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201ewas ist des W\u00e4chters Klag,", "tokens": ["\u201e", "was", "ist", "des", "W\u00e4ch\u00b7ters", "Klag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201ewie ihm die Nacht doch h\u00e4tt gethan,", "tokens": ["\u201e", "wie", "ihm", "die", "Nacht", "doch", "h\u00e4tt", "ge\u00b7than", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eich f\u00fcrcht, da\u00df unsre Tochter,", "tokens": ["\u201e", "ich", "f\u00fcrcht", ",", "da\u00df", "uns\u00b7re", "Toch\u00b7ter", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u201edie hab nicht recht gethan.\u201c", "tokens": ["\u201e", "die", "hab", "nicht", "recht", "ge\u00b7than", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "VAFIN", "PTKNEG", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Der K\u00f6nig zu der K\u00f6niginn sprach:", "tokens": ["Der", "K\u00f6\u00b7nig", "zu", "der", "K\u00f6\u00b7ni\u00b7ginn", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201ez\u00fcnd an ein Kerzlein Licht,", "tokens": ["\u201e", "z\u00fcnd", "an", "ein", "Kerz\u00b7lein", "Licht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eund ", "tokens": ["\u201e", "und"], "token_info": ["punct", "word"], "pos": ["$(", "KON"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "\u201eob ihr sie findet nicht,", "tokens": ["\u201e", "ob", "ihr", "sie", "fin\u00b7det", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201ekannst du sie in dem Bett nicht sehn,", "tokens": ["\u201e", "kannst", "du", "sie", "in", "dem", "Bett", "nicht", "sehn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PPER", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eso wirds demselben W\u00e4chter", "tokens": ["\u201e", "so", "wirds", "dem\u00b7sel\u00b7ben", "W\u00e4ch\u00b7ter"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u201ewohl an sein Leben gehn.\u201c", "tokens": ["\u201e", "wohl", "an", "sein", "Le\u00b7ben", "gehn", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Die K\u00f6niginn war geschwinde,", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7ginn", "war", "ge\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sie z\u00fcndt ein Kerzlein Licht,", "tokens": ["Sie", "z\u00fcndt", "ein", "Kerz\u00b7lein", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie lugt in alle Burgen,", "tokens": ["Sie", "lugt", "in", "al\u00b7le", "Bur\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie fand die Tochter nicht.", "tokens": ["Sie", "fand", "die", "Toch\u00b7ter", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie th\u00e4t ins Bette sehn,", "tokens": ["Sie", "th\u00e4t", "ins", "Bet\u00b7te", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "O reicher Christ vom Himmel", "tokens": ["O", "rei\u00b7cher", "Christ", "vom", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wie wird es heut ergehn.", "tokens": ["Wie", "wird", "es", "heut", "er\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Sie liessen den W\u00e4chter fahen,", "tokens": ["Sie", "lies\u00b7sen", "den", "W\u00e4ch\u00b7ter", "fa\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sie legten ihn auf den Tisch,", "tokens": ["Sie", "leg\u00b7ten", "ihn", "auf", "den", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In St\u00fccken thut man ihn schneiden,", "tokens": ["In", "St\u00fc\u00b7cken", "thut", "man", "ihn", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Gleich wie ein Salmenfisch.", "tokens": ["Gleich", "wie", "ein", "Sal\u00b7men\u00b7fisch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und warum th\u00e4ten sie ihm das,", "tokens": ["Und", "wa\u00b7rum", "th\u00e4\u00b7ten", "sie", "ihm", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PPER", "PDS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df sich ein andrer W\u00e4chter", "tokens": ["Da\u00df", "sich", "ein", "an\u00b7drer", "W\u00e4ch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sollt h\u00fcten desto bas.", "tokens": ["Sollt", "h\u00fc\u00b7ten", "des\u00b7to", "bas", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADV", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}