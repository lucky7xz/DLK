{"dta.poem.9528": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Er ist gehorsam.  \n C. H. v. H.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.57", "sv:0.42"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Sol ich in Lybien die l\u00f6wen-l\u00e4ger st\u00f6ren?", "tokens": ["Sol", "ich", "in", "Ly\u00b7bi\u00b7en", "die", "l\u00f6\u00b7wen\u00b7l\u00e4\u00b7ger", "st\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NE", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll ich Aetn\u00e4 schlund entz\u00fcnden meine hand?", "tokens": ["Soll", "ich", "A\u00b7e\u00b7tn\u00e4", "schlund", "ent\u00b7z\u00fcn\u00b7den", "mei\u00b7ne", "hand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sol ich dir nackt und blo\u00df ins neuen Zembels strand?", "tokens": ["Sol", "ich", "dir", "nackt", "und", "blo\u00df", "ins", "neu\u00b7en", "Zem\u00b7bels", "strand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADJD", "KON", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sol ich der schwartzen see verdorrte leichen mehren?", "tokens": ["Sol", "ich", "der", "schwart\u00b7zen", "see", "ver\u00b7dorr\u00b7te", "lei\u00b7chen", "meh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "VVFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sol ich das Lutherthum in den mosqueen lehren?", "tokens": ["Sol", "ich", "das", "Lu\u00b7ther\u00b7thum", "in", "den", "mos\u00b7que\u00b7en", "leh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sol ich/ wenn Eurus tobt/ durch der Egypter sand?", "tokens": ["Sol", "ich", "/", "wenn", "Eu\u00b7rus", "tobt", "/", "durch", "der", "E\u00b7gyp\u00b7ter", "sand", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "KOUS", "NE", "VVFIN", "$(", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sol ich zu deiner lust erfinden neues land?", "tokens": ["Sol", "ich", "zu", "dei\u00b7ner", "lust", "er\u00b7fin\u00b7den", "neu\u00b7es", "land", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sol ich auf Peters stul Calvin und Bezen ehren?", "tokens": ["Sol", "ich", "auf", "Pe\u00b7ters", "stul", "Cal\u00b7vin", "und", "Be\u00b7zen", "eh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NE", "NE", "NE", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Soll ich bey Zanziba die jungen drachen fangen?", "tokens": ["Soll", "ich", "bey", "Zan\u00b7zi\u00b7ba", "die", "jun\u00b7gen", "dra\u00b7chen", "fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NE", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sol ich das gelbe gift verschlingen von den schlangen?", "tokens": ["Sol", "ich", "das", "gel\u00b7be", "gift", "ver\u00b7schlin\u00b7gen", "von", "den", "schlan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dein wille ist mein zweck/ ich bin gehorsams voll/", "tokens": ["Dein", "wil\u00b7le", "ist", "mein", "zweck", "/", "ich", "bin", "ge\u00b7hor\u00b7sams", "voll", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VAFIN", "PPOSAT", "NN", "$(", "PPER", "VAFIN", "NE", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Es h\u00f6ret/ geht und folgt dir ohre/ fu\u00df und willen/", "tokens": ["Es", "h\u00f6\u00b7ret", "/", "geht", "und", "folgt", "dir", "oh\u00b7re", "/", "fu\u00df", "und", "wil\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "KON", "VVFIN", "PPER", "NN", "$(", "PTKVZ", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was mir dein mund befihlt/ mit freuden zu erf\u00fcllen/", "tokens": ["Was", "mir", "dein", "mund", "be\u00b7fihlt", "/", "mit", "freu\u00b7den", "zu", "er\u00b7f\u00fcl\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVFIN", "$(", "APPR", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nur muthe mir nicht zu/ da\u00df ich dich hassen fol.", "tokens": ["Nur", "mu\u00b7the", "mir", "nicht", "zu", "/", "da\u00df", "ich", "dich", "has\u00b7sen", "fol", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "PTKZU", "$(", "KOUS", "PPER", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}