{"dta.poem.20324": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Ein anders.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ach! wirff doch einen blick auff deine silber-ballen/", "tokens": ["Ach", "!", "wirff", "doch", "ei\u00b7nen", "blick", "auff", "dei\u00b7ne", "sil\u00b7ber\u00b7bal\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verstockte Sylvia/", "tokens": ["Ver\u00b7stock\u00b7te", "Syl\u00b7via", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NE", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Sie sind dem tode nah;", "tokens": ["Sie", "sind", "dem", "to\u00b7de", "nah", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die spitzen lassen schon die rosen-bl\u00fcthe fallen/", "tokens": ["Die", "spit\u00b7zen", "las\u00b7sen", "schon", "die", "ro\u00b7sen\u00b7bl\u00fc\u00b7the", "fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VVFIN", "ADV", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die berge ziehn die stoltzen liljen ein/", "tokens": ["Die", "ber\u00b7ge", "ziehn", "die", "stolt\u00b7zen", "lil\u00b7jen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "ART", "ADJA", "NN", "ART", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "Und werden bald so gleich wie deine wangen seyn.", "tokens": ["Und", "wer\u00b7den", "bald", "so", "gleich", "wie", "dei\u00b7ne", "wan\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADV", "KOKOM", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie/ sind wir/ schreyen sie/ dann darum nur erschaffen/", "tokens": ["Wie", "/", "sind", "wir", "/", "schre\u00b7yen", "sie", "/", "dann", "da\u00b7rum", "nur", "er\u00b7schaf\u00b7fen", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "VAFIN", "PPER", "$(", "VVFIN", "PPER", "$(", "ADV", "PAV", "ADV", "VVPP", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da\u00df uns ein blinder groll", "tokens": ["Da\u00df", "uns", "ein", "blin\u00b7der", "groll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In kercker schliessen soll?", "tokens": ["In", "ker\u00b7cker", "schlies\u00b7sen", "soll", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Cupido nennet uns ja seine liebes-waffen.", "tokens": ["Cu\u00b7pi\u00b7do", "nen\u00b7net", "uns", "ja", "sei\u00b7ne", "lie\u00b7bes\u00b7waf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Was kommet dich dann f\u00fcr ein eyffer an/", "tokens": ["Was", "kom\u00b7met", "dich", "dann", "f\u00fcr", "ein", "eyf\u00b7fer", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df du/ o Sylvia! uns in den bann gethan?", "tokens": ["Da\u00df", "du", "/", "o", "Syl\u00b7via", "!", "uns", "in", "den", "bann", "ge\u00b7than", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "FM", "NE", "$.", "PPER", "APPR", "ART", "ADV", "VVPP", "$."], "meter": "----+-+-+-+", "measure": "unknown.measure.tetra"}}, "stanza.3": {"line.1": {"text": "Ihr m\u00e4nner helffet uns durch eure macht errteten!", "tokens": ["Ihr", "m\u00e4n\u00b7ner", "helf\u00b7fet", "uns", "durch", "eu\u00b7re", "macht", "err\u00b7te\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVFIN", "PPER", "APPR", "PPOSAT", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-++--", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Zerrei\u00dft das m\u00f6rder-schlo\u00df/", "tokens": ["Zer\u00b7rei\u00dft", "das", "m\u00f6r\u00b7der\u00b7schlo\u00df", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und macht uns wieder lo\u00df.", "tokens": ["Und", "macht", "uns", "wie\u00b7der", "lo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wir lieben keinen zwang/ und leiden keine ketten/", "tokens": ["Wir", "lie\u00b7ben", "kei\u00b7nen", "zwang", "/", "und", "lei\u00b7den", "kei\u00b7ne", "ket\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "VVFIN", "$(", "KON", "VVFIN", "PIAT", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Franckreichs mod\u2019 und tolle kleider-pracht/", "tokens": ["Und", "Fran\u00b7ck\u00b7reichs", "mod'", "und", "tol\u00b7le", "klei\u00b7der\u00b7pracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "KON", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Mag seyn f\u00fcr wen sie will/ nur nicht f\u00fcr uns gemacht.", "tokens": ["Mag", "seyn", "f\u00fcr", "wen", "sie", "will", "/", "nur", "nicht", "f\u00fcr", "uns", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "APPR", "PWS", "PPER", "VMFIN", "$(", "ADV", "PTKNEG", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So klagen/ Sylvia/ die hart-bedr\u00e4ngten Kinder.", "tokens": ["So", "kla\u00b7gen", "/", "Syl\u00b7via", "/", "die", "har\u00b7tbe\u00b7dr\u00e4ng\u00b7ten", "Kin\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$(", "NE", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ach h\u00f6re doch ihr schrey\u2019n/", "tokens": ["Ach", "h\u00f6\u00b7re", "doch", "ihr", "schrey'n", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und hilff sie bald befrey\u2019n/", "tokens": ["Und", "hilff", "sie", "bald", "be\u00b7frey'n", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wo nicht/ so schneid sie ab/ und wirff sie vor die rinder.", "tokens": ["Wo", "nicht", "/", "so", "schneid", "sie", "ab", "/", "und", "wirff", "sie", "vor", "die", "rin\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$(", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dann wann sie nur im finstern sollen ruhn/", "tokens": ["Dann", "wann", "sie", "nur", "im", "fins\u00b7tern", "sol\u00b7len", "ruhn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PPER", "ADV", "APPRART", "VVINF", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So kan dirs/ wann du willst/ auch wohl ein schuptuch thun.", "tokens": ["So", "kan", "dirs", "/", "wann", "du", "willst", "/", "auch", "wohl", "ein", "schup\u00b7tuch", "thun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "$(", "PWAV", "PPER", "VMFIN", "$(", "ADV", "ADV", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}