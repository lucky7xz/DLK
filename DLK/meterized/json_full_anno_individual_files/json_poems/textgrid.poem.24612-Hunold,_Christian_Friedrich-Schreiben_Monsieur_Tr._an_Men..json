{"textgrid.poem.24612": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Schreiben Monsieur Tr. an Men.", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wehrter Freund/ Du hast mir offt gesagt/", "tokens": ["Wehr\u00b7ter", "Freund", "/", "Du", "hast", "mir", "offt", "ge\u00b7sagt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$(", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die Liebe sey ein Meer verwirrter Eitelkeiten.", "tokens": ["Die", "Lie\u00b7be", "sey", "ein", "Meer", "ver\u00b7wirr\u00b7ter", "Ei\u00b7tel\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du sprachst: Wer sich hierauf aus blo\u00dfer Wollust wagt/", "tokens": ["Du", "sprachst", ":", "Wer", "sich", "hier\u00b7auf", "aus", "blo\u00b7\u00dfer", "Wol\u00b7lust", "wagt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "PRF", "PAV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem mu\u00df es mehrentheils den Untergang bereiten.", "tokens": ["Dem", "mu\u00df", "es", "meh\u00b7ren\u00b7theils", "den", "Un\u00b7ter\u00b7gang", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und schiffet man zuletzt gleich in den Hafen ein;", "tokens": ["Und", "schif\u00b7fet", "man", "zu\u00b7letzt", "gleich", "in", "den", "Ha\u00b7fen", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So mu\u00df die Landung doch auch selbst ein Schiffbruch seyn.", "tokens": ["So", "mu\u00df", "die", "Lan\u00b7dung", "doch", "auch", "selbst", "ein", "Schiff\u00b7bruch", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADV", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Geehrter Freund/ mein Geist begreist nun deinen Sinn/", "tokens": ["Ge\u00b7ehr\u00b7ter", "Freund", "/", "mein", "Geist", "be\u00b7greist", "nun", "dei\u00b7nen", "Sinn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PPOSAT", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wie den Unterricht der Tugend Zweck gewiesen.", "tokens": ["Und", "wie", "den", "Un\u00b7ter\u00b7richt", "der", "Tu\u00b7gend", "Zweck", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jedoch die sch\u00f6nste Zeit ist meistentheils dahin/", "tokens": ["Je\u00b7doch", "die", "sch\u00f6ns\u00b7te", "Zeit", "ist", "meis\u00b7ten\u00b7theils", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ich zwar allezeit die Klugheit hoch gepriesen;", "tokens": ["Da", "ich", "zwar", "al\u00b7le\u00b7zeit", "die", "Klug\u00b7heit", "hoch", "ge\u00b7prie\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch mein bestricktes Hertz/ dem dein Verstand gebrach/", "tokens": ["Doch", "mein", "be\u00b7strick\u00b7tes", "Hertz", "/", "dem", "dein", "Ver\u00b7stand", "ge\u00b7brach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erkandte nicht/ was hier bey dir die Freundschafft sprach", "tokens": ["Er\u00b7kand\u00b7te", "nicht", "/", "was", "hier", "bey", "dir", "die", "Freund\u00b7schafft", "sprach"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$(", "PWS", "ADV", "APPR", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Es war mir alles rein/ was du so weit verwarfst.", "tokens": ["Es", "war", "mir", "al\u00b7les", "rein", "/", "was", "du", "so", "weit", "ver\u00b7warfst", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "ADJD", "$(", "PWS", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist Freundschafft/ sprach mein Hertz/ ist lieben ein Verbrechen?", "tokens": ["Ist", "Freund\u00b7schafft", "/", "sprach", "mein", "Hertz", "/", "ist", "lie\u00b7ben", "ein", "Ver\u00b7bre\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$(", "VVFIN", "PPOSAT", "NN", "$(", "VAFIN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und siehe/ da\u00df du mir in allen trauen darfst/", "tokens": ["Und", "sie\u00b7he", "/", "da\u00df", "du", "mir", "in", "al\u00b7len", "trau\u00b7en", "darfst", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$(", "KOUS", "PPER", "PRF", "APPR", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So lobt ich meine Glut/ und pflegte wohl zu sprechen:", "tokens": ["So", "lobt", "ich", "mei\u00b7ne", "Glut", "/", "und", "pfleg\u00b7te", "wohl", "zu", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$(", "KON", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich liebe Tugendhafft/ und liebe was mich liebt/", "tokens": ["Ich", "lie\u00b7be", "Tu\u00b7gend\u00b7hafft", "/", "und", "lie\u00b7be", "was", "mich", "liebt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "KON", "VVFIN", "PWS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Di\u00df ist mein Paradie\u00df/ so mir der Himmel giebt.", "tokens": ["Di\u00df", "ist", "mein", "Pa\u00b7ra\u00b7die\u00df", "/", "so", "mir", "der", "Him\u00b7mel", "giebt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$(", "ADV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ich liebe/ wie man nur in Unschuld lieben kan/", "tokens": ["Ich", "lie\u00b7be", "/", "wie", "man", "nur", "in", "Un\u00b7schuld", "lie\u00b7ben", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWAV", "PIS", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich find ein sch\u00f6nes Kind/ mit ihr ein neues Leben.", "tokens": ["Ich", "find", "ein", "sch\u00f6\u00b7nes", "Kind", "/", "mit", "ihr", "ein", "neu\u00b7es", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "APPR", "PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bete sie fast mehr/ als wie den Himmel an/", "tokens": ["Ich", "be\u00b7te", "sie", "fast", "mehr", "/", "als", "wie", "den", "Him\u00b7mel", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$(", "KOUS", "KOKOM", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mir kan ein Liebes Ku\u00df das gr\u00f6ste Labsal geben.", "tokens": ["Mir", "kan", "ein", "Lie\u00b7bes", "Ku\u00df", "das", "gr\u00f6s\u00b7te", "Lab\u00b7sal", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Tugend bleibt hierbey der Hertzen Unterpfand/", "tokens": ["Die", "Tu\u00b7gend", "bleibt", "hier\u00b7bey", "der", "Hert\u00b7zen", "Un\u00b7ter\u00b7pfand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich liebe sie/ sie mich/ und beyde mit Verstand.", "tokens": ["Ich", "lie\u00b7be", "sie", "/", "sie", "mich", "/", "und", "bey\u00b7de", "mit", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PPER", "PPER", "$(", "KON", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Doch da die Schlange so in meinen Busen schlich/", "tokens": ["Doch", "da", "die", "Schlan\u00b7ge", "so", "in", "mei\u00b7nen", "Bu\u00b7sen", "schlich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mein sonst kaltes Hertz die Flammen wolte mehren/", "tokens": ["Und", "mein", "sonst", "kal\u00b7tes", "Hertz", "die", "Flam\u00b7men", "wol\u00b7te", "meh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADV", "ADJA", "NN", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Versetzte sie der Brust den nie geglaubten Stich.", "tokens": ["Ver\u00b7setz\u00b7te", "sie", "der", "Brust", "den", "nie", "ge\u00b7glaub\u00b7ten", "Stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es muste Gifft und Pein die hei\u00dfen Adern nehren.", "tokens": ["Es", "mus\u00b7te", "Gifft", "und", "Pein", "die", "hei\u00b7\u00dfen", "A\u00b7dern", "neh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und endlich merck ich erst/ da\u00df dieses gantz gewi\u00df/", "tokens": ["Und", "end\u00b7lich", "merck", "ich", "erst", "/", "da\u00df", "die\u00b7ses", "gantz", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PDAT", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was dein erfahrner Mund mir vormahls h\u00f6ren lie\u00df.", "tokens": ["Was", "dein", "er\u00b7fahr\u00b7ner", "Mund", "mir", "vor\u00b7mahls", "h\u00f6\u00b7ren", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Mein sonst Vergn\u00fcgter Geist war allzeit mi\u00dfvergn\u00fcgt/", "tokens": ["Mein", "sonst", "Ver\u00b7gn\u00fcg\u00b7ter", "Geist", "war", "all\u00b7zeit", "mi\u00df\u00b7ver\u00b7gn\u00fcgt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "VAFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er labte sich nicht mehr an keuschen Freundschaffts-K\u00fc\u00dfen.", "tokens": ["Er", "lab\u00b7te", "sich", "nicht", "mehr", "an", "keu\u00b7schen", "Freund\u00b7schaffts\u00b7K\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Wolluft hatte mich nun gantz und gar besiegt.", "tokens": ["Die", "Wol\u00b7luft", "hat\u00b7te", "mich", "nun", "gantz", "und", "gar", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich wolte noch was mehr und etwas rarers wi\u00dfen.", "tokens": ["Ich", "wol\u00b7te", "noch", "was", "mehr", "und", "et\u00b7was", "ra\u00b7rers", "wi\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PWS", "ADV", "KON", "ADV", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und als die freche Faust verbohtne Rosen brach/", "tokens": ["Und", "als", "die", "fre\u00b7che", "Faust", "ver\u00b7boht\u00b7ne", "Ro\u00b7sen", "brach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Verlacht ich doch den Dorn/ der mein Gewi\u00dfen stach.", "tokens": ["Ver\u00b7lacht", "ich", "doch", "den", "Dorn", "/", "der", "mein", "Ge\u00b7wi\u00b7\u00dfen", "stach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der gantz verirrte Sinn hie\u00df annoch alles gut.", "tokens": ["Der", "gantz", "ver\u00b7irr\u00b7te", "Sinn", "hie\u00df", "an\u00b7noch", "al\u00b7les", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vergib/ ich werde sie hinfort ", "tokens": ["Ver\u00b7gib", "/", "ich", "wer\u00b7de", "sie", "hin\u00b7fort"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "$(", "PPER", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn da ihr gantzes wohl auf ihrem Nahmen ruht:", "tokens": ["Denn", "da", "ihr", "gant\u00b7zes", "wohl", "auf", "ih\u00b7rem", "Nah\u00b7men", "ruht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Befiehlt mir der ", "tokens": ["Be\u00b7fiehlt", "mir", "der"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ART"], "meter": "-+--", "measure": "dactylic.init"}, "line.5": {"text": "Ja das/ was ich und sie noch ferner hin gethan/", "tokens": ["Ja", "das", "/", "was", "ich", "und", "sie", "noch", "fer\u00b7ner", "hin", "ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "$(", "PWS", "PPER", "KON", "PPER", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zeigt unsre Fehler zwar/ doch wenig Tugend an.", "tokens": ["Zeigt", "uns\u00b7re", "Feh\u00b7ler", "zwar", "/", "doch", "we\u00b7nig", "Tu\u00b7gend", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "$(", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Wir lebten also noch in unsrer Liebe fort.", "tokens": ["Wir", "leb\u00b7ten", "al\u00b7so", "noch", "in", "uns\u00b7rer", "Lie\u00b7be", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da/ wo ", "tokens": ["Da", "/", "wo"], "token_info": ["word", "punct", "word"], "pos": ["ADV", "$(", "PWAV"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Zu letzt beliebte sie mir ihr ", "tokens": ["Zu", "letzt", "be\u00b7lieb\u00b7te", "sie", "mir", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PPER", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In meinen Augen war sie gantz alleine sch\u00f6n.", "tokens": ["In", "mei\u00b7nen", "Au\u00b7gen", "war", "sie", "gantz", "al\u00b7lei\u00b7ne", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und kurtz/ nun wolte Gl\u00fcck und Fall beysammen stehn.", "tokens": ["Und", "kurtz", "/", "nun", "wol\u00b7te", "Gl\u00fcck", "und", "Fall", "bey\u00b7sam\u00b7men", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$(", "ADV", "VMFIN", "NN", "KON", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der Wechsel/ welcher uns am angenehmsten ist/", "tokens": ["Der", "Wech\u00b7sel", "/", "wel\u00b7cher", "uns", "am", "an\u00b7ge\u00b7nehms\u00b7ten", "ist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "APPRART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Unbestand so meist bey allen Sch\u00f6nen wohnet.", "tokens": ["Der", "Un\u00b7be\u00b7stand", "so", "meist", "bey", "al\u00b7len", "Sch\u00f6\u00b7nen", "woh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Zeit/ die offt was Treu und redlich hei\u00dft/ vergi\u00dft/", "tokens": ["Die", "Zeit", "/", "die", "offt", "was", "Treu", "und", "red\u00b7lich", "hei\u00dft", "/", "ver\u00b7gi\u00dft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "PWS", "NN", "KON", "ADJD", "VVFIN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alles/ was die Brust mit eitel Schmertz belohnet/", "tokens": ["Und", "al\u00b7les", "/", "was", "die", "Brust", "mit", "ei\u00b7tel", "Schmertz", "be\u00b7loh\u00b7net", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$(", "PWS", "ART", "NN", "APPR", "ADJD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Fand sich auch noch zu letzt bey unsern Lieben ein/", "tokens": ["Fand", "sich", "auch", "noch", "zu", "letzt", "bey", "un\u00b7sern", "Lie\u00b7ben", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "APPR", "ADV", "APPR", "PPOSAT", "ADJA", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und musten mehr vor mich als tausend Hencker seyn.", "tokens": ["Und", "mus\u00b7ten", "mehr", "vor", "mich", "als", "tau\u00b7send", "Hen\u00b7cker", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PPER", "KOKOM", "CARD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Nun st\u00fcrtzte mich das Gl\u00fcck vom Anmuhts-Gipfel rab/", "tokens": ["Nun", "st\u00fcrtz\u00b7te", "mich", "das", "Gl\u00fcck", "vom", "Anm\u00b7uhts\u00b7Gip\u00b7fel", "rab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor mein gelobtes Land must ich die W\u00fcsten sehen.", "tokens": ["Vor", "mein", "ge\u00b7lob\u00b7tes", "Land", "must", "ich", "die", "W\u00fcs\u00b7ten", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es hie\u00df ihr Wanckelmuht mich ins Verderben gehen.", "tokens": ["Es", "hie\u00df", "ihr", "Wan\u00b7ckel\u00b7muht", "mich", "ins", "Ver\u00b7der\u00b7ben", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was ", "tokens": ["Und", "was"], "token_info": ["word", "word"], "pos": ["KON", "PWS"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Fieng sie hernach mit mir/ nur etwas kl\u00fcger an.", "tokens": ["Fi\u00b7eng", "sie", "her\u00b7nach", "mit", "mir", "/", "nur", "et\u00b7was", "kl\u00fc\u00b7ger", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPER", "$(", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.11": {"line.1": {"text": "Es sagt ein guter Freund/ so mich aufrichtig liebt/", "tokens": ["Es", "sagt", "ein", "gu\u00b7ter", "Freund", "/", "so", "mich", "auf\u00b7rich\u00b7tig", "liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "ADV", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie pflege seine Hand an ihre Brust zu dr\u00fccken.", "tokens": ["Sie", "pfle\u00b7ge", "sei\u00b7ne", "Hand", "an", "ih\u00b7re", "Brust", "zu", "dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was bey ", "tokens": ["Was", "bey"], "token_info": ["word", "word"], "pos": ["PWS", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Hierein/ versichert er/ kan er sich selbst nicht schicken.", "tokens": ["Hier\u00b7ein", "/", "ver\u00b7si\u00b7chert", "er", "/", "kan", "er", "sich", "selbst", "nicht", "schi\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VVFIN", "PPER", "$(", "VMFIN", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sie ist vergn\u00fcgt/ wenn sie in seinen Armen ruht/", "tokens": ["Sie", "ist", "ver\u00b7gn\u00fcgt", "/", "wenn", "sie", "in", "sei\u00b7nen", "Ar\u00b7men", "ruht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und mi\u00dfvergn\u00fcgt/ wenn er nur etwas bl\u00f6de thut.", "tokens": ["Und", "mi\u00df\u00b7ver\u00b7gn\u00fcgt", "/", "wenn", "er", "nur", "et\u00b7was", "bl\u00f6\u00b7de", "thut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPER", "ADV", "PIAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wiewohl es schweigt der Kiel/ da sonst mein redlich Hertz/", "tokens": ["Wie\u00b7wohl", "es", "schweigt", "der", "Kiel", "/", "da", "sonst", "mein", "red\u00b7lich", "Hertz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NE", "$(", "ADV", "ADV", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey der Erinnerung sich fast zu weit vergehet.", "tokens": ["Bey", "der", "E\u00b7rin\u00b7ne\u00b7rung", "sich", "fast", "zu", "weit", "ver\u00b7ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Doch da ein anderer bey jener sch\u00f6nen stehet:", "tokens": ["Doch", "da", "ein", "an\u00b7de\u00b7rer", "bey", "je\u00b7ner", "sch\u00f6\u00b7nen", "ste\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "APPR", "PDAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So schlag' ich mir mit Recht ", "tokens": ["So", "schlag'", "ich", "mir", "mit", "Recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da ich nicht gantz allein in ihrem Hertzen bin.", "tokens": ["Da", "ich", "nicht", "gantz", "al\u00b7lein", "in", "ih\u00b7rem", "Hert\u00b7zen", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Es mu\u00df ein edler Geist sein eigner Meister seyn/", "tokens": ["Es", "mu\u00df", "ein", "ed\u00b7ler", "Geist", "sein", "eig\u00b7ner", "Meis\u00b7ter", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es mag ", "tokens": ["Es", "mag"], "token_info": ["word", "word"], "pos": ["PPER", "VMFIN"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Mein Leben bleibt hierdurch von Wollust-Flecken rein.", "tokens": ["Mein", "Le\u00b7ben", "bleibt", "hier\u00b7durch", "von", "Wol\u00b7lust\u00b7Fle\u00b7cken", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PAV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich will nunmehr mit Lust Gro\u00dfm\u00fchtig sie verachten", "tokens": ["Ich", "will", "nun\u00b7mehr", "mit", "Lust", "Gro\u00df\u00b7m\u00fch\u00b7tig", "sie", "ver\u00b7ach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gnug/ da\u00df ihr leichter Sinn/ der auch zu St\u00fcmpern steigt/", "tokens": ["Gnug", "/", "da\u00df", "ihr", "leich\u00b7ter", "Sinn", "/", "der", "auch", "zu", "St\u00fcm\u00b7pern", "steigt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPOSAT", "ADJA", "NN", "$(", "ART", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mir nun den rechten Weg zur wahren Klugheit zeigt.", "tokens": ["Mir", "nun", "den", "rech\u00b7ten", "Weg", "zur", "wah\u00b7ren", "Klug\u00b7heit", "zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "So fieng sich Wehrter Freund/ die erste Neigung an:", "tokens": ["So", "fi\u00b7eng", "sich", "Wehr\u00b7ter", "Freund", "/", "die", "ers\u00b7te", "Nei\u00b7gung", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "NN", "$(", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So hatte kaum der Mund das Honig-seim geno\u00dfen/", "tokens": ["So", "hat\u00b7te", "kaum", "der", "Mund", "das", "Ho\u00b7nig\u00b7seim", "ge\u00b7no\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da sp\u00fcrt ich bald darauf/ wie Galle schmecken kan/", "tokens": ["Da", "sp\u00fcrt", "ich", "bald", "da\u00b7rauf", "/", "wie", "Gal\u00b7le", "schme\u00b7cken", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$(", "KOKOM", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie aus ", "tokens": ["Und", "wie", "aus"], "token_info": ["word", "word", "word"], "pos": ["KON", "PWAV", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Und endlich hab ich nun mehr als zu sp\u00e4t erkennt:", "tokens": ["Und", "end\u00b7lich", "hab", "ich", "nun", "mehr", "als", "zu", "sp\u00e4t", "er\u00b7kennt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "PIAT", "KOKOM", "PTKA", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df Klugheit schlechter Rauch/ wo Liebes-Feuer brennt.", "tokens": ["Da\u00df", "Klug\u00b7heit", "schlech\u00b7ter", "Rauch", "/", "wo", "Lie\u00b7bes\u00b7Feu\u00b7er", "brennt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "$(", "PWAV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Gewi\u00df/ ich werde so/ als wie die meisten klug.", "tokens": ["Ge\u00b7wi\u00df", "/", "ich", "wer\u00b7de", "so", "/", "als", "wie", "die", "meis\u00b7ten", "klug", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "ADV", "$(", "KOUS", "KOKOM", "ART", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Schaden mu\u00df mich auch zu Wahrer Kenntni\u00df bringen.", "tokens": ["Mein", "Scha\u00b7den", "mu\u00df", "mich", "auch", "zu", "Wah\u00b7rer", "Kennt\u00b7ni\u00df", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch schn\u00f6der Wollust-Trieb/ durch Weiblichen Betrug/", "tokens": ["Durch", "schn\u00f6\u00b7der", "Wol\u00b7lust\u00b7Trieb", "/", "durch", "Weib\u00b7li\u00b7chen", "Be\u00b7trug", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mu\u00df ich mich an den Pol Wahrhaffter Tugend schwingen.", "tokens": ["Mu\u00df", "ich", "mich", "an", "den", "Pol", "Wahr\u00b7haff\u00b7ter", "Tu\u00b7gend", "schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPR", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Verdient mein Lieben gleich gar einen schlechten Prei\u00df:", "tokens": ["Ver\u00b7di\u00b7ent", "mein", "Lie\u00b7ben", "gleich", "gar", "ei\u00b7nen", "schlech\u00b7ten", "Prei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "So hilfft es doch/ da\u00df ich/ was gut und b\u00f6se/ wei\u00df.", "tokens": ["So", "hilfft", "es", "doch", "/", "da\u00df", "ich", "/", "was", "gut", "und", "b\u00f6\u00b7se", "/", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "$(", "PWS", "ADJD", "KON", "ADJD", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Man spricht von alle dem/ als wie ein kleines Kind/", "tokens": ["Man", "spricht", "von", "al\u00b7le", "dem", "/", "als", "wie", "ein", "klei\u00b7nes", "Kind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PIS", "ART", "$(", "KOUS", "KOKOM", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das nichts wahrhafftes wei\u00df/ und dennoch etwas nennet/", "tokens": ["Das", "nichts", "wahr\u00b7haff\u00b7tes", "wei\u00df", "/", "und", "den\u00b7noch", "et\u00b7was", "nen\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "ADJA", "VVFIN", "$(", "KON", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Wo nicht Erfahrenheit und Wi\u00dfen einig sind/", "tokens": ["Wo", "nicht", "Er\u00b7fah\u00b7ren\u00b7heit", "und", "Wi\u00b7\u00dfen", "ei\u00b7nig", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "NN", "KON", "NN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo man die Tugend nicht/ so wie die Liebe kennet.", "tokens": ["Wo", "man", "die", "Tu\u00b7gend", "nicht", "/", "so", "wie", "die", "Lie\u00b7be", "ken\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "PTKNEG", "$(", "ADV", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Tugend/ die verha\u00dft/ wenn ", "tokens": ["Die", "Tu\u00b7gend", "/", "die", "ver\u00b7ha\u00dft", "/", "wenn"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$(", "ART", "ADJD", "$(", "KOUS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Hat bey dem Kl\u00fcgsten offt am Ende noch gesiegt.", "tokens": ["Hat", "bey", "dem", "Kl\u00fcgs\u00b7ten", "offt", "am", "En\u00b7de", "noch", "ge\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Allein/ mein Hertzens-Freund/ aus Tugend wird hinfort", "tokens": ["Al\u00b7lein", "/", "mein", "Hert\u00b7zens\u00b7Freund", "/", "aus", "Tu\u00b7gend", "wird", "hin\u00b7fort"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "PPOSAT", "NN", "$(", "APPR", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Liebe schlauer Trieb nicht in dem Hertzen rasen.", "tokens": ["Der", "Lie\u00b7be", "schlau\u00b7er", "Trieb", "nicht", "in", "dem", "Hert\u00b7zen", "ra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich suche nun mit dir der Tugend sichern Port.", "tokens": ["Ich", "su\u00b7che", "nun", "mit", "dir", "der", "Tu\u00b7gend", "si\u00b7chern", "Port", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "ART", "NN", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verstand und Klugheit soll in meine Seegel blasen.", "tokens": ["Ver\u00b7stand", "und", "Klug\u00b7heit", "soll", "in", "mei\u00b7ne", "See\u00b7gel", "bla\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es geht mein Schiff nicht mehr nach", "tokens": ["Es", "geht", "mein", "Schiff", "nicht", "mehr", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "So lang ich unter dir/ und ein ", "tokens": ["So", "lang", "ich", "un\u00b7ter", "dir", "/", "und", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "APPR", "PPER", "$(", "KON", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Wehrter Freund/ Du hast mir offt gesagt/", "tokens": ["Wehr\u00b7ter", "Freund", "/", "Du", "hast", "mir", "offt", "ge\u00b7sagt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$(", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die Liebe sey ein Meer verwirrter Eitelkeiten.", "tokens": ["Die", "Lie\u00b7be", "sey", "ein", "Meer", "ver\u00b7wirr\u00b7ter", "Ei\u00b7tel\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du sprachst: Wer sich hierauf aus blo\u00dfer Wollust wagt/", "tokens": ["Du", "sprachst", ":", "Wer", "sich", "hier\u00b7auf", "aus", "blo\u00b7\u00dfer", "Wol\u00b7lust", "wagt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "PRF", "PAV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem mu\u00df es mehrentheils den Untergang bereiten.", "tokens": ["Dem", "mu\u00df", "es", "meh\u00b7ren\u00b7theils", "den", "Un\u00b7ter\u00b7gang", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und schiffet man zuletzt gleich in den Hafen ein;", "tokens": ["Und", "schif\u00b7fet", "man", "zu\u00b7letzt", "gleich", "in", "den", "Ha\u00b7fen", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So mu\u00df die Landung doch auch selbst ein Schiffbruch seyn.", "tokens": ["So", "mu\u00df", "die", "Lan\u00b7dung", "doch", "auch", "selbst", "ein", "Schiff\u00b7bruch", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADV", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Geehrter Freund/ mein Geist begreist nun deinen Sinn/", "tokens": ["Ge\u00b7ehr\u00b7ter", "Freund", "/", "mein", "Geist", "be\u00b7greist", "nun", "dei\u00b7nen", "Sinn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PPOSAT", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wie den Unterricht der Tugend Zweck gewiesen.", "tokens": ["Und", "wie", "den", "Un\u00b7ter\u00b7richt", "der", "Tu\u00b7gend", "Zweck", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jedoch die sch\u00f6nste Zeit ist meistentheils dahin/", "tokens": ["Je\u00b7doch", "die", "sch\u00f6ns\u00b7te", "Zeit", "ist", "meis\u00b7ten\u00b7theils", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ich zwar allezeit die Klugheit hoch gepriesen;", "tokens": ["Da", "ich", "zwar", "al\u00b7le\u00b7zeit", "die", "Klug\u00b7heit", "hoch", "ge\u00b7prie\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch mein bestricktes Hertz/ dem dein Verstand gebrach/", "tokens": ["Doch", "mein", "be\u00b7strick\u00b7tes", "Hertz", "/", "dem", "dein", "Ver\u00b7stand", "ge\u00b7brach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erkandte nicht/ was hier bey dir die Freundschafft sprach", "tokens": ["Er\u00b7kand\u00b7te", "nicht", "/", "was", "hier", "bey", "dir", "die", "Freund\u00b7schafft", "sprach"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$(", "PWS", "ADV", "APPR", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Es war mir alles rein/ was du so weit verwarfst.", "tokens": ["Es", "war", "mir", "al\u00b7les", "rein", "/", "was", "du", "so", "weit", "ver\u00b7warfst", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "ADJD", "$(", "PWS", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist Freundschafft/ sprach mein Hertz/ ist lieben ein Verbrechen?", "tokens": ["Ist", "Freund\u00b7schafft", "/", "sprach", "mein", "Hertz", "/", "ist", "lie\u00b7ben", "ein", "Ver\u00b7bre\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$(", "VVFIN", "PPOSAT", "NN", "$(", "VAFIN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und siehe/ da\u00df du mir in allen trauen darfst/", "tokens": ["Und", "sie\u00b7he", "/", "da\u00df", "du", "mir", "in", "al\u00b7len", "trau\u00b7en", "darfst", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$(", "KOUS", "PPER", "PRF", "APPR", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So lobt ich meine Glut/ und pflegte wohl zu sprechen:", "tokens": ["So", "lobt", "ich", "mei\u00b7ne", "Glut", "/", "und", "pfleg\u00b7te", "wohl", "zu", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$(", "KON", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich liebe Tugendhafft/ und liebe was mich liebt/", "tokens": ["Ich", "lie\u00b7be", "Tu\u00b7gend\u00b7hafft", "/", "und", "lie\u00b7be", "was", "mich", "liebt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "KON", "VVFIN", "PWS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Di\u00df ist mein Paradie\u00df/ so mir der Himmel giebt.", "tokens": ["Di\u00df", "ist", "mein", "Pa\u00b7ra\u00b7die\u00df", "/", "so", "mir", "der", "Him\u00b7mel", "giebt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$(", "ADV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Ich liebe/ wie man nur in Unschuld lieben kan/", "tokens": ["Ich", "lie\u00b7be", "/", "wie", "man", "nur", "in", "Un\u00b7schuld", "lie\u00b7ben", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWAV", "PIS", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich find ein sch\u00f6nes Kind/ mit ihr ein neues Leben.", "tokens": ["Ich", "find", "ein", "sch\u00f6\u00b7nes", "Kind", "/", "mit", "ihr", "ein", "neu\u00b7es", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "APPR", "PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bete sie fast mehr/ als wie den Himmel an/", "tokens": ["Ich", "be\u00b7te", "sie", "fast", "mehr", "/", "als", "wie", "den", "Him\u00b7mel", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$(", "KOUS", "KOKOM", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mir kan ein Liebes Ku\u00df das gr\u00f6ste Labsal geben.", "tokens": ["Mir", "kan", "ein", "Lie\u00b7bes", "Ku\u00df", "das", "gr\u00f6s\u00b7te", "Lab\u00b7sal", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Tugend bleibt hierbey der Hertzen Unterpfand/", "tokens": ["Die", "Tu\u00b7gend", "bleibt", "hier\u00b7bey", "der", "Hert\u00b7zen", "Un\u00b7ter\u00b7pfand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich liebe sie/ sie mich/ und beyde mit Verstand.", "tokens": ["Ich", "lie\u00b7be", "sie", "/", "sie", "mich", "/", "und", "bey\u00b7de", "mit", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PPER", "PPER", "$(", "KON", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Doch da die Schlange so in meinen Busen schlich/", "tokens": ["Doch", "da", "die", "Schlan\u00b7ge", "so", "in", "mei\u00b7nen", "Bu\u00b7sen", "schlich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mein sonst kaltes Hertz die Flammen wolte mehren/", "tokens": ["Und", "mein", "sonst", "kal\u00b7tes", "Hertz", "die", "Flam\u00b7men", "wol\u00b7te", "meh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADV", "ADJA", "NN", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Versetzte sie der Brust den nie geglaubten Stich.", "tokens": ["Ver\u00b7setz\u00b7te", "sie", "der", "Brust", "den", "nie", "ge\u00b7glaub\u00b7ten", "Stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es muste Gifft und Pein die hei\u00dfen Adern nehren.", "tokens": ["Es", "mus\u00b7te", "Gifft", "und", "Pein", "die", "hei\u00b7\u00dfen", "A\u00b7dern", "neh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und endlich merck ich erst/ da\u00df dieses gantz gewi\u00df/", "tokens": ["Und", "end\u00b7lich", "merck", "ich", "erst", "/", "da\u00df", "die\u00b7ses", "gantz", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PDAT", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was dein erfahrner Mund mir vormahls h\u00f6ren lie\u00df.", "tokens": ["Was", "dein", "er\u00b7fahr\u00b7ner", "Mund", "mir", "vor\u00b7mahls", "h\u00f6\u00b7ren", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Mein sonst Vergn\u00fcgter Geist war allzeit mi\u00dfvergn\u00fcgt/", "tokens": ["Mein", "sonst", "Ver\u00b7gn\u00fcg\u00b7ter", "Geist", "war", "all\u00b7zeit", "mi\u00df\u00b7ver\u00b7gn\u00fcgt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "VAFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er labte sich nicht mehr an keuschen Freundschaffts-K\u00fc\u00dfen.", "tokens": ["Er", "lab\u00b7te", "sich", "nicht", "mehr", "an", "keu\u00b7schen", "Freund\u00b7schaffts\u00b7K\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Wolluft hatte mich nun gantz und gar besiegt.", "tokens": ["Die", "Wol\u00b7luft", "hat\u00b7te", "mich", "nun", "gantz", "und", "gar", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich wolte noch was mehr und etwas rarers wi\u00dfen.", "tokens": ["Ich", "wol\u00b7te", "noch", "was", "mehr", "und", "et\u00b7was", "ra\u00b7rers", "wi\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PWS", "ADV", "KON", "ADV", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und als die freche Faust verbohtne Rosen brach/", "tokens": ["Und", "als", "die", "fre\u00b7che", "Faust", "ver\u00b7boht\u00b7ne", "Ro\u00b7sen", "brach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Verlacht ich doch den Dorn/ der mein Gewi\u00dfen stach.", "tokens": ["Ver\u00b7lacht", "ich", "doch", "den", "Dorn", "/", "der", "mein", "Ge\u00b7wi\u00b7\u00dfen", "stach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Der gantz verirrte Sinn hie\u00df annoch alles gut.", "tokens": ["Der", "gantz", "ver\u00b7irr\u00b7te", "Sinn", "hie\u00df", "an\u00b7noch", "al\u00b7les", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vergib/ ich werde sie hinfort ", "tokens": ["Ver\u00b7gib", "/", "ich", "wer\u00b7de", "sie", "hin\u00b7fort"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "$(", "PPER", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn da ihr gantzes wohl auf ihrem Nahmen ruht:", "tokens": ["Denn", "da", "ihr", "gant\u00b7zes", "wohl", "auf", "ih\u00b7rem", "Nah\u00b7men", "ruht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Befiehlt mir der ", "tokens": ["Be\u00b7fiehlt", "mir", "der"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ART"], "meter": "-+--", "measure": "dactylic.init"}, "line.5": {"text": "Ja das/ was ich und sie noch ferner hin gethan/", "tokens": ["Ja", "das", "/", "was", "ich", "und", "sie", "noch", "fer\u00b7ner", "hin", "ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "$(", "PWS", "PPER", "KON", "PPER", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zeigt unsre Fehler zwar/ doch wenig Tugend an.", "tokens": ["Zeigt", "uns\u00b7re", "Feh\u00b7ler", "zwar", "/", "doch", "we\u00b7nig", "Tu\u00b7gend", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "$(", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Wir lebten also noch in unsrer Liebe fort.", "tokens": ["Wir", "leb\u00b7ten", "al\u00b7so", "noch", "in", "uns\u00b7rer", "Lie\u00b7be", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da/ wo ", "tokens": ["Da", "/", "wo"], "token_info": ["word", "punct", "word"], "pos": ["ADV", "$(", "PWAV"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Zu letzt beliebte sie mir ihr ", "tokens": ["Zu", "letzt", "be\u00b7lieb\u00b7te", "sie", "mir", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PPER", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In meinen Augen war sie gantz alleine sch\u00f6n.", "tokens": ["In", "mei\u00b7nen", "Au\u00b7gen", "war", "sie", "gantz", "al\u00b7lei\u00b7ne", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und kurtz/ nun wolte Gl\u00fcck und Fall beysammen stehn.", "tokens": ["Und", "kurtz", "/", "nun", "wol\u00b7te", "Gl\u00fcck", "und", "Fall", "bey\u00b7sam\u00b7men", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$(", "ADV", "VMFIN", "NN", "KON", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Der Wechsel/ welcher uns am angenehmsten ist/", "tokens": ["Der", "Wech\u00b7sel", "/", "wel\u00b7cher", "uns", "am", "an\u00b7ge\u00b7nehms\u00b7ten", "ist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "APPRART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Unbestand so meist bey allen Sch\u00f6nen wohnet.", "tokens": ["Der", "Un\u00b7be\u00b7stand", "so", "meist", "bey", "al\u00b7len", "Sch\u00f6\u00b7nen", "woh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Zeit/ die offt was Treu und redlich hei\u00dft/ vergi\u00dft/", "tokens": ["Die", "Zeit", "/", "die", "offt", "was", "Treu", "und", "red\u00b7lich", "hei\u00dft", "/", "ver\u00b7gi\u00dft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "PWS", "NN", "KON", "ADJD", "VVFIN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alles/ was die Brust mit eitel Schmertz belohnet/", "tokens": ["Und", "al\u00b7les", "/", "was", "die", "Brust", "mit", "ei\u00b7tel", "Schmertz", "be\u00b7loh\u00b7net", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$(", "PWS", "ART", "NN", "APPR", "ADJD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Fand sich auch noch zu letzt bey unsern Lieben ein/", "tokens": ["Fand", "sich", "auch", "noch", "zu", "letzt", "bey", "un\u00b7sern", "Lie\u00b7ben", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "APPR", "ADV", "APPR", "PPOSAT", "ADJA", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und musten mehr vor mich als tausend Hencker seyn.", "tokens": ["Und", "mus\u00b7ten", "mehr", "vor", "mich", "als", "tau\u00b7send", "Hen\u00b7cker", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PPER", "KOKOM", "CARD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Nun st\u00fcrtzte mich das Gl\u00fcck vom Anmuhts-Gipfel rab/", "tokens": ["Nun", "st\u00fcrtz\u00b7te", "mich", "das", "Gl\u00fcck", "vom", "Anm\u00b7uhts\u00b7Gip\u00b7fel", "rab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor mein gelobtes Land must ich die W\u00fcsten sehen.", "tokens": ["Vor", "mein", "ge\u00b7lob\u00b7tes", "Land", "must", "ich", "die", "W\u00fcs\u00b7ten", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es hie\u00df ihr Wanckelmuht mich ins Verderben gehen.", "tokens": ["Es", "hie\u00df", "ihr", "Wan\u00b7ckel\u00b7muht", "mich", "ins", "Ver\u00b7der\u00b7ben", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was ", "tokens": ["Und", "was"], "token_info": ["word", "word"], "pos": ["KON", "PWS"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Fieng sie hernach mit mir/ nur etwas kl\u00fcger an.", "tokens": ["Fi\u00b7eng", "sie", "her\u00b7nach", "mit", "mir", "/", "nur", "et\u00b7was", "kl\u00fc\u00b7ger", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPER", "$(", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.28": {"line.1": {"text": "Es sagt ein guter Freund/ so mich aufrichtig liebt/", "tokens": ["Es", "sagt", "ein", "gu\u00b7ter", "Freund", "/", "so", "mich", "auf\u00b7rich\u00b7tig", "liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "ADV", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie pflege seine Hand an ihre Brust zu dr\u00fccken.", "tokens": ["Sie", "pfle\u00b7ge", "sei\u00b7ne", "Hand", "an", "ih\u00b7re", "Brust", "zu", "dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was bey ", "tokens": ["Was", "bey"], "token_info": ["word", "word"], "pos": ["PWS", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Hierein/ versichert er/ kan er sich selbst nicht schicken.", "tokens": ["Hier\u00b7ein", "/", "ver\u00b7si\u00b7chert", "er", "/", "kan", "er", "sich", "selbst", "nicht", "schi\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VVFIN", "PPER", "$(", "VMFIN", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sie ist vergn\u00fcgt/ wenn sie in seinen Armen ruht/", "tokens": ["Sie", "ist", "ver\u00b7gn\u00fcgt", "/", "wenn", "sie", "in", "sei\u00b7nen", "Ar\u00b7men", "ruht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und mi\u00dfvergn\u00fcgt/ wenn er nur etwas bl\u00f6de thut.", "tokens": ["Und", "mi\u00df\u00b7ver\u00b7gn\u00fcgt", "/", "wenn", "er", "nur", "et\u00b7was", "bl\u00f6\u00b7de", "thut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPER", "ADV", "PIAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Wiewohl es schweigt der Kiel/ da sonst mein redlich Hertz/", "tokens": ["Wie\u00b7wohl", "es", "schweigt", "der", "Kiel", "/", "da", "sonst", "mein", "red\u00b7lich", "Hertz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NE", "$(", "ADV", "ADV", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey der Erinnerung sich fast zu weit vergehet.", "tokens": ["Bey", "der", "E\u00b7rin\u00b7ne\u00b7rung", "sich", "fast", "zu", "weit", "ver\u00b7ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Doch da ein anderer bey jener sch\u00f6nen stehet:", "tokens": ["Doch", "da", "ein", "an\u00b7de\u00b7rer", "bey", "je\u00b7ner", "sch\u00f6\u00b7nen", "ste\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "APPR", "PDAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So schlag' ich mir mit Recht ", "tokens": ["So", "schlag'", "ich", "mir", "mit", "Recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da ich nicht gantz allein in ihrem Hertzen bin.", "tokens": ["Da", "ich", "nicht", "gantz", "al\u00b7lein", "in", "ih\u00b7rem", "Hert\u00b7zen", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Es mu\u00df ein edler Geist sein eigner Meister seyn/", "tokens": ["Es", "mu\u00df", "ein", "ed\u00b7ler", "Geist", "sein", "eig\u00b7ner", "Meis\u00b7ter", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es mag ", "tokens": ["Es", "mag"], "token_info": ["word", "word"], "pos": ["PPER", "VMFIN"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Mein Leben bleibt hierdurch von Wollust-Flecken rein.", "tokens": ["Mein", "Le\u00b7ben", "bleibt", "hier\u00b7durch", "von", "Wol\u00b7lust\u00b7Fle\u00b7cken", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PAV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich will nunmehr mit Lust Gro\u00dfm\u00fchtig sie verachten", "tokens": ["Ich", "will", "nun\u00b7mehr", "mit", "Lust", "Gro\u00df\u00b7m\u00fch\u00b7tig", "sie", "ver\u00b7ach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gnug/ da\u00df ihr leichter Sinn/ der auch zu St\u00fcmpern steigt/", "tokens": ["Gnug", "/", "da\u00df", "ihr", "leich\u00b7ter", "Sinn", "/", "der", "auch", "zu", "St\u00fcm\u00b7pern", "steigt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPOSAT", "ADJA", "NN", "$(", "ART", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mir nun den rechten Weg zur wahren Klugheit zeigt.", "tokens": ["Mir", "nun", "den", "rech\u00b7ten", "Weg", "zur", "wah\u00b7ren", "Klug\u00b7heit", "zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "So fieng sich Wehrter Freund/ die erste Neigung an:", "tokens": ["So", "fi\u00b7eng", "sich", "Wehr\u00b7ter", "Freund", "/", "die", "ers\u00b7te", "Nei\u00b7gung", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "NN", "$(", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So hatte kaum der Mund das Honig-seim geno\u00dfen/", "tokens": ["So", "hat\u00b7te", "kaum", "der", "Mund", "das", "Ho\u00b7nig\u00b7seim", "ge\u00b7no\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da sp\u00fcrt ich bald darauf/ wie Galle schmecken kan/", "tokens": ["Da", "sp\u00fcrt", "ich", "bald", "da\u00b7rauf", "/", "wie", "Gal\u00b7le", "schme\u00b7cken", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$(", "KOKOM", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie aus ", "tokens": ["Und", "wie", "aus"], "token_info": ["word", "word", "word"], "pos": ["KON", "PWAV", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Und endlich hab ich nun mehr als zu sp\u00e4t erkennt:", "tokens": ["Und", "end\u00b7lich", "hab", "ich", "nun", "mehr", "als", "zu", "sp\u00e4t", "er\u00b7kennt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "PIAT", "KOKOM", "PTKA", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df Klugheit schlechter Rauch/ wo Liebes-Feuer brennt.", "tokens": ["Da\u00df", "Klug\u00b7heit", "schlech\u00b7ter", "Rauch", "/", "wo", "Lie\u00b7bes\u00b7Feu\u00b7er", "brennt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "$(", "PWAV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Gewi\u00df/ ich werde so/ als wie die meisten klug.", "tokens": ["Ge\u00b7wi\u00df", "/", "ich", "wer\u00b7de", "so", "/", "als", "wie", "die", "meis\u00b7ten", "klug", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "ADV", "$(", "KOUS", "KOKOM", "ART", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Schaden mu\u00df mich auch zu Wahrer Kenntni\u00df bringen.", "tokens": ["Mein", "Scha\u00b7den", "mu\u00df", "mich", "auch", "zu", "Wah\u00b7rer", "Kennt\u00b7ni\u00df", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch schn\u00f6der Wollust-Trieb/ durch Weiblichen Betrug/", "tokens": ["Durch", "schn\u00f6\u00b7der", "Wol\u00b7lust\u00b7Trieb", "/", "durch", "Weib\u00b7li\u00b7chen", "Be\u00b7trug", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mu\u00df ich mich an den Pol Wahrhaffter Tugend schwingen.", "tokens": ["Mu\u00df", "ich", "mich", "an", "den", "Pol", "Wahr\u00b7haff\u00b7ter", "Tu\u00b7gend", "schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPR", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Verdient mein Lieben gleich gar einen schlechten Prei\u00df:", "tokens": ["Ver\u00b7di\u00b7ent", "mein", "Lie\u00b7ben", "gleich", "gar", "ei\u00b7nen", "schlech\u00b7ten", "Prei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "So hilfft es doch/ da\u00df ich/ was gut und b\u00f6se/ wei\u00df.", "tokens": ["So", "hilfft", "es", "doch", "/", "da\u00df", "ich", "/", "was", "gut", "und", "b\u00f6\u00b7se", "/", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "$(", "PWS", "ADJD", "KON", "ADJD", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Man spricht von alle dem/ als wie ein kleines Kind/", "tokens": ["Man", "spricht", "von", "al\u00b7le", "dem", "/", "als", "wie", "ein", "klei\u00b7nes", "Kind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PIS", "ART", "$(", "KOUS", "KOKOM", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das nichts wahrhafftes wei\u00df/ und dennoch etwas nennet/", "tokens": ["Das", "nichts", "wahr\u00b7haff\u00b7tes", "wei\u00df", "/", "und", "den\u00b7noch", "et\u00b7was", "nen\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "ADJA", "VVFIN", "$(", "KON", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Wo nicht Erfahrenheit und Wi\u00dfen einig sind/", "tokens": ["Wo", "nicht", "Er\u00b7fah\u00b7ren\u00b7heit", "und", "Wi\u00b7\u00dfen", "ei\u00b7nig", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "NN", "KON", "NN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo man die Tugend nicht/ so wie die Liebe kennet.", "tokens": ["Wo", "man", "die", "Tu\u00b7gend", "nicht", "/", "so", "wie", "die", "Lie\u00b7be", "ken\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "PTKNEG", "$(", "ADV", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Tugend/ die verha\u00dft/ wenn ", "tokens": ["Die", "Tu\u00b7gend", "/", "die", "ver\u00b7ha\u00dft", "/", "wenn"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$(", "ART", "ADJD", "$(", "KOUS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Hat bey dem Kl\u00fcgsten offt am Ende noch gesiegt.", "tokens": ["Hat", "bey", "dem", "Kl\u00fcgs\u00b7ten", "offt", "am", "En\u00b7de", "noch", "ge\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Allein/ mein Hertzens-Freund/ aus Tugend wird hinfort", "tokens": ["Al\u00b7lein", "/", "mein", "Hert\u00b7zens\u00b7Freund", "/", "aus", "Tu\u00b7gend", "wird", "hin\u00b7fort"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "PPOSAT", "NN", "$(", "APPR", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Liebe schlauer Trieb nicht in dem Hertzen rasen.", "tokens": ["Der", "Lie\u00b7be", "schlau\u00b7er", "Trieb", "nicht", "in", "dem", "Hert\u00b7zen", "ra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich suche nun mit dir der Tugend sichern Port.", "tokens": ["Ich", "su\u00b7che", "nun", "mit", "dir", "der", "Tu\u00b7gend", "si\u00b7chern", "Port", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "ART", "NN", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verstand und Klugheit soll in meine Seegel blasen.", "tokens": ["Ver\u00b7stand", "und", "Klug\u00b7heit", "soll", "in", "mei\u00b7ne", "See\u00b7gel", "bla\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es geht mein Schiff nicht mehr nach", "tokens": ["Es", "geht", "mein", "Schiff", "nicht", "mehr", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "So lang ich unter dir/ und ein ", "tokens": ["So", "lang", "ich", "un\u00b7ter", "dir", "/", "und", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "APPR", "PPER", "$(", "KON", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}