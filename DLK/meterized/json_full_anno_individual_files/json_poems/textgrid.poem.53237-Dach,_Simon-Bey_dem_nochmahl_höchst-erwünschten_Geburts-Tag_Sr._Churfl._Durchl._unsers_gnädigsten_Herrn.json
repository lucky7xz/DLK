{"textgrid.poem.53237": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Bey dem nochmahl h\u00f6chst-erw\u00fcnschten Geburts-Tag Sr. Churfl. Durchl. unsers gn\u00e4digsten Herrn", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jetzund prangt mein Seiten-Werck,", "tokens": ["Je\u00b7tzund", "prangt", "mein", "Sei\u00b7ten\u00b7\u00b7Werck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Weisse Seid' h\u00e4lt es bezogen,", "tokens": ["Weis\u00b7se", "Seid'", "h\u00e4lt", "es", "be\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle Zier in K\u00f6nigsbergk", "tokens": ["Al\u00b7le", "Zier", "in", "K\u00f6\u00b7nigs\u00b7bergk"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weichet meinem g\u00fcldnen Bogen,", "tokens": ["Wei\u00b7chet", "mei\u00b7nem", "g\u00fcld\u00b7nen", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vieles Lint und G\u00fclden Band", "tokens": ["Vie\u00b7les", "Lint", "und", "G\u00fcl\u00b7den", "Band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat umbwunden meine Hand.", "tokens": ["Hat", "um\u00b7bwun\u00b7den", "mei\u00b7ne", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "H\u00f6rt, O Spree und Oder, mich,", "tokens": ["H\u00f6rt", ",", "O", "Spree", "und", "O\u00b7der", ",", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "NE", "KON", "NE", "$,", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6r, O Elbe, mich von weiten,", "tokens": ["H\u00f6r", ",", "O", "El\u00b7be", ",", "mich", "von", "wei\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "NE", "$,", "PRF", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und du Rein-Strom sonderlich,", "tokens": ["Und", "du", "Rein\u00b7Strom", "son\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00f6r die Amnuth meiner Seiten,", "tokens": ["H\u00f6r", "die", "Am\u00b7nuth", "mei\u00b7ner", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was in Cleve sich er\u00e4ugt", "tokens": ["Was", "in", "Cle\u00b7ve", "sich", "er\u00b7\u00e4ugt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NE", "PRF", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Werde meinem Spiel geneigt,", "tokens": ["Wer\u00b7de", "mei\u00b7nem", "Spiel", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wo die Lieb und Zier der Welt,", "tokens": ["Wo", "die", "Lieb", "und", "Zier", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser ChurF\u00fcrst, und sein Leben,", "tokens": ["Un\u00b7ser", "Chur", "F\u00fcrst", ",", "und", "sein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "KON", "PPOSAT", "NN", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Sie Loyse, sich enth\u00e4lt,", "tokens": ["Sie", "Loy\u00b7se", ",", "sich", "ent\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NE", "$,", "PRF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die mir Fug zu singen geben,", "tokens": ["Die", "mir", "Fug", "zu", "sin\u00b7gen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich diesen wehrten Tag,", "tokens": ["Da\u00df", "ich", "die\u00b7sen", "wehr\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie geb\u00fchrt, begehen mag.", "tokens": ["Wie", "ge\u00b7b\u00fchrt", ",", "be\u00b7ge\u00b7hen", "mag."], "token_info": ["word", "word", "punct", "word", "abbreviation"], "pos": ["PWAV", "VVPP", "$,", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Wenn der Morgenr\u00f6hte Gut", "tokens": ["Wenn", "der", "Mor\u00b7gen\u00b7r\u00f6h\u00b7te", "Gut"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Reichthum aller Erden", "tokens": ["Und", "der", "Reicht\u00b7hum", "al\u00b7ler", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nte durch des Pregels Flut", "tokens": ["K\u00f6n\u00b7te", "durch", "des", "Pre\u00b7gels", "Flut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In mein Hau\u00df gesp\u00fchlet werden,", "tokens": ["In", "mein", "Hau\u00df", "ge\u00b7sp\u00fch\u00b7let", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4r' es mir so thewer nicht", "tokens": ["W\u00e4r'", "es", "mir", "so", "the\u00b7wer", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADJD", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als die\u00df sch\u00f6ne Tagelicht.", "tokens": ["Als", "die\u00df", "sch\u00f6\u00b7ne", "Ta\u00b7ge\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich bekenn' es durch den Wind", "tokens": ["Ich", "be\u00b7kenn'", "es", "durch", "den", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner Seufftzer, durch die Zehren,", "tokens": ["Mei\u00b7ner", "Seufft\u00b7zer", ",", "durch", "die", "Zeh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche hei\u00df von Andacht sind", "tokens": ["Wel\u00b7che", "hei\u00df", "von", "An\u00b7dacht", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "APPR", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dem Himmel Danck gewehren,", "tokens": ["Und", "dem", "Him\u00b7mel", "Danck", "ge\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Diesen Tag-Schein setz' ich nach", "tokens": ["Die\u00b7sen", "Tag\u00b7Schein", "setz'", "ich", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dem, den mir die Mutter brach.", "tokens": ["Dem", ",", "den", "mir", "die", "Mut\u00b7ter", "brach", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sch\u00f6ne Sonne, la\u00df dich au\u00df", "tokens": ["Sch\u00f6\u00b7ne", "Son\u00b7ne", ",", "la\u00df", "dich", "au\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit der besten Lufft im Lentzen,", "tokens": ["Mit", "der", "bes\u00b7ten", "Lufft", "im", "Lent\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mahl uns blaw des Himmels Hau\u00df,", "tokens": ["Mahl", "uns", "blaw", "des", "Him\u00b7mels", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df dein Fewer heller gl\u00e4ntzen,", "tokens": ["La\u00df", "dein", "Fe\u00b7wer", "hel\u00b7ler", "gl\u00e4nt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und schlag' umb die gantze Welt", "tokens": ["Und", "schlag'", "umb", "die", "gant\u00b7ze", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Deiner Stralen g\u00fcldnes Zelt.", "tokens": ["Dei\u00b7ner", "Stra\u00b7len", "g\u00fcld\u00b7nes", "Zelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und so lang du Licht und Pracht", "tokens": ["Und", "so", "lang", "du", "Licht", "und", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "PPER", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fchrst auff deinem g\u00fcldnen Wagen,", "tokens": ["F\u00fchrst", "auff", "dei\u00b7nem", "g\u00fcld\u00b7nen", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nimm uns diesen Tag in acht,", "tokens": ["Nimm", "uns", "die\u00b7sen", "Tag", "in", "acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PDAT", "NN", "APPR", "CARD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df ihn Lust und Anmuht tragen,", "tokens": ["La\u00df", "ihn", "Lust", "und", "An\u00b7muht", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df in ihm durchaus kein Weh", "tokens": ["Da\u00df", "in", "ihm", "durc\u00b7haus", "kein", "Weh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Sey zu Lande noch zur See,", "tokens": ["Sey", "zu", "Lan\u00b7de", "noch", "zur", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Da\u00df alsdann die G\u00f6tter sich", "tokens": ["Da\u00df", "als\u00b7dann", "die", "G\u00f6t\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4uffig auff die Erde finden,", "tokens": ["H\u00e4uf\u00b7fig", "auff", "die", "Er\u00b7de", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sich alles inniglich", "tokens": ["Da\u00df", "sich", "al\u00b7les", "in\u00b7nig\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PIS", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00f6g in Liebe fest verbinden,", "tokens": ["M\u00f6g", "in", "Lie\u00b7be", "fest", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und gew\u00fcnschte Gn\u00fcg und Rhu", "tokens": ["Und", "ge\u00b7w\u00fcnschte", "Gn\u00fcg", "und", "Rhu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Sich zu allen Menschen thu.", "tokens": ["Sich", "zu", "al\u00b7len", "Men\u00b7schen", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Denn der ChurF\u00fcrst, unser Heil,", "tokens": ["Denn", "der", "Chur", "F\u00fcrst", ",", "un\u00b7ser", "Heil", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward vor zwey und dreissig Jahren", "tokens": ["Ward", "vor", "zwey", "und", "dreis\u00b7sig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "CARD", "KON", "CARD", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Uns, den Seinen, heut zu theil,", "tokens": ["Uns", ",", "den", "Sei\u00b7nen", ",", "heut", "zu", "theil", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "PPOSS", "$,", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was durch Ihn uns wiederfahren,", "tokens": ["Was", "durch", "Ihn", "uns", "wie\u00b7der\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was an Heil uns jetzt behagt,", "tokens": ["Was", "an", "Heil", "uns", "jetzt", "be\u00b7hagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ward uns damals zugesagt.", "tokens": ["Ward", "uns", "da\u00b7mals", "zu\u00b7ge\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Wie, wenn Castors Stern ersteht,", "tokens": ["Wie", ",", "wenn", "Cas\u00b7tors", "Stern", "er\u00b7steht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schiffer Hertz und Leben fassen,", "tokens": ["Schif\u00b7fer", "Hertz", "und", "Le\u00b7ben", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die helle Morgenr\u00f6ht", "tokens": ["Wie", "die", "hel\u00b7le", "Mor\u00b7gen\u00b7r\u00f6ht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns das Wetter sch\u00f6n wil lassen,", "tokens": ["Uns", "das", "Wet\u00b7ter", "sch\u00f6n", "wil", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also schlug uns diesen Stand", "tokens": ["Al\u00b7so", "schlug", "uns", "die\u00b7sen", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schon sein Ursprung in die Hand.", "tokens": ["Schon", "sein", "Ur\u00b7sprung", "in", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "O des guten, welches wir,", "tokens": ["O", "des", "gu\u00b7ten", ",", "wel\u00b7ches", "wir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "$,", "PRELS", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seit Gott Ihn geschenckt, empfunden!", "tokens": ["Seit", "Gott", "Ihn", "ge\u00b7schenckt", ",", "emp\u00b7fun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ein jeder kennt an Zier,", "tokens": ["Was", "ein", "je\u00b7der", "kennt", "an", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "PIS", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was er zehlt an guten Stunden,", "tokens": ["Was", "er", "zehlt", "an", "gu\u00b7ten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine Lust, sein Gl\u00fcckes-Schein", "tokens": ["Sei\u00b7ne", "Lust", ",", "sein", "Gl\u00fc\u00b7ckes\u00b7Schein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Giebet Gott durch Ihn allein.", "tokens": ["Gie\u00b7bet", "Gott", "durch", "Ihn", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Da\u00df den Bawren umb das Feld", "tokens": ["Da\u00df", "den", "Baw\u00b7ren", "umb", "das", "Feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre Hoffnung nicht kan fehlen,", "tokens": ["Ih\u00b7re", "Hoff\u00b7nung", "nicht", "kan", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihr Vieh' sich tr\u00e4chtig h\u00e4lt", "tokens": ["Da\u00df", "ihr", "Vieh'", "sich", "tr\u00e4ch\u00b7tig", "h\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "PRF", "ADJD", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sie grosse Heerden zehlen,", "tokens": ["Und", "sie", "gros\u00b7se", "Heer\u00b7den", "zeh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df sie frey sind von Beschwer,", "tokens": ["Da\u00df", "sie", "frey", "sind", "von", "Be\u00b7schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schaffen einig Gott und Er.", "tokens": ["Schaf\u00b7fen", "ei\u00b7nig", "Gott", "und", "Er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Er, der L\u00e4nder Schutz und Krohn,", "tokens": ["Er", ",", "der", "L\u00e4n\u00b7der", "Schutz", "und", "Krohn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist uns alle Gn\u00fcg' und G\u00fcte,", "tokens": ["Ist", "uns", "al\u00b7le", "Gn\u00fcg'", "und", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Er erh\u00e4lt den Helicon", "tokens": ["Er", "er\u00b7h\u00e4lt", "den", "He\u00b7li\u00b7con"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die K\u00fcnst' in ihrer Bl\u00fcte,", "tokens": ["Und", "die", "K\u00fcnst'", "in", "ih\u00b7rer", "Bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihm geb\u00fchrt der Danck und Prei\u00df", "tokens": ["Ihm", "ge\u00b7b\u00fchrt", "der", "Danck", "und", "Prei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Tugend die man wei\u00df.", "tokens": ["Al\u00b7ler", "Tu\u00b7gend", "die", "man", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Ach, wer wei\u00df an welchem Ort", "tokens": ["Ach", ",", "wer", "wei\u00df", "an", "wel\u00b7chem", "Ort"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWS", "VVFIN", "APPR", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir im Elend m\u00f6chten schweben", "tokens": ["Wir", "im", "E\u00b7lend", "m\u00f6ch\u00b7ten", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwischen Drangsal, Raub und Mord,", "tokens": ["Zwi\u00b7schen", "Dran\u00b7gsal", ",", "Raub", "und", "Mord", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00e4tt' uns Ihn Gott nicht gegeben,", "tokens": ["H\u00e4tt'", "uns", "Ihn", "Gott", "nicht", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "NN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was war vor der Zeit Athen,", "tokens": ["Was", "war", "vor", "der", "Zeit", "A\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Eh der Held kam von Tr\u00f6zen?", "tokens": ["Eh", "der", "Held", "kam", "von", "Tr\u00f6\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.15": {"line.1": {"text": "Umb Corinth her \u00fcberall", "tokens": ["Umb", "Co\u00b7rinth", "her", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "NE", "APZR", "ADV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Thurste sich kein Mensch beweisen,", "tokens": ["Thurs\u00b7te", "sich", "kein", "Mensch", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemand kunte dazumal", "tokens": ["Nie\u00b7mand", "kun\u00b7te", "da\u00b7zu\u00b7mal"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sicher durch den Isthmus reisen:", "tokens": ["Si\u00b7cher", "durch", "den", "Isth\u00b7mus", "rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Theseus setzt in gutten Stand", "tokens": ["The\u00b7seus", "setzt", "in", "gut\u00b7ten", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Fast das gantze Griechen-Land.", "tokens": ["Fast", "das", "gant\u00b7ze", "Grie\u00b7chen\u00b7Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Solt' ich nun nicht hoch erfrewt", "tokens": ["Solt'", "ich", "nun", "nicht", "hoch", "er\u00b7frewt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "ADJD", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Diesen werthen Tag begehen?", "tokens": ["Die\u00b7sen", "wert\u00b7hen", "Tag", "be\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auff, wer seine gutte Zeit", "tokens": ["Auff", ",", "wer", "sei\u00b7ne", "gut\u00b7te", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$,", "PWS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gl\u00fcck und Wolfahrt kan gestehen,", "tokens": ["Gl\u00fcck", "und", "Wol\u00b7fahrt", "kan", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Er heb' als im vollen Chor", "tokens": ["Er", "heb'", "als", "im", "vol\u00b7len", "Chor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "APPRART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Sinn und Hertz zu Gott empor.", "tokens": ["Sinn", "und", "Hertz", "zu", "Gott", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Vater, sprech' er, welches Land", "tokens": ["Va\u00b7ter", ",", "sprech'", "er", ",", "wel\u00b7ches", "Land"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Deiner Gunst soll f\u00e4hig werden,", "tokens": ["Dei\u00b7ner", "Gunst", "soll", "f\u00e4\u00b7hig", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das erh\u00e4lt au\u00df deiner Hand", "tokens": ["Das", "er\u00b7h\u00e4lt", "au\u00df", "dei\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcrsten, die ein Licht der Erden", "tokens": ["F\u00fcrs\u00b7ten", ",", "die", "ein", "Licht", "der", "Er\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und durch Lieb' und Unschuld rein", "tokens": ["Und", "durch", "Lieb'", "und", "Un\u00b7schuld", "rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und nach deinem Hertzen seyn.", "tokens": ["Und", "nach", "dei\u00b7nem", "Hert\u00b7zen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Du ertheilst uns einen Held", "tokens": ["Du", "er\u00b7theilst", "uns", "ei\u00b7nen", "Held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So von Gaben au\u00dferlesen,", "tokens": ["So", "von", "Ga\u00b7ben", "au\u00b7\u00dfer\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df die alte g\u00fcldne Welt", "tokens": ["Da\u00df", "die", "al\u00b7te", "g\u00fcld\u00b7ne", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sein kaum w\u00e4re wehrt gewesen,", "tokens": ["Sein", "kaum", "w\u00e4\u00b7re", "wehrt", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "VAFIN", "ADJD", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und hast Ihn auch dieses Jahr", "tokens": ["Und", "hast", "Ihn", "auch", "die\u00b7ses", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns gesichert f\u00fcr Gefahr.", "tokens": ["Uns", "ge\u00b7si\u00b7chert", "f\u00fcr", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Du erh\u00e4ltst uns dieses Licht,", "tokens": ["Du", "er\u00b7h\u00e4ltst", "uns", "die\u00b7ses", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4ssest uns nicht kl\u00e4glich heulen,", "tokens": ["L\u00e4s\u00b7sest", "uns", "nicht", "kl\u00e4g\u00b7lich", "heu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df dem grossen Hause nicht", "tokens": ["Da\u00df", "dem", "gros\u00b7sen", "Hau\u00b7se", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gar entgehen alle Seulen,", "tokens": ["Gar", "ent\u00b7ge\u00b7hen", "al\u00b7le", "Seu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vor die Gutthat opffern wir", "tokens": ["Vor", "die", "Gut\u00b7that", "opf\u00b7fern", "wir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsrer Hertzen Dancklied dir.", "tokens": ["Uns\u00b7rer", "Hert\u00b7zen", "Danck\u00b7lied", "dir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Nimm Dich Sein auch ferner an,", "tokens": ["Nimm", "Dich", "Sein", "auch", "fer\u00b7ner", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PPOSAT", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df Ihn starck und fr\u00f6lich leben,", "tokens": ["La\u00df", "Ihn", "starck", "und", "fr\u00f6\u00b7lich", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ein Mensch nicht bitten kann", "tokens": ["Was", "ein", "Mensch", "nicht", "bit\u00b7ten", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "PTKNEG", "VVINF", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch verstehn, weist du zu geben,", "tokens": ["Noch", "ver\u00b7stehn", ",", "weist", "du", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hilff durch Samen, wie zuvor,", "tokens": ["Hilff", "durch", "Sa\u00b7men", ",", "wie", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "PWAV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Diesem wehrten Haus' empor.", "tokens": ["Die\u00b7sem", "wehr\u00b7ten", "Haus'", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Bild uns unsre Noth wol ein,", "tokens": ["Bild", "uns", "uns\u00b7re", "Noth", "wol", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die uns w\u00fcrde sonst betreten,", "tokens": ["Die", "uns", "w\u00fcr\u00b7de", "sonst", "be\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir flehen in gemein", "tokens": ["Da\u00df", "wir", "fle\u00b7hen", "in", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dir mit Thr\u00e4nen und Gebehten,", "tokens": ["Dir", "mit", "Thr\u00e4\u00b7nen", "und", "Ge\u00b7beh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bi\u00df du wendest diese Last", "tokens": ["Bi\u00df", "du", "wen\u00b7dest", "die\u00b7se", "Last"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und uns, Gott, erh\u00f6ret hast.", "tokens": ["Und", "uns", ",", "Gott", ",", "er\u00b7h\u00f6\u00b7ret", "hast", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "NN", "$,", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Auff die Andacht wer nur kan", "tokens": ["Auff", "die", "An\u00b7dacht", "wer", "nur", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PWS", "ADV", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Irgends gute Lust erfinden,", "tokens": ["Ir\u00b7gends", "gu\u00b7te", "Lust", "er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nehme sie erfrewlich an,", "tokens": ["Neh\u00b7me", "sie", "er\u00b7frew\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und la\u00df alle Sorgen schwinden,", "tokens": ["Und", "la\u00df", "al\u00b7le", "Sor\u00b7gen", "schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die durch s\u00fcssen Frewden-Wein", "tokens": ["Die", "durch", "s\u00fcs\u00b7sen", "Fre\u00b7wden\u00b7Wein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcberw\u00e4ltigt m\u00fcssen seyn.", "tokens": ["\u00dc\u00b7berw\u00b7\u00e4l\u00b7tigt", "m\u00fcs\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Preussen wird nicht hinten stehn,", "tokens": ["Preus\u00b7sen", "wird", "nicht", "hin\u00b7ten", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre Pillau wird f\u00fcr allen", "tokens": ["Uns\u00b7re", "Pil\u00b7lau", "wird", "f\u00fcr", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Gesch\u00fctze lassen gehn,", "tokens": ["Die", "Ge\u00b7sch\u00fct\u00b7ze", "las\u00b7sen", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df die N\u00e4hrung sol erschallen", "tokens": ["Da\u00df", "die", "N\u00e4h\u00b7rung", "sol", "er\u00b7schal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die ferne Galathee", "tokens": ["Und", "die", "fer\u00b7ne", "Ga\u00b7la\u00b7thee"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sol erschrecken auff der See.", "tokens": ["Sol", "er\u00b7schre\u00b7cken", "auff", "der", "See", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "La\u00df, O ChurF\u00fcrst, unsre Rhu,", "tokens": ["La\u00df", ",", "O", "Chur", "F\u00fcrst", ",", "uns\u00b7re", "Rhu", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NE", "NE", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gn\u00e4digst dir mein Hertz belieben,", "tokens": ["Gn\u00e4\u00b7digst", "dir", "mein", "Hertz", "be\u00b7lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wa\u00df ich hier au\u00df Andacht thu,", "tokens": ["Wa\u00df", "ich", "hier", "au\u00df", "An\u00b7dacht", "thu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich gutes je geschrieben,", "tokens": ["Was", "ich", "gu\u00b7tes", "je", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJA", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wann es deine Gnad' erh\u00e4lt,", "tokens": ["Wann", "es", "dei\u00b7ne", "Gnad'", "er\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "So besitz' ich eine Welt.", "tokens": ["So", "be\u00b7sitz'", "ich", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Jetzund prangt mein Seiten-Werck,", "tokens": ["Je\u00b7tzund", "prangt", "mein", "Sei\u00b7ten\u00b7\u00b7Werck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Weisse Seid' h\u00e4lt es bezogen,", "tokens": ["Weis\u00b7se", "Seid'", "h\u00e4lt", "es", "be\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle Zier in K\u00f6nigsbergk", "tokens": ["Al\u00b7le", "Zier", "in", "K\u00f6\u00b7nigs\u00b7bergk"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weichet meinem g\u00fcldnen Bogen,", "tokens": ["Wei\u00b7chet", "mei\u00b7nem", "g\u00fcld\u00b7nen", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vieles Lint und G\u00fclden Band", "tokens": ["Vie\u00b7les", "Lint", "und", "G\u00fcl\u00b7den", "Band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat umbwunden meine Hand.", "tokens": ["Hat", "um\u00b7bwun\u00b7den", "mei\u00b7ne", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "H\u00f6rt, O Spree und Oder, mich,", "tokens": ["H\u00f6rt", ",", "O", "Spree", "und", "O\u00b7der", ",", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "NE", "KON", "NE", "$,", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6r, O Elbe, mich von weiten,", "tokens": ["H\u00f6r", ",", "O", "El\u00b7be", ",", "mich", "von", "wei\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "NE", "$,", "PRF", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und du Rein-Strom sonderlich,", "tokens": ["Und", "du", "Rein\u00b7Strom", "son\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00f6r die Amnuth meiner Seiten,", "tokens": ["H\u00f6r", "die", "Am\u00b7nuth", "mei\u00b7ner", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was in Cleve sich er\u00e4ugt", "tokens": ["Was", "in", "Cle\u00b7ve", "sich", "er\u00b7\u00e4ugt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NE", "PRF", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Werde meinem Spiel geneigt,", "tokens": ["Wer\u00b7de", "mei\u00b7nem", "Spiel", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Wo die Lieb und Zier der Welt,", "tokens": ["Wo", "die", "Lieb", "und", "Zier", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser ChurF\u00fcrst, und sein Leben,", "tokens": ["Un\u00b7ser", "Chur", "F\u00fcrst", ",", "und", "sein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "KON", "PPOSAT", "NN", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Sie Loyse, sich enth\u00e4lt,", "tokens": ["Sie", "Loy\u00b7se", ",", "sich", "ent\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NE", "$,", "PRF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die mir Fug zu singen geben,", "tokens": ["Die", "mir", "Fug", "zu", "sin\u00b7gen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich diesen wehrten Tag,", "tokens": ["Da\u00df", "ich", "die\u00b7sen", "wehr\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie geb\u00fchrt, begehen mag.", "tokens": ["Wie", "ge\u00b7b\u00fchrt", ",", "be\u00b7ge\u00b7hen", "mag."], "token_info": ["word", "word", "punct", "word", "abbreviation"], "pos": ["PWAV", "VVPP", "$,", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Wenn der Morgenr\u00f6hte Gut", "tokens": ["Wenn", "der", "Mor\u00b7gen\u00b7r\u00f6h\u00b7te", "Gut"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Reichthum aller Erden", "tokens": ["Und", "der", "Reicht\u00b7hum", "al\u00b7ler", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nte durch des Pregels Flut", "tokens": ["K\u00f6n\u00b7te", "durch", "des", "Pre\u00b7gels", "Flut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In mein Hau\u00df gesp\u00fchlet werden,", "tokens": ["In", "mein", "Hau\u00df", "ge\u00b7sp\u00fch\u00b7let", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4r' es mir so thewer nicht", "tokens": ["W\u00e4r'", "es", "mir", "so", "the\u00b7wer", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADJD", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als die\u00df sch\u00f6ne Tagelicht.", "tokens": ["Als", "die\u00df", "sch\u00f6\u00b7ne", "Ta\u00b7ge\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Ich bekenn' es durch den Wind", "tokens": ["Ich", "be\u00b7kenn'", "es", "durch", "den", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner Seufftzer, durch die Zehren,", "tokens": ["Mei\u00b7ner", "Seufft\u00b7zer", ",", "durch", "die", "Zeh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche hei\u00df von Andacht sind", "tokens": ["Wel\u00b7che", "hei\u00df", "von", "An\u00b7dacht", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "APPR", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dem Himmel Danck gewehren,", "tokens": ["Und", "dem", "Him\u00b7mel", "Danck", "ge\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Diesen Tag-Schein setz' ich nach", "tokens": ["Die\u00b7sen", "Tag\u00b7Schein", "setz'", "ich", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dem, den mir die Mutter brach.", "tokens": ["Dem", ",", "den", "mir", "die", "Mut\u00b7ter", "brach", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Sch\u00f6ne Sonne, la\u00df dich au\u00df", "tokens": ["Sch\u00f6\u00b7ne", "Son\u00b7ne", ",", "la\u00df", "dich", "au\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit der besten Lufft im Lentzen,", "tokens": ["Mit", "der", "bes\u00b7ten", "Lufft", "im", "Lent\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mahl uns blaw des Himmels Hau\u00df,", "tokens": ["Mahl", "uns", "blaw", "des", "Him\u00b7mels", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df dein Fewer heller gl\u00e4ntzen,", "tokens": ["La\u00df", "dein", "Fe\u00b7wer", "hel\u00b7ler", "gl\u00e4nt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und schlag' umb die gantze Welt", "tokens": ["Und", "schlag'", "umb", "die", "gant\u00b7ze", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Deiner Stralen g\u00fcldnes Zelt.", "tokens": ["Dei\u00b7ner", "Stra\u00b7len", "g\u00fcld\u00b7nes", "Zelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Und so lang du Licht und Pracht", "tokens": ["Und", "so", "lang", "du", "Licht", "und", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "PPER", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fchrst auff deinem g\u00fcldnen Wagen,", "tokens": ["F\u00fchrst", "auff", "dei\u00b7nem", "g\u00fcld\u00b7nen", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nimm uns diesen Tag in acht,", "tokens": ["Nimm", "uns", "die\u00b7sen", "Tag", "in", "acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PDAT", "NN", "APPR", "CARD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df ihn Lust und Anmuht tragen,", "tokens": ["La\u00df", "ihn", "Lust", "und", "An\u00b7muht", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df in ihm durchaus kein Weh", "tokens": ["Da\u00df", "in", "ihm", "durc\u00b7haus", "kein", "Weh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Sey zu Lande noch zur See,", "tokens": ["Sey", "zu", "Lan\u00b7de", "noch", "zur", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Da\u00df alsdann die G\u00f6tter sich", "tokens": ["Da\u00df", "als\u00b7dann", "die", "G\u00f6t\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4uffig auff die Erde finden,", "tokens": ["H\u00e4uf\u00b7fig", "auff", "die", "Er\u00b7de", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sich alles inniglich", "tokens": ["Da\u00df", "sich", "al\u00b7les", "in\u00b7nig\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PIS", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00f6g in Liebe fest verbinden,", "tokens": ["M\u00f6g", "in", "Lie\u00b7be", "fest", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und gew\u00fcnschte Gn\u00fcg und Rhu", "tokens": ["Und", "ge\u00b7w\u00fcnschte", "Gn\u00fcg", "und", "Rhu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Sich zu allen Menschen thu.", "tokens": ["Sich", "zu", "al\u00b7len", "Men\u00b7schen", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Denn der ChurF\u00fcrst, unser Heil,", "tokens": ["Denn", "der", "Chur", "F\u00fcrst", ",", "un\u00b7ser", "Heil", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward vor zwey und dreissig Jahren", "tokens": ["Ward", "vor", "zwey", "und", "dreis\u00b7sig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "CARD", "KON", "CARD", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Uns, den Seinen, heut zu theil,", "tokens": ["Uns", ",", "den", "Sei\u00b7nen", ",", "heut", "zu", "theil", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "PPOSS", "$,", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was durch Ihn uns wiederfahren,", "tokens": ["Was", "durch", "Ihn", "uns", "wie\u00b7der\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was an Heil uns jetzt behagt,", "tokens": ["Was", "an", "Heil", "uns", "jetzt", "be\u00b7hagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ward uns damals zugesagt.", "tokens": ["Ward", "uns", "da\u00b7mals", "zu\u00b7ge\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Wie, wenn Castors Stern ersteht,", "tokens": ["Wie", ",", "wenn", "Cas\u00b7tors", "Stern", "er\u00b7steht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schiffer Hertz und Leben fassen,", "tokens": ["Schif\u00b7fer", "Hertz", "und", "Le\u00b7ben", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die helle Morgenr\u00f6ht", "tokens": ["Wie", "die", "hel\u00b7le", "Mor\u00b7gen\u00b7r\u00f6ht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns das Wetter sch\u00f6n wil lassen,", "tokens": ["Uns", "das", "Wet\u00b7ter", "sch\u00f6n", "wil", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also schlug uns diesen Stand", "tokens": ["Al\u00b7so", "schlug", "uns", "die\u00b7sen", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schon sein Ursprung in die Hand.", "tokens": ["Schon", "sein", "Ur\u00b7sprung", "in", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "O des guten, welches wir,", "tokens": ["O", "des", "gu\u00b7ten", ",", "wel\u00b7ches", "wir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "$,", "PRELS", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seit Gott Ihn geschenckt, empfunden!", "tokens": ["Seit", "Gott", "Ihn", "ge\u00b7schenckt", ",", "emp\u00b7fun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ein jeder kennt an Zier,", "tokens": ["Was", "ein", "je\u00b7der", "kennt", "an", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "PIS", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was er zehlt an guten Stunden,", "tokens": ["Was", "er", "zehlt", "an", "gu\u00b7ten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine Lust, sein Gl\u00fcckes-Schein", "tokens": ["Sei\u00b7ne", "Lust", ",", "sein", "Gl\u00fc\u00b7ckes\u00b7Schein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Giebet Gott durch Ihn allein.", "tokens": ["Gie\u00b7bet", "Gott", "durch", "Ihn", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Da\u00df den Bawren umb das Feld", "tokens": ["Da\u00df", "den", "Baw\u00b7ren", "umb", "das", "Feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre Hoffnung nicht kan fehlen,", "tokens": ["Ih\u00b7re", "Hoff\u00b7nung", "nicht", "kan", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihr Vieh' sich tr\u00e4chtig h\u00e4lt", "tokens": ["Da\u00df", "ihr", "Vieh'", "sich", "tr\u00e4ch\u00b7tig", "h\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "PRF", "ADJD", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sie grosse Heerden zehlen,", "tokens": ["Und", "sie", "gros\u00b7se", "Heer\u00b7den", "zeh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df sie frey sind von Beschwer,", "tokens": ["Da\u00df", "sie", "frey", "sind", "von", "Be\u00b7schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schaffen einig Gott und Er.", "tokens": ["Schaf\u00b7fen", "ei\u00b7nig", "Gott", "und", "Er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Er, der L\u00e4nder Schutz und Krohn,", "tokens": ["Er", ",", "der", "L\u00e4n\u00b7der", "Schutz", "und", "Krohn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist uns alle Gn\u00fcg' und G\u00fcte,", "tokens": ["Ist", "uns", "al\u00b7le", "Gn\u00fcg'", "und", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Er erh\u00e4lt den Helicon", "tokens": ["Er", "er\u00b7h\u00e4lt", "den", "He\u00b7li\u00b7con"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die K\u00fcnst' in ihrer Bl\u00fcte,", "tokens": ["Und", "die", "K\u00fcnst'", "in", "ih\u00b7rer", "Bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihm geb\u00fchrt der Danck und Prei\u00df", "tokens": ["Ihm", "ge\u00b7b\u00fchrt", "der", "Danck", "und", "Prei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Tugend die man wei\u00df.", "tokens": ["Al\u00b7ler", "Tu\u00b7gend", "die", "man", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Ach, wer wei\u00df an welchem Ort", "tokens": ["Ach", ",", "wer", "wei\u00df", "an", "wel\u00b7chem", "Ort"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWS", "VVFIN", "APPR", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir im Elend m\u00f6chten schweben", "tokens": ["Wir", "im", "E\u00b7lend", "m\u00f6ch\u00b7ten", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwischen Drangsal, Raub und Mord,", "tokens": ["Zwi\u00b7schen", "Dran\u00b7gsal", ",", "Raub", "und", "Mord", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00e4tt' uns Ihn Gott nicht gegeben,", "tokens": ["H\u00e4tt'", "uns", "Ihn", "Gott", "nicht", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "NN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was war vor der Zeit Athen,", "tokens": ["Was", "war", "vor", "der", "Zeit", "A\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Eh der Held kam von Tr\u00f6zen?", "tokens": ["Eh", "der", "Held", "kam", "von", "Tr\u00f6\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.39": {"line.1": {"text": "Umb Corinth her \u00fcberall", "tokens": ["Umb", "Co\u00b7rinth", "her", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "NE", "APZR", "ADV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Thurste sich kein Mensch beweisen,", "tokens": ["Thurs\u00b7te", "sich", "kein", "Mensch", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemand kunte dazumal", "tokens": ["Nie\u00b7mand", "kun\u00b7te", "da\u00b7zu\u00b7mal"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sicher durch den Isthmus reisen:", "tokens": ["Si\u00b7cher", "durch", "den", "Isth\u00b7mus", "rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Theseus setzt in gutten Stand", "tokens": ["The\u00b7seus", "setzt", "in", "gut\u00b7ten", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Fast das gantze Griechen-Land.", "tokens": ["Fast", "das", "gant\u00b7ze", "Grie\u00b7chen\u00b7Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Solt' ich nun nicht hoch erfrewt", "tokens": ["Solt'", "ich", "nun", "nicht", "hoch", "er\u00b7frewt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "ADJD", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Diesen werthen Tag begehen?", "tokens": ["Die\u00b7sen", "wert\u00b7hen", "Tag", "be\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auff, wer seine gutte Zeit", "tokens": ["Auff", ",", "wer", "sei\u00b7ne", "gut\u00b7te", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$,", "PWS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gl\u00fcck und Wolfahrt kan gestehen,", "tokens": ["Gl\u00fcck", "und", "Wol\u00b7fahrt", "kan", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Er heb' als im vollen Chor", "tokens": ["Er", "heb'", "als", "im", "vol\u00b7len", "Chor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "APPRART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Sinn und Hertz zu Gott empor.", "tokens": ["Sinn", "und", "Hertz", "zu", "Gott", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Vater, sprech' er, welches Land", "tokens": ["Va\u00b7ter", ",", "sprech'", "er", ",", "wel\u00b7ches", "Land"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Deiner Gunst soll f\u00e4hig werden,", "tokens": ["Dei\u00b7ner", "Gunst", "soll", "f\u00e4\u00b7hig", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das erh\u00e4lt au\u00df deiner Hand", "tokens": ["Das", "er\u00b7h\u00e4lt", "au\u00df", "dei\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcrsten, die ein Licht der Erden", "tokens": ["F\u00fcrs\u00b7ten", ",", "die", "ein", "Licht", "der", "Er\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und durch Lieb' und Unschuld rein", "tokens": ["Und", "durch", "Lieb'", "und", "Un\u00b7schuld", "rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und nach deinem Hertzen seyn.", "tokens": ["Und", "nach", "dei\u00b7nem", "Hert\u00b7zen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Du ertheilst uns einen Held", "tokens": ["Du", "er\u00b7theilst", "uns", "ei\u00b7nen", "Held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So von Gaben au\u00dferlesen,", "tokens": ["So", "von", "Ga\u00b7ben", "au\u00b7\u00dfer\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df die alte g\u00fcldne Welt", "tokens": ["Da\u00df", "die", "al\u00b7te", "g\u00fcld\u00b7ne", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sein kaum w\u00e4re wehrt gewesen,", "tokens": ["Sein", "kaum", "w\u00e4\u00b7re", "wehrt", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "VAFIN", "ADJD", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und hast Ihn auch dieses Jahr", "tokens": ["Und", "hast", "Ihn", "auch", "die\u00b7ses", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns gesichert f\u00fcr Gefahr.", "tokens": ["Uns", "ge\u00b7si\u00b7chert", "f\u00fcr", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Du erh\u00e4ltst uns dieses Licht,", "tokens": ["Du", "er\u00b7h\u00e4ltst", "uns", "die\u00b7ses", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4ssest uns nicht kl\u00e4glich heulen,", "tokens": ["L\u00e4s\u00b7sest", "uns", "nicht", "kl\u00e4g\u00b7lich", "heu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df dem grossen Hause nicht", "tokens": ["Da\u00df", "dem", "gros\u00b7sen", "Hau\u00b7se", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gar entgehen alle Seulen,", "tokens": ["Gar", "ent\u00b7ge\u00b7hen", "al\u00b7le", "Seu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vor die Gutthat opffern wir", "tokens": ["Vor", "die", "Gut\u00b7that", "opf\u00b7fern", "wir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsrer Hertzen Dancklied dir.", "tokens": ["Uns\u00b7rer", "Hert\u00b7zen", "Danck\u00b7lied", "dir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Nimm Dich Sein auch ferner an,", "tokens": ["Nimm", "Dich", "Sein", "auch", "fer\u00b7ner", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PPOSAT", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df Ihn starck und fr\u00f6lich leben,", "tokens": ["La\u00df", "Ihn", "starck", "und", "fr\u00f6\u00b7lich", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ein Mensch nicht bitten kann", "tokens": ["Was", "ein", "Mensch", "nicht", "bit\u00b7ten", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "PTKNEG", "VVINF", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch verstehn, weist du zu geben,", "tokens": ["Noch", "ver\u00b7stehn", ",", "weist", "du", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hilff durch Samen, wie zuvor,", "tokens": ["Hilff", "durch", "Sa\u00b7men", ",", "wie", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "PWAV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Diesem wehrten Haus' empor.", "tokens": ["Die\u00b7sem", "wehr\u00b7ten", "Haus'", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Bild uns unsre Noth wol ein,", "tokens": ["Bild", "uns", "uns\u00b7re", "Noth", "wol", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die uns w\u00fcrde sonst betreten,", "tokens": ["Die", "uns", "w\u00fcr\u00b7de", "sonst", "be\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir flehen in gemein", "tokens": ["Da\u00df", "wir", "fle\u00b7hen", "in", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dir mit Thr\u00e4nen und Gebehten,", "tokens": ["Dir", "mit", "Thr\u00e4\u00b7nen", "und", "Ge\u00b7beh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bi\u00df du wendest diese Last", "tokens": ["Bi\u00df", "du", "wen\u00b7dest", "die\u00b7se", "Last"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und uns, Gott, erh\u00f6ret hast.", "tokens": ["Und", "uns", ",", "Gott", ",", "er\u00b7h\u00f6\u00b7ret", "hast", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "NN", "$,", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Auff die Andacht wer nur kan", "tokens": ["Auff", "die", "An\u00b7dacht", "wer", "nur", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PWS", "ADV", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Irgends gute Lust erfinden,", "tokens": ["Ir\u00b7gends", "gu\u00b7te", "Lust", "er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nehme sie erfrewlich an,", "tokens": ["Neh\u00b7me", "sie", "er\u00b7frew\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und la\u00df alle Sorgen schwinden,", "tokens": ["Und", "la\u00df", "al\u00b7le", "Sor\u00b7gen", "schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die durch s\u00fcssen Frewden-Wein", "tokens": ["Die", "durch", "s\u00fcs\u00b7sen", "Fre\u00b7wden\u00b7Wein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcberw\u00e4ltigt m\u00fcssen seyn.", "tokens": ["\u00dc\u00b7berw\u00b7\u00e4l\u00b7tigt", "m\u00fcs\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Preussen wird nicht hinten stehn,", "tokens": ["Preus\u00b7sen", "wird", "nicht", "hin\u00b7ten", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre Pillau wird f\u00fcr allen", "tokens": ["Uns\u00b7re", "Pil\u00b7lau", "wird", "f\u00fcr", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Gesch\u00fctze lassen gehn,", "tokens": ["Die", "Ge\u00b7sch\u00fct\u00b7ze", "las\u00b7sen", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df die N\u00e4hrung sol erschallen", "tokens": ["Da\u00df", "die", "N\u00e4h\u00b7rung", "sol", "er\u00b7schal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die ferne Galathee", "tokens": ["Und", "die", "fer\u00b7ne", "Ga\u00b7la\u00b7thee"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sol erschrecken auff der See.", "tokens": ["Sol", "er\u00b7schre\u00b7cken", "auff", "der", "See", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "La\u00df, O ChurF\u00fcrst, unsre Rhu,", "tokens": ["La\u00df", ",", "O", "Chur", "F\u00fcrst", ",", "uns\u00b7re", "Rhu", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NE", "NE", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gn\u00e4digst dir mein Hertz belieben,", "tokens": ["Gn\u00e4\u00b7digst", "dir", "mein", "Hertz", "be\u00b7lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wa\u00df ich hier au\u00df Andacht thu,", "tokens": ["Wa\u00df", "ich", "hier", "au\u00df", "An\u00b7dacht", "thu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich gutes je geschrieben,", "tokens": ["Was", "ich", "gu\u00b7tes", "je", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJA", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wann es deine Gnad' erh\u00e4lt,", "tokens": ["Wann", "es", "dei\u00b7ne", "Gnad'", "er\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "So besitz' ich eine Welt.", "tokens": ["So", "be\u00b7sitz'", "ich", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}