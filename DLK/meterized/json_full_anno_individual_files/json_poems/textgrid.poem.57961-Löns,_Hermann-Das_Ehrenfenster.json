{"textgrid.poem.57961": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Das Ehrenfenster", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbdir zu Ehr'n woll'n wir stiften", "tokens": ["\u00bb", "dir", "zu", "Ehr'n", "woll'n", "wir", "stif\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "APPR", "NN", "VMFIN", "PPER", "VVFIN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "F\u00fcr das Rathaus aus Glas", "tokens": ["F\u00fcr", "das", "Rat\u00b7haus", "aus", "Glas"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ein pikfeines Fenster,", "tokens": ["Ein", "pik\u00b7fei\u00b7nes", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wie gef\u00e4llt dir denn das?", "tokens": ["Wie", "ge\u00b7f\u00e4llt", "dir", "denn", "das", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PDS", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Wir haben die Gelder,", "tokens": ["Wir", "ha\u00b7ben", "die", "Gel\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Zehntausend und mehr,", "tokens": ["Zehn\u00b7tau\u00b7send", "und", "mehr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wir geben dir zu Ehren", "tokens": ["Wir", "ge\u00b7ben", "dir", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie liebendgern her.\u00ab", "tokens": ["Sie", "lie\u00b7bend\u00b7gern", "her", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "\u00bbsehr freundlich, meine Herren,", "tokens": ["\u00bb", "sehr", "freund\u00b7lich", ",", "mei\u00b7ne", "Her\u00b7ren", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich bedank' mich auch sch\u00f6n,", "tokens": ["Ich", "be\u00b7dank'", "mich", "auch", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Doch was hilft mir ein Fenster,", "tokens": ["Doch", "was", "hilft", "mir", "ein", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich tu doch nicht 'raussehn.", "tokens": ["Ich", "tu", "doch", "nicht", "'raus\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und was meine Frau ist,", "tokens": ["Und", "was", "mei\u00b7ne", "Frau", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Macht sich auch nichts daraus,", "tokens": ["Macht", "sich", "auch", "nichts", "da\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADV", "PIS", "PAV", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Was hilft ihr ein Fenster,", "tokens": ["Was", "hilft", "ihr", "ein", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sie kuckt nicht daraus.", "tokens": ["Sie", "kuckt", "nicht", "da\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PAV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Was H\u00fcbsches, was Feines,", "tokens": ["Was", "H\u00fcb\u00b7sches", ",", "was", "Fei\u00b7nes", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJA", "$,", "PWS", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Das ziemt sich viel mehr,", "tokens": ["Das", "ziemt", "sich", "viel", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Denn allzuviel Ehre,", "tokens": ["Denn", "all\u00b7zu\u00b7viel", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Das ist zu viel Ehr'!\u00ab", "tokens": ["Das", "ist", "zu", "viel", "Ehr'", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Wie 's weiter gekommen,", "tokens": ["Wie", "'s", "wei\u00b7ter", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Das wei\u00df man noch nicht,", "tokens": ["Das", "wei\u00df", "man", "noch", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "PTKNEG", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Darum macht der S\u00e4nger", "tokens": ["Da\u00b7rum", "macht", "der", "S\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Vorl\u00e4ufig hier Schicht.", "tokens": ["Vor\u00b7l\u00e4u\u00b7fig", "hier", "Schicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.7": {"line.1": {"text": "\u00bbdir zu Ehr'n woll'n wir stiften", "tokens": ["\u00bb", "dir", "zu", "Ehr'n", "woll'n", "wir", "stif\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "APPR", "NN", "VMFIN", "PPER", "VVFIN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "F\u00fcr das Rathaus aus Glas", "tokens": ["F\u00fcr", "das", "Rat\u00b7haus", "aus", "Glas"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ein pikfeines Fenster,", "tokens": ["Ein", "pik\u00b7fei\u00b7nes", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wie gef\u00e4llt dir denn das?", "tokens": ["Wie", "ge\u00b7f\u00e4llt", "dir", "denn", "das", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PDS", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Wir haben die Gelder,", "tokens": ["Wir", "ha\u00b7ben", "die", "Gel\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Zehntausend und mehr,", "tokens": ["Zehn\u00b7tau\u00b7send", "und", "mehr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wir geben dir zu Ehren", "tokens": ["Wir", "ge\u00b7ben", "dir", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie liebendgern her.\u00ab", "tokens": ["Sie", "lie\u00b7bend\u00b7gern", "her", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.9": {"line.1": {"text": "\u00bbsehr freundlich, meine Herren,", "tokens": ["\u00bb", "sehr", "freund\u00b7lich", ",", "mei\u00b7ne", "Her\u00b7ren", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich bedank' mich auch sch\u00f6n,", "tokens": ["Ich", "be\u00b7dank'", "mich", "auch", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Doch was hilft mir ein Fenster,", "tokens": ["Doch", "was", "hilft", "mir", "ein", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich tu doch nicht 'raussehn.", "tokens": ["Ich", "tu", "doch", "nicht", "'raus\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und was meine Frau ist,", "tokens": ["Und", "was", "mei\u00b7ne", "Frau", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Macht sich auch nichts daraus,", "tokens": ["Macht", "sich", "auch", "nichts", "da\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADV", "PIS", "PAV", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Was hilft ihr ein Fenster,", "tokens": ["Was", "hilft", "ihr", "ein", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sie kuckt nicht daraus.", "tokens": ["Sie", "kuckt", "nicht", "da\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PAV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.11": {"line.1": {"text": "Was H\u00fcbsches, was Feines,", "tokens": ["Was", "H\u00fcb\u00b7sches", ",", "was", "Fei\u00b7nes", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJA", "$,", "PWS", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Das ziemt sich viel mehr,", "tokens": ["Das", "ziemt", "sich", "viel", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Denn allzuviel Ehre,", "tokens": ["Denn", "all\u00b7zu\u00b7viel", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Das ist zu viel Ehr'!\u00ab", "tokens": ["Das", "ist", "zu", "viel", "Ehr'", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.12": {"line.1": {"text": "Wie 's weiter gekommen,", "tokens": ["Wie", "'s", "wei\u00b7ter", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Das wei\u00df man noch nicht,", "tokens": ["Das", "wei\u00df", "man", "noch", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "PTKNEG", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Darum macht der S\u00e4nger", "tokens": ["Da\u00b7rum", "macht", "der", "S\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Vorl\u00e4ufig hier Schicht.", "tokens": ["Vor\u00b7l\u00e4u\u00b7fig", "hier", "Schicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}}}}