{"textgrid.poem.48723": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "10. Herrn D. H\u00f6veln zu Rige, 1633 November", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich hab' euch Leid getan, ihr deutschen Kastalinnen,", "tokens": ["Ich", "hab'", "euch", "Leid", "ge\u00b7tan", ",", "ihr", "deut\u00b7schen", "Kas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "VVPP", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "o ihr mein andrer Ruhm, als ich mir bildet ein,", "tokens": ["o", "ihr", "mein", "an\u00b7drer", "Ruhm", ",", "als", "ich", "mir", "bil\u00b7det", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "PPER", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "man ehr' euch weiter nicht, als was der weise ", "tokens": ["man", "ehr'", "euch", "wei\u00b7ter", "nicht", ",", "als", "was", "der", "wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "KOUS", "PIS", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der ", "tokens": ["der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.2": {"line.1": {"text": "Ich hab' euch Leid getan, ihr edlen Pierinnen;", "tokens": ["Ich", "hab'", "euch", "Leid", "ge\u00b7tan", ",", "ihr", "ed\u00b7len", "Pie\u00b7rin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "VVPP", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "verzeiht mir meiner Feld. Itzt la\u00df ich's gar wol sein,", "tokens": ["ver\u00b7zeiht", "mir", "mei\u00b7ner", "Feld", ".", "Itzt", "la\u00df", "ich's", "gar", "wol", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PIS", "ADV", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "das, was nur Ph\u00f6bus nimmt in seinen Augenschein,", "tokens": ["das", ",", "was", "nur", "Ph\u00f6\u00b7bus", "nimmt", "in", "sei\u00b7nen", "Au\u00b7gen\u00b7schein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ADV", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "das werdet ihr mit Ruhm' in kurzem haben innen.", "tokens": ["das", "wer\u00b7det", "ihr", "mit", "Ruhm'", "in", "kur\u00b7zem", "ha\u00b7ben", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "NN", "APPR", "ADJA", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der ungelehrte Belt wird euch auch lernen ehren.", "tokens": ["Der", "un\u00b7ge\u00b7lehr\u00b7te", "Belt", "wird", "euch", "auch", "ler\u00b7nen", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Kind der Barbarei, die ", "tokens": ["Das", "Kind", "der", "Bar\u00b7ba\u00b7rei", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und fleu\u00dft mit zahmer Flut die sch\u00f6ne Stadt vorbei.", "tokens": ["und", "fleu\u00dft", "mit", "zah\u00b7mer", "Flut", "die", "sch\u00f6\u00b7ne", "Stadt", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Gl\u00fcck zu, o weites Reich! Ich fahre fort zu reisen,", "tokens": ["Gl\u00fcck", "zu", ",", "o", "wei\u00b7tes", "Reich", "!", "Ich", "fah\u00b7re", "fort", "zu", "rei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "FM", "ADJA", "NN", "$.", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da\u00df ich der Mitternacht und Morgen auch mag weisen,", "tokens": ["da\u00df", "ich", "der", "Mit\u00b7ter\u00b7nacht", "und", "Mor\u00b7gen", "auch", "mag", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df, was uns Deutsche preist, auch ihnen r\u00fchmlich sei.", "tokens": ["da\u00df", ",", "was", "uns", "Deut\u00b7sche", "preist", ",", "auch", "ih\u00b7nen", "r\u00fchm\u00b7lich", "sei", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PPER", "ADJA", "NN", "$,", "ADV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich hab' euch Leid getan, ihr deutschen Kastalinnen,", "tokens": ["Ich", "hab'", "euch", "Leid", "ge\u00b7tan", ",", "ihr", "deut\u00b7schen", "Kas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "VVPP", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "o ihr mein andrer Ruhm, als ich mir bildet ein,", "tokens": ["o", "ihr", "mein", "an\u00b7drer", "Ruhm", ",", "als", "ich", "mir", "bil\u00b7det", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "PPER", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "man ehr' euch weiter nicht, als was der weise ", "tokens": ["man", "ehr'", "euch", "wei\u00b7ter", "nicht", ",", "als", "was", "der", "wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "KOUS", "PIS", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der ", "tokens": ["der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.6": {"line.1": {"text": "Ich hab' euch Leid getan, ihr edlen Pierinnen;", "tokens": ["Ich", "hab'", "euch", "Leid", "ge\u00b7tan", ",", "ihr", "ed\u00b7len", "Pie\u00b7rin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "VVPP", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "verzeiht mir meiner Feld. Itzt la\u00df ich's gar wol sein,", "tokens": ["ver\u00b7zeiht", "mir", "mei\u00b7ner", "Feld", ".", "Itzt", "la\u00df", "ich's", "gar", "wol", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PIS", "ADV", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "das, was nur Ph\u00f6bus nimmt in seinen Augenschein,", "tokens": ["das", ",", "was", "nur", "Ph\u00f6\u00b7bus", "nimmt", "in", "sei\u00b7nen", "Au\u00b7gen\u00b7schein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ADV", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "das werdet ihr mit Ruhm' in kurzem haben innen.", "tokens": ["das", "wer\u00b7det", "ihr", "mit", "Ruhm'", "in", "kur\u00b7zem", "ha\u00b7ben", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "NN", "APPR", "ADJA", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der ungelehrte Belt wird euch auch lernen ehren.", "tokens": ["Der", "un\u00b7ge\u00b7lehr\u00b7te", "Belt", "wird", "euch", "auch", "ler\u00b7nen", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Kind der Barbarei, die ", "tokens": ["Das", "Kind", "der", "Bar\u00b7ba\u00b7rei", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und fleu\u00dft mit zahmer Flut die sch\u00f6ne Stadt vorbei.", "tokens": ["und", "fleu\u00dft", "mit", "zah\u00b7mer", "Flut", "die", "sch\u00f6\u00b7ne", "Stadt", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Gl\u00fcck zu, o weites Reich! Ich fahre fort zu reisen,", "tokens": ["Gl\u00fcck", "zu", ",", "o", "wei\u00b7tes", "Reich", "!", "Ich", "fah\u00b7re", "fort", "zu", "rei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "FM", "ADJA", "NN", "$.", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da\u00df ich der Mitternacht und Morgen auch mag weisen,", "tokens": ["da\u00df", "ich", "der", "Mit\u00b7ter\u00b7nacht", "und", "Mor\u00b7gen", "auch", "mag", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df, was uns Deutsche preist, auch ihnen r\u00fchmlich sei.", "tokens": ["da\u00df", ",", "was", "uns", "Deut\u00b7sche", "preist", ",", "auch", "ih\u00b7nen", "r\u00fchm\u00b7lich", "sei", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PPER", "ADJA", "NN", "$,", "ADV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}