{"textgrid.poem.39625": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "An einen Sanskritisten", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gar mancherlei pronominale Wurzeln", "tokens": ["Gar", "man\u00b7cher\u00b7lei", "pro\u00b7no\u00b7mi\u00b7na\u00b7le", "Wur\u00b7zeln"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ergr\u00fcbelst du, aus denen nichts erw\u00e4chst;", "tokens": ["Er\u00b7gr\u00fc\u00b7belst", "du", ",", "aus", "de\u00b7nen", "nichts", "er\u00b7w\u00e4chst", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "L\u00e4\u00dfst Doppel-Apostrophe durch einander purzeln,", "tokens": ["L\u00e4\u00df\u00b7st", "Dop\u00b7pel\u00b7Apo\u00b7stro\u00b7phe", "durch", "ein\u00b7an\u00b7der", "pur\u00b7zeln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "PRF", "VVINF", "$,"], "meter": "+-+--+---+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und machst unlesbar jeden Text.", "tokens": ["Und", "machst", "un\u00b7les\u00b7bar", "je\u00b7den", "Text", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PIAT", "NN", "$."], "meter": "-++-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Grammatisch orthographische Normen,", "tokens": ["Gram\u00b7ma\u00b7tisch", "or\u00b7tho\u00b7gra\u00b7phi\u00b7sche", "Nor\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,"], "meter": "+-----+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Leer, unn\u00fctz, kleinlich, hast du aufgestellt;", "tokens": ["Leer", ",", "un\u00b7n\u00fctz", ",", "klein\u00b7lich", ",", "hast", "du", "auf\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "$,", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Du b\u00fcrstest uns die Uniformen,", "tokens": ["Du", "b\u00fcrs\u00b7test", "uns", "die", "U\u00b7nif\u00b7or\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Derweil wir r\u00fccken in das Feld.", "tokens": ["Der\u00b7weil", "wir", "r\u00fc\u00b7cken", "in", "das", "Feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gar mancherlei pronominale Wurzeln", "tokens": ["Gar", "man\u00b7cher\u00b7lei", "pro\u00b7no\u00b7mi\u00b7na\u00b7le", "Wur\u00b7zeln"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ergr\u00fcbelst du, aus denen nichts erw\u00e4chst;", "tokens": ["Er\u00b7gr\u00fc\u00b7belst", "du", ",", "aus", "de\u00b7nen", "nichts", "er\u00b7w\u00e4chst", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "L\u00e4\u00dfst Doppel-Apostrophe durch einander purzeln,", "tokens": ["L\u00e4\u00df\u00b7st", "Dop\u00b7pel\u00b7Apo\u00b7stro\u00b7phe", "durch", "ein\u00b7an\u00b7der", "pur\u00b7zeln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "PRF", "VVINF", "$,"], "meter": "+-+--+---+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und machst unlesbar jeden Text.", "tokens": ["Und", "machst", "un\u00b7les\u00b7bar", "je\u00b7den", "Text", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PIAT", "NN", "$."], "meter": "-++-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Grammatisch orthographische Normen,", "tokens": ["Gram\u00b7ma\u00b7tisch", "or\u00b7tho\u00b7gra\u00b7phi\u00b7sche", "Nor\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,"], "meter": "+-----+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Leer, unn\u00fctz, kleinlich, hast du aufgestellt;", "tokens": ["Leer", ",", "un\u00b7n\u00fctz", ",", "klein\u00b7lich", ",", "hast", "du", "auf\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "$,", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Du b\u00fcrstest uns die Uniformen,", "tokens": ["Du", "b\u00fcrs\u00b7test", "uns", "die", "U\u00b7nif\u00b7or\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Derweil wir r\u00fccken in das Feld.", "tokens": ["Der\u00b7weil", "wir", "r\u00fc\u00b7cken", "in", "das", "Feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}