{"dta.poem.20861": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der  \n Sterbende  \n  Socrates.", "genre": "Lyrik; Prosa; Drama", "period": "N.A.", "pub_year": "1679", "urn": "urn:nbn:de:kobv:b4-20289-1", "language": ["de:0.99"], "booktitle": "Hofmann von Hofmannswaldau, Christian: Deutsche Ubersetzungen und Gedichte. Breslau, 1679."}, "poem": {"stanza.1": {"line.1": {"text": "Ist euer Sinn darauf gewand/", "tokens": ["Ist", "eu\u00b7er", "Sinn", "da\u00b7rauf", "ge\u00b7wand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PAV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So zeigt das kluge Grichenland", "tokens": ["So", "zeigt", "das", "klu\u00b7ge", "Gri\u00b7chen\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gem\u00fchter/ die die Welt mit hohen Titeln lehret/", "tokens": ["Ge\u00b7m\u00fch\u00b7ter", "/", "die", "die", "Welt", "mit", "ho\u00b7hen", "Ti\u00b7teln", "leh\u00b7ret", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PRELS", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wo hier nichts zu finden ist/", "tokens": ["Und", "wo", "hier", "nichts", "zu", "fin\u00b7den", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PIS", "PTKZU", "VVINF", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So sucht die Barbarey/ was in der Fremde wohnet/", "tokens": ["So", "sucht", "die", "Bar\u00b7ba\u00b7rey", "/", "was", "in", "der", "Frem\u00b7de", "woh\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "PWS", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gedenckt ihr da\u00df aldar ihr Wonhau\u00df wird erkiest/", "tokens": ["Ge\u00b7denckt", "ihr", "da\u00df", "al\u00b7dar", "ihr", "Won\u00b7hau\u00df", "wird", "er\u00b7kiest", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "ADV", "PPOSAT", "NN", "VAFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Last euren Flei\u00df die Kr\u00e4fften zeigen/", "tokens": ["Last", "eu\u00b7ren", "Flei\u00df", "die", "Kr\u00e4ff\u00b7ten", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "In Berge/ See und Th\u00e4ler steigen/", "tokens": ["In", "Ber\u00b7ge", "/", "See", "und", "Th\u00e4\u00b7ler", "stei\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Last diese weite Welt den Zeug der Arbeit seyn;", "tokens": ["Last", "die\u00b7se", "wei\u00b7te", "Welt", "den", "Zeug", "der", "Ar\u00b7beit", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Erlernet wie man stirbt/ und wieder werde leben/", "tokens": ["Er\u00b7ler\u00b7net", "wie", "man", "stirbt", "/", "und", "wie\u00b7der", "wer\u00b7de", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "PIS", "VVFIN", "$(", "KON", "ADV", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ist euch die Seele lieb/ so lehrt auch Haut und Bein", "tokens": ["Ist", "euch", "die", "See\u00b7le", "lieb", "/", "so", "lehrt", "auch", "Haut", "und", "Bein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJD", "$(", "ADV", "VVFIN", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zu schaffen/ wo Cocit und seine Fluten schweben.", "tokens": ["Zu", "schaf\u00b7fen", "/", "wo", "Co\u00b7cit", "und", "sei\u00b7ne", "Flu\u00b7ten", "schwe\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "PWAV", "NE", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mit was ein Fremder euch auch kan entgegen gehn/", "tokens": ["Mit", "was", "ein", "Frem\u00b7der", "euch", "auch", "kan", "ent\u00b7ge\u00b7gen", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "PPER", "ADV", "VMFIN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und vor gelehrte Setze bringen/", "tokens": ["Und", "vor", "ge\u00b7lehr\u00b7te", "Set\u00b7ze", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "So last doch euren Witz nicht gantz dahinden stehn/", "tokens": ["So", "last", "doch", "eu\u00b7ren", "Witz", "nicht", "gantz", "da\u00b7hin\u00b7den", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "ADV", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bem\u00fcht euch selbst dadurch zu dringen/", "tokens": ["Be\u00b7m\u00fcht", "euch", "selbst", "da\u00b7durch", "zu", "drin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PAV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Vielleicht da\u00df in der grossen Rey/", "tokens": ["Viel\u00b7leicht", "da\u00df", "in", "der", "gros\u00b7sen", "Rey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Von denen unsre Grichen singen/", "tokens": ["Von", "de\u00b7nen", "uns\u00b7re", "Gri\u00b7chen", "sin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Nicht gar wol einer ist/ der euch zugleichen sey.", "tokens": ["Nicht", "gar", "wol", "ei\u00b7ner", "ist", "/", "der", "euch", "zu\u00b7glei\u00b7chen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "PIS", "VAFIN", "$(", "PRELS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}