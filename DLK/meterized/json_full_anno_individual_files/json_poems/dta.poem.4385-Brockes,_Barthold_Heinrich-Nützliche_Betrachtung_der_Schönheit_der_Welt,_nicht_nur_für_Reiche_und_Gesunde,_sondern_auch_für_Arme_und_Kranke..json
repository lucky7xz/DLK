{"dta.poem.4385": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "N\u00fctzliche Betrachtung  \n der  \n  Sch\u00f6nheit der Welt,  \n nicht nur  \n  f\u00fcr Reiche und Gesunde, sondern auch  \n f\u00fcr Arme und Kranke.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Geliebte Menschen, la\u00dft uns einst in unserm Leben", "tokens": ["Ge\u00b7lieb\u00b7te", "Men\u00b7schen", ",", "la\u00dft", "uns", "einst", "in", "un\u00b7serm", "Le\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "stille stehn,", "tokens": ["stil\u00b7le", "stehn", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und unsern eigentlichen Stand, beym Licht der Wahrheit,", "tokens": ["Und", "un\u00b7sern", "ei\u00b7gent\u00b7li\u00b7chen", "Stand", ",", "beym", "Licht", "der", "Wahr\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u00fcbersehn,", "tokens": ["\u00fc\u00b7ber\u00b7sehn", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Erwegen, was wir Guts besitzen, und was f\u00fcr uns der", "tokens": ["Er\u00b7we\u00b7gen", ",", "was", "wir", "Guts", "be\u00b7sit\u00b7zen", ",", "und", "was", "f\u00fcr", "uns", "der"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "PPER", "NN", "VVINF", "$,", "KON", "PWS", "APPR", "PPER", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Kreis der Welt", "tokens": ["Kreis", "der", "Welt"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "F\u00fcr ungez\u00e4hlte G\u00fcter, Wunder und unsch\u00e4tzbare Sch\u00e4tz\u2019", "tokens": ["F\u00fcr", "un\u00b7ge\u00b7z\u00e4hl\u00b7te", "G\u00fc\u00b7ter", ",", "Wun\u00b7der", "und", "un\u00b7sch\u00e4tz\u00b7ba\u00b7re", "Sch\u00e4tz'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "enth\u00e4lt,", "tokens": ["ent\u00b7h\u00e4lt", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Die alle blo\u00df f\u00fcr uns bestimmt! Wir werden, wenn wir", "tokens": ["Die", "al\u00b7le", "blo\u00df", "f\u00fcr", "uns", "be\u00b7stimmt", "!", "Wir", "wer\u00b7den", ",", "wenn", "wir"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "PIS", "ADV", "APPR", "PPER", "VVPP", "$.", "PPER", "VAFIN", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "auf der Erden", "tokens": ["auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "(aus unserm dunklen Nichts gezogen) erscheinen und", "tokens": ["(", "aus", "un\u00b7serm", "dunk\u00b7len", "Nichts", "ge\u00b7zo\u00b7gen", ")", "er\u00b7schei\u00b7nen", "und"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$(", "VVINF", "KON"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "gebohren werden,", "tokens": ["ge\u00b7boh\u00b7ren", "wer\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "In einem Pallast ja gebohren, der, so an Gr\u00f6\u00df\u2019 als Zier-", "tokens": ["In", "ei\u00b7nem", "Pal\u00b7last", "ja", "ge\u00b7boh\u00b7ren", ",", "der", ",", "so", "an", "Gr\u00f6\u00df'", "als", "Zier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVPP", "$,", "PRELS", "$,", "ADV", "APPR", "NE", "KOUS", "TRUNC"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "lichkeit,", "tokens": ["lich\u00b7keit", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Bey weitem alle \u00fcbertrift, die alle Kunst je aufgef\u00fchret.", "tokens": ["Bey", "wei\u00b7tem", "al\u00b7le", "\u00fc\u00b7bert\u00b7rift", ",", "die", "al\u00b7le", "Kunst", "je", "auf\u00b7ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PIS", "VVFIN", "$,", "PRELS", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.16": {"text": "Die Kunst ist nie so weit gekommen, sie kann auch an die", "tokens": ["Die", "Kunst", "ist", "nie", "so", "weit", "ge\u00b7kom\u00b7men", ",", "sie", "kann", "auch", "an", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "VVPP", "$,", "PPER", "VMFIN", "ADV", "APPR", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Seltenheit", "tokens": ["Sel\u00b7ten\u00b7heit"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.18": {"text": "Der bildenden Natur nicht reichen, der allezeit der Preis", "tokens": ["Der", "bil\u00b7den\u00b7den", "Na\u00b7tur", "nicht", "rei\u00b7chen", ",", "der", "al\u00b7le\u00b7zeit", "der", "Preis"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "VVINF", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.19": {"text": "geb\u00fchret.", "tokens": ["ge\u00b7b\u00fch\u00b7ret", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.20": {"text": "Das unerm\u00e4\u00dfliche Gew\u00f6lbe, der Boden- lose Stern-Altan,", "tokens": ["Das", "un\u00b7er\u00b7m\u00e4\u00df\u00b7li\u00b7che", "Ge\u00b7w\u00f6l\u00b7be", ",", "der", "Bo\u00b7den", "lo\u00b7se", "Stern\u00b7Al\u00b7tan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "TRUNC", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.21": {"text": "Zeigt diese Gr\u00f6sse, sonder gleichen, am allerdeutlichsten", "tokens": ["Zeigt", "die\u00b7se", "Gr\u00f6s\u00b7se", ",", "son\u00b7der", "glei\u00b7chen", ",", "am", "al\u00b7ler\u00b7deut\u00b7lichs\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PDAT", "NN", "$,", "KON", "ADJA", "$,", "APPRART", "ADJA"], "meter": "+--+-+-+--+-+--", "measure": "iambic.hexa.invert"}, "line.22": {"text": "uns an.", "tokens": ["uns", "an", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "Es lehrt uns die\u00df des Himmels Blau, worinn sich das", "tokens": ["Es", "lehrt", "uns", "die\u00df", "des", "Him\u00b7mels", "Blau", ",", "wo\u00b7rinn", "sich", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PDS", "ART", "NN", "NN", "$,", "PWAV", "PRF", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gesicht verlieret,", "tokens": ["Ge\u00b7sicht", "ver\u00b7lie\u00b7ret", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Wenn uns, selbst seine Dunkelheit, mit einer Art von Ehr-", "tokens": ["Wenn", "uns", ",", "selbst", "sei\u00b7ne", "Dun\u00b7kel\u00b7heit", ",", "mit", "ei\u00b7ner", "Art", "von", "Ehr"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "ADV", "PPOSAT", "NN", "$,", "APPR", "ART", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "furcht, r\u00fchret.", "tokens": ["furcht", ",", "r\u00fch\u00b7ret", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Die Sonne, die, durch ihre Ferne, wie gro\u00df sie gleich,", "tokens": ["Die", "Son\u00b7ne", ",", "die", ",", "durch", "ih\u00b7re", "Fer\u00b7ne", ",", "wie", "gro\u00df", "sie", "gleich", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "$,", "APPR", "PPOSAT", "NN", "$,", "PWAV", "ADJD", "PPER", "ADV", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "uns dennoch klein,", "tokens": ["uns", "den\u00b7noch", "klein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Durch den Betrug der Augen, scheint, h\u00f6rt nimmer auf,", "tokens": ["Durch", "den", "Be\u00b7trug", "der", "Au\u00b7gen", ",", "scheint", ",", "h\u00f6rt", "nim\u00b7mer", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "VVFIN", "$,", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "den Lebens-Schein", "tokens": ["den", "Le\u00b7bens\u00b7Schein"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "An allen Orten zu verbreiten. Die Nacht l\u00e4\u00dft, mitten", "tokens": ["An", "al\u00b7len", "Or\u00b7ten", "zu", "ver\u00b7brei\u00b7ten", ".", "Die", "Nacht", "l\u00e4\u00dft", ",", "mit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "PTKZU", "VVINF", "$.", "ART", "NN", "VVFIN", "$,", "ADV"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "in dem Dunkeln,", "tokens": ["in", "dem", "Dun\u00b7keln", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,"], "meter": "--+-", "measure": "anapaest.init"}, "line.11": {"text": "Die Stern\u2019, und zwar fast alle Wochen den Augen andre", "tokens": ["Die", "Stern'", ",", "und", "zwar", "fast", "al\u00b7le", "Wo\u00b7chen", "den", "Au\u00b7gen", "and\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "ADV", "ADV", "PIAT", "NN", "ART", "NN", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Sterne funkeln.", "tokens": ["Ster\u00b7ne", "fun\u00b7keln", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Der Tages-Wechsel macht, da\u00df wir zur Ruhe von der", "tokens": ["Der", "Ta\u00b7ges\u00b7Wech\u00b7sel", "macht", ",", "da\u00df", "wir", "zur", "Ru\u00b7he", "von", "der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NN", "APPR", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Arbeit gehn,", "tokens": ["Ar\u00b7beit", "gehn", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "Des Jahres Wechsel, da\u00df von Arbeit verschiedne Arten", "tokens": ["Des", "Jah\u00b7res", "Wech\u00b7sel", ",", "da\u00df", "von", "Ar\u00b7beit", "ver\u00b7schied\u00b7ne", "Ar\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "KOUS", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "stets geschehn.", "tokens": ["stets", "ge\u00b7schehn", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "Berufet dieses uns nun gleich zu neuen Sorgen; so ent-", "tokens": ["Be\u00b7ru\u00b7fet", "die\u00b7ses", "uns", "nun", "gleich", "zu", "neu\u00b7en", "Sor\u00b7gen", ";", "so", "ent"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PDAT", "PPER", "ADV", "ADV", "APPR", "ADJA", "NN", "$.", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.18": {"text": "stehn", "tokens": ["stehn"], "token_info": ["word"], "pos": ["VVINF"], "meter": "+", "measure": "single.up"}, "line.19": {"text": "Daraus auch neue Lieblichkeiten, Belohnungen und neuer", "tokens": ["Da\u00b7raus", "auch", "neu\u00b7e", "Lieb\u00b7lich\u00b7kei\u00b7ten", ",", "Be\u00b7loh\u00b7nun\u00b7gen", "und", "neu\u00b7er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "ADV", "ADJA", "NN", "$,", "NN", "KON", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "Segen,", "tokens": ["Se\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.21": {"text": "Worunter denn die Erde selbst, die so geschm\u00fcckt, so reich,", "tokens": ["Wo\u00b7run\u00b7ter", "denn", "die", "Er\u00b7de", "selbst", ",", "die", "so", "ge\u00b7schm\u00fcckt", ",", "so", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "ADV", "$,", "PRELS", "ADV", "VVPP", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.22": {"text": "so sch\u00f6n,", "tokens": ["so", "sch\u00f6n", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.23": {"text": "Fast ungez\u00e4hlte Seltenheiten gewohnet ist uns darzu-", "tokens": ["Fast", "un\u00b7ge\u00b7z\u00e4hl\u00b7te", "Sel\u00b7ten\u00b7hei\u00b7ten", "ge\u00b7woh\u00b7net", "ist", "uns", "dar\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVPP", "VAFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+--+--+-+", "measure": "iambic.septa.relaxed"}, "line.24": {"text": "legen.", "tokens": ["le\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.25": {"text": "Dieselbe giebt uns ihre Bluhmen, auch ihre Fr\u00fcchte,", "tokens": ["Die\u00b7sel\u00b7be", "giebt", "uns", "ih\u00b7re", "Bluh\u00b7men", ",", "auch", "ih\u00b7re", "Fr\u00fcch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Wiesen, Felder,", "tokens": ["Wie\u00b7sen", ",", "Fel\u00b7der", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.27": {"text": "Erhabne H\u00fcgel, sanfte Fl\u00e4chen, Geb\u00fcrge, Th\u00e4ler, B\u00fcsch\u2019", "tokens": ["Er\u00b7hab\u00b7ne", "H\u00fc\u00b7gel", ",", "sanf\u00b7te", "Fl\u00e4\u00b7chen", ",", "Ge\u00b7b\u00fcr\u00b7ge", ",", "Th\u00e4\u00b7ler", ",", "B\u00fcsch'"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.28": {"text": "und W\u00e4lder.", "tokens": ["und", "W\u00e4l\u00b7der", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.29": {"text": "Da sind die Wasser \u00fcberall, die sich, wie eine Schlange,", "tokens": ["Da", "sind", "die", "Was\u00b7ser", "\u00fc\u00b7be\u00b7rall", ",", "die", "sich", ",", "wie", "ei\u00b7ne", "Schlan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "$,", "PRELS", "PRF", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.30": {"text": "winden,", "tokens": ["win\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.31": {"text": "Die Erde sch\u00f6n sowohl, als fruchtbar zu machen, \u00fcberall", "tokens": ["Die", "Er\u00b7de", "sch\u00f6n", "so\u00b7wohl", ",", "als", "frucht\u00b7bar", "zu", "ma\u00b7chen", ",", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADJD", "KON", "$,", "KOUS", "ADJD", "PTKZU", "VVINF", "$,", "ADV"], "meter": "-+-+-+-++-+-+-+", "measure": "unknown.measure.octa.plus"}, "line.32": {"text": "zu finden.", "tokens": ["zu", "fin\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.3": {"line.1": {"text": "Die Jahres-Zeiten geben uns den Regen, unsre Aecker", "tokens": ["Die", "Jah\u00b7res\u00b7Zei\u00b7ten", "ge\u00b7ben", "uns", "den", "Re\u00b7gen", ",", "uns\u00b7re", "A\u00b7e\u00b7cker"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "reich,", "tokens": ["reich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Den Wind, die L\u00fcfte rein zu machen. Man sieht sie uns", "tokens": ["Den", "Wind", ",", "die", "L\u00fcf\u00b7te", "rein", "zu", "ma\u00b7chen", ".", "Man", "sieht", "sie", "uns"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$.", "PIS", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "die V\u00f6gel bringen,", "tokens": ["die", "V\u00f6\u00b7gel", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Die von so sehr verschiedner Art, und welche so verschied-", "tokens": ["Die", "von", "so", "sehr", "ver\u00b7schied\u00b7ner", "Art", ",", "und", "wel\u00b7che", "so", "ver\u00b7schie\u00b7d"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ADV", "ADV", "ADJA", "NN", "$,", "KON", "PRELS", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "lich singen.", "tokens": ["lich", "sin\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Sie liefern uns so viele Thiere, die zahmen, welche sich", "tokens": ["Sie", "lie\u00b7fern", "uns", "so", "vie\u00b7le", "Thie\u00b7re", ",", "die", "zah\u00b7men", ",", "wel\u00b7che", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,", "ART", "ADJA", "$,", "PRELS", "PRF"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "bequehmen,", "tokens": ["be\u00b7queh\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Zu unserm Nutzen, uns zur Lust, bey uns den Aufenthalt", "tokens": ["Zu", "un\u00b7serm", "Nut\u00b7zen", ",", "uns", "zur", "Lust", ",", "bey", "uns", "den", "Auf\u00b7ent\u00b7halt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPER", "APPRART", "NN", "$,", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "zu nehmen,", "tokens": ["zu", "neh\u00b7men", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Und die sich gleichsam selbst gefallen, wenn sie verrichten,", "tokens": ["Und", "die", "sich", "gleich\u00b7sam", "selbst", "ge\u00b7fal\u00b7len", ",", "wenn", "sie", "ver\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "ADJD", "ADV", "VVPP", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.12": {"text": "was wir wollen,", "tokens": ["was", "wir", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Ja gar f\u00fcr die geringe Kost, zur Dankbarkeit, sich selbst", "tokens": ["Ja", "gar", "f\u00fcr", "die", "ge\u00b7rin\u00b7ge", "Kost", ",", "zur", "Dank\u00b7bar\u00b7keit", ",", "sich", "selbst"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "ADV", "APPR", "ART", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "PRF", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.14": {"text": "uns zollen.", "tokens": ["uns", "zol\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Da sind die Thiere, die die W\u00e4lder f\u00fcr uns in solcher", "tokens": ["Da", "sind", "die", "Thie\u00b7re", ",", "die", "die", "W\u00e4l\u00b7der", "f\u00fcr", "uns", "in", "sol\u00b7cher"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN", "APPR", "PPER", "APPR", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Menge n\u00e4hren,", "tokens": ["Men\u00b7ge", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "Da sind die Fische, die die Seen, und die Gew\u00e4sser uns", "tokens": ["Da", "sind", "die", "Fi\u00b7sche", ",", "die", "die", "Seen", ",", "und", "die", "Ge\u00b7w\u00e4s\u00b7ser", "uns"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN", "$,", "KON", "ART", "NN", "PPER"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.18": {"text": "beschehren.", "tokens": ["be\u00b7scheh\u00b7ren", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.19": {"text": "Hier sind die Fl\u00fcsse, dort das Meer, in welches sie sich all\u2019", "tokens": ["Hier", "sind", "die", "Fl\u00fcs\u00b7se", ",", "dort", "das", "Meer", ",", "in", "wel\u00b7ches", "sie", "sich", "all'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "ADV", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "PIAT"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.20": {"text": "ergiessen,", "tokens": ["er\u00b7gies\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.21": {"text": "Auf welchem wir, durch Schiff\u2019 und Winde, von einem", "tokens": ["Auf", "wel\u00b7chem", "wir", ",", "durch", "Schiff'", "und", "Win\u00b7de", ",", "von", "ei\u00b7nem"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "$,", "APPR", "NN", "KON", "NN", "$,", "APPR", "ART"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Ort zum andern fliessen,", "tokens": ["Ort", "zum", "an\u00b7dern", "flies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.23": {"text": "Um neue V\u00f6lker, neue Pflanzen, auch neue Thiere, neue", "tokens": ["Um", "neu\u00b7e", "V\u00f6l\u00b7ker", ",", "neu\u00b7e", "Pflan\u00b7zen", ",", "auch", "neu\u00b7e", "Thie\u00b7re", ",", "neu\u00b7e"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUI", "ADJA", "NN", "$,", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$,", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.24": {"text": "Fr\u00fcchte,", "tokens": ["Fr\u00fcch\u00b7te", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.25": {"text": "Nicht minder neue Heilungs-Mittel, manch neuen Vor-", "tokens": ["Nicht", "min\u00b7der", "neu\u00b7e", "Hei\u00b7lungs\u00b7Mit\u00b7tel", ",", "manch", "neu\u00b7en", "Vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ADJA", "NN", "$,", "PIAT", "ADJA", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "wurf dem Gesichte,", "tokens": ["wurf", "dem", "Ge\u00b7sich\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.27": {"text": "Auch f\u00fcr der Menschen andre Sinnen, viel\u2019 neue Sch\u00e4tze", "tokens": ["Auch", "f\u00fcr", "der", "Men\u00b7schen", "and\u00b7re", "Sin\u00b7nen", ",", "viel'", "neu\u00b7e", "Sch\u00e4t\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "zu erhalten,", "tokens": ["zu", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.29": {"text": "Und sie, auf ungez\u00e4hlte Arten, zu unserm Nutzen zu ver-", "tokens": ["Und", "sie", ",", "auf", "un\u00b7ge\u00b7z\u00e4hl\u00b7te", "Ar\u00b7ten", ",", "zu", "un\u00b7serm", "Nut\u00b7zen", "zu", "ver"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.30": {"text": "walten.", "tokens": ["wal\u00b7ten", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.31": {"text": "Wenn ich, mit einem Ueberlegen, bey dieser Menge stille", "tokens": ["Wenn", "ich", ",", "mit", "ei\u00b7nem", "Ue\u00b7ber\u00b7le\u00b7gen", ",", "bey", "die\u00b7ser", "Men\u00b7ge", "stil\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "NN", "$,", "APPR", "PDAT", "NN", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.32": {"text": "steh,", "tokens": ["steh", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Und, wie sie uns des Sch\u00f6pfers Hand, in solcher F\u00fclle,", "tokens": ["Und", ",", "wie", "sie", "uns", "des", "Sch\u00f6p\u00b7fers", "Hand", ",", "in", "sol\u00b7cher", "F\u00fcl\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "PRF", "ART", "NN", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "giebet, seh,", "tokens": ["gie\u00b7bet", ",", "seh", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Derselben Vielheit immer gr\u00f6sser, die Sch\u00f6nheit immer", "tokens": ["Der\u00b7sel\u00b7ben", "Viel\u00b7heit", "im\u00b7mer", "gr\u00f6s\u00b7ser", ",", "die", "Sch\u00f6n\u00b7heit", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "NN", "ADV", "ADJD", "$,", "ART", "NN", "ADV"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "sch\u00f6ner finde;", "tokens": ["sch\u00f6\u00b7ner", "fin\u00b7de", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "So kommt es mir nicht anders vor, als wenn auf einem", "tokens": ["So", "kommt", "es", "mir", "nicht", "an\u00b7ders", "vor", ",", "als", "wenn", "auf", "ei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "ADV", "PTKVZ", "$,", "KOKOM", "KOUS", "APPR", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "jeden st\u00fcnde:", "tokens": ["je\u00b7den", "st\u00fcn\u00b7de", ":"], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "ADJA", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "\u201co Mensch, f\u00fcr dich geh\u00f6ret alles! Komm, schlacht\u2019,", "tokens": ["\u201c", "o", "Mensch", ",", "f\u00fcr", "dich", "ge\u00b7h\u00f6\u00b7ret", "al\u00b7les", "!", "Komm", ",", "schlacht'", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "APPR", "PPER", "VVFIN", "PIS", "$.", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und i\u00df, und sey vergn\u00fcgt!", "tokens": ["und", "i\u00df", ",", "und", "sey", "ver\u00b7gn\u00fcgt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Wozu sich denn noch diese Lehre, die gleichfalls \u00fcberzeug-", "tokens": ["Wo\u00b7zu", "sich", "denn", "noch", "die\u00b7se", "Leh\u00b7re", ",", "die", "gleich\u00b7falls", "\u00fc\u00b7ber\u00b7zeug"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PRF", "ADV", "ADV", "PDAT", "NN", "$,", "PRELS", "ADV", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "lich, f\u00fcgt:", "tokens": ["lich", ",", "f\u00fcgt", ":"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "\u201eder Sch\u00f6pfer, welcher nichts bedarf, hat aller G\u00fcte", "tokens": ["\u201e", "der", "Sch\u00f6p\u00b7fer", ",", "wel\u00b7cher", "nichts", "be\u00b7darf", ",", "hat", "al\u00b7ler", "G\u00fc\u00b7te"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nutz und Pracht", "tokens": ["Nutz", "und", "Pracht"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "\u201ezu Seinem eignen Nutzen nicht, zu deinem blo\u00df,", "tokens": ["\u201e", "zu", "Sei\u00b7nem", "eig\u00b7nen", "Nut\u00b7zen", "nicht", ",", "zu", "dei\u00b7nem", "blo\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "PTKNEG", "$,", "APPR", "PPOSAT", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "hervorgebracht.", "tokens": ["her\u00b7vor\u00b7ge\u00b7bracht", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "So machet euch doch selber gl\u00fccklich, bringt eure Zeiten", "tokens": ["So", "ma\u00b7chet", "euch", "doch", "sel\u00b7ber", "gl\u00fcck\u00b7lich", ",", "bringt", "eu\u00b7re", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "im Vergn\u00fcgen,", "tokens": ["im", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "Und eure Tag\u2019 in Anmuht zu, sucht allen Unmuht zu be-", "tokens": ["Und", "eu\u00b7re", "Tag'", "in", "An\u00b7muht", "zu", ",", "sucht", "al\u00b7len", "Un\u00b7muht", "zu", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$,", "VVFIN", "PIAT", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.18": {"text": "siegen!", "tokens": ["sie\u00b7gen", "!"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "Kommt, folgt der Stimme der Natur und ihrem wohlge-", "tokens": ["Kommt", ",", "folgt", "der", "Stim\u00b7me", "der", "Na\u00b7tur", "und", "ih\u00b7rem", "wohl\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "ART", "NN", "ART", "NN", "KON", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "meynten Raht,", "tokens": ["meyn\u00b7ten", "Raht", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.21": {"text": "Da GOtt ja Seinen Tisch f\u00fcr euch so herrlich zubereitet", "tokens": ["Da", "Gott", "ja", "Sei\u00b7nen", "Tisch", "f\u00fcr", "euch", "so", "herr\u00b7lich", "zu\u00b7be\u00b7rei\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADV", "PPOSAT", "NN", "APPR", "PPER", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.22": {"text": "hat,", "tokens": ["hat", ","], "token_info": ["word", "punct"], "pos": ["VAFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.23": {"text": "Indem die aufgesetzten Sch\u00e4tze selbst scheinen dazu einzu-", "tokens": ["In\u00b7dem", "die", "auf\u00b7ge\u00b7setz\u00b7ten", "Sch\u00e4t\u00b7ze", "selbst", "schei\u00b7nen", "da\u00b7zu", "ein\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "VVFIN", "PAV", "TRUNC"], "meter": "-+-+-+-+--+--+--", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "laden!", "tokens": ["la\u00b7den", "!"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.25": {"text": "Beweiset eure Dankbarkeit durch die Begierden, Seiner", "tokens": ["Be\u00b7wei\u00b7set", "eu\u00b7re", "Dank\u00b7bar\u00b7keit", "durch", "die", "Be\u00b7gier\u00b7den", ",", "Sei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,", "PPOSAT"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.26": {"text": "Gnaden", "tokens": ["Gna\u00b7den"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.27": {"text": "Bezeugungen recht zu geniessen. In unsern Herzen selber", "tokens": ["Be\u00b7zeu\u00b7gun\u00b7gen", "recht", "zu", "ge\u00b7nies\u00b7sen", ".", "In", "un\u00b7sern", "Her\u00b7zen", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "PTKZU", "VVINF", "$.", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.28": {"text": "liegt", "tokens": ["liegt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.29": {"text": "Ein Grund, der diese Stimme h\u00f6rt, und, gleichsam selbst", "tokens": ["Ein", "Grund", ",", "der", "die\u00b7se", "Stim\u00b7me", "h\u00f6rt", ",", "und", ",", "gleich\u00b7sam", "selbst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PDAT", "NN", "VVFIN", "$,", "KON", "$,", "ADJD", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "dadurch vergn\u00fcgt,", "tokens": ["da\u00b7durch", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.31": {"text": "Darauf ein\u2019 Art von Echo giebt. Ein Trieb, der nimmer", "tokens": ["Da\u00b7rauf", "ein'", "Art", "von", "E\u00b7cho", "giebt", ".", "Ein", "Trieb", ",", "der", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PAV", "ART", "NN", "APPR", "NN", "VVFIN", "$.", "ART", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "zu besiegen,", "tokens": ["zu", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Und ein\u2019 in uns verborgne Neigung reizt unaufh\u00f6rlich", "tokens": ["Und", "ein'", "in", "uns", "ver\u00b7borg\u00b7ne", "Nei\u00b7gung", "reizt", "un\u00b7auf\u00b7h\u00f6r\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPR", "PPER", "ADJA", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+--++--", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "zum Vergn\u00fcgen,", "tokens": ["zum", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Und treibt uns, uns begl\u00fcckt zu machen. Uns lockt, was", "tokens": ["Und", "treibt", "uns", ",", "uns", "be\u00b7gl\u00fcckt", "zu", "ma\u00b7chen", ".", "Uns", "lockt", ",", "was"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VVPP", "PTKZU", "VVINF", "$.", "PPER", "VVFIN", "$,", "PWS"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.4": {"text": "wir von aussen sehn,", "tokens": ["wir", "von", "aus\u00b7sen", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "VVINF", "VVINF", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Und auch was in uns ist, dazu. Woher mu\u00df es denn", "tokens": ["Und", "auch", "was", "in", "uns", "ist", ",", "da\u00b7zu", ".", "Wo\u00b7her", "mu\u00df", "es", "denn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PWS", "APPR", "PPER", "VAFIN", "$,", "PAV", "$.", "PWAV", "VMFIN", "PPER", "ADV"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "doch entstehn,", "tokens": ["doch", "ent\u00b7stehn", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Da\u00df wir, in so begl\u00fccktem Stande, dennoch so ungl\u00fcckselig", "tokens": ["Da\u00df", "wir", ",", "in", "so", "be\u00b7gl\u00fcck\u00b7tem", "Stan\u00b7de", ",", "den\u00b7noch", "so", "un\u00b7gl\u00fcck\u00b7se\u00b7lig"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "ADV", "ADJA", "NN", "$,", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "leben?", "tokens": ["le\u00b7ben", "?"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Woher? weil wir auf alles Gute, was in der Welt, nicht", "tokens": ["Wo\u00b7her", "?", "weil", "wir", "auf", "al\u00b7les", "Gu\u00b7te", ",", "was", "in", "der", "Welt", ",", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "$.", "KOUS", "PPER", "APPR", "PIAT", "NN", "$,", "PRELS", "APPR", "ART", "NN", "$,", "PTKNEG"], "meter": "-+--++-+--+-++", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "Achtung geben,", "tokens": ["Ach\u00b7tung", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "Stets mehr noch zu verdienen glauben, nur das verlangen,", "tokens": ["Stets", "mehr", "noch", "zu", "ver\u00b7die\u00b7nen", "glau\u00b7ben", ",", "nur", "das", "ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PTKZU", "VVINF", "VVINF", "$,", "ADV", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "was uns fehlt,", "tokens": ["was", "uns", "fehlt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Und wenn wir es erlanget haben, von immer neuer Sucht", "tokens": ["Und", "wenn", "wir", "es", "er\u00b7lan\u00b7get", "ha\u00b7ben", ",", "von", "im\u00b7mer", "neu\u00b7er", "Sucht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVFIN", "VAINF", "$,", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "gequ\u00e4lt,", "tokens": ["ge\u00b7qu\u00e4lt", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Den Blick von dem erlangten ab, und immer zum entfern-", "tokens": ["Den", "Blick", "von", "dem", "er\u00b7lang\u00b7ten", "ab", ",", "und", "im\u00b7mer", "zum", "ent\u00b7fern"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "VVFIN", "PTKVZ", "$,", "KON", "ADV", "APPRART", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.16": {"text": "ten kehren,", "tokens": ["ten", "keh\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["FM", "VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.17": {"text": "Stets mit phantastischen Gerichten, mit wirklichen uns", "tokens": ["Stets", "mit", "phan\u00b7tas\u00b7ti\u00b7schen", "Ge\u00b7rich\u00b7ten", ",", "mit", "wirk\u00b7li\u00b7chen", "uns"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "PPER"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "nimmer n\u00e4hren.", "tokens": ["nim\u00b7mer", "n\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.19": {"text": "So lange man, auf diese Weise, mit dem bese\u00dfnen Gut", "tokens": ["So", "lan\u00b7ge", "man", ",", "auf", "die\u00b7se", "Wei\u00b7se", ",", "mit", "dem", "be\u00b7se\u00df\u00b7nen", "Gut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "$,", "APPR", "PDAT", "NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "verf\u00e4hrt,", "tokens": ["ver\u00b7f\u00e4hrt", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.21": {"text": "Und w\u00e4r uns noch einmahl so viel, ja tausend mahl", "tokens": ["Und", "w\u00e4r", "uns", "noch", "ein\u00b7mahl", "so", "viel", ",", "ja", "tau\u00b7send", "mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "$,", "ADV", "CARD", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "so viel, beschehrt;", "tokens": ["so", "viel", ",", "be\u00b7schehrt", ";"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "$,", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.23": {"text": "So w\u00fcrd\u2019 uns Unlust, Kummer, Gram und Unzufriedenheit", "tokens": ["So", "w\u00fcrd'", "uns", "Un\u00b7lust", ",", "Kum\u00b7mer", ",", "Gram", "und", "Un\u00b7zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.24": {"text": "beschwehren,", "tokens": ["be\u00b7schweh\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.25": {"text": "Wenn wir in der Eliser Auen, ja selbst im Paradiese w\u00e4ren.", "tokens": ["Wenn", "wir", "in", "der", "E\u00b7li\u00b7ser", "Au\u00b7en", ",", "ja", "selbst", "im", "Pa\u00b7ra\u00b7die\u00b7se", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "APPRART", "NN", "VAFIN", "$."], "meter": "-+--+--++-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.6": {"line.1": {"text": "Wie j\u00fcngst der arme ", "tokens": ["Wie", "j\u00fcngst", "der", "ar\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Der voller Pein zu Bette lage, da jener vor dem Bette sa\u00df,", "tokens": ["Der", "vol\u00b7ler", "Pein", "zu", "Bet\u00b7te", "la\u00b7ge", ",", "da", "je\u00b7ner", "vor", "dem", "Bet\u00b7te", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "$,", "KOUS", "PDAT", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Die\u00df sonst ermunternde Gedicht, mit Thr\u00e4nen in den Augen,", "tokens": ["Die\u00df", "sonst", "er\u00b7mun\u00b7tern\u00b7de", "Ge\u00b7dicht", ",", "mit", "Thr\u00e4\u00b7nen", "in", "den", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJA", "NN", "$,", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "las;", "tokens": ["las", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.7": {"line.1": {"text": "Erseufzeten sie alle beyde. Ach! fing zuerst der sieche Mann,", "tokens": ["Er\u00b7seuf\u00b7ze\u00b7ten", "sie", "al\u00b7le", "bey\u00b7de", ".", "Ach", "!", "fing", "zu\u00b7erst", "der", "sie\u00b7che", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "PIS", "$.", "ITJ", "$.", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+---+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Nachdem er sich herumgeworfen, mit unterbrochnem", "tokens": ["Nach\u00b7dem", "er", "sich", "her\u00b7um\u00b7ge\u00b7wor\u00b7fen", ",", "mit", "un\u00b7ter\u00b7broch\u00b7nem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "$,", "APPR", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Schluchzen an:", "tokens": ["Schluch\u00b7zen", "an", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "\u201cwas hilft mir Armen dieser Trost? Was n\u00fctzen mir der", "tokens": ["\u201c", "was", "hilft", "mir", "Ar\u00b7men", "die\u00b7ser", "Trost", "?", "Was", "n\u00fct\u00b7zen", "mir", "der"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWS", "VVFIN", "PPER", "NN", "PDAT", "NN", "$.", "PWS", "VVFIN", "PPER", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erden Sch\u00e4tze?", "tokens": ["Er\u00b7den", "Sch\u00e4t\u00b7ze", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "\u201eda ich, ohn\u2019 ihrer zu geniessen, mein Lager stets mit", "tokens": ["\u201e", "da", "ich", ",", "ohn'", "ih\u00b7rer", "zu", "ge\u00b7nies\u00b7sen", ",", "mein", "La\u00b7ger", "stets", "mit"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "$,", "KOUI", "PPOSAT", "PTKZU", "VVINF", "$,", "PPOSAT", "NN", "ADV", "APPR"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Thr\u00e4nen netze,", "tokens": ["Thr\u00e4\u00b7nen", "net\u00b7ze", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "\u201eda mich der Nieren-Stein zerfoltert, die Gicht die Sehnen", "tokens": ["\u201e", "da", "mich", "der", "Nie\u00b7ren\u00b7Stein", "zer\u00b7fol\u00b7tert", ",", "die", "Gicht", "die", "Seh\u00b7nen"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$,", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "dehnt und nagt,", "tokens": ["dehnt", "und", "nagt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "\u201eund mich nicht nur den ganzen Tag, die noch viel l\u00e4ngere", "tokens": ["\u201e", "und", "mich", "nicht", "nur", "den", "gan\u00b7zen", "Tag", ",", "die", "noch", "viel", "l\u00e4n\u00b7ge\u00b7re"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.11": {"text": "Nacht, zerplagt.", "tokens": ["Nacht", ",", "zer\u00b7plagt", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "\u201emich labt kein Trank, mir schmeckt kein Essen, und kurz: Auf", "tokens": ["\u201e", "mich", "labt", "kein", "Trank", ",", "mir", "schmeckt", "kein", "Es\u00b7sen", ",", "und", "kurz", ":", "Auf"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "$,", "PPER", "VVFIN", "PIAT", "NN", "$,", "KON", "ADJD", "$.", "APPR"], "meter": "-+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.13": {"text": "dieser ganzen Welt", "tokens": ["die\u00b7ser", "gan\u00b7zen", "Welt"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "\u201evergn\u00fcget mich von allen nichts. Nichts ist darinn, was", "tokens": ["\u201e", "ver\u00b7gn\u00fc\u00b7get", "mich", "von", "al\u00b7len", "nichts", ".", "Nichts", "ist", "da\u00b7rinn", ",", "was"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["$(", "VVFIN", "PRF", "APPR", "PIAT", "PIS", "$.", "PIS", "VAFIN", "PAV", "$,", "PWS"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "mir gef\u00e4llt.", "tokens": ["mir", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Kaum schwieg er, als auch ", "tokens": ["Kaum", "schwieg", "er", ",", "als", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Wangen wischte,", "tokens": ["Wan\u00b7gen", "wischte", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und mit des Kranken bittren Klagen auch sein betr\u00fcbtes", "tokens": ["Und", "mit", "des", "Kran\u00b7ken", "bit\u00b7tren", "Kla\u00b7gen", "auch", "sein", "be\u00b7tr\u00fcb\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN", "ADV", "PPOSAT", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Klaglied mischte:", "tokens": ["Klag\u00b7lied", "mischte", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.5": {"text": "\u201cer schreibt: Die Welt ist voller Sch\u00e4tze. Ja Sch\u00e4tze, da\u00df", "tokens": ["\u201c", "er", "schreibt", ":", "Die", "Welt", "ist", "vol\u00b7ler", "Sch\u00e4t\u00b7ze", ".", "Ja", "Sch\u00e4t\u00b7ze", ",", "da\u00df"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["$(", "PPER", "VVFIN", "$.", "ART", "NN", "VAFIN", "ADJA", "NN", "$.", "PTKANT", "NN", "$,", "KOUS"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "es GOtt erbarm!", "tokens": ["es", "Gott", "er\u00b7barm", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "\u201esind nicht, bey dem ger\u00fchmten Reichthum so viel\u2019, und", "tokens": ["\u201e", "sind", "nicht", ",", "bey", "dem", "ge\u00b7r\u00fchm\u00b7ten", "Reicht\u00b7hum", "so", "viel'", ",", "und"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["$(", "VAFIN", "PTKNEG", "$,", "APPR", "ART", "ADJA", "NN", "ADV", "ADV", "$,", "KON"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "ich besonders, arm?", "tokens": ["ich", "be\u00b7son\u00b7ders", ",", "arm", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "\u201eer schreibt: F\u00fcr uns soll alles seyn. Ja wohl f\u00fcr uns.", "tokens": ["\u201e", "er", "schreibt", ":", "F\u00fcr", "uns", "soll", "al\u00b7les", "seyn", ".", "Ja", "wohl", "f\u00fcr", "uns", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$.", "APPR", "PPER", "VMFIN", "PIS", "VAINF", "$.", "PTKANT", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Hat einer Mittel,", "tokens": ["Hat", "ei\u00b7ner", "Mit\u00b7tel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "\u201eso decken so viel tausend andre sich kaum mit einem alten", "tokens": ["\u201e", "so", "de\u00b7cken", "so", "viel", "tau\u00b7send", "and\u00b7re", "sich", "kaum", "mit", "ei\u00b7nem", "al\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "ADV", "ADV", "CARD", "PIS", "PRF", "ADV", "APPR", "ART", "ADJA"], "meter": "-+---+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Kittel.", "tokens": ["Kit\u00b7tel", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "\u201ebey dem ger\u00fchmten Ueberflu\u00df hab ich kaum mein erschwitz-", "tokens": ["\u201e", "bey", "dem", "ge\u00b7r\u00fchm\u00b7ten", "Ue\u00b7berf\u00b7lu\u00df", "hab", "ich", "kaum", "mein", "er\u00b7schwitz"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.14": {"text": "tes Brodt,", "tokens": ["tes", "Brodt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "\u201eund meine Kinder schmachten oft, gequ\u00e4lt von bittrer", "tokens": ["\u201e", "und", "mei\u00b7ne", "Kin\u00b7der", "schmach\u00b7ten", "oft", ",", "ge\u00b7qu\u00e4lt", "von", "bit\u00b7trer"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "PPOSAT", "NN", "VVFIN", "ADV", "$,", "VVPP", "APPR", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Hungers-Noht.", "tokens": ["Hun\u00b7ger\u00b7sNoht", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "\u201ewenn der, so die\u00df Gedicht geschrieben, in unsrer Stelle w\u00e4r", "tokens": ["\u201e", "wenn", "der", ",", "so", "die\u00df", "Ge\u00b7dicht", "ge\u00b7schrie\u00b7ben", ",", "in", "uns\u00b7rer", "Stel\u00b7le", "w\u00e4r"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "ART", "$,", "ADV", "PDS", "NN", "VVPP", "$,", "APPR", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "gewesen,", "tokens": ["ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VAPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "\u201eer g\u00e4b uns von der Lust der Welt so viel vergn\u00fcglichs nicht", "tokens": ["\u201e", "er", "g\u00e4b", "uns", "von", "der", "Lust", "der", "Welt", "so", "viel", "ver\u00b7gn\u00fcg\u00b7lichs", "nicht"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "ADV", "ADV", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "zu lesen.", "tokens": ["zu", "le\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Mirander h\u00f6rte beydes an, der eben in die Stube tratt,", "tokens": ["Mi\u00b7ran\u00b7der", "h\u00f6r\u00b7te", "bey\u00b7des", "an", ",", "der", "e\u00b7ben", "in", "die", "Stu\u00b7be", "tratt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "PTKVZ", "$,", "PRELS", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.6": {"text": "Und wie er das von allen beyden ihm eben dargereichte", "tokens": ["Und", "wie", "er", "das", "von", "al\u00b7len", "bey\u00b7den", "ihm", "e\u00b7ben", "dar\u00b7ge\u00b7reich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ART", "APPR", "PIAT", "PIS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Blatt", "tokens": ["Blatt"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Mit Flei\u00df bed\u00e4chtlich durchgelesen; so fragt er erstlich", "tokens": ["Mit", "Flei\u00df", "be\u00b7d\u00e4cht\u00b7lich", "durch\u00b7ge\u00b7le\u00b7sen", ";", "so", "fragt", "er", "erst\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$.", "ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "alle beyde,", "tokens": ["al\u00b7le", "bey\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "PIS", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Nach dem vorher bezeugten Schmerz und Beyleid \u00fcber", "tokens": ["Nach", "dem", "vor\u00b7her", "be\u00b7zeug\u00b7ten", "Schmerz", "und", "Bey\u00b7leid", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "KON", "NN", "APPR"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.11": {"text": "ihrem Leide,", "tokens": ["ih\u00b7rem", "Lei\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.12": {"text": "Mit der ihm eignen sanften Art: Ob das, was in den", "tokens": ["Mit", "der", "ihm", "eig\u00b7nen", "sanf\u00b7ten", "Art", ":", "Ob", "das", ",", "was", "in", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADJA", "ADJA", "NN", "$.", "KOUS", "PDS", "$,", "PRELS", "APPR", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Versen st\u00fcnde,", "tokens": ["Ver\u00b7sen", "st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.14": {"text": "Sich in der That nicht so verhielt\u2019, und sich nicht in der", "tokens": ["Sich", "in", "der", "That", "nicht", "so", "ver\u00b7hielt'", ",", "und", "sich", "nicht", "in", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "NN", "PTKNEG", "ADV", "VVFIN", "$,", "KON", "PRF", "PTKNEG", "APPR", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Welt bef\u00fcnde?", "tokens": ["Welt", "be\u00b7f\u00fcn\u00b7de", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.16": {"text": "Die\u00df stunden sie ihm beydes zu. Da ihr nun die\u00df nicht", "tokens": ["Die\u00df", "stun\u00b7den", "sie", "ihm", "bey\u00b7des", "zu", ".", "Da", "ihr", "nun", "die\u00df", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "PIS", "PTKVZ", "$.", "KOUS", "PPER", "ADV", "PDS", "PTKNEG"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "leugnen k\u00f6nnt,", "tokens": ["leug\u00b7nen", "k\u00f6nnt", ","], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.18": {"text": "Fuhr hier ", "tokens": ["Fuhr", "hier"], "token_info": ["word", "word"], "pos": ["VVFIN", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "nur verg\u00f6nnt,", "tokens": ["nur", "ver\u00b7g\u00f6nnt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "Der hier die Welt so sch\u00f6n beschrieben, so sch\u00f6n dieselbe", "tokens": ["Der", "hier", "die", "Welt", "so", "sch\u00f6n", "be\u00b7schrie\u00b7ben", ",", "so", "sch\u00f6n", "die\u00b7sel\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADV", "ADJD", "VVPP", "$,", "ADV", "ADJD", "PDAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "zu beschreiben,", "tokens": ["zu", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.22": {"text": "Es war dasselbe seine Pflicht. Und werdet ihr so billig", "tokens": ["Es", "war", "das\u00b7sel\u00b7be", "sei\u00b7ne", "Pflicht", ".", "Und", "wer\u00b7det", "ihr", "so", "bil\u00b7lig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "PPOSAT", "NN", "$.", "KON", "VAFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.23": {"text": "seyn,", "tokens": ["seyn", ","], "token_info": ["word", "punct"], "pos": ["VAINF", "$,"], "meter": "+", "measure": "single.up"}, "line.24": {"text": "Die Wahrheit ihm nicht zu ver\u00fcbeln. Doch um nun auch", "tokens": ["Die", "Wahr\u00b7heit", "ihm", "nicht", "zu", "ver\u00b7\u00fc\u00b7beln", ".", "Doch", "um", "nun", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$.", "KON", "KOUI", "ADV", "ADV"], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.25": {"text": "bey euch zu bleiben,", "tokens": ["bey", "euch", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.26": {"text": "Die ihr, die Erde sch\u00f6n zu finden, durch Armuht und durch", "tokens": ["Die", "ihr", ",", "die", "Er\u00b7de", "sch\u00f6n", "zu", "fin\u00b7den", ",", "durch", "Ar\u00b7muht", "und", "durch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,", "APPR", "NN", "KON", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.27": {"text": "bittre Pein,", "tokens": ["bitt\u00b7re", "Pein", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.28": {"text": "Betr\u00fcbt genug, behindert seyd; so la\u00dft uns erst die D\u00fcrf-", "tokens": ["Be\u00b7tr\u00fcbt", "ge\u00b7nug", ",", "be\u00b7hin\u00b7dert", "seyd", ";", "so", "la\u00dft", "uns", "erst", "die", "D\u00fcr\u00b7f"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "VVPP", "VAFIN", "$.", "ADV", "VVIMP", "PPER", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.29": {"text": "tigkeit,", "tokens": ["tig\u00b7keit", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.30": {"text": "Und ob sie, nach der Welt und Menschen geordneten Be-", "tokens": ["Und", "ob", "sie", ",", "nach", "der", "Welt", "und", "Men\u00b7schen", "ge\u00b7ord\u00b7ne\u00b7ten", "Be"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "$,", "APPR", "ART", "NN", "KON", "NN", "ADJA", "TRUNC"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "schaffenheit,", "tokens": ["schaf\u00b7fen\u00b7heit", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Nicht hier auf Erden n\u00f6htig sey, mit einigem Bedacht", "tokens": ["Nicht", "hier", "auf", "Er\u00b7den", "n\u00f6h\u00b7tig", "sey", ",", "mit", "ei\u00b7ni\u00b7gem", "Be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "ADJD", "VAFIN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "ergr\u00fcnden,", "tokens": ["er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Es m\u00f6gte sich vielleicht f\u00fcr dich ein Trost in deiner Armuht", "tokens": ["Es", "m\u00f6g\u00b7te", "sich", "viel\u00b7leicht", "f\u00fcr", "dich", "ein", "Trost", "in", "dei\u00b7ner", "Ar\u00b7muht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPR", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "finden.", "tokens": ["fin\u00b7den", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "(", "tokens": ["("], "token_info": ["punct"], "pos": ["$("]}, "line.6": {"text": "scheid wohl n\u00f6htig sey,", "tokens": ["scheid", "wohl", "n\u00f6h\u00b7tig", "sey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "\u201edas wei\u00df ich ja sowohl, als du. Von dem Beweisthum", "tokens": ["\u201e", "das", "wei\u00df", "ich", "ja", "so\u00b7wohl", ",", "als", "du", ".", "Von", "dem", "Be\u00b7wei\u00b7sthum"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VVFIN", "PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "$.", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "bist du frey.", "tokens": ["bist", "du", "frey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Allein die\u00df Wissen s\u00e4ttigt nicht. (", "tokens": ["Al\u00b7lein", "die\u00df", "Wis\u00b7sen", "s\u00e4t\u00b7tigt", "nicht", ".", "("], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PDS", "NN", "VVFIN", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "es auch nicht hungriger,", "tokens": ["es", "auch", "nicht", "hung\u00b7ri\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und da, bey deiner D\u00fcrftigkeit und deinem Leiden, GOtt", "tokens": ["Und", "da", ",", "bey", "dei\u00b7ner", "D\u00fcrf\u00b7tig\u00b7keit", "und", "dei\u00b7nem", "Lei\u00b7den", ",", "Gott"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "$,", "APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.12": {"text": "der HErr", "tokens": ["der", "Herr"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.13": {"text": "Dir dennoch den Verstand gelassen, der ja von allen an-", "tokens": ["Dir", "den\u00b7noch", "den", "Ver\u00b7stand", "ge\u00b7las\u00b7sen", ",", "der", "ja", "von", "al\u00b7len", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "NN", "VVPP", "$,", "PRELS", "ADV", "APPR", "PIAT", "TRUNC"], "meter": "+-+--+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.14": {"text": "dern Gaben,", "tokens": ["dern", "Ga\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Die wir von unsers Sch\u00f6pfers G\u00fcte auf dieser Welt er-", "tokens": ["Die", "wir", "von", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "G\u00fc\u00b7te", "auf", "die\u00b7ser", "Welt", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "NN", "APPR", "PDAT", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "halten haben,", "tokens": ["hal\u00b7ten", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VAFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "Unstreitig ja die allerbeste; so wend\u2019 ihn denn auch dazu", "tokens": ["Un\u00b7strei\u00b7tig", "ja", "die", "al\u00b7ler\u00b7bes\u00b7te", ";", "so", "wend'", "ihn", "denn", "auch", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "ART", "ADJA", "$.", "ADV", "KOUS", "PPER", "ADV", "ADV", "PAV"], "meter": "+--+-+-+--+--+-+", "measure": "iambic.septa.invert"}, "line.18": {"text": "an,", "tokens": ["an", ","], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$,"], "meter": "+", "measure": "single.up"}, "line.19": {"text": "Da\u00df er dir auch zum Besten diene, so wie er es wahr-", "tokens": ["Da\u00df", "er", "dir", "auch", "zum", "Bes\u00b7ten", "die\u00b7ne", ",", "so", "wie", "er", "es", "wahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,", "ADV", "KOKOM", "PPER", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.20": {"text": "haftig kann.", "tokens": ["haf\u00b7tig", "kann", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VMFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}