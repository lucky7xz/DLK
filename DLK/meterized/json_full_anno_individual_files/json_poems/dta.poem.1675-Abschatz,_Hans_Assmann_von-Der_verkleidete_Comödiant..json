{"dta.poem.1675": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der verkleidete Com\u00f6diant.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Kund und zuwissen sey der Compagnie gethan/ ", "tokens": ["Kund", "und", "zu\u00b7wis\u00b7sen", "sey", "der", "Com\u00b7pag\u00b7nie", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier kommt ein neues Paar Com\u00f6dianten an.", "tokens": ["Hier", "kommt", "ein", "neu\u00b7es", "Paar", "Co\u00b7m\u00f6\u00b7di\u00b7an\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich der Com\u00f6diant bin Edel zu erkennen", "tokens": ["Ich", "der", "Co\u00b7m\u00f6\u00b7di\u00b7ant", "bin", "E\u00b7del", "zu", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "VAFIN", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und darff manch hohes Hau\u00df der Anglen V\u00e4tter nennen.", "tokens": ["Und", "darff", "manch", "ho\u00b7hes", "Hau\u00df", "der", "Ang\u00b7len", "V\u00e4t\u00b7ter", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Mich hat das falsche Recht zu dieser Nahrung bracht/", "tokens": ["Mich", "hat", "das", "fal\u00b7sche", "Recht", "zu", "die\u00b7ser", "Nah\u00b7rung", "bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das meinen Bruder reich und mich zum Bettler macht.", "tokens": ["Das", "mei\u00b7nen", "Bru\u00b7der", "reich", "und", "mich", "zum", "Bett\u00b7ler", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADJD", "KON", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch mag er/ wie er will/ mit seinen G\u00fcttern prangen/", "tokens": ["Doch", "mag", "er", "/", "wie", "er", "will", "/", "mit", "sei\u00b7nen", "G\u00fct\u00b7tern", "pran\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$(", "PWAV", "PPER", "VMFIN", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich kan/ was er niemahls/ in einer Stund erlangen.", "tokens": ["Ich", "kan", "/", "was", "er", "nie\u00b7mahls", "/", "in", "ei\u00b7ner", "Stund", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$(", "PWS", "PPER", "ADV", "$(", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Der g\u00f6ldne K\u00f6nigs-Stab/ die Kronen sind mein Spiel/", "tokens": ["Der", "g\u00f6ld\u00b7ne", "K\u00f6\u00b7nigs\u00b7Stab", "/", "die", "Kro\u00b7nen", "sind", "mein", "Spiel", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich trag und lege sie hinweg/ so offt ich will.", "tokens": ["Ich", "trag", "und", "le\u00b7ge", "sie", "hin\u00b7weg", "/", "so", "offt", "ich", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$(", "ADV", "ADV", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr f\u00fchret allesamt mit mir ein gleiches Leben/", "tokens": ["Ihr", "f\u00fch\u00b7ret", "al\u00b7le\u00b7samt", "mit", "mir", "ein", "glei\u00b7ches", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und m\u00fcsset/ weil ihr lebt/ Com\u00f6dianten geben.", "tokens": ["Und", "m\u00fcs\u00b7set", "/", "weil", "ihr", "lebt", "/", "Co\u00b7m\u00f6\u00b7di\u00b7an\u00b7ten", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$(", "KOUS", "PPER", "VVFIN", "$(", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer mein Gef\u00e4rte sey/ streich ich nicht viel heraus/", "tokens": ["Wer", "mein", "Ge\u00b7f\u00e4r\u00b7te", "sey", "/", "streich", "ich", "nicht", "viel", "he\u00b7raus", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VAFIN", "$(", "VVFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es weists der kluge Mund/ die s\u00fcssen Wangen aus/", "tokens": ["Es", "weists", "der", "klu\u00b7ge", "Mund", "/", "die", "s\u00fcs\u00b7sen", "Wan\u00b7gen", "aus", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn eine G\u00f6ttligkeit soll vorgestellet werden/", "tokens": ["Wenn", "ei\u00b7ne", "G\u00f6tt\u00b7lig\u00b7keit", "soll", "vor\u00b7ge\u00b7stel\u00b7let", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So schicke sich hierzu nichts bessers auff der Erden.", "tokens": ["So", "schi\u00b7cke", "sich", "hier\u00b7zu", "nichts", "bes\u00b7sers", "auff", "der", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PAV", "PIS", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Sie ist/ die nicht allein zum Scheine macht verliebt/", "tokens": ["Sie", "ist", "/", "die", "nicht", "al\u00b7lein", "zum", "Schei\u00b7ne", "macht", "ver\u00b7liebt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "PRELS", "PTKNEG", "ADV", "APPRART", "NN", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Wunden ohne Schwerdt/ und bi\u00df auffs Hertze giebt.", "tokens": ["Die", "Wun\u00b7den", "oh\u00b7ne", "Schwerdt", "/", "und", "bi\u00df", "auffs", "Hert\u00b7ze", "giebt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$(", "KON", "APPR", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was der Gesellschafft wir nun willens vorzutragen/", "tokens": ["Was", "der", "Ge\u00b7sell\u00b7schafft", "wir", "nun", "wil\u00b7lens", "vor\u00b7zu\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "ADV", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird dieser Zeddel euch mit kurtzen Worten sagen:", "tokens": ["Wird", "die\u00b7ser", "Zed\u00b7del", "euch", "mit", "kurt\u00b7zen", "Wor\u00b7ten", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Wir stellen k\u00fcnstlich f\u00fcr/ was zu Athen erklang/", "tokens": ["Wir", "stel\u00b7len", "k\u00fcnst\u00b7lich", "f\u00fcr", "/", "was", "zu", "A\u00b7then", "er\u00b7klang", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "$(", "PWS", "APPR", "NE", "VVFIN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Was Roscius nur wie\u00df/ und Seneca besang/", "tokens": ["Was", "Ro\u00b7sci\u00b7us", "nur", "wie\u00df", "/", "und", "Se\u00b7ne\u00b7ca", "be\u00b7sang", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "ADV", "VVFIN", "$(", "KON", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was Tasso und Guarin/ die klugen Welschen/ lehrten/", "tokens": ["Was", "Tas\u00b7so", "und", "Gu\u00b7a\u00b7rin", "/", "die", "klu\u00b7gen", "Wel\u00b7schen", "/", "lehr\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "$(", "ART", "ADJA", "NN", "$(", "VVFIN", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Corneille/ Molliere in Franckreich neu vermehrten.", "tokens": ["Cor\u00b7neil\u00b7le", "/", "Mol\u00b7lie\u00b7re", "in", "Fran\u00b7ck\u00b7reich", "neu", "ver\u00b7mehr\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "APPR", "NE", "ADJD", "VVINF", "$."], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}}, "stanza.7": {"line.1": {"text": "Was Londen und Madrit Verliebtes weisen kan.", "tokens": ["Was", "Lon\u00b7den", "und", "Mad\u00b7rit", "Ver\u00b7lieb\u00b7tes", "wei\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NN", "NN", "VVINF", "VMFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die Zeit ist/ die ihr uns selbst werdet zeigen an/", "tokens": ["Die", "Zeit", "ist", "/", "die", "ihr", "uns", "selbst", "wer\u00b7det", "zei\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$(", "PRELS", "PPER", "PRF", "ADV", "VAFIN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Prei\u00df/ um welchen wir erlauben zu zuschauen/", "tokens": ["Der", "Prei\u00df", "/", "um", "wel\u00b7chen", "wir", "er\u00b7lau\u00b7ben", "zu", "zu\u00b7schau\u00b7en", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "PWAT", "PPER", "VVINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Ku\u00df/ zu legen ab bey mir und meiner Frauen.", "tokens": ["Ein", "Ku\u00df", "/", "zu", "le\u00b7gen", "ab", "bey", "mir", "und", "mei\u00b7ner", "Frau\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PTKZU", "VVINF", "PTKVZ", "APPR", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}