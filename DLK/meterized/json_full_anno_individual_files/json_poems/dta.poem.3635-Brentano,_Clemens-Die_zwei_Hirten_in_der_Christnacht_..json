{"dta.poem.3635": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Die zwei Hirten in der Christnacht .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519172", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Halton. Ich will dem Kindlein schenken               ", "tokens": ["Hal\u00b7ton", ".", "Ich", "will", "dem", "Kin\u00b7dlein", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein silberweises Lamm,", "tokens": ["Ein", "sil\u00b7ber\u00b7wei\u00b7ses", "Lamm", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So viel ich mich bedenke,", "tokens": ["So", "viel", "ich", "mich", "be\u00b7den\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein sch\u00f6ners ich bekam;", "tokens": ["Kein", "sch\u00f6\u00b7ners", "ich", "be\u00b7kam", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es hat zur linken Seite", "tokens": ["Es", "hat", "zur", "lin\u00b7ken", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wie Blut so roth ein Fleck,", "tokens": ["Wie", "Blut", "so", "roth", "ein", "Fleck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Weis nicht, was der bedeutet,", "tokens": ["Weis", "nicht", ",", "was", "der", "be\u00b7deu\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "PRELS", "ART", "VVFIN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "Und was dahinter steckt.", "tokens": ["Und", "was", "da\u00b7hin\u00b7ter", "steckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PAV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Damon. Und ich schenk diesem Kinde               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "schenk", "die\u00b7sem", "Kin\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein K\u00e4lbchen zart und klein,", "tokens": ["Ein", "K\u00e4lb\u00b7chen", "zart", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit rothen B\u00e4ndern binde", "tokens": ["Mit", "ro\u00b7then", "B\u00e4n\u00b7dern", "bin\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich ihm die F\u00fc\u00dflein sein;", "tokens": ["Ich", "ihm", "die", "F\u00fc\u00df\u00b7lein", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und so will ich es tragen", "tokens": ["Und", "so", "will", "ich", "es", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Gar sch\u00f6n auf meinem Hals,", "tokens": ["Gar", "sch\u00f6n", "auf", "mei\u00b7nem", "Hals", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Das Kindlein wird da sagen:", "tokens": ["Das", "Kin\u00b7dlein", "wird", "da", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ach Mutter, mir gefallts.", "tokens": ["Ach", "Mut\u00b7ter", ",", "mir", "ge\u00b7fallts", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Halton. Und ich will ihm noch schenken               ", "tokens": ["Hal\u00b7ton", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein junges B\u00f6cklein sch\u00f6n,", "tokens": ["Ein", "jun\u00b7ges", "B\u00f6c\u00b7klein", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es treibt wohl tausend Schw\u00e4nke,", "tokens": ["Es", "treibt", "wohl", "tau\u00b7send", "Schw\u00e4n\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und bleibt nicht lange stehn;", "tokens": ["Und", "bleibt", "nicht", "lan\u00b7ge", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es klettert, stutzt und springet,", "tokens": ["Es", "klet\u00b7tert", ",", "stutzt", "und", "sprin\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und bleibt an keiner Stell,", "tokens": ["Und", "bleibt", "an", "kei\u00b7ner", "Stell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "An seinem Halse klinget", "tokens": ["An", "sei\u00b7nem", "Hal\u00b7se", "klin\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Ein goldnes Gl\u00f6cklein hell.", "tokens": ["Ein", "gold\u00b7nes", "Gl\u00f6c\u00b7klein", "hell", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Damon. Und ich will ihm noch schenken               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein rothes Hirschk\u00e4lblein,", "tokens": ["Ein", "ro\u00b7thes", "Hirschk\u00e4l\u00b7blein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Sein F\u00fc\u00dflein und Gelenke", "tokens": ["Sein", "F\u00fc\u00df\u00b7lein", "und", "Ge\u00b7len\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sind gar so zart und fein;", "tokens": ["Sind", "gar", "so", "zart", "und", "fein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da mirs auf gr\u00fcner Stra\u00dfen", "tokens": ["Da", "mirs", "auf", "gr\u00fc\u00b7ner", "Stra\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Im Wald entgegen kam,", "tokens": ["Im", "Wald", "ent\u00b7ge\u00b7gen", "kam", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPO", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Lie\u00df sichs ganz gerne fassen,", "tokens": ["Lie\u00df", "sichs", "ganz", "ger\u00b7ne", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "Gieng mit und wurde zahm.", "tokens": ["Gieng", "mit", "und", "wur\u00b7de", "zahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "KON", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Halton. Und ich will ihm noch schenken               ", "tokens": ["Hal\u00b7ton", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein sch\u00f6nes Eichh\u00f6rnlein,", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Eich\u00b7h\u00f6rn\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kann schnell herum sich schwenken,", "tokens": ["Kann", "schnell", "he\u00b7rum", "sich", "schwen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "PTKVZ", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein hurtig Meisterlein;", "tokens": ["Ein", "hur\u00b7tig", "Meis\u00b7ter\u00b7lein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das Christkindlein wird lachen,", "tokens": ["Das", "Christ\u00b7kin\u00b7dlein", "wird", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wenn es die N\u00fc\u00dflein packt,", "tokens": ["Wenn", "es", "die", "N\u00fc\u00df\u00b7lein", "packt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und schnell sie thut aufkrachen,", "tokens": ["Und", "schnell", "sie", "thut", "auf\u00b7kra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Trick track wohl nach dem Takt.", "tokens": ["Trick", "track", "wohl", "nach", "dem", "Takt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Damon. Und ich will ihm noch schenken               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein weises H\u00e4selein,", "tokens": ["Ein", "wei\u00b7ses", "H\u00e4\u00b7se\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es ist voll tausend R\u00e4nken,", "tokens": ["Es", "ist", "voll", "tau\u00b7send", "R\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Will stets bei Menschen seyn;", "tokens": ["Will", "stets", "bei", "Men\u00b7schen", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es wird beim Kripplein spielen,", "tokens": ["Es", "wird", "beim", "Krip\u00b7plein", "spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und trommeln eigentlich,", "tokens": ["Und", "trom\u00b7meln", "ei\u00b7gent\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Die Schl\u00e4ge nieder zielen", "tokens": ["Die", "Schl\u00e4\u00b7ge", "nie\u00b7der", "zie\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Mit F\u00fc\u00dfen meisterlich.", "tokens": ["Mit", "F\u00fc\u00b7\u00dfen", "meis\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Halton. Und ich will ihm noch schenken               ", "tokens": ["Hal\u00b7ton", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein wachsam H\u00fcndelein,", "tokens": ["Ein", "wach\u00b7sam", "H\u00fcn\u00b7del\u00b7ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So klug, man solls kaum denken,", "tokens": ["So", "klug", ",", "man", "solls", "kaum", "den\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PIS", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es tanzet ganz allein;", "tokens": ["Es", "tan\u00b7zet", "ganz", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es kann auch apportiren,", "tokens": ["Es", "kann", "auch", "ap\u00b7por\u00b7ti\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.6": {"text": "Und stehen auf der Wacht,", "tokens": ["Und", "ste\u00b7hen", "auf", "der", "Wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Sucht, was man thut verlieren,", "tokens": ["Sucht", ",", "was", "man", "thut", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PIS", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Was gilts, das Kindlein lacht.", "tokens": ["Was", "gilts", ",", "das", "Kin\u00b7dlein", "lacht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Damon. Und ich will ihm noch schenken               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein mausig K\u00e4tzelein,", "tokens": ["Ein", "mau\u00b7sig", "K\u00e4t\u00b7zel\u00b7ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihm darf kein H\u00e4rlein kr\u00e4nken", "tokens": ["Ihm", "darf", "kein", "H\u00e4r\u00b7lein", "kr\u00e4n\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Halton, dein H\u00fcndelein.", "tokens": ["Hal\u00b7ton", ",", "dein", "H\u00fcn\u00b7del\u00b7ein", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Es l\u00e4\u00dft sich auch nicht beissen,", "tokens": ["Es", "l\u00e4\u00dft", "sich", "auch", "nicht", "beis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Gar schnell sich widersetzt,", "tokens": ["Gar", "schnell", "sich", "wi\u00b7der\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Thut br\u00fcsten sich und spreissen,", "tokens": ["Thut", "br\u00fcs\u00b7ten", "sich", "und", "spreis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Bleibt immer unverlezt.", "tokens": ["Bleibt", "im\u00b7mer", "un\u00b7ver\u00b7lezt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Halton. Und ich will ihm noch schenken               ", "tokens": ["Hal\u00b7ton", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein St\u00fcckchen Einerlei,", "tokens": ["Ein", "St\u00fcck\u00b7chen", "Ei\u00b7ner\u00b7lei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mein, jetzo wirst du denken,", "tokens": ["Mein", ",", "jet\u00b7zo", "wirst", "du", "den\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$,", "ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was dieses doch wohl sey?", "tokens": ["Was", "die\u00b7ses", "doch", "wohl", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zu deinem K\u00e4tzlein eben", "tokens": ["Zu", "dei\u00b7nem", "K\u00e4tz\u00b7lein", "e\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Will ich ihm noch dabei", "tokens": ["Will", "ich", "ihm", "noch", "da\u00b7bei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PAV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ein pelzern Mausfall geben,", "tokens": ["Ein", "pel\u00b7zern", "Maus\u00b7fall", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "So hats der K\u00e4tzlein zwei.", "tokens": ["So", "hats", "der", "K\u00e4tz\u00b7lein", "zwei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Damon. Und ich will ihm noch schenken               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein muntres T\u00e4ubelein,", "tokens": ["Ein", "mun\u00b7tres", "T\u00e4u\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das lauft auf Tisch und B\u00e4nken", "tokens": ["Das", "lauft", "auf", "Tisch", "und", "B\u00e4n\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit seinem Schwesterlein;", "tokens": ["Mit", "sei\u00b7nem", "Schwes\u00b7ter\u00b7lein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ein Ringlein ihnen beiden", "tokens": ["Ein", "Rin\u00b7glein", "ih\u00b7nen", "bei\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Bezirkelt Hals und Brust,", "tokens": ["Be\u00b7zir\u00b7kelt", "Hals", "und", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Aus Pflaum und Feder-Seiden,", "tokens": ["Aus", "Pflaum", "und", "Fe\u00b7der\u00b7Sei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Recht farbig nach der Lust.", "tokens": ["Recht", "far\u00b7big", "nach", "der", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Halton. Und ich will ihm noch schenken               ", "tokens": ["Hal\u00b7ton", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zwo Turteltauben keusch,", "tokens": ["Zwo", "Tur\u00b7tel\u00b7tau\u00b7ben", "keusch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die spreiten, heben, senken", "tokens": ["Die", "sprei\u00b7ten", ",", "he\u00b7ben", ",", "sen\u00b7ken"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "$,", "VVFIN", "$,", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Fl\u00fcgel ohn Ger\u00e4usch;", "tokens": ["Die", "Fl\u00fc\u00b7gel", "ohn", "Ge\u00b7r\u00e4usch", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ihr Stimmlein, wie man sp\u00fcret,", "tokens": ["Ihr", "Stimm\u00b7lein", ",", "wie", "man", "sp\u00fc\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sind lauter Seufzerlein,", "tokens": ["Sind", "lau\u00b7ter", "Seuf\u00b7zer\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Gott wei\u00df, welch Leid sie r\u00fchret,", "tokens": ["Gott", "wei\u00df", ",", "welch", "Leid", "sie", "r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PWAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "In ihrem Herzelein.", "tokens": ["In", "ih\u00b7rem", "Her\u00b7ze\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Damon. Und ich will ihm noch schenken               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein gro\u00dfen bunten Hahn,", "tokens": ["Ein", "gro\u00b7\u00dfen", "bun\u00b7ten", "Hahn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Haupt und Hals thut schwenken,", "tokens": ["Der", "Haupt", "und", "Hals", "thut", "schwen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gleich einem edlen Schwan;", "tokens": ["Gleich", "ei\u00b7nem", "ed\u00b7len", "Schwan", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Mit Sporn und Busch er gehet,", "tokens": ["Mit", "Sporn", "und", "Busch", "er", "ge\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Stolz als ein Rittersmann,", "tokens": ["Stolz", "als", "ein", "Rit\u00b7ters\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.7": {"text": "Und Morgens flei\u00dfig kr\u00e4het", "tokens": ["Und", "Mor\u00b7gens", "flei\u00b7\u00dfig", "kr\u00e4\u00b7het"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Der bunte Wettermann.", "tokens": ["Der", "bun\u00b7te", "Wet\u00b7ter\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Halton. Und ich will ihm noch schenken               ", "tokens": ["Hal\u00b7ton", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Fink und Nachtigall,", "tokens": ["Ein", "Fink", "und", "Nach\u00b7ti\u00b7gall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Kopf und Ohren lenken,", "tokens": ["Die", "Kopf", "und", "Oh\u00b7ren", "len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nach meiner Fl\u00f6te Schall;", "tokens": ["Nach", "mei\u00b7ner", "Fl\u00f6\u00b7te", "Schall", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Spiel ich die Sch\u00e4ferlieder,", "tokens": ["Spiel", "ich", "die", "Sch\u00e4\u00b7fer\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "So kommen sie herbei,", "tokens": ["So", "kom\u00b7men", "sie", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und pfeifen sie mir wieder", "tokens": ["Und", "pfei\u00b7fen", "sie", "mir", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "In ihrer Melodei.", "tokens": ["In", "ih\u00b7rer", "Me\u00b7lo\u00b7dei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Damon. Und ich will ihm noch schenken               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein wei\u00dfes K\u00f6rbelein,", "tokens": ["Ein", "wei\u00b7\u00dfes", "K\u00f6r\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "An Balken soll mans henken,", "tokens": ["An", "Bal\u00b7ken", "soll", "mans", "hen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+++-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Voll kleiner V\u00f6gelein;", "tokens": ["Voll", "klei\u00b7ner", "V\u00f6\u00b7ge\u00b7lein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Ich selber habs geschnitzet", "tokens": ["Ich", "sel\u00b7ber", "habs", "ge\u00b7schnit\u00b7zet"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "NE", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "In siebenthalben Tag,", "tokens": ["In", "sie\u00b7bent\u00b7hal\u00b7ben", "Tag", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ist neu und unbeschmitzet,", "tokens": ["Ist", "neu", "und", "un\u00b7be\u00b7schmit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Nicht gnug man's loben mag.", "tokens": ["Nicht", "gnug", "man's", "lo\u00b7ben", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PTKNEG", "ADV", "PIS", "VVFIN", "NE"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.15": {"line.1": {"text": "Halton. Und ich will ihm noch schenken               ", "tokens": ["Hal\u00b7ton", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein sch\u00f6nen Hirtenstab,", "tokens": ["Ein", "sch\u00f6\u00b7nen", "Hir\u00b7ten\u00b7stab", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Farben ihn besprengen,", "tokens": ["Mit", "Far\u00b7ben", "ihn", "be\u00b7spren\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie es noch keinen gab;", "tokens": ["Wie", "es", "noch", "kei\u00b7nen", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIAT", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die Kunst hab ich gelernet,", "tokens": ["Die", "Kunst", "hab", "ich", "ge\u00b7ler\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wie man es machen soll,", "tokens": ["Wie", "man", "es", "ma\u00b7chen", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df ganz er wird gesternet,", "tokens": ["Da\u00df", "ganz", "er", "wird", "ge\u00b7ster\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und bunter Flecken voll.", "tokens": ["Und", "bun\u00b7ter", "Fle\u00b7cken", "voll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Damon. Und ich will ihm noch schenken               ", "tokens": ["Da\u00b7mon", ".", "Und", "ich", "will", "ihm", "noch", "schen\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Viel sch\u00f6ne Sachen mehr,", "tokens": ["Viel", "sch\u00f6\u00b7ne", "Sa\u00b7chen", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ja schenken und noch schenken", "tokens": ["Ja", "schen\u00b7ken", "und", "noch", "schen\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKANT", "VVINF", "KON", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Je mehr und je noch mehr;", "tokens": ["Je", "mehr", "und", "je", "noch", "mehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Auch Aepfel, Birn und N\u00fcsse,", "tokens": ["Auch", "A\u00b7e\u00b7pfel", ",", "Birn", "und", "N\u00fcs\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Milch, Honig, Butter, K\u00e4\u00df,", "tokens": ["Milch", ",", "Ho\u00b7nig", ",", "But\u00b7ter", ",", "K\u00e4\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ach wenn ich doch k\u00f6nnt wissen,", "tokens": ["Ach", "wenn", "ich", "doch", "k\u00f6nnt", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "PPER", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Was es recht gerne \u00e4\u00df.", "tokens": ["Was", "es", "recht", "ger\u00b7ne", "\u00e4\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.17": {"line.1": {"text": "Halton. Wohl dann, so la\u00dft uns reisen               ", "tokens": ["Hal\u00b7ton", ".", "Wohl", "dann", ",", "so", "la\u00dft", "uns", "rei\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "ADV", "ADV", "$,", "ADV", "VVIMP", "PPER", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zum sch\u00f6nen Kindelein,", "tokens": ["Zum", "sch\u00f6\u00b7nen", "Kin\u00b7de\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und unsre Gaben preisen,", "tokens": ["Und", "uns\u00b7re", "Ga\u00b7ben", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem kleinen Sch\u00e4ferlein;", "tokens": ["Dem", "klei\u00b7nen", "Sch\u00e4\u00b7fer\u00b7lein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ihm alles auf soll heben", "tokens": ["Ihm", "al\u00b7les", "auf", "soll", "he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PIS", "APPR", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die Mutter mit Bescheid,", "tokens": ["Die", "Mut\u00b7ter", "mit", "Be\u00b7scheid", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df es ihm wird gegeben", "tokens": ["Da\u00df", "es", "ihm", "wird", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Hernach zu seiner Zeit.", "tokens": ["Her\u00b7nach", "zu", "sei\u00b7ner", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}