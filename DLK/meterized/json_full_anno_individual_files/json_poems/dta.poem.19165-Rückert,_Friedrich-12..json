{"dta.poem.19165": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "12.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195090", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein einzig Bienchen war im Bienenstock erwacht,", "tokens": ["Ein", "ein\u00b7zig", "Bien\u00b7chen", "war", "im", "Bie\u00b7nen\u00b7stock", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die andern schliefen noch in honigduftiger Nacht.", "tokens": ["Die", "an\u00b7dern", "schlie\u00b7fen", "noch", "in", "ho\u00b7nig\u00b7duf\u00b7ti\u00b7ger", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.2": {"line.1": {"text": "Ein einzig Bl\u00fcmchen war am Blumenstock erbl\u00fcht,", "tokens": ["Ein", "ein\u00b7zig", "Bl\u00fcm\u00b7chen", "war", "am", "Blu\u00b7men\u00b7stock", "er\u00b7bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die andern schliefen tief im d\u00e4mmernden Gem\u00fcth.", "tokens": ["Die", "an\u00b7dern", "schlie\u00b7fen", "tief", "im", "d\u00e4m\u00b7mern\u00b7den", "Ge\u00b7m\u00fcth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ein einzig Bl\u00fcmchen lacht, noch schl\u00e4ft der ganze Flor;", "tokens": ["Ein", "ein\u00b7zig", "Bl\u00fcm\u00b7chen", "lacht", ",", "noch", "schl\u00e4ft", "der", "gan\u00b7ze", "Flor", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein einzig Bienchen wacht, noch schweigt der ganze Chor.", "tokens": ["Ein", "ein\u00b7zig", "Bien\u00b7chen", "wacht", ",", "noch", "schweigt", "der", "gan\u00b7ze", "Chor", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Das eine Bienchen fuhr durch all die Fr\u00fchlingsflur,", "tokens": ["Das", "ei\u00b7ne", "Bien\u00b7chen", "fuhr", "durch", "all", "die", "Fr\u00fch\u00b7lings\u00b7flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVFIN", "APPR", "PIAT", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und fand, wie fand es nur? des einen Bl\u00fcmchens Spur.", "tokens": ["Und", "fand", ",", "wie", "fand", "es", "nur", "?", "des", "ei\u00b7nen", "Bl\u00fcm\u00b7chens", "Spur", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$.", "ART", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wenn dis nicht bl\u00fchte, h\u00e4tt' umsonst sich jens bem\u00fcht,", "tokens": ["Wenn", "dis", "nicht", "bl\u00fch\u00b7te", ",", "h\u00e4tt'", "um\u00b7sonst", "sich", "jens", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PTKNEG", "VVFIN", "$,", "VAFIN", "ADV", "PRF", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wenn nicht jenes kam, wem h\u00e4tte dis gebl\u00fcht?", "tokens": ["Und", "wenn", "nicht", "je\u00b7nes", "kam", ",", "wem", "h\u00e4t\u00b7te", "dis", "ge\u00b7bl\u00fcht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PTKNEG", "PDS", "VVFIN", "$,", "PWS", "VAFIN", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Hat jenes wol gewu\u00dft, da\u00df dieses bl\u00fchte just?", "tokens": ["Hat", "je\u00b7nes", "wol", "ge\u00b7wu\u00dft", ",", "da\u00df", "die\u00b7ses", "bl\u00fch\u00b7te", "just", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "VVPP", "$,", "KOUS", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat dieses bl\u00fchn gemu\u00dft, weil jenes war voll Luft?", "tokens": ["Hat", "die\u00b7ses", "bl\u00fchn", "ge\u00b7mu\u00dft", ",", "weil", "je\u00b7nes", "war", "voll", "Luft", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "VVPP", "$,", "KOUS", "PDS", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Von beiden welches rief das andre das noch schlief?", "tokens": ["Von", "bei\u00b7den", "wel\u00b7ches", "rief", "das", "and\u00b7re", "das", "noch", "schlief", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PIS", "VVFIN", "ART", "PIS", "ART", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein drittes rief die zwei, sonst schliefen sie noch tief.", "tokens": ["Ein", "drit\u00b7tes", "rief", "die", "zwei", ",", "sonst", "schlie\u00b7fen", "sie", "noch", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "CARD", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Sei's fern wie Orient von Occident getrennt,", "tokens": ["Sei's", "fern", "wie", "O\u00b7rient", "von", "Oc\u00b7ci\u00b7dent", "ge\u00b7trennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "KOKOM", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Es findet sich und kennt, was gleichen Triebs entbrennt.", "tokens": ["Es", "fin\u00b7det", "sich", "und", "kennt", ",", "was", "glei\u00b7chen", "Triebs", "ent\u00b7brennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "KON", "VVFIN", "$,", "PWS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Was gleichen Triebs entbrennt und gleichen Sinns sich nennt,", "tokens": ["Was", "glei\u00b7chen", "Triebs", "ent\u00b7brennt", "und", "glei\u00b7chen", "Sinns", "sich", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VVFIN", "KON", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es findet sich und kennt und eint sich ungetrennt.", "tokens": ["Es", "fin\u00b7det", "sich", "und", "kennt", "und", "eint", "sich", "un\u00b7ge\u00b7trennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "KON", "VVFIN", "KON", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Es eint sich ungetrennt in gleichem Element", "tokens": ["Es", "eint", "sich", "un\u00b7ge\u00b7trennt", "in", "glei\u00b7chem", "E\u00b7le\u00b7ment"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Lieb' aus Orient der Lieb' im Occident.", "tokens": ["Die", "Lieb'", "aus", "O\u00b7rient", "der", "Lieb'", "im", "Oc\u00b7ci\u00b7dent", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}}}}