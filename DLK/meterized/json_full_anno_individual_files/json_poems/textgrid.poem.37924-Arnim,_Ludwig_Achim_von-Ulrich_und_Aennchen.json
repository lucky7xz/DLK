{"textgrid.poem.37924": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Ulrich und Aennchen", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ritt einst Ulrich spazieren aus,", "tokens": ["Es", "ritt", "einst", "Ul\u00b7rich", "spa\u00b7zie\u00b7ren", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er ritt wohl vor lieb Aennchens Haus:", "tokens": ["Er", "ritt", "wohl", "vor", "lieb", "A\u00b7enn\u00b7chens", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJD", "NE", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bblieb Aennchen, willst mit in gr\u00fcnen Wald?", "tokens": ["\u00bb", "lieb", "A\u00b7enn\u00b7chen", ",", "willst", "mit", "in", "gr\u00fc\u00b7nen", "Wald", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NE", "$,", "VMFIN", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ich will dir lehren den Vogelsang.\u00ab", "tokens": ["Ich", "will", "dir", "leh\u00b7ren", "den", "Vo\u00b7gel\u00b7sang", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Sie gingen wohl mit einander fort,", "tokens": ["Sie", "gin\u00b7gen", "wohl", "mit", "ein\u00b7an\u00b7der", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "Sie kamen an eine Hasel dort,", "tokens": ["Sie", "ka\u00b7men", "an", "ei\u00b7ne", "Ha\u00b7sel", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie kamen ein Fleckchen weiter hin,", "tokens": ["Sie", "ka\u00b7men", "ein", "Fleck\u00b7chen", "wei\u00b7ter", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie kamen auf eine Wiese gr\u00fcn.", "tokens": ["Sie", "ka\u00b7men", "auf", "ei\u00b7ne", "Wie\u00b7se", "gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Er f\u00fchrte sie ins gr\u00fcne Gras,", "tokens": ["Er", "f\u00fchr\u00b7te", "sie", "ins", "gr\u00fc\u00b7ne", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er bat, lieb Aennchen niedersa\u00df,", "tokens": ["Er", "bat", ",", "lieb", "A\u00b7enn\u00b7chen", "nie\u00b7der\u00b7sa\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er legt seinen Kopf in ihren Schoos,", "tokens": ["Er", "legt", "sei\u00b7nen", "Kopf", "in", "ih\u00b7ren", "Schoos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit hei\u00dfen Thr\u00e4nen sie ihn bego\u00df.", "tokens": ["Mit", "hei\u00b7\u00dfen", "Thr\u00e4\u00b7nen", "sie", "ihn", "be\u00b7go\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "\u00bbach Aennchen, liebes Aennchen mein,", "tokens": ["\u00bb", "ach", "A\u00b7enn\u00b7chen", ",", "lie\u00b7bes", "A\u00b7enn\u00b7chen", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NE", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Warum weinst du denn so sehr um ein'n?", "tokens": ["Wa\u00b7rum", "weinst", "du", "denn", "so", "sehr", "um", "ein'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Weinst irgend um deines Vaters Gut?", "tokens": ["Weinst", "ir\u00b7gend", "um", "dei\u00b7nes", "Va\u00b7ters", "Gut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "++--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Oder weinest um dein junges Blut?", "tokens": ["O\u00b7der", "wei\u00b7nest", "um", "dein", "jun\u00b7ges", "Blut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Oder bin ich dir nicht sch\u00f6n genug?\u00ab", "tokens": ["O\u00b7der", "bin", "ich", "dir", "nicht", "sch\u00f6n", "ge\u00b7nug", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "PTKNEG", "ADJD", "ADV", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbich weine nicht um meines Vaters Gut,", "tokens": ["\u00bb", "ich", "wei\u00b7ne", "nicht", "um", "mei\u00b7nes", "Va\u00b7ters", "Gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich wein' auch nicht um mein junges Blut,", "tokens": ["Ich", "wein'", "auch", "nicht", "um", "mein", "jun\u00b7ges", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und, Ulrich, bist mir auch sch\u00f6n genug.", "tokens": ["Und", ",", "Ul\u00b7rich", ",", "bist", "mir", "auch", "sch\u00f6n", "ge\u00b7nug", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NE", "$,", "VAFIN", "PPER", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Da droben auf jener Tannen,", "tokens": ["Da", "dro\u00b7ben", "auf", "je\u00b7ner", "Tan\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Eilf Jungfrauen sah ich hangen.\u00ab", "tokens": ["Eilf", "Jung\u00b7frau\u00b7en", "sah", "ich", "han\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NN", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbach Aennchen, liebes Aennchen mein,", "tokens": ["\u00bb", "ach", "A\u00b7enn\u00b7chen", ",", "lie\u00b7bes", "A\u00b7enn\u00b7chen", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NE", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Wie bald sollst du die zw\u00f6lfte seyn.\u00ab", "tokens": ["Wie", "bald", "sollst", "du", "die", "zw\u00f6lf\u00b7te", "seyn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "ART", "ADJA", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbsoll ich denn nun die zw\u00f6lfte seyn?", "tokens": ["\u00bb", "soll", "ich", "denn", "nun", "die", "zw\u00f6lf\u00b7te", "seyn", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bitt, ihr wollt mir drei Schrei verleihn.\u00ab", "tokens": ["Ich", "bitt", ",", "ihr", "wollt", "mir", "drei", "Schrei", "ver\u00b7leihn", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "CARD", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Den ersten Schrei und den sie that,", "tokens": ["Den", "ers\u00b7ten", "Schrei", "und", "den", "sie", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie rufte ihren Vater an,", "tokens": ["Sie", "ruf\u00b7te", "ih\u00b7ren", "Va\u00b7ter", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Den andern Schrei und den sie that,", "tokens": ["Den", "an\u00b7dern", "Schrei", "und", "den", "sie", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ruft ihren lieben Herr Gott an,", "tokens": ["Sie", "ruft", "ih\u00b7ren", "lie\u00b7ben", "Herr", "Gott", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den dritten Schrei und den sie that,", "tokens": ["Den", "drit\u00b7ten", "Schrei", "und", "den", "sie", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ruft ihren j\u00fcngsten Bruder an.", "tokens": ["Sie", "ruft", "ih\u00b7ren", "j\u00fcng\u00b7sten", "Bru\u00b7der", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Ihr Bruder sa\u00df beim rothen k\u00fchlen Wein,", "tokens": ["Ihr", "Bru\u00b7der", "sa\u00df", "beim", "ro\u00b7then", "k\u00fch\u00b7len", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Schall der fuhr zum Fenster hinein:", "tokens": ["Der", "Schall", "der", "fuhr", "zum", "Fens\u00b7ter", "hin\u00b7ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00bbh\u00f6ret ihr Br\u00fcder alle,", "tokens": ["\u00bb", "h\u00f6\u00b7ret", "ihr", "Br\u00fc\u00b7der", "al\u00b7le", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "PIS", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Meine Schwester schreit aus dem Walde.\u00ab", "tokens": ["Mei\u00b7ne", "Schwes\u00b7ter", "schreit", "aus", "dem", "Wal\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "\u00bbach Ulrich, lieber Ulrich mein,", "tokens": ["\u00bb", "ach", "Ul\u00b7rich", ",", "lie\u00b7ber", "Ul\u00b7rich", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NE", "$,", "ADV", "NE", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo hast du die j\u00fcngste Schwester mein?\u00ab", "tokens": ["Wo", "hast", "du", "die", "j\u00fcngs\u00b7te", "Schwes\u00b7ter", "mein", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ART", "ADJA", "NN", "PPOSAT", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbdort oben auf jener Linde,", "tokens": ["\u00bb", "dort", "o\u00b7ben", "auf", "je\u00b7ner", "Lin\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "APPR", "PDAT", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Schwarzbraune Seide thut sie spinnen.\u00ab", "tokens": ["Schwarz\u00b7brau\u00b7ne", "Sei\u00b7de", "thut", "sie", "spin\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "\u00bbwarum sind deine Schuh so blutroth?", "tokens": ["\u00bb", "wa\u00b7rum", "sind", "dei\u00b7ne", "Schuh", "so", "blut\u00b7roth", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum sind deine Augen so todt?\u00ab", "tokens": ["Wa\u00b7rum", "sind", "dei\u00b7ne", "Au\u00b7gen", "so", "todt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00bbwarum sollten sie nicht blutroth seyn?", "tokens": ["\u00bb", "wa\u00b7rum", "soll\u00b7ten", "sie", "nicht", "blut\u00b7roth", "seyn", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ich scho\u00df ein Turtelt\u00e4ubelein.\u00ab", "tokens": ["Ich", "scho\u00df", "ein", "Tur\u00b7tel\u00b7t\u00e4u\u00b7be\u00b7lein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbdas Turtelt\u00e4ublein, das du erscho\u00dft,", "tokens": ["\u00bb", "das", "Tur\u00b7tel\u00b7t\u00e4u\u00b7blein", ",", "das", "du", "er\u00b7scho\u00dft", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das trug meine Mutter unter ihrer Brust,", "tokens": ["Das", "trug", "mei\u00b7ne", "Mut\u00b7ter", "un\u00b7ter", "ih\u00b7rer", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das trug meine Mutter in ihrem Schoo\u00df,", "tokens": ["Das", "trug", "mei\u00b7ne", "Mut\u00b7ter", "in", "ih\u00b7rem", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und zog es mit ihrem Blute gro\u00df.\u00ab", "tokens": ["Und", "zog", "es", "mit", "ih\u00b7rem", "Blu\u00b7te", "gro\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Lieb Aennchen kam ins tiefe Grab,", "tokens": ["Lieb", "A\u00b7enn\u00b7chen", "kam", "ins", "tie\u00b7fe", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Schwager Ulrich auf das hohe Rad,", "tokens": ["Schwa\u00b7ger", "Ul\u00b7rich", "auf", "das", "ho\u00b7he", "Rad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Um Aennchen sungen die Engelein,", "tokens": ["Um", "A\u00b7enn\u00b7chen", "sun\u00b7gen", "die", "En\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Um Ulrich schrieen die Raben allein.", "tokens": ["Um", "Ul\u00b7rich", "schri\u00b7een", "die", "Ra\u00b7ben", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Es ritt einst Ulrich spazieren aus,", "tokens": ["Es", "ritt", "einst", "Ul\u00b7rich", "spa\u00b7zie\u00b7ren", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er ritt wohl vor lieb Aennchens Haus:", "tokens": ["Er", "ritt", "wohl", "vor", "lieb", "A\u00b7enn\u00b7chens", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJD", "NE", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bblieb Aennchen, willst mit in gr\u00fcnen Wald?", "tokens": ["\u00bb", "lieb", "A\u00b7enn\u00b7chen", ",", "willst", "mit", "in", "gr\u00fc\u00b7nen", "Wald", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NE", "$,", "VMFIN", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ich will dir lehren den Vogelsang.\u00ab", "tokens": ["Ich", "will", "dir", "leh\u00b7ren", "den", "Vo\u00b7gel\u00b7sang", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Sie gingen wohl mit einander fort,", "tokens": ["Sie", "gin\u00b7gen", "wohl", "mit", "ein\u00b7an\u00b7der", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "Sie kamen an eine Hasel dort,", "tokens": ["Sie", "ka\u00b7men", "an", "ei\u00b7ne", "Ha\u00b7sel", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie kamen ein Fleckchen weiter hin,", "tokens": ["Sie", "ka\u00b7men", "ein", "Fleck\u00b7chen", "wei\u00b7ter", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie kamen auf eine Wiese gr\u00fcn.", "tokens": ["Sie", "ka\u00b7men", "auf", "ei\u00b7ne", "Wie\u00b7se", "gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Er f\u00fchrte sie ins gr\u00fcne Gras,", "tokens": ["Er", "f\u00fchr\u00b7te", "sie", "ins", "gr\u00fc\u00b7ne", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er bat, lieb Aennchen niedersa\u00df,", "tokens": ["Er", "bat", ",", "lieb", "A\u00b7enn\u00b7chen", "nie\u00b7der\u00b7sa\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er legt seinen Kopf in ihren Schoos,", "tokens": ["Er", "legt", "sei\u00b7nen", "Kopf", "in", "ih\u00b7ren", "Schoos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit hei\u00dfen Thr\u00e4nen sie ihn bego\u00df.", "tokens": ["Mit", "hei\u00b7\u00dfen", "Thr\u00e4\u00b7nen", "sie", "ihn", "be\u00b7go\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bbach Aennchen, liebes Aennchen mein,", "tokens": ["\u00bb", "ach", "A\u00b7enn\u00b7chen", ",", "lie\u00b7bes", "A\u00b7enn\u00b7chen", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NE", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Warum weinst du denn so sehr um ein'n?", "tokens": ["Wa\u00b7rum", "weinst", "du", "denn", "so", "sehr", "um", "ein'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Weinst irgend um deines Vaters Gut?", "tokens": ["Weinst", "ir\u00b7gend", "um", "dei\u00b7nes", "Va\u00b7ters", "Gut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "++--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Oder weinest um dein junges Blut?", "tokens": ["O\u00b7der", "wei\u00b7nest", "um", "dein", "jun\u00b7ges", "Blut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.18": {"line.1": {"text": "Oder bin ich dir nicht sch\u00f6n genug?\u00ab", "tokens": ["O\u00b7der", "bin", "ich", "dir", "nicht", "sch\u00f6n", "ge\u00b7nug", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "PTKNEG", "ADJD", "ADV", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbich weine nicht um meines Vaters Gut,", "tokens": ["\u00bb", "ich", "wei\u00b7ne", "nicht", "um", "mei\u00b7nes", "Va\u00b7ters", "Gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich wein' auch nicht um mein junges Blut,", "tokens": ["Ich", "wein'", "auch", "nicht", "um", "mein", "jun\u00b7ges", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und, Ulrich, bist mir auch sch\u00f6n genug.", "tokens": ["Und", ",", "Ul\u00b7rich", ",", "bist", "mir", "auch", "sch\u00f6n", "ge\u00b7nug", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NE", "$,", "VAFIN", "PPER", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Da droben auf jener Tannen,", "tokens": ["Da", "dro\u00b7ben", "auf", "je\u00b7ner", "Tan\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Eilf Jungfrauen sah ich hangen.\u00ab", "tokens": ["Eilf", "Jung\u00b7frau\u00b7en", "sah", "ich", "han\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NN", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbach Aennchen, liebes Aennchen mein,", "tokens": ["\u00bb", "ach", "A\u00b7enn\u00b7chen", ",", "lie\u00b7bes", "A\u00b7enn\u00b7chen", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NE", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Wie bald sollst du die zw\u00f6lfte seyn.\u00ab", "tokens": ["Wie", "bald", "sollst", "du", "die", "zw\u00f6lf\u00b7te", "seyn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "ART", "ADJA", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "\u00bbsoll ich denn nun die zw\u00f6lfte seyn?", "tokens": ["\u00bb", "soll", "ich", "denn", "nun", "die", "zw\u00f6lf\u00b7te", "seyn", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bitt, ihr wollt mir drei Schrei verleihn.\u00ab", "tokens": ["Ich", "bitt", ",", "ihr", "wollt", "mir", "drei", "Schrei", "ver\u00b7leihn", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "CARD", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Den ersten Schrei und den sie that,", "tokens": ["Den", "ers\u00b7ten", "Schrei", "und", "den", "sie", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie rufte ihren Vater an,", "tokens": ["Sie", "ruf\u00b7te", "ih\u00b7ren", "Va\u00b7ter", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Den andern Schrei und den sie that,", "tokens": ["Den", "an\u00b7dern", "Schrei", "und", "den", "sie", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ruft ihren lieben Herr Gott an,", "tokens": ["Sie", "ruft", "ih\u00b7ren", "lie\u00b7ben", "Herr", "Gott", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den dritten Schrei und den sie that,", "tokens": ["Den", "drit\u00b7ten", "Schrei", "und", "den", "sie", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ruft ihren j\u00fcngsten Bruder an.", "tokens": ["Sie", "ruft", "ih\u00b7ren", "j\u00fcng\u00b7sten", "Bru\u00b7der", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "Ihr Bruder sa\u00df beim rothen k\u00fchlen Wein,", "tokens": ["Ihr", "Bru\u00b7der", "sa\u00df", "beim", "ro\u00b7then", "k\u00fch\u00b7len", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Schall der fuhr zum Fenster hinein:", "tokens": ["Der", "Schall", "der", "fuhr", "zum", "Fens\u00b7ter", "hin\u00b7ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00bbh\u00f6ret ihr Br\u00fcder alle,", "tokens": ["\u00bb", "h\u00f6\u00b7ret", "ihr", "Br\u00fc\u00b7der", "al\u00b7le", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "PIS", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Meine Schwester schreit aus dem Walde.\u00ab", "tokens": ["Mei\u00b7ne", "Schwes\u00b7ter", "schreit", "aus", "dem", "Wal\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "\u00bbach Ulrich, lieber Ulrich mein,", "tokens": ["\u00bb", "ach", "Ul\u00b7rich", ",", "lie\u00b7ber", "Ul\u00b7rich", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NE", "$,", "ADV", "NE", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo hast du die j\u00fcngste Schwester mein?\u00ab", "tokens": ["Wo", "hast", "du", "die", "j\u00fcngs\u00b7te", "Schwes\u00b7ter", "mein", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ART", "ADJA", "NN", "PPOSAT", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbdort oben auf jener Linde,", "tokens": ["\u00bb", "dort", "o\u00b7ben", "auf", "je\u00b7ner", "Lin\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "APPR", "PDAT", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Schwarzbraune Seide thut sie spinnen.\u00ab", "tokens": ["Schwarz\u00b7brau\u00b7ne", "Sei\u00b7de", "thut", "sie", "spin\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "\u00bbwarum sind deine Schuh so blutroth?", "tokens": ["\u00bb", "wa\u00b7rum", "sind", "dei\u00b7ne", "Schuh", "so", "blut\u00b7roth", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum sind deine Augen so todt?\u00ab", "tokens": ["Wa\u00b7rum", "sind", "dei\u00b7ne", "Au\u00b7gen", "so", "todt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00bbwarum sollten sie nicht blutroth seyn?", "tokens": ["\u00bb", "wa\u00b7rum", "soll\u00b7ten", "sie", "nicht", "blut\u00b7roth", "seyn", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ich scho\u00df ein Turtelt\u00e4ubelein.\u00ab", "tokens": ["Ich", "scho\u00df", "ein", "Tur\u00b7tel\u00b7t\u00e4u\u00b7be\u00b7lein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "\u00bbdas Turtelt\u00e4ublein, das du erscho\u00dft,", "tokens": ["\u00bb", "das", "Tur\u00b7tel\u00b7t\u00e4u\u00b7blein", ",", "das", "du", "er\u00b7scho\u00dft", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das trug meine Mutter unter ihrer Brust,", "tokens": ["Das", "trug", "mei\u00b7ne", "Mut\u00b7ter", "un\u00b7ter", "ih\u00b7rer", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das trug meine Mutter in ihrem Schoo\u00df,", "tokens": ["Das", "trug", "mei\u00b7ne", "Mut\u00b7ter", "in", "ih\u00b7rem", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und zog es mit ihrem Blute gro\u00df.\u00ab", "tokens": ["Und", "zog", "es", "mit", "ih\u00b7rem", "Blu\u00b7te", "gro\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.26": {"line.1": {"text": "Lieb Aennchen kam ins tiefe Grab,", "tokens": ["Lieb", "A\u00b7enn\u00b7chen", "kam", "ins", "tie\u00b7fe", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Schwager Ulrich auf das hohe Rad,", "tokens": ["Schwa\u00b7ger", "Ul\u00b7rich", "auf", "das", "ho\u00b7he", "Rad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Um Aennchen sungen die Engelein,", "tokens": ["Um", "A\u00b7enn\u00b7chen", "sun\u00b7gen", "die", "En\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Um Ulrich schrieen die Raben allein.", "tokens": ["Um", "Ul\u00b7rich", "schri\u00b7een", "die", "Ra\u00b7ben", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}}}}