{"textgrid.poem.62817": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Beate reicht die welke Hand", "genre": "verse", "period": "N.A.", "pub_year": 1756, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Beate reicht die welke Hand", "tokens": ["Bea\u00b7te", "reicht", "die", "wel\u00b7ke", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch einem h\u00fcbschen jungen Fant.", "tokens": ["Noch", "ei\u00b7nem", "h\u00fcb\u00b7schen", "jun\u00b7gen", "Fant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was hat sie wohl dazu bewogen?", "tokens": ["Was", "hat", "sie", "wohl", "da\u00b7zu", "be\u00b7wo\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie spricht: des Menschen D\u00fcrftigkeit", "tokens": ["Sie", "spricht", ":", "des", "Men\u00b7schen", "D\u00fcrf\u00b7tig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und christliche Gelassenheit.", "tokens": ["Und", "christ\u00b7li\u00b7che", "Ge\u00b7las\u00b7sen\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Als Raps Besitz vom Erbe nahm,", "tokens": ["Als", "Raps", "Be\u00b7sitz", "vom", "Er\u00b7be", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das er vom Oheim Rips bekam,", "tokens": ["Das", "er", "vom", "O\u00b7heim", "Rips", "be\u00b7kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Rief er in lauten Monologen:", "tokens": ["Rief", "er", "in", "lau\u00b7ten", "Mo\u00b7no\u00b7lo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie gern verz\u00f6g ich auf sein Geld,", "tokens": ["Wie", "gern", "ver\u00b7z\u00f6g", "ich", "auf", "sein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "W\u00e4r er nur noch auf dieser Welt!", "tokens": ["W\u00e4r", "er", "nur", "noch", "auf", "die\u00b7ser", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Sejan, der bauchige Magnat,", "tokens": ["Se\u00b7jan", ",", "der", "bau\u00b7chi\u00b7ge", "Mag\u00b7nat", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der, einem Vampyr gleich, den Staat", "tokens": ["Der", ",", "ei\u00b7nem", "Vam\u00b7pyr", "gleich", ",", "den", "Staat"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "$,", "ART", "NN", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis auf das Herzblut ausgesogen,", "tokens": ["Bis", "auf", "das", "Herz\u00b7blut", "aus\u00b7ge\u00b7so\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "R\u00fchmt, da\u00df er f\u00fcr sein Vaterland", "tokens": ["R\u00fchmt", ",", "da\u00df", "er", "f\u00fcr", "sein", "Va\u00b7ter\u00b7land"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gut und Gesundheit aufgewandt.", "tokens": ["Gut", "und", "Ge\u00b7sund\u00b7heit", "auf\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Man hat dem Junker Leonhard", "tokens": ["Man", "hat", "dem", "Jun\u00b7ker", "Le\u00b7on\u00b7hard"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Heut seinen alten Knecht verscharrt,", "tokens": ["Heut", "sei\u00b7nen", "al\u00b7ten", "Knecht", "ver\u00b7scharrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem er die Bissen dargewogen.", "tokens": ["Dem", "er", "die", "Bis\u00b7sen", "dar\u00b7ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er sagt, da\u00df er den armen Wicht", "tokens": ["Er", "sagt", ",", "da\u00df", "er", "den", "ar\u00b7men", "Wicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu todt gef\u00fcttert, wie man spricht.", "tokens": ["Zu", "todt", "ge\u00b7f\u00fct\u00b7tert", ",", "wie", "man", "spricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVPP", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Um Clelien h\u00e4lt Lindor an;", "tokens": ["Um", "Cle\u00b7li\u00b7en", "h\u00e4lt", "Lin\u00b7dor", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er, der wie ein verliebter Hahn", "tokens": ["Er", ",", "der", "wie", "ein", "ver\u00b7lieb\u00b7ter", "Hahn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bisher von Weib zu Weib geflogen.", "tokens": ["Bis\u00b7her", "von", "Weib", "zu", "Weib", "ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er schw\u00f6rt beym Hymen, ihr allein", "tokens": ["Er", "schw\u00f6rt", "beym", "Hy\u00b7men", ",", "ihr", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis in das Grab getreu zu seyn.", "tokens": ["Bis", "in", "das", "Grab", "ge\u00b7treu", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Rufill, ein schwangerer Poet,", "tokens": ["Ru\u00b7fill", ",", "ein", "schwan\u00b7ge\u00b7rer", "Po\u00b7et", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gebahr ein Buch, in diesem steht", "tokens": ["Ge\u00b7bahr", "ein", "Buch", ",", "in", "die\u00b7sem", "steht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "APPR", "PDAT", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl dreymal auf dem ersten Bogen:", "tokens": ["Wohl", "drey\u00b7mal", "auf", "dem", "ers\u00b7ten", "Bo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ihn geneigter Kenner Rath", "tokens": ["Da\u00df", "ihn", "ge\u00b7neig\u00b7ter", "Ken\u00b7ner", "Rath"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu diesem Druck verleitet hat.", "tokens": ["Zu", "die\u00b7sem", "Druck", "ver\u00b7lei\u00b7tet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Als Phryne j\u00fcngst im Spiegelsaal", "tokens": ["Als", "Phry\u00b7ne", "j\u00fcngst", "im", "Spie\u00b7gel\u00b7saal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr ihren alten Ehgemahl", "tokens": ["F\u00fcr", "ih\u00b7ren", "al\u00b7ten", "Eh\u00b7ge\u00b7mahl"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Trauerkleider angezogen,", "tokens": ["Die", "Trau\u00b7er\u00b7klei\u00b7der", "an\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Rief sie mit einem Thr\u00e4nenbach:", "tokens": ["Rief", "sie", "mit", "ei\u00b7nem", "Thr\u00e4\u00b7nen\u00b7bach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O folgt ich doch nur bald ihm nach!", "tokens": ["O", "folgt", "ich", "doch", "nur", "bald", "ihm", "nach", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Der Mann der jungen Lesbia,", "tokens": ["Der", "Mann", "der", "jun\u00b7gen", "Les\u00b7bia", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Dem das verw\u00fcnschte Podagra", "tokens": ["Dem", "das", "ver\u00b7w\u00fcnschte", "Po\u00b7da\u00b7gra"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ART", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Die morschen Knochen krumm gebogen,", "tokens": ["Die", "mor\u00b7schen", "Kno\u00b7chen", "krumm", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wankt keuchend um sein Weib herum", "tokens": ["Wankt", "keu\u00b7chend", "um", "sein", "Weib", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und nennet sie sein Eigenthum.", "tokens": ["Und", "nen\u00b7net", "sie", "sein", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Blandin gelobt mir seine Gunst;", "tokens": ["Blan\u00b7din", "ge\u00b7lobt", "mir", "sei\u00b7ne", "Gunst", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Er, dessen glatte Redekunst", "tokens": ["Er", ",", "des\u00b7sen", "glat\u00b7te", "Re\u00b7de\u00b7kunst"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon oft den feinsten Schalk betrogen,", "tokens": ["Schon", "oft", "den", "feins\u00b7ten", "Schalk", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Versichert, als ein Biedermann,", "tokens": ["Ver\u00b7si\u00b7chert", ",", "als", "ein", "Bie\u00b7der\u00b7mann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Mich da\u00df er gar nicht l\u00fcgen kann.", "tokens": ["Mich", "da\u00df", "er", "gar", "nicht", "l\u00fc\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Faustin erh\u00e4lt ein Pastorat.", "tokens": ["Faus\u00b7tin", "er\u00b7h\u00e4lt", "ein", "Pas\u00b7to\u00b7rat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Geb\u00fcckt erscheint der Candidat", "tokens": ["Ge\u00b7b\u00fcckt", "er\u00b7scheint", "der", "Can\u00b7di\u00b7dat"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Zirkel grauer Theologen.", "tokens": ["Im", "Zir\u00b7kel", "grau\u00b7er", "Theo\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er glaubt kein Evangelium", "tokens": ["Er", "glaubt", "kein", "E\u00b7van\u00b7ge\u00b7li\u00b7um"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und schw\u00f6rt auf Luthers Symbolum.", "tokens": ["Und", "schw\u00f6rt", "auf", "Lu\u00b7thers", "Sym\u00b7bo\u00b7lum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Beate reicht die welke Hand", "tokens": ["Bea\u00b7te", "reicht", "die", "wel\u00b7ke", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch einem h\u00fcbschen jungen Fant.", "tokens": ["Noch", "ei\u00b7nem", "h\u00fcb\u00b7schen", "jun\u00b7gen", "Fant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was hat sie wohl dazu bewogen?", "tokens": ["Was", "hat", "sie", "wohl", "da\u00b7zu", "be\u00b7wo\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie spricht: des Menschen D\u00fcrftigkeit", "tokens": ["Sie", "spricht", ":", "des", "Men\u00b7schen", "D\u00fcrf\u00b7tig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und christliche Gelassenheit.", "tokens": ["Und", "christ\u00b7li\u00b7che", "Ge\u00b7las\u00b7sen\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Als Raps Besitz vom Erbe nahm,", "tokens": ["Als", "Raps", "Be\u00b7sitz", "vom", "Er\u00b7be", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das er vom Oheim Rips bekam,", "tokens": ["Das", "er", "vom", "O\u00b7heim", "Rips", "be\u00b7kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Rief er in lauten Monologen:", "tokens": ["Rief", "er", "in", "lau\u00b7ten", "Mo\u00b7no\u00b7lo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie gern verz\u00f6g ich auf sein Geld,", "tokens": ["Wie", "gern", "ver\u00b7z\u00f6g", "ich", "auf", "sein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "W\u00e4r er nur noch auf dieser Welt!", "tokens": ["W\u00e4r", "er", "nur", "noch", "auf", "die\u00b7ser", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.13": {"line.1": {"text": "Sejan, der bauchige Magnat,", "tokens": ["Se\u00b7jan", ",", "der", "bau\u00b7chi\u00b7ge", "Mag\u00b7nat", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der, einem Vampyr gleich, den Staat", "tokens": ["Der", ",", "ei\u00b7nem", "Vam\u00b7pyr", "gleich", ",", "den", "Staat"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "$,", "ART", "NN", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis auf das Herzblut ausgesogen,", "tokens": ["Bis", "auf", "das", "Herz\u00b7blut", "aus\u00b7ge\u00b7so\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "R\u00fchmt, da\u00df er f\u00fcr sein Vaterland", "tokens": ["R\u00fchmt", ",", "da\u00df", "er", "f\u00fcr", "sein", "Va\u00b7ter\u00b7land"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gut und Gesundheit aufgewandt.", "tokens": ["Gut", "und", "Ge\u00b7sund\u00b7heit", "auf\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.14": {"line.1": {"text": "Man hat dem Junker Leonhard", "tokens": ["Man", "hat", "dem", "Jun\u00b7ker", "Le\u00b7on\u00b7hard"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Heut seinen alten Knecht verscharrt,", "tokens": ["Heut", "sei\u00b7nen", "al\u00b7ten", "Knecht", "ver\u00b7scharrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem er die Bissen dargewogen.", "tokens": ["Dem", "er", "die", "Bis\u00b7sen", "dar\u00b7ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er sagt, da\u00df er den armen Wicht", "tokens": ["Er", "sagt", ",", "da\u00df", "er", "den", "ar\u00b7men", "Wicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu todt gef\u00fcttert, wie man spricht.", "tokens": ["Zu", "todt", "ge\u00b7f\u00fct\u00b7tert", ",", "wie", "man", "spricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVPP", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.15": {"line.1": {"text": "Um Clelien h\u00e4lt Lindor an;", "tokens": ["Um", "Cle\u00b7li\u00b7en", "h\u00e4lt", "Lin\u00b7dor", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er, der wie ein verliebter Hahn", "tokens": ["Er", ",", "der", "wie", "ein", "ver\u00b7lieb\u00b7ter", "Hahn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bisher von Weib zu Weib geflogen.", "tokens": ["Bis\u00b7her", "von", "Weib", "zu", "Weib", "ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er schw\u00f6rt beym Hymen, ihr allein", "tokens": ["Er", "schw\u00f6rt", "beym", "Hy\u00b7men", ",", "ihr", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis in das Grab getreu zu seyn.", "tokens": ["Bis", "in", "das", "Grab", "ge\u00b7treu", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Rufill, ein schwangerer Poet,", "tokens": ["Ru\u00b7fill", ",", "ein", "schwan\u00b7ge\u00b7rer", "Po\u00b7et", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gebahr ein Buch, in diesem steht", "tokens": ["Ge\u00b7bahr", "ein", "Buch", ",", "in", "die\u00b7sem", "steht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "APPR", "PDAT", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl dreymal auf dem ersten Bogen:", "tokens": ["Wohl", "drey\u00b7mal", "auf", "dem", "ers\u00b7ten", "Bo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ihn geneigter Kenner Rath", "tokens": ["Da\u00df", "ihn", "ge\u00b7neig\u00b7ter", "Ken\u00b7ner", "Rath"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu diesem Druck verleitet hat.", "tokens": ["Zu", "die\u00b7sem", "Druck", "ver\u00b7lei\u00b7tet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.17": {"line.1": {"text": "Als Phryne j\u00fcngst im Spiegelsaal", "tokens": ["Als", "Phry\u00b7ne", "j\u00fcngst", "im", "Spie\u00b7gel\u00b7saal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr ihren alten Ehgemahl", "tokens": ["F\u00fcr", "ih\u00b7ren", "al\u00b7ten", "Eh\u00b7ge\u00b7mahl"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Trauerkleider angezogen,", "tokens": ["Die", "Trau\u00b7er\u00b7klei\u00b7der", "an\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Rief sie mit einem Thr\u00e4nenbach:", "tokens": ["Rief", "sie", "mit", "ei\u00b7nem", "Thr\u00e4\u00b7nen\u00b7bach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O folgt ich doch nur bald ihm nach!", "tokens": ["O", "folgt", "ich", "doch", "nur", "bald", "ihm", "nach", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "Der Mann der jungen Lesbia,", "tokens": ["Der", "Mann", "der", "jun\u00b7gen", "Les\u00b7bia", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Dem das verw\u00fcnschte Podagra", "tokens": ["Dem", "das", "ver\u00b7w\u00fcnschte", "Po\u00b7da\u00b7gra"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ART", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Die morschen Knochen krumm gebogen,", "tokens": ["Die", "mor\u00b7schen", "Kno\u00b7chen", "krumm", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wankt keuchend um sein Weib herum", "tokens": ["Wankt", "keu\u00b7chend", "um", "sein", "Weib", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und nennet sie sein Eigenthum.", "tokens": ["Und", "nen\u00b7net", "sie", "sein", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.19": {"line.1": {"text": "Blandin gelobt mir seine Gunst;", "tokens": ["Blan\u00b7din", "ge\u00b7lobt", "mir", "sei\u00b7ne", "Gunst", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Er, dessen glatte Redekunst", "tokens": ["Er", ",", "des\u00b7sen", "glat\u00b7te", "Re\u00b7de\u00b7kunst"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon oft den feinsten Schalk betrogen,", "tokens": ["Schon", "oft", "den", "feins\u00b7ten", "Schalk", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Versichert, als ein Biedermann,", "tokens": ["Ver\u00b7si\u00b7chert", ",", "als", "ein", "Bie\u00b7der\u00b7mann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Mich da\u00df er gar nicht l\u00fcgen kann.", "tokens": ["Mich", "da\u00df", "er", "gar", "nicht", "l\u00fc\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.20": {"line.1": {"text": "Faustin erh\u00e4lt ein Pastorat.", "tokens": ["Faus\u00b7tin", "er\u00b7h\u00e4lt", "ein", "Pas\u00b7to\u00b7rat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Geb\u00fcckt erscheint der Candidat", "tokens": ["Ge\u00b7b\u00fcckt", "er\u00b7scheint", "der", "Can\u00b7di\u00b7dat"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Zirkel grauer Theologen.", "tokens": ["Im", "Zir\u00b7kel", "grau\u00b7er", "Theo\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er glaubt kein Evangelium", "tokens": ["Er", "glaubt", "kein", "E\u00b7van\u00b7ge\u00b7li\u00b7um"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und schw\u00f6rt auf Luthers Symbolum.", "tokens": ["Und", "schw\u00f6rt", "auf", "Lu\u00b7thers", "Sym\u00b7bo\u00b7lum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hei\u00dft gelogen.", "tokens": ["Das", "hei\u00dft", "ge\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}