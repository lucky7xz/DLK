{"textgrid.poem.24248": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Der patriotische Holl\u00e4nder", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man hatte sich mit allen guten Dingen", "tokens": ["Man", "hat\u00b7te", "sich", "mit", "al\u00b7len", "gu\u00b7ten", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PRF", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So vollgestopft, wie man es mu\u00df,", "tokens": ["So", "voll\u00b7ge\u00b7stopft", ",", "wie", "man", "es", "mu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "PWAV", "PIS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn die Ern\u00e4hrung soll gelingen;", "tokens": ["Wenn", "die", "Er\u00b7n\u00e4h\u00b7rung", "soll", "ge\u00b7lin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Voll war man, voll bis zum Zerspringen,", "tokens": ["Voll", "war", "man", ",", "voll", "bis", "zum", "Zer\u00b7sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PIS", "$,", "ADJD", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Atem sah man schon die Kinder ringen,", "tokens": ["Nach", "A\u00b7tem", "sah", "man", "schon", "die", "Kin\u00b7der", "rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da rief der Hausherr: \u00bbNun der Magenschlu\u00df!", "tokens": ["Da", "rief", "der", "Haus\u00b7herr", ":", "\u00bb", "Nun", "der", "Ma\u00b7gen\u00b7schlu\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Resi soll den K\u00e4se bringen!\u00ab", "tokens": ["Die", "Re\u00b7si", "soll", "den", "K\u00e4\u00b7se", "brin\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die Resi kam. Wie war sie bla\u00df.", "tokens": ["Die", "Re\u00b7si", "kam", ".", "Wie", "war", "sie", "bla\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWAV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Hausfrau rief: \u00bbWas ist denn das?", "tokens": ["Die", "Haus\u00b7frau", "rief", ":", "\u00bb", "Was", "ist", "denn", "das", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PWS", "VAFIN", "ADV", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Reicht man den K\u00e4se ohne Glocke?!\u00ab", "tokens": ["Reicht", "man", "den", "K\u00e4\u00b7se", "oh\u00b7ne", "Glo\u00b7cke", "?!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "APPR", "NN", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "\u2013 \u00bbAch gn\u00e4dge Frau!\u00ab rief Resi, \u00bbach!", "tokens": ["\u2013", "\u00bb", "Ach", "gn\u00e4d\u00b7ge", "Frau", "!", "\u00ab", "rief", "Re\u00b7si", ",", "\u00bb", "ach", "!"], "token_info": ["punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "$(", "ITJ", "ADJA", "NN", "$.", "$(", "VVFIN", "NE", "$,", "$(", "ITJ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es tat auf einmal einen Krach,", "tokens": ["Es", "tat", "auf", "ein\u00b7mal", "ei\u00b7nen", "Krach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da war sie ...\u00ab \u2013 \u00bbUngeschickte Docke!\u00ab", "tokens": ["Da", "war", "sie", "...", "\u00ab", "\u2013", "\u00bb", "Un\u00b7ge\u00b7schick\u00b7te", "Do\u00b7cke", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "$(", "$(", "$(", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Erwiderte die Hausfrau drauf,", "tokens": ["Er\u00b7wi\u00b7der\u00b7te", "die", "Haus\u00b7frau", "drauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbso geh und kauf", "tokens": ["\u00bb", "so", "geh", "und", "kauf"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "ne andre, aber, bitte, eine,", "tokens": ["ne", "and\u00b7re", ",", "a\u00b7ber", ",", "bit\u00b7te", ",", "ei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADJA", "$,", "ADV", "$,", "PTKANT", "$,", "ART", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Nimmt Resi untern Arm und rennt.", "tokens": ["Nimmt", "Re\u00b7si", "un\u00b7tern", "Arm", "und", "rennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "W\u00e4r die Geschichte jetzt am End,", "tokens": ["W\u00e4r", "die", "Ge\u00b7schich\u00b7te", "jetzt", "am", "End", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So w\u00e4r es keine.", "tokens": ["So", "w\u00e4r", "es", "kei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Doch, denken Sie! Nach einer Stunde", "tokens": ["Doch", ",", "den\u00b7ken", "Sie", "!", "Nach", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "VVFIN", "PPER", "$.", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Erscheint mit schreckenschiefem Munde", "tokens": ["Er\u00b7scheint", "mit", "schre\u00b7cken\u00b7schie\u00b7fem", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Besagte Resi. Ihr Geschrei", "tokens": ["Be\u00b7sag\u00b7te", "Re\u00b7si", ".", "Ihr", "Ge\u00b7schrei"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "NE", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verk\u00fcndet: \u00bbGn\u00e4dge Frau! Entzwei", "tokens": ["Ver\u00b7k\u00fcn\u00b7det", ":", "\u00bb", "Gn\u00e4d\u00b7ge", "Frau", "!", "Ent\u00b7zwei"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["VVPP", "$.", "$(", "ADJA", "NN", "$.", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist auch die zweite Glocke!", "tokens": ["Ist", "auch", "die", "zwei\u00b7te", "Glo\u00b7cke", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ich bin ", "tokens": ["Ich", "bin"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Die Gn\u00e4dge sieht sie flammend an", "tokens": ["Die", "Gn\u00e4d\u00b7ge", "sieht", "sie", "flam\u00b7mend", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und hei\u00dft sie ", "tokens": ["Und", "hei\u00dft", "sie"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "\u00bbdu tust das, scheint mir, zum Pl\u00e4sier!", "tokens": ["\u00bb", "du", "tust", "das", ",", "scheint", "mir", ",", "zum", "Pl\u00e4\u00b7sier", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PDS", "$,", "VVFIN", "PPER", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+++", "measure": "unknown.measure.penta"}, "line.10": {"text": "Schweig! sag ich ... Und ", "tokens": ["Schweig", "!", "sag", "ich", "...", "Und"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "$.", "VVFIN", "PPER", "$(", "KON"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Pa\u00df auf! Sonst! ... O! Ist es zu sagen?!", "tokens": ["Pa\u00df", "auf", "!", "Sonst", "!", "...", "O", "!", "Ist", "es", "zu", "sa\u00b7gen", "?!"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "NN", "$.", "$(", "NE", "$.", "VAFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Hol eine andre!\u00ab \u2013 Ihre Beine", "tokens": ["Hol", "ei\u00b7ne", "and\u00b7re", "!", "\u00ab", "\u2013", "Ih\u00b7re", "Bei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word"], "pos": ["NN", "ART", "ADJA", "$.", "$(", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Nimmt Resi untern Arm und rennt.", "tokens": ["Nimmt", "Re\u00b7si", "un\u00b7tern", "Arm", "und", "rennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "W\u00e4r die Geschichte hier am End,", "tokens": ["W\u00e4r", "die", "Ge\u00b7schich\u00b7te", "hier", "am", "End", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So war es immer noch wohl keine.", "tokens": ["So", "war", "es", "im\u00b7mer", "noch", "wohl", "kei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.4": {"text": "Das Abendessen ist serviert,", "tokens": ["Das", "A\u00b7ben\u00b7des\u00b7sen", "ist", "ser\u00b7viert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie lieblich lockt die kalte Platte,", "tokens": ["Wie", "lieb\u00b7lich", "lockt", "die", "kal\u00b7te", "Plat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Petersilie sch\u00f6n garniert,", "tokens": ["Mit", "Pe\u00b7ter\u00b7si\u00b7lie", "sch\u00f6n", "gar\u00b7niert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die schon dasselbe Amt beim Mittagsbraten hatte.", "tokens": ["Die", "schon", "das\u00b7sel\u00b7be", "Amt", "beim", "Mit\u00b7tags\u00b7bra\u00b7ten", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PDAT", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nur eines fehlt: der K\u00e4se ist nicht da.", "tokens": ["Nur", "ei\u00b7nes", "fehlt", ":", "der", "K\u00e4\u00b7se", "ist", "nicht", "da", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "$.", "ART", "NN", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbich sagte doch, Veronika,\u00ab", "tokens": ["\u00bb", "ich", "sag\u00b7te", "doch", ",", "Ve\u00b7ro\u00b7ni\u00b7ka", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "$,", "NE", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bemerkt der Hausherr mit Verdru\u00df,", "tokens": ["Be\u00b7merkt", "der", "Haus\u00b7herr", "mit", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "\u00bbes soll und mu\u00df", "tokens": ["\u00bb", "es", "soll", "und", "mu\u00df"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "KON", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Stets K\u00e4se auf dem Tische sein!", "tokens": ["Stets", "K\u00e4\u00b7se", "auf", "dem", "Ti\u00b7sche", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Mu\u00df man denn jeden Tag dasselbe sagen?\u00ab", "tokens": ["Mu\u00df", "man", "denn", "je\u00b7den", "Tag", "das\u00b7sel\u00b7be", "sa\u00b7gen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PIAT", "NN", "PDAT", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die Gn\u00e4dge klingelt, Resi wankt herein;", "tokens": ["Die", "Gn\u00e4d\u00b7ge", "klin\u00b7gelt", ",", "Re\u00b7si", "wankt", "her\u00b7ein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NE", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Man sieht ihr an, wie ihre Pulse schlagen.", "tokens": ["Man", "sieht", "ihr", "an", ",", "wie", "ih\u00b7re", "Pul\u00b7se", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Da str\u00e4ubt der Gn\u00e4digen sich selbst das ", "tokens": ["Da", "str\u00e4ubt", "der", "Gn\u00e4\u00b7di\u00b7gen", "sich", "selbst", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "ADV", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihr beredter Mund hat keine Worte.", "tokens": ["Und", "ihr", "be\u00b7red\u00b7ter", "Mund", "hat", "kei\u00b7ne", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbwie!?!\u00ab ruft sie endlich, \u00bbtust du mirs zum ", "tokens": ["\u00bb", "wie", "!?!", "\u00ab", "ruft", "sie", "end\u00b7lich", ",", "\u00bb", "tust", "du", "mirs", "zum"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "$.", "$(", "VVFIN", "PPER", "ADV", "$,", "$(", "VVFIN", "PPER", "NE", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "O die Verworfne! ", "tokens": ["O", "die", "Ver\u00b7worf\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Das halte aus, wers kann und mag!", "tokens": ["Das", "hal\u00b7te", "aus", ",", "wers", "kann", "und", "mag", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "$,", "PWS", "VMFIN", "KON", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und will der Ungl\u00fcckseligen ins Gesicht,", "tokens": ["Und", "will", "der", "Un\u00b7gl\u00fcck\u00b7se\u00b7li\u00b7gen", "ins", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "So scheint es, h\u00f6chst pers\u00f6nlich springen.", "tokens": ["So", "scheint", "es", ",", "h\u00f6chst", "per\u00b7s\u00f6n\u00b7lich", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Da hebt ein wunderliches Klingen", "tokens": ["Da", "hebt", "ein", "wun\u00b7der\u00b7li\u00b7ches", "Klin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich wie von \u00c4olsharfen durch die L\u00fcfte,", "tokens": ["Sich", "wie", "von", "\u00c4\u00b7ols\u00b7har\u00b7fen", "durch", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KOKOM", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und unter s\u00fc\u00df diskretem Rahmged\u00fcfte", "tokens": ["Und", "un\u00b7ter", "s\u00fc\u00df", "dis\u00b7kre\u00b7tem", "Rahm\u00b7ge\u00b7d\u00fcf\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der rot geschminkte Edamk\u00e4se spricht:", "tokens": ["Der", "rot", "ge\u00b7schmink\u00b7te", "E\u00b7dam\u00b7k\u00e4\u00b7se", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbentschuldgen Sie, wenn ich das Wort ergreife,", "tokens": ["\u00bb", "ent\u00b7schuld\u00b7gen", "Sie", ",", "wenn", "ich", "das", "Wort", "er\u00b7grei\u00b7fe", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das meiner Art sonst nicht gegeben ist.", "tokens": ["Das", "mei\u00b7ner", "Art", "sonst", "nicht", "ge\u00b7ge\u00b7ben", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich bin ein K\u00e4se von vollkommner Reife,", "tokens": ["Ich", "bin", "ein", "K\u00e4\u00b7se", "von", "voll\u00b7komm\u00b7ner", "Rei\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Daher der Ruhe hold und feind dem Zwist,", "tokens": ["Da\u00b7her", "der", "Ru\u00b7he", "hold", "und", "feind", "dem", "Zwist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein Sohn des Landes, wo aus Ton die Pfeife", "tokens": ["Ein", "Sohn", "des", "Lan\u00b7des", ",", "wo", "aus", "Ton", "die", "Pfei\u00b7fe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PWAV", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und jeder Mensch ein tadelloser Christ!", "tokens": ["Und", "je\u00b7der", "Mensch", "ein", "ta\u00b7del\u00b7lo\u00b7ser", "Christ", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Weshalb es mir unm\u00f6glich ist, zu schweigen,", "tokens": ["We\u00b7shalb", "es", "mir", "un\u00b7m\u00f6g\u00b7lich", "ist", ",", "zu", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADJD", "VAFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wo Unschuld soll das Haupt der Strafe neigen,", "tokens": ["Wo", "Un\u00b7schuld", "soll", "das", "Haupt", "der", "Stra\u00b7fe", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VMFIN", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Drum, kurz und gut, Madam, ", "tokens": ["Drum", ",", "kurz", "und", "gut", ",", "Ma\u00b7dam", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "$,", "ADJD", "KON", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Der die drei Glocken leider hat zerschlagen,", "tokens": ["Der", "die", "drei", "Glo\u00b7cken", "lei\u00b7der", "hat", "zer\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "CARD", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und zur Entschuldigung kann ich nur sagen,", "tokens": ["Und", "zur", "Ent\u00b7schul\u00b7di\u00b7gung", "kann", "ich", "nur", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.16": {"text": "Ich tats als Patriot, nicht l\u00e4sterlich.", "tokens": ["Ich", "tats", "als", "Pat\u00b7ri\u00b7ot", ",", "nicht", "l\u00e4s\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "NN", "$,", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ich sprang vor ", "tokens": ["Ich", "sprang", "vor"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Der Patriot in mir wars, ders zu tun mich hie\u00df.", "tokens": ["Der", "Pat\u00b7ri\u00b7ot", "in", "mir", "wars", ",", "ders", "zu", "tun", "mich", "hie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "$,", "PRELS", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich w\u00e4r nicht wert, da\u00df diese Lampe mich beschiene,", "tokens": ["Ich", "w\u00e4r", "nicht", "wert", ",", "da\u00df", "die\u00b7se", "Lam\u00b7pe", "mich", "be\u00b7schie\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PDAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Spr\u00e4ng ich nicht heute hoch als edler Patriot\u00ab", "tokens": ["Spr\u00e4ng", "ich", "nicht", "heu\u00b7te", "hoch", "als", "ed\u00b7ler", "Pat\u00b7ri\u00b7ot", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "KOKOM", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "(hier sprang er wiederum, gleich einer Ballerine,", "tokens": ["(", "hier", "sprang", "er", "wie\u00b7de\u00b7rum", ",", "gleich", "ei\u00b7ner", "Bal\u00b7le\u00b7ri\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was einen wirklich sch\u00f6nen Anblick bot;", "tokens": ["Was", "ei\u00b7nen", "wirk\u00b7lich", "sch\u00f6\u00b7nen", "An\u00b7blick", "bot", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Bewundernd klirrten Ma\u00dfkrug und Terrine),", "tokens": ["Be\u00b7wun\u00b7dernd", "klirr\u00b7ten", "Ma\u00df\u00b7krug", "und", "Ter\u00b7ri\u00b7ne", ")", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "VVFIN", "NN", "KON", "NE", "$(", "$,"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "\u00bbheut ist vor ", "tokens": ["\u00bb", "heut", "ist", "vor"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Heut ist der Hochzeitstag von \u203aunsrer Wilhelmine\u2039!\u00ab", "tokens": ["Heut", "ist", "der", "Hoch\u00b7zeits\u00b7tag", "von", "\u203a", "uns\u00b7rer", "Wil\u00b7hel\u00b7mi\u00b7ne", "\u2039", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "$(", "PPOSAT", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Man hatte sich mit allen guten Dingen", "tokens": ["Man", "hat\u00b7te", "sich", "mit", "al\u00b7len", "gu\u00b7ten", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PRF", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So vollgestopft, wie man es mu\u00df,", "tokens": ["So", "voll\u00b7ge\u00b7stopft", ",", "wie", "man", "es", "mu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "PWAV", "PIS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn die Ern\u00e4hrung soll gelingen;", "tokens": ["Wenn", "die", "Er\u00b7n\u00e4h\u00b7rung", "soll", "ge\u00b7lin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Voll war man, voll bis zum Zerspringen,", "tokens": ["Voll", "war", "man", ",", "voll", "bis", "zum", "Zer\u00b7sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PIS", "$,", "ADJD", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Atem sah man schon die Kinder ringen,", "tokens": ["Nach", "A\u00b7tem", "sah", "man", "schon", "die", "Kin\u00b7der", "rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da rief der Hausherr: \u00bbNun der Magenschlu\u00df!", "tokens": ["Da", "rief", "der", "Haus\u00b7herr", ":", "\u00bb", "Nun", "der", "Ma\u00b7gen\u00b7schlu\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Resi soll den K\u00e4se bringen!\u00ab", "tokens": ["Die", "Re\u00b7si", "soll", "den", "K\u00e4\u00b7se", "brin\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die Resi kam. Wie war sie bla\u00df.", "tokens": ["Die", "Re\u00b7si", "kam", ".", "Wie", "war", "sie", "bla\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWAV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Hausfrau rief: \u00bbWas ist denn das?", "tokens": ["Die", "Haus\u00b7frau", "rief", ":", "\u00bb", "Was", "ist", "denn", "das", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PWS", "VAFIN", "ADV", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Reicht man den K\u00e4se ohne Glocke?!\u00ab", "tokens": ["Reicht", "man", "den", "K\u00e4\u00b7se", "oh\u00b7ne", "Glo\u00b7cke", "?!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "APPR", "NN", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "\u2013 \u00bbAch gn\u00e4dge Frau!\u00ab rief Resi, \u00bbach!", "tokens": ["\u2013", "\u00bb", "Ach", "gn\u00e4d\u00b7ge", "Frau", "!", "\u00ab", "rief", "Re\u00b7si", ",", "\u00bb", "ach", "!"], "token_info": ["punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "$(", "ITJ", "ADJA", "NN", "$.", "$(", "VVFIN", "NE", "$,", "$(", "ITJ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es tat auf einmal einen Krach,", "tokens": ["Es", "tat", "auf", "ein\u00b7mal", "ei\u00b7nen", "Krach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da war sie ...\u00ab \u2013 \u00bbUngeschickte Docke!\u00ab", "tokens": ["Da", "war", "sie", "...", "\u00ab", "\u2013", "\u00bb", "Un\u00b7ge\u00b7schick\u00b7te", "Do\u00b7cke", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$(", "$(", "$(", "$(", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Erwiderte die Hausfrau drauf,", "tokens": ["Er\u00b7wi\u00b7der\u00b7te", "die", "Haus\u00b7frau", "drauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbso geh und kauf", "tokens": ["\u00bb", "so", "geh", "und", "kauf"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "ne andre, aber, bitte, eine,", "tokens": ["ne", "and\u00b7re", ",", "a\u00b7ber", ",", "bit\u00b7te", ",", "ei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "ADJA", "$,", "ADV", "$,", "PTKANT", "$,", "ART", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Nimmt Resi untern Arm und rennt.", "tokens": ["Nimmt", "Re\u00b7si", "un\u00b7tern", "Arm", "und", "rennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "W\u00e4r die Geschichte jetzt am End,", "tokens": ["W\u00e4r", "die", "Ge\u00b7schich\u00b7te", "jetzt", "am", "End", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So w\u00e4r es keine.", "tokens": ["So", "w\u00e4r", "es", "kei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Doch, denken Sie! Nach einer Stunde", "tokens": ["Doch", ",", "den\u00b7ken", "Sie", "!", "Nach", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "VVFIN", "PPER", "$.", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Erscheint mit schreckenschiefem Munde", "tokens": ["Er\u00b7scheint", "mit", "schre\u00b7cken\u00b7schie\u00b7fem", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Besagte Resi. Ihr Geschrei", "tokens": ["Be\u00b7sag\u00b7te", "Re\u00b7si", ".", "Ihr", "Ge\u00b7schrei"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "NE", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verk\u00fcndet: \u00bbGn\u00e4dge Frau! Entzwei", "tokens": ["Ver\u00b7k\u00fcn\u00b7det", ":", "\u00bb", "Gn\u00e4d\u00b7ge", "Frau", "!", "Ent\u00b7zwei"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["VVPP", "$.", "$(", "ADJA", "NN", "$.", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist auch die zweite Glocke!", "tokens": ["Ist", "auch", "die", "zwei\u00b7te", "Glo\u00b7cke", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ich bin ", "tokens": ["Ich", "bin"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Die Gn\u00e4dge sieht sie flammend an", "tokens": ["Die", "Gn\u00e4d\u00b7ge", "sieht", "sie", "flam\u00b7mend", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und hei\u00dft sie ", "tokens": ["Und", "hei\u00dft", "sie"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "\u00bbdu tust das, scheint mir, zum Pl\u00e4sier!", "tokens": ["\u00bb", "du", "tust", "das", ",", "scheint", "mir", ",", "zum", "Pl\u00e4\u00b7sier", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PDS", "$,", "VVFIN", "PPER", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+++", "measure": "unknown.measure.penta"}, "line.10": {"text": "Schweig! sag ich ... Und ", "tokens": ["Schweig", "!", "sag", "ich", "...", "Und"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "$.", "VVFIN", "PPER", "$(", "KON"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Pa\u00df auf! Sonst! ... O! Ist es zu sagen?!", "tokens": ["Pa\u00df", "auf", "!", "Sonst", "!", "...", "O", "!", "Ist", "es", "zu", "sa\u00b7gen", "?!"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "NN", "$.", "$(", "NE", "$.", "VAFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Hol eine andre!\u00ab \u2013 Ihre Beine", "tokens": ["Hol", "ei\u00b7ne", "and\u00b7re", "!", "\u00ab", "\u2013", "Ih\u00b7re", "Bei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word"], "pos": ["NN", "ART", "ADJA", "$.", "$(", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Nimmt Resi untern Arm und rennt.", "tokens": ["Nimmt", "Re\u00b7si", "un\u00b7tern", "Arm", "und", "rennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "W\u00e4r die Geschichte hier am End,", "tokens": ["W\u00e4r", "die", "Ge\u00b7schich\u00b7te", "hier", "am", "End", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So war es immer noch wohl keine.", "tokens": ["So", "war", "es", "im\u00b7mer", "noch", "wohl", "kei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.4": {"text": "Das Abendessen ist serviert,", "tokens": ["Das", "A\u00b7ben\u00b7des\u00b7sen", "ist", "ser\u00b7viert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie lieblich lockt die kalte Platte,", "tokens": ["Wie", "lieb\u00b7lich", "lockt", "die", "kal\u00b7te", "Plat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Petersilie sch\u00f6n garniert,", "tokens": ["Mit", "Pe\u00b7ter\u00b7si\u00b7lie", "sch\u00f6n", "gar\u00b7niert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die schon dasselbe Amt beim Mittagsbraten hatte.", "tokens": ["Die", "schon", "das\u00b7sel\u00b7be", "Amt", "beim", "Mit\u00b7tags\u00b7bra\u00b7ten", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PDAT", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nur eines fehlt: der K\u00e4se ist nicht da.", "tokens": ["Nur", "ei\u00b7nes", "fehlt", ":", "der", "K\u00e4\u00b7se", "ist", "nicht", "da", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "$.", "ART", "NN", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbich sagte doch, Veronika,\u00ab", "tokens": ["\u00bb", "ich", "sag\u00b7te", "doch", ",", "Ve\u00b7ro\u00b7ni\u00b7ka", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "$,", "NE", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bemerkt der Hausherr mit Verdru\u00df,", "tokens": ["Be\u00b7merkt", "der", "Haus\u00b7herr", "mit", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "\u00bbes soll und mu\u00df", "tokens": ["\u00bb", "es", "soll", "und", "mu\u00df"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "KON", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Stets K\u00e4se auf dem Tische sein!", "tokens": ["Stets", "K\u00e4\u00b7se", "auf", "dem", "Ti\u00b7sche", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Mu\u00df man denn jeden Tag dasselbe sagen?\u00ab", "tokens": ["Mu\u00df", "man", "denn", "je\u00b7den", "Tag", "das\u00b7sel\u00b7be", "sa\u00b7gen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PIS", "ADV", "PIAT", "NN", "PDAT", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die Gn\u00e4dge klingelt, Resi wankt herein;", "tokens": ["Die", "Gn\u00e4d\u00b7ge", "klin\u00b7gelt", ",", "Re\u00b7si", "wankt", "her\u00b7ein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NE", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Man sieht ihr an, wie ihre Pulse schlagen.", "tokens": ["Man", "sieht", "ihr", "an", ",", "wie", "ih\u00b7re", "Pul\u00b7se", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Da str\u00e4ubt der Gn\u00e4digen sich selbst das ", "tokens": ["Da", "str\u00e4ubt", "der", "Gn\u00e4\u00b7di\u00b7gen", "sich", "selbst", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "ADV", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihr beredter Mund hat keine Worte.", "tokens": ["Und", "ihr", "be\u00b7red\u00b7ter", "Mund", "hat", "kei\u00b7ne", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbwie!?!\u00ab ruft sie endlich, \u00bbtust du mirs zum ", "tokens": ["\u00bb", "wie", "!?!", "\u00ab", "ruft", "sie", "end\u00b7lich", ",", "\u00bb", "tust", "du", "mirs", "zum"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "$.", "$(", "VVFIN", "PPER", "ADV", "$,", "$(", "VVFIN", "PPER", "NE", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "O die Verworfne! ", "tokens": ["O", "die", "Ver\u00b7worf\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Das halte aus, wers kann und mag!", "tokens": ["Das", "hal\u00b7te", "aus", ",", "wers", "kann", "und", "mag", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "$,", "PWS", "VMFIN", "KON", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und will der Ungl\u00fcckseligen ins Gesicht,", "tokens": ["Und", "will", "der", "Un\u00b7gl\u00fcck\u00b7se\u00b7li\u00b7gen", "ins", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "So scheint es, h\u00f6chst pers\u00f6nlich springen.", "tokens": ["So", "scheint", "es", ",", "h\u00f6chst", "per\u00b7s\u00f6n\u00b7lich", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Da hebt ein wunderliches Klingen", "tokens": ["Da", "hebt", "ein", "wun\u00b7der\u00b7li\u00b7ches", "Klin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich wie von \u00c4olsharfen durch die L\u00fcfte,", "tokens": ["Sich", "wie", "von", "\u00c4\u00b7ols\u00b7har\u00b7fen", "durch", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KOKOM", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und unter s\u00fc\u00df diskretem Rahmged\u00fcfte", "tokens": ["Und", "un\u00b7ter", "s\u00fc\u00df", "dis\u00b7kre\u00b7tem", "Rahm\u00b7ge\u00b7d\u00fcf\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der rot geschminkte Edamk\u00e4se spricht:", "tokens": ["Der", "rot", "ge\u00b7schmink\u00b7te", "E\u00b7dam\u00b7k\u00e4\u00b7se", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbentschuldgen Sie, wenn ich das Wort ergreife,", "tokens": ["\u00bb", "ent\u00b7schuld\u00b7gen", "Sie", ",", "wenn", "ich", "das", "Wort", "er\u00b7grei\u00b7fe", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das meiner Art sonst nicht gegeben ist.", "tokens": ["Das", "mei\u00b7ner", "Art", "sonst", "nicht", "ge\u00b7ge\u00b7ben", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich bin ein K\u00e4se von vollkommner Reife,", "tokens": ["Ich", "bin", "ein", "K\u00e4\u00b7se", "von", "voll\u00b7komm\u00b7ner", "Rei\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Daher der Ruhe hold und feind dem Zwist,", "tokens": ["Da\u00b7her", "der", "Ru\u00b7he", "hold", "und", "feind", "dem", "Zwist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein Sohn des Landes, wo aus Ton die Pfeife", "tokens": ["Ein", "Sohn", "des", "Lan\u00b7des", ",", "wo", "aus", "Ton", "die", "Pfei\u00b7fe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PWAV", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und jeder Mensch ein tadelloser Christ!", "tokens": ["Und", "je\u00b7der", "Mensch", "ein", "ta\u00b7del\u00b7lo\u00b7ser", "Christ", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Weshalb es mir unm\u00f6glich ist, zu schweigen,", "tokens": ["We\u00b7shalb", "es", "mir", "un\u00b7m\u00f6g\u00b7lich", "ist", ",", "zu", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADJD", "VAFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wo Unschuld soll das Haupt der Strafe neigen,", "tokens": ["Wo", "Un\u00b7schuld", "soll", "das", "Haupt", "der", "Stra\u00b7fe", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VMFIN", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Drum, kurz und gut, Madam, ", "tokens": ["Drum", ",", "kurz", "und", "gut", ",", "Ma\u00b7dam", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "$,", "ADJD", "KON", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Der die drei Glocken leider hat zerschlagen,", "tokens": ["Der", "die", "drei", "Glo\u00b7cken", "lei\u00b7der", "hat", "zer\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "CARD", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und zur Entschuldigung kann ich nur sagen,", "tokens": ["Und", "zur", "Ent\u00b7schul\u00b7di\u00b7gung", "kann", "ich", "nur", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.16": {"text": "Ich tats als Patriot, nicht l\u00e4sterlich.", "tokens": ["Ich", "tats", "als", "Pat\u00b7ri\u00b7ot", ",", "nicht", "l\u00e4s\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "NN", "$,", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Ich sprang vor ", "tokens": ["Ich", "sprang", "vor"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Der Patriot in mir wars, ders zu tun mich hie\u00df.", "tokens": ["Der", "Pat\u00b7ri\u00b7ot", "in", "mir", "wars", ",", "ders", "zu", "tun", "mich", "hie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "$,", "PRELS", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich w\u00e4r nicht wert, da\u00df diese Lampe mich beschiene,", "tokens": ["Ich", "w\u00e4r", "nicht", "wert", ",", "da\u00df", "die\u00b7se", "Lam\u00b7pe", "mich", "be\u00b7schie\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PDAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Spr\u00e4ng ich nicht heute hoch als edler Patriot\u00ab", "tokens": ["Spr\u00e4ng", "ich", "nicht", "heu\u00b7te", "hoch", "als", "ed\u00b7ler", "Pat\u00b7ri\u00b7ot", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "KOKOM", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "(hier sprang er wiederum, gleich einer Ballerine,", "tokens": ["(", "hier", "sprang", "er", "wie\u00b7de\u00b7rum", ",", "gleich", "ei\u00b7ner", "Bal\u00b7le\u00b7ri\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was einen wirklich sch\u00f6nen Anblick bot;", "tokens": ["Was", "ei\u00b7nen", "wirk\u00b7lich", "sch\u00f6\u00b7nen", "An\u00b7blick", "bot", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Bewundernd klirrten Ma\u00dfkrug und Terrine),", "tokens": ["Be\u00b7wun\u00b7dernd", "klirr\u00b7ten", "Ma\u00df\u00b7krug", "und", "Ter\u00b7ri\u00b7ne", ")", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "VVFIN", "NN", "KON", "NE", "$(", "$,"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "\u00bbheut ist vor ", "tokens": ["\u00bb", "heut", "ist", "vor"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Heut ist der Hochzeitstag von \u203aunsrer Wilhelmine\u2039!\u00ab", "tokens": ["Heut", "ist", "der", "Hoch\u00b7zeits\u00b7tag", "von", "\u203a", "uns\u00b7rer", "Wil\u00b7hel\u00b7mi\u00b7ne", "\u2039", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "$(", "PPOSAT", "NN", "$(", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}