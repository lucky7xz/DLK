{"dta.poem.13095": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "Achtes Buch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20535-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "\u201eso bauet, mahlt und schnizt! h\u00f6rt aber auch mein Wort,", "tokens": ["\u201e", "so", "bau\u00b7et", ",", "mahlt", "und", "schnizt", "!", "h\u00f6rt", "a\u00b7ber", "auch", "mein", "Wort", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$.", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201ehernach r\u00fchmt was ihr wollt, schnizt, mahlt und bauet fort!", "tokens": ["\u201e", "her\u00b7nach", "r\u00fchmt", "was", "ihr", "wollt", ",", "schnizt", ",", "mahlt", "und", "bau\u00b7et", "fort", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PWS", "PPER", "VMFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "295\u201dWas ist vom Anbeginn der Kunst in Schutt begraben,", "tokens": ["\"", "Was", "ist", "vom", "An\u00b7be\u00b7ginn", "der", "Kunst", "in", "Schutt", "be\u00b7gra\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "APPRART", "NN", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ewovon wir doch bi\u00df jezt bew\u00e4hrte Nachricht haben?", "tokens": ["\u201e", "wo\u00b7von", "wir", "doch", "bi\u00df", "jezt", "be\u00b7w\u00e4hr\u00b7te", "Nach\u00b7richt", "ha\u00b7ben", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ADV", "ADV", "ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201ewie drang es aus dem Rost des Alterthums hervor,", "tokens": ["\u201e", "wie", "drang", "es", "aus", "dem", "Rost", "des", "Al\u00b7ter\u00b7thums", "her\u00b7vor", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201ein dessen Staub es fast den Nahmen selbst verlohr?", "tokens": ["\u201e", "in", "des\u00b7sen", "Staub", "es", "fast", "den", "Nah\u00b7men", "selbst", "ver\u00b7lohr", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PRELAT", "NN", "PPER", "ADV", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201ewie wi\u00dft ihr was es war? ich! ich hab es gef\u00fcget,", "tokens": ["\u201e", "wie", "wi\u00dft", "ihr", "was", "es", "war", "?", "ich", "!", "ich", "hab", "es", "ge\u00b7f\u00fc\u00b7get", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "PWS", "PPER", "VAFIN", "$.", "PPER", "$.", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "300\u201dDa\u00df, was zu selber Zeit gefiel, noch heut vergn\u00fcget.", "tokens": ["\"", "Da\u00df", ",", "was", "zu", "sel\u00b7ber", "Zeit", "ge\u00b7fiel", ",", "noch", "heut", "ver\u00b7gn\u00fc\u00b7get", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201ewie schwebte die Geschicht von mancher Helden That", "tokens": ["\u201e", "wie", "schweb\u00b7te", "die", "Ge\u00b7schicht", "von", "man\u00b7cher", "Hel\u00b7den", "That"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ein Unvergessenheit? was sag\u2019 ich? manche Stadt,", "tokens": ["\u201e", "in", "Un\u00b7ver\u00b7ges\u00b7sen\u00b7heit", "?", "was", "sag'", "ich", "?", "man\u00b7che", "Stadt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$.", "PWS", "VVFIN", "PPER", "$.", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201ewas w\u00fc\u00dftet ihr davon, wann meiner Sayten Klingen", "tokens": ["\u201e", "was", "w\u00fc\u00df\u00b7tet", "ihr", "da\u00b7von", ",", "wann", "mei\u00b7ner", "Say\u00b7ten", "Klin\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PAV", "$,", "PWAV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201esich nicht beflissen h\u00e4tt euch solche vorzusingen?", "tokens": ["\u201e", "sich", "nicht", "be\u00b7flis\u00b7sen", "h\u00e4tt", "euch", "sol\u00b7che", "vor\u00b7zu\u00b7sin\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRF", "PTKNEG", "VVPP", "VAFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "305\u201dWer wu\u00dfte von dem Krieg, von der und jener Schlacht?", "tokens": ["\"", "Wer", "wu\u00df\u00b7te", "von", "dem", "Krieg", ",", "von", "der", "und", "je\u00b7ner", "Schlacht", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "APPR", "ART", "NN", "$,", "APPR", "ART", "KON", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201evon jener V\u00f6lcker Prei\u00df, Verrichtung, Staat und Macht", "tokens": ["\u201e", "von", "je\u00b7ner", "V\u00f6l\u00b7cker", "Prei\u00df", ",", "Ver\u00b7rich\u00b7tung", ",", "Staat", "und", "Macht"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "APPR", "PDAT", "NN", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201edie bey dem Urbeginn der Helden-Zeit gewesen?", "tokens": ["\u201e", "die", "bey", "dem", "Ur\u00b7be\u00b7ginn", "der", "Hel\u00b7den\u00b7Zeit", "ge\u00b7we\u00b7sen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "APPR", "ART", "NN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201esehr wenig wird davon in Farb\u2019 und Stein gelesen.", "tokens": ["\u201e", "sehr", "we\u00b7nig", "wird", "da\u00b7von", "in", "Fa\u00b7rb'", "und", "Stein", "ge\u00b7le\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "VAFIN", "PAV", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "\u201edie ", "tokens": ["\u201e", "die"], "token_info": ["punct", "word"], "pos": ["$(", "ART"], "meter": "-", "measure": "single.down"}, "line.18": {"text": "310\u201dDie dieser Sachen Ruhm aus dem Vergessen rafft.", "tokens": ["\"", "Die", "die\u00b7ser", "Sa\u00b7chen", "Ruhm", "aus", "dem", "Ver\u00b7ges\u00b7sen", "rafft", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PDAT", "NN", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}