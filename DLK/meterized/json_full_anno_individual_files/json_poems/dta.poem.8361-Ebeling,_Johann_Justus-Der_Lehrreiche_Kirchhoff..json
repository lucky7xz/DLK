{"dta.poem.8361": {"metadata": {"author": {"name": "Ebeling, Johann Justus", "birth": "N.A.", "death": "N.A."}, "title": "Der Lehrreiche Kirchhoff.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1747", "urn": "urn:nbn:de:kobv:b4-200905198782", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr Menschen! die ein toller Wahn", "tokens": ["Ihr", "Men\u00b7schen", "!", "die", "ein", "tol\u00b7ler", "Wahn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der falschen Einbildung betrogen,", "tokens": ["Der", "fal\u00b7schen", "Ein\u00b7bil\u00b7dung", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Als wenn kein Todt euch treffen kan,", "tokens": ["Als", "wenn", "kein", "Todt", "euch", "tref\u00b7fen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIAT", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da ihr in Eitelkeit erzogen,", "tokens": ["Da", "ihr", "in", "Ei\u00b7tel\u00b7keit", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kommt seht und lernet was ihr seid,", "tokens": ["Kommt", "seht", "und", "ler\u00b7net", "was", "ihr", "seid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "KON", "VVFIN", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach einer kurzen Daur der Zeit,", "tokens": ["Nach", "ei\u00b7ner", "kur\u00b7zen", "Daur", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da euch die kalte Hand ger\u00fchret,", "tokens": ["Da", "euch", "die", "kal\u00b7te", "Hand", "ge\u00b7r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zu diesen Sammelplaz gef\u00fchret.", "tokens": ["Zu", "die\u00b7sen", "Sam\u00b7mel\u00b7plaz", "ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kommt her an diesen stillen Ort,", "tokens": ["Kommt", "her", "an", "die\u00b7sen", "stil\u00b7len", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verbannet nur das bange Grauen;", "tokens": ["Ver\u00b7ban\u00b7net", "nur", "das", "ban\u00b7ge", "Grau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Jhr werdet nichts als hier und dort", "tokens": ["Ihr", "wer\u00b7det", "nichts", "als", "hier", "und", "dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "KOKOM", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur aufgeworffne H\u00fcgel schauen;", "tokens": ["Nur", "auf\u00b7ge\u00b7worff\u00b7ne", "H\u00fc\u00b7gel", "schau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das Schrekgespenste stiller Nacht,", "tokens": ["Das", "Schrek\u00b7ge\u00b7spens\u00b7te", "stil\u00b7ler", "Nacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das euch den Kirchhof gr\u00e4ulich macht,", "tokens": ["Das", "euch", "den", "Kirch\u00b7hof", "gr\u00e4u\u00b7lich", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wird bei den wollgefa\u00dften Sinnen,", "tokens": ["Wird", "bei", "den", "woll\u00b7ge\u00b7fa\u00df\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gleich als ein leerer Dunst zerrinnen.", "tokens": ["Gleich", "als", "ein", "lee\u00b7rer", "Dunst", "zer\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Hier ist ein Tempel kommt herein,", "tokens": ["Hier", "ist", "ein", "Tem\u00b7pel", "kommt", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Darinnen ihr das k\u00f6nnet lernen", "tokens": ["Da\u00b7rin\u00b7nen", "ihr", "das", "k\u00f6n\u00b7net", "ler\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PDS", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Menschen dennoch sterblich seyn,", "tokens": ["Da\u00df", "Men\u00b7schen", "den\u00b7noch", "sterb\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob sie sich gleich vom Todt entsernen;", "tokens": ["Ob", "sie", "sich", "gleich", "vom", "Todt", "ent\u00b7ser\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Zahl die hier begraben liegt,", "tokens": ["Die", "Zahl", "die", "hier", "be\u00b7gra\u00b7ben", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ihren lezten Feind besiegt,", "tokens": ["Und", "ih\u00b7ren", "lez\u00b7ten", "Feind", "be\u00b7siegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die lehret euch mit stummen Munde,", "tokens": ["Die", "leh\u00b7ret", "euch", "mit", "stum\u00b7men", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Es komm auch eure lezte Stunde.", "tokens": ["Es", "komm", "auch", "eu\u00b7re", "lez\u00b7te", "Stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was ist der Vorwurf des Gesichts?", "tokens": ["Was", "ist", "der", "Vor\u00b7wurf", "des", "Ge\u00b7sichts", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beschriebne Steine, hohe H\u00fcgel;", "tokens": ["Be\u00b7schrieb\u00b7ne", "Stei\u00b7ne", ",", "ho\u00b7he", "H\u00fc\u00b7gel", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und diese sind von euren Nichts", "tokens": ["Und", "die\u00b7se", "sind", "von", "eu\u00b7ren", "Nichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von euren Eitelkeiten Spiegel;", "tokens": ["Von", "eu\u00b7ren", "Ei\u00b7tel\u00b7kei\u00b7ten", "Spie\u00b7gel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Blikt nur dieselben flei\u00dfig an,", "tokens": ["Blikt", "nur", "die\u00b7sel\u00b7ben", "flei\u00b7\u00dfig", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PDAT", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Weil draus ein jeder lesen kan,", "tokens": ["Weil", "draus", "ein", "je\u00b7der", "le\u00b7sen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "ART", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was wir so schwerlich sonsten fassen,", "tokens": ["Was", "wir", "so", "schwer\u00b7lich", "sons\u00b7ten", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df all ohn Unterscheid erblassen.", "tokens": ["Da\u00df", "all", "ohn", "Un\u00b7ter\u00b7scheid", "er\u00b7blas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Le\u00dft was auf denen Steinen steht:\nMein Wandrer steh um zu bedenken,", "tokens": ["Le\u00dft", "was", "auf", "de\u00b7nen", "Stei\u00b7nen", "steht", ":", "Mein", "Wand\u00b7rer", "steh", "um", "zu", "be\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PRELS", "NN", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Wie bald auch deine Zeit vergeht,", "tokens": ["Wie", "bald", "auch", "dei\u00b7ne", "Zeit", "ver\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da man auch dich wird hie versenken.", "tokens": ["Da", "man", "auch", "dich", "wird", "hie", "ver\u00b7sen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir haben auch gelebt, gebl\u00fcht,", "tokens": ["Wir", "ha\u00b7ben", "auch", "ge\u00b7lebt", ",", "ge\u00b7bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Uns in der Eitelkeit bem\u00fcht,", "tokens": ["Uns", "in", "der", "Ei\u00b7tel\u00b7keit", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun aber sind wir durch die Bogen", "tokens": ["Nun", "a\u00b7ber", "sind", "wir", "durch", "die", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ins Land der Todten heimgezogen.", "tokens": ["Ins", "Land", "der", "Tod\u00b7ten", "heim\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier seht ihr H\u00fcgel, gros und klein,", "tokens": ["Hier", "seht", "ihr", "H\u00fc\u00b7gel", ",", "gros", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sind die aufgeworffnen Zeichen,", "tokens": ["Das", "sind", "die", "auf\u00b7ge\u00b7worff\u00b7nen", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df die die hier begraben seyn,", "tokens": ["Da\u00df", "die", "die", "hier", "be\u00b7gra\u00b7ben", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ART", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Theils grosse, theils auch kleine Leichen:", "tokens": ["Theils", "gros\u00b7se", ",", "theils", "auch", "klei\u00b7ne", "Lei\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "$,", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie lehren euch da\u00df alt und iung,", "tokens": ["Sie", "leh\u00b7ren", "euch", "da\u00df", "alt", "und", "i\u00b7ung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KOUS", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df S\u00e4uglinge auch reif genug,", "tokens": ["Da\u00df", "S\u00e4ug\u00b7lin\u00b7ge", "auch", "reif", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ADJD", "ADV", "$,"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Wenn sie kaum in der Welt aufbl\u00fchen.", "tokens": ["Wenn", "sie", "kaum", "in", "der", "Welt", "auf\u00b7bl\u00fc\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Jm Tode wieder weg zufliehen.", "tokens": ["Jm", "To\u00b7de", "wie\u00b7der", "weg", "zu\u00b7flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie mancher ist hier hingelegt,", "tokens": ["Wie", "man\u00b7cher", "ist", "hier", "hin\u00b7ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der sich sein Ziel noch weit gesezzet,", "tokens": ["Der", "sich", "sein", "Ziel", "noch", "weit", "ge\u00b7sez\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn er den Lebenslauf erwegt,", "tokens": ["Wenn", "er", "den", "Le\u00b7bens\u00b7lauf", "er\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den er vor sich sehr lang gesch\u00e4zzet;", "tokens": ["Den", "er", "vor", "sich", "sehr", "lang", "ge\u00b7sch\u00e4z\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PRF", "ADV", "ADJD", "VVPP", "$."], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Wie viele sind des Todes-Raub", "tokens": ["Wie", "vie\u00b7le", "sind", "des", "To\u00b7des\u00b7Raub"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und nunmehr Knochen, Moder, Staub", "tokens": ["Und", "nun\u00b7mehr", "Kno\u00b7chen", ",", "Mo\u00b7der", ",", "Staub"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "ADV", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die damahls als sie noch vorhanden,", "tokens": ["Die", "da\u00b7mahls", "als", "sie", "noch", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Kaum da\u00df sie sterblich eingestanden.", "tokens": ["Kaum", "da\u00df", "sie", "sterb\u00b7lich", "ein\u00b7ge\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Jhr Zeugen unsrer Eitelkeit!", "tokens": ["Ihr", "Zeu\u00b7gen", "uns\u00b7rer", "Ei\u00b7tel\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O! liesset ihr uns deutlich lesen,", "tokens": ["O", "!", "lies\u00b7set", "ihr", "uns", "deut\u00b7lich", "le\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was ihr in eurer Lebens-Zeit,", "tokens": ["Was", "ihr", "in", "eu\u00b7rer", "Le\u00b7bens\u00b7Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gedacht, in euren Sinn gewesen;", "tokens": ["Ge\u00b7dacht", ",", "in", "eu\u00b7ren", "Sinn", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "PPOSAT", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und machte eures Herzensgrund,", "tokens": ["Und", "mach\u00b7te", "eu\u00b7res", "Her\u00b7zens\u00b7grund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das aufgestellte Denkmal kund;", "tokens": ["Das", "auf\u00b7ge\u00b7stell\u00b7te", "Denk\u00b7mal", "kund", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So w\u00fcrden wir dadurch belehret,", "tokens": ["So", "w\u00fcr\u00b7den", "wir", "da\u00b7durch", "be\u00b7leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie mancher Anschlag sey zerst\u00f6hret.", "tokens": ["Wie", "man\u00b7cher", "An\u00b7schlag", "sey", "zer\u00b7st\u00f6h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Da ruht der Sch\u00f6nheit Ebenbild,", "tokens": ["Da", "ruht", "der", "Sch\u00f6n\u00b7heit", "E\u00b7ben\u00b7bild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie uns des Grabes-Stein berichtet,", "tokens": ["Wie", "uns", "des", "Gra\u00b7bes\u00b7Stein", "be\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von Lust und Hofnung angef\u00fcllt:", "tokens": ["Von", "Lust", "und", "Hof\u00b7nung", "an\u00b7ge\u00b7f\u00fcllt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Allein wie ist sie nun zernichtet?", "tokens": ["Al\u00b7lein", "wie", "ist", "sie", "nun", "zer\u00b7nich\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Purpurwangen Morgenroth,", "tokens": ["Der", "Pur\u00b7pur\u00b7wan\u00b7gen", "Mor\u00b7gen\u00b7roth", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist l\u00e4ngst durch einen blassen Todt,", "tokens": ["Ist", "l\u00e4ngst", "durch", "ei\u00b7nen", "blas\u00b7sen", "Todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Entf\u00e4rbt und in die Haut verkehret,", "tokens": ["Ent\u00b7f\u00e4rbt", "und", "in", "die", "Haut", "ver\u00b7keh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die scheu\u00dflich Ungezieffer n\u00e4hret.", "tokens": ["Die", "scheu\u00df\u00b7lich", "Un\u00b7ge\u00b7zief\u00b7fer", "n\u00e4h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Da hat der Todt den weggeraubt,", "tokens": ["Da", "hat", "der", "Todt", "den", "weg\u00b7ge\u00b7raubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie uns die Ueberschrifften melden,", "tokens": ["Wie", "uns", "die", "Ue\u00b7ber\u00b7schriff\u00b7ten", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der als er lebte fest geglaubt,", "tokens": ["Der", "als", "er", "leb\u00b7te", "fest", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOUS", "PPER", "VVFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er w\u00e4r ein Held vor allen Helden;", "tokens": ["Er", "w\u00e4r", "ein", "Held", "vor", "al\u00b7len", "Hel\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sein K\u00f6rper w\u00e4re von Metal;", "tokens": ["Sein", "K\u00f6r\u00b7per", "w\u00e4\u00b7re", "von", "Me\u00b7tal", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und dennoch hat ein Sturz und Fall,", "tokens": ["Und", "den\u00b7noch", "hat", "ein", "Sturz", "und", "Fall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bei seines Stolzes wilden Pochen", "tokens": ["Bei", "sei\u00b7nes", "Stol\u00b7zes", "wil\u00b7den", "Po\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Jhm Hals und Bein entzwei gebrochen.", "tokens": ["Jhm", "Hals", "und", "Bein", "ent\u00b7zwei", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Dort ist die festvermaurte Kluft,", "tokens": ["Dort", "ist", "die", "fest\u00b7ver\u00b7maur\u00b7te", "Kluft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geziert mit einem Ehrenbogen,", "tokens": ["Ge\u00b7ziert", "mit", "ei\u00b7nem", "Eh\u00b7ren\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Woraus die Fama th\u00f6nend ruft:", "tokens": ["Wo\u00b7raus", "die", "Fa\u00b7ma", "th\u00f6\u00b7nend", "ruft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein jeder sahe diesen Mann", "tokens": ["Ein", "je\u00b7der", "sa\u00b7he", "die\u00b7sen", "Mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als einen GOtt auf Erden an:", "tokens": ["Als", "ei\u00b7nen", "Gott", "auf", "Er\u00b7den", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er glaubte immerfort zu leben,", "tokens": ["Er", "glaub\u00b7te", "im\u00b7mer\u00b7fort", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und muste doch den Geist aufgeben.", "tokens": ["Und", "mus\u00b7te", "doch", "den", "Geist", "auf\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Hie ist ein Grab: wer liegt darin?\nEin Mensch den sonst die Welt zu enge,", "tokens": ["Hie", "ist", "ein", "Grab", ":", "wer", "liegt", "da\u00b7rin", "?", "Ein", "Mensch", "den", "sonst", "die", "Welt", "zu", "en\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "PWS", "VVFIN", "PAV", "$.", "ART", "NN", "ART", "ADV", "ART", "NN", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Und sich abma\u00df nach seinen Sinn,", "tokens": ["Und", "sich", "ab\u00b7ma\u00df", "nach", "sei\u00b7nen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und nicht nach seiner Leibes L\u00e4nge:", "tokens": ["Und", "nicht", "nach", "sei\u00b7ner", "Lei\u00b7bes", "L\u00e4n\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er war nur blos ein Erden-Gast,", "tokens": ["Er", "war", "nur", "blos", "ein", "Er\u00b7den\u00b7Gast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein Wohnhaus war wie ein Pallast,", "tokens": ["Sein", "Wohn\u00b7haus", "war", "wie", "ein", "Pal\u00b7last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und doch zu klein: Nun mu\u00df er liegen,", "tokens": ["Und", "doch", "zu", "klein", ":", "Nun", "mu\u00df", "er", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKA", "ADJD", "$.", "ADV", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und sich mit engen Sarg begn\u00fcgen.", "tokens": ["Und", "sich", "mit", "en\u00b7gen", "Sarg", "be\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "O Eitelkeit! wer ruhet da?\nEin Mensch der immer unzufrieden;", "tokens": ["O", "Ei\u00b7tel\u00b7keit", "!", "wer", "ru\u00b7het", "da", "?", "Ein", "Mensch", "der", "im\u00b7mer", "un\u00b7zu\u00b7frie\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWS", "VVFIN", "ADV", "$.", "ART", "NN", "ART", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Wenn er in seinem Leben sah,", "tokens": ["Wenn", "er", "in", "sei\u00b7nem", "Le\u00b7ben", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df GOtt dem andern mehr beschieden:", "tokens": ["Da\u00df", "Gott", "dem", "an\u00b7dern", "mehr", "be\u00b7schie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "ADJA", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Unruh trieb ihm Tag und Nacht,", "tokens": ["Die", "Un\u00b7ruh", "trieb", "ihm", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Gram hat ihn auch umgebracht;", "tokens": ["Der", "Gram", "hat", "ihn", "auch", "um\u00b7ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun ist sein sehnend Herz gestillet,", "tokens": ["Nun", "ist", "sein", "seh\u00b7nend", "Herz", "ge\u00b7stil\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJD", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da er der Erden Bauch gef\u00fcllet.", "tokens": ["Da", "er", "der", "Er\u00b7den", "Bauch", "ge\u00b7f\u00fcl\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wer ist sein Nachbahr des Gebein,", "tokens": ["Wer", "ist", "sein", "Nach\u00b7bahr", "des", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Mit keinen Denkmal \u00fcberdekket?", "tokens": ["Mit", "kei\u00b7nen", "Denk\u00b7mal", "\u00fc\u00b7ber\u00b7dek\u00b7ket", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was mag das vor ein Herze seyn,", "tokens": ["Was", "mag", "das", "vor", "ein", "Her\u00b7ze", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PDS", "APPR", "ART", "VVFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df hier in diese Grufft verstekket?", "tokens": ["Da\u00df", "hier", "in", "die\u00b7se", "Grufft", "vers\u00b7tek\u00b7ket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vermutlich ist es Gernegros,", "tokens": ["Ver\u00b7mut\u00b7lich", "ist", "es", "Ger\u00b7ne\u00b7gros", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der ob er gleich sehr arm und blos,", "tokens": ["Der", "ob", "er", "gleich", "sehr", "arm", "und", "blos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOUS", "PPER", "ADV", "ADV", "ADJD", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dennoch sich w\u00fcnschte das Vergn\u00fcgen", "tokens": ["Den\u00b7noch", "sich", "w\u00fcnschte", "das", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PRF", "VVFIN", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Bei einem reichen Mann zu liegen.", "tokens": ["Bei", "ei\u00b7nem", "rei\u00b7chen", "Mann", "zu", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Denn der dabei sein Grabmahl hat,", "tokens": ["Denn", "der", "da\u00b7bei", "sein", "Grab\u00b7mahl", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PAV", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Heist Cr\u00f6sus dessen ganzes Leben", "tokens": ["Heist", "Cr\u00f6\u00b7sus", "des\u00b7sen", "gan\u00b7zes", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Des Morgens fr\u00fch, des Abends spat,", "tokens": ["Des", "Mor\u00b7gens", "fr\u00fch", ",", "des", "A\u00b7bends", "spat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob er gleich reich mit Noth umgeben.", "tokens": ["Ob", "er", "gleich", "reich", "mit", "Noth", "um\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NN", "VVPP", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Er lebte immer k\u00fcmmerlich,", "tokens": ["Er", "leb\u00b7te", "im\u00b7mer", "k\u00fcm\u00b7mer\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sparte aber nicht vor sich", "tokens": ["Und", "spar\u00b7te", "a\u00b7ber", "nicht", "vor", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Er lebte arm bei dem Erwerben,", "tokens": ["Er", "leb\u00b7te", "arm", "bei", "dem", "Er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nur als ein reicher Mann zu sterben.", "tokens": ["Nur", "als", "ein", "rei\u00b7cher", "Mann", "zu", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein Thraso lieget dort im Ruh", "tokens": ["Ein", "Thra\u00b7so", "lie\u00b7get", "dort", "im", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der keine Ruh und Frieden liebte,", "tokens": ["Der", "kei\u00b7ne", "Ruh", "und", "Frie\u00b7den", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Todt dr\u00fckt ihm die Augen zu", "tokens": ["Der", "Todt", "dr\u00fckt", "ihm", "die", "Au\u00b7gen", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da er nichts als nur Rach aus\u00fcbte.", "tokens": ["Da", "er", "nichts", "als", "nur", "Rach", "aus\u00b7\u00fcb\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "KOKOM", "ADV", "NN", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Die Zanksucht liegt ihm an der Seit,", "tokens": ["Die", "Zank\u00b7sucht", "liegt", "ihm", "an", "der", "Seit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Seht Menschen hier die Eitelkeit,", "tokens": ["Seht", "Men\u00b7schen", "hier", "die", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die sich wie Feur und Wasser mieden,", "tokens": ["Die", "sich", "wie", "Feur", "und", "Was\u00b7ser", "mie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "KOKOM", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vereinigt oft der Todt zum Frieden.", "tokens": ["Ver\u00b7ei\u00b7nigt", "oft", "der", "Todt", "zum", "Frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Was find ich da vor Ueberschrifft:", "tokens": ["Was", "find", "ich", "da", "vor", "Ue\u00b7ber\u00b7schrifft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie heist: ", "tokens": ["Sie", "heist", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Liegt einer den kein Moder trift,", "tokens": ["Liegt", "ei\u00b7ner", "den", "kein", "Mo\u00b7der", "trift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O! Wunder! was sinds vor Gebeine", "tokens": ["O", "!", "Wun\u00b7der", "!", "was", "sinds", "vor", "Ge\u00b7bei\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "NN", "$.", "PWS", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Woran kein Wurm noch Fa\u00fclnis nagt?", "tokens": ["Wo\u00b7ran", "kein", "Wurm", "noch", "Fa\u00fcl\u00b7nis", "nagt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich hatte kaum darnach gefragt;", "tokens": ["Ich", "hat\u00b7te", "kaum", "dar\u00b7nach", "ge\u00b7fragt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So h\u00f6rt ich da\u00df ein Mann von Gaben", "tokens": ["So", "h\u00f6rt", "ich", "da\u00df", "ein", "Mann", "von", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "An diesen Orte w\u00e4r begraben.", "tokens": ["An", "die\u00b7sen", "Or\u00b7te", "w\u00e4r", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ein Mann von Fleis, von Kunst und Wiz,", "tokens": ["Ein", "Mann", "von", "Fleis", ",", "von", "Kunst", "und", "Wiz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Nahme nimmer wird ersterben,", "tokens": ["Des", "Nah\u00b7me", "nim\u00b7mer", "wird", "ers\u00b7ter\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mu\u00df doch wo ihren Wohnungs Siz", "tokens": ["Mu\u00df", "doch", "wo", "ih\u00b7ren", "Woh\u00b7nungs", "Siz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PWAV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Eitelkeit erw\u00e4hlt, verderben;", "tokens": ["Die", "Ei\u00b7tel\u00b7keit", "er\u00b7w\u00e4hlt", ",", "ver\u00b7der\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die freien K\u00fcnste sind nicht frei,", "tokens": ["Die", "frei\u00b7en", "K\u00fcns\u00b7te", "sind", "nicht", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es ist dem Tode einerlei,", "tokens": ["Es", "ist", "dem", "To\u00b7de", "ei\u00b7ner\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ob einer vieles \u00fcberlesen,", "tokens": ["Ob", "ei\u00b7ner", "vie\u00b7les", "\u00fc\u00b7berl\u00b7e\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Genug! wenn er ein Mensch gewesen.", "tokens": ["Ge\u00b7nug", "!", "wenn", "er", "ein", "Mensch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KOUS", "PPER", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Die Ehre, W\u00fcrde, Stand und Ruhm,", "tokens": ["Die", "Eh\u00b7re", ",", "W\u00fcr\u00b7de", ",", "Stand", "und", "Ruhm", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sch\u00f6nheit, Reichthum, Klugheit Tietel,", "tokens": ["Die", "Sch\u00f6n\u00b7heit", ",", "Reicht\u00b7hum", ",", "Klug\u00b7heit", "Tie\u00b7tel", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der hohen Seelen Eigenthum:", "tokens": ["Der", "ho\u00b7hen", "See\u00b7len", "Ei\u00b7gen\u00b7thum", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verachtung, Armut, Baurenkittel;", "tokens": ["Ver\u00b7ach\u00b7tung", ",", "Ar\u00b7mut", ",", "Bau\u00b7ren\u00b7kit\u00b7tel", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die man im Leben, auf der Welt,", "tokens": ["Die", "man", "im", "Le\u00b7ben", ",", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In unterschiednen Reihen stellt;", "tokens": ["In", "un\u00b7ter\u00b7schied\u00b7nen", "Rei\u00b7hen", "stellt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die sind im Sterben gleich geachtet,", "tokens": ["Die", "sind", "im", "Ster\u00b7ben", "gleich", "ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn man des Todes Recht betrachtet.", "tokens": ["Wenn", "man", "des", "To\u00b7des", "Recht", "be\u00b7trach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.20": {"line.1": {"text": "Da ist ein Beinhaus! seht nur an,", "tokens": ["Da", "ist", "ein", "Be\u00b7in\u00b7haus", "!", "seht", "nur", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Die d\u00fcrren aufbewahrten Knochen,", "tokens": ["Die", "d\u00fcr\u00b7ren", "auf\u00b7be\u00b7wahr\u00b7ten", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die durch der Zeiten scharffen Zahn,", "tokens": ["Die", "durch", "der", "Zei\u00b7ten", "scharf\u00b7fen", "Zahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schon meist zermalmmet und zerbrochen,", "tokens": ["Schon", "meist", "zer\u00b7malm\u00b7met", "und", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer sagt uns welcher Herr und Knecht,", "tokens": ["Wer", "sagt", "uns", "wel\u00b7cher", "Herr", "und", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PWAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jhr eitlen Menschen! komt und sprecht,", "tokens": ["Ihr", "eit\u00b7len", "Men\u00b7schen", "!", "komt", "und", "sprecht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und lehrt uns welcher Kopf und Schedel,", "tokens": ["Und", "lehrt", "uns", "wel\u00b7cher", "Kopf", "und", "Sche\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PWAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nunmehr vor andern, herrlich, edel.", "tokens": ["Nun\u00b7mehr", "vor", "an\u00b7dern", ",", "herr\u00b7lich", ",", "e\u00b7del", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "PIS", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Der Todt hat alles gleich gemacht,", "tokens": ["Der", "Todt", "hat", "al\u00b7les", "gleich", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und der der alle Welt best\u00fcrmet,", "tokens": ["Und", "der", "der", "al\u00b7le", "Welt", "be\u00b7st\u00fcr\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wird welches er woll nicht gedacht,", "tokens": ["Wird", "wel\u00b7ches", "er", "woll", "nicht", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRELS", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Nebst andern K\u00f6rpern aufgeth\u00fcrmet;", "tokens": ["Nebst", "an\u00b7dern", "K\u00f6r\u00b7pern", "auf\u00b7ge\u00b7th\u00fcr\u00b7met", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Vorzug ist nur Einbildung,", "tokens": ["Der", "Vor\u00b7zug", "ist", "nur", "Ein\u00b7bil\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Dies lehret die Vernichtigung;", "tokens": ["Dies", "leh\u00b7ret", "die", "Ver\u00b7nich\u00b7ti\u00b7gung", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Weil sich im Todesreich die Schatten,", "tokens": ["Weil", "sich", "im", "To\u00b7des\u00b7reich", "die", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit ihren K\u00f6rper nicht mehr gatten.", "tokens": ["Mit", "ih\u00b7ren", "K\u00f6r\u00b7per", "nicht", "mehr", "gat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Da fliegt die Ehre gleich zur\u00fck,", "tokens": ["Da", "fliegt", "die", "Eh\u00b7re", "gleich", "zu\u00b7r\u00fck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Grab verd\u00fcstert alles Gl\u00e4nzen,", "tokens": ["Das", "Grab", "ver\u00b7d\u00fcs\u00b7tert", "al\u00b7les", "Gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und dessen Rand sezt Stand und Gl\u00fck,", "tokens": ["Und", "des\u00b7sen", "Rand", "sezt", "Stand", "und", "Gl\u00fck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Vorzug, die geme\u00dfnen Grenzen;", "tokens": ["Und", "Vor\u00b7zug", ",", "die", "ge\u00b7me\u00df\u00b7nen", "Gren\u00b7zen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da wo des Todes Reich und Land,", "tokens": ["Da", "wo", "des", "To\u00b7des", "Reich", "und", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zerbricht die eitle Scheidewand,", "tokens": ["Zer\u00b7bricht", "die", "eit\u00b7le", "Schei\u00b7de\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dadurch auf Erden so viel Orden,", "tokens": ["Da\u00b7durch", "auf", "Er\u00b7den", "so", "viel", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nach ihren Rang zertheilet worden.", "tokens": ["Nach", "ih\u00b7ren", "Rang", "zer\u00b7thei\u00b7let", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Die Knochen die da aufbewahrt,", "tokens": ["Die", "Kno\u00b7chen", "die", "da", "auf\u00b7be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sind die H\u00fclsen aller St\u00e4nde,", "tokens": ["Die", "sind", "die", "H\u00fcl\u00b7sen", "al\u00b7ler", "St\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da sind was alt und jung verpaart;", "tokens": ["Da", "sind", "was", "alt", "und", "jung", "ver\u00b7paart", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jhr Eitlen! lernt hier euer Ende;", "tokens": ["Ihr", "Eit\u00b7len", "!", "lernt", "hier", "eu\u00b7er", "En\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn euch der Stand hat aufgebl\u00e4ht,", "tokens": ["Wenn", "euch", "der", "Stand", "hat", "auf\u00b7ge\u00b7bl\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So komt zum Kirchhoff und beseht,", "tokens": ["So", "komt", "zum", "Kirch\u00b7hoff", "und", "be\u00b7seht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie euer Ansehn von euch weichet.", "tokens": ["Wie", "eu\u00b7er", "An\u00b7sehn", "von", "euch", "wei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So bald ihr kalt und todt erbleichet.", "tokens": ["So", "bald", "ihr", "kalt", "und", "todt", "er\u00b7blei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Bedenkt welch eine grosse Zahl", "tokens": ["Be\u00b7denkt", "welch", "ei\u00b7ne", "gros\u00b7se", "Zahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PWAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf diesen Sammelplaz ges\u00e4et;", "tokens": ["Auf", "die\u00b7sen", "Sam\u00b7mel\u00b7plaz", "ge\u00b7s\u00e4et", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie der Rest dreinst \u00fcberall,", "tokens": ["Und", "wie", "der", "Rest", "dreinst", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit seinen Sarg und Grab verwehet;", "tokens": ["Mit", "sei\u00b7nen", "Sarg", "und", "Grab", "ver\u00b7we\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Viel frische Gr\u00e4ber sind noch hier,", "tokens": ["Viel", "fri\u00b7sche", "Gr\u00e4\u00b7ber", "sind", "noch", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vielleicht wird bald vor unsrer Th\u00fcr,", "tokens": ["Viel\u00b7leicht", "wird", "bald", "vor", "uns\u00b7rer", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn wir noch sicher, eh wirs meinen,", "tokens": ["Wenn", "wir", "noch", "si\u00b7cher", ",", "eh", "wirs", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Todt mit seiner Bahr erscheinen.", "tokens": ["Der", "Todt", "mit", "sei\u00b7ner", "Bahr", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Was ist die Sch\u00f6nheit die uns schm\u00fckt,", "tokens": ["Was", "ist", "die", "Sch\u00f6n\u00b7heit", "die", "uns", "schm\u00fckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Alsdenn nichts als verblichne Rosen,", "tokens": ["Als\u00b7denn", "nichts", "als", "ver\u00b7blich\u00b7ne", "Ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die wenn sie in der Bl\u00fct erblikt", "tokens": ["Die", "wenn", "sie", "in", "der", "Bl\u00fct", "er\u00b7blikt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "PPER", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein jeder w\u00fcnschet liebzukosen,", "tokens": ["Ein", "je\u00b7der", "w\u00fcn\u00b7schet", "lieb\u00b7zu\u00b7ko\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie leicht verfleugt ein Rosenblatt,", "tokens": ["Wie", "leicht", "ver\u00b7fleugt", "ein", "Ro\u00b7sen\u00b7blatt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das keine lange Dauer hat?", "tokens": ["Das", "kei\u00b7ne", "lan\u00b7ge", "Dau\u00b7er", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So leicht vergehen auch die Sch\u00f6nen", "tokens": ["So", "leicht", "ver\u00b7ge\u00b7hen", "auch", "die", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVINF", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die sich mit Rosenschmuk bekr\u00f6nen.", "tokens": ["Die", "sich", "mit", "Ro\u00b7sen\u00b7schmuk", "be\u00b7kr\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Wie viele sind in langer Zeit,", "tokens": ["Wie", "vie\u00b7le", "sind", "in", "lan\u00b7ger", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Rosen hier im Staub vergangen,", "tokens": ["Als", "Ro\u00b7sen", "hier", "im", "Staub", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein gleiches Schiksahl wird gedr\u00e4ut", "tokens": ["Ein", "glei\u00b7ches", "Schik\u00b7sahl", "wird", "ge\u00b7dr\u00e4ut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den, die in ihrer Bl\u00fcte prangen:", "tokens": ["Den", ",", "die", "in", "ih\u00b7rer", "Bl\u00fc\u00b7te", "pran\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bedenket dieses die ihr meint,", "tokens": ["Be\u00b7den\u00b7ket", "die\u00b7ses", "die", "ihr", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df euer Antliz herlich scheint;", "tokens": ["Da\u00df", "eu\u00b7er", "Ant\u00b7liz", "her\u00b7lich", "scheint", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie leicht ist es nicht auch geschehen,", "tokens": ["Wie", "leicht", "ist", "es", "nicht", "auch", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Da\u00df ihr hier m\u00fcst erbla\u00dft verwehen.", "tokens": ["Da\u00df", "ihr", "hier", "m\u00fcst", "er\u00b7bla\u00dft", "ver\u00b7we\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Drum lernet eure Eitelkeit,", "tokens": ["Drum", "ler\u00b7net", "eu\u00b7re", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf diesen Sammelplaz erkennen;", "tokens": ["Auf", "die\u00b7sen", "Sam\u00b7mel\u00b7plaz", "er\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Raum ist kaum ein Spannebreit,", "tokens": ["Der", "Raum", "ist", "kaum", "ein", "Span\u00b7ne\u00b7breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Todt und Leben bei uns trennen;", "tokens": ["Die", "Todt", "und", "Le\u00b7ben", "bei", "uns", "tren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie mannigfaltig ist die Noth,", "tokens": ["Wie", "man\u00b7nig\u00b7fal\u00b7tig", "ist", "die", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die uns mit der Verwesung droht;", "tokens": ["Die", "uns", "mit", "der", "Ver\u00b7we\u00b7sung", "droht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die uns auf denen Sterbgefilden,", "tokens": ["Die", "uns", "auf", "de\u00b7nen", "Sterb\u00b7ge\u00b7fil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PRELS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Gr\u00e4ber vor die Augen bilden.", "tokens": ["Die", "Gr\u00e4\u00b7ber", "vor", "die", "Au\u00b7gen", "bil\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Seht was da sey die Leidenschaft", "tokens": ["Seht", "was", "da", "sey", "die", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PWS", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die uns hat Lebenslang gequ\u00e4let,", "tokens": ["Die", "uns", "hat", "Le\u00b7bens\u00b7lang", "ge\u00b7qu\u00e4\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn uns der Todt von hinnen raft", "tokens": ["Wenn", "uns", "der", "Todt", "von", "hin\u00b7nen", "raft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo bleibt das Ziel das wir erw\u00e4hlet?", "tokens": ["Wo", "bleibt", "das", "Ziel", "das", "wir", "er\u00b7w\u00e4h\u00b7let", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O! m\u00f6chte also jederman,", "tokens": ["O", "!", "m\u00f6ch\u00b7te", "al\u00b7so", "je\u00b7der\u00b7man", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VMFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der den Affect nicht zwingen kan,", "tokens": ["Der", "den", "Af\u00b7fect", "nicht", "zwin\u00b7gen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Nur auf dem Kirchhof das an h\u00f6ren,", "tokens": ["Nur", "auf", "dem", "Kirch\u00b7hof", "das", "an", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "APPR", "VVINF", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was uns die stummen Todten lehren!", "tokens": ["Was", "uns", "die", "stum\u00b7men", "Tod\u00b7ten", "leh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Sie machen mit verschlossnen Mund,", "tokens": ["Sie", "ma\u00b7chen", "mit", "ver\u00b7schloss\u00b7nen", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das was ein jeder zu bedenken", "tokens": ["Das", "was", "ein", "je\u00b7der", "zu", "be\u00b7den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRELS", "ART", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "An ihrer eignen Beispiel kund:", "tokens": ["An", "ih\u00b7rer", "eig\u00b7nen", "Bei\u00b7spiel", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Sterbliche sich nur versenken", "tokens": ["Da\u00df", "Sterb\u00b7li\u00b7che", "sich", "nur", "ver\u00b7sen\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In eine eitle K\u00fcmernis,", "tokens": ["In", "ei\u00b7ne", "eit\u00b7le", "K\u00fc\u00b7mer\u00b7nis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dieweil doch allemahl gewis", "tokens": ["Die\u00b7weil", "doch", "al\u00b7le\u00b7mahl", "ge\u00b7wis"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df wir nach denen eitlen Dingen,", "tokens": ["Da\u00df", "wir", "nach", "de\u00b7nen", "eit\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PRELS", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Als Thoren nicht als Kluge ringen.", "tokens": ["Als", "Tho\u00b7ren", "nicht", "als", "Klu\u00b7ge", "rin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Sie zeigen uns was sie gethan,", "tokens": ["Sie", "zei\u00b7gen", "uns", "was", "sie", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus eingebildeten Vergn\u00fcgen;", "tokens": ["Aus", "ein\u00b7ge\u00b7bil\u00b7de\u00b7ten", "Ver\u00b7gn\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie die Menschen auf der Bahn", "tokens": ["Und", "wie", "die", "Men\u00b7schen", "auf", "der", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Lebens, oft nach Schatten fliegen,", "tokens": ["Des", "Le\u00b7bens", ",", "oft", "nach", "Schat\u00b7ten", "flie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was n\u00fczt den Reichen Gut und Geld?", "tokens": ["Was", "n\u00fczt", "den", "Rei\u00b7chen", "Gut", "und", "Geld", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was n\u00fczt es den erstorbnen Held", "tokens": ["Was", "n\u00fczt", "es", "den", "ers\u00b7torb\u00b7nen", "Held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df er so m\u00f6rderlich gerungen,", "tokens": ["Da\u00df", "er", "so", "m\u00f6r\u00b7der\u00b7lich", "ge\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn ihn des Todes-Macht bezwungen?", "tokens": ["Wenn", "ihn", "des", "To\u00b7des\u00b7Macht", "be\u00b7zwun\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Was hilft dem aller Zank und Streit,", "tokens": ["Was", "hilft", "dem", "al\u00b7ler", "Zank", "und", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der auf dem GOttes-Akker lieget,", "tokens": ["Der", "auf", "dem", "Got\u00b7tes\u00b7Ak\u00b7ker", "lie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo ihm im Land der Sterbligkeit", "tokens": ["Wo", "ihm", "im", "Land", "der", "Ster\u00b7blig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der W\u00fcrmer Heer so gar besieget?", "tokens": ["Der", "W\u00fcr\u00b7mer", "Heer", "so", "gar", "be\u00b7sie\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was n\u00fczt es wenn man durch die Macht,", "tokens": ["Was", "n\u00fczt", "es", "wenn", "man", "durch", "die", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "KOUS", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den andern hat zu Fall gebracht,", "tokens": ["Den", "an\u00b7dern", "hat", "zu", "Fall", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der sich wenn Seel und Leib sich trennen", "tokens": ["Der", "sich", "wenn", "Seel", "und", "Leib", "sich", "tren\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "KOUS", "NN", "KON", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht wieder Maden wehren k\u00f6nnen?", "tokens": ["Nicht", "wie\u00b7der", "Ma\u00b7den", "weh\u00b7ren", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Was hilft uns alle eitle Lust?", "tokens": ["Was", "hilft", "uns", "al\u00b7le", "eit\u00b7le", "Lust", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Honig worin Stachel stekken,", "tokens": ["Der", "Ho\u00b7nig", "wo\u00b7rin", "Sta\u00b7chel", "stek\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PWAV", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie lange sind wir es bewust,", "tokens": ["Wie", "lan\u00b7ge", "sind", "wir", "es", "be\u00b7wust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was wir vor S\u00fc\u00dfigkeiten lekken;", "tokens": ["Was", "wir", "vor", "S\u00fc\u00b7\u00dfig\u00b7kei\u00b7ten", "lek\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So bald wir werden weggeraft,", "tokens": ["So", "bald", "wir", "wer\u00b7den", "weg\u00b7ge\u00b7raft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Komt unsre Zeit zur Rechenschaft", "tokens": ["Komt", "uns\u00b7re", "Zeit", "zur", "Re\u00b7chen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da wir die bittre Straf der S\u00fcnden,", "tokens": ["Da", "wir", "die", "bitt\u00b7re", "Straf", "der", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "In einer andern Welt empfinden.", "tokens": ["In", "ei\u00b7ner", "an\u00b7dern", "Welt", "emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Was hilft es da\u00df wir uns der Welt", "tokens": ["Was", "hilft", "es", "da\u00df", "wir", "uns", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "KOUS", "PPER", "PRF", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihren G\u00f6zen \u00fcbergeben?", "tokens": ["Und", "ih\u00b7ren", "G\u00f6\u00b7zen", "\u00fc\u00b7ber\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df wir uns nur, was ihr gef\u00e4llt", "tokens": ["Da\u00df", "wir", "uns", "nur", ",", "was", "ihr", "ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "$,", "PWS", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu thun mit saurer M\u00fch bestreben?", "tokens": ["Zu", "thun", "mit", "sau\u00b7rer", "M\u00fch", "be\u00b7stre\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es ist doch alles Eitelkeit,", "tokens": ["Es", "ist", "doch", "al\u00b7les", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und unser Ziel ist nicht mehr weit,", "tokens": ["Und", "un\u00b7ser", "Ziel", "ist", "nicht", "mehr", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da wir zu denen kommen m\u00fcssen,", "tokens": ["Da", "wir", "zu", "de\u00b7nen", "kom\u00b7men", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PRELS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die hier in Gr\u00e4bern sich verschliessen.", "tokens": ["Die", "hier", "in", "Gr\u00e4\u00b7bern", "sich", "ver\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Wir Menschen w\u00fchlen immerfort,", "tokens": ["Wir", "Men\u00b7schen", "w\u00fch\u00b7len", "im\u00b7mer\u00b7fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und folgen unsern blinden Triebe,", "tokens": ["Und", "fol\u00b7gen", "un\u00b7sern", "blin\u00b7den", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Warum? wir meinen da\u00df der Ort,", "tokens": ["Wa\u00b7rum", "?", "wir", "mei\u00b7nen", "da\u00df", "der", "Ort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VVFIN", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Stets unsre ewge Wohnung bliebe;", "tokens": ["Stets", "uns\u00b7re", "ew\u00b7ge", "Woh\u00b7nung", "blie\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wir kleben an dem Erdenklos,", "tokens": ["Wir", "kle\u00b7ben", "an", "dem", "Er\u00b7denk\u00b7los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und denken nicht an jenes Schlo\u00df", "tokens": ["Und", "den\u00b7ken", "nicht", "an", "je\u00b7nes", "Schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Ewigkeit, bei diesen Ballen,", "tokens": ["Der", "E\u00b7wig\u00b7keit", ",", "bei", "die\u00b7sen", "Bal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Darauf wir nur als Fremde wallen.", "tokens": ["Da\u00b7rauf", "wir", "nur", "als", "Frem\u00b7de", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Der Torheit werden wir entfliehn,", "tokens": ["Der", "Tor\u00b7heit", "wer\u00b7den", "wir", "ent\u00b7fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns aller Eitelkeit entfernen,", "tokens": ["Uns", "al\u00b7ler", "Ei\u00b7tel\u00b7keit", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn wir bei Gr\u00e4bern uns bem\u00fchn", "tokens": ["Wenn", "wir", "bei", "Gr\u00e4\u00b7bern", "uns", "be\u00b7m\u00fchn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df wir auch sterblich, zu erlernen:", "tokens": ["Da\u00df", "wir", "auch", "sterb\u00b7lich", ",", "zu", "er\u00b7ler\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O! woll dem! der das Leichen-Feld", "tokens": ["O", "!", "woll", "dem", "!", "der", "das", "Lei\u00b7chen\u00b7Feld"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "ADV", "ART", "$.", "ART", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor seine beste Lehrschul h\u00e4lt,", "tokens": ["Vor", "sei\u00b7ne", "bes\u00b7te", "Lehr\u00b7schul", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den Tand der Welt als Nichts verfluchet,", "tokens": ["Den", "Tand", "der", "Welt", "als", "Nichts", "ver\u00b7flu\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und Klugheit bei den Todten suchet.", "tokens": ["Und", "Klug\u00b7heit", "bei", "den", "Tod\u00b7ten", "su\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Ach! GOtt! vertreib den dikken Dunst,", "tokens": ["Ach", "!", "Gott", "!", "ver\u00b7treib", "den", "dik\u00b7ken", "Dunst", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "NN", "$.", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Damit die Welt uns nur betrieget,", "tokens": ["Da\u00b7mit", "die", "Welt", "uns", "nur", "be\u00b7trie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und gieb da\u00df das sey meine Kunst", "tokens": ["Und", "gieb", "da\u00df", "das", "sey", "mei\u00b7ne", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "KOUS", "PDS", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu sehen was in Gr\u00e4bern lieget!", "tokens": ["Zu", "se\u00b7hen", "was", "in", "Gr\u00e4\u00b7bern", "lie\u00b7get", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PRELS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da lerne ich, das was ich bin,", "tokens": ["Da", "ler\u00b7ne", "ich", ",", "das", "was", "ich", "bin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PRELS", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das f\u00fchrt mich zur Betrachtung hin,", "tokens": ["Das", "f\u00fchrt", "mich", "zur", "Be\u00b7trach\u00b7tung", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Jm Geiste auch voraus zu sehen,", "tokens": ["Jm", "Geis\u00b7te", "auch", "vo\u00b7raus", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie es mir nachmahls werde gehen.", "tokens": ["Wie", "es", "mir", "nach\u00b7mahls", "wer\u00b7de", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Und r\u00fchrt mich manches Schrekkenbild", "tokens": ["Und", "r\u00fchrt", "mich", "man\u00b7ches", "Schrek\u00b7ken\u00b7bild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf diesen f\u00fcrchterlichen Auen;", "tokens": ["Auf", "die\u00b7sen", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Au\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So la\u00df mich was vor Vortheil quillt;", "tokens": ["So", "la\u00df", "mich", "was", "vor", "Vor\u00b7theil", "quillt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus der Betrachtung, wieder schauen;", "tokens": ["Aus", "der", "Be\u00b7trach\u00b7tung", ",", "wie\u00b7der", "schau\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So wird das Schrekken der Natur,", "tokens": ["So", "wird", "das", "Schrek\u00b7ken", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf dieser Saamenreichen Flur,", "tokens": ["Auf", "die\u00b7ser", "Saa\u00b7men\u00b7rei\u00b7chen", "Flur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bei der Betrachtung stiller Leichen,", "tokens": ["Bei", "der", "Be\u00b7trach\u00b7tung", "stil\u00b7ler", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Durch die Bekandschaft endlich weichen.", "tokens": ["Durch", "die", "Be\u00b7kand\u00b7schaft", "end\u00b7lich", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF", "$."], "meter": "++-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "La\u00df mich kein todt Gerippe scheun,", "tokens": ["La\u00df", "mich", "kein", "todt", "Ge\u00b7rip\u00b7pe", "scheun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIAT", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es sind verdorrte Menschen Knochen,", "tokens": ["Es", "sind", "ver\u00b7dorr\u00b7te", "Men\u00b7schen", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die durch den f\u00fcrchterlichen Schein,", "tokens": ["Die", "durch", "den", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Woll manchen Vorsaz unterbrochen", "tokens": ["Woll", "man\u00b7chen", "Vor\u00b7saz", "un\u00b7ter\u00b7bro\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der auf das B\u00f6se abgezielt:", "tokens": ["Der", "auf", "das", "B\u00f6\u00b7se", "ab\u00b7ge\u00b7zielt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wird der Schauder gleich gef\u00fchlt;", "tokens": ["Und", "wird", "der", "Schau\u00b7der", "gleich", "ge\u00b7f\u00fchlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wird hernach des ", "tokens": ["So", "wird", "her\u00b7nach", "des"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Die Ruhekammer meiner Seele. ", "tokens": ["Die", "Ru\u00b7he\u00b7kam\u00b7mer", "mei\u00b7ner", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "La\u00df mich bedenken da\u00df der Todt,", "tokens": ["La\u00df", "mich", "be\u00b7den\u00b7ken", "da\u00df", "der", "Todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der F\u00fcrst des Schrekkens, einen Christen,", "tokens": ["Der", "F\u00fcrst", "des", "Schrek\u00b7kens", ",", "ei\u00b7nen", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht wie die blinden Heiden droht,", "tokens": ["Nicht", "wie", "die", "blin\u00b7den", "Hei\u00b7den", "droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOKOM", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit seinen schwarzen Schauger\u00fcsten:", "tokens": ["Mit", "sei\u00b7nen", "schwar\u00b7zen", "Schau\u00b7ge\u00b7r\u00fcs\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich weis da\u00df mein Erl\u00f6ser lebt,", "tokens": ["Ich", "weis", "da\u00df", "mein", "Er\u00b7l\u00f6\u00b7ser", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der das was schrekhafft ihm anklebt,", "tokens": ["Der", "das", "was", "schrek\u00b7hafft", "ihm", "an\u00b7klebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "PIS", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+--++", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "In seinen Todeskampf verschlungen,", "tokens": ["In", "sei\u00b7nen", "To\u00b7des\u00b7kampf", "ver\u00b7schlun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da er uns ewgen Sieg errungen.", "tokens": ["Da", "er", "uns", "ew\u00b7gen", "Sieg", "er\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}