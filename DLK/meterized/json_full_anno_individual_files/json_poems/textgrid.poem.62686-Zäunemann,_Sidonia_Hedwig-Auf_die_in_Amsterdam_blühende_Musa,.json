{"textgrid.poem.62686": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Auf die in Amsterdam bl\u00fchende Musa,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wach auf mein Geist! erweg und merke", "tokens": ["Wach", "auf", "mein", "Geist", "!", "er\u00b7weg", "und", "mer\u00b7ke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$.", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des grossen Sch\u00f6pfers Wunder-Macht,", "tokens": ["Des", "gros\u00b7sen", "Sch\u00f6p\u00b7fers", "Wun\u00b7der\u00b7Macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und untersuche mit Bedacht", "tokens": ["Und", "un\u00b7ter\u00b7su\u00b7che", "mit", "Be\u00b7dacht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So viel dir m\u00f6glich, ihre St\u00e4rke.", "tokens": ["So", "viel", "dir", "m\u00f6g\u00b7lich", ",", "ih\u00b7re", "St\u00e4r\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch sie ist unersch\u00f6pflich gro\u00df;", "tokens": ["Doch", "sie", "ist", "un\u00b7er\u00b7sch\u00f6pf\u00b7lich", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr Wesen ist nicht zuergr\u00fcnden:", "tokens": ["Ihr", "We\u00b7sen", "ist", "nicht", "zu\u00b7er\u00b7gr\u00fcn\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wer ihr Ende meint zufinden,", "tokens": ["Und", "wer", "ihr", "En\u00b7de", "meint", "zu\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der giebt sich in der Thorheit blo\u00df.", "tokens": ["Der", "giebt", "sich", "in", "der", "Thor\u00b7heit", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Man sp\u00fchrt die Allmachts-Hand in G\u00e4rten und in Fluren,", "tokens": ["Man", "sp\u00fchrt", "die", "All\u00b7machts\u00b7Hand", "in", "G\u00e4r\u00b7ten", "und", "in", "Flu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Man findet ihre Kraft in allen Creaturen.", "tokens": ["Man", "fin\u00b7det", "ih\u00b7re", "Kraft", "in", "al\u00b7len", "Crea\u00b7tu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Da sieht das forschende Gesichte", "tokens": ["Da", "sieht", "das", "for\u00b7schen\u00b7de", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wohin sich nur sein Auge f\u00fcgt,", "tokens": ["Wo\u00b7hin", "sich", "nur", "sein", "Au\u00b7ge", "f\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das, was es reitzet und vergn\u00fcgt,", "tokens": ["Das", ",", "was", "es", "reit\u00b7zet", "und", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erstaunend, und im vollen Lichte.", "tokens": ["Er\u00b7stau\u00b7nend", ",", "und", "im", "vol\u00b7len", "Lich\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was ehedessen Eden war:", "tokens": ["Was", "e\u00b7he\u00b7des\u00b7sen", "E\u00b7den", "war", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was man von Sch\u00f6nheit da gefunden,", "tokens": ["Was", "man", "von", "Sch\u00f6n\u00b7heit", "da", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das sieht man noch zu diesen Stunden", "tokens": ["Das", "sieht", "man", "noch", "zu", "die\u00b7sen", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bald hier, bald dorten offenbar.", "tokens": ["Bald", "hier", ",", "bald", "dor\u00b7ten", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "La\u00dft Eden, Eden seyn! auf andern sch\u00f6nen Auen;", "tokens": ["La\u00dft", "E\u00b7den", ",", "E\u00b7den", "seyn", "!", "auf", "an\u00b7dern", "sch\u00f6\u00b7nen", "Au\u00b7en", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "NN", "VAINF", "$.", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Kan mans in kleinen sehn, wo nicht vollkommen schauen.", "tokens": ["Kan", "mans", "in", "klei\u00b7nen", "sehn", ",", "wo", "nicht", "voll\u00b7kom\u00b7men", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "ADJA", "VVINF", "$,", "PWAV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wie? Ist nicht Tempens Lust-Gef\u00fclde", "tokens": ["Wie", "?", "Ist", "nicht", "Tem\u00b7pens", "Lust\u00b7Ge\u00b7f\u00fcl\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VAFIN", "PTKNEG", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An Fr\u00fcchten und Gew\u00e4chsen reich?", "tokens": ["An", "Fr\u00fcch\u00b7ten", "und", "Ge\u00b7w\u00e4ch\u00b7sen", "reich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo kommt ihn leicht ein Garten gleich?", "tokens": ["Wo", "kommt", "ihn", "leicht", "ein", "Gar\u00b7ten", "gleich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADJD", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier ist die H\u00f6chste Hand sehr milde!", "tokens": ["Hier", "ist", "die", "H\u00f6chs\u00b7te", "Hand", "sehr", "mil\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dort tr\u00e4gt America ein Kraut,", "tokens": ["Dort", "tr\u00e4gt", "A\u00b7me\u00b7ri\u00b7ca", "ein", "Kraut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das von des Sch\u00f6pfers Wundern zeiget.", "tokens": ["Das", "von", "des", "Sch\u00f6p\u00b7fers", "Wun\u00b7dern", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Gleich wie Jud\u00e4a auch nicht schweiget;", "tokens": ["Gleich", "wie", "Ju\u00b7d\u00e4a", "auch", "nicht", "schwei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NE", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Es wei\u00dft was Gott vor Pflantzen baut.", "tokens": ["Es", "wei\u00dft", "was", "Gott", "vor", "Pflant\u00b7zen", "baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Egypten, Africa und Europ\u00e4ens H\u00f6hen,", "tokens": ["E\u00b7gyp\u00b7ten", ",", "A\u00b7fri\u00b7ca", "und", "Eu\u00b7ro\u00b7p\u00e4\u00b7ens", "H\u00f6\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die lassen dem Gesicht die sch\u00f6nsten Blumen sehen.", "tokens": ["Die", "las\u00b7sen", "dem", "Ge\u00b7sicht", "die", "sch\u00f6ns\u00b7ten", "Blu\u00b7men", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wien, Franckreich, Welschland, Dre\u00dfden lehret,", "tokens": ["Wi\u00b7en", ",", "Fran\u00b7ck\u00b7reich", ",", "Wel\u00b7schland", ",", "Dre\u00df\u00b7den", "leh\u00b7ret", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "$,", "NE", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und zeiget uns sehr reichlich an,", "tokens": ["Und", "zei\u00b7get", "uns", "sehr", "reich\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was hier die Wunderhand gethan,", "tokens": ["Was", "hier", "die", "Wun\u00b7der\u00b7hand", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wie sie ihre Wercke mehret.", "tokens": ["Und", "wie", "sie", "ih\u00b7re", "Wer\u00b7cke", "meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was l\u00e4\u00dft nicht Hollands Garten-Feld", "tokens": ["Was", "l\u00e4\u00dft", "nicht", "Hol\u00b7lands", "Gar\u00b7ten\u00b7Feld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PTKNEG", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor Pflanzen und vor Bl\u00fcthen schie\u00dfen?", "tokens": ["Vor", "Pflan\u00b7zen", "und", "vor", "Bl\u00fc\u00b7then", "schie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hier mu\u00df des Menschen Herze schlie\u00dfen?", "tokens": ["Hier", "mu\u00df", "des", "Men\u00b7schen", "Her\u00b7ze", "schlie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gro\u00df ist der Meister dieser Welt!", "tokens": ["Gro\u00df", "ist", "der", "Meis\u00b7ter", "die\u00b7ser", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Geht nur nach Leiden hin! Ihr m\u00fcsset ja gestehen,", "tokens": ["Geht", "nur", "nach", "Lei\u00b7den", "hin", "!", "Ihr", "m\u00fcs\u00b7set", "ja", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df ihr die Aloe daselbst im Flor gesehen.", "tokens": ["Da\u00df", "ihr", "die", "A\u00b7loe", "da\u00b7selbst", "im", "Flor", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PAV", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Wo sinnt ihr hin! Was vor Vergn\u00fcgen", "tokens": ["Wo", "sinnt", "ihr", "hin", "!", "Was", "vor", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Treft ihr bey weisen Beeten an?", "tokens": ["Treft", "ihr", "bey", "wei\u00b7sen", "Bee\u00b7ten", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer denkt noch jetzo wohl daran,", "tokens": ["Wer", "denkt", "noch", "jet\u00b7zo", "wohl", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Florens Schoo\u00df vergn\u00fcgt zu liegen?", "tokens": ["Auf", "Flo\u00b7rens", "Schoo\u00df", "ver\u00b7gn\u00fcgt", "zu", "lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Zephyr z\u00fcrnt mit seiner Braut,", "tokens": ["Der", "Ze\u00b7phyr", "z\u00fcrnt", "mit", "sei\u00b7ner", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sondert sich von ihren Gr\u00e4nzen.", "tokens": ["Und", "son\u00b7dert", "sich", "von", "ih\u00b7ren", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wo will der Blumen Farbe gl\u00e4nzen?", "tokens": ["Wo", "will", "der", "Blu\u00b7men", "Far\u00b7be", "gl\u00e4n\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wo bl\u00fchet jetzt ein rares Kraut?", "tokens": ["Wo", "bl\u00fc\u00b7het", "jetzt", "ein", "ra\u00b7res", "Kraut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das Mahlwerk der Natur und was hervor gesprossen,", "tokens": ["Das", "Mahl\u00b7werk", "der", "Na\u00b7tur", "und", "was", "her\u00b7vor", "ge\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "PWS", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das hat ein weises Grab verdecket und verschlossen.", "tokens": ["Das", "hat", "ein", "wei\u00b7ses", "Grab", "ver\u00b7de\u00b7cket", "und", "ver\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die\u00df ist wohl wahr; doch bleibt darneben", "tokens": ["Die\u00df", "ist", "wohl", "wahr", ";", "doch", "bleibt", "dar\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$.", "ADV", "VVFIN", "PAV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Allmacht Gottes unverletzt;", "tokens": ["Die", "All\u00b7macht", "Got\u00b7tes", "un\u00b7ver\u00b7letzt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie kan dem, der sich dran erg\u00f6tzt", "tokens": ["Sie", "kan", "dem", ",", "der", "sich", "dran", "er\u00b7g\u00f6tzt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "$,", "PRELS", "PRF", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Best\u00e4ndig neue Proben geben.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "neu\u00b7e", "Pro\u00b7ben", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geschicht was ausserordentlich,", "tokens": ["Ge\u00b7schicht", "was", "aus\u00b7ser\u00b7or\u00b7dent\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PWS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So ist das Wunder desto gr\u00f6sser,", "tokens": ["So", "ist", "das", "Wun\u00b7der", "des\u00b7to", "gr\u00f6s\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man merkt des Sch\u00f6pfers Wei\u00dfheit besser,", "tokens": ["Man", "merkt", "des", "Sch\u00f6p\u00b7fers", "Wei\u00df\u00b7heit", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und unsre Ehrfurcht mehret sich.", "tokens": ["Und", "uns\u00b7re", "Ehr\u00b7furcht", "meh\u00b7ret", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bewei\u00dft Gott seine Kraft und Wunderhand auf Erden,", "tokens": ["Be\u00b7wei\u00dft", "Gott", "sei\u00b7ne", "Kraft", "und", "Wun\u00b7der\u00b7hand", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPOSAT", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So mu\u00df wenn er nur will aus Winter Sommer werden.", "tokens": ["So", "mu\u00df", "wenn", "er", "nur", "will", "aus", "Win\u00b7ter", "Som\u00b7mer", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "KOUS", "PPER", "ADV", "VMFIN", "APPR", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Die\u00df mu\u00df jetzt Amsterdam bezeugen,", "tokens": ["Die\u00df", "mu\u00df", "jetzt", "A\u00b7mster\u00b7dam", "be\u00b7zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und aller Augen auf sich ziehn;/", "tokens": ["Und", "al\u00b7ler", "Au\u00b7gen", "auf", "sich", "ziehn", ";", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PRF", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hier sieht man eine Pflanze bl\u00fchn,", "tokens": ["Hier", "sieht", "man", "ei\u00b7ne", "Pflan\u00b7ze", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die wenig hohen H\u00e4uptern eigen.", "tokens": ["Die", "we\u00b7nig", "ho\u00b7hen", "H\u00e4up\u00b7tern", "ei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Tag der uns zw\u00f6lf Monath bringt,", "tokens": ["Der", "Tag", "der", "uns", "zw\u00f6lf", "Mo\u00b7nath", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPER", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "War kaum mit seinem Licht gekommen,", "tokens": ["War", "kaum", "mit", "sei\u00b7nem", "Licht", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So hat man freudig wargenommen,", "tokens": ["So", "hat", "man", "freu\u00b7dig", "war\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wiewohl des G\u00e4rtners Wunsch gelingt.", "tokens": ["Wie\u00b7wohl", "des", "G\u00e4rt\u00b7ners", "Wunsch", "ge\u00b7lingt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Musa ein Gew\u00e4chs und Pflanze seltner Sch\u00f6ne,", "tokens": ["Die", "Mu\u00b7sa", "ein", "Ge\u00b7w\u00e4chs", "und", "Pflan\u00b7ze", "selt\u00b7ner", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Vergn\u00fcgt das Silber-Haar, und auch die muntre S\u00f6hne.", "tokens": ["Ver\u00b7gn\u00fcgt", "das", "Sil\u00b7ber\u00b7Haar", ",", "und", "auch", "die", "mun\u00b7tre", "S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ganz Holland hat in vorgen Tagen", "tokens": ["Ganz", "Hol\u00b7land", "hat", "in", "vor\u00b7gen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kaum einmahl ihre Blum gesehn,", "tokens": ["Kaum", "ein\u00b7mahl", "ih\u00b7re", "Blum", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Soll Deutschland ihren Flor gestehn,", "tokens": ["Soll", "Deutschland", "ih\u00b7ren", "Flor", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So kan es nur von zweymahl sagen.", "tokens": ["So", "kan", "es", "nur", "von", "zwey\u00b7mahl", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Europa kommt fast klagend ein,", "tokens": ["Eu\u00b7ro\u00b7pa", "kommt", "fast", "kla\u00b7gend", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und murret \u00fcber das Geschicke,", "tokens": ["Und", "mur\u00b7ret", "\u00fc\u00b7ber", "das", "Ge\u00b7schi\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ihr die\u00df sonderbahre Gl\u00fccke", "tokens": ["Da\u00df", "ihr", "die\u00df", "son\u00b7der\u00b7bah\u00b7re", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So wenigmahl soll wissend seyn.", "tokens": ["So", "we\u00b7nig\u00b7mahl", "soll", "wis\u00b7send", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Allmacht will im Gl\u00fcck bey diesen rauhen Zeiten,", "tokens": ["Die", "All\u00b7macht", "will", "im", "Gl\u00fcck", "bey", "die\u00b7sen", "rau\u00b7hen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPRART", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch dieser Pflanze Pracht vor Amsterdam bereiten.", "tokens": ["Durch", "die\u00b7ser", "Pflan\u00b7ze", "Pracht", "vor", "A\u00b7mster\u00b7dam", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "NN", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ihr Augen! Was vor ein Vergn\u00fcgen", "tokens": ["Ihr", "Au\u00b7gen", "!", "Was", "vor", "ein", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "PWS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stellt euch nicht diese Musa dar?", "tokens": ["Stellt", "euch", "nicht", "die\u00b7se", "Mu\u00b7sa", "dar", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel hundert Seelen nimmt man wahr,", "tokens": ["Viel", "hun\u00b7dert", "See\u00b7len", "nimmt", "man", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sich zu ihren Zweigen f\u00fcgen.", "tokens": ["Die", "sich", "zu", "ih\u00b7ren", "Zwei\u00b7gen", "f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier steht man still; hier ruft man laut:", "tokens": ["Hier", "steht", "man", "still", ";", "hier", "ruft", "man", "laut", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$.", "ADV", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was kan wohl dieser Sch\u00f6nheit gleichen?", "tokens": ["Was", "kan", "wohl", "die\u00b7ser", "Sch\u00f6n\u00b7heit", "glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hier mu\u00df der gr\u00f6\u00dfte K\u00fcnstler weichen,", "tokens": ["Hier", "mu\u00df", "der", "gr\u00f6\u00df\u00b7te", "K\u00fcnst\u00b7ler", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So sehr er auf sein Wissen baut.", "tokens": ["So", "sehr", "er", "auf", "sein", "Wis\u00b7sen", "baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Blumen, die sie tr\u00e4gt, sind von besondern Gaben,", "tokens": ["Die", "Blu\u00b7men", ",", "die", "sie", "tr\u00e4gt", ",", "sind", "von", "be\u00b7son\u00b7dern", "Ga\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Daher sie in der Welt den gr\u00f6sten Vorzug haben.", "tokens": ["Da\u00b7her", "sie", "in", "der", "Welt", "den", "gr\u00f6s\u00b7ten", "Vor\u00b7zug", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Des Salomonis Herrlichkeiten", "tokens": ["Des", "Sa\u00b7lo\u00b7mo\u00b7nis", "Herr\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erreichten nicht der Lilien Pracht,", "tokens": ["Er\u00b7reich\u00b7ten", "nicht", "der", "Li\u00b7li\u00b7en", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Die Hand die sie hervor gebracht", "tokens": ["Die", "Hand", "die", "sie", "her\u00b7vor", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "PTKVZ", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weis ihren Adel anzudeuten.", "tokens": ["Weis", "ih\u00b7ren", "A\u00b7del", "an\u00b7zu\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In einen Garten k\u00f6nnen wir,", "tokens": ["In", "ei\u00b7nen", "Gar\u00b7ten", "k\u00f6n\u00b7nen", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An unsers hohen Sch\u00f6pfers Werken,", "tokens": ["An", "un\u00b7sers", "ho\u00b7hen", "Sch\u00f6p\u00b7fers", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Gr\u00f6sse seiner Wunder merken.", "tokens": ["Die", "Gr\u00f6s\u00b7se", "sei\u00b7ner", "Wun\u00b7der", "mer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "O! welche Wei\u00dfheit gleichet dir!", "tokens": ["O", "!", "wel\u00b7che", "Wei\u00df\u00b7heit", "glei\u00b7chet", "dir", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kan eine Lilie nun dein Lob so sehr erheben;", "tokens": ["Kan", "ei\u00b7ne", "Li\u00b7lie", "nun", "dein", "Lob", "so", "sehr", "er\u00b7he\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So mu\u00df dir Hollands Frucht noch gr\u00f6\u00dfre Ehre geben.", "tokens": ["So", "mu\u00df", "dir", "Hol\u00b7lands", "Frucht", "noch", "gr\u00f6\u00df\u00b7re", "Eh\u00b7re", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NE", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Zwar Ihr Gelehrten wolt jetzt fragen:", "tokens": ["Zwar", "Ihr", "Ge\u00b7lehr\u00b7ten", "wolt", "jetzt", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was vor ein Baum die Musa sey?", "tokens": ["Was", "vor", "ein", "Baum", "die", "Mu\u00b7sa", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Frag ist schwer und mancherley,", "tokens": ["Die", "Frag", "ist", "schwer", "und", "man\u00b7cher\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jeder meinet recht zu sagen.", "tokens": ["Und", "je\u00b7der", "mei\u00b7net", "recht", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Forscht immerhin und critisirt,", "tokens": ["Forscht", "im\u00b7mer\u00b7hin", "und", "cri\u00b7ti\u00b7sirt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr m\u00fcsset doch mit mir bekennen,", "tokens": ["Ihr", "m\u00fcs\u00b7set", "doch", "mit", "mir", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie sey ein solches Werk zu nennen,", "tokens": ["Sie", "sey", "ein", "sol\u00b7ches", "Werk", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das uns zum Lobe Gottes f\u00fchrt.", "tokens": ["Das", "uns", "zum", "Lo\u00b7be", "Got\u00b7tes", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Wesen giebt die Kraft des H\u00f6chsten zu verstehen,", "tokens": ["Ihr", "We\u00b7sen", "giebt", "die", "Kraft", "des", "H\u00f6chs\u00b7ten", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und l\u00e4sset uns ein St\u00fcck von seiner Allmacht sehen.", "tokens": ["Und", "l\u00e4s\u00b7set", "uns", "ein", "St\u00fcck", "von", "sei\u00b7ner", "All\u00b7macht", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wach auf mein Geist! erweg und merke", "tokens": ["Wach", "auf", "mein", "Geist", "!", "er\u00b7weg", "und", "mer\u00b7ke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$.", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des grossen Sch\u00f6pfers Wunder-Macht,", "tokens": ["Des", "gros\u00b7sen", "Sch\u00f6p\u00b7fers", "Wun\u00b7der\u00b7Macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und untersuche mit Bedacht", "tokens": ["Und", "un\u00b7ter\u00b7su\u00b7che", "mit", "Be\u00b7dacht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So viel dir m\u00f6glich, ihre St\u00e4rke.", "tokens": ["So", "viel", "dir", "m\u00f6g\u00b7lich", ",", "ih\u00b7re", "St\u00e4r\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch sie ist unersch\u00f6pflich gro\u00df;", "tokens": ["Doch", "sie", "ist", "un\u00b7er\u00b7sch\u00f6pf\u00b7lich", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr Wesen ist nicht zuergr\u00fcnden:", "tokens": ["Ihr", "We\u00b7sen", "ist", "nicht", "zu\u00b7er\u00b7gr\u00fcn\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wer ihr Ende meint zufinden,", "tokens": ["Und", "wer", "ihr", "En\u00b7de", "meint", "zu\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der giebt sich in der Thorheit blo\u00df.", "tokens": ["Der", "giebt", "sich", "in", "der", "Thor\u00b7heit", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Man sp\u00fchrt die Allmachts-Hand in G\u00e4rten und in Fluren,", "tokens": ["Man", "sp\u00fchrt", "die", "All\u00b7machts\u00b7Hand", "in", "G\u00e4r\u00b7ten", "und", "in", "Flu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Man findet ihre Kraft in allen Creaturen.", "tokens": ["Man", "fin\u00b7det", "ih\u00b7re", "Kraft", "in", "al\u00b7len", "Crea\u00b7tu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.13": {"line.1": {"text": "Da sieht das forschende Gesichte", "tokens": ["Da", "sieht", "das", "for\u00b7schen\u00b7de", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wohin sich nur sein Auge f\u00fcgt,", "tokens": ["Wo\u00b7hin", "sich", "nur", "sein", "Au\u00b7ge", "f\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das, was es reitzet und vergn\u00fcgt,", "tokens": ["Das", ",", "was", "es", "reit\u00b7zet", "und", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erstaunend, und im vollen Lichte.", "tokens": ["Er\u00b7stau\u00b7nend", ",", "und", "im", "vol\u00b7len", "Lich\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was ehedessen Eden war:", "tokens": ["Was", "e\u00b7he\u00b7des\u00b7sen", "E\u00b7den", "war", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was man von Sch\u00f6nheit da gefunden,", "tokens": ["Was", "man", "von", "Sch\u00f6n\u00b7heit", "da", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das sieht man noch zu diesen Stunden", "tokens": ["Das", "sieht", "man", "noch", "zu", "die\u00b7sen", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bald hier, bald dorten offenbar.", "tokens": ["Bald", "hier", ",", "bald", "dor\u00b7ten", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "La\u00dft Eden, Eden seyn! auf andern sch\u00f6nen Auen;", "tokens": ["La\u00dft", "E\u00b7den", ",", "E\u00b7den", "seyn", "!", "auf", "an\u00b7dern", "sch\u00f6\u00b7nen", "Au\u00b7en", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "NN", "VAINF", "$.", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Kan mans in kleinen sehn, wo nicht vollkommen schauen.", "tokens": ["Kan", "mans", "in", "klei\u00b7nen", "sehn", ",", "wo", "nicht", "voll\u00b7kom\u00b7men", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "ADJA", "VVINF", "$,", "PWAV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Wie? Ist nicht Tempens Lust-Gef\u00fclde", "tokens": ["Wie", "?", "Ist", "nicht", "Tem\u00b7pens", "Lust\u00b7Ge\u00b7f\u00fcl\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VAFIN", "PTKNEG", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An Fr\u00fcchten und Gew\u00e4chsen reich?", "tokens": ["An", "Fr\u00fcch\u00b7ten", "und", "Ge\u00b7w\u00e4ch\u00b7sen", "reich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo kommt ihn leicht ein Garten gleich?", "tokens": ["Wo", "kommt", "ihn", "leicht", "ein", "Gar\u00b7ten", "gleich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADJD", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier ist die H\u00f6chste Hand sehr milde!", "tokens": ["Hier", "ist", "die", "H\u00f6chs\u00b7te", "Hand", "sehr", "mil\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dort tr\u00e4gt America ein Kraut,", "tokens": ["Dort", "tr\u00e4gt", "A\u00b7me\u00b7ri\u00b7ca", "ein", "Kraut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Das von des Sch\u00f6pfers Wundern zeiget.", "tokens": ["Das", "von", "des", "Sch\u00f6p\u00b7fers", "Wun\u00b7dern", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Gleich wie Jud\u00e4a auch nicht schweiget;", "tokens": ["Gleich", "wie", "Ju\u00b7d\u00e4a", "auch", "nicht", "schwei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "NE", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Es wei\u00dft was Gott vor Pflantzen baut.", "tokens": ["Es", "wei\u00dft", "was", "Gott", "vor", "Pflant\u00b7zen", "baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Egypten, Africa und Europ\u00e4ens H\u00f6hen,", "tokens": ["E\u00b7gyp\u00b7ten", ",", "A\u00b7fri\u00b7ca", "und", "Eu\u00b7ro\u00b7p\u00e4\u00b7ens", "H\u00f6\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die lassen dem Gesicht die sch\u00f6nsten Blumen sehen.", "tokens": ["Die", "las\u00b7sen", "dem", "Ge\u00b7sicht", "die", "sch\u00f6ns\u00b7ten", "Blu\u00b7men", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Wien, Franckreich, Welschland, Dre\u00dfden lehret,", "tokens": ["Wi\u00b7en", ",", "Fran\u00b7ck\u00b7reich", ",", "Wel\u00b7schland", ",", "Dre\u00df\u00b7den", "leh\u00b7ret", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "$,", "NE", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und zeiget uns sehr reichlich an,", "tokens": ["Und", "zei\u00b7get", "uns", "sehr", "reich\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was hier die Wunderhand gethan,", "tokens": ["Was", "hier", "die", "Wun\u00b7der\u00b7hand", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wie sie ihre Wercke mehret.", "tokens": ["Und", "wie", "sie", "ih\u00b7re", "Wer\u00b7cke", "meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was l\u00e4\u00dft nicht Hollands Garten-Feld", "tokens": ["Was", "l\u00e4\u00dft", "nicht", "Hol\u00b7lands", "Gar\u00b7ten\u00b7Feld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PTKNEG", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor Pflanzen und vor Bl\u00fcthen schie\u00dfen?", "tokens": ["Vor", "Pflan\u00b7zen", "und", "vor", "Bl\u00fc\u00b7then", "schie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hier mu\u00df des Menschen Herze schlie\u00dfen?", "tokens": ["Hier", "mu\u00df", "des", "Men\u00b7schen", "Her\u00b7ze", "schlie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gro\u00df ist der Meister dieser Welt!", "tokens": ["Gro\u00df", "ist", "der", "Meis\u00b7ter", "die\u00b7ser", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Geht nur nach Leiden hin! Ihr m\u00fcsset ja gestehen,", "tokens": ["Geht", "nur", "nach", "Lei\u00b7den", "hin", "!", "Ihr", "m\u00fcs\u00b7set", "ja", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df ihr die Aloe daselbst im Flor gesehen.", "tokens": ["Da\u00df", "ihr", "die", "A\u00b7loe", "da\u00b7selbst", "im", "Flor", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PAV", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.16": {"line.1": {"text": "Wo sinnt ihr hin! Was vor Vergn\u00fcgen", "tokens": ["Wo", "sinnt", "ihr", "hin", "!", "Was", "vor", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Treft ihr bey weisen Beeten an?", "tokens": ["Treft", "ihr", "bey", "wei\u00b7sen", "Bee\u00b7ten", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer denkt noch jetzo wohl daran,", "tokens": ["Wer", "denkt", "noch", "jet\u00b7zo", "wohl", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Florens Schoo\u00df vergn\u00fcgt zu liegen?", "tokens": ["Auf", "Flo\u00b7rens", "Schoo\u00df", "ver\u00b7gn\u00fcgt", "zu", "lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Zephyr z\u00fcrnt mit seiner Braut,", "tokens": ["Der", "Ze\u00b7phyr", "z\u00fcrnt", "mit", "sei\u00b7ner", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sondert sich von ihren Gr\u00e4nzen.", "tokens": ["Und", "son\u00b7dert", "sich", "von", "ih\u00b7ren", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wo will der Blumen Farbe gl\u00e4nzen?", "tokens": ["Wo", "will", "der", "Blu\u00b7men", "Far\u00b7be", "gl\u00e4n\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wo bl\u00fchet jetzt ein rares Kraut?", "tokens": ["Wo", "bl\u00fc\u00b7het", "jetzt", "ein", "ra\u00b7res", "Kraut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das Mahlwerk der Natur und was hervor gesprossen,", "tokens": ["Das", "Mahl\u00b7werk", "der", "Na\u00b7tur", "und", "was", "her\u00b7vor", "ge\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "PWS", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das hat ein weises Grab verdecket und verschlossen.", "tokens": ["Das", "hat", "ein", "wei\u00b7ses", "Grab", "ver\u00b7de\u00b7cket", "und", "ver\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Die\u00df ist wohl wahr; doch bleibt darneben", "tokens": ["Die\u00df", "ist", "wohl", "wahr", ";", "doch", "bleibt", "dar\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$.", "ADV", "VVFIN", "PAV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Allmacht Gottes unverletzt;", "tokens": ["Die", "All\u00b7macht", "Got\u00b7tes", "un\u00b7ver\u00b7letzt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie kan dem, der sich dran erg\u00f6tzt", "tokens": ["Sie", "kan", "dem", ",", "der", "sich", "dran", "er\u00b7g\u00f6tzt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "$,", "PRELS", "PRF", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Best\u00e4ndig neue Proben geben.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "neu\u00b7e", "Pro\u00b7ben", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geschicht was ausserordentlich,", "tokens": ["Ge\u00b7schicht", "was", "aus\u00b7ser\u00b7or\u00b7dent\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PWS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So ist das Wunder desto gr\u00f6sser,", "tokens": ["So", "ist", "das", "Wun\u00b7der", "des\u00b7to", "gr\u00f6s\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man merkt des Sch\u00f6pfers Wei\u00dfheit besser,", "tokens": ["Man", "merkt", "des", "Sch\u00f6p\u00b7fers", "Wei\u00df\u00b7heit", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und unsre Ehrfurcht mehret sich.", "tokens": ["Und", "uns\u00b7re", "Ehr\u00b7furcht", "meh\u00b7ret", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bewei\u00dft Gott seine Kraft und Wunderhand auf Erden,", "tokens": ["Be\u00b7wei\u00dft", "Gott", "sei\u00b7ne", "Kraft", "und", "Wun\u00b7der\u00b7hand", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPOSAT", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So mu\u00df wenn er nur will aus Winter Sommer werden.", "tokens": ["So", "mu\u00df", "wenn", "er", "nur", "will", "aus", "Win\u00b7ter", "Som\u00b7mer", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "KOUS", "PPER", "ADV", "VMFIN", "APPR", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Die\u00df mu\u00df jetzt Amsterdam bezeugen,", "tokens": ["Die\u00df", "mu\u00df", "jetzt", "A\u00b7mster\u00b7dam", "be\u00b7zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und aller Augen auf sich ziehn;/", "tokens": ["Und", "al\u00b7ler", "Au\u00b7gen", "auf", "sich", "ziehn", ";", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PRF", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hier sieht man eine Pflanze bl\u00fchn,", "tokens": ["Hier", "sieht", "man", "ei\u00b7ne", "Pflan\u00b7ze", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die wenig hohen H\u00e4uptern eigen.", "tokens": ["Die", "we\u00b7nig", "ho\u00b7hen", "H\u00e4up\u00b7tern", "ei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Tag der uns zw\u00f6lf Monath bringt,", "tokens": ["Der", "Tag", "der", "uns", "zw\u00f6lf", "Mo\u00b7nath", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPER", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "War kaum mit seinem Licht gekommen,", "tokens": ["War", "kaum", "mit", "sei\u00b7nem", "Licht", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So hat man freudig wargenommen,", "tokens": ["So", "hat", "man", "freu\u00b7dig", "war\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wiewohl des G\u00e4rtners Wunsch gelingt.", "tokens": ["Wie\u00b7wohl", "des", "G\u00e4rt\u00b7ners", "Wunsch", "ge\u00b7lingt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Musa ein Gew\u00e4chs und Pflanze seltner Sch\u00f6ne,", "tokens": ["Die", "Mu\u00b7sa", "ein", "Ge\u00b7w\u00e4chs", "und", "Pflan\u00b7ze", "selt\u00b7ner", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Vergn\u00fcgt das Silber-Haar, und auch die muntre S\u00f6hne.", "tokens": ["Ver\u00b7gn\u00fcgt", "das", "Sil\u00b7ber\u00b7Haar", ",", "und", "auch", "die", "mun\u00b7tre", "S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Ganz Holland hat in vorgen Tagen", "tokens": ["Ganz", "Hol\u00b7land", "hat", "in", "vor\u00b7gen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kaum einmahl ihre Blum gesehn,", "tokens": ["Kaum", "ein\u00b7mahl", "ih\u00b7re", "Blum", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Soll Deutschland ihren Flor gestehn,", "tokens": ["Soll", "Deutschland", "ih\u00b7ren", "Flor", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So kan es nur von zweymahl sagen.", "tokens": ["So", "kan", "es", "nur", "von", "zwey\u00b7mahl", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Europa kommt fast klagend ein,", "tokens": ["Eu\u00b7ro\u00b7pa", "kommt", "fast", "kla\u00b7gend", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und murret \u00fcber das Geschicke,", "tokens": ["Und", "mur\u00b7ret", "\u00fc\u00b7ber", "das", "Ge\u00b7schi\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ihr die\u00df sonderbahre Gl\u00fccke", "tokens": ["Da\u00df", "ihr", "die\u00df", "son\u00b7der\u00b7bah\u00b7re", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So wenigmahl soll wissend seyn.", "tokens": ["So", "we\u00b7nig\u00b7mahl", "soll", "wis\u00b7send", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Allmacht will im Gl\u00fcck bey diesen rauhen Zeiten,", "tokens": ["Die", "All\u00b7macht", "will", "im", "Gl\u00fcck", "bey", "die\u00b7sen", "rau\u00b7hen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPRART", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Durch dieser Pflanze Pracht vor Amsterdam bereiten.", "tokens": ["Durch", "die\u00b7ser", "Pflan\u00b7ze", "Pracht", "vor", "A\u00b7mster\u00b7dam", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "NN", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Ihr Augen! Was vor ein Vergn\u00fcgen", "tokens": ["Ihr", "Au\u00b7gen", "!", "Was", "vor", "ein", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "PWS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stellt euch nicht diese Musa dar?", "tokens": ["Stellt", "euch", "nicht", "die\u00b7se", "Mu\u00b7sa", "dar", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel hundert Seelen nimmt man wahr,", "tokens": ["Viel", "hun\u00b7dert", "See\u00b7len", "nimmt", "man", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sich zu ihren Zweigen f\u00fcgen.", "tokens": ["Die", "sich", "zu", "ih\u00b7ren", "Zwei\u00b7gen", "f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier steht man still; hier ruft man laut:", "tokens": ["Hier", "steht", "man", "still", ";", "hier", "ruft", "man", "laut", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$.", "ADV", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was kan wohl dieser Sch\u00f6nheit gleichen?", "tokens": ["Was", "kan", "wohl", "die\u00b7ser", "Sch\u00f6n\u00b7heit", "glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hier mu\u00df der gr\u00f6\u00dfte K\u00fcnstler weichen,", "tokens": ["Hier", "mu\u00df", "der", "gr\u00f6\u00df\u00b7te", "K\u00fcnst\u00b7ler", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So sehr er auf sein Wissen baut.", "tokens": ["So", "sehr", "er", "auf", "sein", "Wis\u00b7sen", "baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Blumen, die sie tr\u00e4gt, sind von besondern Gaben,", "tokens": ["Die", "Blu\u00b7men", ",", "die", "sie", "tr\u00e4gt", ",", "sind", "von", "be\u00b7son\u00b7dern", "Ga\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Daher sie in der Welt den gr\u00f6sten Vorzug haben.", "tokens": ["Da\u00b7her", "sie", "in", "der", "Welt", "den", "gr\u00f6s\u00b7ten", "Vor\u00b7zug", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Des Salomonis Herrlichkeiten", "tokens": ["Des", "Sa\u00b7lo\u00b7mo\u00b7nis", "Herr\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erreichten nicht der Lilien Pracht,", "tokens": ["Er\u00b7reich\u00b7ten", "nicht", "der", "Li\u00b7li\u00b7en", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Die Hand die sie hervor gebracht", "tokens": ["Die", "Hand", "die", "sie", "her\u00b7vor", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "PTKVZ", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weis ihren Adel anzudeuten.", "tokens": ["Weis", "ih\u00b7ren", "A\u00b7del", "an\u00b7zu\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In einen Garten k\u00f6nnen wir,", "tokens": ["In", "ei\u00b7nen", "Gar\u00b7ten", "k\u00f6n\u00b7nen", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An unsers hohen Sch\u00f6pfers Werken,", "tokens": ["An", "un\u00b7sers", "ho\u00b7hen", "Sch\u00f6p\u00b7fers", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Gr\u00f6sse seiner Wunder merken.", "tokens": ["Die", "Gr\u00f6s\u00b7se", "sei\u00b7ner", "Wun\u00b7der", "mer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "O! welche Wei\u00dfheit gleichet dir!", "tokens": ["O", "!", "wel\u00b7che", "Wei\u00df\u00b7heit", "glei\u00b7chet", "dir", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kan eine Lilie nun dein Lob so sehr erheben;", "tokens": ["Kan", "ei\u00b7ne", "Li\u00b7lie", "nun", "dein", "Lob", "so", "sehr", "er\u00b7he\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So mu\u00df dir Hollands Frucht noch gr\u00f6\u00dfre Ehre geben.", "tokens": ["So", "mu\u00df", "dir", "Hol\u00b7lands", "Frucht", "noch", "gr\u00f6\u00df\u00b7re", "Eh\u00b7re", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NE", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Zwar Ihr Gelehrten wolt jetzt fragen:", "tokens": ["Zwar", "Ihr", "Ge\u00b7lehr\u00b7ten", "wolt", "jetzt", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was vor ein Baum die Musa sey?", "tokens": ["Was", "vor", "ein", "Baum", "die", "Mu\u00b7sa", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Frag ist schwer und mancherley,", "tokens": ["Die", "Frag", "ist", "schwer", "und", "man\u00b7cher\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jeder meinet recht zu sagen.", "tokens": ["Und", "je\u00b7der", "mei\u00b7net", "recht", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Forscht immerhin und critisirt,", "tokens": ["Forscht", "im\u00b7mer\u00b7hin", "und", "cri\u00b7ti\u00b7sirt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr m\u00fcsset doch mit mir bekennen,", "tokens": ["Ihr", "m\u00fcs\u00b7set", "doch", "mit", "mir", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie sey ein solches Werk zu nennen,", "tokens": ["Sie", "sey", "ein", "sol\u00b7ches", "Werk", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das uns zum Lobe Gottes f\u00fchrt.", "tokens": ["Das", "uns", "zum", "Lo\u00b7be", "Got\u00b7tes", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Wesen giebt die Kraft des H\u00f6chsten zu verstehen,", "tokens": ["Ihr", "We\u00b7sen", "giebt", "die", "Kraft", "des", "H\u00f6chs\u00b7ten", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und l\u00e4sset uns ein St\u00fcck von seiner Allmacht sehen.", "tokens": ["Und", "l\u00e4s\u00b7set", "uns", "ein", "St\u00fcck", "von", "sei\u00b7ner", "All\u00b7macht", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}