{"textgrid.poem.32588": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "1L: In einem Hain, der einer Wildnis glich", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In einem Hain, der einer Wildnis glich", "tokens": ["In", "ei\u00b7nem", "Hain", ",", "der", "ei\u00b7ner", "Wild\u00b7nis", "glich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und nah am Meer ein kleines Gut begrenzte,", "tokens": ["Und", "nah", "am", "Meer", "ein", "klei\u00b7nes", "Gut", "be\u00b7grenz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ging Phanias mit seinem Gram und sich", "tokens": ["Ging", "Pha\u00b7ni\u00b7as", "mit", "sei\u00b7nem", "Gram", "und", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "PPOSAT", "NN", "KON", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Allein umher; der Abendwind durchstrich", "tokens": ["Al\u00b7lein", "um\u00b7her", ";", "der", "Ab\u00b7end\u00b7wind", "durch\u00b7strich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PTKVZ", "$.", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein fliegend Haar, das keine Ros umkr\u00e4nzte;", "tokens": ["Sein", "flie\u00b7gend", "Haar", ",", "das", "kei\u00b7ne", "Ros", "um\u00b7kr\u00e4nz\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verdrossenheit und Tr\u00fcbsinn malte sich", "tokens": ["Ver\u00b7dros\u00b7sen\u00b7heit", "und", "Tr\u00fcb\u00b7sinn", "mal\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "In Blick und Gang und Stellung sichtbarlich;", "tokens": ["In", "Blick", "und", "Gang", "und", "Stel\u00b7lung", "sicht\u00b7bar\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und was ihm noch zum Timon", "tokens": ["Und", "was", "ihm", "noch", "zum", "Ti\u00b7mon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Ein Mantel, so entfasert, abgef\u00e4rbt", "tokens": ["Ein", "Man\u00b7tel", ",", "so", "ent\u00b7fa\u00b7sert", ",", "ab\u00b7ge\u00b7f\u00e4rbt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ADV", "VVPP", "$,", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und ausgen\u00fctzt, da\u00df es Verdacht erweckte,", "tokens": ["Und", "aus\u00b7ge\u00b7n\u00fctzt", ",", "da\u00df", "es", "Ver\u00b7dacht", "er\u00b7weck\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Er h\u00e4tte den, der einst den Krates deckte,", "tokens": ["Er", "h\u00e4t\u00b7te", "den", ",", "der", "einst", "den", "Kra\u00b7tes", "deck\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Vom Aldermann der Cyniker geerbt.", "tokens": ["Vom", "Al\u00b7der\u00b7mann", "der", "Cy\u00b7ni\u00b7ker", "ge\u00b7erbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Gedankenvoll, mit halb geschlo\u00dfnen Blicken,", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7voll", ",", "mit", "halb", "ge\u00b7schlo\u00df\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Kopf gesenkt, die H\u00e4nde auf den R\u00fccken,", "tokens": ["Den", "Kopf", "ge\u00b7senkt", ",", "die", "H\u00e4n\u00b7de", "auf", "den", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ging er daher. Verwandelt wie er war,", "tokens": ["Ging", "er", "da\u00b7her", ".", "Ver\u00b7wan\u00b7delt", "wie", "er", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$.", "VVPP", "KOKOM", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit langem Bart und ungeschm\u00fccktem Haar,", "tokens": ["Mit", "lan\u00b7gem", "Bart", "und", "un\u00b7ge\u00b7schm\u00fcck\u00b7tem", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mit finstrer Stirn, in Cynischem Gewand", "tokens": ["Mit", "finst\u00b7rer", "Stirn", ",", "in", "Cy\u00b7ni\u00b7schem", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wer h\u00e4tt in ihm den Phanias erkannt,", "tokens": ["Wer", "h\u00e4tt", "in", "ihm", "den", "Pha\u00b7ni\u00b7as", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der k\u00fcrzlich noch von Grazien und Scherzen", "tokens": ["Der", "k\u00fcrz\u00b7lich", "noch", "von", "Gra\u00b7zi\u00b7en", "und", "Scher\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Umflattert war, den Sieger aller Herzen.", "tokens": ["Um\u00b7flat\u00b7tert", "war", ",", "den", "Sie\u00b7ger", "al\u00b7ler", "Her\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Der an Geschmack und Aufwand keinem wich,", "tokens": ["Der", "an", "Ge\u00b7schmack", "und", "Auf\u00b7wand", "kei\u00b7nem", "wich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und zu Athen, wo auch Sokraten zechten,", "tokens": ["Und", "zu", "A\u00b7then", ",", "wo", "auch", "Sok\u00b7ra\u00b7ten", "zech\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "$,", "PWAV", "ADV", "NN", "VVFIN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Beim muntern Fest, in durchgescherzten N\u00e4chten,", "tokens": ["Beim", "mun\u00b7tern", "Fest", ",", "in", "durch\u00b7ge\u00b7scherz\u00b7ten", "N\u00e4ch\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dem Komus bald, und bald dem Amor glich?", "tokens": ["Dem", "Ko\u00b7mus", "bald", ",", "und", "bald", "dem", "A\u00b7mor", "glich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KON", "ADV", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Erm\u00fcdet wirft er sich auf einen Rasen nieder,", "tokens": ["Er\u00b7m\u00fc\u00b7det", "wirft", "er", "sich", "auf", "ei\u00b7nen", "Ra\u00b7sen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sieht unger\u00fchrt die reizende Natur", "tokens": ["Sieht", "un\u00b7ge\u00b7r\u00fchrt", "die", "rei\u00b7zen\u00b7de", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So sch\u00f6n in ihrer Einfalt! h\u00f6rt die Lieder", "tokens": ["So", "sch\u00f6n", "in", "ih\u00b7rer", "Ein\u00b7falt", "!", "h\u00f6rt", "die", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$.", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Nachtigall, doch mit den Ohren nur.", "tokens": ["Der", "Nach\u00b7ti\u00b7gall", ",", "doch", "mit", "den", "Oh\u00b7ren", "nur", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ihr z\u00e4rtlicher Gesang sagt seinem Herzen nichts;", "tokens": ["Ihr", "z\u00e4rt\u00b7li\u00b7cher", "Ge\u00b7sang", "sagt", "sei\u00b7nem", "Her\u00b7zen", "nichts", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn ihn beraubt des Grams umschattendes Gefieder", "tokens": ["Denn", "ihn", "be\u00b7raubt", "des", "Grams", "um\u00b7schat\u00b7ten\u00b7des", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Des innern Ohrs, des geistigen Gesichts.", "tokens": ["Des", "in\u00b7nern", "Ohrs", ",", "des", "geis\u00b7ti\u00b7gen", "Ge\u00b7sichts", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Empfindungslos, wie einer der Medusen", "tokens": ["Emp\u00b7fin\u00b7dungs\u00b7los", ",", "wie", "ei\u00b7ner", "der", "Me\u00b7du\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PWAV", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Erblickt und starrt, erw\u00e4gt er zweifelsvoll", "tokens": ["Er\u00b7blickt", "und", "starrt", ",", "er\u00b7w\u00e4gt", "er", "zwei\u00b7fels\u00b7voll"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "KON", "VVFIN", "$,", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Nicht, wie vordem, wof\u00fcr er seufzen soll,", "tokens": ["Nicht", ",", "wie", "vor\u00b7dem", ",", "wo\u00b7f\u00fcr", "er", "seuf\u00b7zen", "soll", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "ADV", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "F\u00fcr welchen Mund, f\u00fcr welchen sch\u00f6nen Busen,", "tokens": ["F\u00fcr", "wel\u00b7chen", "Mund", ",", "f\u00fcr", "wel\u00b7chen", "sch\u00f6\u00b7nen", "Bu\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "$,", "APPR", "PWAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Nein, Phanias spricht jetzt der Torheit Hohn,", "tokens": ["Nein", ",", "Pha\u00b7ni\u00b7as", "spricht", "jetzt", "der", "Tor\u00b7heit", "Hohn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und ruft, seitdem aus seinem hohlen Beutel", "tokens": ["Und", "ruft", ",", "seit\u00b7dem", "aus", "sei\u00b7nem", "hoh\u00b7len", "Beu\u00b7tel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die letzte Drachme flog, wie K\u00f6nig Salomon:", "tokens": ["Die", "letz\u00b7te", "Drach\u00b7me", "flog", ",", "wie", "K\u00f6\u00b7nig", "Sa\u00b7lo\u00b7mon", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Was unterm Monde liegt, ist eitel!", "tokens": ["Was", "un\u00b7term", "Mon\u00b7de", "liegt", ",", "ist", "ei\u00b7tel", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NE", "VVFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ja wohl, verg\u00e4nglich ist und fl\u00fcchtiger als Wind", "tokens": ["Ja", "wohl", ",", "ver\u00b7g\u00e4ng\u00b7lich", "ist", "und", "fl\u00fcch\u00b7ti\u00b7ger", "als", "Wind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$,", "ADJD", "VAFIN", "KON", "ADJA", "KOUS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sch\u00f6nen Gunst, die Brudertreu der Zecher;", "tokens": ["Der", "Sch\u00f6\u00b7nen", "Gunst", ",", "die", "Bru\u00b7der\u00b7treu", "der", "Ze\u00b7cher", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So bald nicht mehr der goldne Regen rinnt,", "tokens": ["So", "bald", "nicht", "mehr", "der", "gold\u00b7ne", "Re\u00b7gen", "rinnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ist keine Danae, so bald im trocknen Becher", "tokens": ["Ist", "kei\u00b7ne", "Da\u00b7nae", ",", "so", "bald", "im", "trock\u00b7nen", "Be\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NE", "$,", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Der Wein versiegt, ist kein Patroklus mehr.", "tokens": ["Der", "Wein", "ver\u00b7siegt", ",", "ist", "kein", "Pat\u00b7ro\u00b7klus", "mehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was Fliegen lockt, das lockt auch Freunde her;", "tokens": ["Was", "Flie\u00b7gen", "lockt", ",", "das", "lockt", "auch", "Freun\u00b7de", "her", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$,", "PDS", "VVFIN", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Gold zieht magnetischer, als Sch\u00f6nheit, Witz und Jugend:", "tokens": ["Gold", "zieht", "mag\u00b7ne\u00b7ti\u00b7scher", ",", "als", "Sch\u00f6n\u00b7heit", ",", "Witz", "und", "Ju\u00b7gend", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,", "KOUS", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.8": {"text": "Ist eure Hand, ist eure Tafel leer,", "tokens": ["Ist", "eu\u00b7re", "Hand", ",", "ist", "eu\u00b7re", "Ta\u00b7fel", "leer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "So flieht der N\u00e4scher Schwarm, und Lais spricht von Tugend.", "tokens": ["So", "flieht", "der", "N\u00e4\u00b7scher", "Schwarm", ",", "und", "Lais", "spricht", "von", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "NE", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Der gro\u00dfen Wahrheit voll, da\u00df alles eitel sei", "tokens": ["Der", "gro\u00b7\u00dfen", "Wahr\u00b7heit", "voll", ",", "da\u00df", "al\u00b7les", "ei\u00b7tel", "sei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "KOUS", "PIS", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Womit der Mensch in seinen Fr\u00fchlingsjahren,", "tokens": ["Wo\u00b7mit", "der", "Mensch", "in", "sei\u00b7nen", "Fr\u00fch\u00b7lings\u00b7jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Berauscht von s\u00fc\u00dfer Raserei,", "tokens": ["Be\u00b7rauscht", "von", "s\u00fc\u00b7\u00dfer", "Ra\u00b7se\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Leichtsinnig, l\u00fcstern, rasch und unerfahren,", "tokens": ["Leicht\u00b7sin\u00b7nig", ",", "l\u00fcs\u00b7tern", ",", "rasch", "und", "un\u00b7er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "In seinem Paradies von Rosen und Schasmin", "tokens": ["In", "sei\u00b7nem", "Pa\u00b7ra\u00b7dies", "von", "Ro\u00b7sen", "und", "Schas\u00b7min"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Ein kleiner Gott sich d\u00fcnkt, setzt Phanias, der Weise,", "tokens": ["Ein", "klei\u00b7ner", "Gott", "sich", "d\u00fcnkt", ",", "setzt", "Pha\u00b7ni\u00b7as", ",", "der", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "$,", "VVFIN", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie Herkules, sich auf den ", "tokens": ["Wie", "Her\u00b7ku\u00b7les", ",", "sich", "auf", "den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "NE", "$,", "PRF", "APPR", "ART"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "(nur schon zu sp\u00e4t) und sinnt der schweren Reise", "tokens": ["(", "nur", "schon", "zu", "sp\u00e4t", ")", "und", "sinnt", "der", "schwe\u00b7ren", "Rei\u00b7se"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADV", "PTKA", "ADJD", "$(", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Des Lebens nach. Was soll, was kann er tun?", "tokens": ["Des", "Le\u00b7bens", "nach", ".", "Was", "soll", ",", "was", "kann", "er", "tun", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "PWS", "VMFIN", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Es ist so s\u00fc\u00df, auf Flaum und Rosenbl\u00e4ttern", "tokens": ["Es", "ist", "so", "s\u00fc\u00df", ",", "auf", "Flaum", "und", "Ro\u00b7sen\u00b7bl\u00e4t\u00b7tern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Im Arm der Wollust sich verg\u00f6ttern,", "tokens": ["Im", "Arm", "der", "Wol\u00b7lust", "sich", "ver\u00b7g\u00f6t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und nur vom \u00dcberma\u00df der Freuden auszuruhn!", "tokens": ["Und", "nur", "vom", "\u00dc\u00b7berm\u00b7a\u00df", "der", "Freu\u00b7den", "aus\u00b7zu\u00b7ruhn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Es ist so unbequem, den Dornenpfad zu klettern!", "tokens": ["Es", "ist", "so", "un\u00b7be\u00b7quem", ",", "den", "Dor\u00b7nen\u00b7pfad", "zu", "klet\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was t\u00e4tet ihr? \u2013 Hier ist, wie vielen deucht,", "tokens": ["Was", "t\u00e4\u00b7tet", "ihr", "?", "\u2013", "Hier", "ist", ",", "wie", "vie\u00b7len", "deucht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "$(", "ADV", "VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Das W\u00e4hlen schwer: dem Phanias war's leicht.", "tokens": ["Das", "W\u00e4h\u00b7len", "schwer", ":", "dem", "Pha\u00b7ni\u00b7as", "wa\u00b7r's", "leicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Er sieht die sch\u00f6ne Ungetreue,", "tokens": ["Er", "sieht", "die", "sch\u00f6\u00b7ne", "Un\u00b7ge\u00b7treu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.18": {"text": "Zu j\u00fcngern G\u00fcnstlingen aus seinen Armen fliehn;", "tokens": ["Zu", "j\u00fcn\u00b7gern", "G\u00fcnst\u00b7lin\u00b7gen", "aus", "sei\u00b7nen", "Ar\u00b7men", "fliehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Die Scherze mit den Amorinen fliehn", "tokens": ["Die", "Scher\u00b7ze", "mit", "den", "A\u00b7mo\u00b7ri\u00b7nen", "fliehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Der G\u00f6ttin nach, verlassen lachend ihn,", "tokens": ["Der", "G\u00f6t\u00b7tin", "nach", ",", "ver\u00b7las\u00b7sen", "la\u00b7chend", "ihn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "VVFIN", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Und schicken ihm zum Zeitvertreib die ", "tokens": ["Und", "schi\u00b7cken", "ihm", "zum", "Zeit\u00b7ver\u00b7treib", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Hingegen winken ihm aus ihrem Heiligtum", "tokens": ["Hin\u00b7ge\u00b7gen", "win\u00b7ken", "ihm", "aus", "ih\u00b7rem", "Hei\u00b7lig\u00b7tum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.23": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.24": {"text": "Und zeigen ihm den edlen ", "tokens": ["Und", "zei\u00b7gen", "ihm", "den", "ed\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Der neue Herkules schickt seufzend einen Blick", "tokens": ["Der", "neu\u00b7e", "Her\u00b7ku\u00b7les", "schickt", "seuf\u00b7zend", "ei\u00b7nen", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.26": {"text": "Den schon Entflohnen nach, ob sie nicht wiederkehren:", "tokens": ["Den", "schon", "Ent\u00b7floh\u00b7nen", "nach", ",", "ob", "sie", "nicht", "wie\u00b7der\u00b7keh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "PTKVZ", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Sie kehren, leider! nicht zur\u00fcck,", "tokens": ["Sie", "keh\u00b7ren", ",", "lei\u00b7der", "!", "nicht", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "$.", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und nun entschlie\u00dft er sich der Helden Zahl zu mehren!", "tokens": ["Und", "nun", "ent\u00b7schlie\u00dft", "er", "sich", "der", "Hel\u00b7den", "Zahl", "zu", "meh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der Helden Zahl? \u2013 Hier steht er wieder an;", "tokens": ["Der", "Hel\u00b7den", "Zahl", "?", "\u2013", "Hier", "steht", "er", "wie\u00b7der", "an", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der k\u00fchne Vorsatz bleibt in neuen Zweifeln schweben.", "tokens": ["Der", "k\u00fch\u00b7ne", "Vor\u00b7satz", "bleibt", "in", "neu\u00b7en", "Zwei\u00b7feln", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zwar ist es sch\u00f6n, auf lorbeernvoller Bahn", "tokens": ["Zwar", "ist", "es", "sch\u00f6n", ",", "auf", "lor\u00b7be\u00b7ern\u00b7vol\u00b7ler", "Bahn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Zum Rang der G\u00f6ttlichen die in der Nachwelt leben,", "tokens": ["Zum", "Rang", "der", "G\u00f6tt\u00b7li\u00b7chen", "die", "in", "der", "Nach\u00b7welt", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu einem Platz im Sternenplan", "tokens": ["Zu", "ei\u00b7nem", "Platz", "im", "Ster\u00b7nen\u00b7plan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und im Plutarch, sich zu erheben;", "tokens": ["Und", "im", "Plu\u00b7tarch", ",", "sich", "zu", "er\u00b7he\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sch\u00f6n, sich der tr\u00e4gen Ruh entziehn,", "tokens": ["Sch\u00f6n", ",", "sich", "der", "tr\u00e4\u00b7gen", "Ruh", "ent\u00b7ziehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRF", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.8": {"text": "Gefahren suchen; keine fliehn, Auf edle Abenteuer ziehn,", "tokens": ["Ge\u00b7fah\u00b7ren", "su\u00b7chen", ";", "kei\u00b7ne", "fliehn", ",", "Auf", "ed\u00b7le", "A\u00b7bent\u00b7eu\u00b7er", "ziehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$.", "PIAT", "VVINF", "$,", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.9": {"text": "Und die gerochne Welt mit Riesenblute f\u00e4rben;", "tokens": ["Und", "die", "ge\u00b7roch\u00b7ne", "Welt", "mit", "Rie\u00b7sen\u00b7blu\u00b7te", "f\u00e4r\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sch\u00f6n, ", "tokens": ["Sch\u00f6n", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Ein Dichter, der zwar selbst beim ersten Anla\u00df floh,", "tokens": ["Ein", "Dich\u00b7ter", ",", "der", "zwar", "selbst", "beim", "ers\u00b7ten", "An\u00b7la\u00df", "floh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "S\u00fc\u00df ist's, und ehrenvoll, f\u00fcrs Vaterland zu sterben.", "tokens": ["S\u00fc\u00df", "ist's", ",", "und", "eh\u00b7ren\u00b7voll", ",", "f\u00fcrs", "Va\u00b7ter\u00b7land", "zu", "ster\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "ADJD", "$,", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch auch die Weisheit kann Unsterblichkeit erwerben!", "tokens": ["Doch", "auch", "die", "Weis\u00b7heit", "kann", "U\u00b7nsterb\u00b7lich\u00b7keit", "er\u00b7wer\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Wie pr\u00e4chtig klingt's, den fesselfreien Geist", "tokens": ["Wie", "pr\u00e4ch\u00b7tig", "klingt's", ",", "den", "fes\u00b7sel\u00b7frei\u00b7en", "Geist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Im reinsten Quell des Lichts von seinen Flecken waschen,", "tokens": ["Im", "reins\u00b7ten", "Quell", "des", "Lichts", "von", "sei\u00b7nen", "Fle\u00b7cken", "wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Wahrheit, die sich sonst nie ohne Schleier weist,", "tokens": ["Die", "Wahr\u00b7heit", ",", "die", "sich", "sonst", "nie", "oh\u00b7ne", "Schlei\u00b7er", "weist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "(nie, oder G\u00f6ttern nur) entkleidet \u00fcberraschen;", "tokens": ["(", "nie", ",", "o\u00b7der", "G\u00f6t\u00b7tern", "nur", ")", "ent\u00b7klei\u00b7det", "\u00fc\u00b7berr\u00b7a\u00b7schen", ";"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "KON", "NN", "ADV", "$(", "VVPP", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.18": {"text": "Der Sch\u00f6pfung Grundri\u00df \u00fcbersehn,", "tokens": ["Der", "Sch\u00f6p\u00b7fung", "Grun\u00b7dri\u00df", "\u00fc\u00b7ber\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der Sph\u00e4ren mystischen verworrnen Tanz verstehn,", "tokens": ["Der", "Sph\u00e4\u00b7ren", "mys\u00b7ti\u00b7schen", "ver\u00b7worr\u00b7nen", "Tanz", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Vermutungen auf stolze Schl\u00fcsse h\u00e4ufen,", "tokens": ["Ver\u00b7mu\u00b7tun\u00b7gen", "auf", "stol\u00b7ze", "Schl\u00fcs\u00b7se", "h\u00e4u\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Und bis ins Reich der reinen Geister streifen;", "tokens": ["Und", "bis", "ins", "Reich", "der", "rei\u00b7nen", "Geis\u00b7ter", "strei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Wie glorreich! welche Lust! \u2013 Nennt immer Den begl\u00fcckt", "tokens": ["Wie", "glor\u00b7reich", "!", "wel\u00b7che", "Lust", "!", "\u2013", "Nennt", "im\u00b7mer", "Den", "be\u00b7gl\u00fcckt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$.", "PWAT", "NN", "$.", "$(", "VVFIN", "ADV", "ART", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und frei und gro\u00df, den Mann der nie gezittert,", "tokens": ["Und", "frei", "und", "gro\u00df", ",", "den", "Mann", "der", "nie", "ge\u00b7zit\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "ART", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Den der Trompete Ruf zur wilden Schlacht entz\u00fcckt,", "tokens": ["Den", "der", "Trom\u00b7pe\u00b7te", "Ruf", "zur", "wil\u00b7den", "Schlacht", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.25": {"text": "Der l\u00e4chelnd sieht was Menschen sonst ersch\u00fcttert", "tokens": ["Der", "l\u00e4\u00b7chelnd", "sieht", "was", "Men\u00b7schen", "sonst", "er\u00b7sch\u00fct\u00b7tert"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVFIN", "PIS", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und selbst den Tod, der ihn mit Lorbeern schm\u00fcckt,", "tokens": ["Und", "selbst", "den", "Tod", ",", "der", "ihn", "mit", "Lor\u00b7beern", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Wie eine Braut an seinen Busen dr\u00fcckt:", "tokens": ["Wie", "ei\u00b7ne", "Braut", "an", "sei\u00b7nen", "Bu\u00b7sen", "dr\u00fcckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Viel gr\u00f6\u00dfer, gl\u00fccklicher ist ", "tokens": ["Viel", "gr\u00f6\u00b7\u00dfer", ",", "gl\u00fcck\u00b7li\u00b7cher", "ist"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADJD", "VAFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.29": {"text": "Den, von Minervens Schild bedeckt,", "tokens": ["Den", ",", "von", "Mi\u00b7ner\u00b7vens", "Schild", "be\u00b7deckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "NE", "NN", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.30": {"text": "Kein n\u00e4chtliches Phantom, kein Aberglaube schreckt;", "tokens": ["Kein", "n\u00e4cht\u00b7li\u00b7ches", "Phan\u00b7tom", ",", "kein", "A\u00b7berg\u00b7lau\u00b7be", "schreckt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Den Flammen, die auf Leinwand brennen,", "tokens": ["Den", "Flam\u00b7men", ",", "die", "auf", "Lein\u00b7wand", "bren\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Und Styx und Acheron nicht bl\u00e4sser machen k\u00f6nnen;", "tokens": ["Und", "Styx", "und", "A\u00b7che\u00b7ron", "nicht", "bl\u00e4s\u00b7ser", "ma\u00b7chen", "k\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NN", "PTKNEG", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Der ohne Furcht Kometen brennen sieht,", "tokens": ["Der", "oh\u00b7ne", "Furcht", "Ko\u00b7me\u00b7ten", "bren\u00b7nen", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Die hohen G\u00f6tter nicht mit Taschenspiel bem\u00fcht,", "tokens": ["Die", "ho\u00b7hen", "G\u00f6t\u00b7ter", "nicht", "mit", "Ta\u00b7schen\u00b7spiel", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und, weil kein Wahn die Augen ihm verbindet,", "tokens": ["Und", ",", "weil", "kein", "Wahn", "die", "Au\u00b7gen", "ihm", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIAT", "NN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Stets die Natur sich gleich, stets regelm\u00e4\u00dfig findet.", "tokens": ["Stets", "die", "Na\u00b7tur", "sich", "gleich", ",", "stets", "re\u00b7gel\u00b7m\u00e4\u00b7\u00dfig", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PRF", "ADV", "$,", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "War Philipps Sohn ein Held, der sich der Lust entzog", "tokens": ["War", "Phi\u00b7lipps", "Sohn", "ein", "Held", ",", "der", "sich", "der", "Lust", "ent\u00b7zog"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NE", "NN", "ART", "NN", "$,", "PRELS", "PRF", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In welcher unber\u00fchmt die Ninias zerrannen,", "tokens": ["In", "wel\u00b7cher", "un\u00b7be\u00b7r\u00fchmt", "die", "Ni\u00b7ni\u00b7as", "zer\u00b7ran\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und auf zertr\u00fcmmerten Tyrannen", "tokens": ["Und", "auf", "zer\u00b7tr\u00fcm\u00b7mer\u00b7ten", "Ty\u00b7ran\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Sieg zu Sieg bis an den Indus flog?", "tokens": ["Von", "Sieg", "zu", "Sieg", "bis", "an", "den", "In\u00b7dus", "flog", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "APPR", "APPR", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein w\u00e4lzender Triumph zermalmte tausend St\u00e4dte,", "tokens": ["Sein", "w\u00e4l\u00b7zen\u00b7der", "Tri\u00b7umph", "zer\u00b7malm\u00b7te", "tau\u00b7send", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zertrat die halbe Welt \u2013 warum? la\u00dft's ihn gestehn!", "tokens": ["Zer\u00b7trat", "die", "hal\u00b7be", "Welt", "\u2013", "wa\u00b7rum", "?", "la\u00dft's", "ihn", "ge\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$(", "PWAV", "$.", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u00bbdamit der P\u00f6bel von Athen", "tokens": ["\u00bb", "da\u00b7mit", "der", "P\u00f6\u00b7bel", "von", "A\u00b7then"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PAV", "ART", "NN", "APPR", "NE"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Beim nassen Schmaus von ihm zu reden h\u00e4tte.\u00ab", "tokens": ["Beim", "nas\u00b7sen", "Schmaus", "von", "ihm", "zu", "re\u00b7den", "h\u00e4t\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "VAFIN", "$.", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Um wie viel mehr, als solch ein Weltbezwinger,", "tokens": ["Um", "wie", "viel", "mehr", ",", "als", "solch", "ein", "Welt\u00b7be\u00b7zwin\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "KOKOM", "ADV", "ADV", "$,", "KOUS", "PIAT", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ist ", "tokens": ["Ist"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Als Jupiter, der ", "tokens": ["Als", "Ju\u00b7pi\u00b7ter", ",", "der"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "NN", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Sich k\u00fchn entschlie\u00dft; dem Lust kein Gut, und Pein", "tokens": ["Sich", "k\u00fchn", "ent\u00b7schlie\u00dft", ";", "dem", "Lust", "kein", "Gut", ",", "und", "Pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PRF", "ADJD", "VVFIN", "$.", "ART", "NN", "PIAT", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Kein \u00dcbel ist; zu gro\u00df, sich zu beklagen,", "tokens": ["Kein", "\u00dc\u00b7bel", "ist", ";", "zu", "gro\u00df", ",", "sich", "zu", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$.", "PTKA", "ADJD", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Zu weise, sich zu freun; der jede Leidenschaft", "tokens": ["Zu", "wei\u00b7se", ",", "sich", "zu", "freun", ";", "der", "je\u00b7de", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKA", "ADJD", "$,", "PRF", "PTKZU", "VVINF", "$.", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Als Sieger an der Tugend Wagen", "tokens": ["Als", "Sie\u00b7ger", "an", "der", "Tu\u00b7gend", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Gefesselt hat und im Triumphe f\u00fchrt;", "tokens": ["Ge\u00b7fes\u00b7selt", "hat", "und", "im", "Tri\u00b7um\u00b7phe", "f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KON", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Den alles Gold der Inder nicht verf\u00fchrt;", "tokens": ["Den", "al\u00b7les", "Gold", "der", "In\u00b7der", "nicht", "ver\u00b7f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Den nur sein eigener, kein fremder Beifall r\u00fchrt;", "tokens": ["Den", "nur", "sein", "ei\u00b7ge\u00b7ner", ",", "kein", "frem\u00b7der", "Bei\u00b7fall", "r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "ADJA", "$,", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.19": {"text": "Kurz, der in Phalaris durchgl\u00fchtem Stier verd\u00e4rbe", "tokens": ["Kurz", ",", "der", "in", "Pha\u00b7la\u00b7ris", "durch\u00b7gl\u00fch\u00b7tem", "Stier", "ver\u00b7d\u00e4r\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PRELS", "APPR", "NE", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Eh er in Phrynens Arm \u2013 ein ", "tokens": ["Eh", "er", "in", "Phry\u00b7nens", "Arm", "\u2013", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPR", "NE", "NN", "$(", "ART"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "In solche schimmernde Betrachtungen vertieft", "tokens": ["In", "sol\u00b7che", "schim\u00b7mern\u00b7de", "Be\u00b7trach\u00b7tun\u00b7gen", "ver\u00b7tieft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lag Phanias, schon mehr als halb entschlossen;", "tokens": ["Lag", "Pha\u00b7ni\u00b7as", ",", "schon", "mehr", "als", "halb", "ent\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ADV", "PIAT", "KOKOM", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als Amor unverhofft die neue Denkart pr\u00fcft,", "tokens": ["Als", "A\u00b7mor", "un\u00b7ver\u00b7hofft", "die", "neu\u00b7e", "Den\u00b7kart", "pr\u00fcft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADJD", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Gram, Philosophie und Not ihm eingegossen.", "tokens": ["Die", "Gram", ",", "Phi\u00b7lo\u00b7so\u00b7phie", "und", "Not", "ihm", "ein\u00b7ge\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er sah, und h\u00e4tte gern den Augen nicht getraut,", "tokens": ["Er", "sah", ",", "und", "h\u00e4t\u00b7te", "gern", "den", "Au\u00b7gen", "nicht", "ge\u00b7traut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VAFIN", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ein Gesicht, wovor ihm billig graut,", "tokens": ["Die", "ein", "Ge\u00b7sicht", ",", "wo\u00b7vor", "ihm", "bil\u00b7lig", "graut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$,", "PWAV", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zu sehn sich nicht erwehren, k\u00f6nnen.", "tokens": ["Zu", "sehn", "sich", "nicht", "er\u00b7weh\u00b7ren", ",", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKZU", "VVINF", "PRF", "PTKNEG", "VVINF", "$,", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die G\u00f6tter werden ihm den Ruhm doch nicht mi\u00dfg\u00f6nnen,", "tokens": ["Die", "G\u00f6t\u00b7ter", "wer\u00b7den", "ihm", "den", "Ruhm", "doch", "nicht", "mi\u00df\u00b7g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Xenokrat zu sein? Was hilft Entschlossenheit?", "tokens": ["Ein", "Xe\u00b7no\u00b7krat", "zu", "sein", "?", "Was", "hilft", "Ent\u00b7schlos\u00b7sen\u00b7heit", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VAINF", "$.", "PWS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Augenblick der uns Minerven weiht", "tokens": ["Im", "Au\u00b7gen\u00b7blick", "der", "uns", "Mi\u00b7ner\u00b7ven", "weiht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "PPER", "NN", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Kommt Cytherea selbst zur ungelegnen Zeit.", "tokens": ["Kommt", "Cy\u00b7the\u00b7rea", "selbst", "zur", "un\u00b7ge\u00b7leg\u00b7nen", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Zwar ", "tokens": ["Zwar"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Die Sch\u00f6ne, welche kam, vielleicht sich vor der Wette,", "tokens": ["Die", "Sch\u00f6\u00b7ne", ",", "wel\u00b7che", "kam", ",", "viel\u00b7leicht", "sich", "vor", "der", "Wet\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$,", "ADV", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Pallas einst verlor, gleich wenig sich gescheut.", "tokens": ["Die", "Pal\u00b7las", "einst", "ver\u00b7lor", ",", "gleich", "we\u00b7nig", "sich", "ge\u00b7scheut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "ADV", "PIS", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sch\u00f6n, wenn der Schleier blo\u00df ihr schwarzes Aug entdeckte,", "tokens": ["Sch\u00f6n", ",", "wenn", "der", "Schlei\u00b7er", "blo\u00df", "ihr", "schwar\u00b7zes", "Aug", "ent\u00b7deck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "ART", "NN", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Noch sch\u00f6ner, wenn er nichts versteckte;", "tokens": ["Noch", "sch\u00f6\u00b7ner", ",", "wenn", "er", "nichts", "ver\u00b7steck\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gefallend, wenn sie schwieg, bezaubernd, wenn sie sprach:", "tokens": ["Ge\u00b7fal\u00b7lend", ",", "wenn", "sie", "schwieg", ",", "be\u00b7zau\u00b7bernd", ",", "wenn", "sie", "sprach", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dann h\u00e4tt ihr Witz auch Wangen ohne Rosen", "tokens": ["Dann", "h\u00e4tt", "ihr", "Witz", "auch", "Wan\u00b7gen", "oh\u00b7ne", "Ro\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Beliebt gemacht; ein Witz, dem's nie an Reiz gebrach,", "tokens": ["Be\u00b7liebt", "ge\u00b7macht", ";", "ein", "Witz", ",", "dem's", "nie", "an", "Reiz", "ge\u00b7brach", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$.", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zu stechen oder liebzukosen", "tokens": ["Zu", "ste\u00b7chen", "o\u00b7der", "lieb\u00b7zu\u00b7ko\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Gleich aufgelegt, doch l\u00e4chelnd wenn er stach", "tokens": ["Gleich", "auf\u00b7ge\u00b7legt", ",", "doch", "l\u00e4\u00b7chelnd", "wenn", "er", "stach"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "$,", "ADV", "ADJD", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und ohne Gift. Nie sahe man die Musen", "tokens": ["Und", "oh\u00b7ne", "Gift", ".", "Nie", "sa\u00b7he", "man", "die", "Mu\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "$.", "ADV", "VVFIN", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und Grazien in einem sch\u00f6nern Bund,", "tokens": ["Und", "Gra\u00b7zi\u00b7en", "in", "ei\u00b7nem", "sch\u00f6\u00b7nern", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Nie scherzte die Vernunft aus einem sch\u00f6nern Mund;", "tokens": ["Nie", "scherz\u00b7te", "die", "Ver\u00b7nunft", "aus", "ei\u00b7nem", "sch\u00f6\u00b7nern", "Mund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und Amor nie um einen sch\u00f6nern Busen.", "tokens": ["Und", "A\u00b7mor", "nie", "um", "ei\u00b7nen", "sch\u00f6\u00b7nern", "Bu\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "So war, die ihm erschien, so war Musarion.", "tokens": ["So", "war", ",", "die", "ihm", "er\u00b7schien", ",", "so", "war", "Mu\u00b7sa\u00b7ri\u00b7on", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sagt, Freunde, wenn mit einer solchen Miene", "tokens": ["Sagt", ",", "Freun\u00b7de", ",", "wenn", "mit", "ei\u00b7ner", "sol\u00b7chen", "Mie\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "KOUS", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Im wildsten Hain ein M\u00e4dchen euch erschiene,", "tokens": ["Im", "wilds\u00b7ten", "Hain", "ein", "M\u00e4d\u00b7chen", "euch", "er\u00b7schie\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "PPER", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Hand aufs Herz! sagt, liefet ihr davon?", "tokens": ["Die", "Hand", "aufs", "Herz", "!", "sagt", ",", "lie\u00b7fet", "ihr", "da\u00b7von", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "VVFIN", "$,", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbso lief denn Phanias?\u00ab \u2013 Das konntet ihr erraten!", "tokens": ["\u00bb", "so", "lief", "denn", "Pha\u00b7ni\u00b7as", "?", "\u00ab", "\u2013", "Das", "konn\u00b7tet", "ihr", "er\u00b7ra\u00b7ten", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "KON", "NE", "$.", "$(", "$(", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er tat was Wenige in seinem Falle ", "tokens": ["Er", "tat", "was", "We\u00b7ni\u00b7ge", "in", "sei\u00b7nem", "Fal\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PWS", "PIS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Allein, was jeder ", "tokens": ["Al\u00b7lein", ",", "was", "je\u00b7der"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADV", "$,", "PRELS", "PIS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Er sprang vom Boden auf, und \u2013 hielt ein wenig still,", "tokens": ["Er", "sprang", "vom", "Bo\u00b7den", "auf", ",", "und", "\u2013", "hielt", "ein", "we\u00b7nig", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "KON", "$(", "VVFIN", "ART", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Um recht gewi\u00df zu sehn was ihm sein Auge sagte;", "tokens": ["Um", "recht", "ge\u00b7wi\u00df", "zu", "sehn", "was", "ihm", "sein", "Au\u00b7ge", "sag\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "PTKZU", "VVINF", "PWS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und da er sah, es sei Musarion,", "tokens": ["Und", "da", "er", "sah", ",", "es", "sei", "Mu\u00b7sa\u00b7ri\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "So lief er euch \u2013 der weise Mann! \u2013 davon", "tokens": ["So", "lief", "er", "euch", "\u2013", "der", "wei\u00b7se", "Mann", "!", "\u2013", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$(", "ART", "ADJA", "NN", "$.", "$(", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Als ob ein Arimasp ihn jagte.", "tokens": ["Als", "ob", "ein", "A\u00b7ri\u00b7masp", "ihn", "jag\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "\u00bbdu fliehest, Phanias?\u00ab ruft sie ihm lachend nach:", "tokens": ["\u00bb", "du", "flie\u00b7hest", ",", "Pha\u00b7ni\u00b7as", "?", "\u00ab", "ruft", "sie", "ihm", "la\u00b7chend", "nach", ":"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "NE", "$.", "$(", "VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "\u00bberkennest mich und fliehst? Gut, fliehe nur, du Spr\u00f6der!", "tokens": ["\u00bb", "er\u00b7ken\u00b7nest", "mich", "und", "fliehst", "?", "Gut", ",", "flie\u00b7he", "nur", ",", "du", "Spr\u00f6\u00b7der", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "KON", "VVFIN", "$.", "ADJD", "$,", "VVFIN", "ADV", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Kaltsinn macht Musarion nicht bl\u00f6der;", "tokens": ["Dein", "Kal\u00b7tsinn", "macht", "Mu\u00b7sa\u00b7ri\u00b7on", "nicht", "bl\u00f6\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du schmeichelst dir doch wohl, sie sei so schwach", "tokens": ["Du", "schmei\u00b7chelst", "dir", "doch", "wohl", ",", "sie", "sei", "so", "schwach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,", "PPER", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dir nachzufliehn?\u00ab \u2013 Durch ungebahnte Pfade", "tokens": ["Dir", "nach\u00b7zu\u00b7fliehn", "?", "\u00ab", "\u2013", "Durch", "un\u00b7ge\u00b7bahn\u00b7te", "Pfa\u00b7de"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVINF", "$.", "$(", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wand er wie eine Schlange sich:", "tokens": ["Wand", "er", "wie", "ei\u00b7ne", "Schlan\u00b7ge", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ART", "NN", "PRF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "So schl\u00fcpft die keusche Oreade", "tokens": ["So", "schl\u00fcpft", "die", "keu\u00b7sche", "O\u00b7rea\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Dem Satyr aus der Hand, der sie im Bad erschlich.", "tokens": ["Dem", "Sa\u00b7tyr", "aus", "der", "Hand", ",", "der", "sie", "im", "Bad", "er\u00b7schlich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Sch\u00f6ne folgt mit leichten Zephyrf\u00fc\u00dfen,", "tokens": ["Die", "Sch\u00f6\u00b7ne", "folgt", "mit", "leich\u00b7ten", "Ze\u00b7phyr\u00b7f\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Doch ohne Hast; denn (dachte sie) am Strand", "tokens": ["Doch", "oh\u00b7ne", "Hast", ";", "denn", "(", "dach\u00b7te", "sie", ")", "am", "Strand"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "NN", "$.", "KON", "$(", "VVFIN", "PPER", "$(", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wohin er flieht, wird er wohl halten m\u00fcssen.", "tokens": ["Wo\u00b7hin", "er", "flieht", ",", "wird", "er", "wohl", "hal\u00b7ten", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Es war ihr Gl\u00fcck, da\u00df sich kein Nachen fand;", "tokens": ["Es", "war", "ihr", "Gl\u00fcck", ",", "da\u00df", "sich", "kein", "Na\u00b7chen", "fand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "KOUS", "PRF", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Denn, der Versuchung zu entgehen,", "tokens": ["Denn", ",", "der", "Ver\u00b7su\u00b7chung", "zu", "ent\u00b7ge\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.14": {"text": "Was t\u00e4t ein Weiser nicht, Doch da er keinen fand,", "tokens": ["Was", "t\u00e4t", "ein", "Wei\u00b7ser", "nicht", ",", "Doch", "da", "er", "kei\u00b7nen", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KON", "KOUS", "PPER", "PIAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wohin entfliehn? \u2013 Es ist um ihn geschehen", "tokens": ["Wo\u00b7hin", "ent\u00b7fliehn", "?", "\u2013", "Es", "ist", "um", "ihn", "ge\u00b7sche\u00b7hen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVINF", "$.", "$(", "PPER", "VAFIN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Wenn ihn sein Kopf verl\u00e4\u00dft! \u2013 Seid unbesorgt! er blieb", "tokens": ["Wenn", "ihn", "sein", "Kopf", "ver\u00b7l\u00e4\u00dft", "!", "\u2013", "Seid", "un\u00b7be\u00b7sorgt", "!", "er", "blieb"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$.", "$(", "VAIMP", "ADJD", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Am Ufer ganz gelassen stehen,", "tokens": ["Am", "U\u00b7fer", "ganz", "ge\u00b7las\u00b7sen", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Sah vor sich hin, schwang seinen Stab, beschrieb", "tokens": ["Sah", "vor", "sich", "hin", ",", "schwang", "sei\u00b7nen", "Stab", ",", "be\u00b7schrieb"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "PRF", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Figuren in den Sand, als ob er \u00fcberd\u00e4chte", "tokens": ["Fi\u00b7gu\u00b7ren", "in", "den", "Sand", ",", "als", "ob", "er", "\u00fc\u00b7berd\u00b7\u00e4ch\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "KOKOM", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wie viele K\u00f6rner wohl der Erdball fassen m\u00f6chte;", "tokens": ["Wie", "vie\u00b7le", "K\u00f6r\u00b7ner", "wohl", "der", "Erd\u00b7ball", "fas\u00b7sen", "m\u00f6ch\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Kurz, tat als s\u00e4h er nichts, und wandte sich nicht um.", "tokens": ["Kurz", ",", "tat", "als", "s\u00e4h", "er", "nichts", ",", "und", "wand\u00b7te", "sich", "nicht", "um", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "KOKOM", "VVFIN", "PPER", "PIS", "$,", "KON", "VVFIN", "PRF", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "\u00bbvortrefflich!\u00ab rief sie aus, \u00bbdas nenn ich Heldentum", "tokens": ["\u00bb", "vor\u00b7treff\u00b7lich", "!", "\u00ab", "rief", "sie", "aus", ",", "\u00bb", "das", "nenn", "ich", "Hel\u00b7den\u00b7tum"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "$.", "$(", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "PDS", "VVFIN", "PPER", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und etwas mehr! Die alte Ordnung wollte,", "tokens": ["Und", "et\u00b7was", "mehr", "!", "Die", "al\u00b7te", "Ord\u00b7nung", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$.", "ART", "ADJA", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df Daphne j\u00fcngferlich mit kurzen Schritten fliehn,", "tokens": ["Da\u00df", "Daph\u00b7ne", "j\u00fcng\u00b7fer\u00b7lich", "mit", "kur\u00b7zen", "Schrit\u00b7ten", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Apollo keuchend folgen sollte;", "tokens": ["A\u00b7pol\u00b7lo", "keu\u00b7chend", "fol\u00b7gen", "soll\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du kehrst es um. \u2013 Fliehst du, mich nachzuziehn?", "tokens": ["Du", "kehrst", "es", "um", ".", "\u2013", "Fliehst", "du", ",", "mich", "nach\u00b7zu\u00b7ziehn", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "VVFIN", "PPER", "$,", "PPER", "VVINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Den kleinen Stolz will ich dir gerne g\u00f6nnen!\u00ab", "tokens": ["Den", "klei\u00b7nen", "Stolz", "will", "ich", "dir", "ger\u00b7ne", "g\u00f6n\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "\u00bbdu irrest dich\u00ab, antwortet unser Held", "tokens": ["\u00bb", "du", "ir\u00b7rest", "dich", "\u00ab", ",", "ant\u00b7wor\u00b7tet", "un\u00b7ser", "Held"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$(", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Mienen, welche nicht, wie sehr sie ihm mi\u00dff\u00e4llt,", "tokens": ["Mit", "Mie\u00b7nen", ",", "wel\u00b7che", "nicht", ",", "wie", "sehr", "sie", "ihm", "mi\u00df\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verbergen wollen oder k\u00f6nnen:", "tokens": ["Ver\u00b7ber\u00b7gen", "wol\u00b7len", "o\u00b7der", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbein rascher meilenbreiter Spalt,", "tokens": ["\u00bb", "ein", "ra\u00b7scher", "mei\u00b7len\u00b7brei\u00b7ter", "Spalt", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der pl\u00f6tzlich zwischen uns den Boden g\u00e4hnen machte,", "tokens": ["Der", "pl\u00f6tz\u00b7lich", "zwi\u00b7schen", "uns", "den", "Bo\u00b7den", "g\u00e4h\u00b7nen", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPER", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist alles, glaube mir, wornach ich sehnlich schmachte,", "tokens": ["Ist", "al\u00b7les", ",", "glau\u00b7be", "mir", ",", "wor\u00b7nach", "ich", "sehn\u00b7lich", "schmach\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "VVFIN", "PPER", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Seitdem ich dich erblickt\u00ab. \u2013 \u00bbDer Gru\u00df ist etwas kalt\u00ab,", "tokens": ["Seit\u00b7dem", "ich", "dich", "er\u00b7blickt", "\u00ab", ".", "\u2013", "\u00bb", "Der", "Gru\u00df", "ist", "et\u00b7was", "kalt", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "PPER", "PRF", "VVPP", "$(", "$.", "$(", "$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$(", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Erwidert sie: \u00bbdu denkest, wie ich sehe,", "tokens": ["Er\u00b7wi\u00b7dert", "sie", ":", "\u00bb", "du", "den\u00b7kest", ",", "wie", "ich", "se\u00b7he", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die Reihe sei nunmehr an dir,", "tokens": ["Die", "Rei\u00b7he", "sei", "nun\u00b7mehr", "an", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und weichst zur\u00fcck so wie ich vorw\u00e4rts gehe.", "tokens": ["Und", "weichst", "zu\u00b7r\u00fcck", "so", "wie", "ich", "vor\u00b7w\u00e4rts", "ge\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "KOKOM", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Doch spiele nicht den Grausamen mit mir!", "tokens": ["Doch", "spie\u00b7le", "nicht", "den", "Grau\u00b7sa\u00b7men", "mit", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Was willst du mehr, als da\u00df ich dir gestehe,", "tokens": ["Was", "willst", "du", "mehr", ",", "als", "da\u00df", "ich", "dir", "ge\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "$,", "KOKOM", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Du z\u00fcrnst mit Recht? Ja, ich mi\u00dfkannte dich:", "tokens": ["Du", "z\u00fcrnst", "mit", "Recht", "?", "Ja", ",", "ich", "mi\u00df\u00b7kann\u00b7te", "dich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$.", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Doch, war ich damals mein? Jetzt bin ich, was du mich,", "tokens": ["Doch", ",", "war", "ich", "da\u00b7mals", "mein", "?", "Jetzt", "bin", "ich", ",", "was", "du", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "PPER", "ADV", "PPOSAT", "$.", "ADV", "VAFIN", "PPER", "$,", "PWS", "PPER", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zu sein, so oft zu meinen F\u00fc\u00dfen batest.\u00ab", "tokens": ["Zu", "sein", ",", "so", "oft", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", "ba\u00b7test", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VAINF", "$,", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "\u00bbwie, (unterbrach er sie) du, die mit kaltem Blut", "tokens": ["\u00bb", "wie", ",", "(", "un\u00b7ter\u00b7brach", "er", "sie", ")", "du", ",", "die", "mit", "kal\u00b7tem", "Blut"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "$,", "$(", "VVFIN", "PPER", "PPER", "$(", "PPER", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein z\u00e4rtlich Herz mit F\u00fc\u00dfen tratest.", "tokens": ["Mein", "z\u00e4rt\u00b7lich", "Herz", "mit", "F\u00fc\u00b7\u00dfen", "tra\u00b7test", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mich l\u00e4chelnd leiden sahst \u2013 du hast den \u00dcbermut", "tokens": ["Mich", "l\u00e4\u00b7chelnd", "lei\u00b7den", "sahst", "\u2013", "du", "hast", "den", "\u00dc\u00b7ber\u00b7mut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "VVINF", "VVFIN", "$(", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und suchst mich auf, mich noch durch Spott zu qu\u00e4len?", "tokens": ["Und", "suchst", "mich", "auf", ",", "mich", "noch", "durch", "Spott", "zu", "qu\u00e4\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zwei Jahre liebt ich dich, Undankbare, so sch\u00f6n,", "tokens": ["Zwei", "Jah\u00b7re", "liebt", "ich", "dich", ",", "Un\u00b7dank\u00b7ba\u00b7re", ",", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "PRF", "$,", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wie keine Sterbliche sich je geliebt gesehn.", "tokens": ["Wie", "kei\u00b7ne", "Sterb\u00b7li\u00b7che", "sich", "je", "ge\u00b7liebt", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PRF", "ADV", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein Blick, dein Atem schien allein mich zu beseelen.", "tokens": ["Dein", "Blick", ",", "dein", "A\u00b7tem", "schien", "al\u00b7lein", "mich", "zu", "be\u00b7see\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Tor, der ich war! von einem Blick entz\u00fcckt", "tokens": ["Tor", ",", "der", "ich", "war", "!", "von", "ei\u00b7nem", "Blick", "ent\u00b7z\u00fcckt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PPER", "VAFIN", "$.", "APPR", "ART", "NN", "VVPP"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Der sich an mir f\u00fcr Nebenbuhler \u00fcbte;", "tokens": ["Der", "sich", "an", "mir", "f\u00fcr", "Ne\u00b7ben\u00b7buh\u00b7ler", "\u00fcb\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Durch falsche Hoffnungen ber\u00fcckt,", "tokens": ["Durch", "fal\u00b7sche", "Hoff\u00b7nun\u00b7gen", "be\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Womit mein krankes Herz get\u00e4uscht zu werden liebte!", "tokens": ["Wo\u00b7mit", "mein", "kran\u00b7kes", "Herz", "ge\u00b7t\u00e4uscht", "zu", "wer\u00b7den", "lieb\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "VVPP", "PTKZU", "VAINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Du botst verf\u00fchrerisch das s\u00fc\u00dfe Gift mir dar,", "tokens": ["Du", "botst", "ver\u00b7f\u00fch\u00b7re\u00b7risch", "das", "s\u00fc\u00b7\u00dfe", "Gift", "mir", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und machtest dann mit einem andern wahr", "tokens": ["Und", "mach\u00b7test", "dann", "mit", "ei\u00b7nem", "an\u00b7dern", "wahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "ADJA", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Was dein Sirenenmund mir zugel\u00e4chelt hatte.", "tokens": ["Was", "dein", "Si\u00b7re\u00b7nen\u00b7mund", "mir", "zu\u00b7ge\u00b7l\u00e4\u00b7chelt", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und, o! mit wem? \u2013 Dies brachte mich zur Wut!", "tokens": ["Und", ",", "o", "!", "mit", "wem", "?", "\u2013", "Dies", "brach\u00b7te", "mich", "zur", "Wut", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "$.", "APPR", "PWS", "$.", "$(", "PDS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "(nur der Gedank emp\u00f6rt noch itzt mein Blut)", "tokens": ["(", "nur", "der", "Ge\u00b7dank", "em\u00b7p\u00f6rt", "noch", "itzt", "mein", "Blut", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.17": {"text": "Ein Knabe war's, \u2013 err\u00f6te nicht, gestatte", "tokens": ["Ein", "Kna\u00b7be", "wa\u00b7r's", ",", "\u2013", "er\u00b7r\u00f6\u00b7te", "nicht", ",", "ge\u00b7stat\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "$(", "VVFIN", "PTKNEG", "$,", "ADJA"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Da\u00df ich ihn malen darf, \u2013 gelblockig, zephyrlich,", "tokens": ["Da\u00df", "ich", "ihn", "ma\u00b7len", "darf", ",", "\u2013", "gel\u00b7blo\u00b7ckig", ",", "ze\u00b7phyr\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VMFIN", "$,", "$(", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-++-+-", "measure": "unknown.measure.hexa"}, "line.19": {"text": "Ein bunter Schmetterling, so glatt wie eine Schlange,", "tokens": ["Ein", "bun\u00b7ter", "Schmet\u00b7ter\u00b7ling", ",", "so", "glatt", "wie", "ei\u00b7ne", "Schlan\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mit G\u00e4nseflaum ums Kinn, mit rotgeschminkter Wange,", "tokens": ["Mit", "G\u00e4n\u00b7se\u00b7flaum", "ums", "Kinn", ",", "mit", "rot\u00b7ge\u00b7schmink\u00b7ter", "Wan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein Ding, das einer Puppe glich,", "tokens": ["Ein", "Ding", ",", "das", "ei\u00b7ner", "Pup\u00b7pe", "glich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wie kleine T\u00f6chterchen mit sich zu Bette nehmen:", "tokens": ["Wie", "klei\u00b7ne", "T\u00f6ch\u00b7ter\u00b7chen", "mit", "sich", "zu", "Bet\u00b7te", "neh\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPR", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Dem gabst du, ohne dich zu sch\u00e4men,", "tokens": ["Dem", "gabst", "du", ",", "oh\u00b7ne", "dich", "zu", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Den Busen preis, um den der Hirt von Ilion", "tokens": ["Den", "Bu\u00b7sen", "preis", ",", "um", "den", "der", "Hirt", "von", "I\u00b7li\u00b7on"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KOUI", "ART", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Helenen untreu worden w\u00e4re;", "tokens": ["He\u00b7le\u00b7nen", "un\u00b7treu", "wor\u00b7den", "w\u00e4\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Dies \u00c4ffchen machte den Adon", "tokens": ["Dies", "\u00c4ff\u00b7chen", "mach\u00b7te", "den", "A\u00b7don"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Der Nebenbuhlerin der G\u00f6ttin von Cythere.", "tokens": ["Der", "Ne\u00b7ben\u00b7buh\u00b7le\u00b7rin", "der", "G\u00f6t\u00b7tin", "von", "Cy\u00b7the\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Und Phanias, indes so ein Insekt", "tokens": ["Und", "Pha\u00b7ni\u00b7as", ",", "in\u00b7des", "so", "ein", "In\u00b7sekt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "$,", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Auf deinen Rosen kriecht, liegt N\u00e4chte durch gestreckt,", "tokens": ["Auf", "dei\u00b7nen", "Ro\u00b7sen", "kriecht", ",", "liegt", "N\u00e4ch\u00b7te", "durch", "ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Mit Tr\u00e4nen, die den Mai von seinen Wangen \u00e4tzen,", "tokens": ["Mit", "Tr\u00e4\u00b7nen", ",", "die", "den", "Mai", "von", "sei\u00b7nen", "Wan\u00b7gen", "\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die Schwelle deiner T\u00fcr, Undankbare, zu netzen!", "tokens": ["Die", "Schwel\u00b7le", "dei\u00b7ner", "T\u00fcr", ",", "Un\u00b7dank\u00b7ba\u00b7re", ",", "zu", "net\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Nein! Der vers\u00f6hnt sich nie, der so beleidigt ward!", "tokens": ["Nein", "!", "Der", "ver\u00b7s\u00f6hnt", "sich", "nie", ",", "der", "so", "be\u00b7lei\u00b7digt", "ward", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "VVFIN", "PRF", "ADV", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Hinweg! die Luft, in der du Atem ziehest,", "tokens": ["Hin\u00b7weg", "!", "die", "Luft", ",", "in", "der", "du", "A\u00b7tem", "zie\u00b7hest", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Ist Pest f\u00fcr mich \u2013 Verla\u00df mich! du bem\u00fchest", "tokens": ["Ist", "Pest", "f\u00fcr", "mich", "\u2013", "Ver\u00b7la\u00df", "mich", "!", "du", "be\u00b7m\u00fc\u00b7hest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "NN", "APPR", "PPER", "$(", "VVIMP", "PPER", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Dich fruchtlos! \u2013 unsre Denkungsart", "tokens": ["Dich", "frucht\u00b7los", "!", "\u2013", "uns\u00b7re", "Den\u00b7kungs\u00b7art"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["PPER", "ADJD", "$.", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Stimmt minder \u00fcberein als ehmals unsre Herzen\u00ab.", "tokens": ["Stimmt", "min\u00b7der", "\u00fc\u00b7be\u00b7re\u00b7in", "als", "eh\u00b7mals", "uns\u00b7re", "Her\u00b7zen", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KOKOM", "ADV", "PPOSAT", "NN", "$(", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "\u00bbmich deucht (erwidert sie) du r\u00e4chest dich zu hart", "tokens": ["\u00bb", "mich", "deucht", "(", "er\u00b7wi\u00b7dert", "sie", ")", "du", "r\u00e4\u00b7chest", "dich", "zu", "hart"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$(", "VVFIN", "PPER", "$(", "PPER", "VVFIN", "PPER", "PTKA", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr selbst gemachte Liebesschmerzen.", "tokens": ["F\u00fcr", "selbst", "ge\u00b7mach\u00b7te", "Lie\u00b7bes\u00b7schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sei wahr, und sprich, ist's stets in unserer Gewalt", "tokens": ["Sei", "wahr", ",", "und", "sprich", ",", "ist's", "stets", "in", "un\u00b7se\u00b7rer", "Ge\u00b7walt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "$,", "KON", "ADJD", "$,", "VAFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu lieben ", "tokens": ["Zu", "lie\u00b7ben"], "token_info": ["word", "word"], "pos": ["PTKZU", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Oft fragt der Liebesgott uns nur nicht ob wir ", "tokens": ["Oft", "fragt", "der", "Lie\u00b7bes\u00b7gott", "uns", "nur", "nicht", "ob", "wir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "PTKNEG", "KOUS", "PPER"], "meter": "-+-+----+-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Wir finden ohne Grund uns z\u00e4rtlich oder kalt,", "tokens": ["Wir", "fin\u00b7den", "oh\u00b7ne", "Grund", "uns", "z\u00e4rt\u00b7lich", "o\u00b7der", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Itzt dem Apollo spr\u00f6d, itzt schwach f\u00fcr einen Faunen.", "tokens": ["Itzt", "dem", "A\u00b7pol\u00b7lo", "spr\u00f6d", ",", "itzt", "schwach", "f\u00fcr", "ei\u00b7nen", "Fau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "VVFIN", "$,", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was wei\u00df ich's selbst? wer z\u00e4hlet Amors Launen?", "tokens": ["Was", "wei\u00df", "ich's", "selbst", "?", "wer", "z\u00e4h\u00b7let", "A\u00b7mors", "Lau\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "$.", "PWS", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ihr, die ihr \u00fcber uns so bitter euch beschwert,", "tokens": ["Ihr", ",", "die", "ihr", "\u00fc\u00b7ber", "uns", "so", "bit\u00b7ter", "euch", "be\u00b7schwert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "APPR", "PPER", "ADV", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "La\u00dft euer eignes Herz f\u00fcr unsers Antwort geben!", "tokens": ["La\u00dft", "eu\u00b7er", "eig\u00b7nes", "Herz", "f\u00fcr", "un\u00b7sers", "Ant\u00b7wort", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ihr bleibt oft an der Stange kleben,", "tokens": ["Ihr", "bleibt", "oft", "an", "der", "Stan\u00b7ge", "kle\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und was euch angelockt war kaum der M\u00fche wert.", "tokens": ["Und", "was", "euch", "an\u00b7ge\u00b7lockt", "war", "kaum", "der", "M\u00fc\u00b7he", "wert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein Halstuch \u00f6ffnet sich, ein \u00c4rmel f\u00e4llt zur\u00fccke,", "tokens": ["Ein", "Hal\u00b7stuch", "\u00f6ff\u00b7net", "sich", ",", "ein", "\u00c4r\u00b7mel", "f\u00e4llt", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und weg ist euer Herz! Oft braucht es nicht so viel;", "tokens": ["Und", "weg", "ist", "eu\u00b7er", "Herz", "!", "Oft", "braucht", "es", "nicht", "so", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ein L\u00e4cheln f\u00e4ngt euch schon, ihr fallt von einem Blicke.", "tokens": ["Ein", "L\u00e4\u00b7cheln", "f\u00e4ngt", "euch", "schon", ",", "ihr", "fallt", "von", "ei\u00b7nem", "Bli\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein fl\u00fcchtiger Geschmack, ein Nichts, ein eitles Spiel", "tokens": ["Ein", "fl\u00fcch\u00b7ti\u00b7ger", "Ge\u00b7schmack", ",", "ein", "Nichts", ",", "ein", "eit\u00b7les", "Spiel"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "PIS", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Phantasie, regiert uns oft im W\u00e4hlen;", "tokens": ["Der", "Phan\u00b7ta\u00b7sie", ",", "re\u00b7giert", "uns", "oft", "im", "W\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Das Sch\u00f6ne selbst verliert auf kurze Zeit", "tokens": ["Das", "Sch\u00f6\u00b7ne", "selbst", "ver\u00b7liert", "auf", "kur\u00b7ze", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Den Reiz f\u00fcr uns; wir wissen da\u00df wir fehlen,", "tokens": ["Den", "Reiz", "f\u00fcr", "uns", ";", "wir", "wis\u00b7sen", "da\u00df", "wir", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$.", "PPER", "VVFIN", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Und finden Grazien bis in der H\u00e4\u00dflichkeit.", "tokens": ["Und", "fin\u00b7den", "Gra\u00b7zi\u00b7en", "bis", "in", "der", "H\u00e4\u00df\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Hat die Erfahrung, wie ich glaube,", "tokens": ["Hat", "die", "Er\u00b7fah\u00b7rung", ",", "wie", "ich", "glau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Von dieser Wahrheit dich belehrt,", "tokens": ["Von", "die\u00b7ser", "Wahr\u00b7heit", "dich", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "So ist mein Irrtum auch vielleicht verzeihenswert.", "tokens": ["So", "ist", "mein", "Irr\u00b7tum", "auch", "viel\u00b7leicht", "ver\u00b7zei\u00b7hens\u00b7wert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Wer suchet unter einer Haube", "tokens": ["Wer", "su\u00b7chet", "un\u00b7ter", "ei\u00b7ner", "Hau\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "So viel Vernunft als Zenons Bart verhei\u00dft?", "tokens": ["So", "viel", "Ver\u00b7nunft", "als", "Ze\u00b7nons", "Bart", "ver\u00b7hei\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KOKOM", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Und wie? mein Freund, wenn ich sogar zu sagen", "tokens": ["Und", "wie", "?", "mein", "Freund", ",", "wenn", "ich", "so\u00b7gar", "zu", "sa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "$.", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Mich untersteh, da\u00df wirklich mein Betragen", "tokens": ["Mich", "un\u00b7ter\u00b7steh", ",", "da\u00df", "wirk\u00b7lich", "mein", "Be\u00b7tra\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Ich sch\u00e4tzt an dir, wof\u00fcr dich jeder preist,", "tokens": ["Ich", "sch\u00e4tzt", "an", "dir", ",", "wo\u00b7f\u00fcr", "dich", "je\u00b7der", "preist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PWAV", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Ein edles Herz und einen sch\u00f6nen Geist:", "tokens": ["Ein", "ed\u00b7les", "Herz", "und", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Geist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Was ich f\u00fcr dich empfand war auf Verdienst gegr\u00fcndet;", "tokens": ["Was", "ich", "f\u00fcr", "dich", "emp\u00b7fand", "war", "auf", "Ver\u00b7dienst", "ge\u00b7gr\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "VVFIN", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Du warst mein ", "tokens": ["Du", "warst", "mein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.32": {"text": "Vergn\u00fcgt mit einem Band das nur die Seelen bindet,", "tokens": ["Ver\u00b7gn\u00fcgt", "mit", "ei\u00b7nem", "Band", "das", "nur", "die", "See\u00b7len", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Sahst du mich Tage lang, und fandest gar nicht schwer", "tokens": ["Sahst", "du", "mich", "Ta\u00b7ge", "lang", ",", "und", "fan\u00b7dest", "gar", "nicht", "schwer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "NN", "ADJD", "$,", "KON", "VVFIN", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mich, wenn der Abendstern dir winkte, zu verlassen,", "tokens": ["Mich", ",", "wenn", "der", "A\u00b7bends\u00b7tern", "dir", "wink\u00b7te", ",", "zu", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "Um an Glycerens T\u00fcr die halbe Nacht zu passen.", "tokens": ["Um", "an", "Gly\u00b7ce\u00b7rens", "T\u00fcr", "die", "hal\u00b7be", "Nacht", "zu", "pas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "NN", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "So ging es gut, bis dich ein Ungef\u00e4hr", "tokens": ["So", "ging", "es", "gut", ",", "bis", "dich", "ein", "Un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "An einem Sommertag in eine Laube f\u00fchrte,", "tokens": ["An", "ei\u00b7nem", "Som\u00b7mer\u00b7tag", "in", "ei\u00b7ne", "Lau\u00b7be", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Worin die ", "tokens": ["Wo\u00b7rin", "die"], "token_info": ["word", "word"], "pos": ["PWAV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.39": {"text": "So ruhig lie\u00df. Ich wei\u00df nicht was dich r\u00fchrte;", "tokens": ["So", "ru\u00b7hig", "lie\u00df", ".", "Ich", "wei\u00df", "nicht", "was", "dich", "r\u00fchr\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Der Schlaf nach einem Bad, wenn man allein sich meint,", "tokens": ["Der", "Schlaf", "nach", "ei\u00b7nem", "Bad", ",", "wenn", "man", "al\u00b7lein", "sich", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NE", "$,", "KOUS", "PIS", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Mu\u00df was versch\u00f6nerndes in euern Augen haben:", "tokens": ["Mu\u00df", "was", "ver\u00b7sch\u00f6\u00b7nern\u00b7des", "in", "eu\u00b7ern", "Au\u00b7gen", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADJA", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Genug, du fandst an ", "tokens": ["Ge\u00b7nug", ",", "du", "fandst", "an"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PTKVZ"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.43": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.44": {"text": "Nichts ahnend wacht ich auf; da lag zu meinen F\u00fc\u00dfen", "tokens": ["Nichts", "ah\u00b7nend", "wacht", "ich", "auf", ";", "da", "lag", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADJD", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Ein Mittelding von Faun und Liebesgott!", "tokens": ["Ein", "Mit\u00b7tel\u00b7ding", "von", "Faun", "und", "Lie\u00b7bes\u00b7gott", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "In dithyrambische Begeistrung hingerissen", "tokens": ["In", "dit\u00b7hy\u00b7ram\u00b7bi\u00b7sche", "Be\u00b7geis\u00b7trung", "hin\u00b7ge\u00b7ris\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Was sagtest du mir nicht! was h\u00e4ttst du wagen m\u00fcssen,", "tokens": ["Was", "sag\u00b7test", "du", "mir", "nicht", "!", "was", "h\u00e4ttst", "du", "wa\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "PTKNEG", "$.", "PWS", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "H\u00e4tt ich, der Schw\u00e4rmerei die Lippen zu verschlie\u00dfen,", "tokens": ["H\u00e4tt", "ich", ",", "der", "Schw\u00e4r\u00b7me\u00b7rei", "die", "Lip\u00b7pen", "zu", "ver\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Das Mittel nicht gekannt! Ein Strom von kaltem Spott", "tokens": ["Das", "Mit\u00b7tel", "nicht", "ge\u00b7kannt", "!", "Ein", "Strom", "von", "kal\u00b7tem", "Spott"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$.", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Nahm deinem Brand die Luft. Mit triefendem Gefieder", "tokens": ["Nahm", "dei\u00b7nem", "Brand", "die", "Luft", ".", "Mit", "trie\u00b7fen\u00b7dem", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ART", "NN", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Flog Amor z\u00fcrnend fort: doch freut ich mich zu fr\u00fch;", "tokens": ["Flog", "A\u00b7mor", "z\u00fcr\u00b7nend", "fort", ":", "doch", "freut", "ich", "mich", "zu", "fr\u00fch", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PRF", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Denn eh ich mir's versah, so kam er seufzend wieder.", "tokens": ["Denn", "eh", "ich", "mir's", "ver\u00b7sah", ",", "so", "kam", "er", "seuf\u00b7zend", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NE", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Mit Seufzen, ich gesteh's, erobert man mich nie;", "tokens": ["Mit", "Seuf\u00b7zen", ",", "ich", "ge\u00b7steh's", ",", "er\u00b7o\u00b7bert", "man", "mich", "nie", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PPER", "NE", "$,", "VVFIN", "PIS", "PRF", "ADV", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.54": {"text": "Der feierliche Schwung erhitzter Phantasie", "tokens": ["Der", "fei\u00b7er\u00b7li\u00b7che", "Schwung", "er\u00b7hitz\u00b7ter", "Phan\u00b7ta\u00b7sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Schl\u00e4gt mir die Lebensgeister nieder.", "tokens": ["Schl\u00e4gt", "mir", "die", "Le\u00b7bens\u00b7geis\u00b7ter", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Ich machte den Versuch, durch Fr\u00f6hlichkeit und Scherz", "tokens": ["Ich", "mach\u00b7te", "den", "Ver\u00b7such", ",", "durch", "Fr\u00f6h\u00b7lich\u00b7keit", "und", "Scherz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Den D\u00e4mon, der dich plagte, zu verjagen;", "tokens": ["Den", "D\u00e4\u00b7mon", ",", "der", "dich", "plag\u00b7te", ",", "zu", "ver\u00b7ja\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.58": {"text": "Doch diese Geisterart kann keinen Scherz ertragen.", "tokens": ["Doch", "die\u00b7se", "Geis\u00b7ter\u00b7art", "kann", "kei\u00b7nen", "Scherz", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Ich \u00e4nderte die Kur. Allein mein eignes Herz", "tokens": ["Ich", "\u00e4n\u00b7der\u00b7te", "die", "Kur", ".", "Al\u00b7lein", "mein", "eig\u00b7nes", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Kam in Gefahr dabei; es wurde mir verd\u00e4chtig;", "tokens": ["Kam", "in", "Ge\u00b7fahr", "da\u00b7bei", ";", "es", "wur\u00b7de", "mir", "ver\u00b7d\u00e4ch\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "PAV", "$.", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Denn Schw\u00e4rmerei steckt wie der Schnupfen an:", "tokens": ["Denn", "Schw\u00e4r\u00b7me\u00b7rei", "steckt", "wie", "der", "Schnup\u00b7fen", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.62": {"text": "Man f\u00fchlt ich wei\u00df nicht was, und eh man wehren kann", "tokens": ["Man", "f\u00fchlt", "ich", "wei\u00df", "nicht", "was", ",", "und", "eh", "man", "weh\u00b7ren", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "VVFIN", "PTKNEG", "PIS", "$,", "KON", "KOUS", "PIS", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Ist unser Kopf des Herzens nicht mehr m\u00e4chtig.", "tokens": ["Ist", "un\u00b7ser", "Kopf", "des", "Her\u00b7zens", "nicht", "mehr", "m\u00e4ch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ART", "NN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.64": {"text": "Auf meine Sicherheit bedacht", "tokens": ["Auf", "mei\u00b7ne", "Si\u00b7cher\u00b7heit", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Fand ich zuletzt ich m\u00fcsse mich zerstreuen.", "tokens": ["Fand", "ich", "zu\u00b7letzt", "ich", "m\u00fcs\u00b7se", "mich", "zer\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Mir schien ein Geck dazu ganz eigentlich gemacht.", "tokens": ["Mir", "schien", "ein", "Geck", "da\u00b7zu", "ganz", "ei\u00b7gent\u00b7lich", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PAV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "F\u00fcr Sch\u00f6nen, die den Zwang der ernsten Liebe scheuen,", "tokens": ["F\u00fcr", "Sch\u00f6\u00b7nen", ",", "die", "den", "Zwang", "der", "erns\u00b7ten", "Lie\u00b7be", "scheu\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Taugt eine Puppe nur, die trillert, h\u00fcpft und lacht;", "tokens": ["Taugt", "ei\u00b7ne", "Pup\u00b7pe", "nur", ",", "die", "tril\u00b7lert", ",", "h\u00fcpft", "und", "lacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "$,", "PRELS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ein bunter Tor, der t\u00e4ndelnd uns umflattert,", "tokens": ["Ein", "bun\u00b7ter", "Tor", ",", "der", "t\u00e4n\u00b7delnd", "uns", "um\u00b7flat\u00b7tert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.70": {"text": "Die Z\u00e4hne weist, nie denkt, und ewig schnattert;", "tokens": ["Die", "Z\u00e4h\u00b7ne", "weist", ",", "nie", "denkt", ",", "und", "e\u00b7wig", "schnat\u00b7tert", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.71": {"text": "Der, schw\u00fclstiger je weniger er f\u00fchlt,", "tokens": ["Der", ",", "schw\u00fcls\u00b7ti\u00b7ger", "je", "we\u00b7ni\u00b7ger", "er", "f\u00fchlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.72": {"text": "Von Flammen schwatzt die unser F\u00e4cher k\u00fchlt,", "tokens": ["Von", "Flam\u00b7men", "schwatzt", "die", "un\u00b7ser", "F\u00e4\u00b7cher", "k\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.73": {"text": "Und, unterdes er sich im Spiegel selbst bel\u00e4chelt,", "tokens": ["Und", ",", "un\u00b7ter\u00b7des", "er", "sich", "im", "Spie\u00b7gel", "selbst", "be\u00b7l\u00e4\u00b7chelt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJA", "PPER", "PRF", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Studierte Seufzerchen mit schaler Anmut f\u00e4chelt.\u00ab", "tokens": ["Stu\u00b7dier\u00b7te", "Seuf\u00b7zer\u00b7chen", "mit", "scha\u00b7ler", "An\u00b7mut", "f\u00e4\u00b7chelt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "\u00bbdas alles was du sagst, (fiel unser Timon ein)", "tokens": ["\u00bb", "das", "al\u00b7les", "was", "du", "sagst", ",", "(", "fiel", "un\u00b7ser", "Ti\u00b7mon", "ein", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PIS", "PWS", "PPER", "VVFIN", "$,", "$(", "VVFIN", "PPOSAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll, wie es scheint, ein kleines Beispiel sein,", "tokens": ["Soll", ",", "wie", "es", "scheint", ",", "ein", "klei\u00b7nes", "Bei\u00b7spiel", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kein Handel sei so schlimm, den nicht der Witz verteidigt.", "tokens": ["Kein", "Han\u00b7del", "sei", "so", "schlimm", ",", "den", "nicht", "der", "Witz", "ver\u00b7tei\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "PRELS", "PTKNEG", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur schade, da\u00df die Ausflucht mehr beleidigt", "tokens": ["Nur", "scha\u00b7de", ",", "da\u00df", "die", "Aus\u00b7flucht", "mehr", "be\u00b7lei\u00b7digt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Als was dadurch verbessert werden soll.", "tokens": ["Als", "was", "da\u00b7durch", "ver\u00b7bes\u00b7sert", "wer\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "VVPP", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Doch, la\u00df es sein! mein Torheitsma\u00df ist voll,", "tokens": ["Doch", ",", "la\u00df", "es", "sein", "!", "mein", "Tor\u00b7heits\u00b7ma\u00df", "ist", "voll", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVIMP", "PPER", "VAINF", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wir wollen uns mit Zanken nicht erm\u00fcden.", "tokens": ["Wir", "wol\u00b7len", "uns", "mit", "Zan\u00b7ken", "nicht", "er\u00b7m\u00fc\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich liebte dich; vergib! ich war ein wenig toll:", "tokens": ["Ich", "lieb\u00b7te", "dich", ";", "ver\u00b7gib", "!", "ich", "war", "ein", "we\u00b7nig", "toll", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "VVIMP", "$.", "PPER", "VAFIN", "ART", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dir selbst gefiel ein Geck, und ich \u2013 ich bin zufrieden;", "tokens": ["Dir", "selbst", "ge\u00b7fiel", "ein", "Geck", ",", "und", "ich", "\u2013", "ich", "bin", "zu\u00b7frie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "$,", "KON", "PPER", "$(", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Erfreut sogar. Denn st\u00e4nd es itzt bei mir,", "tokens": ["Er\u00b7freut", "so\u00b7gar", ".", "Denn", "st\u00e4nd", "es", "itzt", "bei", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "KON", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Durch einen Wunsch an seinen Platz zu fliegen,", "tokens": ["Durch", "ei\u00b7nen", "Wunsch", "an", "sei\u00b7nen", "Platz", "zu", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Bathyll zu sein \u2013 um dir im Arm zu liegen:", "tokens": ["Ba\u00b7thyll", "zu", "sein", "\u2013", "um", "dir", "im", "Arm", "zu", "lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKZU", "VAINF", "$(", "APPR", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Bei deiner Augen Macht! \u2013 ich bliebe hier.", "tokens": ["Bei", "dei\u00b7ner", "Au\u00b7gen", "Macht", "!", "\u2013", "ich", "blie\u00b7be", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$.", "$(", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Du h\u00f6rst, ich schmeichle nicht. Genie\u00dft ", "tokens": ["Du", "h\u00f6rst", ",", "ich", "schmeich\u00b7le", "nicht", ".", "Ge\u00b7nie\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Durch falsche Z\u00e4rtlichkeit einander zu betr\u00fcgen:", "tokens": ["Durch", "fal\u00b7sche", "Z\u00e4rt\u00b7lich\u00b7keit", "ein\u00b7an\u00b7der", "zu", "be\u00b7tr\u00fc\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mich f\u00e4ngt kein L\u00e4cheln mehr! \u2013 Ich seh ein Blumenfeld", "tokens": ["Mich", "f\u00e4ngt", "kein", "L\u00e4\u00b7cheln", "mehr", "!", "\u2013", "Ich", "seh", "ein", "Blu\u00b7men\u00b7feld"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADV", "$.", "$(", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Mit mehr Empfindung an als eure sch\u00f6ne Welt:", "tokens": ["Mit", "mehr", "Emp\u00b7fin\u00b7dung", "an", "als", "eu\u00b7re", "sch\u00f6\u00b7ne", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "KOKOM", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und wenn zum zweiten Mal ein Weib von mir erh\u00e4lt,", "tokens": ["Und", "wenn", "zum", "zwei\u00b7ten", "Mal", "ein", "Weib", "von", "mir", "er\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "ADJA", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Durch einen strengen Blick, durch ein gef\u00e4llig Lachen", "tokens": ["Durch", "ei\u00b7nen", "stren\u00b7gen", "Blick", ",", "durch", "ein", "ge\u00b7f\u00e4l\u00b7lig", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mich bald zum Gott und bald zum Wurm zu machen,", "tokens": ["Mich", "bald", "zum", "Gott", "und", "bald", "zum", "Wurm", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "KON", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Wenn ich, so klein zu sein, noch einmal f\u00e4hig bin:", "tokens": ["Wenn", "ich", ",", "so", "klein", "zu", "sein", ",", "noch", "ein\u00b7mal", "f\u00e4\u00b7hig", "bin", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADJD", "PTKZU", "VAINF", "$,", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Dann, holde Venus, dann verwirre meinen Sinn,", "tokens": ["Dann", ",", "hol\u00b7de", "Ve\u00b7nus", ",", "dann", "ver\u00b7wir\u00b7re", "mei\u00b7nen", "Sinn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Verdamme mich zur l\u00e4cherlichsten Flamme,", "tokens": ["Ver\u00b7dam\u00b7me", "mich", "zur", "l\u00e4\u00b7cher\u00b7lichs\u00b7ten", "Flam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Und mache mich \u2013 verliebt in meine Amme.\u00ab", "tokens": ["Und", "ma\u00b7che", "mich", "\u2013", "ver\u00b7liebt", "in", "mei\u00b7ne", "Am\u00b7me", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "VVPP", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "\u00bbwie lange denkst du so?\u00ab versetzt Musarion:", "tokens": ["\u00bb", "wie", "lan\u00b7ge", "denkst", "du", "so", "?", "\u00ab", "ver\u00b7setzt", "Mu\u00b7sa\u00b7ri\u00b7on", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADV", "VVFIN", "PPER", "ADV", "$.", "$(", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbder Abstich ist zu stark, den dieser neue Ton", "tokens": ["\u00bb", "der", "Ab\u00b7stich", "ist", "zu", "stark", ",", "den", "die\u00b7ser", "neu\u00b7e", "Ton"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "PRELS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit deinem ersten macht! Doch, lieber Freund, erlaube,", "tokens": ["Mit", "dei\u00b7nem", "ers\u00b7ten", "macht", "!", "Doch", ",", "lie\u00b7ber", "Freund", ",", "er\u00b7lau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVFIN", "$.", "KON", "$,", "ADV", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich fordre mehr Beweis eh ich ein Wunder glaube.", "tokens": ["Ich", "ford\u00b7re", "mehr", "Be\u00b7weis", "eh", "ich", "ein", "Wun\u00b7der", "glau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du, welcher ohne Lieb und Scherz", "tokens": ["Du", ",", "wel\u00b7cher", "oh\u00b7ne", "Lieb", "und", "Scherz"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor kurzem noch kein gl\u00fccklich Leben kannte;", "tokens": ["Vor", "kur\u00b7zem", "noch", "kein", "gl\u00fcck\u00b7lich", "Le\u00b7ben", "kann\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADV", "PIAT", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Du, dessen leicht ger\u00fchrtes Herz", "tokens": ["Du", ",", "des\u00b7sen", "leicht", "ge\u00b7r\u00fchr\u00b7tes", "Herz"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von jedem sch\u00f6nen Blick entbrannte,", "tokens": ["Von", "je\u00b7dem", "sch\u00f6\u00b7nen", "Blick", "ent\u00b7brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und der, (err\u00f6te nicht, der Irrtum war nicht gro\u00df)", "tokens": ["Und", "der", ",", "(", "er\u00b7r\u00f6\u00b7te", "nicht", ",", "der", "Irr\u00b7tum", "war", "nicht", "gro\u00df", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "$(", "VVFIN", "PTKNEG", "$,", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn ihm Musarion die spr\u00f6de T\u00fcr verschlo\u00df,", "tokens": ["Wenn", "ihm", "Mu\u00b7sa\u00b7ri\u00b7on", "die", "spr\u00f6\u00b7de", "T\u00fcr", "ver\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.11": {"text": "Zu Lindrung seiner Qual \u2013 nach T\u00e4nzerinnen sandte;", "tokens": ["Zu", "Lind\u00b7rung", "sei\u00b7ner", "Qual", "\u2013", "nach", "T\u00e4n\u00b7ze\u00b7rin\u00b7nen", "sand\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$(", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Du, sprichst von kaltem Blut? du, bietest Amorn Trutz?", "tokens": ["Du", ",", "sprichst", "von", "kal\u00b7tem", "Blut", "?", "du", ",", "bie\u00b7test", "A\u00b7morn", "Trutz", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "APPR", "ADJA", "NN", "$.", "PPER", "$,", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Vermutlich hast du dich, noch gl\u00fccklicher zu leben,", "tokens": ["Ver\u00b7mut\u00b7lich", "hast", "du", "dich", ",", "noch", "gl\u00fcck\u00b7li\u00b7cher", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PRF", "$,", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "In einer andern Gottheit Schutz", "tokens": ["In", "ei\u00b7ner", "an\u00b7dern", "Got\u00b7theit", "Schutz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und in die Br\u00fcderschaft der Fr\u00f6hlichen begehen,", "tokens": ["Und", "in", "die", "Br\u00fc\u00b7der\u00b7schaft", "der", "Fr\u00f6h\u00b7li\u00b7chen", "be\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die sich von Leidenschaft und Phantasie befrein,", "tokens": ["Die", "sich", "von", "Lei\u00b7den\u00b7schaft", "und", "Phan\u00b7ta\u00b7sie", "be\u00b7fr\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Um desto ruhiger der Freude sich zu weihn?", "tokens": ["Um", "des\u00b7to", "ru\u00b7hi\u00b7ger", "der", "Freu\u00b7de", "sich", "zu", "weihn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADJD", "ART", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Du fliehst den Zwang von ernsten Liebesh\u00e4ndeln,", "tokens": ["Du", "fliehst", "den", "Zwang", "von", "erns\u00b7ten", "Lie\u00b7bes\u00b7h\u00e4n\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Und findest sicherer, mit Amorn nur zu t\u00e4ndeln;", "tokens": ["Und", "fin\u00b7dest", "si\u00b7che\u00b7rer", ",", "mit", "A\u00b7morn", "nur", "zu", "t\u00e4n\u00b7deln", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "APPR", "NE", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Verm\u00e4hlst die M\u00e4\u00dfigung der Lust,", "tokens": ["Ver\u00b7m\u00e4hlst", "die", "M\u00e4\u00b7\u00dfi\u00b7gung", "der", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Geschmack mit Unbestand, den Ku\u00df mit Nektarz\u00fcgen,", "tokens": ["Ge\u00b7schmack", "mit", "Un\u00b7be\u00b7stand", ",", "den", "Ku\u00df", "mit", "Nek\u00b7tar\u00b7z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Studierst die Kunst dich immer zu vergn\u00fcgen,", "tokens": ["Stu\u00b7dierst", "die", "Kunst", "dich", "im\u00b7mer", "zu", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Genie\u00dfest wenn du kannst, und leidest wenn du mu\u00dft?", "tokens": ["Ge\u00b7nie\u00b7\u00dfest", "wenn", "du", "kannst", ",", "und", "lei\u00b7dest", "wenn", "du", "mu\u00dft", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VMFIN", "$,", "KON", "VVFIN", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ich finde wenigstens in einem solchen Leben", "tokens": ["Ich", "fin\u00b7de", "we\u00b7nigs\u00b7tens", "in", "ei\u00b7nem", "sol\u00b7chen", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Unendlichmal mehr Wahrheit und Vernunft,", "tokens": ["Un\u00b7end\u00b7lich\u00b7mal", "mehr", "Wahr\u00b7heit", "und", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Als von der freudescheuen Zunft", "tokens": ["Als", "von", "der", "freu\u00b7de\u00b7scheu\u00b7en", "Zunft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Geschwollner Stoiker ein Mitglied abzugeben.", "tokens": ["Ge\u00b7schwoll\u00b7ner", "Stoi\u00b7ker", "ein", "Mit\u00b7glied", "ab\u00b7zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Und denkst du so, dann l\u00e4chle sorgenlos", "tokens": ["Und", "denkst", "du", "so", ",", "dann", "l\u00e4ch\u00b7le", "sor\u00b7gen\u00b7los"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "ADV", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Zum Tadel von Athen, das deiner \u00c4ndrung spottet.", "tokens": ["Zum", "Ta\u00b7del", "von", "A\u00b7then", ",", "das", "dei\u00b7ner", "\u00c4n\u00b7drung", "spot\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.30": {"text": "Nicht, wo die sch\u00f6ne Welt, aus langer Weile blo\u00df,", "tokens": ["Nicht", ",", "wo", "die", "sch\u00f6\u00b7ne", "Welt", ",", "aus", "lan\u00b7ger", "Wei\u00b7le", "blo\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Zu Freuden sich zusammen rottet", "tokens": ["Zu", "Freu\u00b7den", "sich", "zu\u00b7sam\u00b7men", "rot\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PRF", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "An denen nur der Name fr\u00f6hlich t\u00f6nt,", "tokens": ["An", "de\u00b7nen", "nur", "der", "Na\u00b7me", "fr\u00f6h\u00b7lich", "t\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Die, stets gehofft, doch niemals kommen wollen,", "tokens": ["Die", ",", "stets", "ge\u00b7hofft", ",", "doch", "nie\u00b7mals", "kom\u00b7men", "wol\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "VVPP", "$,", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Wobei man k\u00fcnstlich lacht und ungezwungen g\u00e4hnt,", "tokens": ["Wo\u00b7bei", "man", "k\u00fcnst\u00b7lich", "lacht", "und", "un\u00b7ge\u00b7zwun\u00b7gen", "g\u00e4hnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "VVFIN", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und mitten im Genu\u00df sich schon nach andern sehnt", "tokens": ["Und", "mit\u00b7ten", "im", "Ge\u00b7nu\u00df", "sich", "schon", "nach", "an\u00b7dern", "sehnt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "PRF", "ADV", "APPR", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Die da und dort uns g\u00e4hnen machen sollen:", "tokens": ["Die", "da", "und", "dort", "uns", "g\u00e4h\u00b7nen", "ma\u00b7chen", "sol\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "KON", "ADV", "PPER", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Nicht im Get\u00fcmmel, nein, im Scho\u00dfe der Natur,", "tokens": ["Nicht", "im", "Ge\u00b7t\u00fcm\u00b7mel", ",", "nein", ",", "im", "Scho\u00b7\u00dfe", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "$,", "PTKANT", "$,", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Am stillen Bach, in unbelauschten Schatten,", "tokens": ["Am", "stil\u00b7len", "Bach", ",", "in", "un\u00b7be\u00b7lauschten", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "Besuchet uns die holde Freude nur,", "tokens": ["Be\u00b7su\u00b7chet", "uns", "die", "hol\u00b7de", "Freu\u00b7de", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Und \u00fcberrascht uns oft auf einer Spur,", "tokens": ["Und", "\u00fc\u00b7berr\u00b7ascht", "uns", "oft", "auf", "ei\u00b7ner", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Wo wir sie nicht vermutet hatten.", "tokens": ["Wo", "wir", "sie", "nicht", "ver\u00b7mu\u00b7tet", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Doch, Phanias, ist's diese Denkungsart,", "tokens": ["Doch", ",", "Pha\u00b7ni\u00b7as", ",", "ist's", "die\u00b7se", "Den\u00b7kungs\u00b7art", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NE", "$,", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Die dich der Stadt entzog, wozu die Au\u00dfenseite", "tokens": ["Die", "dich", "der", "Stadt", "ent\u00b7zog", ",", "wo\u00b7zu", "die", "Au\u00b7\u00dfen\u00b7sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Von einem Diogen? wozu ein wilder Bart?", "tokens": ["Von", "ei\u00b7nem", "Dio\u00b7gen", "?", "wo\u00b7zu", "ein", "wil\u00b7der", "Bart", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.45": {"text": "Mich deucht, ein weiser Mann tr\u00e4gt sich wie andre Leute?\u00ab", "tokens": ["Mich", "deucht", ",", "ein", "wei\u00b7ser", "Mann", "tr\u00e4gt", "sich", "wie", "and\u00b7re", "Leu\u00b7te", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VVFIN", "PRF", "KOKOM", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "\u00bbmein Ansehn, sch\u00f6ne Sp\u00f6tterin,", "tokens": ["\u00bb", "mein", "An\u00b7sehn", ",", "sch\u00f6\u00b7ne", "Sp\u00f6t\u00b7te\u00b7rin", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist wie es sich zu meinem Gl\u00fccke schicket.", "tokens": ["Ist", "wie", "es", "sich", "zu", "mei\u00b7nem", "Gl\u00fc\u00b7cke", "schi\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie? ist dir unbekannt in welcher Lag ich bin?", "tokens": ["Wie", "?", "ist", "dir", "un\u00b7be\u00b7kannt", "in", "wel\u00b7cher", "Lag", "ich", "bin", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "ADJD", "APPR", "PWAT", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df jenes Dach, von faulem Moos gedr\u00fccket,", "tokens": ["Da\u00df", "je\u00b7nes", "Dach", ",", "von", "fau\u00b7lem", "Moos", "ge\u00b7dr\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und so viel Land als jener Zaun umschlie\u00dft,", "tokens": ["Und", "so", "viel", "Land", "als", "je\u00b7ner", "Zaun", "um\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "KOKOM", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der ganze Rest von meinem Erbgut ist?", "tokens": ["Der", "gan\u00b7ze", "Rest", "von", "mei\u00b7nem", "Erb\u00b7gut", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Was jeder wei\u00df kann dir allein unm\u00f6glich", "tokens": ["Was", "je\u00b7der", "wei\u00df", "kann", "dir", "al\u00b7lein", "un\u00b7m\u00f6g\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIS", "VVFIN", "VMFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Verborgen sein: dein Scherz ist unertr\u00e4glich,", "tokens": ["Ver\u00b7bor\u00b7gen", "sein", ":", "dein", "Scherz", "ist", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Musarion, wie deine Gegenwart.", "tokens": ["Mu\u00b7sa\u00b7ri\u00b7on", ",", "wie", "dei\u00b7ne", "Ge\u00b7gen\u00b7wart", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Mit wem sprichst du von einer Denkungsart,", "tokens": ["Mit", "wem", "sprichst", "du", "von", "ei\u00b7ner", "Den\u00b7kungs\u00b7art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Die von den G\u00fcnstlingen des lachenden Geschickes", "tokens": ["Die", "von", "den", "G\u00fcnst\u00b7lin\u00b7gen", "des", "la\u00b7chen\u00b7den", "Ge\u00b7schi\u00b7ckes"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Das Vorrecht ist?\u00ab \u2013 \u00bbFreund, du vergissest dich:", "tokens": ["Das", "Vor\u00b7recht", "ist", "?", "\u00ab", "\u2013", "\u00bb", "Freund", ",", "du", "ver\u00b7gis\u00b7sest", "dich", ":"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "$(", "$(", "$(", "NN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ein Sklave tr\u00e4gt die Farbe seines Gl\u00fcckes,", "tokens": ["Ein", "Skla\u00b7ve", "tr\u00e4gt", "die", "Far\u00b7be", "sei\u00b7nes", "Gl\u00fc\u00b7ckes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Kein edles Herz. Im Schauspiel stimmen sich", "tokens": ["Kein", "ed\u00b7les", "Herz", ".", "Im", "Schau\u00b7spiel", "stim\u00b7men", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$.", "APPRART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die Fl\u00f6ten nach dem Ton des St\u00fcckes:", "tokens": ["Die", "Fl\u00f6\u00b7ten", "nach", "dem", "Ton", "des", "St\u00fc\u00b7ckes", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Allein ein weiser Mann denkt niemals weinerlich.", "tokens": ["Al\u00b7lein", "ein", "wei\u00b7ser", "Mann", "denkt", "nie\u00b7mals", "wei\u00b7ner\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wie, Phanias? Die Farbe deiner Seelen", "tokens": ["Wie", ",", "Pha\u00b7ni\u00b7as", "?", "Die", "Far\u00b7be", "dei\u00b7ner", "See\u00b7len"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "NE", "$.", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Ist nur der Widerschein der Dinge um dich her?", "tokens": ["Ist", "nur", "der", "Wi\u00b7der\u00b7schein", "der", "Din\u00b7ge", "um", "dich", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und dir die Fr\u00f6hlichkeit, des Lebens Reiz, zu stehlen,", "tokens": ["Und", "dir", "die", "Fr\u00f6h\u00b7lich\u00b7keit", ",", "des", "Le\u00b7bens", "Reiz", ",", "zu", "steh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "$,", "ART", "NN", "NN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Bedarf es nur ein widrig Ungef\u00e4hr?", "tokens": ["Be\u00b7darf", "es", "nur", "ein", "wid\u00b7rig", "Un\u00b7ge\u00b7f\u00e4hr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Ich wei\u00df, mein Freund, wohin uns mi\u00dfverstandne G\u00fcte,", "tokens": ["Ich", "wei\u00df", ",", "mein", "Freund", ",", "wo\u00b7hin", "uns", "mi\u00df\u00b7ver\u00b7stand\u00b7ne", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PWAV", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ein Herz, das Freude liebt, die Klugheit leicht vergi\u00dft,", "tokens": ["Ein", "Herz", ",", "das", "Freu\u00b7de", "liebt", ",", "die", "Klug\u00b7heit", "leicht", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und niemand, als sich selbst, zu schaden f\u00e4hig ist,", "tokens": ["Und", "nie\u00b7mand", ",", "als", "sich", "selbst", ",", "zu", "scha\u00b7den", "f\u00e4\u00b7hig", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "KOUS", "PRF", "ADV", "$,", "PTKA", "ADJD", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ich wei\u00df wohin sie bringen k\u00f6nnen.", "tokens": ["Ich", "wei\u00df", "wo\u00b7hin", "sie", "brin\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWAV", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Doch, alles recht gesch\u00e4tzt, gewinnst du mehr dabei", "tokens": ["Doch", ",", "al\u00b7les", "recht", "ge\u00b7sch\u00e4tzt", ",", "ge\u00b7winnst", "du", "mehr", "da\u00b7bei"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "PIS", "ADJD", "VVPP", "$,", "VVFIN", "PPER", "ADV", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Als du verlierst. Was Toren uns mi\u00dfg\u00f6nnen", "tokens": ["Als", "du", "ver\u00b7lierst", ".", "Was", "To\u00b7ren", "uns", "mi\u00df\u00b7g\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "PWS", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Beweist nicht stets wie sehr man gl\u00fccklich sei.", "tokens": ["Be\u00b7weist", "nicht", "stets", "wie", "sehr", "man", "gl\u00fcck\u00b7lich", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "KOKOM", "ADV", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Das wahre Gl\u00fcck, das Eigentum der Weisen,", "tokens": ["Das", "wah\u00b7re", "Gl\u00fcck", ",", "das", "Ei\u00b7gen\u00b7tum", "der", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Steht fest, indes Fortunens Kugel rollt.", "tokens": ["Steht", "fest", ",", "in\u00b7des", "For\u00b7tu\u00b7nens", "Ku\u00b7gel", "rollt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Dem Reichen mu\u00df die Pracht, die ihm der Indus zollt,", "tokens": ["Dem", "Rei\u00b7chen", "mu\u00df", "die", "Pracht", ",", "die", "ihm", "der", "In\u00b7dus", "zollt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Erst, da\u00df er gl\u00fccklich sei, beweisen:", "tokens": ["Erst", ",", "da\u00df", "er", "gl\u00fcck\u00b7lich", "sei", ",", "be\u00b7wei\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Der Weise f\u00fchlt er ", "tokens": ["Der", "Wei\u00b7se", "f\u00fchlt", "er"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-", "measure": "iambic.di"}, "line.33": {"text": "Aus Ton so gut als aus getriebnem Gold.", "tokens": ["Aus", "Ton", "so", "gut", "als", "aus", "ge\u00b7trieb\u00b7nem", "Gold", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADJD", "KOKOM", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Wenn um ihn her die muntern L\u00e4mmer springen,", "tokens": ["Wenn", "um", "ihn", "her", "die", "mun\u00b7tern", "L\u00e4m\u00b7mer", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Indem er sorgenfrei in eignem Schatten sitzt,", "tokens": ["In\u00b7dem", "er", "sor\u00b7gen\u00b7frei", "in", "eig\u00b7nem", "Schat\u00b7ten", "sitzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und Zephyrn, untermischt mit bunten Schmetterlingen,", "tokens": ["Und", "Ze\u00b7phyrn", ",", "un\u00b7ter\u00b7mischt", "mit", "bun\u00b7ten", "Schmet\u00b7ter\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Gem\u00e4hter Wiesen Duft ihm frisch entgegen bringen,", "tokens": ["Ge\u00b7m\u00e4h\u00b7ter", "Wie\u00b7sen", "Duft", "ihm", "frisch", "ent\u00b7ge\u00b7gen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PPER", "ADJD", "PTKVZ", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Die V\u00f6gel um ihn her aus tausend Zweigen singen,", "tokens": ["Die", "V\u00f6\u00b7gel", "um", "ihn", "her", "aus", "tau\u00b7send", "Zwei\u00b7gen", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "ADV", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und alles, was er sieht, zugleich ergetzt und n\u00fctzt:", "tokens": ["Und", "al\u00b7les", ",", "was", "er", "sieht", ",", "zu\u00b7gleich", "er\u00b7getzt", "und", "n\u00fctzt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Wie leicht vergi\u00dft er da, er, der so viel besitzt,", "tokens": ["Wie", "leicht", "ver\u00b7gi\u00dft", "er", "da", ",", "er", ",", "der", "so", "viel", "be\u00b7sitzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ADV", "$,", "PPER", "$,", "PRELS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Da\u00df sich sein Landhaus nicht auf Marmors\u00e4ulen st\u00fctzt,", "tokens": ["Da\u00df", "sich", "sein", "Land\u00b7haus", "nicht", "auf", "Mar\u00b7mor\u00b7s\u00e4u\u00b7len", "st\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Nicht Sklaven ohne Zahl in seinem Vorhof l\u00e4rmen,", "tokens": ["Nicht", "Skla\u00b7ven", "oh\u00b7ne", "Zahl", "in", "sei\u00b7nem", "Vor\u00b7hof", "l\u00e4r\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und Fliegen nur, wenn er zu Tische sitzt,", "tokens": ["Und", "Flie\u00b7gen", "nur", ",", "wenn", "er", "zu", "Ti\u00b7sche", "sitzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.45": {"text": "Kein Schmeichler-Heer belagert seine T\u00fcr,", "tokens": ["Kein", "Schmeich\u00b7ler\u00b7Heer", "be\u00b7la\u00b7gert", "sei\u00b7ne", "T\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Kein Hof umschimmert ihn! \u2013 Er freue sich! daf\u00fcr", "tokens": ["Kein", "Hof", "um\u00b7schim\u00b7mert", "ihn", "!", "\u2013", "Er", "freu\u00b7e", "sich", "!", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "$(", "PPER", "VVFIN", "PRF", "$.", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Besitzt er was das jedem Midas fehlet,", "tokens": ["Be\u00b7sitzt", "er", "was", "das", "je\u00b7dem", "Mi\u00b7das", "feh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.48": {"text": "Was der Monarch mit Gold zu kaufen f\u00e4lschlich meint,", "tokens": ["Was", "der", "Mon\u00b7arch", "mit", "Gold", "zu", "kau\u00b7fen", "f\u00e4lschlich", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "ADJD", "VVFIN", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.49": {"text": "Was, wer es kennt, vor einer Krone w\u00e4hlet,", "tokens": ["Was", ",", "wer", "es", "kennt", ",", "vor", "ei\u00b7ner", "Kro\u00b7ne", "w\u00e4h\u00b7let", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWS", "PPER", "VVFIN", "$,", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Das h\u00f6chste Gut des Lebens, einen Freund.\u00ab", "tokens": ["Das", "h\u00f6chs\u00b7te", "Gut", "des", "Le\u00b7bens", ",", "ei\u00b7nen", "Freund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "\u00bbdu schw\u00e4rmst, Musarion! \u2013 Er, dem das Gl\u00fcck den R\u00fccken", "tokens": ["\u00bb", "du", "schw\u00e4rmst", ",", "Mu\u00b7sa\u00b7ri\u00b7on", "!", "\u2013", "Er", ",", "dem", "das", "Gl\u00fcck", "den", "R\u00fc\u00b7cken"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "NN", "$.", "$(", "PPER", "$,", "PRELS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gewiesen, einen Freund?\u00ab \u2013 \u00bbEin Beispiel siehst du hier\u00ab,", "tokens": ["Ge\u00b7wie\u00b7sen", ",", "ei\u00b7nen", "Freund", "?", "\u00ab", "\u2013", "\u00bb", "Ein", "Bei\u00b7spiel", "siehst", "du", "hier", "\u00ab", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "ART", "NN", "$.", "$(", "$(", "$(", "ART", "NN", "VVFIN", "PPER", "ADV", "$(", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erwidert sie: \u00bbmich, die von freien St\u00fccken", "tokens": ["Er\u00b7wi\u00b7dert", "sie", ":", "\u00bb", "mich", ",", "die", "von", "frei\u00b7en", "St\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "$(", "PPER", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Athen verlie\u00df, dich sucht, und da du mir", "tokens": ["A\u00b7then", "ver\u00b7lie\u00df", ",", "dich", "sucht", ",", "und", "da", "du", "mir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "PPER", "VVFIN", "$,", "KON", "KOUS", "PPER", "PPER"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Entflohest, dir (der m\u00fctterlichen Lehren", "tokens": ["Ent\u00b7flo\u00b7hest", ",", "dir", "(", "der", "m\u00fct\u00b7ter\u00b7li\u00b7chen", "Leh\u00b7ren"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Uneingedenk) so eifrig nachgejagt,", "tokens": ["Un\u00b7ein\u00b7ge\u00b7denk", ")", "so", "eif\u00b7rig", "nach\u00b7ge\u00b7jagt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie andre meiner Art vor dir geflohen w\u00e4ren.", "tokens": ["Wie", "and\u00b7re", "mei\u00b7ner", "Art", "vor", "dir", "ge\u00b7flo\u00b7hen", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ich d\u00e4chte, das beweist, wenn einem Mann zu Ehren", "tokens": ["Ich", "d\u00e4ch\u00b7te", ",", "das", "be\u00b7weist", ",", "wenn", "ei\u00b7nem", "Mann", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PDS", "VVFIN", "$,", "KOUS", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein M\u00e4dchen \u2013 sich \u2013 und seinen Kopfputz wagt!\u00ab", "tokens": ["Ein", "M\u00e4d\u00b7chen", "\u2013", "sich", "\u2013", "und", "sei\u00b7nen", "Kopf\u00b7putz", "wagt", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "PRF", "$(", "KON", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "\u00bbich wei\u00df die Zeit \u2013 ich trug noch deine Kette \u2013", "tokens": ["\u00bb", "ich", "wei\u00df", "die", "Zeit", "\u2013", "ich", "trug", "noch", "dei\u00b7ne", "Ket\u00b7te", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "$(", "PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(hier seufzte Phanias) da, mich entz\u00fcckt zu sehn,", "tokens": ["(", "hier", "seufz\u00b7te", "Pha\u00b7ni\u00b7as", ")", "da", ",", "mich", "ent\u00b7z\u00fcckt", "zu", "sehn", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "NE", "$(", "ADV", "$,", "PPER", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dich weniger gekostet h\u00e4tte.", "tokens": ["Dich", "we\u00b7ni\u00b7ger", "ge\u00b7kos\u00b7tet", "h\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du durftest, statt mir nachzugehn,", "tokens": ["Du", "durf\u00b7test", ",", "statt", "mir", "nach\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich damals nur nach Art der Nymphen str\u00e4uben,", "tokens": ["Dich", "da\u00b7mals", "nur", "nach", "Art", "der", "Nym\u00b7phen", "str\u00e4u\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die gern an einem Busch im Fliehen hangen bleiben,", "tokens": ["Die", "gern", "an", "ei\u00b7nem", "Busch", "im", "Flie\u00b7hen", "han\u00b7gen", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "APPRART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit leiser Stimme dr\u00e4un und l\u00e4chelnd widerstehn:", "tokens": ["Mit", "lei\u00b7ser", "Stim\u00b7me", "dr\u00e4un", "und", "l\u00e4\u00b7chelnd", "wi\u00b7der\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Allein, wer kann daf\u00fcr, da\u00df ungeneigte Winde", "tokens": ["Al\u00b7lein", ",", "wer", "kann", "da\u00b7f\u00fcr", ",", "da\u00df", "un\u00b7ge\u00b7neig\u00b7te", "Win\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VMFIN", "PAV", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Von unsern W\u00fcnschen stets den besten Teil verwehn?", "tokens": ["Von", "un\u00b7sern", "W\u00fcn\u00b7schen", "stets", "den", "bes\u00b7ten", "Teil", "ver\u00b7wehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dies ist vorbei! Jetzt, wenn es bei mir st\u00fcnde,", "tokens": ["Dies", "ist", "vor\u00b7bei", "!", "Jetzt", ",", "wenn", "es", "bei", "mir", "st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$.", "ADV", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "W\u00fcnscht ich mir nichts als ein gela\u00dfnes Blut.", "tokens": ["W\u00fcnscht", "ich", "mir", "nichts", "als", "ein", "ge\u00b7la\u00df\u00b7nes", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PIS", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Man nennt mich zu Athen ungl\u00fccklich \u2013 doch, ich finde,", "tokens": ["Man", "nennt", "mich", "zu", "A\u00b7then", "un\u00b7gl\u00fcck\u00b7lich", "\u2013", "doch", ",", "ich", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "NE", "ADJD", "$(", "ADV", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Zu etwas, wie man sagt, ist stets das Ungl\u00fcck gut;", "tokens": ["Zu", "et\u00b7was", ",", "wie", "man", "sagt", ",", "ist", "stets", "das", "Un\u00b7gl\u00fcck", "gut", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWAV", "PIS", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Durch ein bezaubertes Gewinde", "tokens": ["Durch", "ein", "be\u00b7zau\u00b7ber\u00b7tes", "Ge\u00b7win\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Von s\u00fc\u00dfem Irrtum hat zuletzt", "tokens": ["Von", "s\u00fc\u00b7\u00dfem", "Irr\u00b7tum", "hat", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Die Torheit selbst mich auf den Weg gesetzt,", "tokens": ["Die", "Tor\u00b7heit", "selbst", "mich", "auf", "den", "Weg", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Gesegnet seist du mir, Geburtstag meines Gl\u00fccks!", "tokens": ["Ge\u00b7seg\u00b7net", "seist", "du", "mir", ",", "Ge\u00b7burts\u00b7tag", "mei\u00b7nes", "Gl\u00fccks", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PPER", "$,", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Nicht Phanias, der G\u00fcnstling des Geschicks,", "tokens": ["Nicht", "Pha\u00b7ni\u00b7as", ",", "der", "G\u00fcnst\u00b7ling", "des", "Ge\u00b7schicks", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Nein, Phanias, der Nackte, der Verbannte,", "tokens": ["Nein", ",", "Pha\u00b7ni\u00b7as", ",", "der", "Nack\u00b7te", ",", "der", "Ver\u00b7bann\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Ist neidenswert! Da war er wirklich arm,", "tokens": ["Ist", "nei\u00b7dens\u00b7wert", "!", "Da", "war", "er", "wirk\u00b7lich", "arm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Ungl\u00fccklicher als Irus, glich dem Kranken", "tokens": ["Un\u00b7gl\u00fcck\u00b7li\u00b7cher", "als", "I\u00b7rus", ",", "glich", "dem", "Kran\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "NE", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Der sich zu Tode tanzt, als Schmeichler, Schwarm an Schwarm.", "tokens": ["Der", "sich", "zu", "To\u00b7de", "tanzt", ",", "als", "Schmeich\u00b7ler", ",", "Schwarm", "an", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVFIN", "$,", "KOUS", "NN", "$,", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sein Herzensblut aus goldnen Bechern tranken:", "tokens": ["Sein", "Her\u00b7zens\u00b7blut", "aus", "gold\u00b7nen", "Be\u00b7chern", "tran\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Beim n\u00e4chtlichen Gelag, an feiler Phrynen Brust,", "tokens": ["Beim", "n\u00e4cht\u00b7li\u00b7chen", "Ge\u00b7lag", ",", "an", "fei\u00b7ler", "Phry\u00b7nen", "Brust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da war er elend, ", "tokens": ["Da", "war", "er", "e\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.26": {"text": "Von jeder Leidenschaft! ein Opfertier der Lust!", "tokens": ["Von", "je\u00b7der", "Lei\u00b7den\u00b7schaft", "!", "ein", "Op\u00b7fer\u00b7tier", "der", "Lust", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$.", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie? Der, der siebenfach von einer Schlang umwunden", "tokens": ["Wie", "?", "Der", ",", "der", "sie\u00b7ben\u00b7fach", "von", "ei\u00b7ner", "Schlang", "um\u00b7wun\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "ART", "$,", "PRELS", "PRF", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Auf Blumen schl\u00e4ft und tr\u00e4umt er sitz auf einem Thron,", "tokens": ["Auf", "Blu\u00b7men", "schl\u00e4ft", "und", "tr\u00e4umt", "er", "sitz", "auf", "ei\u00b7nem", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der sollte gl\u00fccklich sein? \u2013 Und wenn Endymion,", "tokens": ["Der", "soll\u00b7te", "gl\u00fcck\u00b7lich", "sein", "?", "\u2013", "Und", "wenn", "En\u00b7dy\u00b7mi\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADJD", "VAINF", "$.", "$(", "KON", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "(dem Luna, da\u00df sie ihn bequemer k\u00fcssen m\u00f6ge,", "tokens": ["(", "dem", "Lu\u00b7na", ",", "da\u00df", "sie", "ihn", "be\u00b7que\u00b7mer", "k\u00fcs\u00b7sen", "m\u00f6\u00b7ge", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So sch\u00f6ne Tr\u00e4ume gab) durch eine Million", "tokens": ["So", "sch\u00f6\u00b7ne", "Tr\u00e4u\u00b7me", "gab", ")", "durch", "ei\u00b7ne", "Mil\u00b7li\u00b7on"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Von Sonnenaltern stets in s\u00fc\u00dfen Tr\u00e4umen l\u00e4ge,", "tokens": ["Von", "Son\u00b7nen\u00b7al\u00b7tern", "stets", "in", "s\u00fc\u00b7\u00dfen", "Tr\u00e4u\u00b7men", "l\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und tr\u00e4umt' er schmaus am G\u00f6ttertisch", "tokens": ["Und", "tr\u00e4umt'", "er", "schmaus", "am", "G\u00f6t\u00b7ter\u00b7tisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Mit Jupitern und buhle mit G\u00f6ttinnen,", "tokens": ["Mit", "Ju\u00b7pi\u00b7tern", "und", "buh\u00b7le", "mit", "G\u00f6t\u00b7tin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Ein s\u00fc\u00df bet\u00e4ubendes Gemisch", "tokens": ["Ein", "s\u00fc\u00df", "be\u00b7t\u00e4u\u00b7ben\u00b7des", "Ge\u00b7misch"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Von allem was ergetzt berausche seine Sinnen,", "tokens": ["Von", "al\u00b7lem", "was", "er\u00b7getzt", "be\u00b7rau\u00b7sche", "sei\u00b7ne", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PWS", "VVPP", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Mit Einem Wort, er schwimme wie ein Fisch", "tokens": ["Mit", "Ei\u00b7nem", "Wort", ",", "er", "schwim\u00b7me", "wie", "ein", "Fisch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "In einem Ozean von Wonne \u2013", "tokens": ["In", "ei\u00b7nem", "O\u00b7ze\u00b7an", "von", "Won\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Sprich, wer gest\u00e4nd uns, unerr\u00f6tend, ein,", "tokens": ["Sprich", ",", "wer", "ge\u00b7st\u00e4nd", "uns", ",", "un\u00b7er\u00b7r\u00f6\u00b7tend", ",", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVIMP", "$,", "PWS", "VVFIN", "PPER", "$,", "ADJD", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Er w\u00fcnsche sich Endymion zu sein?", "tokens": ["Er", "w\u00fcn\u00b7sche", "sich", "En\u00b7dy\u00b7mi\u00b7on", "zu", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "NN", "PTKZU", "VAINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.41": {"text": "Diogenes, der Hund, in seiner Tonne", "tokens": ["Dio\u00b7ge\u00b7nes", ",", "der", "Hund", ",", "in", "sei\u00b7ner", "Ton\u00b7ne"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.42": {"text": "War gl\u00fccklicher! \u2013 In unsrer eignen Brust,", "tokens": ["War", "gl\u00fcck\u00b7li\u00b7cher", "!", "\u2013", "In", "uns\u00b7rer", "eig\u00b7nen", "Brust", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$.", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Da, oder nirgends, flie\u00dft die Quelle wahrer Lust,", "tokens": ["Da", ",", "o\u00b7der", "nir\u00b7gends", ",", "flie\u00dft", "die", "Quel\u00b7le", "wah\u00b7rer", "Lust", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KON", "ADV", "$,", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Der Freuden, welche nie versiegen,", "tokens": ["Der", "Freu\u00b7den", ",", "wel\u00b7che", "nie", "ver\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Des Zustands dauernder Vergn\u00fcgen,", "tokens": ["Des", "Zu\u00b7stands", "dau\u00b7ern\u00b7der", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Den nichts von au\u00dfen st\u00f6rt! Wie elend h\u00e4tte mich", "tokens": ["Den", "nichts", "von", "au\u00b7\u00dfen", "st\u00f6rt", "!", "Wie", "e\u00b7lend", "h\u00e4t\u00b7te", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ADV", "VVFIN", "$.", "PWAV", "ADJD", "VAFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Ein Wechsel, der mir alles raubte", "tokens": ["Ein", "Wech\u00b7sel", ",", "der", "mir", "al\u00b7les", "raub\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Wodurch ich mich vor diesem gl\u00fccklich glaubte,", "tokens": ["Wo\u00b7durch", "ich", "mich", "vor", "die\u00b7sem", "gl\u00fcck\u00b7lich", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPR", "PDAT", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.49": {"text": "Fortunens ganzen Kram, \u2013 wie elend h\u00e4tt er mich", "tokens": ["For\u00b7tu\u00b7nens", "gan\u00b7zen", "Kram", ",", "\u2013", "wie", "e\u00b7lend", "h\u00e4tt", "er", "mich"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "$(", "PWAV", "ADJD", "VAFIN", "PPER", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Gemacht, wenn mir aus ihrer lichten Sph\u00e4re", "tokens": ["Ge\u00b7macht", ",", "wenn", "mir", "aus", "ih\u00b7rer", "lich\u00b7ten", "Sph\u00e4\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "Die Weisheit nicht zu H\u00fclf erschienen w\u00e4re,", "tokens": ["Die", "Weis\u00b7heit", "nicht", "zu", "H\u00fclf", "er\u00b7schie\u00b7nen", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Die aus den Wolken mir die Arme reicht, zu sich", "tokens": ["Die", "aus", "den", "Wol\u00b7ken", "mir", "die", "Ar\u00b7me", "reicht", ",", "zu", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "$,", "APPR", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Hinauf mich zieht, und mich dahin versetzet,", "tokens": ["Hin\u00b7auf", "mich", "zieht", ",", "und", "mich", "da\u00b7hin", "ver\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "KON", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.54": {"text": "Wo ihre Lieblinge, frei von Begier und Wahn,", "tokens": ["Wo", "ih\u00b7re", "Lieb\u00b7lin\u00b7ge", ",", "frei", "von", "Be\u00b7gier", "und", "Wahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$,", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.55": {"text": "Von keiner Lust gereizt, von keinem Schmerz verletzet,", "tokens": ["Von", "kei\u00b7ner", "Lust", "ge\u00b7reizt", ",", "von", "kei\u00b7nem", "Schmerz", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "$,", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Sich den Olympiern und ihrer Wonne nahn.\u00ab", "tokens": ["Sich", "den", "O\u00b7lym\u00b7piern", "und", "ih\u00b7rer", "Won\u00b7ne", "nahn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ART", "NN", "KON", "PPOSAT", "NN", "ADJA", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.21": {"line.1": {"text": "Hier ward der hohe Schwung, den Phanias zu nehmen", "tokens": ["Hier", "ward", "der", "ho\u00b7he", "Schwung", ",", "den", "Pha\u00b7ni\u00b7as", "zu", "neh\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Begriffen war, gehemmt. Schon schwanden Raum und Zeit", "tokens": ["Be\u00b7grif\u00b7fen", "war", ",", "ge\u00b7hemmt", ".", "Schon", "schwan\u00b7den", "Raum", "und", "Zeit"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "VVPP", "$.", "ADV", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aus seinem Blick, schon f\u00fchlt' er sich entkleidt", "tokens": ["Aus", "sei\u00b7nem", "Blick", ",", "schon", "f\u00fchlt'", "er", "sich", "ent\u00b7kleidt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PRF", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Vom niederziehenden Gewand der Sterblichkeit,", "tokens": ["Vom", "nie\u00b7der\u00b7zie\u00b7hen\u00b7den", "Ge\u00b7wand", "der", "Sterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schon war er halb ein Gott; \u2013 als eine Kleinigkeit,", "tokens": ["Schon", "war", "er", "halb", "ein", "Gott", ";", "\u2013", "als", "ei\u00b7ne", "Klei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ART", "NN", "$.", "$(", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die wir uns fast zu sagen sch\u00e4men,", "tokens": ["Die", "wir", "uns", "fast", "zu", "sa\u00b7gen", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ihn pl\u00f6tzlich in die Unterwelt", "tokens": ["Ihn", "pl\u00f6tz\u00b7lich", "in", "die", "Un\u00b7ter\u00b7welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zur\u00fcckezog. \u2013 Ihr m\u00e4chtigen Besieger", "tokens": ["Zu\u00b7r\u00fc\u00b7ck\u00b7e\u00b7zog", ".", "\u2013", "Ihr", "m\u00e4ch\u00b7ti\u00b7gen", "Be\u00b7sie\u00b7ger"], "token_info": ["word", "punct", "punct", "word", "word", "word"], "pos": ["NE", "$.", "$(", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der Menschlichkeit, die ihr dem Sternenfeld", "tokens": ["Der", "Menschlich\u00b7keit", ",", "die", "ihr", "dem", "Ster\u00b7nen\u00b7feld"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Euch nahe glaubt \u2013 das Herz ist ein Betr\u00fcger!", "tokens": ["Euch", "na\u00b7he", "glaubt", "\u2013", "das", "Herz", "ist", "ein", "Be\u00b7tr\u00fc\u00b7ger", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$(", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Erkennet euer Bild in Phanias und bebt!", "tokens": ["Er\u00b7ken\u00b7net", "eu\u00b7er", "Bild", "in", "Pha\u00b7ni\u00b7as", "und", "bebt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NE", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Weise, der so k\u00fchn sich zum Olymp erhebt,", "tokens": ["Der", "Wei\u00b7se", ",", "der", "so", "k\u00fchn", "sich", "zum", "O\u00b7lymp", "er\u00b7hebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Der schon so hoch empor gestiegen,", "tokens": ["Der", "schon", "so", "hoch", "em\u00b7por", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Da\u00df er (wie Sancho dort auf Magellonens Pferd)", "tokens": ["Da\u00df", "er", "(", "wie", "San\u00b7cho", "dort", "auf", "Ma\u00b7gel\u00b7lo\u00b7nens", "Pferd", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "KOKOM", "NE", "ADV", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die purpurnen und himmelblauen Ziegen", "tokens": ["Die", "pur\u00b7pur\u00b7nen", "und", "him\u00b7mel\u00b7blau\u00b7en", "Zie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Des Himmels grasen sieht,", "tokens": ["Des", "Him\u00b7mels", "gra\u00b7sen", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Und aus der Glut, die sein Gehirn verzehrt,", "tokens": ["Und", "aus", "der", "Glut", ",", "die", "sein", "Ge\u00b7hirn", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Des Feuerhimmels N\u00e4he schlie\u00dfet,", "tokens": ["Des", "Feu\u00b7er\u00b7him\u00b7mels", "N\u00e4\u00b7he", "schlie\u00b7\u00dfet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Ihn, der nichts Sterblichs mehr mit seinem Blick beehrt,", "tokens": ["Ihn", ",", "der", "nichts", "Sterb\u00b7lichs", "mehr", "mit", "sei\u00b7nem", "Blick", "be\u00b7ehrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PIS", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den stolzen Gast des \u00c4thers, schie\u00dfet", "tokens": ["Den", "stol\u00b7zen", "Gast", "des", "\u00c4\u00b7thers", ",", "schie\u00b7\u00dfet"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Musarion mit einem \u2013 Blick herab.", "tokens": ["Mu\u00b7sa\u00b7ri\u00b7on", "mit", "ei\u00b7nem", "\u2013", "Blick", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "$(", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Doch freilich war's ein Blick, nur jenem zu vergleichen", "tokens": ["Doch", "frei\u00b7lich", "wa\u00b7r's", "ein", "Blick", ",", "nur", "je\u00b7nem", "zu", "ver\u00b7glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "$,", "ADV", "PDAT", "PTKZU", "VVINF"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Den Coypel seinem Amor gab;", "tokens": ["Den", "Coy\u00b7pel", "sei\u00b7nem", "A\u00b7mor", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Der, euer Herz gewisser zu beschleichen,", "tokens": ["Der", ",", "eu\u00b7er", "Herz", "ge\u00b7wis\u00b7ser", "zu", "be\u00b7schlei\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Euch schalkhaft warnt, als spr\u00e4ch er: \u00bbSeht ihr mich?", "tokens": ["Euch", "schalk\u00b7haft", "warnt", ",", "als", "spr\u00e4ch", "er", ":", "\u00bb", "Seht", "ihr", "mich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$,", "KOUS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ihr denkt, ich sei ein Kind voll s\u00fc\u00dfer Unschuld, ich?", "tokens": ["Ihr", "denkt", ",", "ich", "sei", "ein", "Kind", "voll", "s\u00fc\u00b7\u00dfer", "Un\u00b7schuld", ",", "ich", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "ADJD", "ADJA", "NN", "$,", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Verla\u00dft euch drauf! Seht ihr an meiner Seite", "tokens": ["Ver\u00b7la\u00dft", "euch", "drauf", "!", "Seht", "ihr", "an", "mei\u00b7ner", "Sei\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "$.", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Den K\u00f6cher hier? Wenn euch zu raten ist,", "tokens": ["Den", "K\u00f6\u00b7cher", "hier", "?", "Wenn", "euch", "zu", "ra\u00b7ten", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$.", "KOUS", "PPER", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "So flieht! \u2013 Und doch, was hilft die kleine Frist?", "tokens": ["So", "flieht", "!", "\u2013", "Und", "doch", ",", "was", "hilft", "die", "klei\u00b7ne", "Frist", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "$(", "KON", "ADV", "$,", "PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Es sei nun morgen oder heute,", "tokens": ["Es", "sei", "nun", "mor\u00b7gen", "o\u00b7der", "heu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Ihr habt ein Herz, und das ist meine Beute!\u00ab", "tokens": ["Ihr", "habt", "ein", "Herz", ",", "und", "das", "ist", "mei\u00b7ne", "Beu\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KON", "PDS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "So, oder doch in diesem Ton,", "tokens": ["So", ",", "o\u00b7der", "doch", "in", "die\u00b7sem", "Ton", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KON", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So etwas sprach der Blick, womit Musarion", "tokens": ["So", "et\u00b7was", "sprach", "der", "Blick", ",", "wo\u00b7mit", "Mu\u00b7sa\u00b7ri\u00b7on"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den weisen Phanias aus seiner Fassung brachte.", "tokens": ["Den", "wei\u00b7sen", "Pha\u00b7ni\u00b7as", "aus", "sei\u00b7ner", "Fas\u00b7sung", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er sah, er stockt', er schwieg; die alte Flamm erwachte,", "tokens": ["Er", "sah", ",", "er", "stockt'", ",", "er", "schwieg", ";", "die", "al\u00b7te", "Flamm", "er\u00b7wach\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und seine Augen f\u00fcllt' ein unfreiwillig Na\u00df.", "tokens": ["Und", "sei\u00b7ne", "Au\u00b7gen", "f\u00fcllt'", "ein", "un\u00b7frei\u00b7wil\u00b7lig", "Na\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Sch\u00f6ne stellte sich sie sehe nichts, und lachte", "tokens": ["Die", "Sch\u00f6\u00b7ne", "stell\u00b7te", "sich", "sie", "se\u00b7he", "nichts", ",", "und", "lach\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "PPER", "VVFIN", "PIS", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nur innerlich. Drauf sprach sie: \u00bbPhanias,", "tokens": ["Nur", "in\u00b7ner\u00b7lich", ".", "Drauf", "sprach", "sie", ":", "\u00bb", "Pha\u00b7ni\u00b7as", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PAV", "VVFIN", "PPER", "$.", "$(", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Es d\u00e4mmert schon. Ich habe mich zu lange", "tokens": ["Es", "d\u00e4m\u00b7mert", "schon", ".", "Ich", "ha\u00b7be", "mich", "zu", "lan\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Bei dir verweilt. Athen ist weit von hier;", "tokens": ["Bei", "dir", "ver\u00b7weilt", ".", "A\u00b7then", "ist", "weit", "von", "hier", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$.", "NE", "VAFIN", "ADJD", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "In dieser Gegend kenn ich niemand au\u00dfer dir,", "tokens": ["In", "die\u00b7ser", "Ge\u00b7gend", "kenn", "ich", "nie\u00b7mand", "au\u00b7\u00dfer", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "PIS", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und hier im Hain, gesteh ich, w\u00e4re mir", "tokens": ["Und", "hier", "im", "Hain", ",", "ge\u00b7steh", "ich", ",", "w\u00e4\u00b7re", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Die Nacht hindurch vor Ziegenf\u00fc\u00dflern bange.", "tokens": ["Die", "Nacht", "hin\u00b7durch", "vor", "Zie\u00b7gen\u00b7f\u00fc\u00df\u00b7lern", "ban\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Was ist zu tun? \u2013 Ich denk ich folge dir?\u00ab", "tokens": ["Was", "ist", "zu", "tun", "?", "\u2013", "Ich", "denk", "ich", "fol\u00b7ge", "dir", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "PTKZU", "VVINF", "$.", "$(", "PPER", "VVFIN", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "\u00bbmir?\u00ab stottert Phanias: \u00bbgewi\u00df sehr viele Ehre!", "tokens": ["\u00bb", "mir", "?", "\u00ab", "stot\u00b7tert", "Pha\u00b7ni\u00b7as", ":", "\u00bb", "ge\u00b7wi\u00df", "sehr", "vie\u00b7le", "Eh\u00b7re", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$.", "$(", "VVFIN", "NE", "$.", "$(", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Allein, mein Haus ist klein\u00ab \u2013 \u00bbUnd wenn es kleiner w\u00e4re,", "tokens": ["Al\u00b7lein", ",", "mein", "Haus", "ist", "klein", "\u00ab", "\u2013", "\u00bb", "Und", "wenn", "es", "klei\u00b7ner", "w\u00e4\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$(", "$(", "$(", "KON", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr eine Freundin hat die kleinste H\u00fctte Raum.\u00ab \u2013", "tokens": ["F\u00fcr", "ei\u00b7ne", "Freun\u00b7din", "hat", "die", "kleins\u00b7te", "H\u00fct\u00b7te", "Raum", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u00bbdu wirst an allem Mangel haben;", "tokens": ["\u00bb", "du", "wirst", "an", "al\u00b7lem", "Man\u00b7gel", "ha\u00b7ben", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PIS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein wenig Milch, ein Ei, und dieses kaum\u00ab \u2013", "tokens": ["Ein", "we\u00b7nig", "Milch", ",", "ein", "Ei", ",", "und", "die\u00b7ses", "kaum", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PIAT", "NN", "$,", "ART", "NN", "$,", "KON", "PDS", "ADV", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "\u00bbmich hungert nicht.\u00ab \u2013 \u00bbNur einen Hirtenknaben,", "tokens": ["\u00bb", "mich", "hun\u00b7gert", "nicht", ".", "\u00ab", "\u2013", "\u00bb", "Nur", "ei\u00b7nen", "Hir\u00b7ten\u00b7kna\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "$.", "$(", "$(", "$(", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Dich zu bedienen\u00ab \u2013 \u00bbNur? Es ist an Dem zu viel.", "tokens": ["Dich", "zu", "be\u00b7die\u00b7nen", "\u00ab", "\u2013", "\u00bb", "Nur", "?", "Es", "ist", "an", "Dem", "zu", "viel", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$(", "$(", "$(", "ADV", "$.", "PPER", "VAFIN", "APPR", "ART", "PTKA", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wir wollen gehn, mein Freund! die Luft wird k\u00fchl\u00ab \u2013", "tokens": ["Wir", "wol\u00b7len", "gehn", ",", "mein", "Freund", "!", "die", "Luft", "wird", "k\u00fchl", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "PPOSAT", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbvergib, Musarion; ich mu\u00df dir alles sagen:", "tokens": ["\u00bb", "ver\u00b7gib", ",", "Mu\u00b7sa\u00b7ri\u00b7on", ";", "ich", "mu\u00df", "dir", "al\u00b7les", "sa\u00b7gen", ":"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "$,", "NN", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mein H\u00e4uschen ist besetzt; ich habe seit acht Tagen", "tokens": ["Mein", "H\u00e4usc\u00b7hen", "ist", "be\u00b7setzt", ";", "ich", "ha\u00b7be", "seit", "acht", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Zwei Freunde, die bei mir\u00ab \u2013 \u00bbZwei Freunde?\u00ab \u2013 \u00bbJa, und zwar", "tokens": ["Zwei", "Freun\u00b7de", ",", "die", "bei", "mir", "\u00ab", "\u2013", "\u00bb", "Zwei", "Freun\u00b7de", "?", "\u00ab", "\u2013", "\u00bb", "Ja", ",", "und", "zwar"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "$,", "PRELS", "APPR", "PPER", "$(", "$(", "$(", "CARD", "NN", "$.", "$(", "$(", "$(", "PTKANT", "$,", "KON", "ADV"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.12": {"text": "Die, deucht mir, nicht zu deinem Umgang taugen.\u00ab \u2013", "tokens": ["Die", ",", "deucht", "mir", ",", "nicht", "zu", "dei\u00b7nem", "Um\u00b7gang", "tau\u00b7gen", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "$,", "VVFIN", "PPER", "$,", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "\u00bbwas sagst du? \u2013 Philosophen gar?", "tokens": ["\u00bb", "was", "sagst", "du", "?", "\u2013", "Phi\u00b7lo\u00b7so\u00b7phen", "gar", "?"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Sie haben doch noch ihre Augen?", "tokens": ["Sie", "ha\u00b7ben", "doch", "noch", "ih\u00b7re", "Au\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Gut, Phanias, ich will sie kennen, ich\u00ab \u2013", "tokens": ["Gut", ",", "Pha\u00b7ni\u00b7as", ",", "ich", "will", "sie", "ken\u00b7nen", ",", "ich", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJD", "$,", "NE", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,", "PPER", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "\u00bbdu scherzest.\u00ab \u2013 \u00bbNein, mein Herr; ich hatte, wie ihr mich", "tokens": ["\u00bb", "du", "scher\u00b7zest", ".", "\u00ab", "\u2013", "\u00bb", "Nein", ",", "mein", "Herr", ";", "ich", "hat\u00b7te", ",", "wie", "ihr", "mich"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$.", "$(", "$(", "$(", "PTKANT", "$,", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "$,", "PWAV", "PPER", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Hier seht, von ihrer Art wohl eher", "tokens": ["Hier", "seht", ",", "von", "ih\u00b7rer", "Art", "wohl", "e\u00b7her"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Um meinen Nachttisch stehn.\u00ab \u2013 \u00bbVergib, ich zweifle sehr:", "tokens": ["Um", "mei\u00b7nen", "Nacht\u00b7tisch", "stehn", ".", "\u00ab", "\u2013", "\u00bb", "Ver\u00b7gib", ",", "ich", "zweif\u00b7le", "sehr", ":"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF", "$.", "$(", "$(", "$(", "VVIMP", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der stoische Kleanth \u00ab \u2013 \u00bbO Ceres! und wer mehr?\u00ab", "tokens": ["Der", "sto\u00b7i\u00b7sche", "Kle\u00b7an\u00b7th", "\u00ab", "\u2013", "\u00bb", "O", "Ce\u00b7res", "!", "und", "wer", "mehr", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$(", "$(", "NE", "NE", "$.", "KON", "PWS", "ADV", "$.", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "\u00bbtheophron, der Pythagor\u00e4er,", "tokens": ["\u00bb", "theo\u00b7phron", ",", "der", "Py\u00b7tha\u00b7go\u00b7r\u00e4\u00b7er", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.21": {"text": "Sind schwerlich von so bl\u00f6dem Geist\u00ab \u2013", "tokens": ["Sind", "schwer\u00b7lich", "von", "so", "bl\u00f6\u00b7dem", "Geist", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ADV", "ADJA", "NN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "\u00bbo Phanias, ist alles Gold was glei\u00dft?", "tokens": ["\u00bb", "o", "Pha\u00b7ni\u00b7as", ",", "ist", "al\u00b7les", "Gold", "was", "glei\u00dft", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NE", "$,", "VAFIN", "PIAT", "NN", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Allein, gesetzt, sie w\u00e4ren lauter Geist,", "tokens": ["Al\u00b7lein", ",", "ge\u00b7setzt", ",", "sie", "w\u00e4\u00b7ren", "lau\u00b7ter", "Geist", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVPP", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Was hindert dies? Nur desto mehr Vergn\u00fcgen!\u00ab", "tokens": ["Was", "hin\u00b7dert", "dies", "?", "Nur", "des\u00b7to", "mehr", "Ver\u00b7gn\u00fc\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PDS", "$.", "ADV", "ADV", "PIAT", "NN", "$.", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "\u00bbkurz, wir sind drei, Madam, und auf den Mann", "tokens": ["\u00bb", "kurz", ",", "wir", "sind", "drei", ",", "Ma\u00b7dam", ",", "und", "auf", "den", "Mann"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "$,", "PPER", "VAFIN", "CARD", "$,", "NN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ein kleines Ruhebett\u00ab -\u00bb Man hilft sich wie man kann;", "tokens": ["Ein", "klei\u00b7nes", "Ru\u00b7he\u00b7bett", "\u00ab", "\u00bb", "Man", "hilft", "sich", "wie", "man", "kann", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$(", "$(", "PIS", "VVFIN", "PRF", "KOKOM", "PIS", "VMFIN", "$."], "meter": "-+-+-+-+-++-+", "measure": "unknown.measure.septa"}, "line.27": {"text": "Und k\u00f6nnen wir den Schlaf durch Schwatzen nicht betr\u00fcgen?", "tokens": ["Und", "k\u00f6n\u00b7nen", "wir", "den", "Schlaf", "durch", "Schwat\u00b7zen", "nicht", "be\u00b7tr\u00fc\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wir gehn, mein Lieber \u2013 deinen Arm!", "tokens": ["Wir", "gehn", ",", "mein", "Lie\u00b7ber", "\u2013", "dei\u00b7nen", "Arm", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Nun, Phanias? macht dir mein Antrag warm?", "tokens": ["Nun", ",", "Pha\u00b7ni\u00b7as", "?", "macht", "dir", "mein", "An\u00b7trag", "warm", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Man d\u00e4cht es w\u00e4re hier wer wei\u00df wie viel zu wagen.", "tokens": ["Man", "d\u00e4cht", "es", "w\u00e4\u00b7re", "hier", "wer", "wei\u00df", "wie", "viel", "zu", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "VAFIN", "ADV", "PWS", "VVFIN", "KOKOM", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Drei Weise werden mir doch wohl gewachsen sein?", "tokens": ["Drei", "Wei\u00b7se", "wer\u00b7den", "mir", "doch", "wohl", "ge\u00b7wach\u00b7sen", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Ich f\u00fcrchte nichts bei euch, und bin allein.\u00ab", "tokens": ["Ich", "f\u00fcrch\u00b7te", "nichts", "bei", "euch", ",", "und", "bin", "al\u00b7lein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPER", "$,", "KON", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Was soll er tun? \u2013 Wo Widersterben", "tokens": ["Was", "soll", "er", "tun", "?", "\u2013", "Wo", "Wi\u00b7ders\u00b7ter\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "$(", "PWAV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vorm Untergang das Schiff nicht retten kann,", "tokens": ["Vorm", "Un\u00b7ter\u00b7gang", "das", "Schiff", "nicht", "ret\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da wird ein weiser Steuermann", "tokens": ["Da", "wird", "ein", "wei\u00b7ser", "Steu\u00b7er\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit guter Art sich in den Wind ergehen.", "tokens": ["Mit", "gu\u00b7ter", "Art", "sich", "in", "den", "Wind", "er\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mein Phanias, der nur aus bl\u00f6der Scheu", "tokens": ["Mein", "Pha\u00b7ni\u00b7as", ",", "der", "nur", "aus", "bl\u00f6\u00b7der", "Scheu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Vor seinen Mentorn sich so lange widersetzte,", "tokens": ["Vor", "sei\u00b7nen", "Men\u00b7torn", "sich", "so", "lan\u00b7ge", "wi\u00b7der\u00b7setz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Schwor, da\u00df er seine Einsiedlei", "tokens": ["Schwor", ",", "da\u00df", "er", "sei\u00b7ne", "Ein\u00b7sied\u00b7lei"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dem Musentempel \u00e4hnlich sch\u00e4tzte,", "tokens": ["Dem", "Mu\u00b7sen\u00b7tem\u00b7pel", "\u00e4hn\u00b7lich", "sch\u00e4tz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Weil ihr das Gl\u00fcck beschieden sei,", "tokens": ["Weil", "ihr", "das", "Gl\u00fcck", "be\u00b7schie\u00b7den", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die liebensw\u00fcrdigste der Musen zu beschatten.", "tokens": ["Die", "lie\u00b7bens\u00b7w\u00fcr\u00b7digs\u00b7te", "der", "Mu\u00b7sen", "zu", "be\u00b7schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Schon zeigte sich, da\u00df ihre Reize noch", "tokens": ["Schon", "zeig\u00b7te", "sich", ",", "da\u00df", "ih\u00b7re", "Rei\u00b7ze", "noch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "$,", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Nicht alle Macht auf ihn verloren hatten.", "tokens": ["Nicht", "al\u00b7le", "Macht", "auf", "ihn", "ver\u00b7lo\u00b7ren", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der ausgetriebne Amor kroch,", "tokens": ["Der", "aus\u00b7ge\u00b7trieb\u00b7ne", "A\u00b7mor", "kroch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So leise, wie auf Blumenspitzen,", "tokens": ["So", "lei\u00b7se", ",", "wie", "auf", "Blu\u00b7men\u00b7spit\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Aus ihren Augen in sein Herz.", "tokens": ["Aus", "ih\u00b7ren", "Au\u00b7gen", "in", "sein", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Des Gottes Ankunft k\u00fcndt ein fliegendes Erhitzen", "tokens": ["Des", "Got\u00b7tes", "An\u00b7kunft", "k\u00fcndt", "ein", "flie\u00b7gen\u00b7des", "Er\u00b7hit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der blassen Wang, ein wollustvoller Schmerz", "tokens": ["Der", "blas\u00b7sen", "Wang", ",", "ein", "wol\u00b7lust\u00b7vol\u00b7ler", "Schmerz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Mit Tr\u00e4nen an, die wider seinen Willen", "tokens": ["Mit", "Tr\u00e4\u00b7nen", "an", ",", "die", "wi\u00b7der", "sei\u00b7nen", "Wil\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PTKVZ", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "In runden Tropfen ihm die Augenwinkel f\u00fcllen.", "tokens": ["In", "run\u00b7den", "Trop\u00b7fen", "ihm", "die", "Au\u00b7gen\u00b7win\u00b7kel", "f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Er meint er atme nur, und seufzt; starrt unverwandt", "tokens": ["Er", "meint", "er", "at\u00b7me", "nur", ",", "und", "seufzt", ";", "starrt", "un\u00b7ver\u00b7wandt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ADV", "$,", "KON", "VVFIN", "$.", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "(indes sie schwatzt und scherzt) sie an, als ob er h\u00f6re,", "tokens": ["(", "in\u00b7des", "sie", "schwatzt", "und", "scherzt", ")", "sie", "an", ",", "als", "ob", "er", "h\u00f6\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPER", "VVFIN", "KON", "VVFIN", "$(", "PPER", "PTKVZ", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und h\u00f6rt doch nichts; dr\u00fcckt ihr die runde Hand,", "tokens": ["Und", "h\u00f6rt", "doch", "nichts", ";", "dr\u00fcckt", "ihr", "die", "run\u00b7de", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIS", "$.", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "Und denkt, indem durchs steigende Gewand", "tokens": ["Und", "denkt", ",", "in\u00b7dem", "durchs", "stei\u00b7gen\u00b7de", "Ge\u00b7wand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Die sch\u00f6ne Brust sich bl\u00e4ht, ob diese halbe Sph\u00e4re", "tokens": ["Die", "sch\u00f6\u00b7ne", "Brust", "sich", "bl\u00e4ht", ",", "ob", "die\u00b7se", "hal\u00b7be", "Sph\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "$,", "KOUS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Der Pythagorischen nicht vorzuziehen w\u00e4re?", "tokens": ["Der", "Py\u00b7tha\u00b7go\u00b7ri\u00b7schen", "nicht", "vor\u00b7zu\u00b7zie\u00b7hen", "w\u00e4\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Die Sch\u00f6ne wurde die Gefahr", "tokens": ["Die", "Sch\u00f6\u00b7ne", "wur\u00b7de", "die", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Worin der Ruhm der Stoa schwebte,", "tokens": ["Wo\u00b7rin", "der", "Ruhm", "der", "Stoa", "schweb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Den Kampf in seiner Brust und ihren Sieg gewahr,", "tokens": ["Den", "Kampf", "in", "sei\u00b7ner", "Brust", "und", "ih\u00b7ren", "Sieg", "ge\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie vergebens er der Macht entgegen strebte,", "tokens": ["Und", "wie", "ver\u00b7ge\u00b7bens", "er", "der", "Macht", "ent\u00b7ge\u00b7gen", "streb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PPER", "ART", "NN", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wovon (so lispelt ihr der Liebesgott ins Ohr)", "tokens": ["Wo\u00b7von", "(", "so", "lis\u00b7pelt", "ihr", "der", "Lie\u00b7bes\u00b7gott", "ins", "Ohr", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Philosophen selbst, sie wollten", "tokens": ["Die", "Phi\u00b7lo\u00b7so\u00b7phen", "selbst", ",", "sie", "woll\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "PPER", "VMFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Nun oder wollten nicht, bald Zeugen werden sollten.", "tokens": ["Nun", "o\u00b7der", "woll\u00b7ten", "nicht", ",", "bald", "Zeu\u00b7gen", "wer\u00b7den", "soll\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "VMFIN", "PTKNEG", "$,", "ADV", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie sah, wie nach und nach sein Tr\u00fcbsinn sich verlor,", "tokens": ["Sie", "sah", ",", "wie", "nach", "und", "nach", "sein", "Tr\u00fcb\u00b7sinn", "sich", "ver\u00b7lor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "APPR", "KON", "APPR", "PPOSAT", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und wie beredt, wie stark sein Auge sagte,", "tokens": ["Und", "wie", "be\u00b7redt", ",", "wie", "stark", "sein", "Au\u00b7ge", "sag\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Was er sich selbst kaum zu gestehen wagte:", "tokens": ["Was", "er", "sich", "selbst", "kaum", "zu", "ge\u00b7ste\u00b7hen", "wag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PRF", "ADV", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Allein sie fand f\u00fcr gut, (und tat sehr klug ", "tokens": ["Al\u00b7lein", "sie", "fand", "f\u00fcr", "gut", ",", "(", "und", "tat", "sehr", "klug"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "APPR", "ADJD", "$,", "$(", "KON", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ihm, was sie sah, und ihrer beiden Seelen", "tokens": ["Ihm", ",", "was", "sie", "sah", ",", "und", "ih\u00b7rer", "bei\u00b7den", "See\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Geheime Sympathie zur Zeit noch zu verhehlen.", "tokens": ["Ge\u00b7hei\u00b7me", "Sym\u00b7pa\u00b7thie", "zur", "Zeit", "noch", "zu", "ver\u00b7heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nur sah sie ihn mit solchen Blicken an,", "tokens": ["Nur", "sah", "sie", "ihn", "mit", "sol\u00b7chen", "Bli\u00b7cken", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die er berechtigt war so g\u00fcnstig auszulegen", "tokens": ["Die", "er", "be\u00b7rech\u00b7tigt", "war", "so", "g\u00fcns\u00b7tig", "aus\u00b7zu\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Als ihm gefiel. Allein, macht die Begier verwegen,", "tokens": ["Als", "ihm", "ge\u00b7fiel", ".", "Al\u00b7lein", ",", "macht", "die", "Be\u00b7gier", "ver\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "ADV", "$,", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "So macht die Liebe bl\u00f6d. Er sah in ihrem Blick", "tokens": ["So", "macht", "die", "Lie\u00b7be", "bl\u00f6d", ".", "Er", "sah", "in", "ih\u00b7rem", "Blick"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sonst jeden Reiz, nur nicht sein nahes Gl\u00fcck.", "tokens": ["Sonst", "je\u00b7den", "Reiz", ",", "nur", "nicht", "sein", "na\u00b7hes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "ADV", "PTKNEG", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "So langten sie, da schon die letzten Strahlen schwanden,", "tokens": ["So", "lang\u00b7ten", "sie", ",", "da", "schon", "die", "letz\u00b7ten", "Strah\u00b7len", "schwan\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bei seinem Landgut an, wo sie das weise Paar,", "tokens": ["Bei", "sei\u00b7nem", "Land\u00b7gut", "an", ",", "wo", "sie", "das", "wei\u00b7se", "Paar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "PWAV", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von Linden die im Vorhof standen", "tokens": ["Von", "Lin\u00b7den", "die", "im", "Vor\u00b7hof", "stan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ART", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Umduftet, unverhofft in einer Stellung fanden,", "tokens": ["Um\u00b7duf\u00b7tet", ",", "un\u00b7ver\u00b7hofft", "in", "ei\u00b7ner", "Stel\u00b7lung", "fan\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die der Philosophie nicht allzu r\u00fchmlich war.", "tokens": ["Die", "der", "Phi\u00b7lo\u00b7so\u00b7phie", "nicht", "all\u00b7zu", "r\u00fchm\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "In einem Hain, der einer Wildnis glich", "tokens": ["In", "ei\u00b7nem", "Hain", ",", "der", "ei\u00b7ner", "Wild\u00b7nis", "glich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und nah am Meer ein kleines Gut begrenzte,", "tokens": ["Und", "nah", "am", "Meer", "ein", "klei\u00b7nes", "Gut", "be\u00b7grenz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ging Phanias mit seinem Gram und sich", "tokens": ["Ging", "Pha\u00b7ni\u00b7as", "mit", "sei\u00b7nem", "Gram", "und", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "PPOSAT", "NN", "KON", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Allein umher; der Abendwind durchstrich", "tokens": ["Al\u00b7lein", "um\u00b7her", ";", "der", "Ab\u00b7end\u00b7wind", "durch\u00b7strich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PTKVZ", "$.", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein fliegend Haar, das keine Ros umkr\u00e4nzte;", "tokens": ["Sein", "flie\u00b7gend", "Haar", ",", "das", "kei\u00b7ne", "Ros", "um\u00b7kr\u00e4nz\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verdrossenheit und Tr\u00fcbsinn malte sich", "tokens": ["Ver\u00b7dros\u00b7sen\u00b7heit", "und", "Tr\u00fcb\u00b7sinn", "mal\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "In Blick und Gang und Stellung sichtbarlich;", "tokens": ["In", "Blick", "und", "Gang", "und", "Stel\u00b7lung", "sicht\u00b7bar\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und was ihm noch zum Timon", "tokens": ["Und", "was", "ihm", "noch", "zum", "Ti\u00b7mon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Ein Mantel, so entfasert, abgef\u00e4rbt", "tokens": ["Ein", "Man\u00b7tel", ",", "so", "ent\u00b7fa\u00b7sert", ",", "ab\u00b7ge\u00b7f\u00e4rbt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ADV", "VVPP", "$,", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und ausgen\u00fctzt, da\u00df es Verdacht erweckte,", "tokens": ["Und", "aus\u00b7ge\u00b7n\u00fctzt", ",", "da\u00df", "es", "Ver\u00b7dacht", "er\u00b7weck\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Er h\u00e4tte den, der einst den Krates deckte,", "tokens": ["Er", "h\u00e4t\u00b7te", "den", ",", "der", "einst", "den", "Kra\u00b7tes", "deck\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Vom Aldermann der Cyniker geerbt.", "tokens": ["Vom", "Al\u00b7der\u00b7mann", "der", "Cy\u00b7ni\u00b7ker", "ge\u00b7erbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Gedankenvoll, mit halb geschlo\u00dfnen Blicken,", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7voll", ",", "mit", "halb", "ge\u00b7schlo\u00df\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Kopf gesenkt, die H\u00e4nde auf den R\u00fccken,", "tokens": ["Den", "Kopf", "ge\u00b7senkt", ",", "die", "H\u00e4n\u00b7de", "auf", "den", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ging er daher. Verwandelt wie er war,", "tokens": ["Ging", "er", "da\u00b7her", ".", "Ver\u00b7wan\u00b7delt", "wie", "er", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$.", "VVPP", "KOKOM", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit langem Bart und ungeschm\u00fccktem Haar,", "tokens": ["Mit", "lan\u00b7gem", "Bart", "und", "un\u00b7ge\u00b7schm\u00fcck\u00b7tem", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mit finstrer Stirn, in Cynischem Gewand", "tokens": ["Mit", "finst\u00b7rer", "Stirn", ",", "in", "Cy\u00b7ni\u00b7schem", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wer h\u00e4tt in ihm den Phanias erkannt,", "tokens": ["Wer", "h\u00e4tt", "in", "ihm", "den", "Pha\u00b7ni\u00b7as", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der k\u00fcrzlich noch von Grazien und Scherzen", "tokens": ["Der", "k\u00fcrz\u00b7lich", "noch", "von", "Gra\u00b7zi\u00b7en", "und", "Scher\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Umflattert war, den Sieger aller Herzen.", "tokens": ["Um\u00b7flat\u00b7tert", "war", ",", "den", "Sie\u00b7ger", "al\u00b7ler", "Her\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Der an Geschmack und Aufwand keinem wich,", "tokens": ["Der", "an", "Ge\u00b7schmack", "und", "Auf\u00b7wand", "kei\u00b7nem", "wich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und zu Athen, wo auch Sokraten zechten,", "tokens": ["Und", "zu", "A\u00b7then", ",", "wo", "auch", "Sok\u00b7ra\u00b7ten", "zech\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "$,", "PWAV", "ADV", "NN", "VVFIN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Beim muntern Fest, in durchgescherzten N\u00e4chten,", "tokens": ["Beim", "mun\u00b7tern", "Fest", ",", "in", "durch\u00b7ge\u00b7scherz\u00b7ten", "N\u00e4ch\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dem Komus bald, und bald dem Amor glich?", "tokens": ["Dem", "Ko\u00b7mus", "bald", ",", "und", "bald", "dem", "A\u00b7mor", "glich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KON", "ADV", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Erm\u00fcdet wirft er sich auf einen Rasen nieder,", "tokens": ["Er\u00b7m\u00fc\u00b7det", "wirft", "er", "sich", "auf", "ei\u00b7nen", "Ra\u00b7sen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sieht unger\u00fchrt die reizende Natur", "tokens": ["Sieht", "un\u00b7ge\u00b7r\u00fchrt", "die", "rei\u00b7zen\u00b7de", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So sch\u00f6n in ihrer Einfalt! h\u00f6rt die Lieder", "tokens": ["So", "sch\u00f6n", "in", "ih\u00b7rer", "Ein\u00b7falt", "!", "h\u00f6rt", "die", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$.", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Nachtigall, doch mit den Ohren nur.", "tokens": ["Der", "Nach\u00b7ti\u00b7gall", ",", "doch", "mit", "den", "Oh\u00b7ren", "nur", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ihr z\u00e4rtlicher Gesang sagt seinem Herzen nichts;", "tokens": ["Ihr", "z\u00e4rt\u00b7li\u00b7cher", "Ge\u00b7sang", "sagt", "sei\u00b7nem", "Her\u00b7zen", "nichts", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn ihn beraubt des Grams umschattendes Gefieder", "tokens": ["Denn", "ihn", "be\u00b7raubt", "des", "Grams", "um\u00b7schat\u00b7ten\u00b7des", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Des innern Ohrs, des geistigen Gesichts.", "tokens": ["Des", "in\u00b7nern", "Ohrs", ",", "des", "geis\u00b7ti\u00b7gen", "Ge\u00b7sichts", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Empfindungslos, wie einer der Medusen", "tokens": ["Emp\u00b7fin\u00b7dungs\u00b7los", ",", "wie", "ei\u00b7ner", "der", "Me\u00b7du\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PWAV", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Erblickt und starrt, erw\u00e4gt er zweifelsvoll", "tokens": ["Er\u00b7blickt", "und", "starrt", ",", "er\u00b7w\u00e4gt", "er", "zwei\u00b7fels\u00b7voll"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "KON", "VVFIN", "$,", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Nicht, wie vordem, wof\u00fcr er seufzen soll,", "tokens": ["Nicht", ",", "wie", "vor\u00b7dem", ",", "wo\u00b7f\u00fcr", "er", "seuf\u00b7zen", "soll", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "ADV", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "F\u00fcr welchen Mund, f\u00fcr welchen sch\u00f6nen Busen,", "tokens": ["F\u00fcr", "wel\u00b7chen", "Mund", ",", "f\u00fcr", "wel\u00b7chen", "sch\u00f6\u00b7nen", "Bu\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "$,", "APPR", "PWAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Nein, Phanias spricht jetzt der Torheit Hohn,", "tokens": ["Nein", ",", "Pha\u00b7ni\u00b7as", "spricht", "jetzt", "der", "Tor\u00b7heit", "Hohn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und ruft, seitdem aus seinem hohlen Beutel", "tokens": ["Und", "ruft", ",", "seit\u00b7dem", "aus", "sei\u00b7nem", "hoh\u00b7len", "Beu\u00b7tel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die letzte Drachme flog, wie K\u00f6nig Salomon:", "tokens": ["Die", "letz\u00b7te", "Drach\u00b7me", "flog", ",", "wie", "K\u00f6\u00b7nig", "Sa\u00b7lo\u00b7mon", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Was unterm Monde liegt, ist eitel!", "tokens": ["Was", "un\u00b7term", "Mon\u00b7de", "liegt", ",", "ist", "ei\u00b7tel", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NE", "VVFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Ja wohl, verg\u00e4nglich ist und fl\u00fcchtiger als Wind", "tokens": ["Ja", "wohl", ",", "ver\u00b7g\u00e4ng\u00b7lich", "ist", "und", "fl\u00fcch\u00b7ti\u00b7ger", "als", "Wind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$,", "ADJD", "VAFIN", "KON", "ADJA", "KOUS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sch\u00f6nen Gunst, die Brudertreu der Zecher;", "tokens": ["Der", "Sch\u00f6\u00b7nen", "Gunst", ",", "die", "Bru\u00b7der\u00b7treu", "der", "Ze\u00b7cher", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So bald nicht mehr der goldne Regen rinnt,", "tokens": ["So", "bald", "nicht", "mehr", "der", "gold\u00b7ne", "Re\u00b7gen", "rinnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ist keine Danae, so bald im trocknen Becher", "tokens": ["Ist", "kei\u00b7ne", "Da\u00b7nae", ",", "so", "bald", "im", "trock\u00b7nen", "Be\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NE", "$,", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Der Wein versiegt, ist kein Patroklus mehr.", "tokens": ["Der", "Wein", "ver\u00b7siegt", ",", "ist", "kein", "Pat\u00b7ro\u00b7klus", "mehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was Fliegen lockt, das lockt auch Freunde her;", "tokens": ["Was", "Flie\u00b7gen", "lockt", ",", "das", "lockt", "auch", "Freun\u00b7de", "her", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$,", "PDS", "VVFIN", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Gold zieht magnetischer, als Sch\u00f6nheit, Witz und Jugend:", "tokens": ["Gold", "zieht", "mag\u00b7ne\u00b7ti\u00b7scher", ",", "als", "Sch\u00f6n\u00b7heit", ",", "Witz", "und", "Ju\u00b7gend", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,", "KOUS", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.8": {"text": "Ist eure Hand, ist eure Tafel leer,", "tokens": ["Ist", "eu\u00b7re", "Hand", ",", "ist", "eu\u00b7re", "Ta\u00b7fel", "leer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "So flieht der N\u00e4scher Schwarm, und Lais spricht von Tugend.", "tokens": ["So", "flieht", "der", "N\u00e4\u00b7scher", "Schwarm", ",", "und", "Lais", "spricht", "von", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "NE", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.31": {"line.1": {"text": "Der gro\u00dfen Wahrheit voll, da\u00df alles eitel sei", "tokens": ["Der", "gro\u00b7\u00dfen", "Wahr\u00b7heit", "voll", ",", "da\u00df", "al\u00b7les", "ei\u00b7tel", "sei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "KOUS", "PIS", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Womit der Mensch in seinen Fr\u00fchlingsjahren,", "tokens": ["Wo\u00b7mit", "der", "Mensch", "in", "sei\u00b7nen", "Fr\u00fch\u00b7lings\u00b7jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Berauscht von s\u00fc\u00dfer Raserei,", "tokens": ["Be\u00b7rauscht", "von", "s\u00fc\u00b7\u00dfer", "Ra\u00b7se\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Leichtsinnig, l\u00fcstern, rasch und unerfahren,", "tokens": ["Leicht\u00b7sin\u00b7nig", ",", "l\u00fcs\u00b7tern", ",", "rasch", "und", "un\u00b7er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "In seinem Paradies von Rosen und Schasmin", "tokens": ["In", "sei\u00b7nem", "Pa\u00b7ra\u00b7dies", "von", "Ro\u00b7sen", "und", "Schas\u00b7min"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Ein kleiner Gott sich d\u00fcnkt, setzt Phanias, der Weise,", "tokens": ["Ein", "klei\u00b7ner", "Gott", "sich", "d\u00fcnkt", ",", "setzt", "Pha\u00b7ni\u00b7as", ",", "der", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "$,", "VVFIN", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie Herkules, sich auf den ", "tokens": ["Wie", "Her\u00b7ku\u00b7les", ",", "sich", "auf", "den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "NE", "$,", "PRF", "APPR", "ART"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "(nur schon zu sp\u00e4t) und sinnt der schweren Reise", "tokens": ["(", "nur", "schon", "zu", "sp\u00e4t", ")", "und", "sinnt", "der", "schwe\u00b7ren", "Rei\u00b7se"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADV", "PTKA", "ADJD", "$(", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Des Lebens nach. Was soll, was kann er tun?", "tokens": ["Des", "Le\u00b7bens", "nach", ".", "Was", "soll", ",", "was", "kann", "er", "tun", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "PWS", "VMFIN", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Es ist so s\u00fc\u00df, auf Flaum und Rosenbl\u00e4ttern", "tokens": ["Es", "ist", "so", "s\u00fc\u00df", ",", "auf", "Flaum", "und", "Ro\u00b7sen\u00b7bl\u00e4t\u00b7tern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Im Arm der Wollust sich verg\u00f6ttern,", "tokens": ["Im", "Arm", "der", "Wol\u00b7lust", "sich", "ver\u00b7g\u00f6t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und nur vom \u00dcberma\u00df der Freuden auszuruhn!", "tokens": ["Und", "nur", "vom", "\u00dc\u00b7berm\u00b7a\u00df", "der", "Freu\u00b7den", "aus\u00b7zu\u00b7ruhn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Es ist so unbequem, den Dornenpfad zu klettern!", "tokens": ["Es", "ist", "so", "un\u00b7be\u00b7quem", ",", "den", "Dor\u00b7nen\u00b7pfad", "zu", "klet\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was t\u00e4tet ihr? \u2013 Hier ist, wie vielen deucht,", "tokens": ["Was", "t\u00e4\u00b7tet", "ihr", "?", "\u2013", "Hier", "ist", ",", "wie", "vie\u00b7len", "deucht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "$(", "ADV", "VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Das W\u00e4hlen schwer: dem Phanias war's leicht.", "tokens": ["Das", "W\u00e4h\u00b7len", "schwer", ":", "dem", "Pha\u00b7ni\u00b7as", "wa\u00b7r's", "leicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Er sieht die sch\u00f6ne Ungetreue,", "tokens": ["Er", "sieht", "die", "sch\u00f6\u00b7ne", "Un\u00b7ge\u00b7treu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.18": {"text": "Zu j\u00fcngern G\u00fcnstlingen aus seinen Armen fliehn;", "tokens": ["Zu", "j\u00fcn\u00b7gern", "G\u00fcnst\u00b7lin\u00b7gen", "aus", "sei\u00b7nen", "Ar\u00b7men", "fliehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Die Scherze mit den Amorinen fliehn", "tokens": ["Die", "Scher\u00b7ze", "mit", "den", "A\u00b7mo\u00b7ri\u00b7nen", "fliehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Der G\u00f6ttin nach, verlassen lachend ihn,", "tokens": ["Der", "G\u00f6t\u00b7tin", "nach", ",", "ver\u00b7las\u00b7sen", "la\u00b7chend", "ihn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "VVFIN", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Und schicken ihm zum Zeitvertreib die ", "tokens": ["Und", "schi\u00b7cken", "ihm", "zum", "Zeit\u00b7ver\u00b7treib", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Hingegen winken ihm aus ihrem Heiligtum", "tokens": ["Hin\u00b7ge\u00b7gen", "win\u00b7ken", "ihm", "aus", "ih\u00b7rem", "Hei\u00b7lig\u00b7tum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.23": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.24": {"text": "Und zeigen ihm den edlen ", "tokens": ["Und", "zei\u00b7gen", "ihm", "den", "ed\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Der neue Herkules schickt seufzend einen Blick", "tokens": ["Der", "neu\u00b7e", "Her\u00b7ku\u00b7les", "schickt", "seuf\u00b7zend", "ei\u00b7nen", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.26": {"text": "Den schon Entflohnen nach, ob sie nicht wiederkehren:", "tokens": ["Den", "schon", "Ent\u00b7floh\u00b7nen", "nach", ",", "ob", "sie", "nicht", "wie\u00b7der\u00b7keh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "PTKVZ", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Sie kehren, leider! nicht zur\u00fcck,", "tokens": ["Sie", "keh\u00b7ren", ",", "lei\u00b7der", "!", "nicht", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "$.", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und nun entschlie\u00dft er sich der Helden Zahl zu mehren!", "tokens": ["Und", "nun", "ent\u00b7schlie\u00dft", "er", "sich", "der", "Hel\u00b7den", "Zahl", "zu", "meh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Der Helden Zahl? \u2013 Hier steht er wieder an;", "tokens": ["Der", "Hel\u00b7den", "Zahl", "?", "\u2013", "Hier", "steht", "er", "wie\u00b7der", "an", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der k\u00fchne Vorsatz bleibt in neuen Zweifeln schweben.", "tokens": ["Der", "k\u00fch\u00b7ne", "Vor\u00b7satz", "bleibt", "in", "neu\u00b7en", "Zwei\u00b7feln", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zwar ist es sch\u00f6n, auf lorbeernvoller Bahn", "tokens": ["Zwar", "ist", "es", "sch\u00f6n", ",", "auf", "lor\u00b7be\u00b7ern\u00b7vol\u00b7ler", "Bahn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Zum Rang der G\u00f6ttlichen die in der Nachwelt leben,", "tokens": ["Zum", "Rang", "der", "G\u00f6tt\u00b7li\u00b7chen", "die", "in", "der", "Nach\u00b7welt", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu einem Platz im Sternenplan", "tokens": ["Zu", "ei\u00b7nem", "Platz", "im", "Ster\u00b7nen\u00b7plan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und im Plutarch, sich zu erheben;", "tokens": ["Und", "im", "Plu\u00b7tarch", ",", "sich", "zu", "er\u00b7he\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sch\u00f6n, sich der tr\u00e4gen Ruh entziehn,", "tokens": ["Sch\u00f6n", ",", "sich", "der", "tr\u00e4\u00b7gen", "Ruh", "ent\u00b7ziehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRF", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.8": {"text": "Gefahren suchen; keine fliehn, Auf edle Abenteuer ziehn,", "tokens": ["Ge\u00b7fah\u00b7ren", "su\u00b7chen", ";", "kei\u00b7ne", "fliehn", ",", "Auf", "ed\u00b7le", "A\u00b7bent\u00b7eu\u00b7er", "ziehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$.", "PIAT", "VVINF", "$,", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.9": {"text": "Und die gerochne Welt mit Riesenblute f\u00e4rben;", "tokens": ["Und", "die", "ge\u00b7roch\u00b7ne", "Welt", "mit", "Rie\u00b7sen\u00b7blu\u00b7te", "f\u00e4r\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sch\u00f6n, ", "tokens": ["Sch\u00f6n", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Ein Dichter, der zwar selbst beim ersten Anla\u00df floh,", "tokens": ["Ein", "Dich\u00b7ter", ",", "der", "zwar", "selbst", "beim", "ers\u00b7ten", "An\u00b7la\u00df", "floh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "S\u00fc\u00df ist's, und ehrenvoll, f\u00fcrs Vaterland zu sterben.", "tokens": ["S\u00fc\u00df", "ist's", ",", "und", "eh\u00b7ren\u00b7voll", ",", "f\u00fcrs", "Va\u00b7ter\u00b7land", "zu", "ster\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "ADJD", "$,", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch auch die Weisheit kann Unsterblichkeit erwerben!", "tokens": ["Doch", "auch", "die", "Weis\u00b7heit", "kann", "U\u00b7nsterb\u00b7lich\u00b7keit", "er\u00b7wer\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Wie pr\u00e4chtig klingt's, den fesselfreien Geist", "tokens": ["Wie", "pr\u00e4ch\u00b7tig", "klingt's", ",", "den", "fes\u00b7sel\u00b7frei\u00b7en", "Geist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Im reinsten Quell des Lichts von seinen Flecken waschen,", "tokens": ["Im", "reins\u00b7ten", "Quell", "des", "Lichts", "von", "sei\u00b7nen", "Fle\u00b7cken", "wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Wahrheit, die sich sonst nie ohne Schleier weist,", "tokens": ["Die", "Wahr\u00b7heit", ",", "die", "sich", "sonst", "nie", "oh\u00b7ne", "Schlei\u00b7er", "weist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "(nie, oder G\u00f6ttern nur) entkleidet \u00fcberraschen;", "tokens": ["(", "nie", ",", "o\u00b7der", "G\u00f6t\u00b7tern", "nur", ")", "ent\u00b7klei\u00b7det", "\u00fc\u00b7berr\u00b7a\u00b7schen", ";"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "KON", "NN", "ADV", "$(", "VVPP", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.18": {"text": "Der Sch\u00f6pfung Grundri\u00df \u00fcbersehn,", "tokens": ["Der", "Sch\u00f6p\u00b7fung", "Grun\u00b7dri\u00df", "\u00fc\u00b7ber\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der Sph\u00e4ren mystischen verworrnen Tanz verstehn,", "tokens": ["Der", "Sph\u00e4\u00b7ren", "mys\u00b7ti\u00b7schen", "ver\u00b7worr\u00b7nen", "Tanz", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Vermutungen auf stolze Schl\u00fcsse h\u00e4ufen,", "tokens": ["Ver\u00b7mu\u00b7tun\u00b7gen", "auf", "stol\u00b7ze", "Schl\u00fcs\u00b7se", "h\u00e4u\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Und bis ins Reich der reinen Geister streifen;", "tokens": ["Und", "bis", "ins", "Reich", "der", "rei\u00b7nen", "Geis\u00b7ter", "strei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Wie glorreich! welche Lust! \u2013 Nennt immer Den begl\u00fcckt", "tokens": ["Wie", "glor\u00b7reich", "!", "wel\u00b7che", "Lust", "!", "\u2013", "Nennt", "im\u00b7mer", "Den", "be\u00b7gl\u00fcckt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$.", "PWAT", "NN", "$.", "$(", "VVFIN", "ADV", "ART", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und frei und gro\u00df, den Mann der nie gezittert,", "tokens": ["Und", "frei", "und", "gro\u00df", ",", "den", "Mann", "der", "nie", "ge\u00b7zit\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "ART", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Den der Trompete Ruf zur wilden Schlacht entz\u00fcckt,", "tokens": ["Den", "der", "Trom\u00b7pe\u00b7te", "Ruf", "zur", "wil\u00b7den", "Schlacht", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.25": {"text": "Der l\u00e4chelnd sieht was Menschen sonst ersch\u00fcttert", "tokens": ["Der", "l\u00e4\u00b7chelnd", "sieht", "was", "Men\u00b7schen", "sonst", "er\u00b7sch\u00fct\u00b7tert"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVFIN", "PIS", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und selbst den Tod, der ihn mit Lorbeern schm\u00fcckt,", "tokens": ["Und", "selbst", "den", "Tod", ",", "der", "ihn", "mit", "Lor\u00b7beern", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Wie eine Braut an seinen Busen dr\u00fcckt:", "tokens": ["Wie", "ei\u00b7ne", "Braut", "an", "sei\u00b7nen", "Bu\u00b7sen", "dr\u00fcckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Viel gr\u00f6\u00dfer, gl\u00fccklicher ist ", "tokens": ["Viel", "gr\u00f6\u00b7\u00dfer", ",", "gl\u00fcck\u00b7li\u00b7cher", "ist"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADJD", "VAFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.29": {"text": "Den, von Minervens Schild bedeckt,", "tokens": ["Den", ",", "von", "Mi\u00b7ner\u00b7vens", "Schild", "be\u00b7deckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "NE", "NN", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.30": {"text": "Kein n\u00e4chtliches Phantom, kein Aberglaube schreckt;", "tokens": ["Kein", "n\u00e4cht\u00b7li\u00b7ches", "Phan\u00b7tom", ",", "kein", "A\u00b7berg\u00b7lau\u00b7be", "schreckt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Den Flammen, die auf Leinwand brennen,", "tokens": ["Den", "Flam\u00b7men", ",", "die", "auf", "Lein\u00b7wand", "bren\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Und Styx und Acheron nicht bl\u00e4sser machen k\u00f6nnen;", "tokens": ["Und", "Styx", "und", "A\u00b7che\u00b7ron", "nicht", "bl\u00e4s\u00b7ser", "ma\u00b7chen", "k\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NN", "PTKNEG", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Der ohne Furcht Kometen brennen sieht,", "tokens": ["Der", "oh\u00b7ne", "Furcht", "Ko\u00b7me\u00b7ten", "bren\u00b7nen", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Die hohen G\u00f6tter nicht mit Taschenspiel bem\u00fcht,", "tokens": ["Die", "ho\u00b7hen", "G\u00f6t\u00b7ter", "nicht", "mit", "Ta\u00b7schen\u00b7spiel", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und, weil kein Wahn die Augen ihm verbindet,", "tokens": ["Und", ",", "weil", "kein", "Wahn", "die", "Au\u00b7gen", "ihm", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIAT", "NN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Stets die Natur sich gleich, stets regelm\u00e4\u00dfig findet.", "tokens": ["Stets", "die", "Na\u00b7tur", "sich", "gleich", ",", "stets", "re\u00b7gel\u00b7m\u00e4\u00b7\u00dfig", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PRF", "ADV", "$,", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "War Philipps Sohn ein Held, der sich der Lust entzog", "tokens": ["War", "Phi\u00b7lipps", "Sohn", "ein", "Held", ",", "der", "sich", "der", "Lust", "ent\u00b7zog"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NE", "NN", "ART", "NN", "$,", "PRELS", "PRF", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In welcher unber\u00fchmt die Ninias zerrannen,", "tokens": ["In", "wel\u00b7cher", "un\u00b7be\u00b7r\u00fchmt", "die", "Ni\u00b7ni\u00b7as", "zer\u00b7ran\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und auf zertr\u00fcmmerten Tyrannen", "tokens": ["Und", "auf", "zer\u00b7tr\u00fcm\u00b7mer\u00b7ten", "Ty\u00b7ran\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Sieg zu Sieg bis an den Indus flog?", "tokens": ["Von", "Sieg", "zu", "Sieg", "bis", "an", "den", "In\u00b7dus", "flog", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "APPR", "APPR", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein w\u00e4lzender Triumph zermalmte tausend St\u00e4dte,", "tokens": ["Sein", "w\u00e4l\u00b7zen\u00b7der", "Tri\u00b7umph", "zer\u00b7malm\u00b7te", "tau\u00b7send", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zertrat die halbe Welt \u2013 warum? la\u00dft's ihn gestehn!", "tokens": ["Zer\u00b7trat", "die", "hal\u00b7be", "Welt", "\u2013", "wa\u00b7rum", "?", "la\u00dft's", "ihn", "ge\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$(", "PWAV", "$.", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u00bbdamit der P\u00f6bel von Athen", "tokens": ["\u00bb", "da\u00b7mit", "der", "P\u00f6\u00b7bel", "von", "A\u00b7then"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PAV", "ART", "NN", "APPR", "NE"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Beim nassen Schmaus von ihm zu reden h\u00e4tte.\u00ab", "tokens": ["Beim", "nas\u00b7sen", "Schmaus", "von", "ihm", "zu", "re\u00b7den", "h\u00e4t\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "VAFIN", "$.", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Um wie viel mehr, als solch ein Weltbezwinger,", "tokens": ["Um", "wie", "viel", "mehr", ",", "als", "solch", "ein", "Welt\u00b7be\u00b7zwin\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "KOKOM", "ADV", "ADV", "$,", "KOUS", "PIAT", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ist ", "tokens": ["Ist"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}, "line.11": {"text": "Als Jupiter, der ", "tokens": ["Als", "Ju\u00b7pi\u00b7ter", ",", "der"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "NN", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Sich k\u00fchn entschlie\u00dft; dem Lust kein Gut, und Pein", "tokens": ["Sich", "k\u00fchn", "ent\u00b7schlie\u00dft", ";", "dem", "Lust", "kein", "Gut", ",", "und", "Pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PRF", "ADJD", "VVFIN", "$.", "ART", "NN", "PIAT", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Kein \u00dcbel ist; zu gro\u00df, sich zu beklagen,", "tokens": ["Kein", "\u00dc\u00b7bel", "ist", ";", "zu", "gro\u00df", ",", "sich", "zu", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$.", "PTKA", "ADJD", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Zu weise, sich zu freun; der jede Leidenschaft", "tokens": ["Zu", "wei\u00b7se", ",", "sich", "zu", "freun", ";", "der", "je\u00b7de", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKA", "ADJD", "$,", "PRF", "PTKZU", "VVINF", "$.", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Als Sieger an der Tugend Wagen", "tokens": ["Als", "Sie\u00b7ger", "an", "der", "Tu\u00b7gend", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Gefesselt hat und im Triumphe f\u00fchrt;", "tokens": ["Ge\u00b7fes\u00b7selt", "hat", "und", "im", "Tri\u00b7um\u00b7phe", "f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KON", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Den alles Gold der Inder nicht verf\u00fchrt;", "tokens": ["Den", "al\u00b7les", "Gold", "der", "In\u00b7der", "nicht", "ver\u00b7f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Den nur sein eigener, kein fremder Beifall r\u00fchrt;", "tokens": ["Den", "nur", "sein", "ei\u00b7ge\u00b7ner", ",", "kein", "frem\u00b7der", "Bei\u00b7fall", "r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "ADJA", "$,", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.19": {"text": "Kurz, der in Phalaris durchgl\u00fchtem Stier verd\u00e4rbe", "tokens": ["Kurz", ",", "der", "in", "Pha\u00b7la\u00b7ris", "durch\u00b7gl\u00fch\u00b7tem", "Stier", "ver\u00b7d\u00e4r\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PRELS", "APPR", "NE", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Eh er in Phrynens Arm \u2013 ein ", "tokens": ["Eh", "er", "in", "Phry\u00b7nens", "Arm", "\u2013", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPR", "NE", "NN", "$(", "ART"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.34": {"line.1": {"text": "In solche schimmernde Betrachtungen vertieft", "tokens": ["In", "sol\u00b7che", "schim\u00b7mern\u00b7de", "Be\u00b7trach\u00b7tun\u00b7gen", "ver\u00b7tieft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lag Phanias, schon mehr als halb entschlossen;", "tokens": ["Lag", "Pha\u00b7ni\u00b7as", ",", "schon", "mehr", "als", "halb", "ent\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ADV", "PIAT", "KOKOM", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als Amor unverhofft die neue Denkart pr\u00fcft,", "tokens": ["Als", "A\u00b7mor", "un\u00b7ver\u00b7hofft", "die", "neu\u00b7e", "Den\u00b7kart", "pr\u00fcft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADJD", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Gram, Philosophie und Not ihm eingegossen.", "tokens": ["Die", "Gram", ",", "Phi\u00b7lo\u00b7so\u00b7phie", "und", "Not", "ihm", "ein\u00b7ge\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er sah, und h\u00e4tte gern den Augen nicht getraut,", "tokens": ["Er", "sah", ",", "und", "h\u00e4t\u00b7te", "gern", "den", "Au\u00b7gen", "nicht", "ge\u00b7traut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VAFIN", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ein Gesicht, wovor ihm billig graut,", "tokens": ["Die", "ein", "Ge\u00b7sicht", ",", "wo\u00b7vor", "ihm", "bil\u00b7lig", "graut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$,", "PWAV", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zu sehn sich nicht erwehren, k\u00f6nnen.", "tokens": ["Zu", "sehn", "sich", "nicht", "er\u00b7weh\u00b7ren", ",", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKZU", "VVINF", "PRF", "PTKNEG", "VVINF", "$,", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die G\u00f6tter werden ihm den Ruhm doch nicht mi\u00dfg\u00f6nnen,", "tokens": ["Die", "G\u00f6t\u00b7ter", "wer\u00b7den", "ihm", "den", "Ruhm", "doch", "nicht", "mi\u00df\u00b7g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Xenokrat zu sein? Was hilft Entschlossenheit?", "tokens": ["Ein", "Xe\u00b7no\u00b7krat", "zu", "sein", "?", "Was", "hilft", "Ent\u00b7schlos\u00b7sen\u00b7heit", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VAINF", "$.", "PWS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Augenblick der uns Minerven weiht", "tokens": ["Im", "Au\u00b7gen\u00b7blick", "der", "uns", "Mi\u00b7ner\u00b7ven", "weiht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "PPER", "NN", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Kommt Cytherea selbst zur ungelegnen Zeit.", "tokens": ["Kommt", "Cy\u00b7the\u00b7rea", "selbst", "zur", "un\u00b7ge\u00b7leg\u00b7nen", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.35": {"line.1": {"text": "Zwar ", "tokens": ["Zwar"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Die Sch\u00f6ne, welche kam, vielleicht sich vor der Wette,", "tokens": ["Die", "Sch\u00f6\u00b7ne", ",", "wel\u00b7che", "kam", ",", "viel\u00b7leicht", "sich", "vor", "der", "Wet\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$,", "ADV", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Pallas einst verlor, gleich wenig sich gescheut.", "tokens": ["Die", "Pal\u00b7las", "einst", "ver\u00b7lor", ",", "gleich", "we\u00b7nig", "sich", "ge\u00b7scheut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "ADV", "PIS", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sch\u00f6n, wenn der Schleier blo\u00df ihr schwarzes Aug entdeckte,", "tokens": ["Sch\u00f6n", ",", "wenn", "der", "Schlei\u00b7er", "blo\u00df", "ihr", "schwar\u00b7zes", "Aug", "ent\u00b7deck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "ART", "NN", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Noch sch\u00f6ner, wenn er nichts versteckte;", "tokens": ["Noch", "sch\u00f6\u00b7ner", ",", "wenn", "er", "nichts", "ver\u00b7steck\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gefallend, wenn sie schwieg, bezaubernd, wenn sie sprach:", "tokens": ["Ge\u00b7fal\u00b7lend", ",", "wenn", "sie", "schwieg", ",", "be\u00b7zau\u00b7bernd", ",", "wenn", "sie", "sprach", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dann h\u00e4tt ihr Witz auch Wangen ohne Rosen", "tokens": ["Dann", "h\u00e4tt", "ihr", "Witz", "auch", "Wan\u00b7gen", "oh\u00b7ne", "Ro\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Beliebt gemacht; ein Witz, dem's nie an Reiz gebrach,", "tokens": ["Be\u00b7liebt", "ge\u00b7macht", ";", "ein", "Witz", ",", "dem's", "nie", "an", "Reiz", "ge\u00b7brach", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$.", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zu stechen oder liebzukosen", "tokens": ["Zu", "ste\u00b7chen", "o\u00b7der", "lieb\u00b7zu\u00b7ko\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Gleich aufgelegt, doch l\u00e4chelnd wenn er stach", "tokens": ["Gleich", "auf\u00b7ge\u00b7legt", ",", "doch", "l\u00e4\u00b7chelnd", "wenn", "er", "stach"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "$,", "ADV", "ADJD", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und ohne Gift. Nie sahe man die Musen", "tokens": ["Und", "oh\u00b7ne", "Gift", ".", "Nie", "sa\u00b7he", "man", "die", "Mu\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "$.", "ADV", "VVFIN", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und Grazien in einem sch\u00f6nern Bund,", "tokens": ["Und", "Gra\u00b7zi\u00b7en", "in", "ei\u00b7nem", "sch\u00f6\u00b7nern", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Nie scherzte die Vernunft aus einem sch\u00f6nern Mund;", "tokens": ["Nie", "scherz\u00b7te", "die", "Ver\u00b7nunft", "aus", "ei\u00b7nem", "sch\u00f6\u00b7nern", "Mund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und Amor nie um einen sch\u00f6nern Busen.", "tokens": ["Und", "A\u00b7mor", "nie", "um", "ei\u00b7nen", "sch\u00f6\u00b7nern", "Bu\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "So war, die ihm erschien, so war Musarion.", "tokens": ["So", "war", ",", "die", "ihm", "er\u00b7schien", ",", "so", "war", "Mu\u00b7sa\u00b7ri\u00b7on", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sagt, Freunde, wenn mit einer solchen Miene", "tokens": ["Sagt", ",", "Freun\u00b7de", ",", "wenn", "mit", "ei\u00b7ner", "sol\u00b7chen", "Mie\u00b7ne"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "KOUS", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Im wildsten Hain ein M\u00e4dchen euch erschiene,", "tokens": ["Im", "wilds\u00b7ten", "Hain", "ein", "M\u00e4d\u00b7chen", "euch", "er\u00b7schie\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "PPER", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Hand aufs Herz! sagt, liefet ihr davon?", "tokens": ["Die", "Hand", "aufs", "Herz", "!", "sagt", ",", "lie\u00b7fet", "ihr", "da\u00b7von", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "VVFIN", "$,", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbso lief denn Phanias?\u00ab \u2013 Das konntet ihr erraten!", "tokens": ["\u00bb", "so", "lief", "denn", "Pha\u00b7ni\u00b7as", "?", "\u00ab", "\u2013", "Das", "konn\u00b7tet", "ihr", "er\u00b7ra\u00b7ten", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "KON", "NE", "$.", "$(", "$(", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er tat was Wenige in seinem Falle ", "tokens": ["Er", "tat", "was", "We\u00b7ni\u00b7ge", "in", "sei\u00b7nem", "Fal\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PWS", "PIS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Allein, was jeder ", "tokens": ["Al\u00b7lein", ",", "was", "je\u00b7der"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADV", "$,", "PRELS", "PIS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Er sprang vom Boden auf, und \u2013 hielt ein wenig still,", "tokens": ["Er", "sprang", "vom", "Bo\u00b7den", "auf", ",", "und", "\u2013", "hielt", "ein", "we\u00b7nig", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "KON", "$(", "VVFIN", "ART", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Um recht gewi\u00df zu sehn was ihm sein Auge sagte;", "tokens": ["Um", "recht", "ge\u00b7wi\u00df", "zu", "sehn", "was", "ihm", "sein", "Au\u00b7ge", "sag\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "PTKZU", "VVINF", "PWS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und da er sah, es sei Musarion,", "tokens": ["Und", "da", "er", "sah", ",", "es", "sei", "Mu\u00b7sa\u00b7ri\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "So lief er euch \u2013 der weise Mann! \u2013 davon", "tokens": ["So", "lief", "er", "euch", "\u2013", "der", "wei\u00b7se", "Mann", "!", "\u2013", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$(", "ART", "ADJA", "NN", "$.", "$(", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Als ob ein Arimasp ihn jagte.", "tokens": ["Als", "ob", "ein", "A\u00b7ri\u00b7masp", "ihn", "jag\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "\u00bbdu fliehest, Phanias?\u00ab ruft sie ihm lachend nach:", "tokens": ["\u00bb", "du", "flie\u00b7hest", ",", "Pha\u00b7ni\u00b7as", "?", "\u00ab", "ruft", "sie", "ihm", "la\u00b7chend", "nach", ":"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "NE", "$.", "$(", "VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "\u00bberkennest mich und fliehst? Gut, fliehe nur, du Spr\u00f6der!", "tokens": ["\u00bb", "er\u00b7ken\u00b7nest", "mich", "und", "fliehst", "?", "Gut", ",", "flie\u00b7he", "nur", ",", "du", "Spr\u00f6\u00b7der", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "KON", "VVFIN", "$.", "ADJD", "$,", "VVFIN", "ADV", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Kaltsinn macht Musarion nicht bl\u00f6der;", "tokens": ["Dein", "Kal\u00b7tsinn", "macht", "Mu\u00b7sa\u00b7ri\u00b7on", "nicht", "bl\u00f6\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du schmeichelst dir doch wohl, sie sei so schwach", "tokens": ["Du", "schmei\u00b7chelst", "dir", "doch", "wohl", ",", "sie", "sei", "so", "schwach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,", "PPER", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dir nachzufliehn?\u00ab \u2013 Durch ungebahnte Pfade", "tokens": ["Dir", "nach\u00b7zu\u00b7fliehn", "?", "\u00ab", "\u2013", "Durch", "un\u00b7ge\u00b7bahn\u00b7te", "Pfa\u00b7de"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVINF", "$.", "$(", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wand er wie eine Schlange sich:", "tokens": ["Wand", "er", "wie", "ei\u00b7ne", "Schlan\u00b7ge", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ART", "NN", "PRF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "So schl\u00fcpft die keusche Oreade", "tokens": ["So", "schl\u00fcpft", "die", "keu\u00b7sche", "O\u00b7rea\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Dem Satyr aus der Hand, der sie im Bad erschlich.", "tokens": ["Dem", "Sa\u00b7tyr", "aus", "der", "Hand", ",", "der", "sie", "im", "Bad", "er\u00b7schlich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Sch\u00f6ne folgt mit leichten Zephyrf\u00fc\u00dfen,", "tokens": ["Die", "Sch\u00f6\u00b7ne", "folgt", "mit", "leich\u00b7ten", "Ze\u00b7phyr\u00b7f\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Doch ohne Hast; denn (dachte sie) am Strand", "tokens": ["Doch", "oh\u00b7ne", "Hast", ";", "denn", "(", "dach\u00b7te", "sie", ")", "am", "Strand"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "NN", "$.", "KON", "$(", "VVFIN", "PPER", "$(", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wohin er flieht, wird er wohl halten m\u00fcssen.", "tokens": ["Wo\u00b7hin", "er", "flieht", ",", "wird", "er", "wohl", "hal\u00b7ten", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Es war ihr Gl\u00fcck, da\u00df sich kein Nachen fand;", "tokens": ["Es", "war", "ihr", "Gl\u00fcck", ",", "da\u00df", "sich", "kein", "Na\u00b7chen", "fand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "KOUS", "PRF", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Denn, der Versuchung zu entgehen,", "tokens": ["Denn", ",", "der", "Ver\u00b7su\u00b7chung", "zu", "ent\u00b7ge\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.14": {"text": "Was t\u00e4t ein Weiser nicht, Doch da er keinen fand,", "tokens": ["Was", "t\u00e4t", "ein", "Wei\u00b7ser", "nicht", ",", "Doch", "da", "er", "kei\u00b7nen", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KON", "KOUS", "PPER", "PIAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wohin entfliehn? \u2013 Es ist um ihn geschehen", "tokens": ["Wo\u00b7hin", "ent\u00b7fliehn", "?", "\u2013", "Es", "ist", "um", "ihn", "ge\u00b7sche\u00b7hen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVINF", "$.", "$(", "PPER", "VAFIN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Wenn ihn sein Kopf verl\u00e4\u00dft! \u2013 Seid unbesorgt! er blieb", "tokens": ["Wenn", "ihn", "sein", "Kopf", "ver\u00b7l\u00e4\u00dft", "!", "\u2013", "Seid", "un\u00b7be\u00b7sorgt", "!", "er", "blieb"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$.", "$(", "VAIMP", "ADJD", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Am Ufer ganz gelassen stehen,", "tokens": ["Am", "U\u00b7fer", "ganz", "ge\u00b7las\u00b7sen", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Sah vor sich hin, schwang seinen Stab, beschrieb", "tokens": ["Sah", "vor", "sich", "hin", ",", "schwang", "sei\u00b7nen", "Stab", ",", "be\u00b7schrieb"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "PRF", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Figuren in den Sand, als ob er \u00fcberd\u00e4chte", "tokens": ["Fi\u00b7gu\u00b7ren", "in", "den", "Sand", ",", "als", "ob", "er", "\u00fc\u00b7berd\u00b7\u00e4ch\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "KOKOM", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wie viele K\u00f6rner wohl der Erdball fassen m\u00f6chte;", "tokens": ["Wie", "vie\u00b7le", "K\u00f6r\u00b7ner", "wohl", "der", "Erd\u00b7ball", "fas\u00b7sen", "m\u00f6ch\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Kurz, tat als s\u00e4h er nichts, und wandte sich nicht um.", "tokens": ["Kurz", ",", "tat", "als", "s\u00e4h", "er", "nichts", ",", "und", "wand\u00b7te", "sich", "nicht", "um", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "KOKOM", "VVFIN", "PPER", "PIS", "$,", "KON", "VVFIN", "PRF", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "\u00bbvortrefflich!\u00ab rief sie aus, \u00bbdas nenn ich Heldentum", "tokens": ["\u00bb", "vor\u00b7treff\u00b7lich", "!", "\u00ab", "rief", "sie", "aus", ",", "\u00bb", "das", "nenn", "ich", "Hel\u00b7den\u00b7tum"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "$.", "$(", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "PDS", "VVFIN", "PPER", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und etwas mehr! Die alte Ordnung wollte,", "tokens": ["Und", "et\u00b7was", "mehr", "!", "Die", "al\u00b7te", "Ord\u00b7nung", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$.", "ART", "ADJA", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df Daphne j\u00fcngferlich mit kurzen Schritten fliehn,", "tokens": ["Da\u00df", "Daph\u00b7ne", "j\u00fcng\u00b7fer\u00b7lich", "mit", "kur\u00b7zen", "Schrit\u00b7ten", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Apollo keuchend folgen sollte;", "tokens": ["A\u00b7pol\u00b7lo", "keu\u00b7chend", "fol\u00b7gen", "soll\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du kehrst es um. \u2013 Fliehst du, mich nachzuziehn?", "tokens": ["Du", "kehrst", "es", "um", ".", "\u2013", "Fliehst", "du", ",", "mich", "nach\u00b7zu\u00b7ziehn", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "VVFIN", "PPER", "$,", "PPER", "VVINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Den kleinen Stolz will ich dir gerne g\u00f6nnen!\u00ab", "tokens": ["Den", "klei\u00b7nen", "Stolz", "will", "ich", "dir", "ger\u00b7ne", "g\u00f6n\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "\u00bbdu irrest dich\u00ab, antwortet unser Held", "tokens": ["\u00bb", "du", "ir\u00b7rest", "dich", "\u00ab", ",", "ant\u00b7wor\u00b7tet", "un\u00b7ser", "Held"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$(", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Mienen, welche nicht, wie sehr sie ihm mi\u00dff\u00e4llt,", "tokens": ["Mit", "Mie\u00b7nen", ",", "wel\u00b7che", "nicht", ",", "wie", "sehr", "sie", "ihm", "mi\u00df\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verbergen wollen oder k\u00f6nnen:", "tokens": ["Ver\u00b7ber\u00b7gen", "wol\u00b7len", "o\u00b7der", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbein rascher meilenbreiter Spalt,", "tokens": ["\u00bb", "ein", "ra\u00b7scher", "mei\u00b7len\u00b7brei\u00b7ter", "Spalt", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der pl\u00f6tzlich zwischen uns den Boden g\u00e4hnen machte,", "tokens": ["Der", "pl\u00f6tz\u00b7lich", "zwi\u00b7schen", "uns", "den", "Bo\u00b7den", "g\u00e4h\u00b7nen", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPER", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist alles, glaube mir, wornach ich sehnlich schmachte,", "tokens": ["Ist", "al\u00b7les", ",", "glau\u00b7be", "mir", ",", "wor\u00b7nach", "ich", "sehn\u00b7lich", "schmach\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "VVFIN", "PPER", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Seitdem ich dich erblickt\u00ab. \u2013 \u00bbDer Gru\u00df ist etwas kalt\u00ab,", "tokens": ["Seit\u00b7dem", "ich", "dich", "er\u00b7blickt", "\u00ab", ".", "\u2013", "\u00bb", "Der", "Gru\u00df", "ist", "et\u00b7was", "kalt", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "PPER", "PRF", "VVPP", "$(", "$.", "$(", "$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$(", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Erwidert sie: \u00bbdu denkest, wie ich sehe,", "tokens": ["Er\u00b7wi\u00b7dert", "sie", ":", "\u00bb", "du", "den\u00b7kest", ",", "wie", "ich", "se\u00b7he", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die Reihe sei nunmehr an dir,", "tokens": ["Die", "Rei\u00b7he", "sei", "nun\u00b7mehr", "an", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und weichst zur\u00fcck so wie ich vorw\u00e4rts gehe.", "tokens": ["Und", "weichst", "zu\u00b7r\u00fcck", "so", "wie", "ich", "vor\u00b7w\u00e4rts", "ge\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "KOKOM", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Doch spiele nicht den Grausamen mit mir!", "tokens": ["Doch", "spie\u00b7le", "nicht", "den", "Grau\u00b7sa\u00b7men", "mit", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Was willst du mehr, als da\u00df ich dir gestehe,", "tokens": ["Was", "willst", "du", "mehr", ",", "als", "da\u00df", "ich", "dir", "ge\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "$,", "KOKOM", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Du z\u00fcrnst mit Recht? Ja, ich mi\u00dfkannte dich:", "tokens": ["Du", "z\u00fcrnst", "mit", "Recht", "?", "Ja", ",", "ich", "mi\u00df\u00b7kann\u00b7te", "dich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$.", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Doch, war ich damals mein? Jetzt bin ich, was du mich,", "tokens": ["Doch", ",", "war", "ich", "da\u00b7mals", "mein", "?", "Jetzt", "bin", "ich", ",", "was", "du", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "PPER", "ADV", "PPOSAT", "$.", "ADV", "VAFIN", "PPER", "$,", "PWS", "PPER", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zu sein, so oft zu meinen F\u00fc\u00dfen batest.\u00ab", "tokens": ["Zu", "sein", ",", "so", "oft", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", "ba\u00b7test", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VAINF", "$,", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "\u00bbwie, (unterbrach er sie) du, die mit kaltem Blut", "tokens": ["\u00bb", "wie", ",", "(", "un\u00b7ter\u00b7brach", "er", "sie", ")", "du", ",", "die", "mit", "kal\u00b7tem", "Blut"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "$,", "$(", "VVFIN", "PPER", "PPER", "$(", "PPER", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein z\u00e4rtlich Herz mit F\u00fc\u00dfen tratest.", "tokens": ["Mein", "z\u00e4rt\u00b7lich", "Herz", "mit", "F\u00fc\u00b7\u00dfen", "tra\u00b7test", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mich l\u00e4chelnd leiden sahst \u2013 du hast den \u00dcbermut", "tokens": ["Mich", "l\u00e4\u00b7chelnd", "lei\u00b7den", "sahst", "\u2013", "du", "hast", "den", "\u00dc\u00b7ber\u00b7mut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "VVINF", "VVFIN", "$(", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und suchst mich auf, mich noch durch Spott zu qu\u00e4len?", "tokens": ["Und", "suchst", "mich", "auf", ",", "mich", "noch", "durch", "Spott", "zu", "qu\u00e4\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zwei Jahre liebt ich dich, Undankbare, so sch\u00f6n,", "tokens": ["Zwei", "Jah\u00b7re", "liebt", "ich", "dich", ",", "Un\u00b7dank\u00b7ba\u00b7re", ",", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "PRF", "$,", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wie keine Sterbliche sich je geliebt gesehn.", "tokens": ["Wie", "kei\u00b7ne", "Sterb\u00b7li\u00b7che", "sich", "je", "ge\u00b7liebt", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PRF", "ADV", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein Blick, dein Atem schien allein mich zu beseelen.", "tokens": ["Dein", "Blick", ",", "dein", "A\u00b7tem", "schien", "al\u00b7lein", "mich", "zu", "be\u00b7see\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Tor, der ich war! von einem Blick entz\u00fcckt", "tokens": ["Tor", ",", "der", "ich", "war", "!", "von", "ei\u00b7nem", "Blick", "ent\u00b7z\u00fcckt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PPER", "VAFIN", "$.", "APPR", "ART", "NN", "VVPP"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Der sich an mir f\u00fcr Nebenbuhler \u00fcbte;", "tokens": ["Der", "sich", "an", "mir", "f\u00fcr", "Ne\u00b7ben\u00b7buh\u00b7ler", "\u00fcb\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Durch falsche Hoffnungen ber\u00fcckt,", "tokens": ["Durch", "fal\u00b7sche", "Hoff\u00b7nun\u00b7gen", "be\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Womit mein krankes Herz get\u00e4uscht zu werden liebte!", "tokens": ["Wo\u00b7mit", "mein", "kran\u00b7kes", "Herz", "ge\u00b7t\u00e4uscht", "zu", "wer\u00b7den", "lieb\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "VVPP", "PTKZU", "VAINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Du botst verf\u00fchrerisch das s\u00fc\u00dfe Gift mir dar,", "tokens": ["Du", "botst", "ver\u00b7f\u00fch\u00b7re\u00b7risch", "das", "s\u00fc\u00b7\u00dfe", "Gift", "mir", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und machtest dann mit einem andern wahr", "tokens": ["Und", "mach\u00b7test", "dann", "mit", "ei\u00b7nem", "an\u00b7dern", "wahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "ADJA", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Was dein Sirenenmund mir zugel\u00e4chelt hatte.", "tokens": ["Was", "dein", "Si\u00b7re\u00b7nen\u00b7mund", "mir", "zu\u00b7ge\u00b7l\u00e4\u00b7chelt", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und, o! mit wem? \u2013 Dies brachte mich zur Wut!", "tokens": ["Und", ",", "o", "!", "mit", "wem", "?", "\u2013", "Dies", "brach\u00b7te", "mich", "zur", "Wut", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "$.", "APPR", "PWS", "$.", "$(", "PDS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "(nur der Gedank emp\u00f6rt noch itzt mein Blut)", "tokens": ["(", "nur", "der", "Ge\u00b7dank", "em\u00b7p\u00f6rt", "noch", "itzt", "mein", "Blut", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.17": {"text": "Ein Knabe war's, \u2013 err\u00f6te nicht, gestatte", "tokens": ["Ein", "Kna\u00b7be", "wa\u00b7r's", ",", "\u2013", "er\u00b7r\u00f6\u00b7te", "nicht", ",", "ge\u00b7stat\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "$(", "VVFIN", "PTKNEG", "$,", "ADJA"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Da\u00df ich ihn malen darf, \u2013 gelblockig, zephyrlich,", "tokens": ["Da\u00df", "ich", "ihn", "ma\u00b7len", "darf", ",", "\u2013", "gel\u00b7blo\u00b7ckig", ",", "ze\u00b7phyr\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VMFIN", "$,", "$(", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-++-+-", "measure": "unknown.measure.hexa"}, "line.19": {"text": "Ein bunter Schmetterling, so glatt wie eine Schlange,", "tokens": ["Ein", "bun\u00b7ter", "Schmet\u00b7ter\u00b7ling", ",", "so", "glatt", "wie", "ei\u00b7ne", "Schlan\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mit G\u00e4nseflaum ums Kinn, mit rotgeschminkter Wange,", "tokens": ["Mit", "G\u00e4n\u00b7se\u00b7flaum", "ums", "Kinn", ",", "mit", "rot\u00b7ge\u00b7schmink\u00b7ter", "Wan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein Ding, das einer Puppe glich,", "tokens": ["Ein", "Ding", ",", "das", "ei\u00b7ner", "Pup\u00b7pe", "glich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wie kleine T\u00f6chterchen mit sich zu Bette nehmen:", "tokens": ["Wie", "klei\u00b7ne", "T\u00f6ch\u00b7ter\u00b7chen", "mit", "sich", "zu", "Bet\u00b7te", "neh\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPR", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Dem gabst du, ohne dich zu sch\u00e4men,", "tokens": ["Dem", "gabst", "du", ",", "oh\u00b7ne", "dich", "zu", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Den Busen preis, um den der Hirt von Ilion", "tokens": ["Den", "Bu\u00b7sen", "preis", ",", "um", "den", "der", "Hirt", "von", "I\u00b7li\u00b7on"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KOUI", "ART", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Helenen untreu worden w\u00e4re;", "tokens": ["He\u00b7le\u00b7nen", "un\u00b7treu", "wor\u00b7den", "w\u00e4\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Dies \u00c4ffchen machte den Adon", "tokens": ["Dies", "\u00c4ff\u00b7chen", "mach\u00b7te", "den", "A\u00b7don"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Der Nebenbuhlerin der G\u00f6ttin von Cythere.", "tokens": ["Der", "Ne\u00b7ben\u00b7buh\u00b7le\u00b7rin", "der", "G\u00f6t\u00b7tin", "von", "Cy\u00b7the\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Und Phanias, indes so ein Insekt", "tokens": ["Und", "Pha\u00b7ni\u00b7as", ",", "in\u00b7des", "so", "ein", "In\u00b7sekt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "$,", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Auf deinen Rosen kriecht, liegt N\u00e4chte durch gestreckt,", "tokens": ["Auf", "dei\u00b7nen", "Ro\u00b7sen", "kriecht", ",", "liegt", "N\u00e4ch\u00b7te", "durch", "ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Mit Tr\u00e4nen, die den Mai von seinen Wangen \u00e4tzen,", "tokens": ["Mit", "Tr\u00e4\u00b7nen", ",", "die", "den", "Mai", "von", "sei\u00b7nen", "Wan\u00b7gen", "\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die Schwelle deiner T\u00fcr, Undankbare, zu netzen!", "tokens": ["Die", "Schwel\u00b7le", "dei\u00b7ner", "T\u00fcr", ",", "Un\u00b7dank\u00b7ba\u00b7re", ",", "zu", "net\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Nein! Der vers\u00f6hnt sich nie, der so beleidigt ward!", "tokens": ["Nein", "!", "Der", "ver\u00b7s\u00f6hnt", "sich", "nie", ",", "der", "so", "be\u00b7lei\u00b7digt", "ward", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "VVFIN", "PRF", "ADV", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Hinweg! die Luft, in der du Atem ziehest,", "tokens": ["Hin\u00b7weg", "!", "die", "Luft", ",", "in", "der", "du", "A\u00b7tem", "zie\u00b7hest", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Ist Pest f\u00fcr mich \u2013 Verla\u00df mich! du bem\u00fchest", "tokens": ["Ist", "Pest", "f\u00fcr", "mich", "\u2013", "Ver\u00b7la\u00df", "mich", "!", "du", "be\u00b7m\u00fc\u00b7hest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "NN", "APPR", "PPER", "$(", "VVIMP", "PPER", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Dich fruchtlos! \u2013 unsre Denkungsart", "tokens": ["Dich", "frucht\u00b7los", "!", "\u2013", "uns\u00b7re", "Den\u00b7kungs\u00b7art"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["PPER", "ADJD", "$.", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Stimmt minder \u00fcberein als ehmals unsre Herzen\u00ab.", "tokens": ["Stimmt", "min\u00b7der", "\u00fc\u00b7be\u00b7re\u00b7in", "als", "eh\u00b7mals", "uns\u00b7re", "Her\u00b7zen", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KOKOM", "ADV", "PPOSAT", "NN", "$(", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.41": {"line.1": {"text": "\u00bbmich deucht (erwidert sie) du r\u00e4chest dich zu hart", "tokens": ["\u00bb", "mich", "deucht", "(", "er\u00b7wi\u00b7dert", "sie", ")", "du", "r\u00e4\u00b7chest", "dich", "zu", "hart"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$(", "VVFIN", "PPER", "$(", "PPER", "VVFIN", "PPER", "PTKA", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr selbst gemachte Liebesschmerzen.", "tokens": ["F\u00fcr", "selbst", "ge\u00b7mach\u00b7te", "Lie\u00b7bes\u00b7schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sei wahr, und sprich, ist's stets in unserer Gewalt", "tokens": ["Sei", "wahr", ",", "und", "sprich", ",", "ist's", "stets", "in", "un\u00b7se\u00b7rer", "Ge\u00b7walt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "$,", "KON", "ADJD", "$,", "VAFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu lieben ", "tokens": ["Zu", "lie\u00b7ben"], "token_info": ["word", "word"], "pos": ["PTKZU", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Oft fragt der Liebesgott uns nur nicht ob wir ", "tokens": ["Oft", "fragt", "der", "Lie\u00b7bes\u00b7gott", "uns", "nur", "nicht", "ob", "wir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "PTKNEG", "KOUS", "PPER"], "meter": "-+-+----+-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Wir finden ohne Grund uns z\u00e4rtlich oder kalt,", "tokens": ["Wir", "fin\u00b7den", "oh\u00b7ne", "Grund", "uns", "z\u00e4rt\u00b7lich", "o\u00b7der", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Itzt dem Apollo spr\u00f6d, itzt schwach f\u00fcr einen Faunen.", "tokens": ["Itzt", "dem", "A\u00b7pol\u00b7lo", "spr\u00f6d", ",", "itzt", "schwach", "f\u00fcr", "ei\u00b7nen", "Fau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "VVFIN", "$,", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was wei\u00df ich's selbst? wer z\u00e4hlet Amors Launen?", "tokens": ["Was", "wei\u00df", "ich's", "selbst", "?", "wer", "z\u00e4h\u00b7let", "A\u00b7mors", "Lau\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "$.", "PWS", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ihr, die ihr \u00fcber uns so bitter euch beschwert,", "tokens": ["Ihr", ",", "die", "ihr", "\u00fc\u00b7ber", "uns", "so", "bit\u00b7ter", "euch", "be\u00b7schwert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "APPR", "PPER", "ADV", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "La\u00dft euer eignes Herz f\u00fcr unsers Antwort geben!", "tokens": ["La\u00dft", "eu\u00b7er", "eig\u00b7nes", "Herz", "f\u00fcr", "un\u00b7sers", "Ant\u00b7wort", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ihr bleibt oft an der Stange kleben,", "tokens": ["Ihr", "bleibt", "oft", "an", "der", "Stan\u00b7ge", "kle\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und was euch angelockt war kaum der M\u00fche wert.", "tokens": ["Und", "was", "euch", "an\u00b7ge\u00b7lockt", "war", "kaum", "der", "M\u00fc\u00b7he", "wert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein Halstuch \u00f6ffnet sich, ein \u00c4rmel f\u00e4llt zur\u00fccke,", "tokens": ["Ein", "Hal\u00b7stuch", "\u00f6ff\u00b7net", "sich", ",", "ein", "\u00c4r\u00b7mel", "f\u00e4llt", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und weg ist euer Herz! Oft braucht es nicht so viel;", "tokens": ["Und", "weg", "ist", "eu\u00b7er", "Herz", "!", "Oft", "braucht", "es", "nicht", "so", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ein L\u00e4cheln f\u00e4ngt euch schon, ihr fallt von einem Blicke.", "tokens": ["Ein", "L\u00e4\u00b7cheln", "f\u00e4ngt", "euch", "schon", ",", "ihr", "fallt", "von", "ei\u00b7nem", "Bli\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein fl\u00fcchtiger Geschmack, ein Nichts, ein eitles Spiel", "tokens": ["Ein", "fl\u00fcch\u00b7ti\u00b7ger", "Ge\u00b7schmack", ",", "ein", "Nichts", ",", "ein", "eit\u00b7les", "Spiel"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "PIS", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Phantasie, regiert uns oft im W\u00e4hlen;", "tokens": ["Der", "Phan\u00b7ta\u00b7sie", ",", "re\u00b7giert", "uns", "oft", "im", "W\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Das Sch\u00f6ne selbst verliert auf kurze Zeit", "tokens": ["Das", "Sch\u00f6\u00b7ne", "selbst", "ver\u00b7liert", "auf", "kur\u00b7ze", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Den Reiz f\u00fcr uns; wir wissen da\u00df wir fehlen,", "tokens": ["Den", "Reiz", "f\u00fcr", "uns", ";", "wir", "wis\u00b7sen", "da\u00df", "wir", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$.", "PPER", "VVFIN", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Und finden Grazien bis in der H\u00e4\u00dflichkeit.", "tokens": ["Und", "fin\u00b7den", "Gra\u00b7zi\u00b7en", "bis", "in", "der", "H\u00e4\u00df\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Hat die Erfahrung, wie ich glaube,", "tokens": ["Hat", "die", "Er\u00b7fah\u00b7rung", ",", "wie", "ich", "glau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Von dieser Wahrheit dich belehrt,", "tokens": ["Von", "die\u00b7ser", "Wahr\u00b7heit", "dich", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "So ist mein Irrtum auch vielleicht verzeihenswert.", "tokens": ["So", "ist", "mein", "Irr\u00b7tum", "auch", "viel\u00b7leicht", "ver\u00b7zei\u00b7hens\u00b7wert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Wer suchet unter einer Haube", "tokens": ["Wer", "su\u00b7chet", "un\u00b7ter", "ei\u00b7ner", "Hau\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "So viel Vernunft als Zenons Bart verhei\u00dft?", "tokens": ["So", "viel", "Ver\u00b7nunft", "als", "Ze\u00b7nons", "Bart", "ver\u00b7hei\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KOKOM", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Und wie? mein Freund, wenn ich sogar zu sagen", "tokens": ["Und", "wie", "?", "mein", "Freund", ",", "wenn", "ich", "so\u00b7gar", "zu", "sa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "$.", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Mich untersteh, da\u00df wirklich mein Betragen", "tokens": ["Mich", "un\u00b7ter\u00b7steh", ",", "da\u00df", "wirk\u00b7lich", "mein", "Be\u00b7tra\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Ich sch\u00e4tzt an dir, wof\u00fcr dich jeder preist,", "tokens": ["Ich", "sch\u00e4tzt", "an", "dir", ",", "wo\u00b7f\u00fcr", "dich", "je\u00b7der", "preist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PWAV", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Ein edles Herz und einen sch\u00f6nen Geist:", "tokens": ["Ein", "ed\u00b7les", "Herz", "und", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Geist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Was ich f\u00fcr dich empfand war auf Verdienst gegr\u00fcndet;", "tokens": ["Was", "ich", "f\u00fcr", "dich", "emp\u00b7fand", "war", "auf", "Ver\u00b7dienst", "ge\u00b7gr\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "VVFIN", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Du warst mein ", "tokens": ["Du", "warst", "mein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.32": {"text": "Vergn\u00fcgt mit einem Band das nur die Seelen bindet,", "tokens": ["Ver\u00b7gn\u00fcgt", "mit", "ei\u00b7nem", "Band", "das", "nur", "die", "See\u00b7len", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Sahst du mich Tage lang, und fandest gar nicht schwer", "tokens": ["Sahst", "du", "mich", "Ta\u00b7ge", "lang", ",", "und", "fan\u00b7dest", "gar", "nicht", "schwer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "NN", "ADJD", "$,", "KON", "VVFIN", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mich, wenn der Abendstern dir winkte, zu verlassen,", "tokens": ["Mich", ",", "wenn", "der", "A\u00b7bends\u00b7tern", "dir", "wink\u00b7te", ",", "zu", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "Um an Glycerens T\u00fcr die halbe Nacht zu passen.", "tokens": ["Um", "an", "Gly\u00b7ce\u00b7rens", "T\u00fcr", "die", "hal\u00b7be", "Nacht", "zu", "pas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "NN", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "So ging es gut, bis dich ein Ungef\u00e4hr", "tokens": ["So", "ging", "es", "gut", ",", "bis", "dich", "ein", "Un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "An einem Sommertag in eine Laube f\u00fchrte,", "tokens": ["An", "ei\u00b7nem", "Som\u00b7mer\u00b7tag", "in", "ei\u00b7ne", "Lau\u00b7be", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Worin die ", "tokens": ["Wo\u00b7rin", "die"], "token_info": ["word", "word"], "pos": ["PWAV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.39": {"text": "So ruhig lie\u00df. Ich wei\u00df nicht was dich r\u00fchrte;", "tokens": ["So", "ru\u00b7hig", "lie\u00df", ".", "Ich", "wei\u00df", "nicht", "was", "dich", "r\u00fchr\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Der Schlaf nach einem Bad, wenn man allein sich meint,", "tokens": ["Der", "Schlaf", "nach", "ei\u00b7nem", "Bad", ",", "wenn", "man", "al\u00b7lein", "sich", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NE", "$,", "KOUS", "PIS", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Mu\u00df was versch\u00f6nerndes in euern Augen haben:", "tokens": ["Mu\u00df", "was", "ver\u00b7sch\u00f6\u00b7nern\u00b7des", "in", "eu\u00b7ern", "Au\u00b7gen", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADJA", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Genug, du fandst an ", "tokens": ["Ge\u00b7nug", ",", "du", "fandst", "an"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PTKVZ"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.43": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.44": {"text": "Nichts ahnend wacht ich auf; da lag zu meinen F\u00fc\u00dfen", "tokens": ["Nichts", "ah\u00b7nend", "wacht", "ich", "auf", ";", "da", "lag", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADJD", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Ein Mittelding von Faun und Liebesgott!", "tokens": ["Ein", "Mit\u00b7tel\u00b7ding", "von", "Faun", "und", "Lie\u00b7bes\u00b7gott", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "In dithyrambische Begeistrung hingerissen", "tokens": ["In", "dit\u00b7hy\u00b7ram\u00b7bi\u00b7sche", "Be\u00b7geis\u00b7trung", "hin\u00b7ge\u00b7ris\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Was sagtest du mir nicht! was h\u00e4ttst du wagen m\u00fcssen,", "tokens": ["Was", "sag\u00b7test", "du", "mir", "nicht", "!", "was", "h\u00e4ttst", "du", "wa\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "PTKNEG", "$.", "PWS", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "H\u00e4tt ich, der Schw\u00e4rmerei die Lippen zu verschlie\u00dfen,", "tokens": ["H\u00e4tt", "ich", ",", "der", "Schw\u00e4r\u00b7me\u00b7rei", "die", "Lip\u00b7pen", "zu", "ver\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Das Mittel nicht gekannt! Ein Strom von kaltem Spott", "tokens": ["Das", "Mit\u00b7tel", "nicht", "ge\u00b7kannt", "!", "Ein", "Strom", "von", "kal\u00b7tem", "Spott"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$.", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Nahm deinem Brand die Luft. Mit triefendem Gefieder", "tokens": ["Nahm", "dei\u00b7nem", "Brand", "die", "Luft", ".", "Mit", "trie\u00b7fen\u00b7dem", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ART", "NN", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Flog Amor z\u00fcrnend fort: doch freut ich mich zu fr\u00fch;", "tokens": ["Flog", "A\u00b7mor", "z\u00fcr\u00b7nend", "fort", ":", "doch", "freut", "ich", "mich", "zu", "fr\u00fch", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PRF", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Denn eh ich mir's versah, so kam er seufzend wieder.", "tokens": ["Denn", "eh", "ich", "mir's", "ver\u00b7sah", ",", "so", "kam", "er", "seuf\u00b7zend", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NE", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Mit Seufzen, ich gesteh's, erobert man mich nie;", "tokens": ["Mit", "Seuf\u00b7zen", ",", "ich", "ge\u00b7steh's", ",", "er\u00b7o\u00b7bert", "man", "mich", "nie", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PPER", "NE", "$,", "VVFIN", "PIS", "PRF", "ADV", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.54": {"text": "Der feierliche Schwung erhitzter Phantasie", "tokens": ["Der", "fei\u00b7er\u00b7li\u00b7che", "Schwung", "er\u00b7hitz\u00b7ter", "Phan\u00b7ta\u00b7sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Schl\u00e4gt mir die Lebensgeister nieder.", "tokens": ["Schl\u00e4gt", "mir", "die", "Le\u00b7bens\u00b7geis\u00b7ter", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Ich machte den Versuch, durch Fr\u00f6hlichkeit und Scherz", "tokens": ["Ich", "mach\u00b7te", "den", "Ver\u00b7such", ",", "durch", "Fr\u00f6h\u00b7lich\u00b7keit", "und", "Scherz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Den D\u00e4mon, der dich plagte, zu verjagen;", "tokens": ["Den", "D\u00e4\u00b7mon", ",", "der", "dich", "plag\u00b7te", ",", "zu", "ver\u00b7ja\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.58": {"text": "Doch diese Geisterart kann keinen Scherz ertragen.", "tokens": ["Doch", "die\u00b7se", "Geis\u00b7ter\u00b7art", "kann", "kei\u00b7nen", "Scherz", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Ich \u00e4nderte die Kur. Allein mein eignes Herz", "tokens": ["Ich", "\u00e4n\u00b7der\u00b7te", "die", "Kur", ".", "Al\u00b7lein", "mein", "eig\u00b7nes", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Kam in Gefahr dabei; es wurde mir verd\u00e4chtig;", "tokens": ["Kam", "in", "Ge\u00b7fahr", "da\u00b7bei", ";", "es", "wur\u00b7de", "mir", "ver\u00b7d\u00e4ch\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "PAV", "$.", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Denn Schw\u00e4rmerei steckt wie der Schnupfen an:", "tokens": ["Denn", "Schw\u00e4r\u00b7me\u00b7rei", "steckt", "wie", "der", "Schnup\u00b7fen", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.62": {"text": "Man f\u00fchlt ich wei\u00df nicht was, und eh man wehren kann", "tokens": ["Man", "f\u00fchlt", "ich", "wei\u00df", "nicht", "was", ",", "und", "eh", "man", "weh\u00b7ren", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "VVFIN", "PTKNEG", "PIS", "$,", "KON", "KOUS", "PIS", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Ist unser Kopf des Herzens nicht mehr m\u00e4chtig.", "tokens": ["Ist", "un\u00b7ser", "Kopf", "des", "Her\u00b7zens", "nicht", "mehr", "m\u00e4ch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ART", "NN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.64": {"text": "Auf meine Sicherheit bedacht", "tokens": ["Auf", "mei\u00b7ne", "Si\u00b7cher\u00b7heit", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Fand ich zuletzt ich m\u00fcsse mich zerstreuen.", "tokens": ["Fand", "ich", "zu\u00b7letzt", "ich", "m\u00fcs\u00b7se", "mich", "zer\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Mir schien ein Geck dazu ganz eigentlich gemacht.", "tokens": ["Mir", "schien", "ein", "Geck", "da\u00b7zu", "ganz", "ei\u00b7gent\u00b7lich", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PAV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "F\u00fcr Sch\u00f6nen, die den Zwang der ernsten Liebe scheuen,", "tokens": ["F\u00fcr", "Sch\u00f6\u00b7nen", ",", "die", "den", "Zwang", "der", "erns\u00b7ten", "Lie\u00b7be", "scheu\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Taugt eine Puppe nur, die trillert, h\u00fcpft und lacht;", "tokens": ["Taugt", "ei\u00b7ne", "Pup\u00b7pe", "nur", ",", "die", "tril\u00b7lert", ",", "h\u00fcpft", "und", "lacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "$,", "PRELS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ein bunter Tor, der t\u00e4ndelnd uns umflattert,", "tokens": ["Ein", "bun\u00b7ter", "Tor", ",", "der", "t\u00e4n\u00b7delnd", "uns", "um\u00b7flat\u00b7tert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.70": {"text": "Die Z\u00e4hne weist, nie denkt, und ewig schnattert;", "tokens": ["Die", "Z\u00e4h\u00b7ne", "weist", ",", "nie", "denkt", ",", "und", "e\u00b7wig", "schnat\u00b7tert", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.71": {"text": "Der, schw\u00fclstiger je weniger er f\u00fchlt,", "tokens": ["Der", ",", "schw\u00fcls\u00b7ti\u00b7ger", "je", "we\u00b7ni\u00b7ger", "er", "f\u00fchlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.72": {"text": "Von Flammen schwatzt die unser F\u00e4cher k\u00fchlt,", "tokens": ["Von", "Flam\u00b7men", "schwatzt", "die", "un\u00b7ser", "F\u00e4\u00b7cher", "k\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.73": {"text": "Und, unterdes er sich im Spiegel selbst bel\u00e4chelt,", "tokens": ["Und", ",", "un\u00b7ter\u00b7des", "er", "sich", "im", "Spie\u00b7gel", "selbst", "be\u00b7l\u00e4\u00b7chelt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJA", "PPER", "PRF", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Studierte Seufzerchen mit schaler Anmut f\u00e4chelt.\u00ab", "tokens": ["Stu\u00b7dier\u00b7te", "Seuf\u00b7zer\u00b7chen", "mit", "scha\u00b7ler", "An\u00b7mut", "f\u00e4\u00b7chelt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "\u00bbdas alles was du sagst, (fiel unser Timon ein)", "tokens": ["\u00bb", "das", "al\u00b7les", "was", "du", "sagst", ",", "(", "fiel", "un\u00b7ser", "Ti\u00b7mon", "ein", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PIS", "PWS", "PPER", "VVFIN", "$,", "$(", "VVFIN", "PPOSAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll, wie es scheint, ein kleines Beispiel sein,", "tokens": ["Soll", ",", "wie", "es", "scheint", ",", "ein", "klei\u00b7nes", "Bei\u00b7spiel", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kein Handel sei so schlimm, den nicht der Witz verteidigt.", "tokens": ["Kein", "Han\u00b7del", "sei", "so", "schlimm", ",", "den", "nicht", "der", "Witz", "ver\u00b7tei\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "PRELS", "PTKNEG", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur schade, da\u00df die Ausflucht mehr beleidigt", "tokens": ["Nur", "scha\u00b7de", ",", "da\u00df", "die", "Aus\u00b7flucht", "mehr", "be\u00b7lei\u00b7digt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Als was dadurch verbessert werden soll.", "tokens": ["Als", "was", "da\u00b7durch", "ver\u00b7bes\u00b7sert", "wer\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "VVPP", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Doch, la\u00df es sein! mein Torheitsma\u00df ist voll,", "tokens": ["Doch", ",", "la\u00df", "es", "sein", "!", "mein", "Tor\u00b7heits\u00b7ma\u00df", "ist", "voll", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVIMP", "PPER", "VAINF", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wir wollen uns mit Zanken nicht erm\u00fcden.", "tokens": ["Wir", "wol\u00b7len", "uns", "mit", "Zan\u00b7ken", "nicht", "er\u00b7m\u00fc\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich liebte dich; vergib! ich war ein wenig toll:", "tokens": ["Ich", "lieb\u00b7te", "dich", ";", "ver\u00b7gib", "!", "ich", "war", "ein", "we\u00b7nig", "toll", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "VVIMP", "$.", "PPER", "VAFIN", "ART", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dir selbst gefiel ein Geck, und ich \u2013 ich bin zufrieden;", "tokens": ["Dir", "selbst", "ge\u00b7fiel", "ein", "Geck", ",", "und", "ich", "\u2013", "ich", "bin", "zu\u00b7frie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "$,", "KON", "PPER", "$(", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Erfreut sogar. Denn st\u00e4nd es itzt bei mir,", "tokens": ["Er\u00b7freut", "so\u00b7gar", ".", "Denn", "st\u00e4nd", "es", "itzt", "bei", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "KON", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Durch einen Wunsch an seinen Platz zu fliegen,", "tokens": ["Durch", "ei\u00b7nen", "Wunsch", "an", "sei\u00b7nen", "Platz", "zu", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Bathyll zu sein \u2013 um dir im Arm zu liegen:", "tokens": ["Ba\u00b7thyll", "zu", "sein", "\u2013", "um", "dir", "im", "Arm", "zu", "lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKZU", "VAINF", "$(", "APPR", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Bei deiner Augen Macht! \u2013 ich bliebe hier.", "tokens": ["Bei", "dei\u00b7ner", "Au\u00b7gen", "Macht", "!", "\u2013", "ich", "blie\u00b7be", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$.", "$(", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Du h\u00f6rst, ich schmeichle nicht. Genie\u00dft ", "tokens": ["Du", "h\u00f6rst", ",", "ich", "schmeich\u00b7le", "nicht", ".", "Ge\u00b7nie\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Durch falsche Z\u00e4rtlichkeit einander zu betr\u00fcgen:", "tokens": ["Durch", "fal\u00b7sche", "Z\u00e4rt\u00b7lich\u00b7keit", "ein\u00b7an\u00b7der", "zu", "be\u00b7tr\u00fc\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mich f\u00e4ngt kein L\u00e4cheln mehr! \u2013 Ich seh ein Blumenfeld", "tokens": ["Mich", "f\u00e4ngt", "kein", "L\u00e4\u00b7cheln", "mehr", "!", "\u2013", "Ich", "seh", "ein", "Blu\u00b7men\u00b7feld"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADV", "$.", "$(", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Mit mehr Empfindung an als eure sch\u00f6ne Welt:", "tokens": ["Mit", "mehr", "Emp\u00b7fin\u00b7dung", "an", "als", "eu\u00b7re", "sch\u00f6\u00b7ne", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "KOKOM", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und wenn zum zweiten Mal ein Weib von mir erh\u00e4lt,", "tokens": ["Und", "wenn", "zum", "zwei\u00b7ten", "Mal", "ein", "Weib", "von", "mir", "er\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "ADJA", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Durch einen strengen Blick, durch ein gef\u00e4llig Lachen", "tokens": ["Durch", "ei\u00b7nen", "stren\u00b7gen", "Blick", ",", "durch", "ein", "ge\u00b7f\u00e4l\u00b7lig", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mich bald zum Gott und bald zum Wurm zu machen,", "tokens": ["Mich", "bald", "zum", "Gott", "und", "bald", "zum", "Wurm", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "KON", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Wenn ich, so klein zu sein, noch einmal f\u00e4hig bin:", "tokens": ["Wenn", "ich", ",", "so", "klein", "zu", "sein", ",", "noch", "ein\u00b7mal", "f\u00e4\u00b7hig", "bin", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADJD", "PTKZU", "VAINF", "$,", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Dann, holde Venus, dann verwirre meinen Sinn,", "tokens": ["Dann", ",", "hol\u00b7de", "Ve\u00b7nus", ",", "dann", "ver\u00b7wir\u00b7re", "mei\u00b7nen", "Sinn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Verdamme mich zur l\u00e4cherlichsten Flamme,", "tokens": ["Ver\u00b7dam\u00b7me", "mich", "zur", "l\u00e4\u00b7cher\u00b7lichs\u00b7ten", "Flam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Und mache mich \u2013 verliebt in meine Amme.\u00ab", "tokens": ["Und", "ma\u00b7che", "mich", "\u2013", "ver\u00b7liebt", "in", "mei\u00b7ne", "Am\u00b7me", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "VVPP", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "\u00bbwie lange denkst du so?\u00ab versetzt Musarion:", "tokens": ["\u00bb", "wie", "lan\u00b7ge", "denkst", "du", "so", "?", "\u00ab", "ver\u00b7setzt", "Mu\u00b7sa\u00b7ri\u00b7on", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADV", "VVFIN", "PPER", "ADV", "$.", "$(", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbder Abstich ist zu stark, den dieser neue Ton", "tokens": ["\u00bb", "der", "Ab\u00b7stich", "ist", "zu", "stark", ",", "den", "die\u00b7ser", "neu\u00b7e", "Ton"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "PRELS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit deinem ersten macht! Doch, lieber Freund, erlaube,", "tokens": ["Mit", "dei\u00b7nem", "ers\u00b7ten", "macht", "!", "Doch", ",", "lie\u00b7ber", "Freund", ",", "er\u00b7lau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVFIN", "$.", "KON", "$,", "ADV", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich fordre mehr Beweis eh ich ein Wunder glaube.", "tokens": ["Ich", "ford\u00b7re", "mehr", "Be\u00b7weis", "eh", "ich", "ein", "Wun\u00b7der", "glau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du, welcher ohne Lieb und Scherz", "tokens": ["Du", ",", "wel\u00b7cher", "oh\u00b7ne", "Lieb", "und", "Scherz"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor kurzem noch kein gl\u00fccklich Leben kannte;", "tokens": ["Vor", "kur\u00b7zem", "noch", "kein", "gl\u00fcck\u00b7lich", "Le\u00b7ben", "kann\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADV", "PIAT", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Du, dessen leicht ger\u00fchrtes Herz", "tokens": ["Du", ",", "des\u00b7sen", "leicht", "ge\u00b7r\u00fchr\u00b7tes", "Herz"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von jedem sch\u00f6nen Blick entbrannte,", "tokens": ["Von", "je\u00b7dem", "sch\u00f6\u00b7nen", "Blick", "ent\u00b7brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und der, (err\u00f6te nicht, der Irrtum war nicht gro\u00df)", "tokens": ["Und", "der", ",", "(", "er\u00b7r\u00f6\u00b7te", "nicht", ",", "der", "Irr\u00b7tum", "war", "nicht", "gro\u00df", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "$(", "VVFIN", "PTKNEG", "$,", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn ihm Musarion die spr\u00f6de T\u00fcr verschlo\u00df,", "tokens": ["Wenn", "ihm", "Mu\u00b7sa\u00b7ri\u00b7on", "die", "spr\u00f6\u00b7de", "T\u00fcr", "ver\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.11": {"text": "Zu Lindrung seiner Qual \u2013 nach T\u00e4nzerinnen sandte;", "tokens": ["Zu", "Lind\u00b7rung", "sei\u00b7ner", "Qual", "\u2013", "nach", "T\u00e4n\u00b7ze\u00b7rin\u00b7nen", "sand\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$(", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Du, sprichst von kaltem Blut? du, bietest Amorn Trutz?", "tokens": ["Du", ",", "sprichst", "von", "kal\u00b7tem", "Blut", "?", "du", ",", "bie\u00b7test", "A\u00b7morn", "Trutz", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "APPR", "ADJA", "NN", "$.", "PPER", "$,", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Vermutlich hast du dich, noch gl\u00fccklicher zu leben,", "tokens": ["Ver\u00b7mut\u00b7lich", "hast", "du", "dich", ",", "noch", "gl\u00fcck\u00b7li\u00b7cher", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PRF", "$,", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "In einer andern Gottheit Schutz", "tokens": ["In", "ei\u00b7ner", "an\u00b7dern", "Got\u00b7theit", "Schutz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und in die Br\u00fcderschaft der Fr\u00f6hlichen begehen,", "tokens": ["Und", "in", "die", "Br\u00fc\u00b7der\u00b7schaft", "der", "Fr\u00f6h\u00b7li\u00b7chen", "be\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die sich von Leidenschaft und Phantasie befrein,", "tokens": ["Die", "sich", "von", "Lei\u00b7den\u00b7schaft", "und", "Phan\u00b7ta\u00b7sie", "be\u00b7fr\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Um desto ruhiger der Freude sich zu weihn?", "tokens": ["Um", "des\u00b7to", "ru\u00b7hi\u00b7ger", "der", "Freu\u00b7de", "sich", "zu", "weihn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADJD", "ART", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Du fliehst den Zwang von ernsten Liebesh\u00e4ndeln,", "tokens": ["Du", "fliehst", "den", "Zwang", "von", "erns\u00b7ten", "Lie\u00b7bes\u00b7h\u00e4n\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Und findest sicherer, mit Amorn nur zu t\u00e4ndeln;", "tokens": ["Und", "fin\u00b7dest", "si\u00b7che\u00b7rer", ",", "mit", "A\u00b7morn", "nur", "zu", "t\u00e4n\u00b7deln", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "APPR", "NE", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Verm\u00e4hlst die M\u00e4\u00dfigung der Lust,", "tokens": ["Ver\u00b7m\u00e4hlst", "die", "M\u00e4\u00b7\u00dfi\u00b7gung", "der", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Geschmack mit Unbestand, den Ku\u00df mit Nektarz\u00fcgen,", "tokens": ["Ge\u00b7schmack", "mit", "Un\u00b7be\u00b7stand", ",", "den", "Ku\u00df", "mit", "Nek\u00b7tar\u00b7z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Studierst die Kunst dich immer zu vergn\u00fcgen,", "tokens": ["Stu\u00b7dierst", "die", "Kunst", "dich", "im\u00b7mer", "zu", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Genie\u00dfest wenn du kannst, und leidest wenn du mu\u00dft?", "tokens": ["Ge\u00b7nie\u00b7\u00dfest", "wenn", "du", "kannst", ",", "und", "lei\u00b7dest", "wenn", "du", "mu\u00dft", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VMFIN", "$,", "KON", "VVFIN", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ich finde wenigstens in einem solchen Leben", "tokens": ["Ich", "fin\u00b7de", "we\u00b7nigs\u00b7tens", "in", "ei\u00b7nem", "sol\u00b7chen", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Unendlichmal mehr Wahrheit und Vernunft,", "tokens": ["Un\u00b7end\u00b7lich\u00b7mal", "mehr", "Wahr\u00b7heit", "und", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Als von der freudescheuen Zunft", "tokens": ["Als", "von", "der", "freu\u00b7de\u00b7scheu\u00b7en", "Zunft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Geschwollner Stoiker ein Mitglied abzugeben.", "tokens": ["Ge\u00b7schwoll\u00b7ner", "Stoi\u00b7ker", "ein", "Mit\u00b7glied", "ab\u00b7zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Und denkst du so, dann l\u00e4chle sorgenlos", "tokens": ["Und", "denkst", "du", "so", ",", "dann", "l\u00e4ch\u00b7le", "sor\u00b7gen\u00b7los"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "ADV", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Zum Tadel von Athen, das deiner \u00c4ndrung spottet.", "tokens": ["Zum", "Ta\u00b7del", "von", "A\u00b7then", ",", "das", "dei\u00b7ner", "\u00c4n\u00b7drung", "spot\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.30": {"text": "Nicht, wo die sch\u00f6ne Welt, aus langer Weile blo\u00df,", "tokens": ["Nicht", ",", "wo", "die", "sch\u00f6\u00b7ne", "Welt", ",", "aus", "lan\u00b7ger", "Wei\u00b7le", "blo\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Zu Freuden sich zusammen rottet", "tokens": ["Zu", "Freu\u00b7den", "sich", "zu\u00b7sam\u00b7men", "rot\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PRF", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "An denen nur der Name fr\u00f6hlich t\u00f6nt,", "tokens": ["An", "de\u00b7nen", "nur", "der", "Na\u00b7me", "fr\u00f6h\u00b7lich", "t\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "Die, stets gehofft, doch niemals kommen wollen,", "tokens": ["Die", ",", "stets", "ge\u00b7hofft", ",", "doch", "nie\u00b7mals", "kom\u00b7men", "wol\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "VVPP", "$,", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Wobei man k\u00fcnstlich lacht und ungezwungen g\u00e4hnt,", "tokens": ["Wo\u00b7bei", "man", "k\u00fcnst\u00b7lich", "lacht", "und", "un\u00b7ge\u00b7zwun\u00b7gen", "g\u00e4hnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "VVFIN", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und mitten im Genu\u00df sich schon nach andern sehnt", "tokens": ["Und", "mit\u00b7ten", "im", "Ge\u00b7nu\u00df", "sich", "schon", "nach", "an\u00b7dern", "sehnt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "PRF", "ADV", "APPR", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Die da und dort uns g\u00e4hnen machen sollen:", "tokens": ["Die", "da", "und", "dort", "uns", "g\u00e4h\u00b7nen", "ma\u00b7chen", "sol\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "KON", "ADV", "PPER", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Nicht im Get\u00fcmmel, nein, im Scho\u00dfe der Natur,", "tokens": ["Nicht", "im", "Ge\u00b7t\u00fcm\u00b7mel", ",", "nein", ",", "im", "Scho\u00b7\u00dfe", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "$,", "PTKANT", "$,", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Am stillen Bach, in unbelauschten Schatten,", "tokens": ["Am", "stil\u00b7len", "Bach", ",", "in", "un\u00b7be\u00b7lauschten", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "Besuchet uns die holde Freude nur,", "tokens": ["Be\u00b7su\u00b7chet", "uns", "die", "hol\u00b7de", "Freu\u00b7de", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Und \u00fcberrascht uns oft auf einer Spur,", "tokens": ["Und", "\u00fc\u00b7berr\u00b7ascht", "uns", "oft", "auf", "ei\u00b7ner", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Wo wir sie nicht vermutet hatten.", "tokens": ["Wo", "wir", "sie", "nicht", "ver\u00b7mu\u00b7tet", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Doch, Phanias, ist's diese Denkungsart,", "tokens": ["Doch", ",", "Pha\u00b7ni\u00b7as", ",", "ist's", "die\u00b7se", "Den\u00b7kungs\u00b7art", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NE", "$,", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Die dich der Stadt entzog, wozu die Au\u00dfenseite", "tokens": ["Die", "dich", "der", "Stadt", "ent\u00b7zog", ",", "wo\u00b7zu", "die", "Au\u00b7\u00dfen\u00b7sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Von einem Diogen? wozu ein wilder Bart?", "tokens": ["Von", "ei\u00b7nem", "Dio\u00b7gen", "?", "wo\u00b7zu", "ein", "wil\u00b7der", "Bart", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.45": {"text": "Mich deucht, ein weiser Mann tr\u00e4gt sich wie andre Leute?\u00ab", "tokens": ["Mich", "deucht", ",", "ein", "wei\u00b7ser", "Mann", "tr\u00e4gt", "sich", "wie", "and\u00b7re", "Leu\u00b7te", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VVFIN", "PRF", "KOKOM", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "\u00bbmein Ansehn, sch\u00f6ne Sp\u00f6tterin,", "tokens": ["\u00bb", "mein", "An\u00b7sehn", ",", "sch\u00f6\u00b7ne", "Sp\u00f6t\u00b7te\u00b7rin", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist wie es sich zu meinem Gl\u00fccke schicket.", "tokens": ["Ist", "wie", "es", "sich", "zu", "mei\u00b7nem", "Gl\u00fc\u00b7cke", "schi\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie? ist dir unbekannt in welcher Lag ich bin?", "tokens": ["Wie", "?", "ist", "dir", "un\u00b7be\u00b7kannt", "in", "wel\u00b7cher", "Lag", "ich", "bin", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "ADJD", "APPR", "PWAT", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df jenes Dach, von faulem Moos gedr\u00fccket,", "tokens": ["Da\u00df", "je\u00b7nes", "Dach", ",", "von", "fau\u00b7lem", "Moos", "ge\u00b7dr\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und so viel Land als jener Zaun umschlie\u00dft,", "tokens": ["Und", "so", "viel", "Land", "als", "je\u00b7ner", "Zaun", "um\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "KOKOM", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der ganze Rest von meinem Erbgut ist?", "tokens": ["Der", "gan\u00b7ze", "Rest", "von", "mei\u00b7nem", "Erb\u00b7gut", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Was jeder wei\u00df kann dir allein unm\u00f6glich", "tokens": ["Was", "je\u00b7der", "wei\u00df", "kann", "dir", "al\u00b7lein", "un\u00b7m\u00f6g\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIS", "VVFIN", "VMFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Verborgen sein: dein Scherz ist unertr\u00e4glich,", "tokens": ["Ver\u00b7bor\u00b7gen", "sein", ":", "dein", "Scherz", "ist", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Musarion, wie deine Gegenwart.", "tokens": ["Mu\u00b7sa\u00b7ri\u00b7on", ",", "wie", "dei\u00b7ne", "Ge\u00b7gen\u00b7wart", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Mit wem sprichst du von einer Denkungsart,", "tokens": ["Mit", "wem", "sprichst", "du", "von", "ei\u00b7ner", "Den\u00b7kungs\u00b7art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Die von den G\u00fcnstlingen des lachenden Geschickes", "tokens": ["Die", "von", "den", "G\u00fcnst\u00b7lin\u00b7gen", "des", "la\u00b7chen\u00b7den", "Ge\u00b7schi\u00b7ckes"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Das Vorrecht ist?\u00ab \u2013 \u00bbFreund, du vergissest dich:", "tokens": ["Das", "Vor\u00b7recht", "ist", "?", "\u00ab", "\u2013", "\u00bb", "Freund", ",", "du", "ver\u00b7gis\u00b7sest", "dich", ":"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "$(", "$(", "$(", "NN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ein Sklave tr\u00e4gt die Farbe seines Gl\u00fcckes,", "tokens": ["Ein", "Skla\u00b7ve", "tr\u00e4gt", "die", "Far\u00b7be", "sei\u00b7nes", "Gl\u00fc\u00b7ckes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Kein edles Herz. Im Schauspiel stimmen sich", "tokens": ["Kein", "ed\u00b7les", "Herz", ".", "Im", "Schau\u00b7spiel", "stim\u00b7men", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$.", "APPRART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die Fl\u00f6ten nach dem Ton des St\u00fcckes:", "tokens": ["Die", "Fl\u00f6\u00b7ten", "nach", "dem", "Ton", "des", "St\u00fc\u00b7ckes", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Allein ein weiser Mann denkt niemals weinerlich.", "tokens": ["Al\u00b7lein", "ein", "wei\u00b7ser", "Mann", "denkt", "nie\u00b7mals", "wei\u00b7ner\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wie, Phanias? Die Farbe deiner Seelen", "tokens": ["Wie", ",", "Pha\u00b7ni\u00b7as", "?", "Die", "Far\u00b7be", "dei\u00b7ner", "See\u00b7len"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "NE", "$.", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Ist nur der Widerschein der Dinge um dich her?", "tokens": ["Ist", "nur", "der", "Wi\u00b7der\u00b7schein", "der", "Din\u00b7ge", "um", "dich", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und dir die Fr\u00f6hlichkeit, des Lebens Reiz, zu stehlen,", "tokens": ["Und", "dir", "die", "Fr\u00f6h\u00b7lich\u00b7keit", ",", "des", "Le\u00b7bens", "Reiz", ",", "zu", "steh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "$,", "ART", "NN", "NN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Bedarf es nur ein widrig Ungef\u00e4hr?", "tokens": ["Be\u00b7darf", "es", "nur", "ein", "wid\u00b7rig", "Un\u00b7ge\u00b7f\u00e4hr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Ich wei\u00df, mein Freund, wohin uns mi\u00dfverstandne G\u00fcte,", "tokens": ["Ich", "wei\u00df", ",", "mein", "Freund", ",", "wo\u00b7hin", "uns", "mi\u00df\u00b7ver\u00b7stand\u00b7ne", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PWAV", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ein Herz, das Freude liebt, die Klugheit leicht vergi\u00dft,", "tokens": ["Ein", "Herz", ",", "das", "Freu\u00b7de", "liebt", ",", "die", "Klug\u00b7heit", "leicht", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und niemand, als sich selbst, zu schaden f\u00e4hig ist,", "tokens": ["Und", "nie\u00b7mand", ",", "als", "sich", "selbst", ",", "zu", "scha\u00b7den", "f\u00e4\u00b7hig", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "KOUS", "PRF", "ADV", "$,", "PTKA", "ADJD", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ich wei\u00df wohin sie bringen k\u00f6nnen.", "tokens": ["Ich", "wei\u00df", "wo\u00b7hin", "sie", "brin\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWAV", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Doch, alles recht gesch\u00e4tzt, gewinnst du mehr dabei", "tokens": ["Doch", ",", "al\u00b7les", "recht", "ge\u00b7sch\u00e4tzt", ",", "ge\u00b7winnst", "du", "mehr", "da\u00b7bei"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "PIS", "ADJD", "VVPP", "$,", "VVFIN", "PPER", "ADV", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Als du verlierst. Was Toren uns mi\u00dfg\u00f6nnen", "tokens": ["Als", "du", "ver\u00b7lierst", ".", "Was", "To\u00b7ren", "uns", "mi\u00df\u00b7g\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "PWS", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Beweist nicht stets wie sehr man gl\u00fccklich sei.", "tokens": ["Be\u00b7weist", "nicht", "stets", "wie", "sehr", "man", "gl\u00fcck\u00b7lich", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "KOKOM", "ADV", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Das wahre Gl\u00fcck, das Eigentum der Weisen,", "tokens": ["Das", "wah\u00b7re", "Gl\u00fcck", ",", "das", "Ei\u00b7gen\u00b7tum", "der", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Steht fest, indes Fortunens Kugel rollt.", "tokens": ["Steht", "fest", ",", "in\u00b7des", "For\u00b7tu\u00b7nens", "Ku\u00b7gel", "rollt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Dem Reichen mu\u00df die Pracht, die ihm der Indus zollt,", "tokens": ["Dem", "Rei\u00b7chen", "mu\u00df", "die", "Pracht", ",", "die", "ihm", "der", "In\u00b7dus", "zollt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Erst, da\u00df er gl\u00fccklich sei, beweisen:", "tokens": ["Erst", ",", "da\u00df", "er", "gl\u00fcck\u00b7lich", "sei", ",", "be\u00b7wei\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Der Weise f\u00fchlt er ", "tokens": ["Der", "Wei\u00b7se", "f\u00fchlt", "er"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-", "measure": "iambic.di"}, "line.33": {"text": "Aus Ton so gut als aus getriebnem Gold.", "tokens": ["Aus", "Ton", "so", "gut", "als", "aus", "ge\u00b7trieb\u00b7nem", "Gold", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADJD", "KOKOM", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Wenn um ihn her die muntern L\u00e4mmer springen,", "tokens": ["Wenn", "um", "ihn", "her", "die", "mun\u00b7tern", "L\u00e4m\u00b7mer", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Indem er sorgenfrei in eignem Schatten sitzt,", "tokens": ["In\u00b7dem", "er", "sor\u00b7gen\u00b7frei", "in", "eig\u00b7nem", "Schat\u00b7ten", "sitzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und Zephyrn, untermischt mit bunten Schmetterlingen,", "tokens": ["Und", "Ze\u00b7phyrn", ",", "un\u00b7ter\u00b7mischt", "mit", "bun\u00b7ten", "Schmet\u00b7ter\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Gem\u00e4hter Wiesen Duft ihm frisch entgegen bringen,", "tokens": ["Ge\u00b7m\u00e4h\u00b7ter", "Wie\u00b7sen", "Duft", "ihm", "frisch", "ent\u00b7ge\u00b7gen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PPER", "ADJD", "PTKVZ", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Die V\u00f6gel um ihn her aus tausend Zweigen singen,", "tokens": ["Die", "V\u00f6\u00b7gel", "um", "ihn", "her", "aus", "tau\u00b7send", "Zwei\u00b7gen", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "ADV", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und alles, was er sieht, zugleich ergetzt und n\u00fctzt:", "tokens": ["Und", "al\u00b7les", ",", "was", "er", "sieht", ",", "zu\u00b7gleich", "er\u00b7getzt", "und", "n\u00fctzt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Wie leicht vergi\u00dft er da, er, der so viel besitzt,", "tokens": ["Wie", "leicht", "ver\u00b7gi\u00dft", "er", "da", ",", "er", ",", "der", "so", "viel", "be\u00b7sitzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ADV", "$,", "PPER", "$,", "PRELS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Da\u00df sich sein Landhaus nicht auf Marmors\u00e4ulen st\u00fctzt,", "tokens": ["Da\u00df", "sich", "sein", "Land\u00b7haus", "nicht", "auf", "Mar\u00b7mor\u00b7s\u00e4u\u00b7len", "st\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Nicht Sklaven ohne Zahl in seinem Vorhof l\u00e4rmen,", "tokens": ["Nicht", "Skla\u00b7ven", "oh\u00b7ne", "Zahl", "in", "sei\u00b7nem", "Vor\u00b7hof", "l\u00e4r\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und Fliegen nur, wenn er zu Tische sitzt,", "tokens": ["Und", "Flie\u00b7gen", "nur", ",", "wenn", "er", "zu", "Ti\u00b7sche", "sitzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.45": {"text": "Kein Schmeichler-Heer belagert seine T\u00fcr,", "tokens": ["Kein", "Schmeich\u00b7ler\u00b7Heer", "be\u00b7la\u00b7gert", "sei\u00b7ne", "T\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Kein Hof umschimmert ihn! \u2013 Er freue sich! daf\u00fcr", "tokens": ["Kein", "Hof", "um\u00b7schim\u00b7mert", "ihn", "!", "\u2013", "Er", "freu\u00b7e", "sich", "!", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "$(", "PPER", "VVFIN", "PRF", "$.", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Besitzt er was das jedem Midas fehlet,", "tokens": ["Be\u00b7sitzt", "er", "was", "das", "je\u00b7dem", "Mi\u00b7das", "feh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.48": {"text": "Was der Monarch mit Gold zu kaufen f\u00e4lschlich meint,", "tokens": ["Was", "der", "Mon\u00b7arch", "mit", "Gold", "zu", "kau\u00b7fen", "f\u00e4lschlich", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "ADJD", "VVFIN", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.49": {"text": "Was, wer es kennt, vor einer Krone w\u00e4hlet,", "tokens": ["Was", ",", "wer", "es", "kennt", ",", "vor", "ei\u00b7ner", "Kro\u00b7ne", "w\u00e4h\u00b7let", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWS", "PPER", "VVFIN", "$,", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Das h\u00f6chste Gut des Lebens, einen Freund.\u00ab", "tokens": ["Das", "h\u00f6chs\u00b7te", "Gut", "des", "Le\u00b7bens", ",", "ei\u00b7nen", "Freund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "\u00bbdu schw\u00e4rmst, Musarion! \u2013 Er, dem das Gl\u00fcck den R\u00fccken", "tokens": ["\u00bb", "du", "schw\u00e4rmst", ",", "Mu\u00b7sa\u00b7ri\u00b7on", "!", "\u2013", "Er", ",", "dem", "das", "Gl\u00fcck", "den", "R\u00fc\u00b7cken"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "NN", "$.", "$(", "PPER", "$,", "PRELS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gewiesen, einen Freund?\u00ab \u2013 \u00bbEin Beispiel siehst du hier\u00ab,", "tokens": ["Ge\u00b7wie\u00b7sen", ",", "ei\u00b7nen", "Freund", "?", "\u00ab", "\u2013", "\u00bb", "Ein", "Bei\u00b7spiel", "siehst", "du", "hier", "\u00ab", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "ART", "NN", "$.", "$(", "$(", "$(", "ART", "NN", "VVFIN", "PPER", "ADV", "$(", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erwidert sie: \u00bbmich, die von freien St\u00fccken", "tokens": ["Er\u00b7wi\u00b7dert", "sie", ":", "\u00bb", "mich", ",", "die", "von", "frei\u00b7en", "St\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "$(", "PPER", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Athen verlie\u00df, dich sucht, und da du mir", "tokens": ["A\u00b7then", "ver\u00b7lie\u00df", ",", "dich", "sucht", ",", "und", "da", "du", "mir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "PPER", "VVFIN", "$,", "KON", "KOUS", "PPER", "PPER"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Entflohest, dir (der m\u00fctterlichen Lehren", "tokens": ["Ent\u00b7flo\u00b7hest", ",", "dir", "(", "der", "m\u00fct\u00b7ter\u00b7li\u00b7chen", "Leh\u00b7ren"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Uneingedenk) so eifrig nachgejagt,", "tokens": ["Un\u00b7ein\u00b7ge\u00b7denk", ")", "so", "eif\u00b7rig", "nach\u00b7ge\u00b7jagt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie andre meiner Art vor dir geflohen w\u00e4ren.", "tokens": ["Wie", "and\u00b7re", "mei\u00b7ner", "Art", "vor", "dir", "ge\u00b7flo\u00b7hen", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ich d\u00e4chte, das beweist, wenn einem Mann zu Ehren", "tokens": ["Ich", "d\u00e4ch\u00b7te", ",", "das", "be\u00b7weist", ",", "wenn", "ei\u00b7nem", "Mann", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PDS", "VVFIN", "$,", "KOUS", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein M\u00e4dchen \u2013 sich \u2013 und seinen Kopfputz wagt!\u00ab", "tokens": ["Ein", "M\u00e4d\u00b7chen", "\u2013", "sich", "\u2013", "und", "sei\u00b7nen", "Kopf\u00b7putz", "wagt", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "PRF", "$(", "KON", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "\u00bbich wei\u00df die Zeit \u2013 ich trug noch deine Kette \u2013", "tokens": ["\u00bb", "ich", "wei\u00df", "die", "Zeit", "\u2013", "ich", "trug", "noch", "dei\u00b7ne", "Ket\u00b7te", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "$(", "PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "(hier seufzte Phanias) da, mich entz\u00fcckt zu sehn,", "tokens": ["(", "hier", "seufz\u00b7te", "Pha\u00b7ni\u00b7as", ")", "da", ",", "mich", "ent\u00b7z\u00fcckt", "zu", "sehn", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "NE", "$(", "ADV", "$,", "PPER", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dich weniger gekostet h\u00e4tte.", "tokens": ["Dich", "we\u00b7ni\u00b7ger", "ge\u00b7kos\u00b7tet", "h\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du durftest, statt mir nachzugehn,", "tokens": ["Du", "durf\u00b7test", ",", "statt", "mir", "nach\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich damals nur nach Art der Nymphen str\u00e4uben,", "tokens": ["Dich", "da\u00b7mals", "nur", "nach", "Art", "der", "Nym\u00b7phen", "str\u00e4u\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die gern an einem Busch im Fliehen hangen bleiben,", "tokens": ["Die", "gern", "an", "ei\u00b7nem", "Busch", "im", "Flie\u00b7hen", "han\u00b7gen", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "APPRART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit leiser Stimme dr\u00e4un und l\u00e4chelnd widerstehn:", "tokens": ["Mit", "lei\u00b7ser", "Stim\u00b7me", "dr\u00e4un", "und", "l\u00e4\u00b7chelnd", "wi\u00b7der\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Allein, wer kann daf\u00fcr, da\u00df ungeneigte Winde", "tokens": ["Al\u00b7lein", ",", "wer", "kann", "da\u00b7f\u00fcr", ",", "da\u00df", "un\u00b7ge\u00b7neig\u00b7te", "Win\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VMFIN", "PAV", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Von unsern W\u00fcnschen stets den besten Teil verwehn?", "tokens": ["Von", "un\u00b7sern", "W\u00fcn\u00b7schen", "stets", "den", "bes\u00b7ten", "Teil", "ver\u00b7wehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dies ist vorbei! Jetzt, wenn es bei mir st\u00fcnde,", "tokens": ["Dies", "ist", "vor\u00b7bei", "!", "Jetzt", ",", "wenn", "es", "bei", "mir", "st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$.", "ADV", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "W\u00fcnscht ich mir nichts als ein gela\u00dfnes Blut.", "tokens": ["W\u00fcnscht", "ich", "mir", "nichts", "als", "ein", "ge\u00b7la\u00df\u00b7nes", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PIS", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Man nennt mich zu Athen ungl\u00fccklich \u2013 doch, ich finde,", "tokens": ["Man", "nennt", "mich", "zu", "A\u00b7then", "un\u00b7gl\u00fcck\u00b7lich", "\u2013", "doch", ",", "ich", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "NE", "ADJD", "$(", "ADV", "$,", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Zu etwas, wie man sagt, ist stets das Ungl\u00fcck gut;", "tokens": ["Zu", "et\u00b7was", ",", "wie", "man", "sagt", ",", "ist", "stets", "das", "Un\u00b7gl\u00fcck", "gut", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWAV", "PIS", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Durch ein bezaubertes Gewinde", "tokens": ["Durch", "ein", "be\u00b7zau\u00b7ber\u00b7tes", "Ge\u00b7win\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Von s\u00fc\u00dfem Irrtum hat zuletzt", "tokens": ["Von", "s\u00fc\u00b7\u00dfem", "Irr\u00b7tum", "hat", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Die Torheit selbst mich auf den Weg gesetzt,", "tokens": ["Die", "Tor\u00b7heit", "selbst", "mich", "auf", "den", "Weg", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Gesegnet seist du mir, Geburtstag meines Gl\u00fccks!", "tokens": ["Ge\u00b7seg\u00b7net", "seist", "du", "mir", ",", "Ge\u00b7burts\u00b7tag", "mei\u00b7nes", "Gl\u00fccks", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PPER", "$,", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Nicht Phanias, der G\u00fcnstling des Geschicks,", "tokens": ["Nicht", "Pha\u00b7ni\u00b7as", ",", "der", "G\u00fcnst\u00b7ling", "des", "Ge\u00b7schicks", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Nein, Phanias, der Nackte, der Verbannte,", "tokens": ["Nein", ",", "Pha\u00b7ni\u00b7as", ",", "der", "Nack\u00b7te", ",", "der", "Ver\u00b7bann\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Ist neidenswert! Da war er wirklich arm,", "tokens": ["Ist", "nei\u00b7dens\u00b7wert", "!", "Da", "war", "er", "wirk\u00b7lich", "arm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Ungl\u00fccklicher als Irus, glich dem Kranken", "tokens": ["Un\u00b7gl\u00fcck\u00b7li\u00b7cher", "als", "I\u00b7rus", ",", "glich", "dem", "Kran\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "NE", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Der sich zu Tode tanzt, als Schmeichler, Schwarm an Schwarm.", "tokens": ["Der", "sich", "zu", "To\u00b7de", "tanzt", ",", "als", "Schmeich\u00b7ler", ",", "Schwarm", "an", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVFIN", "$,", "KOUS", "NN", "$,", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sein Herzensblut aus goldnen Bechern tranken:", "tokens": ["Sein", "Her\u00b7zens\u00b7blut", "aus", "gold\u00b7nen", "Be\u00b7chern", "tran\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Beim n\u00e4chtlichen Gelag, an feiler Phrynen Brust,", "tokens": ["Beim", "n\u00e4cht\u00b7li\u00b7chen", "Ge\u00b7lag", ",", "an", "fei\u00b7ler", "Phry\u00b7nen", "Brust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da war er elend, ", "tokens": ["Da", "war", "er", "e\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.26": {"text": "Von jeder Leidenschaft! ein Opfertier der Lust!", "tokens": ["Von", "je\u00b7der", "Lei\u00b7den\u00b7schaft", "!", "ein", "Op\u00b7fer\u00b7tier", "der", "Lust", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$.", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie? Der, der siebenfach von einer Schlang umwunden", "tokens": ["Wie", "?", "Der", ",", "der", "sie\u00b7ben\u00b7fach", "von", "ei\u00b7ner", "Schlang", "um\u00b7wun\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "ART", "$,", "PRELS", "PRF", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Auf Blumen schl\u00e4ft und tr\u00e4umt er sitz auf einem Thron,", "tokens": ["Auf", "Blu\u00b7men", "schl\u00e4ft", "und", "tr\u00e4umt", "er", "sitz", "auf", "ei\u00b7nem", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der sollte gl\u00fccklich sein? \u2013 Und wenn Endymion,", "tokens": ["Der", "soll\u00b7te", "gl\u00fcck\u00b7lich", "sein", "?", "\u2013", "Und", "wenn", "En\u00b7dy\u00b7mi\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADJD", "VAINF", "$.", "$(", "KON", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "(dem Luna, da\u00df sie ihn bequemer k\u00fcssen m\u00f6ge,", "tokens": ["(", "dem", "Lu\u00b7na", ",", "da\u00df", "sie", "ihn", "be\u00b7que\u00b7mer", "k\u00fcs\u00b7sen", "m\u00f6\u00b7ge", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So sch\u00f6ne Tr\u00e4ume gab) durch eine Million", "tokens": ["So", "sch\u00f6\u00b7ne", "Tr\u00e4u\u00b7me", "gab", ")", "durch", "ei\u00b7ne", "Mil\u00b7li\u00b7on"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Von Sonnenaltern stets in s\u00fc\u00dfen Tr\u00e4umen l\u00e4ge,", "tokens": ["Von", "Son\u00b7nen\u00b7al\u00b7tern", "stets", "in", "s\u00fc\u00b7\u00dfen", "Tr\u00e4u\u00b7men", "l\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und tr\u00e4umt' er schmaus am G\u00f6ttertisch", "tokens": ["Und", "tr\u00e4umt'", "er", "schmaus", "am", "G\u00f6t\u00b7ter\u00b7tisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Mit Jupitern und buhle mit G\u00f6ttinnen,", "tokens": ["Mit", "Ju\u00b7pi\u00b7tern", "und", "buh\u00b7le", "mit", "G\u00f6t\u00b7tin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Ein s\u00fc\u00df bet\u00e4ubendes Gemisch", "tokens": ["Ein", "s\u00fc\u00df", "be\u00b7t\u00e4u\u00b7ben\u00b7des", "Ge\u00b7misch"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Von allem was ergetzt berausche seine Sinnen,", "tokens": ["Von", "al\u00b7lem", "was", "er\u00b7getzt", "be\u00b7rau\u00b7sche", "sei\u00b7ne", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PWS", "VVPP", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Mit Einem Wort, er schwimme wie ein Fisch", "tokens": ["Mit", "Ei\u00b7nem", "Wort", ",", "er", "schwim\u00b7me", "wie", "ein", "Fisch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "In einem Ozean von Wonne \u2013", "tokens": ["In", "ei\u00b7nem", "O\u00b7ze\u00b7an", "von", "Won\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Sprich, wer gest\u00e4nd uns, unerr\u00f6tend, ein,", "tokens": ["Sprich", ",", "wer", "ge\u00b7st\u00e4nd", "uns", ",", "un\u00b7er\u00b7r\u00f6\u00b7tend", ",", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVIMP", "$,", "PWS", "VVFIN", "PPER", "$,", "ADJD", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Er w\u00fcnsche sich Endymion zu sein?", "tokens": ["Er", "w\u00fcn\u00b7sche", "sich", "En\u00b7dy\u00b7mi\u00b7on", "zu", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "NN", "PTKZU", "VAINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.41": {"text": "Diogenes, der Hund, in seiner Tonne", "tokens": ["Dio\u00b7ge\u00b7nes", ",", "der", "Hund", ",", "in", "sei\u00b7ner", "Ton\u00b7ne"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.42": {"text": "War gl\u00fccklicher! \u2013 In unsrer eignen Brust,", "tokens": ["War", "gl\u00fcck\u00b7li\u00b7cher", "!", "\u2013", "In", "uns\u00b7rer", "eig\u00b7nen", "Brust", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$.", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Da, oder nirgends, flie\u00dft die Quelle wahrer Lust,", "tokens": ["Da", ",", "o\u00b7der", "nir\u00b7gends", ",", "flie\u00dft", "die", "Quel\u00b7le", "wah\u00b7rer", "Lust", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KON", "ADV", "$,", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Der Freuden, welche nie versiegen,", "tokens": ["Der", "Freu\u00b7den", ",", "wel\u00b7che", "nie", "ver\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Des Zustands dauernder Vergn\u00fcgen,", "tokens": ["Des", "Zu\u00b7stands", "dau\u00b7ern\u00b7der", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Den nichts von au\u00dfen st\u00f6rt! Wie elend h\u00e4tte mich", "tokens": ["Den", "nichts", "von", "au\u00b7\u00dfen", "st\u00f6rt", "!", "Wie", "e\u00b7lend", "h\u00e4t\u00b7te", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ADV", "VVFIN", "$.", "PWAV", "ADJD", "VAFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Ein Wechsel, der mir alles raubte", "tokens": ["Ein", "Wech\u00b7sel", ",", "der", "mir", "al\u00b7les", "raub\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Wodurch ich mich vor diesem gl\u00fccklich glaubte,", "tokens": ["Wo\u00b7durch", "ich", "mich", "vor", "die\u00b7sem", "gl\u00fcck\u00b7lich", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPR", "PDAT", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.49": {"text": "Fortunens ganzen Kram, \u2013 wie elend h\u00e4tt er mich", "tokens": ["For\u00b7tu\u00b7nens", "gan\u00b7zen", "Kram", ",", "\u2013", "wie", "e\u00b7lend", "h\u00e4tt", "er", "mich"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "$(", "PWAV", "ADJD", "VAFIN", "PPER", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Gemacht, wenn mir aus ihrer lichten Sph\u00e4re", "tokens": ["Ge\u00b7macht", ",", "wenn", "mir", "aus", "ih\u00b7rer", "lich\u00b7ten", "Sph\u00e4\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "Die Weisheit nicht zu H\u00fclf erschienen w\u00e4re,", "tokens": ["Die", "Weis\u00b7heit", "nicht", "zu", "H\u00fclf", "er\u00b7schie\u00b7nen", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Die aus den Wolken mir die Arme reicht, zu sich", "tokens": ["Die", "aus", "den", "Wol\u00b7ken", "mir", "die", "Ar\u00b7me", "reicht", ",", "zu", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "$,", "APPR", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Hinauf mich zieht, und mich dahin versetzet,", "tokens": ["Hin\u00b7auf", "mich", "zieht", ",", "und", "mich", "da\u00b7hin", "ver\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "KON", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.54": {"text": "Wo ihre Lieblinge, frei von Begier und Wahn,", "tokens": ["Wo", "ih\u00b7re", "Lieb\u00b7lin\u00b7ge", ",", "frei", "von", "Be\u00b7gier", "und", "Wahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$,", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.55": {"text": "Von keiner Lust gereizt, von keinem Schmerz verletzet,", "tokens": ["Von", "kei\u00b7ner", "Lust", "ge\u00b7reizt", ",", "von", "kei\u00b7nem", "Schmerz", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "$,", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Sich den Olympiern und ihrer Wonne nahn.\u00ab", "tokens": ["Sich", "den", "O\u00b7lym\u00b7piern", "und", "ih\u00b7rer", "Won\u00b7ne", "nahn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ART", "NN", "KON", "PPOSAT", "NN", "ADJA", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.47": {"line.1": {"text": "Hier ward der hohe Schwung, den Phanias zu nehmen", "tokens": ["Hier", "ward", "der", "ho\u00b7he", "Schwung", ",", "den", "Pha\u00b7ni\u00b7as", "zu", "neh\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Begriffen war, gehemmt. Schon schwanden Raum und Zeit", "tokens": ["Be\u00b7grif\u00b7fen", "war", ",", "ge\u00b7hemmt", ".", "Schon", "schwan\u00b7den", "Raum", "und", "Zeit"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "VVPP", "$.", "ADV", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aus seinem Blick, schon f\u00fchlt' er sich entkleidt", "tokens": ["Aus", "sei\u00b7nem", "Blick", ",", "schon", "f\u00fchlt'", "er", "sich", "ent\u00b7kleidt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PRF", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Vom niederziehenden Gewand der Sterblichkeit,", "tokens": ["Vom", "nie\u00b7der\u00b7zie\u00b7hen\u00b7den", "Ge\u00b7wand", "der", "Sterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schon war er halb ein Gott; \u2013 als eine Kleinigkeit,", "tokens": ["Schon", "war", "er", "halb", "ein", "Gott", ";", "\u2013", "als", "ei\u00b7ne", "Klei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ART", "NN", "$.", "$(", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die wir uns fast zu sagen sch\u00e4men,", "tokens": ["Die", "wir", "uns", "fast", "zu", "sa\u00b7gen", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ihn pl\u00f6tzlich in die Unterwelt", "tokens": ["Ihn", "pl\u00f6tz\u00b7lich", "in", "die", "Un\u00b7ter\u00b7welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zur\u00fcckezog. \u2013 Ihr m\u00e4chtigen Besieger", "tokens": ["Zu\u00b7r\u00fc\u00b7ck\u00b7e\u00b7zog", ".", "\u2013", "Ihr", "m\u00e4ch\u00b7ti\u00b7gen", "Be\u00b7sie\u00b7ger"], "token_info": ["word", "punct", "punct", "word", "word", "word"], "pos": ["NE", "$.", "$(", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der Menschlichkeit, die ihr dem Sternenfeld", "tokens": ["Der", "Menschlich\u00b7keit", ",", "die", "ihr", "dem", "Ster\u00b7nen\u00b7feld"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Euch nahe glaubt \u2013 das Herz ist ein Betr\u00fcger!", "tokens": ["Euch", "na\u00b7he", "glaubt", "\u2013", "das", "Herz", "ist", "ein", "Be\u00b7tr\u00fc\u00b7ger", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$(", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Erkennet euer Bild in Phanias und bebt!", "tokens": ["Er\u00b7ken\u00b7net", "eu\u00b7er", "Bild", "in", "Pha\u00b7ni\u00b7as", "und", "bebt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NE", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Weise, der so k\u00fchn sich zum Olymp erhebt,", "tokens": ["Der", "Wei\u00b7se", ",", "der", "so", "k\u00fchn", "sich", "zum", "O\u00b7lymp", "er\u00b7hebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Der schon so hoch empor gestiegen,", "tokens": ["Der", "schon", "so", "hoch", "em\u00b7por", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Da\u00df er (wie Sancho dort auf Magellonens Pferd)", "tokens": ["Da\u00df", "er", "(", "wie", "San\u00b7cho", "dort", "auf", "Ma\u00b7gel\u00b7lo\u00b7nens", "Pferd", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "KOKOM", "NE", "ADV", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die purpurnen und himmelblauen Ziegen", "tokens": ["Die", "pur\u00b7pur\u00b7nen", "und", "him\u00b7mel\u00b7blau\u00b7en", "Zie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Des Himmels grasen sieht,", "tokens": ["Des", "Him\u00b7mels", "gra\u00b7sen", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Und aus der Glut, die sein Gehirn verzehrt,", "tokens": ["Und", "aus", "der", "Glut", ",", "die", "sein", "Ge\u00b7hirn", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Des Feuerhimmels N\u00e4he schlie\u00dfet,", "tokens": ["Des", "Feu\u00b7er\u00b7him\u00b7mels", "N\u00e4\u00b7he", "schlie\u00b7\u00dfet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Ihn, der nichts Sterblichs mehr mit seinem Blick beehrt,", "tokens": ["Ihn", ",", "der", "nichts", "Sterb\u00b7lichs", "mehr", "mit", "sei\u00b7nem", "Blick", "be\u00b7ehrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PIS", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den stolzen Gast des \u00c4thers, schie\u00dfet", "tokens": ["Den", "stol\u00b7zen", "Gast", "des", "\u00c4\u00b7thers", ",", "schie\u00b7\u00dfet"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Musarion mit einem \u2013 Blick herab.", "tokens": ["Mu\u00b7sa\u00b7ri\u00b7on", "mit", "ei\u00b7nem", "\u2013", "Blick", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "$(", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Doch freilich war's ein Blick, nur jenem zu vergleichen", "tokens": ["Doch", "frei\u00b7lich", "wa\u00b7r's", "ein", "Blick", ",", "nur", "je\u00b7nem", "zu", "ver\u00b7glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "$,", "ADV", "PDAT", "PTKZU", "VVINF"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Den Coypel seinem Amor gab;", "tokens": ["Den", "Coy\u00b7pel", "sei\u00b7nem", "A\u00b7mor", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Der, euer Herz gewisser zu beschleichen,", "tokens": ["Der", ",", "eu\u00b7er", "Herz", "ge\u00b7wis\u00b7ser", "zu", "be\u00b7schlei\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Euch schalkhaft warnt, als spr\u00e4ch er: \u00bbSeht ihr mich?", "tokens": ["Euch", "schalk\u00b7haft", "warnt", ",", "als", "spr\u00e4ch", "er", ":", "\u00bb", "Seht", "ihr", "mich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$,", "KOUS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ihr denkt, ich sei ein Kind voll s\u00fc\u00dfer Unschuld, ich?", "tokens": ["Ihr", "denkt", ",", "ich", "sei", "ein", "Kind", "voll", "s\u00fc\u00b7\u00dfer", "Un\u00b7schuld", ",", "ich", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "ADJD", "ADJA", "NN", "$,", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Verla\u00dft euch drauf! Seht ihr an meiner Seite", "tokens": ["Ver\u00b7la\u00dft", "euch", "drauf", "!", "Seht", "ihr", "an", "mei\u00b7ner", "Sei\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "$.", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Den K\u00f6cher hier? Wenn euch zu raten ist,", "tokens": ["Den", "K\u00f6\u00b7cher", "hier", "?", "Wenn", "euch", "zu", "ra\u00b7ten", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$.", "KOUS", "PPER", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "So flieht! \u2013 Und doch, was hilft die kleine Frist?", "tokens": ["So", "flieht", "!", "\u2013", "Und", "doch", ",", "was", "hilft", "die", "klei\u00b7ne", "Frist", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "$(", "KON", "ADV", "$,", "PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Es sei nun morgen oder heute,", "tokens": ["Es", "sei", "nun", "mor\u00b7gen", "o\u00b7der", "heu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Ihr habt ein Herz, und das ist meine Beute!\u00ab", "tokens": ["Ihr", "habt", "ein", "Herz", ",", "und", "das", "ist", "mei\u00b7ne", "Beu\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KON", "PDS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "So, oder doch in diesem Ton,", "tokens": ["So", ",", "o\u00b7der", "doch", "in", "die\u00b7sem", "Ton", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KON", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So etwas sprach der Blick, womit Musarion", "tokens": ["So", "et\u00b7was", "sprach", "der", "Blick", ",", "wo\u00b7mit", "Mu\u00b7sa\u00b7ri\u00b7on"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den weisen Phanias aus seiner Fassung brachte.", "tokens": ["Den", "wei\u00b7sen", "Pha\u00b7ni\u00b7as", "aus", "sei\u00b7ner", "Fas\u00b7sung", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er sah, er stockt', er schwieg; die alte Flamm erwachte,", "tokens": ["Er", "sah", ",", "er", "stockt'", ",", "er", "schwieg", ";", "die", "al\u00b7te", "Flamm", "er\u00b7wach\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und seine Augen f\u00fcllt' ein unfreiwillig Na\u00df.", "tokens": ["Und", "sei\u00b7ne", "Au\u00b7gen", "f\u00fcllt'", "ein", "un\u00b7frei\u00b7wil\u00b7lig", "Na\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Sch\u00f6ne stellte sich sie sehe nichts, und lachte", "tokens": ["Die", "Sch\u00f6\u00b7ne", "stell\u00b7te", "sich", "sie", "se\u00b7he", "nichts", ",", "und", "lach\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "PPER", "VVFIN", "PIS", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nur innerlich. Drauf sprach sie: \u00bbPhanias,", "tokens": ["Nur", "in\u00b7ner\u00b7lich", ".", "Drauf", "sprach", "sie", ":", "\u00bb", "Pha\u00b7ni\u00b7as", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PAV", "VVFIN", "PPER", "$.", "$(", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Es d\u00e4mmert schon. Ich habe mich zu lange", "tokens": ["Es", "d\u00e4m\u00b7mert", "schon", ".", "Ich", "ha\u00b7be", "mich", "zu", "lan\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Bei dir verweilt. Athen ist weit von hier;", "tokens": ["Bei", "dir", "ver\u00b7weilt", ".", "A\u00b7then", "ist", "weit", "von", "hier", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$.", "NE", "VAFIN", "ADJD", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "In dieser Gegend kenn ich niemand au\u00dfer dir,", "tokens": ["In", "die\u00b7ser", "Ge\u00b7gend", "kenn", "ich", "nie\u00b7mand", "au\u00b7\u00dfer", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "PIS", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und hier im Hain, gesteh ich, w\u00e4re mir", "tokens": ["Und", "hier", "im", "Hain", ",", "ge\u00b7steh", "ich", ",", "w\u00e4\u00b7re", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Die Nacht hindurch vor Ziegenf\u00fc\u00dflern bange.", "tokens": ["Die", "Nacht", "hin\u00b7durch", "vor", "Zie\u00b7gen\u00b7f\u00fc\u00df\u00b7lern", "ban\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Was ist zu tun? \u2013 Ich denk ich folge dir?\u00ab", "tokens": ["Was", "ist", "zu", "tun", "?", "\u2013", "Ich", "denk", "ich", "fol\u00b7ge", "dir", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "PTKZU", "VVINF", "$.", "$(", "PPER", "VVFIN", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "\u00bbmir?\u00ab stottert Phanias: \u00bbgewi\u00df sehr viele Ehre!", "tokens": ["\u00bb", "mir", "?", "\u00ab", "stot\u00b7tert", "Pha\u00b7ni\u00b7as", ":", "\u00bb", "ge\u00b7wi\u00df", "sehr", "vie\u00b7le", "Eh\u00b7re", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$.", "$(", "VVFIN", "NE", "$.", "$(", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Allein, mein Haus ist klein\u00ab \u2013 \u00bbUnd wenn es kleiner w\u00e4re,", "tokens": ["Al\u00b7lein", ",", "mein", "Haus", "ist", "klein", "\u00ab", "\u2013", "\u00bb", "Und", "wenn", "es", "klei\u00b7ner", "w\u00e4\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$(", "$(", "$(", "KON", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr eine Freundin hat die kleinste H\u00fctte Raum.\u00ab \u2013", "tokens": ["F\u00fcr", "ei\u00b7ne", "Freun\u00b7din", "hat", "die", "kleins\u00b7te", "H\u00fct\u00b7te", "Raum", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u00bbdu wirst an allem Mangel haben;", "tokens": ["\u00bb", "du", "wirst", "an", "al\u00b7lem", "Man\u00b7gel", "ha\u00b7ben", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PIS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein wenig Milch, ein Ei, und dieses kaum\u00ab \u2013", "tokens": ["Ein", "we\u00b7nig", "Milch", ",", "ein", "Ei", ",", "und", "die\u00b7ses", "kaum", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PIAT", "NN", "$,", "ART", "NN", "$,", "KON", "PDS", "ADV", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "\u00bbmich hungert nicht.\u00ab \u2013 \u00bbNur einen Hirtenknaben,", "tokens": ["\u00bb", "mich", "hun\u00b7gert", "nicht", ".", "\u00ab", "\u2013", "\u00bb", "Nur", "ei\u00b7nen", "Hir\u00b7ten\u00b7kna\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "$.", "$(", "$(", "$(", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Dich zu bedienen\u00ab \u2013 \u00bbNur? Es ist an Dem zu viel.", "tokens": ["Dich", "zu", "be\u00b7die\u00b7nen", "\u00ab", "\u2013", "\u00bb", "Nur", "?", "Es", "ist", "an", "Dem", "zu", "viel", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$(", "$(", "$(", "ADV", "$.", "PPER", "VAFIN", "APPR", "ART", "PTKA", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wir wollen gehn, mein Freund! die Luft wird k\u00fchl\u00ab \u2013", "tokens": ["Wir", "wol\u00b7len", "gehn", ",", "mein", "Freund", "!", "die", "Luft", "wird", "k\u00fchl", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "PPOSAT", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbvergib, Musarion; ich mu\u00df dir alles sagen:", "tokens": ["\u00bb", "ver\u00b7gib", ",", "Mu\u00b7sa\u00b7ri\u00b7on", ";", "ich", "mu\u00df", "dir", "al\u00b7les", "sa\u00b7gen", ":"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "$,", "NN", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mein H\u00e4uschen ist besetzt; ich habe seit acht Tagen", "tokens": ["Mein", "H\u00e4usc\u00b7hen", "ist", "be\u00b7setzt", ";", "ich", "ha\u00b7be", "seit", "acht", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Zwei Freunde, die bei mir\u00ab \u2013 \u00bbZwei Freunde?\u00ab \u2013 \u00bbJa, und zwar", "tokens": ["Zwei", "Freun\u00b7de", ",", "die", "bei", "mir", "\u00ab", "\u2013", "\u00bb", "Zwei", "Freun\u00b7de", "?", "\u00ab", "\u2013", "\u00bb", "Ja", ",", "und", "zwar"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "$,", "PRELS", "APPR", "PPER", "$(", "$(", "$(", "CARD", "NN", "$.", "$(", "$(", "$(", "PTKANT", "$,", "KON", "ADV"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.12": {"text": "Die, deucht mir, nicht zu deinem Umgang taugen.\u00ab \u2013", "tokens": ["Die", ",", "deucht", "mir", ",", "nicht", "zu", "dei\u00b7nem", "Um\u00b7gang", "tau\u00b7gen", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "$,", "VVFIN", "PPER", "$,", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "\u00bbwas sagst du? \u2013 Philosophen gar?", "tokens": ["\u00bb", "was", "sagst", "du", "?", "\u2013", "Phi\u00b7lo\u00b7so\u00b7phen", "gar", "?"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Sie haben doch noch ihre Augen?", "tokens": ["Sie", "ha\u00b7ben", "doch", "noch", "ih\u00b7re", "Au\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Gut, Phanias, ich will sie kennen, ich\u00ab \u2013", "tokens": ["Gut", ",", "Pha\u00b7ni\u00b7as", ",", "ich", "will", "sie", "ken\u00b7nen", ",", "ich", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJD", "$,", "NE", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,", "PPER", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "\u00bbdu scherzest.\u00ab \u2013 \u00bbNein, mein Herr; ich hatte, wie ihr mich", "tokens": ["\u00bb", "du", "scher\u00b7zest", ".", "\u00ab", "\u2013", "\u00bb", "Nein", ",", "mein", "Herr", ";", "ich", "hat\u00b7te", ",", "wie", "ihr", "mich"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$.", "$(", "$(", "$(", "PTKANT", "$,", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "$,", "PWAV", "PPER", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Hier seht, von ihrer Art wohl eher", "tokens": ["Hier", "seht", ",", "von", "ih\u00b7rer", "Art", "wohl", "e\u00b7her"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Um meinen Nachttisch stehn.\u00ab \u2013 \u00bbVergib, ich zweifle sehr:", "tokens": ["Um", "mei\u00b7nen", "Nacht\u00b7tisch", "stehn", ".", "\u00ab", "\u2013", "\u00bb", "Ver\u00b7gib", ",", "ich", "zweif\u00b7le", "sehr", ":"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF", "$.", "$(", "$(", "$(", "VVIMP", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der stoische Kleanth \u00ab \u2013 \u00bbO Ceres! und wer mehr?\u00ab", "tokens": ["Der", "sto\u00b7i\u00b7sche", "Kle\u00b7an\u00b7th", "\u00ab", "\u2013", "\u00bb", "O", "Ce\u00b7res", "!", "und", "wer", "mehr", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$(", "$(", "NE", "NE", "$.", "KON", "PWS", "ADV", "$.", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "\u00bbtheophron, der Pythagor\u00e4er,", "tokens": ["\u00bb", "theo\u00b7phron", ",", "der", "Py\u00b7tha\u00b7go\u00b7r\u00e4\u00b7er", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.21": {"text": "Sind schwerlich von so bl\u00f6dem Geist\u00ab \u2013", "tokens": ["Sind", "schwer\u00b7lich", "von", "so", "bl\u00f6\u00b7dem", "Geist", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ADV", "ADJA", "NN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "\u00bbo Phanias, ist alles Gold was glei\u00dft?", "tokens": ["\u00bb", "o", "Pha\u00b7ni\u00b7as", ",", "ist", "al\u00b7les", "Gold", "was", "glei\u00dft", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NE", "$,", "VAFIN", "PIAT", "NN", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Allein, gesetzt, sie w\u00e4ren lauter Geist,", "tokens": ["Al\u00b7lein", ",", "ge\u00b7setzt", ",", "sie", "w\u00e4\u00b7ren", "lau\u00b7ter", "Geist", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVPP", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Was hindert dies? Nur desto mehr Vergn\u00fcgen!\u00ab", "tokens": ["Was", "hin\u00b7dert", "dies", "?", "Nur", "des\u00b7to", "mehr", "Ver\u00b7gn\u00fc\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PDS", "$.", "ADV", "ADV", "PIAT", "NN", "$.", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "\u00bbkurz, wir sind drei, Madam, und auf den Mann", "tokens": ["\u00bb", "kurz", ",", "wir", "sind", "drei", ",", "Ma\u00b7dam", ",", "und", "auf", "den", "Mann"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "$,", "PPER", "VAFIN", "CARD", "$,", "NN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ein kleines Ruhebett\u00ab -\u00bb Man hilft sich wie man kann;", "tokens": ["Ein", "klei\u00b7nes", "Ru\u00b7he\u00b7bett", "\u00ab", "\u00bb", "Man", "hilft", "sich", "wie", "man", "kann", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$(", "$(", "PIS", "VVFIN", "PRF", "KOKOM", "PIS", "VMFIN", "$."], "meter": "-+-+-+-+-++-+", "measure": "unknown.measure.septa"}, "line.27": {"text": "Und k\u00f6nnen wir den Schlaf durch Schwatzen nicht betr\u00fcgen?", "tokens": ["Und", "k\u00f6n\u00b7nen", "wir", "den", "Schlaf", "durch", "Schwat\u00b7zen", "nicht", "be\u00b7tr\u00fc\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wir gehn, mein Lieber \u2013 deinen Arm!", "tokens": ["Wir", "gehn", ",", "mein", "Lie\u00b7ber", "\u2013", "dei\u00b7nen", "Arm", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Nun, Phanias? macht dir mein Antrag warm?", "tokens": ["Nun", ",", "Pha\u00b7ni\u00b7as", "?", "macht", "dir", "mein", "An\u00b7trag", "warm", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Man d\u00e4cht es w\u00e4re hier wer wei\u00df wie viel zu wagen.", "tokens": ["Man", "d\u00e4cht", "es", "w\u00e4\u00b7re", "hier", "wer", "wei\u00df", "wie", "viel", "zu", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "VAFIN", "ADV", "PWS", "VVFIN", "KOKOM", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Drei Weise werden mir doch wohl gewachsen sein?", "tokens": ["Drei", "Wei\u00b7se", "wer\u00b7den", "mir", "doch", "wohl", "ge\u00b7wach\u00b7sen", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Ich f\u00fcrchte nichts bei euch, und bin allein.\u00ab", "tokens": ["Ich", "f\u00fcrch\u00b7te", "nichts", "bei", "euch", ",", "und", "bin", "al\u00b7lein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPER", "$,", "KON", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "Was soll er tun? \u2013 Wo Widersterben", "tokens": ["Was", "soll", "er", "tun", "?", "\u2013", "Wo", "Wi\u00b7ders\u00b7ter\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "$(", "PWAV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vorm Untergang das Schiff nicht retten kann,", "tokens": ["Vorm", "Un\u00b7ter\u00b7gang", "das", "Schiff", "nicht", "ret\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da wird ein weiser Steuermann", "tokens": ["Da", "wird", "ein", "wei\u00b7ser", "Steu\u00b7er\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit guter Art sich in den Wind ergehen.", "tokens": ["Mit", "gu\u00b7ter", "Art", "sich", "in", "den", "Wind", "er\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mein Phanias, der nur aus bl\u00f6der Scheu", "tokens": ["Mein", "Pha\u00b7ni\u00b7as", ",", "der", "nur", "aus", "bl\u00f6\u00b7der", "Scheu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Vor seinen Mentorn sich so lange widersetzte,", "tokens": ["Vor", "sei\u00b7nen", "Men\u00b7torn", "sich", "so", "lan\u00b7ge", "wi\u00b7der\u00b7setz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Schwor, da\u00df er seine Einsiedlei", "tokens": ["Schwor", ",", "da\u00df", "er", "sei\u00b7ne", "Ein\u00b7sied\u00b7lei"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dem Musentempel \u00e4hnlich sch\u00e4tzte,", "tokens": ["Dem", "Mu\u00b7sen\u00b7tem\u00b7pel", "\u00e4hn\u00b7lich", "sch\u00e4tz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Weil ihr das Gl\u00fcck beschieden sei,", "tokens": ["Weil", "ihr", "das", "Gl\u00fcck", "be\u00b7schie\u00b7den", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die liebensw\u00fcrdigste der Musen zu beschatten.", "tokens": ["Die", "lie\u00b7bens\u00b7w\u00fcr\u00b7digs\u00b7te", "der", "Mu\u00b7sen", "zu", "be\u00b7schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Schon zeigte sich, da\u00df ihre Reize noch", "tokens": ["Schon", "zeig\u00b7te", "sich", ",", "da\u00df", "ih\u00b7re", "Rei\u00b7ze", "noch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "$,", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Nicht alle Macht auf ihn verloren hatten.", "tokens": ["Nicht", "al\u00b7le", "Macht", "auf", "ihn", "ver\u00b7lo\u00b7ren", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der ausgetriebne Amor kroch,", "tokens": ["Der", "aus\u00b7ge\u00b7trieb\u00b7ne", "A\u00b7mor", "kroch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So leise, wie auf Blumenspitzen,", "tokens": ["So", "lei\u00b7se", ",", "wie", "auf", "Blu\u00b7men\u00b7spit\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Aus ihren Augen in sein Herz.", "tokens": ["Aus", "ih\u00b7ren", "Au\u00b7gen", "in", "sein", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Des Gottes Ankunft k\u00fcndt ein fliegendes Erhitzen", "tokens": ["Des", "Got\u00b7tes", "An\u00b7kunft", "k\u00fcndt", "ein", "flie\u00b7gen\u00b7des", "Er\u00b7hit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der blassen Wang, ein wollustvoller Schmerz", "tokens": ["Der", "blas\u00b7sen", "Wang", ",", "ein", "wol\u00b7lust\u00b7vol\u00b7ler", "Schmerz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Mit Tr\u00e4nen an, die wider seinen Willen", "tokens": ["Mit", "Tr\u00e4\u00b7nen", "an", ",", "die", "wi\u00b7der", "sei\u00b7nen", "Wil\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PTKVZ", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "In runden Tropfen ihm die Augenwinkel f\u00fcllen.", "tokens": ["In", "run\u00b7den", "Trop\u00b7fen", "ihm", "die", "Au\u00b7gen\u00b7win\u00b7kel", "f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Er meint er atme nur, und seufzt; starrt unverwandt", "tokens": ["Er", "meint", "er", "at\u00b7me", "nur", ",", "und", "seufzt", ";", "starrt", "un\u00b7ver\u00b7wandt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ADV", "$,", "KON", "VVFIN", "$.", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "(indes sie schwatzt und scherzt) sie an, als ob er h\u00f6re,", "tokens": ["(", "in\u00b7des", "sie", "schwatzt", "und", "scherzt", ")", "sie", "an", ",", "als", "ob", "er", "h\u00f6\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPER", "VVFIN", "KON", "VVFIN", "$(", "PPER", "PTKVZ", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und h\u00f6rt doch nichts; dr\u00fcckt ihr die runde Hand,", "tokens": ["Und", "h\u00f6rt", "doch", "nichts", ";", "dr\u00fcckt", "ihr", "die", "run\u00b7de", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIS", "$.", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "Und denkt, indem durchs steigende Gewand", "tokens": ["Und", "denkt", ",", "in\u00b7dem", "durchs", "stei\u00b7gen\u00b7de", "Ge\u00b7wand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Die sch\u00f6ne Brust sich bl\u00e4ht, ob diese halbe Sph\u00e4re", "tokens": ["Die", "sch\u00f6\u00b7ne", "Brust", "sich", "bl\u00e4ht", ",", "ob", "die\u00b7se", "hal\u00b7be", "Sph\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "$,", "KOUS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Der Pythagorischen nicht vorzuziehen w\u00e4re?", "tokens": ["Der", "Py\u00b7tha\u00b7go\u00b7ri\u00b7schen", "nicht", "vor\u00b7zu\u00b7zie\u00b7hen", "w\u00e4\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Die Sch\u00f6ne wurde die Gefahr", "tokens": ["Die", "Sch\u00f6\u00b7ne", "wur\u00b7de", "die", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Worin der Ruhm der Stoa schwebte,", "tokens": ["Wo\u00b7rin", "der", "Ruhm", "der", "Stoa", "schweb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Den Kampf in seiner Brust und ihren Sieg gewahr,", "tokens": ["Den", "Kampf", "in", "sei\u00b7ner", "Brust", "und", "ih\u00b7ren", "Sieg", "ge\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie vergebens er der Macht entgegen strebte,", "tokens": ["Und", "wie", "ver\u00b7ge\u00b7bens", "er", "der", "Macht", "ent\u00b7ge\u00b7gen", "streb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PPER", "ART", "NN", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wovon (so lispelt ihr der Liebesgott ins Ohr)", "tokens": ["Wo\u00b7von", "(", "so", "lis\u00b7pelt", "ihr", "der", "Lie\u00b7bes\u00b7gott", "ins", "Ohr", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Philosophen selbst, sie wollten", "tokens": ["Die", "Phi\u00b7lo\u00b7so\u00b7phen", "selbst", ",", "sie", "woll\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "PPER", "VMFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Nun oder wollten nicht, bald Zeugen werden sollten.", "tokens": ["Nun", "o\u00b7der", "woll\u00b7ten", "nicht", ",", "bald", "Zeu\u00b7gen", "wer\u00b7den", "soll\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "VMFIN", "PTKNEG", "$,", "ADV", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie sah, wie nach und nach sein Tr\u00fcbsinn sich verlor,", "tokens": ["Sie", "sah", ",", "wie", "nach", "und", "nach", "sein", "Tr\u00fcb\u00b7sinn", "sich", "ver\u00b7lor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "APPR", "KON", "APPR", "PPOSAT", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und wie beredt, wie stark sein Auge sagte,", "tokens": ["Und", "wie", "be\u00b7redt", ",", "wie", "stark", "sein", "Au\u00b7ge", "sag\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Was er sich selbst kaum zu gestehen wagte:", "tokens": ["Was", "er", "sich", "selbst", "kaum", "zu", "ge\u00b7ste\u00b7hen", "wag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PRF", "ADV", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Allein sie fand f\u00fcr gut, (und tat sehr klug ", "tokens": ["Al\u00b7lein", "sie", "fand", "f\u00fcr", "gut", ",", "(", "und", "tat", "sehr", "klug"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "APPR", "ADJD", "$,", "$(", "KON", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ihm, was sie sah, und ihrer beiden Seelen", "tokens": ["Ihm", ",", "was", "sie", "sah", ",", "und", "ih\u00b7rer", "bei\u00b7den", "See\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Geheime Sympathie zur Zeit noch zu verhehlen.", "tokens": ["Ge\u00b7hei\u00b7me", "Sym\u00b7pa\u00b7thie", "zur", "Zeit", "noch", "zu", "ver\u00b7heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nur sah sie ihn mit solchen Blicken an,", "tokens": ["Nur", "sah", "sie", "ihn", "mit", "sol\u00b7chen", "Bli\u00b7cken", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die er berechtigt war so g\u00fcnstig auszulegen", "tokens": ["Die", "er", "be\u00b7rech\u00b7tigt", "war", "so", "g\u00fcns\u00b7tig", "aus\u00b7zu\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Als ihm gefiel. Allein, macht die Begier verwegen,", "tokens": ["Als", "ihm", "ge\u00b7fiel", ".", "Al\u00b7lein", ",", "macht", "die", "Be\u00b7gier", "ver\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "ADV", "$,", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "So macht die Liebe bl\u00f6d. Er sah in ihrem Blick", "tokens": ["So", "macht", "die", "Lie\u00b7be", "bl\u00f6d", ".", "Er", "sah", "in", "ih\u00b7rem", "Blick"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sonst jeden Reiz, nur nicht sein nahes Gl\u00fcck.", "tokens": ["Sonst", "je\u00b7den", "Reiz", ",", "nur", "nicht", "sein", "na\u00b7hes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "ADV", "PTKNEG", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.52": {"line.1": {"text": "So langten sie, da schon die letzten Strahlen schwanden,", "tokens": ["So", "lang\u00b7ten", "sie", ",", "da", "schon", "die", "letz\u00b7ten", "Strah\u00b7len", "schwan\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bei seinem Landgut an, wo sie das weise Paar,", "tokens": ["Bei", "sei\u00b7nem", "Land\u00b7gut", "an", ",", "wo", "sie", "das", "wei\u00b7se", "Paar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "PWAV", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von Linden die im Vorhof standen", "tokens": ["Von", "Lin\u00b7den", "die", "im", "Vor\u00b7hof", "stan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ART", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Umduftet, unverhofft in einer Stellung fanden,", "tokens": ["Um\u00b7duf\u00b7tet", ",", "un\u00b7ver\u00b7hofft", "in", "ei\u00b7ner", "Stel\u00b7lung", "fan\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die der Philosophie nicht allzu r\u00fchmlich war.", "tokens": ["Die", "der", "Phi\u00b7lo\u00b7so\u00b7phie", "nicht", "all\u00b7zu", "r\u00fchm\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}