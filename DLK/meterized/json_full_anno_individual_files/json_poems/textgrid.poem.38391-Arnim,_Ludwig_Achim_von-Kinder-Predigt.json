{"textgrid.poem.38391": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Kinder-Predigt", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Quibus, quabus,", "tokens": ["Qui\u00b7bus", ",", "qua\u00b7bus", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "FM.la", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Die Enten gehn barfu\u00df,", "tokens": ["Die", "En\u00b7ten", "gehn", "bar\u00b7fu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die G\u00e4ns haben gar keine Schuh,", "tokens": ["Die", "G\u00e4ns", "ha\u00b7ben", "gar", "kei\u00b7ne", "Schuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was sagen dann die lieben H\u00fcner dazu?", "tokens": ["Was", "sa\u00b7gen", "dann", "die", "lie\u00b7ben", "H\u00fc\u00b7ner", "da\u00b7zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Und als ich nun kam an das kanaljeische Meer,", "tokens": ["Und", "als", "ich", "nun", "kam", "an", "das", "ka\u00b7nal\u00b7jei\u00b7sche", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da fand ich drey M\u00e4nner, und noch viel mehr,", "tokens": ["Da", "fand", "ich", "drey", "M\u00e4n\u00b7ner", ",", "und", "noch", "viel", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "$,", "KON", "ADV", "ADV", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Der eine hatte niemals was,", "tokens": ["Der", "ei\u00b7ne", "hat\u00b7te", "nie\u00b7mals", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der andre nicht das,", "tokens": ["Der", "and\u00b7re", "nicht", "das", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKNEG", "PDS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Und der dritte gar nichts,", "tokens": ["Und", "der", "drit\u00b7te", "gar", "nichts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADV", "PIS", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Die kauften sich eine Semmel,", "tokens": ["Die", "kauf\u00b7ten", "sich", "ei\u00b7ne", "Sem\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Und einen Zentner holl\u00e4ndischen K\u00e4se,", "tokens": ["Und", "ei\u00b7nen", "Zent\u00b7ner", "hol\u00b7l\u00e4n\u00b7di\u00b7schen", "K\u00e4\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und fuhren damit an das kanaljeische Meer.", "tokens": ["Und", "fuh\u00b7ren", "da\u00b7mit", "an", "das", "ka\u00b7nal\u00b7jei\u00b7sche", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und als sie kamen an das kanaljeische Meer,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "an", "das", "ka\u00b7nal\u00b7jei\u00b7sche", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da kamen sie in ein Land, und das war leer,", "tokens": ["Da", "ka\u00b7men", "sie", "in", "ein", "Land", ",", "und", "das", "war", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KON", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Und sie kamen an eine Kirche von Papier,", "tokens": ["Und", "sie", "ka\u00b7men", "an", "ei\u00b7ne", "Kir\u00b7che", "von", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.16": {"text": "Darin war eine Kanzel von Korduan,", "tokens": ["Da\u00b7rin", "war", "ei\u00b7ne", "Kan\u00b7zel", "von", "Kor\u00b7du\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Und ein Pfaffe von Rothstein,", "tokens": ["Und", "ein", "Pfaf\u00b7fe", "von", "Roth\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.18": {"text": "Der schrie: Heute haben wir S\u00fcnde gethan,", "tokens": ["Der", "schrie", ":", "Heu\u00b7te", "ha\u00b7ben", "wir", "S\u00fcn\u00b7de", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "NN", "VVPP", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Verleiht uns Gott das Leben, so wollen wir morgen wieder dran!", "tokens": ["Ver\u00b7leiht", "uns", "Gott", "das", "Le\u00b7ben", ",", "so", "wol\u00b7len", "wir", "mor\u00b7gen", "wie\u00b7der", "dran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ART", "NN", "$,", "ADV", "VMFIN", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+--+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "Und die drey Schwestern Lazari,", "tokens": ["Und", "die", "drey", "Schwes\u00b7tern", "La\u00b7za\u00b7ri", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "CARD", "NN", "NE", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.21": {"text": "Katharina, Sibilla, Schweigstilla,", "tokens": ["Ka\u00b7tha\u00b7ri\u00b7na", ",", "Si\u00b7bil\u00b7la", ",", "Schweigs\u00b7til\u00b7la", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Weinten bitterlich,", "tokens": ["Wein\u00b7ten", "bit\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.23": {"text": "Und der Hahn kr\u00e4hete Buttermilch!", "tokens": ["Und", "der", "Hahn", "kr\u00e4\u00b7he\u00b7te", "But\u00b7ter\u00b7milch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "NN", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}}, "stanza.2": {"line.1": {"text": "Quibus, quabus,", "tokens": ["Qui\u00b7bus", ",", "qua\u00b7bus", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "FM.la", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Die Enten gehn barfu\u00df,", "tokens": ["Die", "En\u00b7ten", "gehn", "bar\u00b7fu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die G\u00e4ns haben gar keine Schuh,", "tokens": ["Die", "G\u00e4ns", "ha\u00b7ben", "gar", "kei\u00b7ne", "Schuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was sagen dann die lieben H\u00fcner dazu?", "tokens": ["Was", "sa\u00b7gen", "dann", "die", "lie\u00b7ben", "H\u00fc\u00b7ner", "da\u00b7zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Und als ich nun kam an das kanaljeische Meer,", "tokens": ["Und", "als", "ich", "nun", "kam", "an", "das", "ka\u00b7nal\u00b7jei\u00b7sche", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da fand ich drey M\u00e4nner, und noch viel mehr,", "tokens": ["Da", "fand", "ich", "drey", "M\u00e4n\u00b7ner", ",", "und", "noch", "viel", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "$,", "KON", "ADV", "ADV", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Der eine hatte niemals was,", "tokens": ["Der", "ei\u00b7ne", "hat\u00b7te", "nie\u00b7mals", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der andre nicht das,", "tokens": ["Der", "and\u00b7re", "nicht", "das", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKNEG", "PDS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Und der dritte gar nichts,", "tokens": ["Und", "der", "drit\u00b7te", "gar", "nichts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADV", "PIS", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Die kauften sich eine Semmel,", "tokens": ["Die", "kauf\u00b7ten", "sich", "ei\u00b7ne", "Sem\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Und einen Zentner holl\u00e4ndischen K\u00e4se,", "tokens": ["Und", "ei\u00b7nen", "Zent\u00b7ner", "hol\u00b7l\u00e4n\u00b7di\u00b7schen", "K\u00e4\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und fuhren damit an das kanaljeische Meer.", "tokens": ["Und", "fuh\u00b7ren", "da\u00b7mit", "an", "das", "ka\u00b7nal\u00b7jei\u00b7sche", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und als sie kamen an das kanaljeische Meer,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "an", "das", "ka\u00b7nal\u00b7jei\u00b7sche", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da kamen sie in ein Land, und das war leer,", "tokens": ["Da", "ka\u00b7men", "sie", "in", "ein", "Land", ",", "und", "das", "war", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KON", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Und sie kamen an eine Kirche von Papier,", "tokens": ["Und", "sie", "ka\u00b7men", "an", "ei\u00b7ne", "Kir\u00b7che", "von", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.16": {"text": "Darin war eine Kanzel von Korduan,", "tokens": ["Da\u00b7rin", "war", "ei\u00b7ne", "Kan\u00b7zel", "von", "Kor\u00b7du\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Und ein Pfaffe von Rothstein,", "tokens": ["Und", "ein", "Pfaf\u00b7fe", "von", "Roth\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.18": {"text": "Der schrie: Heute haben wir S\u00fcnde gethan,", "tokens": ["Der", "schrie", ":", "Heu\u00b7te", "ha\u00b7ben", "wir", "S\u00fcn\u00b7de", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "NN", "VVPP", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Verleiht uns Gott das Leben, so wollen wir morgen wieder dran!", "tokens": ["Ver\u00b7leiht", "uns", "Gott", "das", "Le\u00b7ben", ",", "so", "wol\u00b7len", "wir", "mor\u00b7gen", "wie\u00b7der", "dran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ART", "NN", "$,", "ADV", "VMFIN", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+--+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "Und die drey Schwestern Lazari,", "tokens": ["Und", "die", "drey", "Schwes\u00b7tern", "La\u00b7za\u00b7ri", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "CARD", "NN", "NE", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.21": {"text": "Katharina, Sibilla, Schweigstilla,", "tokens": ["Ka\u00b7tha\u00b7ri\u00b7na", ",", "Si\u00b7bil\u00b7la", ",", "Schweigs\u00b7til\u00b7la", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Weinten bitterlich,", "tokens": ["Wein\u00b7ten", "bit\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.23": {"text": "Und der Hahn kr\u00e4hete Buttermilch!", "tokens": ["Und", "der", "Hahn", "kr\u00e4\u00b7he\u00b7te", "But\u00b7ter\u00b7milch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "NN", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}}}}}