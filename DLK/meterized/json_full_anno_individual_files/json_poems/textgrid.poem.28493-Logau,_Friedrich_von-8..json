{"textgrid.poem.28493": {"metadata": {"author": {"name": "Logau, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "8.", "genre": "verse", "period": "N.A.", "pub_year": 1630, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es bleibt noch immer so, da\u00df unser beyder Gl\u00fccke,", "tokens": ["Es", "bleibt", "noch", "im\u00b7mer", "so", ",", "da\u00df", "un\u00b7ser", "bey\u00b7der", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Freund, geschwistert ist. De\u00df Bettes kalte L\u00fccke,", "tokens": ["O", "Freund", ",", "ge\u00b7schwis\u00b7tert", "ist", ".", "De\u00df", "Bet\u00b7tes", "kal\u00b7te", "L\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVPP", "VAFIN", "$.", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wozu mich vor und dich hernach de\u00df Himmels Satz", "tokens": ["Wo\u00b7zu", "mich", "vor", "und", "dich", "her\u00b7nach", "de\u00df", "Him\u00b7mels", "Satz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKVZ", "KON", "PPER", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Um Schuld verurtelt hat, ist ein erg\u00e4ntzter Platz", "tokens": ["Um", "Schuld", "ver\u00b7ur\u00b7telt", "hat", ",", "ist", "ein", "er\u00b7g\u00e4ntz\u00b7ter", "Platz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "VVPP", "VAFIN", "$,", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bey mir zuvor, bey dir hernach. Was noch nicht gleiche,", "tokens": ["Bey", "mir", "zu\u00b7vor", ",", "bey", "dir", "her\u00b7nach", ".", "Was", "noch", "nicht", "glei\u00b7che", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$,", "APPR", "PPER", "ADV", "$.", "PWS", "ADV", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das darff drey Viertel-Jahr, bi\u00df da\u00df es di\u00df erreiche,", "tokens": ["Das", "darff", "drey", "Vier\u00b7tel\u00b7Jahr", ",", "bi\u00df", "da\u00df", "es", "di\u00df", "er\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "CARD", "NN", "$,", "KON", "KOUS", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Worinnen ich geh vor. Der ersten Liebe Pfand", "tokens": ["Wo\u00b7rin\u00b7nen", "ich", "geh", "vor", ".", "Der", "ers\u00b7ten", "Lie\u00b7be", "Pfand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "K\u00fcst dir noch deines, mir noch meines Theils die Hand;", "tokens": ["K\u00fcst", "dir", "noch", "dei\u00b7nes", ",", "mir", "noch", "mei\u00b7nes", "Theils", "die", "Hand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "$,", "PPER", "ADV", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da sind wir wieder gleich. Mich d\u00fcnckt, ich sehe schone", "tokens": ["Da", "sind", "wir", "wie\u00b7der", "gleich", ".", "Mich", "d\u00fcnckt", ",", "ich", "se\u00b7he", "scho\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bey dir, und w\u00fcntsche so, vom s\u00fcssen Namen Sohne", "tokens": ["Bey", "dir", ",", "und", "w\u00fcnt\u00b7sche", "so", ",", "vom", "s\u00fcs\u00b7sen", "Na\u00b7men", "Soh\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "KON", "VVFIN", "ADV", "$,", "APPRART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein k\u00fcrmelnd Exemplar, darinnen dieses steht,", "tokens": ["Ein", "k\u00fcr\u00b7melnd", "Ex\u00b7emp\u00b7lar", ",", "da\u00b7rin\u00b7nen", "die\u00b7ses", "steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "ADV", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df dessen, der es hat, sein Namen nicht vergeht;", "tokens": ["Da\u00df", "des\u00b7sen", ",", "der", "es", "hat", ",", "sein", "Na\u00b7men", "nicht", "ver\u00b7geht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "PPER", "VAFIN", "$,", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dann sind wir wieder gleich. Wil mehres was beschlissen", "tokens": ["Dann", "sind", "wir", "wie\u00b7der", "gleich", ".", "Wil", "meh\u00b7res", "was", "be\u00b7schlis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "VMFIN", "PIS", "PWS", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das obre Regiment, das gleichlich zu genissen", "tokens": ["Das", "ob\u00b7re", "Re\u00b7gi\u00b7ment", ",", "das", "gleich\u00b7lich", "zu", "ge\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Uns beyden stehe f\u00fcr: o Gott, so gib uns Theil", "tokens": ["Uns", "bey\u00b7den", "ste\u00b7he", "f\u00fcr", ":", "o", "Gott", ",", "so", "gib", "uns", "Theil"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PIAT", "VVFIN", "APPR", "$.", "FM", "NN", "$,", "ADV", "VVIMP", "PPER", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Am Friede dieser Welt und an de\u00df Himmels Heil!", "tokens": ["Am", "Frie\u00b7de", "die\u00b7ser", "Welt", "und", "an", "de\u00df", "Him\u00b7mels", "Heil", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "KON", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es bleibt noch immer so, da\u00df unser beyder Gl\u00fccke,", "tokens": ["Es", "bleibt", "noch", "im\u00b7mer", "so", ",", "da\u00df", "un\u00b7ser", "bey\u00b7der", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Freund, geschwistert ist. De\u00df Bettes kalte L\u00fccke,", "tokens": ["O", "Freund", ",", "ge\u00b7schwis\u00b7tert", "ist", ".", "De\u00df", "Bet\u00b7tes", "kal\u00b7te", "L\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVPP", "VAFIN", "$.", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wozu mich vor und dich hernach de\u00df Himmels Satz", "tokens": ["Wo\u00b7zu", "mich", "vor", "und", "dich", "her\u00b7nach", "de\u00df", "Him\u00b7mels", "Satz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKVZ", "KON", "PPER", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Um Schuld verurtelt hat, ist ein erg\u00e4ntzter Platz", "tokens": ["Um", "Schuld", "ver\u00b7ur\u00b7telt", "hat", ",", "ist", "ein", "er\u00b7g\u00e4ntz\u00b7ter", "Platz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "VVPP", "VAFIN", "$,", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bey mir zuvor, bey dir hernach. Was noch nicht gleiche,", "tokens": ["Bey", "mir", "zu\u00b7vor", ",", "bey", "dir", "her\u00b7nach", ".", "Was", "noch", "nicht", "glei\u00b7che", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$,", "APPR", "PPER", "ADV", "$.", "PWS", "ADV", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das darff drey Viertel-Jahr, bi\u00df da\u00df es di\u00df erreiche,", "tokens": ["Das", "darff", "drey", "Vier\u00b7tel\u00b7Jahr", ",", "bi\u00df", "da\u00df", "es", "di\u00df", "er\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "CARD", "NN", "$,", "KON", "KOUS", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Worinnen ich geh vor. Der ersten Liebe Pfand", "tokens": ["Wo\u00b7rin\u00b7nen", "ich", "geh", "vor", ".", "Der", "ers\u00b7ten", "Lie\u00b7be", "Pfand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "K\u00fcst dir noch deines, mir noch meines Theils die Hand;", "tokens": ["K\u00fcst", "dir", "noch", "dei\u00b7nes", ",", "mir", "noch", "mei\u00b7nes", "Theils", "die", "Hand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "$,", "PPER", "ADV", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da sind wir wieder gleich. Mich d\u00fcnckt, ich sehe schone", "tokens": ["Da", "sind", "wir", "wie\u00b7der", "gleich", ".", "Mich", "d\u00fcnckt", ",", "ich", "se\u00b7he", "scho\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bey dir, und w\u00fcntsche so, vom s\u00fcssen Namen Sohne", "tokens": ["Bey", "dir", ",", "und", "w\u00fcnt\u00b7sche", "so", ",", "vom", "s\u00fcs\u00b7sen", "Na\u00b7men", "Soh\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "KON", "VVFIN", "ADV", "$,", "APPRART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein k\u00fcrmelnd Exemplar, darinnen dieses steht,", "tokens": ["Ein", "k\u00fcr\u00b7melnd", "Ex\u00b7emp\u00b7lar", ",", "da\u00b7rin\u00b7nen", "die\u00b7ses", "steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "ADV", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df dessen, der es hat, sein Namen nicht vergeht;", "tokens": ["Da\u00df", "des\u00b7sen", ",", "der", "es", "hat", ",", "sein", "Na\u00b7men", "nicht", "ver\u00b7geht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "PPER", "VAFIN", "$,", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dann sind wir wieder gleich. Wil mehres was beschlissen", "tokens": ["Dann", "sind", "wir", "wie\u00b7der", "gleich", ".", "Wil", "meh\u00b7res", "was", "be\u00b7schlis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "VMFIN", "PIS", "PWS", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das obre Regiment, das gleichlich zu genissen", "tokens": ["Das", "ob\u00b7re", "Re\u00b7gi\u00b7ment", ",", "das", "gleich\u00b7lich", "zu", "ge\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Uns beyden stehe f\u00fcr: o Gott, so gib uns Theil", "tokens": ["Uns", "bey\u00b7den", "ste\u00b7he", "f\u00fcr", ":", "o", "Gott", ",", "so", "gib", "uns", "Theil"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PIAT", "VVFIN", "APPR", "$.", "FM", "NN", "$,", "ADV", "VVIMP", "PPER", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Am Friede dieser Welt und an de\u00df Himmels Heil!", "tokens": ["Am", "Frie\u00b7de", "die\u00b7ser", "Welt", "und", "an", "de\u00df", "Him\u00b7mels", "Heil", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "KON", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}