{"dta.poem.23846": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Ubersetzung der f\u00fcnfften Satyre des  \n Boileau.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Der Adel ist alsdenn kein blosser Dienst zu nennen/", "tokens": ["Der", "A\u00b7del", "ist", "als\u00b7denn", "kein", "blos\u00b7ser", "Dienst", "zu", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn man aus solchem Blut/ das Helden zeugen", "tokens": ["Wenn", "man", "aus", "sol\u00b7chem", "Blut", "/", "das", "Hel\u00b7den", "zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "PIAT", "NN", "$(", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Entsprie\u00dft/ und nach dem Satz/ den strenge Tu-", "tokens": ["Ent\u00b7sprie\u00dft", "/", "und", "nach", "dem", "Satz", "/", "den", "stren\u00b7ge", "Tu"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$(", "KON", "APPR", "ART", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Auch so der Ahnen Spuhr/ wie du/ mein Dan-", "tokens": ["Auch", "so", "der", "Ah\u00b7nen", "Spuhr", "/", "wie", "du", "/", "mein", "Dan"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$(", "PWAV", "PPER", "$(", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nur kr\u00e4nckt mich/ wenn ein Thor/ der sich in schn\u00f6den", "tokens": ["Nur", "kr\u00e4nckt", "mich", "/", "wenn", "ein", "Thor", "/", "der", "sich", "in", "schn\u00f6\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOUS", "ART", "NN", "$(", "PRELS", "PRF", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Pflegt eintzig und allein/ mit seinem Stand zu br\u00fcsten/", "tokens": ["Pflegt", "eint\u00b7zig", "und", "al\u00b7lein", "/", "mit", "sei\u00b7nem", "Stand", "zu", "br\u00fcs\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADV", "$(", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So unversch\u00e4mte Pracht mit fremde\u0303 Schmucke treibt/", "tokens": ["So", "un\u00b7ver\u00b7sch\u00e4m\u00b7te", "Pracht", "mit", "frem\u00b7d\u1ebd", "Schmu\u00b7cke", "treibt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und andrer Leute Lob auf seine Rechnung schreibt.", "tokens": ["Und", "an\u00b7drer", "Leu\u00b7te", "Lob", "auf", "sei\u00b7ne", "Rech\u00b7nung", "schreibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sein tapfferes Geschlecht mag durch ber\u00fchmte Sachen", "tokens": ["Sein", "tapf\u00b7fe\u00b7res", "Ge\u00b7schlecht", "mag", "durch", "be\u00b7r\u00fchm\u00b7te", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die \u00e4ltsten Chronicken zu dicken B\u00fcchern machen;", "tokens": ["Die", "\u00e4lts\u00b7ten", "Chro\u00b7ni\u00b7cken", "zu", "di\u00b7cken", "B\u00fc\u00b7chern", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Gesetzt: da\u00df ein Capet/ der Franckreichs Scepter", "tokens": ["Ge\u00b7setzt", ":", "da\u00df", "ein", "Ca\u00b7pet", "/", "der", "Fran\u00b7ck\u00b7reichs", "Scep\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "$.", "KOUS", "ART", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Der Ahnen Ritterschild mit Lilgen ausgeziert;", "tokens": ["Der", "Ah\u00b7nen", "Rit\u00b7ter\u00b7schild", "mit", "Lil\u00b7gen", "aus\u00b7ge\u00b7ziert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wozu sol aber ihm der leere Vorraht dienen/", "tokens": ["Wo\u00b7zu", "sol", "a\u00b7ber", "ihm", "der", "lee\u00b7re", "Vor\u00b7raht", "die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "PPER", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wenn er von solchem Stam\u0303/ der ehmals gro\u00df geschienen/", "tokens": ["Wenn", "er", "von", "sol\u00b7chem", "Stam\u0303", "/", "der", "eh\u00b7mals", "gro\u00df", "ge\u00b7schie\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "$(", "ART", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Welt nichts weisen kan/ als ein verlegnes Blat/", "tokens": ["Der", "Welt", "nichts", "wei\u00b7sen", "kan", "/", "als", "ein", "ver\u00b7leg\u00b7nes", "Blat", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVINF", "VMFIN", "$(", "KOUS", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "An dem das Pergament der Wurm geschonet hat?", "tokens": ["An", "dem", "das", "Per\u00b7ga\u00b7ment", "der", "Wurm", "ge\u00b7scho\u00b7net", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wenn er was g\u00f6ttliches an seiner Quelle sp\u00fchret/", "tokens": ["Wenn", "er", "was", "g\u00f6tt\u00b7li\u00b7ches", "an", "sei\u00b7ner", "Quel\u00b7le", "sp\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADJA", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und doch in seinem Sinn zugleich ist \u00fcberf\u00fchret/", "tokens": ["Und", "doch", "in", "sei\u00b7nem", "Sinn", "zu\u00b7gleich", "ist", "\u00fc\u00b7berf\u00b7\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Da\u00df man nichts grosses mehr an ihm zu sehen kriegt:", "tokens": ["Da\u00df", "man", "nichts", "gros\u00b7ses", "mehr", "an", "ihm", "zu", "se\u00b7hen", "kriegt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "ADJA", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Als da\u00df ein stoltzer Jeck in weicher Wollust liegt.", "tokens": ["Als", "da\u00df", "ein", "stolt\u00b7zer", "Jeck", "in", "wei\u00b7cher", "Wol\u00b7lust", "liegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Doch scheint es/ wenn er sich so \u00fcberm\u00fcthig bl\u00e4het/", "tokens": ["Doch", "scheint", "es", "/", "wenn", "er", "sich", "so", "\u00fc\u00b7ber\u00b7m\u00fct\u00b7hig", "bl\u00e4\u00b7het", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "KOUS", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Da\u00df sich nach seinem Winck des Himmels Axe drehet/", "tokens": ["Da\u00df", "sich", "nach", "sei\u00b7nem", "Win\u00b7ck", "des", "Him\u00b7mels", "A\u00b7xe", "dre\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPR", "PPOSAT", "NN", "ART", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Und da\u00df des Sch\u00f6pffers Hand/ mit reiffem Vorbedacht/", "tokens": ["Und", "da\u00df", "des", "Sch\u00f6pf\u00b7fers", "Hand", "/", "mit", "reif\u00b7fem", "Vor\u00b7be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "NN", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ihn aus viel bessern Thon/ als mich hervor gebracht.", "tokens": ["Ihn", "aus", "viel", "bes\u00b7sern", "Thon", "/", "als", "mich", "her\u00b7vor", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "ADJA", "NN", "$(", "KOUS", "PPER", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Was ist es f\u00fcr ein Thier/ du Geist von hohen Gaben!", "tokens": ["Was", "ist", "es", "f\u00fcr", "ein", "Thier", "/", "du", "Geist", "von", "ho\u00b7hen", "Ga\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "$(", "PPER", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das wir gemeiniglich am allerliebsten haben?", "tokens": ["Das", "wir", "ge\u00b7mei\u00b7nig\u00b7lich", "am", "al\u00b7ler\u00b7liebs\u00b7ten", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPRART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ists nicht ein muntres Pferd/ das Krafft und Feuer", "tokens": ["Ists", "nicht", "ein", "mun\u00b7tres", "Pferd", "/", "das", "Krafft", "und", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKNEG", "ART", "ADJA", "NN", "$(", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Und keinen neben sich das Ziel erreichen l\u00e4\u00dft?", "tokens": ["Und", "kei\u00b7nen", "ne\u00b7ben", "sich", "das", "Ziel", "er\u00b7rei\u00b7chen", "l\u00e4\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "APPR", "PRF", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Da offt ein Koppelgaul wird ohngefehr bezahlet/", "tokens": ["Da", "offt", "ein", "Kop\u00b7pel\u00b7gaul", "wird", "ohn\u00b7ge\u00b7fehr", "be\u00b7zah\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VAFIN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ob gleich manch sch\u00f6nes Ro\u00df in seinem Stammbaum", "tokens": ["Ob", "gleich", "manch", "sch\u00f6\u00b7nes", "Ro\u00df", "in", "sei\u00b7nem", "Stamm\u00b7baum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Und tr\u00e4gt/ wenn er nicht taugt/ den Rentzel \u00fcber Land/", "tokens": ["Und", "tr\u00e4gt", "/", "wenn", "er", "nicht", "taugt", "/", "den", "Rent\u00b7zel", "\u00fc\u00b7ber", "Land", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPER", "PTKNEG", "VVFIN", "$(", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Wo man das Schindvieh nicht gar in die Karre span\u0303t.", "tokens": ["Wo", "man", "das", "Schind\u00b7vieh", "nicht", "gar", "in", "die", "Kar\u00b7re", "spa\u00f1t", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "PTKNEG", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wie aber wilst denn du uns andre so beth\u00f6ren/", "tokens": ["Wie", "a\u00b7ber", "wilst", "denn", "du", "uns", "and\u00b7re", "so", "be\u00b7th\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "KON", "PPER", "PRF", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Da\u00df jederman an dir sol was vergangnes ehren?", "tokens": ["Da\u00df", "je\u00b7der\u00b7man", "an", "dir", "sol", "was", "ver\u00b7gang\u00b7nes", "eh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "VMFIN", "PIS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Mein Freund du irrest dich/ und kennest nicht die Welt/", "tokens": ["Mein", "Freund", "du", "ir\u00b7rest", "dich", "/", "und", "ken\u00b7nest", "nicht", "die", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVFIN", "PPER", "$(", "KON", "VVFIN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wo ich nicht Tugend seh/ da seh\u2019 ich keinen Held.", "tokens": ["Wo", "ich", "nicht", "Tu\u00b7gend", "seh", "/", "da", "seh'", "ich", "kei\u00b7nen", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "NN", "VVFIN", "$(", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Getraust du dich dein Blut von Helden herzuleiten?", "tokens": ["Ge\u00b7traust", "du", "dich", "dein", "Blut", "von", "Hel\u00b7den", "her\u00b7zu\u00b7lei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "So zeig\u2019 auch gleiche Gluth/ wie sie zu ihren Zeiten/", "tokens": ["So", "zeig'", "auch", "glei\u00b7che", "Gluth", "/", "wie", "sie", "zu", "ih\u00b7ren", "Zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADJA", "NN", "$(", "PWAV", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Ein Hertz das Ehre sucht/ und das die Laster scheut/", "tokens": ["Ein", "Hertz", "das", "Eh\u00b7re", "sucht", "/", "und", "das", "die", "Las\u00b7ter", "scheut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$(", "KON", "PDS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Lebst du wie sichs geb\u00fchrt? fleuchst Ungerechtigkeit?", "tokens": ["Lebst", "du", "wie", "sichs", "ge\u00b7b\u00fchrt", "?", "fleuchst", "Un\u00b7ge\u00b7rech\u00b7tig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "PIS", "VVPP", "$.", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Kanst den der dich best\u00fcrmt/ von deinen Mauren treiben?", "tokens": ["Kanst", "den", "der", "dich", "be\u00b7st\u00fcrmt", "/", "von", "dei\u00b7nen", "Mau\u00b7ren", "trei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ART", "PPER", "VVPP", "$(", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Und bi\u00df zum Morgen-Thau im Harnisch stecken bleiben?", "tokens": ["Und", "bi\u00df", "zum", "Mor\u00b7gen\u00b7\u00b7T\u00b7hau", "im", "Har\u00b7nisch", "ste\u00b7cken", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "APPRART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.43": {"text": "Alsdenn erkenn\u2019 ich dich/ da\u00df du recht edel bist/", "tokens": ["Als\u00b7denn", "er\u00b7kenn'", "ich", "dich", "/", "da\u00df", "du", "recht", "e\u00b7del", "bist", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$(", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Weil man aus deinem Thun des Adels Probe list.", "tokens": ["Weil", "man", "aus", "dei\u00b7nem", "Thun", "des", "A\u00b7dels", "Pro\u00b7be", "list", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPOSAT", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Alsdenn sey dir verg\u00f6nnt/ die Ahnen zu erlesen", "tokens": ["Als\u00b7denn", "sey", "dir", "ver\u00b7g\u00f6nnt", "/", "die", "Ah\u00b7nen", "zu", "er\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$(", "ART", "NN", "PTKZU", "VVINF"], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.46": {"text": "Aus denen welche selbst Monarchen sind gewesen/", "tokens": ["Aus", "de\u00b7nen", "wel\u00b7che", "selbst", "Mon\u00b7ar\u00b7chen", "sind", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRELS", "ADV", "NN", "VAFIN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Ins tausende Gelied magst du zur\u00fccke gehn/", "tokens": ["Ins", "tau\u00b7sen\u00b7de", "Ge\u00b7lied", "magst", "du", "zu\u00b7r\u00fc\u00b7cke", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VMFIN", "PPER", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Die l\u00e4ngst verstrichne Zeit sol dir zu Dienste stehn.", "tokens": ["Die", "l\u00e4ngst", "ver\u00b7strich\u00b7ne", "Zeit", "sol", "dir", "zu", "Diens\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Du kanst der Helden Reih/ wenn dirs gef\u00e4llt durchwan-", "tokens": ["Du", "kanst", "der", "Hel\u00b7den", "Reih", "/", "wenn", "dirs", "ge\u00b7f\u00e4llt", "durch\u00b7wan"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "NN", "$(", "KOUS", "PIS", "VVPP", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Komm von Achilles her/ von C\u00e4sarn/ Alexandern.", "tokens": ["Komm", "von", "A\u00b7chil\u00b7les", "her", "/", "von", "C\u00e4\u00b7sarn", "/", "A\u00b7lex\u00b7an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "PTKVZ", "$(", "APPR", "NE", "$(", "NE", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.51": {"text": "Der Neid der streut umsonst dir einen Zweiffel ein/", "tokens": ["Der", "Neid", "der", "streut", "um\u00b7sonst", "dir", "ei\u00b7nen", "Zweif\u00b7fel", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "ADV", "PPER", "ART", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Und bist du nicht ihr Sohn/ so soltest du es seyn.", "tokens": ["Und", "bist", "du", "nicht", "ihr", "Sohn", "/", "so", "sol\u00b7test", "du", "es", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$(", "ADV", "VMFIN", "PPER", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Hingegen/ hast du gleich Bewei\u00df genug in H\u00e4nden/", "tokens": ["Hin\u00b7ge\u00b7gen", "/", "hast", "du", "gleich", "Be\u00b7wei\u00df", "ge\u00b7nug", "in", "H\u00e4n\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VAFIN", "PPER", "ADV", "NN", "ADV", "APPR", "NN", "$("], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.54": {"text": "Da\u00df du von Grad zu Grad stammst aus Alcidens Len-", "tokens": ["Da\u00df", "du", "von", "Grad", "zu", "Grad", "stammst", "aus", "Al\u00b7ci\u00b7dens", "Len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "APPR", "NN", "VVFIN", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Schl\u00e4gst aber aus der Art/ so legt der Eltern Grab", "tokens": ["Schl\u00e4gst", "a\u00b7ber", "aus", "der", "Art", "/", "so", "legt", "der", "El\u00b7tern", "Grab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$(", "ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Am ersten wider dich ein schlimmes Zeugni\u00df ab/", "tokens": ["Am", "ers\u00b7ten", "wi\u00b7der", "dich", "ein", "schlim\u00b7mes", "Zeug\u00b7ni\u00df", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "APPR", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und ihrer W\u00fcrde Glantz/ den du beginnst zu schw\u00e4chen/", "tokens": ["Und", "ih\u00b7rer", "W\u00fcr\u00b7de", "Glantz", "/", "den", "du", "be\u00b7ginnst", "zu", "schw\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$(", "ART", "PPER", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Beleuchtet desto mehr dein sch\u00e4ndliches Verbrechen/", "tokens": ["Be\u00b7leuch\u00b7tet", "des\u00b7to", "mehr", "dein", "sch\u00e4nd\u00b7li\u00b7ches", "Ver\u00b7bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Es hilfft nicht/ da\u00df du dich mit ihren Namen deckst/", "tokens": ["Es", "hilfft", "nicht", "/", "da\u00df", "du", "dich", "mit", "ih\u00b7ren", "Na\u00b7men", "deckst", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Wenn du dich auf der Haut des M\u00fc\u00dfigganges", "tokens": ["Wenn", "du", "dich", "auf", "der", "Haut", "des", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ges"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Und wilst du dergestalt der Ahnen Schutz gebrauchen?", "tokens": ["Und", "wilst", "du", "der\u00b7ge\u00b7stalt", "der", "Ah\u00b7nen", "Schutz", "ge\u00b7brau\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "So wird er wie ein Dampff und leichter noch verrauchen.", "tokens": ["So", "wird", "er", "wie", "ein", "Dampff", "und", "leich\u00b7ter", "noch", "ver\u00b7rau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "KOKOM", "ART", "NN", "KON", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Du bleibst ein bl\u00f6der Held/ der ingeheim betreugt/", "tokens": ["Du", "bleibst", "ein", "bl\u00f6\u00b7der", "Held", "/", "der", "in\u00b7ge\u00b7heim", "be\u00b7treugt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Ob er gleich \u00f6ffentlich viel g\u00fcldne Berge leugt.", "tokens": ["Ob", "er", "gleich", "\u00f6f\u00b7fent\u00b7lich", "viel", "g\u00fcld\u00b7ne", "Ber\u00b7ge", "leugt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.65": {"text": "Ein Falscher der Verraht und lauter Meineyd br\u00fctet/", "tokens": ["Ein", "Fal\u00b7scher", "der", "Ver\u00b7raht", "und", "lau\u00b7ter", "Mei\u00b7neyd", "br\u00fc\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Ein Thor/ doch so ein Thor/ der in dem Wahnwitz w\u00fctet/", "tokens": ["Ein", "Thor", "/", "doch", "so", "ein", "Thor", "/", "der", "in", "dem", "Wahn\u00b7witz", "w\u00fc\u00b7tet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADV", "ART", "NN", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Und wenn man den Entwurff in zweyen Worten", "tokens": ["Und", "wenn", "man", "den", "Ent\u00b7wurff", "in", "zwe\u00b7yen", "Wor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Von einem sch\u00f6nen Baum ein abgefaulter Ast.", "tokens": ["Von", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Baum", "ein", "ab\u00b7ge\u00b7faul\u00b7ter", "Ast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Wird meiner Musen Zorn sich auch zu sehr ergiessen?", "tokens": ["Wird", "mei\u00b7ner", "Mu\u00b7sen", "Zorn", "sich", "auch", "zu", "sehr", "er\u00b7gies\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "PRF", "ADV", "PTKA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "L\u00e4\u00dft sie nicht schon zu viel verg\u00e4llte Worte fliessen?", "tokens": ["L\u00e4\u00dft", "sie", "nicht", "schon", "zu", "viel", "ver\u00b7g\u00e4ll\u00b7te", "Wor\u00b7te", "flies\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Sie geht vielleicht zu weit/ und kennt die Weise nicht/", "tokens": ["Sie", "geht", "viel\u00b7leicht", "zu", "weit", "/", "und", "kennt", "die", "Wei\u00b7se", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKA", "ADJD", "$(", "KON", "VVFIN", "ART", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Nach der man insgemein mit Stands-Personen", "tokens": ["Nach", "der", "man", "ins\u00b7ge\u00b7mein", "mit", "Stands\u00b7Per\u00b7so\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIS", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.73": {"text": "Wolan so wil ich denn mit Glimpff nur dieses fragen:", "tokens": ["Wo\u00b7lan", "so", "wil", "ich", "denn", "mit", "Glimpff", "nur", "die\u00b7ses", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ADV", "APPR", "NN", "ADV", "PDAT", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Ists lange da\u00df man h\u00f6rt von deinem Adel sagen?", "tokens": ["Ists", "lan\u00b7ge", "da\u00df", "man", "h\u00f6rt", "von", "dei\u00b7nem", "A\u00b7del", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KOUS", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Schon gantzer tausend Jahr. Un\u0303 dein bekandtes Haus", "tokens": ["Schon", "gant\u00b7zer", "tau\u00b7send", "Jahr", ".", "U\u00f1", "dein", "be\u00b7kand\u00b7tes", "Haus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "CARD", "NN", "$.", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Streckt seiner Ahnen Zahl/ auf zwey und drey\u00dfig aus?", "tokens": ["Streckt", "sei\u00b7ner", "Ah\u00b7nen", "Zahl", "/", "auf", "zwey", "und", "drey\u00b7\u00dfig", "aus", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$(", "APPR", "CARD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "In Warheit das ist viel/ zumahl da zu erweisen/", "tokens": ["In", "War\u00b7heit", "das", "ist", "viel", "/", "zu\u00b7mahl", "da", "zu", "er\u00b7wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDS", "VAFIN", "ADV", "$(", "KOUS", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Da\u00df ihrer Titel Pracht fast alle Schrifften preisen/", "tokens": ["Da\u00df", "ih\u00b7rer", "Ti\u00b7tel", "Pracht", "fast", "al\u00b7le", "Schriff\u00b7ten", "prei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Ihr Rame lebt/ und trutzt dem Schiffbruch rauher", "tokens": ["Ihr", "Ra\u00b7me", "lebt", "/", "und", "trutzt", "dem", "Schiff\u00b7bruch", "rau\u00b7her"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "KON", "VVFIN", "ART", "NN", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.80": {"text": "Das alles ist sehr gut; doch wer schwert einen Eyd/", "tokens": ["Das", "al\u00b7les", "ist", "sehr", "gut", ";", "doch", "wer", "schwert", "ei\u00b7nen", "Eyd", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "ADV", "ADJD", "$.", "KON", "PWS", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Da\u00df binnen solcher Frist/ der M\u00fctter keusches Lieben", "tokens": ["Da\u00df", "bin\u00b7nen", "sol\u00b7cher", "Frist", "/", "der", "M\u00fct\u00b7ter", "keu\u00b7sches", "Lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "NN", "$(", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Den M\u00e4nnern immer treu/ den Buhlern feind geblieben;", "tokens": ["Den", "M\u00e4n\u00b7nern", "im\u00b7mer", "treu", "/", "den", "Buh\u00b7lern", "feind", "ge\u00b7blie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$(", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Da\u00df nie ein k\u00fchner Freund sie gl\u00fccklich angelacht/", "tokens": ["Da\u00df", "nie", "ein", "k\u00fch\u00b7ner", "Freund", "sie", "gl\u00fcck\u00b7lich", "an\u00b7ge\u00b7lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Und durch den Adel-Stand dir einen Strich gemacht.", "tokens": ["Und", "durch", "den", "A\u00b7del\u00b7Stand", "dir", "ei\u00b7nen", "Strich", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Und da\u00df ein reines Blut/ aus nicht geringerm Orden", "tokens": ["Und", "da\u00df", "ein", "rei\u00b7nes", "Blut", "/", "aus", "nicht", "ge\u00b7rin\u00b7germ", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "$(", "APPR", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Stets durch Lucretien dir zugefl\u00f6sset worden?", "tokens": ["Stets", "durch", "Lu\u00b7cre\u00b7ti\u00b7en", "dir", "zu\u00b7ge\u00b7fl\u00f6s\u00b7set", "wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PPER", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Verflucht sey jener Tag an dem der eitle Tand", "tokens": ["Ver\u00b7flucht", "sey", "je\u00b7ner", "Tag", "an", "dem", "der", "eit\u00b7le", "Tand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PDAT", "NN", "APPR", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Zuerst die Reinigkeit der Sitten weggebannt!", "tokens": ["Zu\u00b7erst", "die", "Rei\u00b7nig\u00b7keit", "der", "Sit\u00b7ten", "weg\u00b7ge\u00b7bannt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Als die noch zarte Welt lag gleichsam in der Wiegen/", "tokens": ["Als", "die", "noch", "zar\u00b7te", "Welt", "lag", "gleich\u00b7sam", "in", "der", "Wie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ADJA", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Durfft einer sich auf nichts als auf die Unschuld triegen/", "tokens": ["Durfft", "ei\u00b7ner", "sich", "auf", "nichts", "als", "auf", "die", "Un\u00b7schuld", "trie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PRF", "APPR", "PIS", "KOKOM", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Das Volck das war vergn\u00fcgt und in Gesetzen gleich/", "tokens": ["Das", "Volck", "das", "war", "ver\u00b7gn\u00fcgt", "und", "in", "Ge\u00b7set\u00b7zen", "gleich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDS", "VAFIN", "VVPP", "KON", "APPR", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Verdienst war Adels werth/ und galt ein K\u00f6nigreich.", "tokens": ["Ver\u00b7dienst", "war", "A\u00b7dels", "werth", "/", "und", "galt", "ein", "K\u00f6\u00b7nig\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "ADJD", "$(", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Da fand man keinen Held/ der sich auf Herkunfft st\u00fctzte/", "tokens": ["Da", "fand", "man", "kei\u00b7nen", "Held", "/", "der", "sich", "auf", "Her\u00b7kunfft", "st\u00fctz\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PIAT", "NN", "$(", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Und der nicht von sich selbst mit eignen Straalen blitzte/", "tokens": ["Und", "der", "nicht", "von", "sich", "selbst", "mit", "eig\u00b7nen", "Straa\u00b7len", "blitz\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "APPR", "PRF", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Bi\u00df da\u00df man mit der Zeit die Tugend so verlie\u00df/", "tokens": ["Bi\u00df", "da\u00df", "man", "mit", "der", "Zeit", "die", "Tu\u00b7gend", "so", "ver\u00b7lie\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "APPR", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Da\u00df man sie B\u00fcrgerlich/ das Laster edel hie\u00df.", "tokens": ["Da\u00df", "man", "sie", "B\u00fcr\u00b7ger\u00b7lich", "/", "das", "Las\u00b7ter", "e\u00b7del", "hie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "NE", "$(", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Der neu-erwachsene Stand hielt andre bald f\u00fcr Scla-", "tokens": ["Der", "neu\u00b7er\u00b7wach\u00b7se\u00b7ne", "Stand", "hielt", "and\u00b7re", "bald", "f\u00fcr", "Scla"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "ADV", "APPR", "TRUNC"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.98": {"text": "Das Land ward \u00fcberschwem\u0303t von ", "tokens": ["Das", "Land", "ward", "\u00fc\u00b7ber\u00b7schwem\u0303t", "von"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.99": {"text": "Man hatte Tugend gnug/ wenn man sich Titel gab/", "tokens": ["Man", "hat\u00b7te", "Tu\u00b7gend", "gnug", "/", "wenn", "man", "sich", "Ti\u00b7tel", "gab", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "NN", "ADV", "$(", "KOUS", "PIS", "PRF", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und wie\u00df an statt des Kerns die Welt mit Schaalen ab.", "tokens": ["Und", "wie\u00df", "an", "statt", "des", "Kerns", "die", "Welt", "mit", "Schaa\u00b7len", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Bald ward ein Wapen-Recht mit Regeln ausersonnen/", "tokens": ["Bald", "ward", "ein", "Wa\u00b7pen\u00b7Recht", "mit", "Re\u00b7geln", "aus\u00b7er\u00b7son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Das/ weil es im Gehirn der Schw\u00e4rmer angesponnen/", "tokens": ["Das", "/", "weil", "es", "im", "Ge\u00b7hirn", "der", "Schw\u00e4r\u00b7mer", "an\u00b7ge\u00b7spon\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Ihm eigne W\u00f6rter macht/ und unvernehmlich spricht/", "tokens": ["Ihm", "eig\u00b7ne", "W\u00f6r\u00b7ter", "macht", "/", "und", "un\u00b7ver\u00b7nehm\u00b7lich", "spricht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVFIN", "$(", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Die Schilde bald bekr\u00f6nt/ bald in vier Theile bricht.", "tokens": ["Die", "Schil\u00b7de", "bald", "be\u00b7kr\u00f6nt", "/", "bald", "in", "vier", "Thei\u00b7le", "bricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$(", "ADV", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Bald pf\u00e4hlt und gegenpf\u00e4hlt/ bald kerbet und verbindet/", "tokens": ["Bald", "pf\u00e4hlt", "und", "ge\u00b7gen\u00b7pf\u00e4hlt", "/", "bald", "ker\u00b7bet", "und", "ver\u00b7bin\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVPP", "$(", "ADV", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Und was dergleichen mehr die Herolds-Kunst erfindet.", "tokens": ["Und", "was", "derg\u00b7lei\u00b7chen", "mehr", "die", "He\u00b7rolds\u00b7Kunst", "er\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Da ward nun die Vernunfft der Thorheit unterthan/", "tokens": ["Da", "ward", "nun", "die", "Ver\u00b7nunfft", "der", "Thor\u00b7heit", "un\u00b7ter\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Die Ehre war besch\u00e4mt/ denn keiner sah sie an.", "tokens": ["Die", "Eh\u00b7re", "war", "be\u00b7sch\u00e4mt", "/", "denn", "kei\u00b7ner", "sah", "sie", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "KON", "PIS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Die Kosten nahmen zu/ man lie\u00df Verschwendung sp\u00fcren/", "tokens": ["Die", "Kos\u00b7ten", "nah\u00b7men", "zu", "/", "man", "lie\u00df", "Ver\u00b7schwen\u00b7dung", "sp\u00fc\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "$(", "PIS", "VVFIN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Den Vorzug der Gebuhrt nach W\u00fcrden auszuf\u00fchren/", "tokens": ["Den", "Vor\u00b7zug", "der", "Ge\u00b7buhrt", "nach", "W\u00fcr\u00b7den", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Man baute Schl\u00f6sser auf/ und gab zum Unterscheid/", "tokens": ["Man", "bau\u00b7te", "Schl\u00f6s\u00b7ser", "auf", "/", "und", "gab", "zum", "Un\u00b7ter\u00b7scheid", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "APPR", "$(", "KON", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Der Hoffbedienten Schaar ein bunt-gebr\u00e4mtes Kleid.", "tokens": ["Der", "Hoff\u00b7be\u00b7dien\u00b7ten", "Schaar", "ein", "bunt\u00b7ge\u00b7br\u00e4m\u00b7tes", "Kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Da muste man viel Tro\u00df zum Ansehn bey sich haben/", "tokens": ["Da", "mus\u00b7te", "man", "viel", "Tro\u00df", "zum", "An\u00b7sehn", "bey", "sich", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PIAT", "NN", "APPRART", "NN", "APPR", "PRF", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Und wer gar vornehm war/ der hielt sich Edelknaben/", "tokens": ["Und", "wer", "gar", "vor\u00b7nehm", "war", "/", "der", "hielt", "sich", "E\u00b7del\u00b7kna\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADJD", "VAFIN", "$(", "ART", "VVFIN", "PRF", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Als aber Geld und Gut des Adels bald verschwandt/", "tokens": ["Als", "a\u00b7ber", "Geld", "und", "Gut", "des", "A\u00b7dels", "bald", "ver\u00b7schwandt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KON", "NN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Und er zum Unterhalt kein leichter Mittel fandt/", "tokens": ["Und", "er", "zum", "Un\u00b7ter\u00b7halt", "kein", "leich\u00b7ter", "Mit\u00b7tel", "fandt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "PIAT", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Ward er aus D\u00fcrfftigkeit in einer Kunst ge\u00fcbet/", "tokens": ["Ward", "er", "aus", "D\u00fcr\u00b7ff\u00b7tig\u00b7keit", "in", "ei\u00b7ner", "Kunst", "ge\u00b7\u00fc\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.118": {"text": "Die allenthalben borgt/ und nichts nicht wieder giebet;", "tokens": ["Die", "al\u00b7len\u00b7thal\u00b7ben", "borgt", "/", "und", "nichts", "nicht", "wie\u00b7der", "gie\u00b7bet", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "$(", "KON", "PIS", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Kein Scherge war so frech/ der sich an ihn vergriff/", "tokens": ["Kein", "Scher\u00b7ge", "war", "so", "frech", "/", "der", "sich", "an", "ihn", "ver\u00b7griff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$(", "PRELS", "PRF", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.120": {"text": "Und wenn ein Gl\u00e4ubiger nach der Bezahlung lieff/", "tokens": ["Und", "wenn", "ein", "Gl\u00e4u\u00b7bi\u00b7ger", "nach", "der", "Be\u00b7zah\u00b7lung", "lieff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.121": {"text": "Lie\u00df ihn ein solcher Herr f\u00fcr seiner Schwelle frieren/", "tokens": ["Lie\u00df", "ihn", "ein", "sol\u00b7cher", "Herr", "f\u00fcr", "sei\u00b7ner", "Schwel\u00b7le", "frie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Bi\u00df man ihn zum Beschlu\u00df sah\u2019 in den Schuld-Thurm", "tokens": ["Bi\u00df", "man", "ihn", "zum", "Be\u00b7schlu\u00df", "sah'", "in", "den", "Schuld\u00b7Thurm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "APPRART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-++-+-+--+", "measure": "iambic.hexa.chol"}, "line.123": {"text": "Da er/ wiewohl zu sp\u00e4t/ sein Ungemach beklagt/", "tokens": ["Da", "er", "/", "wie\u00b7wohl", "zu", "sp\u00e4t", "/", "sein", "Un\u00b7ge\u00b7mach", "be\u00b7klagt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "KOUS", "PTKA", "ADJD", "$(", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Wenn ihn des Richters Spruch von Hau\u00df und Hoff", "tokens": ["Wenn", "ihn", "des", "Rich\u00b7ters", "Spruch", "von", "Hau\u00df", "und", "Hoff"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "APPR", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.125": {"text": "Di\u00df gab Gelegenheit/ indem die Nohtdurfft fehlte/", "tokens": ["Di\u00df", "gab", "Ge\u00b7le\u00b7gen\u00b7heit", "/", "in\u00b7dem", "die", "Noht\u00b7durfft", "fehl\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "$(", "KOUS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Da\u00df er aus Lumpen-Volck ein reiches Weib erwehlte/", "tokens": ["Da\u00df", "er", "aus", "Lum\u00b7pen\u00b7Volck", "ein", "rei\u00b7ches", "Weib", "er\u00b7wehl\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Der Ahnen Alterthum das gab er in den Kauff/", "tokens": ["Der", "Ah\u00b7nen", "Al\u00b7ter\u00b7thum", "das", "gab", "er", "in", "den", "Kauff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Und half sich aus dem Schimpff mit Schande wieder", "tokens": ["Und", "half", "sich", "aus", "dem", "Schimpff", "mit", "Schan\u00b7de", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "APPR", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.129": {"text": "Denn wo der Adel nicht den Schein vom Golde lehnet/", "tokens": ["Denn", "wo", "der", "A\u00b7del", "nicht", "den", "Schein", "vom", "Gol\u00b7de", "leh\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "PTKNEG", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Und blo\u00df sein Alter liebt/ so bleibt er wol verh\u00f6net/", "tokens": ["Und", "blo\u00df", "sein", "Al\u00b7ter", "liebt", "/", "so", "bleibt", "er", "wol", "ver\u00b7h\u00f6\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "$(", "ADV", "VVFIN", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Ein jeder h\u00e4lt ihn werth ins Toll-Hau\u00df einzugehn/", "tokens": ["Ein", "je\u00b7der", "h\u00e4lt", "ihn", "werth", "ins", "Toll\u00b7Hau\u00df", "ein\u00b7zu\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Und wer ihm anverwandt/ der wil es nicht gestehn.", "tokens": ["Und", "wer", "ihm", "an\u00b7ver\u00b7wandt", "/", "der", "wil", "es", "nicht", "ge\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "$(", "ART", "VMFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Ist aber jemand reich/ nach dem wird alles fragen/", "tokens": ["Ist", "a\u00b7ber", "je\u00b7mand", "reich", "/", "nach", "dem", "wird", "al\u00b7les", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "ADJD", "$(", "APPR", "ART", "VAFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Ja h\u00e4tt\u2019 er in Pari\u00df gleich Lieberey getragen/", "tokens": ["Ja", "h\u00e4tt'", "er", "in", "Pa\u00b7ri\u00df", "gleich", "Lie\u00b7be\u00b7rey", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "APPR", "NE", "ADV", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Und w\u00fcste selber nicht/ wie recht sein Name sey/", "tokens": ["Und", "w\u00fcs\u00b7te", "sel\u00b7ber", "nicht", "/", "wie", "recht", "sein", "Na\u00b7me", "sey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "$(", "PWAV", "ADJD", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Ein Schmeichler steht ihm bald mit hundert Ahnen", "tokens": ["Ein", "Schmeich\u00b7ler", "steht", "ihm", "bald", "mit", "hun\u00b7dert", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.137": {"text": "Und wird ihn/ wer er ist/ aus den Geschichten lehren.", "tokens": ["Und", "wird", "ihn", "/", "wer", "er", "ist", "/", "aus", "den", "Ge\u00b7schich\u00b7ten", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$(", "PWS", "PPER", "VAFIN", "$(", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Auff! Dangeau den Verdienst und Gl\u00fcck f\u00fcr andern", "tokens": ["Auff", "!", "Dan\u00b7ge\u00b7au", "den", "Ver\u00b7dienst", "und", "Gl\u00fcck", "f\u00fcr", "an\u00b7dern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "$.", "NE", "ART", "NN", "KON", "NN", "APPR", "ADJA"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.139": {"text": "Der du des Hofes Meer so kl\u00fcglich durchgesp\u00fcrt/", "tokens": ["Der", "du", "des", "Ho\u00b7fes", "Meer", "so", "kl\u00fcg\u00b7lich", "durch\u00b7ge\u00b7sp\u00fcrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Da\u00df deine Tugend nie die Klippen hat ber\u00fchrt.", "tokens": ["Da\u00df", "dei\u00b7ne", "Tu\u00b7gend", "nie", "die", "Klip\u00b7pen", "hat", "be\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Dich hat des K\u00f6nigs Huld zu einem Stand geruffen/", "tokens": ["Dich", "hat", "des", "K\u00f6\u00b7nigs", "Huld", "zu", "ei\u00b7nem", "Stand", "ge\u00b7ruf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Da du ihn t\u00e4glich siehst auf neuen Sieges-Stuffen;", "tokens": ["Da", "du", "ihn", "t\u00e4g\u00b7lich", "siehst", "auf", "neu\u00b7en", "Sie\u00b7ges\u00b7Stuf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Und wie was g\u00f6ttliches/ das ihm ist eingepr\u00e4gt/", "tokens": ["Und", "wie", "was", "g\u00f6tt\u00b7li\u00b7ches", "/", "das", "ihm", "ist", "ein\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADJA", "$(", "PRELS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Mehr als der Lilgen Glantz an ihm zu schimmern", "tokens": ["Mehr", "als", "der", "Lil\u00b7gen", "Glantz", "an", "ihm", "zu", "schim\u00b7mern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "KOKOM", "ART", "NN", "NN", "APPR", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.145": {"text": "Wie ers ver\u00e4chtlich h\u00e4lt/ wann andre Majest\u00e4ten", "tokens": ["Wie", "ers", "ver\u00b7\u00e4cht\u00b7lich", "h\u00e4lt", "/", "wann", "and\u00b7re", "Ma\u00b7jes\u00b7t\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADJD", "VVFIN", "$(", "PWAV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Vor ihrer Uppigkeit im Purpur nicht err\u00f6hten/", "tokens": ["Vor", "ih\u00b7rer", "Up\u00b7pig\u00b7keit", "im", "Pur\u00b7pur", "nicht", "er\u00b7r\u00f6h\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Wie er die tr\u00e4ge Lust f\u00fcr eine B\u00fcrde sch\u00e4tzt/", "tokens": ["Wie", "er", "die", "tr\u00e4\u00b7ge", "Lust", "f\u00fcr", "ei\u00b7ne", "B\u00fcr\u00b7de", "sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Dem wanckelbaren Gl\u00fcck durch Klugheit Gr\u00e4ntzen", "tokens": ["Dem", "wan\u00b7ckel\u00b7ba\u00b7ren", "Gl\u00fcck", "durch", "Klug\u00b7heit", "Gr\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.149": {"text": "Und ihm sein Wohlergehn mit eignen H\u00e4nden bauet/", "tokens": ["Und", "ihm", "sein", "Woh\u00b7ler\u00b7gehn", "mit", "eig\u00b7nen", "H\u00e4n\u00b7den", "bau\u00b7et", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "So da\u00df der Erden Crey\u00df an ihm ein Muster schauet/", "tokens": ["So", "da\u00df", "der", "Er\u00b7den", "Crey\u00df", "an", "ihm", "ein", "Mus\u00b7ter", "schau\u00b7et", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "NN", "APPR", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Wie man sol K\u00f6nig seyn; Auf! sag ich/ sey bem\u00fcht/", "tokens": ["Wie", "man", "sol", "K\u00f6\u00b7nig", "seyn", ";", "Auf", "!", "sag", "ich", "/", "sey", "be\u00b7m\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PIAT", "NN", "VAINF", "$.", "APPR", "$.", "VVFIN", "PPER", "$(", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Wenn dein rechtschaffner Muth/ den Ruhm zum", "tokens": ["Wenn", "dein", "recht\u00b7schaff\u00b7ner", "Muth", "/", "den", "Ruhm", "zum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "$(", "ART", "NN", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.153": {"text": "Wie du durch treuen Dienst/ und tapfferes Beginnen/", "tokens": ["Wie", "du", "durch", "treu\u00b7en", "Dienst", "/", "und", "tapf\u00b7fe\u00b7res", "Be\u00b7gin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Magst deines Herren Hertz je mehr und mehr gewinnen/", "tokens": ["Magst", "dei\u00b7nes", "Her\u00b7ren", "Hertz", "je", "mehr", "und", "mehr", "ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "ADV", "ADV", "KON", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Und zeig ihm: da\u00df er heut noch Unterthanen find/", "tokens": ["Und", "zeig", "ihm", ":", "da\u00df", "er", "heut", "noch", "Un\u00b7ter\u00b7tha\u00b7nen", "find", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "KOUS", "PPER", "ADV", "ADV", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Die solches K\u00f6niges/ wie er ist/ w\u00fcrdig sind.", "tokens": ["Die", "sol\u00b7ches", "K\u00f6\u00b7ni\u00b7ges", "/", "wie", "er", "ist", "/", "w\u00fcr\u00b7dig", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$(", "PWAV", "PPER", "VAFIN", "$(", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}