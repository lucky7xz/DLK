{"textgrid.poem.44371": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Der Genesene", "genre": "verse", "period": "N.A.", "pub_year": 1820, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jetzt, da ichs bestanden habe,", "tokens": ["Jetzt", ",", "da", "ichs", "be\u00b7stan\u00b7den", "ha\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leuchtet mirs erst deutlich ein:", "tokens": ["Leuch\u00b7tet", "mirs", "erst", "deut\u00b7lich", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Krankheit, du bist Gottes Gabe!", "tokens": ["Krank\u00b7heit", ",", "du", "bist", "Got\u00b7tes", "Ga\u00b7be", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er soll drum gepriesen sein!", "tokens": ["Er", "soll", "drum", "ge\u00b7prie\u00b7sen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "VVPP", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Wie der Mensch dich schwer bek\u00e4mpfe,", "tokens": ["Wie", "der", "Mensch", "dich", "schwer", "be\u00b7k\u00e4mp\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch im Ringen allzumal", "tokens": ["Doch", "im", "Rin\u00b7gen", "all\u00b7zu\u00b7mal"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00f6sen sich der Seele Kr\u00e4mpfe,", "tokens": ["L\u00f6\u00b7sen", "sich", "der", "See\u00b7le", "Kr\u00e4mp\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Innrer Schmerz in \u00e4u\u00dfrer Qual.", "tokens": ["Inn\u00b7rer", "Schmerz", "in", "\u00e4u\u00df\u00b7rer", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Besserst an der Menschheit Bilde,", "tokens": ["Bes\u00b7serst", "an", "der", "Menschheit", "Bil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Scharfe Z\u00fcge m\u00e4\u00dfigst du:", "tokens": ["Schar\u00b7fe", "Z\u00fc\u00b7ge", "m\u00e4\u00b7\u00dfigst", "du", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "War sonst rauh, jetzt bin ich milde,", "tokens": ["War", "sonst", "rauh", ",", "jetzt", "bin", "ich", "mil\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unst\u00e4t sonst und jetzt in Ruh.", "tokens": ["Un\u00b7st\u00e4t", "sonst", "und", "jetzt", "in", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auch die andern, die da kamen,", "tokens": ["Auch", "die", "an\u00b7dern", ",", "die", "da", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Waren alle gut und weich,", "tokens": ["Wa\u00b7ren", "al\u00b7le", "gut", "und", "weich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil sie mich als Gleichen nahmen:", "tokens": ["Weil", "sie", "mich", "als", "Glei\u00b7chen", "nah\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "KOUS", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleiches Leiden macht ja gleich.", "tokens": ["Glei\u00b7ches", "Lei\u00b7den", "macht", "ja", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ob man sonst nach Fernem jage,", "tokens": ["Ob", "man", "sonst", "nach", "Fer\u00b7nem", "ja\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Setzest du ein n\u00e4her Ziel,", "tokens": ["Set\u00b7zest", "du", "ein", "n\u00e4\u00b7her", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Machst den Tag zum Ziel dem Tage,", "tokens": ["Machst", "den", "Tag", "zum", "Ziel", "dem", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine ruh'ge Nacht scheint viel;", "tokens": ["Ei\u00b7ne", "ruh'\u00b7ge", "Nacht", "scheint", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und der Wunsch \u00fcbt in Beschwerden", "tokens": ["Und", "der", "Wunsch", "\u00fcbt", "in", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ans Gebi\u00df den stolzen Mund:", "tokens": ["Ans", "Ge\u00b7bi\u00df", "den", "stol\u00b7zen", "Mund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Frage nicht: was soll ich werden?", "tokens": ["Fra\u00b7ge", "nicht", ":", "was", "soll", "ich", "wer\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$.", "PWS", "VMFIN", "PPER", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bin ich jetzo doch gesund.", "tokens": ["Bin", "ich", "jet\u00b7zo", "doch", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Das Gem\u00fct, verstockt, verquollen,", "tokens": ["Das", "Ge\u00b7m\u00fct", ",", "ver\u00b7stockt", ",", "ver\u00b7quol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von so manchem, das es trug,", "tokens": ["Von", "so", "man\u00b7chem", ",", "das", "es", "trug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00d6ffnet sich, wie Ackers Schollen,", "tokens": ["\u00d6ff\u00b7net", "sich", ",", "wie", "A\u00b7ckers", "Schol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "PWAV", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aufgelockert durch den Pflug,", "tokens": ["Auf\u00b7ge\u00b7lo\u00b7ckert", "durch", "den", "Pflug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und, als ob der Lenz erwache", "tokens": ["Und", ",", "als", "ob", "der", "Lenz", "er\u00b7wa\u00b7che"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOKOM", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "All mit seiner Freuden Chor,", "tokens": ["All", "mit", "sei\u00b7ner", "Freu\u00b7den", "Chor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Treibt es nach der langen Brache", "tokens": ["Treibt", "es", "nach", "der", "lan\u00b7gen", "Bra\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gr\u00fcne Spitzen neu hervor.", "tokens": ["Gr\u00fc\u00b7ne", "Spit\u00b7zen", "neu", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wie ist all mein Innres offen!", "tokens": ["Wie", "ist", "all", "mein", "Inn\u00b7res", "of\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIAT", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie verdoppelt jeder Sinn!", "tokens": ["Wie", "ver\u00b7dop\u00b7pelt", "je\u00b7der", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nachbild hat das Bild getroffen,", "tokens": ["Nach\u00b7bild", "hat", "das", "Bild", "ge\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jeder Augenblick Gewinn!", "tokens": ["Je\u00b7der", "Au\u00b7gen\u00b7blick", "Ge\u00b7winn", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Was ich lese, seh ich stehen,", "tokens": ["Was", "ich", "le\u00b7se", ",", "seh", "ich", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ich h\u00f6re, wird ein Bild,", "tokens": ["Was", "ich", "h\u00f6\u00b7re", ",", "wird", "ein", "Bild", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ich spreche, wird geschehen,", "tokens": ["Was", "ich", "spre\u00b7che", ",", "wird", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich w\u00fcnsche, wird erf\u00fcllt.", "tokens": ["Was", "ich", "w\u00fcn\u00b7sche", ",", "wird", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Mit der Welt in tiefem Frieden,", "tokens": ["Mit", "der", "Welt", "in", "tie\u00b7fem", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und in Frieden auch mit mir,", "tokens": ["Und", "in", "Frie\u00b7den", "auch", "mit", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dank ich ", "tokens": ["Dank", "ich"], "token_info": ["word", "word"], "pos": ["APPR", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Sich geoffenbaret hier,", "tokens": ["Sich", "ge\u00b7of\u00b7fen\u00b7ba\u00b7ret", "hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Und, erquickt von all der Labe,", "tokens": ["Und", ",", "er\u00b7quickt", "von", "all", "der", "La\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVPP", "APPR", "PIAT", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruf ich froh in Sonnenschein:", "tokens": ["Ruf", "ich", "froh", "in", "Son\u00b7nen\u00b7schein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Krankheit auch ist Gottes Gabe!", "tokens": ["Krank\u00b7heit", "auch", "ist", "Got\u00b7tes", "Ga\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er soll drum gepriesen sein!", "tokens": ["Er", "soll", "drum", "ge\u00b7prie\u00b7sen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "VVPP", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Jetzt, da ichs bestanden habe,", "tokens": ["Jetzt", ",", "da", "ichs", "be\u00b7stan\u00b7den", "ha\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leuchtet mirs erst deutlich ein:", "tokens": ["Leuch\u00b7tet", "mirs", "erst", "deut\u00b7lich", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Krankheit, du bist Gottes Gabe!", "tokens": ["Krank\u00b7heit", ",", "du", "bist", "Got\u00b7tes", "Ga\u00b7be", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er soll drum gepriesen sein!", "tokens": ["Er", "soll", "drum", "ge\u00b7prie\u00b7sen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "VVPP", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Wie der Mensch dich schwer bek\u00e4mpfe,", "tokens": ["Wie", "der", "Mensch", "dich", "schwer", "be\u00b7k\u00e4mp\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch im Ringen allzumal", "tokens": ["Doch", "im", "Rin\u00b7gen", "all\u00b7zu\u00b7mal"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00f6sen sich der Seele Kr\u00e4mpfe,", "tokens": ["L\u00f6\u00b7sen", "sich", "der", "See\u00b7le", "Kr\u00e4mp\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Innrer Schmerz in \u00e4u\u00dfrer Qual.", "tokens": ["Inn\u00b7rer", "Schmerz", "in", "\u00e4u\u00df\u00b7rer", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Besserst an der Menschheit Bilde,", "tokens": ["Bes\u00b7serst", "an", "der", "Menschheit", "Bil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Scharfe Z\u00fcge m\u00e4\u00dfigst du:", "tokens": ["Schar\u00b7fe", "Z\u00fc\u00b7ge", "m\u00e4\u00b7\u00dfigst", "du", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "War sonst rauh, jetzt bin ich milde,", "tokens": ["War", "sonst", "rauh", ",", "jetzt", "bin", "ich", "mil\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unst\u00e4t sonst und jetzt in Ruh.", "tokens": ["Un\u00b7st\u00e4t", "sonst", "und", "jetzt", "in", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Auch die andern, die da kamen,", "tokens": ["Auch", "die", "an\u00b7dern", ",", "die", "da", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Waren alle gut und weich,", "tokens": ["Wa\u00b7ren", "al\u00b7le", "gut", "und", "weich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil sie mich als Gleichen nahmen:", "tokens": ["Weil", "sie", "mich", "als", "Glei\u00b7chen", "nah\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "KOUS", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleiches Leiden macht ja gleich.", "tokens": ["Glei\u00b7ches", "Lei\u00b7den", "macht", "ja", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ob man sonst nach Fernem jage,", "tokens": ["Ob", "man", "sonst", "nach", "Fer\u00b7nem", "ja\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Setzest du ein n\u00e4her Ziel,", "tokens": ["Set\u00b7zest", "du", "ein", "n\u00e4\u00b7her", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Machst den Tag zum Ziel dem Tage,", "tokens": ["Machst", "den", "Tag", "zum", "Ziel", "dem", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine ruh'ge Nacht scheint viel;", "tokens": ["Ei\u00b7ne", "ruh'\u00b7ge", "Nacht", "scheint", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Und der Wunsch \u00fcbt in Beschwerden", "tokens": ["Und", "der", "Wunsch", "\u00fcbt", "in", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ans Gebi\u00df den stolzen Mund:", "tokens": ["Ans", "Ge\u00b7bi\u00df", "den", "stol\u00b7zen", "Mund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Frage nicht: was soll ich werden?", "tokens": ["Fra\u00b7ge", "nicht", ":", "was", "soll", "ich", "wer\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$.", "PWS", "VMFIN", "PPER", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bin ich jetzo doch gesund.", "tokens": ["Bin", "ich", "jet\u00b7zo", "doch", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Das Gem\u00fct, verstockt, verquollen,", "tokens": ["Das", "Ge\u00b7m\u00fct", ",", "ver\u00b7stockt", ",", "ver\u00b7quol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von so manchem, das es trug,", "tokens": ["Von", "so", "man\u00b7chem", ",", "das", "es", "trug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00d6ffnet sich, wie Ackers Schollen,", "tokens": ["\u00d6ff\u00b7net", "sich", ",", "wie", "A\u00b7ckers", "Schol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "PWAV", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aufgelockert durch den Pflug,", "tokens": ["Auf\u00b7ge\u00b7lo\u00b7ckert", "durch", "den", "Pflug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Und, als ob der Lenz erwache", "tokens": ["Und", ",", "als", "ob", "der", "Lenz", "er\u00b7wa\u00b7che"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOKOM", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "All mit seiner Freuden Chor,", "tokens": ["All", "mit", "sei\u00b7ner", "Freu\u00b7den", "Chor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Treibt es nach der langen Brache", "tokens": ["Treibt", "es", "nach", "der", "lan\u00b7gen", "Bra\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gr\u00fcne Spitzen neu hervor.", "tokens": ["Gr\u00fc\u00b7ne", "Spit\u00b7zen", "neu", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Wie ist all mein Innres offen!", "tokens": ["Wie", "ist", "all", "mein", "Inn\u00b7res", "of\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIAT", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie verdoppelt jeder Sinn!", "tokens": ["Wie", "ver\u00b7dop\u00b7pelt", "je\u00b7der", "Sinn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nachbild hat das Bild getroffen,", "tokens": ["Nach\u00b7bild", "hat", "das", "Bild", "ge\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jeder Augenblick Gewinn!", "tokens": ["Je\u00b7der", "Au\u00b7gen\u00b7blick", "Ge\u00b7winn", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Was ich lese, seh ich stehen,", "tokens": ["Was", "ich", "le\u00b7se", ",", "seh", "ich", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ich h\u00f6re, wird ein Bild,", "tokens": ["Was", "ich", "h\u00f6\u00b7re", ",", "wird", "ein", "Bild", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ich spreche, wird geschehen,", "tokens": ["Was", "ich", "spre\u00b7che", ",", "wird", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich w\u00fcnsche, wird erf\u00fcllt.", "tokens": ["Was", "ich", "w\u00fcn\u00b7sche", ",", "wird", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Mit der Welt in tiefem Frieden,", "tokens": ["Mit", "der", "Welt", "in", "tie\u00b7fem", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und in Frieden auch mit mir,", "tokens": ["Und", "in", "Frie\u00b7den", "auch", "mit", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dank ich ", "tokens": ["Dank", "ich"], "token_info": ["word", "word"], "pos": ["APPR", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Sich geoffenbaret hier,", "tokens": ["Sich", "ge\u00b7of\u00b7fen\u00b7ba\u00b7ret", "hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Und, erquickt von all der Labe,", "tokens": ["Und", ",", "er\u00b7quickt", "von", "all", "der", "La\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVPP", "APPR", "PIAT", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruf ich froh in Sonnenschein:", "tokens": ["Ruf", "ich", "froh", "in", "Son\u00b7nen\u00b7schein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Krankheit auch ist Gottes Gabe!", "tokens": ["Krank\u00b7heit", "auch", "ist", "Got\u00b7tes", "Ga\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er soll drum gepriesen sein!", "tokens": ["Er", "soll", "drum", "ge\u00b7prie\u00b7sen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "VVPP", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}