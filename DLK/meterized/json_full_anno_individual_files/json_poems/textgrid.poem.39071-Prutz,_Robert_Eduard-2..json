{"textgrid.poem.39071": {"metadata": {"author": {"name": "Prutz, Robert Eduard", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sitz' ich dann vor meinem Hause,", "tokens": ["Sitz'", "ich", "dann", "vor", "mei\u00b7nem", "Hau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "munter, wie ein Vollmond gl\u00e4nzend,", "tokens": ["mun\u00b7ter", ",", "wie", "ein", "Voll\u00b7mond", "gl\u00e4n\u00b7zend", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "neben mir ein holdes M\u00e4dchen,", "tokens": ["ne\u00b7ben", "mir", "ein", "hol\u00b7des", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "meinen Scherbet mir kredenzend:", "tokens": ["mei\u00b7nen", "Scher\u00b7bet", "mir", "kre\u00b7den\u00b7zend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.5": {"text": "Nun, wenn Allah so gewollt hat,", "tokens": ["Nun", ",", "wenn", "Al\u00b7lah", "so", "ge\u00b7wollt", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "NN", "ADV", "VMPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "kann es wohl einmal geschehen,", "tokens": ["kann", "es", "wohl", "ein\u00b7mal", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da\u00df der Sultan, Sohn der Sonne,", "tokens": ["da\u00df", "der", "Sul\u00b7tan", ",", "Sohn", "der", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "wird an mir vor\u00fcbergehn.", "tokens": ["wird", "an", "mir", "vor\u00b7\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hurtig vor dem Herrn der Erde", "tokens": ["Hur\u00b7tig", "vor", "dem", "Herrn", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in den Staub werd' ich mich b\u00fccken,", "tokens": ["in", "den", "Staub", "werd'", "ich", "mich", "b\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "seines Fu\u00dfes heil'ge Spuren", "tokens": ["sei\u00b7nes", "Fu\u00b7\u00dfes", "heil'\u00b7ge", "Spu\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "werd' ich k\u00fcssen voll Entz\u00fccken:", "tokens": ["werd'", "ich", "k\u00fcs\u00b7sen", "voll", "Ent\u00b7z\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann vielleicht auf meinem Schmerbauch,", "tokens": ["Dann", "viel\u00b7leicht", "auf", "mei\u00b7nem", "Schmer\u00b7bauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "auf den Wangen ohne Runzeln", "tokens": ["auf", "den", "Wan\u00b7gen", "oh\u00b7ne", "Run\u00b7zeln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "l\u00e4\u00dft er dann sein Auge ruhen,", "tokens": ["l\u00e4\u00dft", "er", "dann", "sein", "Au\u00b7ge", "ru\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "und er spricht zu mir mit Schmunzeln:", "tokens": ["und", "er", "spricht", "zu", "mir", "mit", "Schmun\u00b7zeln", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbwie so glatt sind deine Wangen,", "tokens": ["\u00bb", "wie", "so", "glatt", "sind", "dei\u00b7ne", "Wan\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ADV", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und dein Bauch, was der so rund ist!", "tokens": ["und", "dein", "Bauch", ",", "was", "der", "so", "rund", "ist", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ART", "ADV", "ADJD", "VAFIN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Daraus seh' ich, Knecht der Knechte,", "tokens": ["Da\u00b7raus", "seh'", "ich", ",", "Knecht", "der", "Knech\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df dein Beutel sehr gesund ist.", "tokens": ["da\u00df", "dein", "Beu\u00b7tel", "sehr", "ge\u00b7sund", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also gleich von allem sollst du", "tokens": ["Al\u00b7so", "gleich", "von", "al\u00b7lem", "sollst", "du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PIS", "VMFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mir die H\u00e4lfte wiedergeben!", "tokens": ["mir", "die", "H\u00e4lf\u00b7te", "wie\u00b7der\u00b7ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Schenken werd' ich dir die andre", "tokens": ["Schen\u00b7ken", "werd'", "ich", "dir", "die", "and\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "PPER", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "und zum Vezier dich erheben.\u00ab", "tokens": ["und", "zum", "Ve\u00b7zier", "dich", "er\u00b7he\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPRART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Also wird der Sultan sprechen;", "tokens": ["Al\u00b7so", "wird", "der", "Sul\u00b7tan", "spre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mit gn\u00e4digem Behagen", "tokens": ["und", "mit", "gn\u00e4\u00b7di\u00b7gem", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "(wenn dies nicht zuviel ist) gibt er", "tokens": ["(", "wenn", "dies", "nicht", "zu\u00b7viel", "ist", ")", "gibt", "er"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "KOUS", "PDS", "PTKNEG", "PIS", "VAFIN", "$(", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einen Tritt mir auf den Magen.", "tokens": ["ei\u00b7nen", "Tritt", "mir", "auf", "den", "Ma\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Selig werd' ich mich erheben,", "tokens": ["Se\u00b7lig", "werd'", "ich", "mich", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "meine Sch\u00e4tze flink zu teilen,", "tokens": ["mei\u00b7ne", "Sch\u00e4t\u00b7ze", "flink", "zu", "tei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "dann als Vezier an die goldnen", "tokens": ["dann", "als", "Ve\u00b7zier", "an", "die", "gold\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NN", "APPR", "ART", "ADJA"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Stufen seines Thrones eilen.", "tokens": ["Stu\u00b7fen", "sei\u00b7nes", "Thro\u00b7nes", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Fragt ihr nun, wie ich es f\u00fcrder", "tokens": ["Fragt", "ihr", "nun", ",", "wie", "ich", "es", "f\u00fcr\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "PPER", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "als Minister werde treiben?", "tokens": ["als", "Mi\u00b7nis\u00b7ter", "wer\u00b7de", "trei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun, versteht sich: als Minister!", "tokens": ["Nun", ",", "ver\u00b7steht", "sich", ":", "als", "Mi\u00b7nis\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PRF", "$.", "KOUS", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles wird beim alten bleiben:", "tokens": ["Al\u00b7les", "wird", "beim", "al\u00b7ten", "blei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPRART", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nur die Steuern werden steigen,", "tokens": ["Nur", "die", "Steu\u00b7ern", "wer\u00b7den", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nur die Galgen sich vermehren,", "tokens": ["nur", "die", "Gal\u00b7gen", "sich", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "um Verweichlichung und Luxus", "tokens": ["um", "Ver\u00b7weich\u00b7li\u00b7chung", "und", "Lu\u00b7xus"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "von den B\u00fcrgern abzuwehren.", "tokens": ["von", "den", "B\u00fcr\u00b7gern", "ab\u00b7zu\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Tag f\u00fcr Tag, mit ernster Miene,", "tokens": ["Tag", "f\u00fcr", "Tag", ",", "mit", "erns\u00b7ter", "Mie\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in dem Divan werd' ich sitzen,", "tokens": ["in", "dem", "Di\u00b7van", "werd'", "ich", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "alle, die mein Antlitz schauen,", "tokens": ["al\u00b7le", ",", "die", "mein", "Ant\u00b7litz", "schau\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sollen vor Bewundrung schwitzen.", "tokens": ["sol\u00b7len", "vor", "Be\u00b7wund\u00b7rung", "schwit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sollten mal Parteien kommen,", "tokens": ["Soll\u00b7ten", "mal", "Par\u00b7tei\u00b7en", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo ich nicht wei\u00df zu entscheiden:", "tokens": ["wo", "ich", "nicht", "wei\u00df", "zu", "ent\u00b7schei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.7": {"text": "Hundert Pr\u00fcgel dann diktier' ich", "tokens": ["Hun\u00b7dert", "Pr\u00fc\u00b7gel", "dann", "dik\u00b7tier'", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "VVFIN", "PPER"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "salomonisch allen beiden. \u2013", "tokens": ["sa\u00b7lo\u00b7mo\u00b7nisch", "al\u00b7len", "bei\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PIAT", "PIS", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "K\u00e4me dann vor meine Stufen", "tokens": ["K\u00e4\u00b7me", "dann", "vor", "mei\u00b7ne", "Stu\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ein europam\u00fcder Dichter,", "tokens": ["ein", "eu\u00b7ro\u00b7pa\u00b7m\u00fc\u00b7der", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "so ein Dingelstedt und Herwegh,", "tokens": ["so", "ein", "Din\u00b7gel\u00b7stedt", "und", "Her\u00b7wegh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "oder \u00e4hnliches Gelichter,", "tokens": ["o\u00b7der", "\u00e4hn\u00b7li\u00b7ches", "Ge\u00b7lich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "die mit ihren frechen Liedern,", "tokens": ["die", "mit", "ih\u00b7ren", "fre\u00b7chen", "Lie\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Freiheitjubel, Freiheitschmerzen,", "tokens": ["Frei\u00b7heit\u00b7ju\u00b7bel", ",", "Frei\u00b7heitsc\u00b7hmer\u00b7zen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wahre Drachenz\u00e4hne streuen", "tokens": ["wah\u00b7re", "Dra\u00b7chen\u00b7z\u00e4h\u00b7ne", "streu\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "in der B\u00fcrger treue Herzen:", "tokens": ["in", "der", "B\u00fcr\u00b7ger", "treu\u00b7e", "Her\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nun, nicht wahr? Ihr meint, ich lie\u00dfe", "tokens": ["Nun", ",", "nicht", "wahr", "?", "Ihr", "meint", ",", "ich", "lie\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "PTKNEG", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ohne weiteres sie s\u00e4cken?", "tokens": ["oh\u00b7ne", "wei\u00b7te\u00b7res", "sie", "s\u00e4\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weit gefehlt! In meinen Harem", "tokens": ["Weit", "ge\u00b7fehlt", "!", "In", "mei\u00b7nen", "Ha\u00b7rem"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVPP", "$.", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lie\u00df ich diese Burschen stecken,", "tokens": ["lie\u00df", "ich", "die\u00b7se", "Bur\u00b7schen", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "zu der allersch\u00f6nsten Sklavin", "tokens": ["zu", "der", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "Skla\u00b7vin"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "mit den schw\u00e4rzsten Augensternen \u2013", "tokens": ["mit", "den", "schw\u00e4rz\u00b7sten", "Au\u00b7gens\u00b7ter\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und ich wette drauf, sie w\u00fcrden", "tokens": ["und", "ich", "wet\u00b7te", "drauf", ",", "sie", "w\u00fcr\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "ihre Poesie verlernen!", "tokens": ["ih\u00b7re", "Poe\u00b7sie", "ver\u00b7ler\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.9": {"line.1": {"text": "Aber will auch das nicht helfen,", "tokens": ["A\u00b7ber", "will", "auch", "das", "nicht", "hel\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PDS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wider menschliches Vermuten:", "tokens": ["wi\u00b7der", "menschli\u00b7ches", "Ver\u00b7mu\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Sei's darum! In Gottes Namen", "tokens": ["Sei's", "da\u00b7rum", "!", "In", "Got\u00b7tes", "Na\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PAV", "$.", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "singen lie\u00df' ich dann die Guten.", "tokens": ["sin\u00b7gen", "lie\u00df'", "ich", "dann", "die", "Gu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bin ich doch kein deutscher K\u00f6nig!", "tokens": ["Bin", "ich", "doch", "kein", "deut\u00b7scher", "K\u00f6\u00b7nig", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und so will ich's ihnen g\u00f6nnen,", "tokens": ["Und", "so", "will", "ich's", "ih\u00b7nen", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PIS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da ich wei\u00df, da\u00df meinen T\u00fcrken", "tokens": ["da", "ich", "wei\u00df", ",", "da\u00df", "mei\u00b7nen", "T\u00fcr\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "sie ja doch nicht schaden k\u00f6nnen.", "tokens": ["sie", "ja", "doch", "nicht", "scha\u00b7den", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00dcbrigens um die Regierung", "tokens": ["\u00dcb\u00b7ri\u00b7gens", "um", "die", "Re\u00b7gie\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "w\u00fcrd' ich mich nur wenig gr\u00e4men:", "tokens": ["w\u00fcrd'", "ich", "mich", "nur", "we\u00b7nig", "gr\u00e4\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn kein Geld im Schatze w\u00e4re,", "tokens": ["Wenn", "kein", "Geld", "im", "Schat\u00b7ze", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "w\u00fcrd' ich borgen oder nehmen.", "tokens": ["w\u00fcrd'", "ich", "bor\u00b7gen", "o\u00b7der", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wenn etwa der \u00c4gypter", "tokens": ["Und", "wenn", "et\u00b7wa", "der", "\u00c4\u00b7gyp\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "unsre Truppen sollte schlagen \u2013", "tokens": ["uns\u00b7re", "Trup\u00b7pen", "soll\u00b7te", "schla\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Gott ist gro\u00df! Er wird die Feinde,", "tokens": ["Gott", "ist", "gro\u00df", "!", "Er", "wird", "die", "Fein\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "wenn es Zeit ist, schon verjagen.", "tokens": ["wenn", "es", "Zeit", "ist", ",", "schon", "ver\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "$,", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Zwar der Sultan wird mir z\u00fcrnen,", "tokens": ["Zwar", "der", "Sul\u00b7tan", "wird", "mir", "z\u00fcr\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und dann wird das Schauspiel enden.", "tokens": ["und", "dann", "wird", "das", "Schau\u00b7spiel", "en\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Schnur, recht eine h\u00fcbsche", "tokens": ["Ei\u00b7ne", "Schnur", ",", "recht", "ei\u00b7ne", "h\u00fcb\u00b7sche"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "seidne Schnur wird er mir senden \u2013", "tokens": ["seid\u00b7ne", "Schnur", "wird", "er", "mir", "sen\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$("], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Wohl zu merken: Ein Verfahren,", "tokens": ["Wohl", "zu", "mer\u00b7ken", ":", "Ein", "Ver\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$.", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das man auch Europas Kronen", "tokens": ["das", "man", "auch", "Eu\u00b7ro\u00b7pas", "Kro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "NE", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "ernst und dringend soll empfehlen;", "tokens": ["ernst", "und", "drin\u00b7gend", "soll", "emp\u00b7feh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "denn es spart die Pensionen \u2013", "tokens": ["denn", "es", "spart", "die", "Pen\u00b7si\u00b7o\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch mit der gewohnten Demut", "tokens": ["Doch", "mit", "der", "ge\u00b7wohn\u00b7ten", "De\u00b7mut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "----+---", "measure": "unknown.measure.single"}, "line.2": {"text": "seinen Willen w\u00fcrd' ich ehren,", "tokens": ["sei\u00b7nen", "Wil\u00b7len", "w\u00fcrd'", "ich", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "lie\u00df' den Bart noch einmal salben,", "tokens": ["lie\u00df'", "den", "Bart", "noch", "ein\u00b7mal", "sal\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einmal noch den Schopf mir scheren:", "tokens": ["ein\u00b7mal", "noch", "den", "Schopf", "mir", "sche\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann die allerliebste Schlinge", "tokens": ["Dann", "die", "al\u00b7ler\u00b7liebs\u00b7te", "Schlin\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "um die fette Kehle kn\u00fcpft' ich \u2013", "tokens": ["um", "die", "fet\u00b7te", "Keh\u00b7le", "kn\u00fcpft'", "ich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ein Moment! Und ohne weitres", "tokens": ["ein", "Mo\u00b7ment", "!", "Und", "oh\u00b7ne", "weit\u00b7res"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$.", "KON", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "in den Garten Gottes schl\u00fcpft' ich.", "tokens": ["in", "den", "Gar\u00b7ten", "Got\u00b7tes", "schl\u00fcpft'", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ha, was dort f\u00fcr eine Pracht ist!", "tokens": ["Ha", ",", "was", "dort", "f\u00fcr", "ei\u00b7ne", "Pracht", "ist", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PRELS", "ADV", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was f\u00fcr Essen, was f\u00fcr Trinken!", "tokens": ["Was", "f\u00fcr", "Es\u00b7sen", ",", "was", "f\u00fcr", "Trin\u00b7ken", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "$,", "PRELS", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die uns der Prophet verhei\u00dfen,", "tokens": ["Die", "uns", "der", "Pro\u00b7phet", "ver\u00b7hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "s\u00fc\u00dfe Huris seh' ich winken \u2013", "tokens": ["s\u00fc\u00b7\u00dfe", "Hu\u00b7ris", "seh'", "ich", "win\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "O verdammt, da\u00df ich als Deutscher,", "tokens": ["O", "ver\u00b7dammt", ",", "da\u00df", "ich", "als", "Deut\u00b7scher", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$,", "KOUS", "PPER", "KOUS", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nicht als T\u00fcrke bin geboren!", "tokens": ["nicht", "als", "T\u00fcr\u00b7ke", "bin", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUS", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn so geht zusamt der Erde", "tokens": ["Denn", "so", "geht", "zu\u00b7samt", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "auch der Himmel mir verloren.", "tokens": ["auch", "der", "Him\u00b7mel", "mir", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Sitz' ich dann vor meinem Hause,", "tokens": ["Sitz'", "ich", "dann", "vor", "mei\u00b7nem", "Hau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "munter, wie ein Vollmond gl\u00e4nzend,", "tokens": ["mun\u00b7ter", ",", "wie", "ein", "Voll\u00b7mond", "gl\u00e4n\u00b7zend", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "neben mir ein holdes M\u00e4dchen,", "tokens": ["ne\u00b7ben", "mir", "ein", "hol\u00b7des", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "meinen Scherbet mir kredenzend:", "tokens": ["mei\u00b7nen", "Scher\u00b7bet", "mir", "kre\u00b7den\u00b7zend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.5": {"text": "Nun, wenn Allah so gewollt hat,", "tokens": ["Nun", ",", "wenn", "Al\u00b7lah", "so", "ge\u00b7wollt", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "NN", "ADV", "VMPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "kann es wohl einmal geschehen,", "tokens": ["kann", "es", "wohl", "ein\u00b7mal", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da\u00df der Sultan, Sohn der Sonne,", "tokens": ["da\u00df", "der", "Sul\u00b7tan", ",", "Sohn", "der", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "wird an mir vor\u00fcbergehn.", "tokens": ["wird", "an", "mir", "vor\u00b7\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Hurtig vor dem Herrn der Erde", "tokens": ["Hur\u00b7tig", "vor", "dem", "Herrn", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in den Staub werd' ich mich b\u00fccken,", "tokens": ["in", "den", "Staub", "werd'", "ich", "mich", "b\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "seines Fu\u00dfes heil'ge Spuren", "tokens": ["sei\u00b7nes", "Fu\u00b7\u00dfes", "heil'\u00b7ge", "Spu\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "werd' ich k\u00fcssen voll Entz\u00fccken:", "tokens": ["werd'", "ich", "k\u00fcs\u00b7sen", "voll", "Ent\u00b7z\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann vielleicht auf meinem Schmerbauch,", "tokens": ["Dann", "viel\u00b7leicht", "auf", "mei\u00b7nem", "Schmer\u00b7bauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "auf den Wangen ohne Runzeln", "tokens": ["auf", "den", "Wan\u00b7gen", "oh\u00b7ne", "Run\u00b7zeln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "l\u00e4\u00dft er dann sein Auge ruhen,", "tokens": ["l\u00e4\u00dft", "er", "dann", "sein", "Au\u00b7ge", "ru\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "und er spricht zu mir mit Schmunzeln:", "tokens": ["und", "er", "spricht", "zu", "mir", "mit", "Schmun\u00b7zeln", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bbwie so glatt sind deine Wangen,", "tokens": ["\u00bb", "wie", "so", "glatt", "sind", "dei\u00b7ne", "Wan\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ADV", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und dein Bauch, was der so rund ist!", "tokens": ["und", "dein", "Bauch", ",", "was", "der", "so", "rund", "ist", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ART", "ADV", "ADJD", "VAFIN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Daraus seh' ich, Knecht der Knechte,", "tokens": ["Da\u00b7raus", "seh'", "ich", ",", "Knecht", "der", "Knech\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df dein Beutel sehr gesund ist.", "tokens": ["da\u00df", "dein", "Beu\u00b7tel", "sehr", "ge\u00b7sund", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also gleich von allem sollst du", "tokens": ["Al\u00b7so", "gleich", "von", "al\u00b7lem", "sollst", "du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PIS", "VMFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mir die H\u00e4lfte wiedergeben!", "tokens": ["mir", "die", "H\u00e4lf\u00b7te", "wie\u00b7der\u00b7ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Schenken werd' ich dir die andre", "tokens": ["Schen\u00b7ken", "werd'", "ich", "dir", "die", "and\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "PPER", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "und zum Vezier dich erheben.\u00ab", "tokens": ["und", "zum", "Ve\u00b7zier", "dich", "er\u00b7he\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPRART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Also wird der Sultan sprechen;", "tokens": ["Al\u00b7so", "wird", "der", "Sul\u00b7tan", "spre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mit gn\u00e4digem Behagen", "tokens": ["und", "mit", "gn\u00e4\u00b7di\u00b7gem", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "(wenn dies nicht zuviel ist) gibt er", "tokens": ["(", "wenn", "dies", "nicht", "zu\u00b7viel", "ist", ")", "gibt", "er"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "KOUS", "PDS", "PTKNEG", "PIS", "VAFIN", "$(", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einen Tritt mir auf den Magen.", "tokens": ["ei\u00b7nen", "Tritt", "mir", "auf", "den", "Ma\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Selig werd' ich mich erheben,", "tokens": ["Se\u00b7lig", "werd'", "ich", "mich", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "meine Sch\u00e4tze flink zu teilen,", "tokens": ["mei\u00b7ne", "Sch\u00e4t\u00b7ze", "flink", "zu", "tei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "dann als Vezier an die goldnen", "tokens": ["dann", "als", "Ve\u00b7zier", "an", "die", "gold\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NN", "APPR", "ART", "ADJA"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Stufen seines Thrones eilen.", "tokens": ["Stu\u00b7fen", "sei\u00b7nes", "Thro\u00b7nes", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Fragt ihr nun, wie ich es f\u00fcrder", "tokens": ["Fragt", "ihr", "nun", ",", "wie", "ich", "es", "f\u00fcr\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "PPER", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "als Minister werde treiben?", "tokens": ["als", "Mi\u00b7nis\u00b7ter", "wer\u00b7de", "trei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun, versteht sich: als Minister!", "tokens": ["Nun", ",", "ver\u00b7steht", "sich", ":", "als", "Mi\u00b7nis\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PRF", "$.", "KOUS", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles wird beim alten bleiben:", "tokens": ["Al\u00b7les", "wird", "beim", "al\u00b7ten", "blei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPRART", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nur die Steuern werden steigen,", "tokens": ["Nur", "die", "Steu\u00b7ern", "wer\u00b7den", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nur die Galgen sich vermehren,", "tokens": ["nur", "die", "Gal\u00b7gen", "sich", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "um Verweichlichung und Luxus", "tokens": ["um", "Ver\u00b7weich\u00b7li\u00b7chung", "und", "Lu\u00b7xus"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "von den B\u00fcrgern abzuwehren.", "tokens": ["von", "den", "B\u00fcr\u00b7gern", "ab\u00b7zu\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Tag f\u00fcr Tag, mit ernster Miene,", "tokens": ["Tag", "f\u00fcr", "Tag", ",", "mit", "erns\u00b7ter", "Mie\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in dem Divan werd' ich sitzen,", "tokens": ["in", "dem", "Di\u00b7van", "werd'", "ich", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "alle, die mein Antlitz schauen,", "tokens": ["al\u00b7le", ",", "die", "mein", "Ant\u00b7litz", "schau\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sollen vor Bewundrung schwitzen.", "tokens": ["sol\u00b7len", "vor", "Be\u00b7wund\u00b7rung", "schwit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sollten mal Parteien kommen,", "tokens": ["Soll\u00b7ten", "mal", "Par\u00b7tei\u00b7en", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo ich nicht wei\u00df zu entscheiden:", "tokens": ["wo", "ich", "nicht", "wei\u00df", "zu", "ent\u00b7schei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.7": {"text": "Hundert Pr\u00fcgel dann diktier' ich", "tokens": ["Hun\u00b7dert", "Pr\u00fc\u00b7gel", "dann", "dik\u00b7tier'", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "VVFIN", "PPER"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "salomonisch allen beiden. \u2013", "tokens": ["sa\u00b7lo\u00b7mo\u00b7nisch", "al\u00b7len", "bei\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PIAT", "PIS", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "K\u00e4me dann vor meine Stufen", "tokens": ["K\u00e4\u00b7me", "dann", "vor", "mei\u00b7ne", "Stu\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ein europam\u00fcder Dichter,", "tokens": ["ein", "eu\u00b7ro\u00b7pa\u00b7m\u00fc\u00b7der", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "so ein Dingelstedt und Herwegh,", "tokens": ["so", "ein", "Din\u00b7gel\u00b7stedt", "und", "Her\u00b7wegh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "oder \u00e4hnliches Gelichter,", "tokens": ["o\u00b7der", "\u00e4hn\u00b7li\u00b7ches", "Ge\u00b7lich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "die mit ihren frechen Liedern,", "tokens": ["die", "mit", "ih\u00b7ren", "fre\u00b7chen", "Lie\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Freiheitjubel, Freiheitschmerzen,", "tokens": ["Frei\u00b7heit\u00b7ju\u00b7bel", ",", "Frei\u00b7heitsc\u00b7hmer\u00b7zen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wahre Drachenz\u00e4hne streuen", "tokens": ["wah\u00b7re", "Dra\u00b7chen\u00b7z\u00e4h\u00b7ne", "streu\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "in der B\u00fcrger treue Herzen:", "tokens": ["in", "der", "B\u00fcr\u00b7ger", "treu\u00b7e", "Her\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Nun, nicht wahr? Ihr meint, ich lie\u00dfe", "tokens": ["Nun", ",", "nicht", "wahr", "?", "Ihr", "meint", ",", "ich", "lie\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "PTKNEG", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ohne weiteres sie s\u00e4cken?", "tokens": ["oh\u00b7ne", "wei\u00b7te\u00b7res", "sie", "s\u00e4\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weit gefehlt! In meinen Harem", "tokens": ["Weit", "ge\u00b7fehlt", "!", "In", "mei\u00b7nen", "Ha\u00b7rem"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVPP", "$.", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lie\u00df ich diese Burschen stecken,", "tokens": ["lie\u00df", "ich", "die\u00b7se", "Bur\u00b7schen", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "zu der allersch\u00f6nsten Sklavin", "tokens": ["zu", "der", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "Skla\u00b7vin"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "mit den schw\u00e4rzsten Augensternen \u2013", "tokens": ["mit", "den", "schw\u00e4rz\u00b7sten", "Au\u00b7gens\u00b7ter\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und ich wette drauf, sie w\u00fcrden", "tokens": ["und", "ich", "wet\u00b7te", "drauf", ",", "sie", "w\u00fcr\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "ihre Poesie verlernen!", "tokens": ["ih\u00b7re", "Poe\u00b7sie", "ver\u00b7ler\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.22": {"line.1": {"text": "Aber will auch das nicht helfen,", "tokens": ["A\u00b7ber", "will", "auch", "das", "nicht", "hel\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PDS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wider menschliches Vermuten:", "tokens": ["wi\u00b7der", "menschli\u00b7ches", "Ver\u00b7mu\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Sei's darum! In Gottes Namen", "tokens": ["Sei's", "da\u00b7rum", "!", "In", "Got\u00b7tes", "Na\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PAV", "$.", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "singen lie\u00df' ich dann die Guten.", "tokens": ["sin\u00b7gen", "lie\u00df'", "ich", "dann", "die", "Gu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bin ich doch kein deutscher K\u00f6nig!", "tokens": ["Bin", "ich", "doch", "kein", "deut\u00b7scher", "K\u00f6\u00b7nig", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und so will ich's ihnen g\u00f6nnen,", "tokens": ["Und", "so", "will", "ich's", "ih\u00b7nen", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PIS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da ich wei\u00df, da\u00df meinen T\u00fcrken", "tokens": ["da", "ich", "wei\u00df", ",", "da\u00df", "mei\u00b7nen", "T\u00fcr\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "sie ja doch nicht schaden k\u00f6nnen.", "tokens": ["sie", "ja", "doch", "nicht", "scha\u00b7den", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "\u00dcbrigens um die Regierung", "tokens": ["\u00dcb\u00b7ri\u00b7gens", "um", "die", "Re\u00b7gie\u00b7rung"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "w\u00fcrd' ich mich nur wenig gr\u00e4men:", "tokens": ["w\u00fcrd'", "ich", "mich", "nur", "we\u00b7nig", "gr\u00e4\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn kein Geld im Schatze w\u00e4re,", "tokens": ["Wenn", "kein", "Geld", "im", "Schat\u00b7ze", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "w\u00fcrd' ich borgen oder nehmen.", "tokens": ["w\u00fcrd'", "ich", "bor\u00b7gen", "o\u00b7der", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wenn etwa der \u00c4gypter", "tokens": ["Und", "wenn", "et\u00b7wa", "der", "\u00c4\u00b7gyp\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "unsre Truppen sollte schlagen \u2013", "tokens": ["uns\u00b7re", "Trup\u00b7pen", "soll\u00b7te", "schla\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Gott ist gro\u00df! Er wird die Feinde,", "tokens": ["Gott", "ist", "gro\u00df", "!", "Er", "wird", "die", "Fein\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "wenn es Zeit ist, schon verjagen.", "tokens": ["wenn", "es", "Zeit", "ist", ",", "schon", "ver\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "$,", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Zwar der Sultan wird mir z\u00fcrnen,", "tokens": ["Zwar", "der", "Sul\u00b7tan", "wird", "mir", "z\u00fcr\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und dann wird das Schauspiel enden.", "tokens": ["und", "dann", "wird", "das", "Schau\u00b7spiel", "en\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Schnur, recht eine h\u00fcbsche", "tokens": ["Ei\u00b7ne", "Schnur", ",", "recht", "ei\u00b7ne", "h\u00fcb\u00b7sche"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "seidne Schnur wird er mir senden \u2013", "tokens": ["seid\u00b7ne", "Schnur", "wird", "er", "mir", "sen\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$("], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Wohl zu merken: Ein Verfahren,", "tokens": ["Wohl", "zu", "mer\u00b7ken", ":", "Ein", "Ver\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$.", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das man auch Europas Kronen", "tokens": ["das", "man", "auch", "Eu\u00b7ro\u00b7pas", "Kro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "NE", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "ernst und dringend soll empfehlen;", "tokens": ["ernst", "und", "drin\u00b7gend", "soll", "emp\u00b7feh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "denn es spart die Pensionen \u2013", "tokens": ["denn", "es", "spart", "die", "Pen\u00b7si\u00b7o\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Doch mit der gewohnten Demut", "tokens": ["Doch", "mit", "der", "ge\u00b7wohn\u00b7ten", "De\u00b7mut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "----+---", "measure": "unknown.measure.single"}, "line.2": {"text": "seinen Willen w\u00fcrd' ich ehren,", "tokens": ["sei\u00b7nen", "Wil\u00b7len", "w\u00fcrd'", "ich", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "lie\u00df' den Bart noch einmal salben,", "tokens": ["lie\u00df'", "den", "Bart", "noch", "ein\u00b7mal", "sal\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einmal noch den Schopf mir scheren:", "tokens": ["ein\u00b7mal", "noch", "den", "Schopf", "mir", "sche\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann die allerliebste Schlinge", "tokens": ["Dann", "die", "al\u00b7ler\u00b7liebs\u00b7te", "Schlin\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "um die fette Kehle kn\u00fcpft' ich \u2013", "tokens": ["um", "die", "fet\u00b7te", "Keh\u00b7le", "kn\u00fcpft'", "ich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "ein Moment! Und ohne weitres", "tokens": ["ein", "Mo\u00b7ment", "!", "Und", "oh\u00b7ne", "weit\u00b7res"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$.", "KON", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "in den Garten Gottes schl\u00fcpft' ich.", "tokens": ["in", "den", "Gar\u00b7ten", "Got\u00b7tes", "schl\u00fcpft'", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Ha, was dort f\u00fcr eine Pracht ist!", "tokens": ["Ha", ",", "was", "dort", "f\u00fcr", "ei\u00b7ne", "Pracht", "ist", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PRELS", "ADV", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was f\u00fcr Essen, was f\u00fcr Trinken!", "tokens": ["Was", "f\u00fcr", "Es\u00b7sen", ",", "was", "f\u00fcr", "Trin\u00b7ken", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "$,", "PRELS", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die uns der Prophet verhei\u00dfen,", "tokens": ["Die", "uns", "der", "Pro\u00b7phet", "ver\u00b7hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "s\u00fc\u00dfe Huris seh' ich winken \u2013", "tokens": ["s\u00fc\u00b7\u00dfe", "Hu\u00b7ris", "seh'", "ich", "win\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "O verdammt, da\u00df ich als Deutscher,", "tokens": ["O", "ver\u00b7dammt", ",", "da\u00df", "ich", "als", "Deut\u00b7scher", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$,", "KOUS", "PPER", "KOUS", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nicht als T\u00fcrke bin geboren!", "tokens": ["nicht", "als", "T\u00fcr\u00b7ke", "bin", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUS", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn so geht zusamt der Erde", "tokens": ["Denn", "so", "geht", "zu\u00b7samt", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "auch der Himmel mir verloren.", "tokens": ["auch", "der", "Him\u00b7mel", "mir", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}