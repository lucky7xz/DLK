{"dta.poem.21801": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  \n  Das angenehme Gespenst.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Das Wolken-dach war mit der Nacht umzogen/", "tokens": ["Das", "Wol\u00b7ken\u00b7dach", "war", "mit", "der", "Nacht", "um\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Arkas hielt die Mittel-stelle durch den Sternen-", "tokens": ["Ar\u00b7kas", "hielt", "die", "Mit\u00b7tel\u00b7stel\u00b7le", "durch", "den", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN", "APPR", "ART", "TRUNC"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Als Oridor verhindert von den Zug", "tokens": ["Als", "O\u00b7ri\u00b7dor", "ver\u00b7hin\u00b7dert", "von", "den", "Zug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "nach seiner Mele Verlangen trug.", "tokens": ["nach", "sei\u00b7ner", "Me\u00b7le", "Ver\u00b7lan\u00b7gen", "trug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Er lieff entsinnt durch Wiesen/ W\u00e4lder/ Berg und", "tokens": ["Er", "lieff", "ent\u00b7sinnt", "durch", "Wie\u00b7sen", "/", "W\u00e4l\u00b7der", "/", "Berg", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "$(", "NN", "$(", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "das Scheiden bracht ihm Herzens-angst und Qwaal.", "tokens": ["das", "Schei\u00b7den", "bracht", "ihm", "Her\u00b7zens\u00b7angst", "und", "Qwaal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "ach Sch\u00f6ne/ dich", "tokens": ["ach", "Sch\u00f6\u00b7ne", "/", "dich"], "token_info": ["word", "word", "punct", "word"], "pos": ["XY", "NN", "$(", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "noch sehn einmahl!", "tokens": ["noch", "sehn", "ein\u00b7mahl", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "So schrie er bi\u00df er zu der H\u00fctte kahme/", "tokens": ["So", "schrie", "er", "bi\u00df", "er", "zu", "der", "H\u00fct\u00b7te", "kah\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "da/ wo seine Mele die f\u00fcsse Ruh einnahme.", "tokens": ["da", "/", "wo", "sei\u00b7ne", "Me\u00b7le", "die", "f\u00fcs\u00b7se", "Ruh", "ein\u00b7nah\u00b7me", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PWAV", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Kaum r\u00fchrt\u2019 er an den Riegel bey der T\u00fchr/", "tokens": ["Kaum", "r\u00fchrt'", "er", "an", "den", "Rie\u00b7gel", "bey", "der", "T\u00fchr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Werklopffet an so langsam schon nach Mitternacht?", "tokens": ["Wer\u00b7klopf\u00b7fet", "an", "so", "lang\u00b7sam", "schon", "nach", "Mit\u00b7ter\u00b7nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "ADJD", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mach/ M\u00e4gdchen auf! Ja/ bald h\u00e4tt\u2019 ich auf gemacht.", "tokens": ["Mach", "/", "M\u00e4gd\u00b7chen", "auf", "!", "Ja", "/", "bald", "h\u00e4tt'", "ich", "auf", "ge\u00b7macht", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NN", "PTKVZ", "$.", "PTKANT", "$(", "ADV", "VAFIN", "PPER", "APPR", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wer ist denn da?", "tokens": ["Wer", "ist", "denn", "da", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "hastu nicht acht?", "tokens": ["has\u00b7tu", "nicht", "acht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "CARD", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Kennstu nicht mehr der Melen ihren Treuen/", "tokens": ["Kenns\u00b7tu", "nicht", "mehr", "der", "Me\u00b7len", "ih\u00b7ren", "Treu\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADV", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "kan ein halber Tag so bald der Liebe Band entzweyen?", "tokens": ["kan", "ein", "hal\u00b7ber", "Tag", "so", "bald", "der", "Lie\u00b7be", "Band", "ent\u00b7zwe\u00b7yen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "ADV", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Doch sie wei\u00df nichts hiervon das gute Kind/", "tokens": ["Doch", "sie", "wei\u00df", "nichts", "hier\u00b7von", "das", "gu\u00b7te", "Kind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "PAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df Oridor so schnell Abschied find:", "tokens": ["da\u00df", "O\u00b7ri\u00b7dor", "so", "schnell", "Ab\u00b7schied", "find", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ach! m\u00f6chte nur das fromme Herze werden wach", "tokens": ["Ach", "!", "m\u00f6ch\u00b7te", "nur", "das", "from\u00b7me", "Her\u00b7ze", "wer\u00b7den", "wach"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VMFIN", "ADV", "ART", "ADJA", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ich wei\u00df gewi\u00df/ Oridor k\u00e4hm unter Dach.", "tokens": ["ich", "wei\u00df", "ge\u00b7wi\u00df", "/", "O\u00b7ri\u00b7dor", "k\u00e4hm", "un\u00b7ter", "Dach", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "NE", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "ich/ ich vergeh!", "tokens": ["ich", "/", "ich", "ver\u00b7geh", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$(", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "wer fragt darnach.", "tokens": ["wer", "fragt", "dar\u00b7nach", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Der Oridor/ den du hich f\u00e4lschlich nennest/", "tokens": ["Der", "O\u00b7ri\u00b7dor", "/", "den", "du", "hich", "f\u00e4lschlich", "nen\u00b7nest", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "PPER", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "weil du unsrer Hirtin Liebes-Brunst vielleichten ken-", "tokens": ["weil", "du", "uns\u00b7rer", "Hir\u00b7tin", "Lie\u00b7bes\u00b7Brunst", "viel\u00b7leich\u00b7ten", "ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN", "ADJA", "TRUNC"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "ist weit von hier/ wo der Trommeten Hall", "tokens": ["ist", "weit", "von", "hier", "/", "wo", "der", "Trom\u00b7me\u00b7ten", "Hall"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "APPR", "ADV", "$(", "PWAV", "ART", "NN", "NE"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "bed\u00e4mpfft den s\u00fcssen Schallmeien Schall.", "tokens": ["be\u00b7d\u00e4mpfft", "den", "s\u00fcs\u00b7sen", "Schall\u00b7mei\u00b7en", "Schall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Er ist hinweg/ und wolte Gott! er w\u00e4re hier", "tokens": ["Er", "ist", "hin\u00b7weg", "/", "und", "wol\u00b7te", "Gott", "!", "er", "w\u00e4\u00b7re", "hier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "$(", "KON", "VMFIN", "NN", "$.", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "er w\u00fcrde bald weisen dir ein\u2019 andre T\u00fchr/", "tokens": ["er", "w\u00fcr\u00b7de", "bald", "wei\u00b7sen", "dir", "ein'", "and\u00b7re", "T\u00fchr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "es kan nicht sein.", "tokens": ["es", "kan", "nicht", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Geh sag\u2019 es ihr.", "tokens": ["Geh", "sag'", "es", "ihr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Was mag es sein/ da\u00df W\u00e4chter so mu\u00df bellen.", "tokens": ["Was", "mag", "es", "sein", "/", "da\u00df", "W\u00e4ch\u00b7ter", "so", "mu\u00df", "bel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VAINF", "$(", "KOUS", "NE", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mopsa/ Mopsa/ h\u00f6rstu Magd nicht/ wer ist an der", "tokens": ["Mop\u00b7sa", "/", "Mop\u00b7sa", "/", "h\u00f6rs\u00b7tu", "Magd", "nicht", "/", "wer", "ist", "an", "der"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "NE", "$(", "VVFIN", "NN", "PTKNEG", "$(", "PWS", "VAFIN", "APPR", "ART"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ich gl\u00e4ube/ Sakk/ du h\u00e4st dir wen bestellt", "tokens": ["Ich", "gl\u00e4u\u00b7be", "/", "Sakk", "/", "du", "h\u00e4st", "dir", "wen", "be\u00b7stellt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "NE", "$(", "PPER", "VVFIN", "PPER", "PWS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "des Nachbarn Knecht/ der dir so gef\u00e4llt.", "tokens": ["des", "Nach\u00b7barn", "Knecht", "/", "der", "dir", "so", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$(", "PRELS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Mach lieber Feur im Schorrstein/ spinne deine Zahl/", "tokens": ["Mach", "lie\u00b7ber", "Feur", "im", "Schorrs\u00b7tein", "/", "spin\u00b7ne", "dei\u00b7ne", "Zahl", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPRART", "NN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "tezt kreht der Han allbereit zum andernmahl.", "tokens": ["tezt", "kreht", "der", "Han", "all\u00b7be\u00b7reit", "zum", "an\u00b7dern\u00b7mahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPRART", "ADV", "$."], "meter": "----+-+-+-+", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Es ist die Frau/", "tokens": ["Es", "ist", "die", "Frau", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "ich leg mich tahl.", "tokens": ["ich", "leg", "mich", "tahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Was? meinstu so zu bergen deine T\u00fckke?", "tokens": ["Was", "?", "meins\u00b7tu", "so", "zu", "ber\u00b7gen", "dei\u00b7ne", "T\u00fck\u00b7ke", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "VVFIN", "ADV", "PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Sag mit wehme triebstu vor der T\u00fchr so Schelmen-", "tokens": ["Sag", "mit", "weh\u00b7me", "triebs\u00b7tu", "vor", "der", "T\u00fchr", "so", "Schel\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "VVFIN", "APPR", "ART", "NN", "ADV", "TRUNC"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ach herze Frau/ wir sind verrahten hier/", "tokens": ["Ach", "her\u00b7ze", "Frau", "/", "wir", "sind", "ver\u00b7rah\u00b7ten", "hier", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "NN", "$(", "PPER", "VAFIN", "VVPP", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "es ist ein Mensche drau\u00df f\u00fcr der T\u00fchr/", "tokens": ["es", "ist", "ein", "Men\u00b7sche", "drau\u00df", "f\u00fcr", "der", "T\u00fchr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "der klopffet an/ wil mit Gewalt zu uns herein/", "tokens": ["der", "klopf\u00b7fet", "an", "/", "wil", "mit", "Ge\u00b7walt", "zu", "uns", "her\u00b7ein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PTKVZ", "$(", "VMFIN", "APPR", "NN", "APPR", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gebt Achtung drauff.", "tokens": ["Gebt", "Ach\u00b7tung", "drauff", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Die Stimm\u2019 ist sein.", "tokens": ["Die", "Stimm'", "ist", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "O Mele/ Mele/ was hab\u2019 ich verbrochen", "tokens": ["O", "Me\u00b7le", "/", "Me\u00b7le", "/", "was", "hab'", "ich", "ver\u00b7bro\u00b7chen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$(", "NE", "$(", "PWS", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ist nu di\u00df die Treue/ die du mir so offt versprochen?", "tokens": ["ist", "nu", "di\u00df", "die", "Treu\u00b7e", "/", "die", "du", "mir", "so", "offt", "ver\u00b7spro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDS", "ART", "NN", "$(", "PRELS", "PPER", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Nu steh ich hier der Regen treufft auff mich", "tokens": ["Nu", "steh", "ich", "hier", "der", "Re\u00b7gen", "treufft", "auff", "mich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der Wind durchweht mich kalt-grimmiglich.", "tokens": ["der", "Wind", "durch\u00b7weht", "mich", "kal\u00b7tgrim\u00b7mig\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach/ meines Leids! wo kommt doch diese Stimme her?", "tokens": ["Ach", "/", "mei\u00b7nes", "Leids", "!", "wo", "kommt", "doch", "die\u00b7se", "Stim\u00b7me", "her", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "PPOSAT", "NN", "$.", "PWAV", "VVFIN", "ADV", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So seuffzet/ klagt/ so beschweert und bittet er.", "tokens": ["So", "seuff\u00b7zet", "/", "klagt", "/", "so", "be\u00b7schweert", "und", "bit\u00b7tet", "er", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "VVFIN", "$(", "ADV", "VVPP", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "den du vergist/", "tokens": ["den", "du", "ver\u00b7gist", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "was darff es mehr.", "tokens": ["was", "darff", "es", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Jhr G\u00f6tter ach! was soll ich darvon denken/", "tokens": ["Ihr", "G\u00f6t\u00b7ter", "ach", "!", "was", "soll", "ich", "dar\u00b7von", "den\u00b7ken", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ITJ", "$.", "PWS", "VMFIN", "PPER", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wollt ihr meine kranke Seele gar zu Tode kr\u00e4nken.", "tokens": ["wollt", "ihr", "mei\u00b7ne", "kran\u00b7ke", "See\u00b7le", "gar", "zu", "To\u00b7de", "kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Ists Oridor! Ach nein/ es ist ein Geist/", "tokens": ["Ists", "O\u00b7ri\u00b7dor", "!", "Ach", "nein", "/", "es", "ist", "ein", "Geist", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "NN", "PTKANT", "$(", "PPER", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "mein Oridor ist ja fortgereist.", "tokens": ["mein", "O\u00b7ri\u00b7dor", "ist", "ja", "fort\u00b7ge\u00b7reist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Ich wil hingehn/ er sey es oder sey es nicht.", "tokens": ["Ich", "wil", "hin\u00b7gehn", "/", "er", "sey", "es", "o\u00b7der", "sey", "es", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$(", "PPER", "VAFIN", "PPER", "KON", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Trit mit herzu/ Mopsa/ sich/ hier kommt ein Licht.", "tokens": ["Trit", "mit", "her\u00b7zu", "/", "Mop\u00b7sa", "/", "sich", "/", "hier", "kommt", "ein", "Licht", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "$(", "NE", "$(", "PRF", "$(", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Ja/ Frau/ ihr wists.", "tokens": ["Ja", "/", "Frau", "/", "ihr", "wists", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$(", "NN", "$(", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Schweig/ B\u00f6sewicht.", "tokens": ["Schweig", "/", "B\u00f6\u00b7se\u00b7wicht", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Ich wag\u2019 es drauff/ und wil den Riegel ziehen:", "tokens": ["Ich", "wag'", "es", "drauff", "/", "und", "wil", "den", "Rie\u00b7gel", "zie\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "$(", "KON", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bleibe Sch\u00e4lkinn/ wirstu nu von mir in N\u00f6hten flie-", "tokens": ["Blei\u00b7be", "Sch\u00e4l\u00b7kinn", "/", "wirs\u00b7tu", "nu", "von", "mir", "in", "N\u00f6h\u00b7ten", "flie"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$(", "VAFIN", "ADV", "APPR", "PPER", "APPR", "ADJA", "TRUNC"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Ich f\u00fcrchte mich/ Frau/ lasset ja nichts ein/", "tokens": ["Ich", "f\u00fcrch\u00b7te", "mich", "/", "Frau", "/", "las\u00b7set", "ja", "nichts", "ein", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "NN", "$(", "VVFIN", "ADV", "PIS", "ART", "$("], "meter": "-+-+++-+-+", "measure": "zehnsilber"}, "line.4": {"text": "wer wei\u00df es/ was f\u00fcr ein Ding mag sein/", "tokens": ["wer", "wei\u00df", "es", "/", "was", "f\u00fcr", "ein", "Ding", "mag", "sein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$(", "PWS", "APPR", "ART", "NN", "VMFIN", "VAINF", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "denn Oridor hab\u2019 ich ja heute selbst gesehn", "tokens": ["denn", "O\u00b7ri\u00b7dor", "hab'", "ich", "ja", "heu\u00b7te", "selbst", "ge\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "dort \u00fcbern Berg schnell mit vielen Pferden gehn.", "tokens": ["dort", "\u00fc\u00b7bern", "Berg", "schnell", "mit", "vie\u00b7len", "Pfer\u00b7den", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADJD", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "was auff der Reis\u2019", "tokens": ["was", "auff", "der", "Reis'"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN"], "meter": "---+", "measure": "unknown.measure.single"}, "line.8": {"text": "ihm sey geschehn.", "tokens": ["ihm", "sey", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Still mit der T\u00fchr? da\u00df nicht mein Vaterh\u00f6re/", "tokens": ["Still", "mit", "der", "T\u00fchr", "?", "da\u00df", "nicht", "mein", "Va\u00b7ter\u00b7h\u00f6\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$.", "KOUS", "PTKNEG", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und mir meine Lust mit Oridor auff heute wehre.", "tokens": ["und", "mir", "mei\u00b7ne", "Lust", "mit", "O\u00b7ri\u00b7dor", "auff", "heu\u00b7te", "weh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "APPR", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Ach Frau/ er ists/ z\u00fcnd\u2019 ich den Schorrstein an", "tokens": ["Ach", "Frau", "/", "er", "ists", "/", "z\u00fcnd'", "ich", "den", "Schorrs\u00b7tein", "an"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "$(", "PPER", "VAFIN", "$(", "VVIMP", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df meine Zahl ich au\u00dfspinnen kan?", "tokens": ["da\u00df", "mei\u00b7ne", "Zahl", "ich", "au\u00df\u00b7spin\u00b7nen", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Schweig/ N\u00e4rrin/ nein iezt ist nicht Licht noch spi", "tokens": ["Schweig", "/", "N\u00e4r\u00b7rin", "/", "nein", "iezt", "ist", "nicht", "Licht", "noch", "spi"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "NN", "$(", "PTKANT", "ADV", "VAFIN", "PTKNEG", "NN", "ADV", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "mein Vater hat ja Gott lob ohn di\u00df noch Brodt.", "tokens": ["mein", "Va\u00b7ter", "hat", "ja", "Gott", "lob", "ohn", "di\u00df", "noch", "Brodt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "NN", "NN", "APPR", "PDS", "ADV", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "mein Oridor/", "tokens": ["mein", "O\u00b7ri\u00b7dor", "/"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Drauff trat er ein. Ein liebliches umfangen", "tokens": ["Drauff", "trat", "er", "ein", ".", "Ein", "lieb\u00b7li\u00b7ches", "um\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und ob die Nacht schon sonder Monden war", "tokens": ["und", "ob", "die", "Nacht", "schon", "son\u00b7der", "Mon\u00b7den", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "war doch ein Ku\u00df genug zu leschen ihre Brunst/", "tokens": ["war", "doch", "ein", "Ku\u00df", "ge\u00b7nug", "zu", "le\u00b7schen", "ih\u00b7re", "Brunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "PTKZU", "VVINF", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "die Pallas hat so bewiesen Lieb und Gunst/", "tokens": ["die", "Pal\u00b7las", "hat", "so", "be\u00b7wie\u00b7sen", "Lieb", "und", "Gunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "wenn sie besucht", "tokens": ["wenn", "sie", "be\u00b7sucht"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "der Gott der Kunst.", "tokens": ["der", "Gott", "der", "Kunst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Darum/ mein Freund/ der du die Nacht bedenkest/", "tokens": ["Da\u00b7rum", "/", "mein", "Freund", "/", "der", "du", "die", "Nacht", "be\u00b7den\u00b7kest", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "PPOSAT", "NN", "$(", "PRELS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "und auff ihre s\u00fcsse Lust die heisse Sinnen lenkest/", "tokens": ["und", "auff", "ih\u00b7re", "s\u00fcs\u00b7se", "Lust", "die", "heis\u00b7se", "Sin\u00b7nen", "len\u00b7kest", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie haben nichts nicht iemahls getahn.", "tokens": ["Sie", "ha\u00b7ben", "nichts", "nicht", "ie\u00b7mahls", "ge\u00b7tahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das wieder Zucht/ Geb\u00fchr/ Zula\u00df und Tugend", "tokens": ["Das", "wie\u00b7der", "Zucht", "/", "Ge\u00b7b\u00fchr", "/", "Zu\u00b7la\u00df", "und", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PDS", "ADV", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie liebten sich in der seltnen Reinligkeit.", "tokens": ["Sie", "lieb\u00b7ten", "sich", "in", "der", "selt\u00b7nen", "Rein\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Geschwister ie", "tokens": ["Ge\u00b7schwis\u00b7ter", "ie"], "token_info": ["word", "word"], "pos": ["FM.la", "FM.la"], "meter": "-+-+", "measure": "iambic.di"}}}}}