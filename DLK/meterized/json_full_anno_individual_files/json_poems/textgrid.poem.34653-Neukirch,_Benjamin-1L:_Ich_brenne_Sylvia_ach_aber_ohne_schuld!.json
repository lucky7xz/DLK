{"textgrid.poem.34653": {"metadata": {"author": {"name": "Neukirch, Benjamin", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich brenne/ Sylvia/ ach aber ohne schuld!", "genre": "verse", "period": "N.A.", "pub_year": 1697, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich brenne/ Sylvia/ ach aber ohne schuld!", "tokens": ["Ich", "bren\u00b7ne", "/", "Syl\u00b7via", "/", "ach", "a\u00b7ber", "oh\u00b7ne", "schuld", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "NE", "$(", "ADV", "ADV", "APPR", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Denn du hast mich entz\u00fcndet.", "tokens": ["Denn", "du", "hast", "mich", "ent\u00b7z\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jedennoch leid ich mit gedult", "tokens": ["Je\u00b7den\u00b7noch", "leid", "ich", "mit", "ge\u00b7dult"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den schaden/ den mein hertz empfindet.", "tokens": ["Den", "scha\u00b7den", "/", "den", "mein", "hertz", "emp\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wei\u00df es allzuwohl/ da\u00df du es hast gethan/", "tokens": ["Ich", "wei\u00df", "es", "all\u00b7zu\u00b7wohl", "/", "da\u00df", "du", "es", "hast", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch klag ich/ sch\u00f6nste/ dich bey keinem richter an.", "tokens": ["Doch", "klag", "ich", "/", "sch\u00f6ns\u00b7te", "/", "dich", "bey", "kei\u00b7nem", "rich\u00b7ter", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "VVFIN", "$(", "PPER", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ach strenge Sylvia! wie k\u00f6nt ich besser seyn?", "tokens": ["Ach", "stren\u00b7ge", "Syl\u00b7via", "!", "wie", "k\u00f6nt", "ich", "bes\u00b7ser", "seyn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "NE", "$.", "PWAV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Du suchest mein verderben/", "tokens": ["Du", "su\u00b7chest", "mein", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der brandt nimmt meine glieder ein/", "tokens": ["Der", "brandt", "nimmt", "mei\u00b7ne", "glie\u00b7der", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und heist mich sonder ursach sterben;", "tokens": ["Und", "heist", "mich", "son\u00b7der", "ur\u00b7sach", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich aber liebe dich/ und k\u00fcsse noch das licht/", "tokens": ["Ich", "a\u00b7ber", "lie\u00b7be", "dich", "/", "und", "k\u00fcs\u00b7se", "noch", "das", "licht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "$(", "KON", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das mir di\u00df feuer hat so listig angericht.", "tokens": ["Das", "mir", "di\u00df", "feu\u00b7er", "hat", "so", "lis\u00b7tig", "an\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PDS", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Du weist es selber ja/ wie heimlich es geschehn/", "tokens": ["Du", "weist", "es", "sel\u00b7ber", "ja", "/", "wie", "heim\u00b7lich", "es", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$(", "PWAV", "ADJD", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir waren stets beysammen/", "tokens": ["Wir", "wa\u00b7ren", "stets", "bey\u00b7sam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und hatten uns schon offt gesehn/", "tokens": ["Und", "hat\u00b7ten", "uns", "schon", "offt", "ge\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch wust ich nichts von liebes-flammen.", "tokens": ["Doch", "wust", "ich", "nichts", "von", "lie\u00b7bes\u00b7flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Allein so bald du mich zum tantzen auffgef\u00fchrt/", "tokens": ["Al\u00b7lein", "so", "bald", "du", "mich", "zum", "tant\u00b7zen", "auff\u00b7ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPER", "PRF", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hastu mein kaltes hertz/ ich wei\u00df nicht wie/ ger\u00fchrt.", "tokens": ["Has\u00b7tu", "mein", "kal\u00b7tes", "hertz", "/", "ich", "wei\u00df", "nicht", "wie", "/", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$(", "VVPP", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}}, "stanza.4": {"line.1": {"text": "Ich sahe dich alsbald mit andern augen an/", "tokens": ["Ich", "sa\u00b7he", "dich", "als\u00b7bald", "mit", "an\u00b7dern", "au\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jedoch ie mehr ich sahe/", "tokens": ["Je\u00b7doch", "ie", "mehr", "ich", "sa\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Je mehr versanck ich in den wahn/", "tokens": ["Je", "mehr", "ver\u00b7sanck", "ich", "in", "den", "wahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch den mein s\u00fcsser fall geschahe.", "tokens": ["Durch", "den", "mein", "s\u00fcs\u00b7ser", "fall", "ge\u00b7scha\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist dir mein lieben nun/ so wie es scheint/ verdru\u00df/", "tokens": ["Ist", "dir", "mein", "lie\u00b7ben", "nun", "/", "so", "wie", "es", "scheint", "/", "ver\u00b7dru\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "VVFIN", "ADV", "$(", "ADV", "KOKOM", "PPER", "VVFIN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Warum verlangest du denn da\u00df ich brennen mu\u00df?", "tokens": ["Wa\u00b7rum", "ver\u00b7lan\u00b7gest", "du", "denn", "da\u00df", "ich", "bren\u00b7nen", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ein ieder in der welt gl\u00e4ubt/ da\u00df es s\u00fcnde sey/", "tokens": ["Ein", "ie\u00b7der", "in", "der", "welt", "gl\u00e4ubt", "/", "da\u00df", "es", "s\u00fcn\u00b7de", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "VVFIN", "$(", "KOUS", "PPER", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein h\u00e4u\u00dfgen anzustecken;", "tokens": ["Ein", "h\u00e4u\u00df\u00b7gen", "an\u00b7zu\u00b7ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein hau\u00df kommt keinem menschen bey;", "tokens": ["Ein", "hau\u00df", "kommt", "kei\u00b7nem", "men\u00b7schen", "bey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Di\u00df solte billig dich erschrecken.", "tokens": ["Di\u00df", "sol\u00b7te", "bil\u00b7lig", "dich", "er\u00b7schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und dennoch denckestu/ indem du mich verletzt/", "tokens": ["Und", "den\u00b7noch", "den\u00b7ckes\u00b7tu", "/", "in\u00b7dem", "du", "mich", "ver\u00b7letzt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$(", "KOUS", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df keine straffe sey auff deine that gesetzt.", "tokens": ["Da\u00df", "kei\u00b7ne", "straf\u00b7fe", "sey", "auff", "dei\u00b7ne", "that", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VAFIN", "APPR", "PPOSAT", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ach \u00f6ffne doch einmahl dein felsen-hartes hertz/", "tokens": ["Ach", "\u00f6ff\u00b7ne", "doch", "ein\u00b7mahl", "dein", "fel\u00b7sen\u00b7har\u00b7tes", "hertz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und h\u00f6re meine klagen!", "tokens": ["Und", "h\u00f6\u00b7re", "mei\u00b7ne", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich leide zwar/ wie vor/ den schmertz/", "tokens": ["Ich", "lei\u00b7de", "zwar", "/", "wie", "vor", "/", "den", "schmertz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "KOKOM", "APPR", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und will ihn mit zu grabe tragen;", "tokens": ["Und", "will", "ihn", "mit", "zu", "gra\u00b7be", "tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PTKZU", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch alle rechte sind von diesen lehren voll:", "tokens": ["Doch", "al\u00b7le", "rech\u00b7te", "sind", "von", "die\u00b7sen", "leh\u00b7ren", "voll", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "VAFIN", "APPR", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df der/ so andre brennt/ auch wieder brennen soll.", "tokens": ["Da\u00df", "der", "/", "so", "and\u00b7re", "brennt", "/", "auch", "wie\u00b7der", "bren\u00b7nen", "soll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "ADV", "PIS", "VVFIN", "$(", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ich brenne/ Sylvia/ ach aber ohne schuld!", "tokens": ["Ich", "bren\u00b7ne", "/", "Syl\u00b7via", "/", "ach", "a\u00b7ber", "oh\u00b7ne", "schuld", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "NE", "$(", "ADV", "ADV", "APPR", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Denn du hast mich entz\u00fcndet.", "tokens": ["Denn", "du", "hast", "mich", "ent\u00b7z\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jedennoch leid ich mit gedult", "tokens": ["Je\u00b7den\u00b7noch", "leid", "ich", "mit", "ge\u00b7dult"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den schaden/ den mein hertz empfindet.", "tokens": ["Den", "scha\u00b7den", "/", "den", "mein", "hertz", "emp\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wei\u00df es allzuwohl/ da\u00df du es hast gethan/", "tokens": ["Ich", "wei\u00df", "es", "all\u00b7zu\u00b7wohl", "/", "da\u00df", "du", "es", "hast", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch klag ich/ sch\u00f6nste/ dich bey keinem richter an.", "tokens": ["Doch", "klag", "ich", "/", "sch\u00f6ns\u00b7te", "/", "dich", "bey", "kei\u00b7nem", "rich\u00b7ter", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "VVFIN", "$(", "PPER", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ach strenge Sylvia! wie k\u00f6nt ich besser seyn?", "tokens": ["Ach", "stren\u00b7ge", "Syl\u00b7via", "!", "wie", "k\u00f6nt", "ich", "bes\u00b7ser", "seyn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "NE", "$.", "PWAV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Du suchest mein verderben/", "tokens": ["Du", "su\u00b7chest", "mein", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der brandt nimmt meine glieder ein/", "tokens": ["Der", "brandt", "nimmt", "mei\u00b7ne", "glie\u00b7der", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und heist mich sonder ursach sterben;", "tokens": ["Und", "heist", "mich", "son\u00b7der", "ur\u00b7sach", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich aber liebe dich/ und k\u00fcsse noch das licht/", "tokens": ["Ich", "a\u00b7ber", "lie\u00b7be", "dich", "/", "und", "k\u00fcs\u00b7se", "noch", "das", "licht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "$(", "KON", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das mir di\u00df feuer hat so listig angericht.", "tokens": ["Das", "mir", "di\u00df", "feu\u00b7er", "hat", "so", "lis\u00b7tig", "an\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PDS", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Du weist es selber ja/ wie heimlich es geschehn/", "tokens": ["Du", "weist", "es", "sel\u00b7ber", "ja", "/", "wie", "heim\u00b7lich", "es", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$(", "PWAV", "ADJD", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir waren stets beysammen/", "tokens": ["Wir", "wa\u00b7ren", "stets", "bey\u00b7sam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und hatten uns schon offt gesehn/", "tokens": ["Und", "hat\u00b7ten", "uns", "schon", "offt", "ge\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch wust ich nichts von liebes-flammen.", "tokens": ["Doch", "wust", "ich", "nichts", "von", "lie\u00b7bes\u00b7flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Allein so bald du mich zum tantzen auffgef\u00fchrt/", "tokens": ["Al\u00b7lein", "so", "bald", "du", "mich", "zum", "tant\u00b7zen", "auff\u00b7ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPER", "PRF", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hastu mein kaltes hertz/ ich wei\u00df nicht wie/ ger\u00fchrt.", "tokens": ["Has\u00b7tu", "mein", "kal\u00b7tes", "hertz", "/", "ich", "wei\u00df", "nicht", "wie", "/", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$(", "VVPP", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}}, "stanza.10": {"line.1": {"text": "Ich sahe dich alsbald mit andern augen an/", "tokens": ["Ich", "sa\u00b7he", "dich", "als\u00b7bald", "mit", "an\u00b7dern", "au\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jedoch ie mehr ich sahe/", "tokens": ["Je\u00b7doch", "ie", "mehr", "ich", "sa\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Je mehr versanck ich in den wahn/", "tokens": ["Je", "mehr", "ver\u00b7sanck", "ich", "in", "den", "wahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch den mein s\u00fcsser fall geschahe.", "tokens": ["Durch", "den", "mein", "s\u00fcs\u00b7ser", "fall", "ge\u00b7scha\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist dir mein lieben nun/ so wie es scheint/ verdru\u00df/", "tokens": ["Ist", "dir", "mein", "lie\u00b7ben", "nun", "/", "so", "wie", "es", "scheint", "/", "ver\u00b7dru\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "VVFIN", "ADV", "$(", "ADV", "KOKOM", "PPER", "VVFIN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Warum verlangest du denn da\u00df ich brennen mu\u00df?", "tokens": ["Wa\u00b7rum", "ver\u00b7lan\u00b7gest", "du", "denn", "da\u00df", "ich", "bren\u00b7nen", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Ein ieder in der welt gl\u00e4ubt/ da\u00df es s\u00fcnde sey/", "tokens": ["Ein", "ie\u00b7der", "in", "der", "welt", "gl\u00e4ubt", "/", "da\u00df", "es", "s\u00fcn\u00b7de", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "VVFIN", "$(", "KOUS", "PPER", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein h\u00e4u\u00dfgen anzustecken;", "tokens": ["Ein", "h\u00e4u\u00df\u00b7gen", "an\u00b7zu\u00b7ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein hau\u00df kommt keinem menschen bey;", "tokens": ["Ein", "hau\u00df", "kommt", "kei\u00b7nem", "men\u00b7schen", "bey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Di\u00df solte billig dich erschrecken.", "tokens": ["Di\u00df", "sol\u00b7te", "bil\u00b7lig", "dich", "er\u00b7schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und dennoch denckestu/ indem du mich verletzt/", "tokens": ["Und", "den\u00b7noch", "den\u00b7ckes\u00b7tu", "/", "in\u00b7dem", "du", "mich", "ver\u00b7letzt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$(", "KOUS", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df keine straffe sey auff deine that gesetzt.", "tokens": ["Da\u00df", "kei\u00b7ne", "straf\u00b7fe", "sey", "auff", "dei\u00b7ne", "that", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VAFIN", "APPR", "PPOSAT", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ach \u00f6ffne doch einmahl dein felsen-hartes hertz/", "tokens": ["Ach", "\u00f6ff\u00b7ne", "doch", "ein\u00b7mahl", "dein", "fel\u00b7sen\u00b7har\u00b7tes", "hertz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und h\u00f6re meine klagen!", "tokens": ["Und", "h\u00f6\u00b7re", "mei\u00b7ne", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich leide zwar/ wie vor/ den schmertz/", "tokens": ["Ich", "lei\u00b7de", "zwar", "/", "wie", "vor", "/", "den", "schmertz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "KOKOM", "APPR", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und will ihn mit zu grabe tragen;", "tokens": ["Und", "will", "ihn", "mit", "zu", "gra\u00b7be", "tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PTKZU", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch alle rechte sind von diesen lehren voll:", "tokens": ["Doch", "al\u00b7le", "rech\u00b7te", "sind", "von", "die\u00b7sen", "leh\u00b7ren", "voll", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "VAFIN", "APPR", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df der/ so andre brennt/ auch wieder brennen soll.", "tokens": ["Da\u00df", "der", "/", "so", "and\u00b7re", "brennt", "/", "auch", "wie\u00b7der", "bren\u00b7nen", "soll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "ADV", "PIS", "VVFIN", "$(", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}