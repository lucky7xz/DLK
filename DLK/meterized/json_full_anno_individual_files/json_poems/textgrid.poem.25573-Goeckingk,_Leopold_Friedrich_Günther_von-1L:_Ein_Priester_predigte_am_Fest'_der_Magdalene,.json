{"textgrid.poem.25573": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Priester predigte am Fest' der Magdalene,", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Priester predigte am Fest' der Magdalene,", "tokens": ["Ein", "Pries\u00b7ter", "pre\u00b7dig\u00b7te", "am", "Fest'", "der", "Mag\u00b7da\u00b7le\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom Gr\u00e4uel ihrer ersten Lebensart,", "tokens": ["Vom", "Gr\u00e4u\u00b7el", "ih\u00b7rer", "ers\u00b7ten", "Le\u00b7ben\u00b7sart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch ward hernach das Lob der Sch\u00f6ne,", "tokens": ["Doch", "ward", "her\u00b7nach", "das", "Lob", "der", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ob ihrer Reu' und Bu\u00dfe, nicht gespart.", "tokens": ["Ob", "ih\u00b7rer", "Reu'", "und", "Bu\u00b7\u00dfe", ",", "nicht", "ge\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN", "$,", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbnun!\u00ab fuhr der Redner zu den Damen,", "tokens": ["\u00bb", "nun", "!", "\u00ab", "fuhr", "der", "Red\u00b7ner", "zu", "den", "Da\u00b7men", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "$(", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die vor ihm sa\u00dfen, eifernd fort,", "tokens": ["Die", "vor", "ihm", "sa\u00b7\u00dfen", ",", "ei\u00b7fernd", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVFIN", "$,", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbwie viel sind unter euch, die mehr an diesen Ort", "tokens": ["\u00bb", "wie", "viel", "sind", "un\u00b7ter", "euch", ",", "die", "mehr", "an", "die\u00b7sen", "Ort"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PIS", "VAFIN", "APPR", "PPER", "$,", "PRELS", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sich zu belustigen, als zu erbauen, kamen!", "tokens": ["Sich", "zu", "be\u00b7lus\u00b7ti\u00b7gen", ",", "als", "zu", "er\u00b7bau\u00b7en", ",", "ka\u00b7men", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "$,", "KOUS", "PTKZU", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O sonderlich ist ", "tokens": ["O", "son\u00b7der\u00b7lich", "ist"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADJD", "VAFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Bei der hilft weder Drohn noch Bitten;", "tokens": ["Bei", "der", "hilft", "we\u00b7der", "Drohn", "noch", "Bit\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "An unversch\u00e4mten, l\u00fcderlichen Sitten", "tokens": ["An", "un\u00b7ver\u00b7sch\u00e4m\u00b7ten", ",", "l\u00fc\u00b7der\u00b7li\u00b7chen", "Sit\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.12": {"text": "Bleibt sie vielmehr sich immer gleich.", "tokens": ["Bleibt", "sie", "viel\u00b7mehr", "sich", "im\u00b7mer", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Wie heilig hat sie alle Jahr", "tokens": ["Wie", "hei\u00b7lig", "hat", "sie", "al\u00b7le", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Im Beichtstuhl' Besserung versprochen!", "tokens": ["Im", "Beicht\u00b7stuhl'", "Bes\u00b7se\u00b7rung", "ver\u00b7spro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Allein wie bald ward die\u00df Gel\u00fcbd gebrochen!", "tokens": ["Al\u00b7lein", "wie", "bald", "ward", "die\u00df", "Ge\u00b7l\u00fcbd", "ge\u00b7bro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "VAFIN", "PDS", "NN", "VVPP", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Und da sich ihre Frechheit immerdar", "tokens": ["Und", "da", "sich", "ih\u00b7re", "Frech\u00b7heit", "im\u00b7mer\u00b7dar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PRF", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Noch gar vermehrt: wer kann uns \u00fcbel nehmen,", "tokens": ["Noch", "gar", "ver\u00b7mehrt", ":", "wer", "kann", "uns", "\u00fc\u00b7bel", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$.", "PWS", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Wenn endlich wir sie \u00f6ffentlich besch\u00e4men?", "tokens": ["Wenn", "end\u00b7lich", "wir", "sie", "\u00f6f\u00b7fent\u00b7lich", "be\u00b7sch\u00e4\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Denn, sagt die Bibel, wenn dein Bruder fehlt,", "tokens": ["Denn", ",", "sagt", "die", "Bi\u00b7bel", ",", "wenn", "dein", "Bru\u00b7der", "fehlt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "ART", "NN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Erinnr' ihn Ein- auch zweimal dran,", "tokens": ["Er\u00b7inn\u00b7r'", "ihn", "Ein", "auch", "zwei\u00b7mal", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "TRUNC", "ADV", "ADV", "PAV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Doch wenn er dann den Weg der Besserung nicht w\u00e4hlt,", "tokens": ["Doch", "wenn", "er", "dann", "den", "Weg", "der", "Bes\u00b7se\u00b7rung", "nicht", "w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "So zeig's nach Pflicht der Kirche an.\u00ab", "tokens": ["So", "zeig's", "nach", "Pflicht", "der", "Kir\u00b7che", "an", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "\u00bbdas will auch ich itzt thun. Es ist \u2013 es ist \u2013", "tokens": ["\u00bb", "das", "will", "auch", "ich", "itzt", "thun", ".", "Es", "ist", "\u2013", "es", "ist", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "ADV", "PPER", "ADV", "VVINF", "$.", "PPER", "VAFIN", "$(", "PPER", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Was meint ihr? Soll ich namentlich sie nennen?", "tokens": ["Was", "meint", "ihr", "?", "Soll", "ich", "na\u00b7ment\u00b7lich", "sie", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Ich sollte billig wohl; doch wi\u00dft \u2013", "tokens": ["Ich", "soll\u00b7te", "bil\u00b7lig", "wohl", ";", "doch", "wi\u00dft", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "ADV", "$.", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Allein warum nicht? Gut! ihr sollt sie kennen.", "tokens": ["Al\u00b7lein", "wa\u00b7rum", "nicht", "?", "Gut", "!", "ihr", "sollt", "sie", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PTKNEG", "$.", "NN", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Vielleicht bringt die\u00df zu ihrer Pflicht", "tokens": ["Viel\u00b7leicht", "bringt", "die\u00df", "zu", "ih\u00b7rer", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Sie noch zur\u00fcck, so leid mir's thut, sie zu besch\u00e4men.", "tokens": ["Sie", "noch", "zu\u00b7r\u00fcck", ",", "so", "leid", "mir's", "thut", ",", "sie", "zu", "be\u00b7sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKVZ", "$,", "ADV", "ADJD", "NE", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Es ist \u2013 doch ohne Makel k\u00f6nnt' ich nicht", "tokens": ["Es", "ist", "\u2013", "doch", "oh\u00b7ne", "Ma\u00b7kel", "k\u00f6nnt'", "ich", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$(", "ADV", "APPR", "NN", "VMFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Den Namen nur einmal auf meine Zunge nehmen.", "tokens": ["Den", "Na\u00b7men", "nur", "ein\u00b7mal", "auf", "mei\u00b7ne", "Zun\u00b7ge", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.31": {"text": "Ich will sie denn auf andre Art der Welt", "tokens": ["Ich", "will", "sie", "denn", "auf", "and\u00b7re", "Art", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Kund machen, und einmal an ihr das Strafamt sch\u00e4rfen.", "tokens": ["Kund", "ma\u00b7chen", ",", "und", "ein\u00b7mal", "an", "ihr", "das", "Stra\u00b7famt", "sch\u00e4r\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "KON", "ADV", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.33": {"text": "Dort sitzt sie! Wie sie sich nicht stellt!", "tokens": ["Dort", "sitzt", "sie", "!", "Wie", "sie", "sich", "nicht", "stellt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PWAV", "PPER", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Gebt Acht! Ich werde mein Gebetbuch nach ihr werfen;", "tokens": ["Gebt", "Acht", "!", "Ich", "wer\u00b7de", "mein", "Ge\u00b7bet\u00b7buch", "nach", "ihr", "wer\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Gebt Acht! Gebt Acht! auf welch' es f\u00e4llt!\u00ab", "tokens": ["Gebt", "Acht", "!", "Gebt", "Acht", "!", "auf", "welch'", "es", "f\u00e4llt", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "CARD", "$.", "VVIMP", "CARD", "$.", "APPR", "PWAT", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Indem er nun empor mit seinem Buche fuhr,", "tokens": ["In\u00b7dem", "er", "nun", "em\u00b7por", "mit", "sei\u00b7nem", "Bu\u00b7che", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKVZ", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "War jede bange vor dem Falle,", "tokens": ["War", "je\u00b7de", "ban\u00b7ge", "vor", "dem", "Fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Und jede b\u00fcckte sich.", "tokens": ["Und", "je\u00b7de", "b\u00fcck\u00b7te", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.39": {"text": "\u00bbverdorbene Natur!", "tokens": ["\u00bb", "ver\u00b7dor\u00b7be\u00b7ne", "Na\u00b7tur", "!"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$."], "meter": "-+---+", "measure": "dactylic.init"}, "line.40": {"text": "Ich dacht', es w\u00e4re Eine nur,", "tokens": ["Ich", "dacht'", ",", "es", "w\u00e4\u00b7re", "Ei\u00b7ne", "nur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Nun seh' ich wohl, sie sind es alle.\u00ab", "tokens": ["Nun", "seh'", "ich", "wohl", ",", "sie", "sind", "es", "al\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein Priester predigte am Fest' der Magdalene,", "tokens": ["Ein", "Pries\u00b7ter", "pre\u00b7dig\u00b7te", "am", "Fest'", "der", "Mag\u00b7da\u00b7le\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom Gr\u00e4uel ihrer ersten Lebensart,", "tokens": ["Vom", "Gr\u00e4u\u00b7el", "ih\u00b7rer", "ers\u00b7ten", "Le\u00b7ben\u00b7sart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch ward hernach das Lob der Sch\u00f6ne,", "tokens": ["Doch", "ward", "her\u00b7nach", "das", "Lob", "der", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ob ihrer Reu' und Bu\u00dfe, nicht gespart.", "tokens": ["Ob", "ih\u00b7rer", "Reu'", "und", "Bu\u00b7\u00dfe", ",", "nicht", "ge\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN", "$,", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbnun!\u00ab fuhr der Redner zu den Damen,", "tokens": ["\u00bb", "nun", "!", "\u00ab", "fuhr", "der", "Red\u00b7ner", "zu", "den", "Da\u00b7men", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "$(", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die vor ihm sa\u00dfen, eifernd fort,", "tokens": ["Die", "vor", "ihm", "sa\u00b7\u00dfen", ",", "ei\u00b7fernd", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVFIN", "$,", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbwie viel sind unter euch, die mehr an diesen Ort", "tokens": ["\u00bb", "wie", "viel", "sind", "un\u00b7ter", "euch", ",", "die", "mehr", "an", "die\u00b7sen", "Ort"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PIS", "VAFIN", "APPR", "PPER", "$,", "PRELS", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sich zu belustigen, als zu erbauen, kamen!", "tokens": ["Sich", "zu", "be\u00b7lus\u00b7ti\u00b7gen", ",", "als", "zu", "er\u00b7bau\u00b7en", ",", "ka\u00b7men", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "$,", "KOUS", "PTKZU", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O sonderlich ist ", "tokens": ["O", "son\u00b7der\u00b7lich", "ist"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADJD", "VAFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Bei der hilft weder Drohn noch Bitten;", "tokens": ["Bei", "der", "hilft", "we\u00b7der", "Drohn", "noch", "Bit\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "An unversch\u00e4mten, l\u00fcderlichen Sitten", "tokens": ["An", "un\u00b7ver\u00b7sch\u00e4m\u00b7ten", ",", "l\u00fc\u00b7der\u00b7li\u00b7chen", "Sit\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.12": {"text": "Bleibt sie vielmehr sich immer gleich.", "tokens": ["Bleibt", "sie", "viel\u00b7mehr", "sich", "im\u00b7mer", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Wie heilig hat sie alle Jahr", "tokens": ["Wie", "hei\u00b7lig", "hat", "sie", "al\u00b7le", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Im Beichtstuhl' Besserung versprochen!", "tokens": ["Im", "Beicht\u00b7stuhl'", "Bes\u00b7se\u00b7rung", "ver\u00b7spro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Allein wie bald ward die\u00df Gel\u00fcbd gebrochen!", "tokens": ["Al\u00b7lein", "wie", "bald", "ward", "die\u00df", "Ge\u00b7l\u00fcbd", "ge\u00b7bro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "VAFIN", "PDS", "NN", "VVPP", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Und da sich ihre Frechheit immerdar", "tokens": ["Und", "da", "sich", "ih\u00b7re", "Frech\u00b7heit", "im\u00b7mer\u00b7dar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PRF", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Noch gar vermehrt: wer kann uns \u00fcbel nehmen,", "tokens": ["Noch", "gar", "ver\u00b7mehrt", ":", "wer", "kann", "uns", "\u00fc\u00b7bel", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$.", "PWS", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Wenn endlich wir sie \u00f6ffentlich besch\u00e4men?", "tokens": ["Wenn", "end\u00b7lich", "wir", "sie", "\u00f6f\u00b7fent\u00b7lich", "be\u00b7sch\u00e4\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Denn, sagt die Bibel, wenn dein Bruder fehlt,", "tokens": ["Denn", ",", "sagt", "die", "Bi\u00b7bel", ",", "wenn", "dein", "Bru\u00b7der", "fehlt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "ART", "NN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Erinnr' ihn Ein- auch zweimal dran,", "tokens": ["Er\u00b7inn\u00b7r'", "ihn", "Ein", "auch", "zwei\u00b7mal", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "TRUNC", "ADV", "ADV", "PAV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Doch wenn er dann den Weg der Besserung nicht w\u00e4hlt,", "tokens": ["Doch", "wenn", "er", "dann", "den", "Weg", "der", "Bes\u00b7se\u00b7rung", "nicht", "w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "So zeig's nach Pflicht der Kirche an.\u00ab", "tokens": ["So", "zeig's", "nach", "Pflicht", "der", "Kir\u00b7che", "an", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "\u00bbdas will auch ich itzt thun. Es ist \u2013 es ist \u2013", "tokens": ["\u00bb", "das", "will", "auch", "ich", "itzt", "thun", ".", "Es", "ist", "\u2013", "es", "ist", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "ADV", "PPER", "ADV", "VVINF", "$.", "PPER", "VAFIN", "$(", "PPER", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Was meint ihr? Soll ich namentlich sie nennen?", "tokens": ["Was", "meint", "ihr", "?", "Soll", "ich", "na\u00b7ment\u00b7lich", "sie", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Ich sollte billig wohl; doch wi\u00dft \u2013", "tokens": ["Ich", "soll\u00b7te", "bil\u00b7lig", "wohl", ";", "doch", "wi\u00dft", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "ADV", "$.", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Allein warum nicht? Gut! ihr sollt sie kennen.", "tokens": ["Al\u00b7lein", "wa\u00b7rum", "nicht", "?", "Gut", "!", "ihr", "sollt", "sie", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PTKNEG", "$.", "NN", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Vielleicht bringt die\u00df zu ihrer Pflicht", "tokens": ["Viel\u00b7leicht", "bringt", "die\u00df", "zu", "ih\u00b7rer", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Sie noch zur\u00fcck, so leid mir's thut, sie zu besch\u00e4men.", "tokens": ["Sie", "noch", "zu\u00b7r\u00fcck", ",", "so", "leid", "mir's", "thut", ",", "sie", "zu", "be\u00b7sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKVZ", "$,", "ADV", "ADJD", "NE", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Es ist \u2013 doch ohne Makel k\u00f6nnt' ich nicht", "tokens": ["Es", "ist", "\u2013", "doch", "oh\u00b7ne", "Ma\u00b7kel", "k\u00f6nnt'", "ich", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$(", "ADV", "APPR", "NN", "VMFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Den Namen nur einmal auf meine Zunge nehmen.", "tokens": ["Den", "Na\u00b7men", "nur", "ein\u00b7mal", "auf", "mei\u00b7ne", "Zun\u00b7ge", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.31": {"text": "Ich will sie denn auf andre Art der Welt", "tokens": ["Ich", "will", "sie", "denn", "auf", "and\u00b7re", "Art", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Kund machen, und einmal an ihr das Strafamt sch\u00e4rfen.", "tokens": ["Kund", "ma\u00b7chen", ",", "und", "ein\u00b7mal", "an", "ihr", "das", "Stra\u00b7famt", "sch\u00e4r\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "KON", "ADV", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.33": {"text": "Dort sitzt sie! Wie sie sich nicht stellt!", "tokens": ["Dort", "sitzt", "sie", "!", "Wie", "sie", "sich", "nicht", "stellt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PWAV", "PPER", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Gebt Acht! Ich werde mein Gebetbuch nach ihr werfen;", "tokens": ["Gebt", "Acht", "!", "Ich", "wer\u00b7de", "mein", "Ge\u00b7bet\u00b7buch", "nach", "ihr", "wer\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Gebt Acht! Gebt Acht! auf welch' es f\u00e4llt!\u00ab", "tokens": ["Gebt", "Acht", "!", "Gebt", "Acht", "!", "auf", "welch'", "es", "f\u00e4llt", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "CARD", "$.", "VVIMP", "CARD", "$.", "APPR", "PWAT", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Indem er nun empor mit seinem Buche fuhr,", "tokens": ["In\u00b7dem", "er", "nun", "em\u00b7por", "mit", "sei\u00b7nem", "Bu\u00b7che", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKVZ", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "War jede bange vor dem Falle,", "tokens": ["War", "je\u00b7de", "ban\u00b7ge", "vor", "dem", "Fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Und jede b\u00fcckte sich.", "tokens": ["Und", "je\u00b7de", "b\u00fcck\u00b7te", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.39": {"text": "\u00bbverdorbene Natur!", "tokens": ["\u00bb", "ver\u00b7dor\u00b7be\u00b7ne", "Na\u00b7tur", "!"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$."], "meter": "-+---+", "measure": "dactylic.init"}, "line.40": {"text": "Ich dacht', es w\u00e4re Eine nur,", "tokens": ["Ich", "dacht'", ",", "es", "w\u00e4\u00b7re", "Ei\u00b7ne", "nur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Nun seh' ich wohl, sie sind es alle.\u00ab", "tokens": ["Nun", "seh'", "ich", "wohl", ",", "sie", "sind", "es", "al\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}