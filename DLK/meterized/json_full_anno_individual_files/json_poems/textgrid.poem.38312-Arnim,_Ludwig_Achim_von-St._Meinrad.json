{"textgrid.poem.38312": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "St. Meinrad", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Graf Berthold von Sulchen, der fromme Mann,", "tokens": ["Graf", "Bert\u00b7hold", "von", "Sul\u00b7chen", ",", "der", "from\u00b7me", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Er f\u00fchrt sein S\u00f6hnlein an der Hand;", "tokens": ["Er", "f\u00fchrt", "sein", "S\u00f6hn\u00b7lein", "an", "der", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Meinrad, mein S\u00f6hnlein von f\u00fcnf Jahren,", "tokens": ["Mein\u00b7rad", ",", "mein", "S\u00f6hn\u00b7lein", "von", "f\u00fcnf", "Jah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du mu\u00dft mit mir gen Reichenau fahren.", "tokens": ["Du", "mu\u00dft", "mit", "mir", "gen", "Rei\u00b7che\u00b7nau", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Hatto, Hatto, nimm hin das Kind,", "tokens": ["Hat\u00b7to", ",", "Hat\u00b7to", ",", "nimm", "hin", "das", "Kind", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VVIMP", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Alle liebe Engelein mit ihm sind;", "tokens": ["Al\u00b7le", "lie\u00b7be", "En\u00b7ge\u00b7lein", "mit", "ihm", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "PPER", "VAFIN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Die geistlich Zucht mag er wohl lernen,", "tokens": ["Die", "geist\u00b7lich", "Zucht", "mag", "er", "wohl", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und mag ein Spiegel der M\u00fcnche werden.", "tokens": ["Und", "mag", "ein", "Spie\u00b7gel", "der", "M\u00fcn\u00b7che", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Er ging zur Schul barfu\u00df ohne Schuh;", "tokens": ["Er", "ging", "zur", "Schul", "bar\u00b7fu\u00df", "oh\u00b7ne", "Schuh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und legt die geistlich Kunst sich zu;", "tokens": ["Und", "legt", "die", "geist\u00b7lich", "Kunst", "sich", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJD", "NN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Weisheit kam ihm vor der Zeit,", "tokens": ["Die", "Weis\u00b7heit", "kam", "ihm", "vor", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da ward er zu einem Priester geweiht.", "tokens": ["Da", "ward", "er", "zu", "ei\u00b7nem", "Pries\u00b7ter", "ge\u00b7weiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Da schickt ihn Hatto auf den Z\u00fcrcher See,", "tokens": ["Da", "schickt", "ihn", "Hat\u00b7to", "auf", "den", "Z\u00fcr\u00b7cher", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df er ins Kl\u00f6sterlein bei Jona geh;", "tokens": ["Da\u00df", "er", "ins", "Kl\u00f6s\u00b7ter\u00b7lein", "bei", "Jo\u00b7na", "geh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bei Jona zu Oberpollingen,", "tokens": ["Bei", "Jo\u00b7na", "zu", "O\u00b7ber\u00b7pol\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Da lehrt er die M\u00fcnch beten und singen.", "tokens": ["Da", "lehrt", "er", "die", "M\u00fcnch", "be\u00b7ten", "und", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "VVINF", "KON", "VVFIN", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Da er lange ihr Schulmeister war,", "tokens": ["Da", "er", "lan\u00b7ge", "ihr", "Schul\u00b7meis\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und ihn die Br\u00fcder ehrten gar;", "tokens": ["Und", "ihn", "die", "Br\u00fc\u00b7der", "ehr\u00b7ten", "gar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Th\u00e4t er oft an dem Ufer stehen,", "tokens": ["Th\u00e4t", "er", "oft", "an", "dem", "U\u00b7fer", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und nach dem wilden Gebirg hinsehen.", "tokens": ["Und", "nach", "dem", "wil\u00b7den", "Ge\u00b7birg", "hin\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Sein Gewissen zog ihn zur W\u00fcste hin,", "tokens": ["Sein", "Ge\u00b7wis\u00b7sen", "zog", "ihn", "zur", "W\u00fcs\u00b7te", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zur Einsamkeit stand all sein Sinn;", "tokens": ["Zur", "Ein\u00b7sam\u00b7keit", "stand", "all", "sein", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er sprach zu einem M\u00fcnch: Mein Bruder,", "tokens": ["Er", "sprach", "zu", "ei\u00b7nem", "M\u00fcnch", ":", "Mein", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "R\u00fcst uns ein Schifflein und zwey Ruder.", "tokens": ["R\u00fcst", "uns", "ein", "Schif\u00b7flein", "und", "zwey", "Ru\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "KON", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ueber See zur Wildni\u00df zur W\u00fcsteney,", "tokens": ["Ue\u00b7ber", "See", "zur", "Wild\u00b7ni\u00df", "zur", "W\u00fcs\u00b7te\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Hab ich geh\u00f6rt gut fischen sey;", "tokens": ["Hab", "ich", "ge\u00b7h\u00f6rt", "gut", "fi\u00b7schen", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "ADJD", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da gehn die Fischlein in den einsamen B\u00e4chen! \u2013", "tokens": ["Da", "gehn", "die", "Fisc\u00b7hlein", "in", "den", "ein\u00b7sa\u00b7men", "B\u00e4\u00b7chen", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ja Herr, mein Meister, der M\u00fcnch th\u00e4t sprechen.", "tokens": ["Ja", "Herr", ",", "mein", "Meis\u00b7ter", ",", "der", "M\u00fcnch", "th\u00e4t", "spre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Sie fuhren gen Rapperswyl \u00fcber See,", "tokens": ["Sie", "fuh\u00b7ren", "gen", "Rap\u00b7per\u00b7swyl", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Zu einer frommen Wittib sie da gehn;", "tokens": ["Zu", "ei\u00b7ner", "from\u00b7men", "Wit\u00b7tib", "sie", "da", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bewahr uns die Gewand, sie zu ihr sprechen,", "tokens": ["Be\u00b7wahr", "uns", "die", "Ge\u00b7wand", ",", "sie", "zu", "ihr", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df sie uns nicht in der Wildni\u00df zerbrechen.", "tokens": ["Da\u00df", "sie", "uns", "nicht", "in", "der", "Wild\u00b7ni\u00df", "zer\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Sankt Meinrad und der Bruder gut,", "tokens": ["Sankt", "Mein\u00b7rad", "und", "der", "Bru\u00b7der", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "ART", "NN", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sie folgten wohl der B\u00e4chlein Fluth;", "tokens": ["Sie", "folg\u00b7ten", "wohl", "der", "B\u00e4ch\u00b7lein", "Fluth", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie fischten hinan in dem Fl\u00fc\u00dflein Sille,", "tokens": ["Sie", "fischten", "hi\u00b7nan", "in", "dem", "Fl\u00fc\u00df\u00b7lein", "Sil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bis in die Alp gar wild und stille.", "tokens": ["Bis", "in", "die", "Alp", "gar", "wild", "und", "stil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ADV", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "O Herr und Meister, lieber Sankt Meinrad,", "tokens": ["O", "Herr", "und", "Meis\u00b7ter", ",", "lie\u00b7ber", "Sankt", "Mein\u00b7rad", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$,", "ADV", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wir haben Fischlein schon mehr als satt;", "tokens": ["Wir", "ha\u00b7ben", "Fisc\u00b7hlein", "schon", "mehr", "als", "satt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "PIAT", "KOKOM", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Noch nit genug Meinrad da saget,", "tokens": ["Noch", "nit", "ge\u00b7nug", "Mein\u00b7rad", "da", "sa\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Steigt wo der Finsterwald herraget.", "tokens": ["Steigt", "wo", "der", "Fins\u00b7ter\u00b7wald", "her\u00b7ra\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Und da sie gegangen den dritten Tag", "tokens": ["Und", "da", "sie", "ge\u00b7gan\u00b7gen", "den", "drit\u00b7ten", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVPP", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Im finstern Wald eine Matte lag;", "tokens": ["Im", "fins\u00b7tern", "Wald", "ei\u00b7ne", "Mat\u00b7te", "lag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Born da unter Steinen quillet,", "tokens": ["Ein", "Born", "da", "un\u00b7ter", "Stei\u00b7nen", "quil\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da hat Sankt Meinrad den Durst gestillet.", "tokens": ["Da", "hat", "Sankt", "Mein\u00b7rad", "den", "Durst", "ge\u00b7stil\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVFIN", "NE", "ART", "NN", "VVPP", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}}, "stanza.12": {"line.1": {"text": "Nun lieber Bruder, nun ists genug,", "tokens": ["Nun", "lie\u00b7ber", "Bru\u00b7der", ",", "nun", "ists", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "$,", "ADV", "VAFIN", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gen Rapperswyl die Fisch er trug;", "tokens": ["Gen", "Rap\u00b7per\u00b7swyl", "die", "Fisch", "er", "trug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die fromm Wittib stand vor der Pforten,", "tokens": ["Die", "fromm", "Wit\u00b7tib", "stand", "vor", "der", "Pfor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und gr\u00fc\u00dft die M\u00fcnch mit frohen Worten.", "tokens": ["Und", "gr\u00fc\u00dft", "die", "M\u00fcnch", "mit", "fro\u00b7hen", "Wor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Willkomm, willkomm ihr bleibt schier lang,", "tokens": ["Will\u00b7komm", ",", "will\u00b7komm", "ihr", "bleibt", "schier", "lang", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die rei\u00dfende Thier, die machten mich bang;", "tokens": ["Die", "rei\u00b7\u00dfen\u00b7de", "Thier", ",", "die", "mach\u00b7ten", "mich", "bang", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Fisch, die th\u00e4t sie braten und sieden,", "tokens": ["Die", "Fisch", ",", "die", "th\u00e4t", "sie", "bra\u00b7ten", "und", "sie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "PPER", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die assen sie in Gottes Frieden.", "tokens": ["Die", "as\u00b7sen", "sie", "in", "Got\u00b7tes", "Frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Frau h\u00f6rt mich an durch Gott den Herrn! \u2013", "tokens": ["Frau", "h\u00f6rt", "mich", "an", "durch", "Gott", "den", "Herrn", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "APPR", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wittib sprach: Das thu ich gern!", "tokens": ["Die", "Wit\u00b7tib", "sprach", ":", "Das", "thu", "ich", "gern", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein armer Priester hat das Begehren,", "tokens": ["Ein", "ar\u00b7mer", "Pries\u00b7ter", "hat", "das", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sein Leben im Finsterwald zu verzehren.", "tokens": ["Sein", "Le\u00b7ben", "im", "Fins\u00b7ter\u00b7wald", "zu", "ver\u00b7zeh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Nun sprecht ob hier ein Frommer leb,", "tokens": ["Nun", "sprecht", "ob", "hier", "ein", "From\u00b7mer", "leb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ihm ein klein Almosen geb;", "tokens": ["Der", "ihm", "ein", "klein", "Al\u00b7mo\u00b7sen", "geb", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sprach: Ich bin allein allhiere,", "tokens": ["Sie", "sprach", ":", "Ich", "bin", "al\u00b7lein", "all\u00b7hie\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich werd ihm ein Almoseniere.", "tokens": ["Ich", "werd", "ihm", "ein", "Al\u00b7mo\u00b7se\u00b7nie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Da th\u00e4t Sankt Meinrad ihr vertrauen,", "tokens": ["Da", "th\u00e4t", "Sankt", "Mein\u00b7rad", "ihr", "ver\u00b7trau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVFIN", "NE", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er sich wollt ein Zelle bauen;", "tokens": ["Da\u00df", "er", "sich", "wollt", "ein", "Zel\u00b7le", "bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und kehrt nach Oberpollingen,", "tokens": ["Und", "kehrt", "nach", "O\u00b7ber\u00b7pol\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Th\u00e4t noch ein Jahr da beten und singen.", "tokens": ["Th\u00e4t", "noch", "ein", "Jahr", "da", "be\u00b7ten", "und", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Aber die Einsamkeit dr\u00e4ngt ihn sehr,", "tokens": ["A\u00b7ber", "die", "Ein\u00b7sam\u00b7keit", "dr\u00e4ngt", "ihn", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Er hat kein ruhig Stund da mehr;", "tokens": ["Er", "hat", "kein", "ru\u00b7hig", "Stund", "da", "mehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJD", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und eilt nach Rapperswyl zu der Frauen,", "tokens": ["Und", "eilt", "nach", "Rap\u00b7per\u00b7swyl", "zu", "der", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die lie\u00df ihm da seine Zelle bauen.", "tokens": ["Die", "lie\u00df", "ihm", "da", "sei\u00b7ne", "Zel\u00b7le", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Am Etzel wohnt er sieben Jahr,", "tokens": ["Am", "Et\u00b7zel", "wohnt", "er", "sie\u00b7ben", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel fromme Leut die kamen dar;", "tokens": ["Viel", "from\u00b7me", "Leut", "die", "ka\u00b7men", "dar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ART", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Seine Heiligkeit macht gro\u00df Geschrey,", "tokens": ["Sei\u00b7ne", "Hei\u00b7lig\u00b7keit", "macht", "gro\u00df", "Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und zog da gar viel Volks herbei.", "tokens": ["Und", "zog", "da", "gar", "viel", "Volks", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Solch weltlich Ehr bracht ihm viel Schmerz,", "tokens": ["Solch", "welt\u00b7lich", "Ehr", "bracht", "ihm", "viel", "Schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sein H\u00fcttlein r\u00fcckt er waldeinw\u00e4rts;", "tokens": ["Sein", "H\u00fctt\u00b7lein", "r\u00fcckt", "er", "wal\u00b7de\u00b7in\u00b7w\u00e4rts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zum finstern Wald, wo das Br\u00fcnnlein quillet,", "tokens": ["Zum", "fins\u00b7tern", "Wald", ",", "wo", "das", "Br\u00fcnn\u00b7lein", "quil\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das ihm einst seinen Durst gestillet.", "tokens": ["Das", "ihm", "einst", "sei\u00b7nen", "Durst", "ge\u00b7stil\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Und wenn er sich das Holz abhaut,", "tokens": ["Und", "wenn", "er", "sich", "das", "Holz", "ab\u00b7haut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daraus er seine Zelle baut;", "tokens": ["Da\u00b7raus", "er", "sei\u00b7ne", "Zel\u00b7le", "baut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Findt er ein Nest mit jungen Raben,", "tokens": ["Findt", "er", "ein", "Nest", "mit", "jun\u00b7gen", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die th\u00e4t er da mit Brod erlaben.", "tokens": ["Die", "th\u00e4t", "er", "da", "mit", "Brod", "er\u00b7la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Die fromm Frau auch von Rapperswyl", "tokens": ["Die", "fromm", "Frau", "auch", "von", "Rap\u00b7per\u00b7swyl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "ADV", "APPR", "NE"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schickt ihm Almosen ein gut Theil;", "tokens": ["Schickt", "ihm", "Al\u00b7mo\u00b7sen", "ein", "gut", "Theil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So lebt er w\u00e4hrend funfzehn Jahren,", "tokens": ["So", "lebt", "er", "w\u00e4h\u00b7rend", "funf\u00b7zehn", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Freund die beiden Raben waren.", "tokens": ["Sein", "Freund", "die", "bei\u00b7den", "Ra\u00b7ben", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Von Wollrau war ein Zimmermann,", "tokens": ["Von", "Woll\u00b7rau", "war", "ein", "Zim\u00b7mer\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der kam da zu dem Wald heran;", "tokens": ["Der", "kam", "da", "zu", "dem", "Wald", "he\u00b7ran", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und bat auch den St. Meinrad eben,", "tokens": ["Und", "bat", "auch", "den", "St.", "Mein\u00b7rad", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NE", "NE", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sein Kindlein aus der Tauf zu heben.", "tokens": ["Sein", "Kin\u00b7dlein", "aus", "der", "Tauf", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Da gieng St. Meinrad hinab ins Land,", "tokens": ["Da", "gieng", "St.", "Mein\u00b7rad", "hin\u00b7ab", "ins", "Land", ","], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Zimmermann zur Taufe stand;", "tokens": ["Dem", "Zim\u00b7mer\u00b7mann", "zur", "Tau\u00b7fe", "stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kam da wieder zu vielen Ehren,", "tokens": ["Und", "kam", "da", "wie\u00b7der", "zu", "vie\u00b7len", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das th\u00e4ten zwei b\u00f6se M\u00f6rder h\u00f6ren.", "tokens": ["Das", "th\u00e4\u00b7ten", "zwei", "b\u00f6\u00b7se", "M\u00f6r\u00b7der", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "CARD", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Peter und Reinhard dachten wohl,", "tokens": ["Pe\u00b7ter", "und", "Rein\u00b7hard", "dach\u00b7ten", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "VVFIN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "St. Meinrads Opferstock w\u00e4r voll;", "tokens": ["St.", "Mein\u00b7rads", "Op\u00b7fer\u00b7stock", "w\u00e4r", "voll", ";"], "token_info": ["abbreviation", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie sie zum Finsterwald eintreten,", "tokens": ["Und", "wie", "sie", "zum", "Fins\u00b7ter\u00b7wald", "ein\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Raben schreien in gro\u00dfen N\u00f6then.", "tokens": ["Die", "Ra\u00b7ben", "schrei\u00b7en", "in", "gro\u00b7\u00dfen", "N\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.25": {"line.1": {"text": "St. Meinrad las' die Me\u00df zur Stund,", "tokens": ["St.", "Mein\u00b7rad", "las'", "die", "Me\u00df", "zur", "Stund", ","], "token_info": ["abbreviation", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Der Herr th\u00e4t ihm sein St\u00fcndlein kund;", "tokens": ["Der", "Herr", "th\u00e4t", "ihm", "sein", "St\u00fcnd\u00b7lein", "kund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da betet er aus ganzer Seele,", "tokens": ["Da", "be\u00b7tet", "er", "aus", "gan\u00b7zer", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ihn der Himmel auserw\u00e4hle.", "tokens": ["Da\u00df", "ihn", "der", "Him\u00b7mel", "au\u00b7ser\u00b7w\u00e4h\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Die M\u00f6rder schlagen an die Th\u00fcr:", "tokens": ["Die", "M\u00f6r\u00b7der", "schla\u00b7gen", "an", "die", "Th\u00fcr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du b\u00f6ser M\u00fcnich tret herf\u00fcr;", "tokens": ["Du", "b\u00f6\u00b7ser", "M\u00fc\u00b7nich", "tret", "her\u00b7f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Thu auf, gieb uns dein Geld zusammen,", "tokens": ["Thu", "auf", ",", "gieb", "uns", "dein", "Geld", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVIMP", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst stecken wir dein Haus in Flammen.", "tokens": ["Sonst", "ste\u00b7cken", "wir", "dein", "Haus", "in", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Im Finsterwald schallts ganz verworrn,", "tokens": ["Im", "Fins\u00b7ter\u00b7wald", "schallts", "ganz", "ver\u00b7worrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Raben mehren ihren Zorn;", "tokens": ["Die", "Ra\u00b7ben", "meh\u00b7ren", "ih\u00b7ren", "Zorn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um ihre H\u00e4upter sie w\u00fcthend kreisen,", "tokens": ["Um", "ih\u00b7re", "H\u00e4up\u00b7ter", "sie", "w\u00fct\u00b7hend", "krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nach ihren Augen hakken und bei\u00dfen.", "tokens": ["Nach", "ih\u00b7ren", "Au\u00b7gen", "hak\u00b7ken", "und", "bei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.28": {"line.1": {"text": "St. Meinrad sanft zu ihnen tritt,", "tokens": ["St.", "Mein\u00b7rad", "sanft", "zu", "ih\u00b7nen", "tritt", ","], "token_info": ["abbreviation", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bringt ihnen Brod und Wasser mit;", "tokens": ["Bringt", "ih\u00b7nen", "Brod", "und", "Was\u00b7ser", "mit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "E\u00dft, trinkt, ihr G\u00e4ste, seyd willkommen,", "tokens": ["E\u00dft", ",", "trinkt", ",", "ihr", "G\u00e4s\u00b7te", ",", "seyd", "will\u00b7kom\u00b7men", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dann thut, warum ihr hergekommen.", "tokens": ["Dann", "thut", ",", "wa\u00b7rum", "ihr", "her\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Der Reinhard sprach: Warum komm ich?", "tokens": ["Der", "Rein\u00b7hard", "sprach", ":", "Wa\u00b7rum", "komm", "ich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "St. Meinrad sprach: Zu t\u00f6dten mich;", "tokens": ["St.", "Mein\u00b7rad", "sprach", ":", "Zu", "t\u00f6d\u00b7ten", "mich", ";"], "token_info": ["abbreviation", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "PTKZU", "VVINF", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da schrien sie beide: Kannst du es wissen?", "tokens": ["Da", "schri\u00b7en", "sie", "bei\u00b7de", ":", "Kannst", "du", "es", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "$.", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So werden wirs vollbringen m\u00fcssen.", "tokens": ["So", "wer\u00b7den", "wirs", "voll\u00b7brin\u00b7gen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Nun gieb dein Silber und all dein Gut! \u2013", "tokens": ["Nun", "gieb", "dein", "Sil\u00b7ber", "und", "all", "dein", "Gut", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVIMP", "PPOSAT", "NN", "KON", "PIAT", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da schlugen sie ihn wohl aufs Blut;", "tokens": ["Da", "schlu\u00b7gen", "sie", "ihn", "wohl", "aufs", "Blut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und da sie seine Armuth sahen,", "tokens": ["Und", "da", "sie", "sei\u00b7ne", "Ar\u00b7muth", "sa\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Th\u00e4ten sie ihn zu Boden schlagen.", "tokens": ["Th\u00e4\u00b7ten", "sie", "ihn", "zu", "Bo\u00b7den", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.31": {"line.1": {"text": "Da sprach der liebe Gottesmann:", "tokens": ["Da", "sprach", "der", "lie\u00b7be", "Got\u00b7tes\u00b7mann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr lieben Freund nun h\u00f6rt mich an;", "tokens": ["Ihr", "lie\u00b7ben", "Freund", "nun", "h\u00f6rt", "mich", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Z\u00fcndt mir ein Licht zu meiner Leiche,", "tokens": ["Z\u00fcndt", "mir", "ein", "Licht", "zu", "mei\u00b7ner", "Lei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dann eilt, da\u00df euch kein Feind erreiche.", "tokens": ["Dann", "eilt", ",", "da\u00df", "euch", "kein", "Feind", "er\u00b7rei\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Der Peter gieng da zur Kapell,", "tokens": ["Der", "Pe\u00b7ter", "gieng", "da", "zur", "Ka\u00b7pell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu z\u00fcnden an die Kerze hell;", "tokens": ["Zu", "z\u00fcn\u00b7den", "an", "die", "Ker\u00b7ze", "hell", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die th\u00e4t durch Gott von selbst erbrennen,", "tokens": ["Die", "th\u00e4t", "durch", "Gott", "von", "selbst", "er\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die M\u00f6rder da ihr Schuld erkennen.", "tokens": ["Die", "M\u00f6r\u00b7der", "da", "ihr", "Schuld", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Die Kerze brennt an seiner Seit,", "tokens": ["Die", "Ker\u00b7ze", "brennt", "an", "sei\u00b7ner", "Seit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Wohlgeruch sich auch verbreit;", "tokens": ["Ein", "Wohl\u00b7ge\u00b7ruch", "sich", "auch", "ver\u00b7breit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Seel th\u00e4t zu dem Himmel ziehen,", "tokens": ["Sein", "Seel", "th\u00e4t", "zu", "dem", "Him\u00b7mel", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die M\u00f6rder da erschrocken fliehen.", "tokens": ["Die", "M\u00f6r\u00b7der", "da", "er\u00b7schro\u00b7cken", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Aber die frommen Raben beid,", "tokens": ["A\u00b7ber", "die", "from\u00b7men", "Ra\u00b7ben", "beid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die gaben ihnen b\u00f6s Geleit;", "tokens": ["Die", "ga\u00b7ben", "ih\u00b7nen", "b\u00f6s", "Ge\u00b7leit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um ihre H\u00e4upter sie zornig kreisen,", "tokens": ["Um", "ih\u00b7re", "H\u00e4up\u00b7ter", "sie", "zor\u00b7nig", "krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und ihnen Haar und Stirn zerreissen.", "tokens": ["Und", "ih\u00b7nen", "Haar", "und", "Stirn", "zer\u00b7reis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Durch Wolrau kamen sie gerannt,", "tokens": ["Durch", "Wol\u00b7rau", "ka\u00b7men", "sie", "ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Zimmermann die Raben kannt;", "tokens": ["Der", "Zim\u00b7mer\u00b7mann", "die", "Ra\u00b7ben", "kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da th\u00e4t er seinen Bruder bitten,", "tokens": ["Da", "th\u00e4t", "er", "sei\u00b7nen", "Bru\u00b7der", "bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu folgen ihren wilden Schritten.", "tokens": ["Zu", "fol\u00b7gen", "ih\u00b7ren", "wil\u00b7den", "Schrit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Inde\u00df lief er in den Finsterwald,", "tokens": ["In\u00b7de\u00df", "lief", "er", "in", "den", "Fins\u00b7ter\u00b7wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sucht seinen lieben Gevatter bald;", "tokens": ["Sucht", "sei\u00b7nen", "lie\u00b7ben", "Ge\u00b7vat\u00b7ter", "bald", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der lag erschlagen auf gr\u00fcner Heide,", "tokens": ["Der", "lag", "er\u00b7schla\u00b7gen", "auf", "gr\u00fc\u00b7ner", "Hei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Kerze brannt an seiner Seite.", "tokens": ["Die", "Ker\u00b7ze", "brannt", "an", "sei\u00b7ner", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Er k\u00fc\u00dft ihn auf den blutgen Mund,", "tokens": ["Er", "k\u00fc\u00dft", "ihn", "auf", "den", "blut\u00b7gen", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00fcllt in den Mantel ihn zur Stund;", "tokens": ["H\u00fcllt", "in", "den", "Man\u00b7tel", "ihn", "zur", "Stund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "APPRART", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Legt weinend ihn in die Kapelle,", "tokens": ["Legt", "wei\u00b7nend", "ihn", "in", "die", "Ka\u00b7pel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An seines heilgen Altars Schwelle.", "tokens": ["An", "sei\u00b7nes", "heil\u00b7gen", "Al\u00b7tars", "Schwel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Und eilt herunter in das Land,", "tokens": ["Und", "eilt", "her\u00b7un\u00b7ter", "in", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Jammer allen macht bekannt;", "tokens": ["Sein", "Jam\u00b7mer", "al\u00b7len", "macht", "be\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PIAT", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schickt hinauf sein Kind und Frauen,", "tokens": ["Und", "schickt", "hin\u00b7auf", "sein", "Kind", "und", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nach ihrem heilgen Freund zu schauen.", "tokens": ["Nach", "ih\u00b7rem", "heil\u00b7gen", "Freund", "zu", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Die M\u00f6rder fand er im Wirthshaus,", "tokens": ["Die", "M\u00f6r\u00b7der", "fand", "er", "im", "Wirths\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "An der Schifflande zu Z\u00fcrich draus;", "tokens": ["An", "der", "Schif\u00b7flan\u00b7de", "zu", "Z\u00fc\u00b7rich", "draus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "PAV", "$."], "meter": "--+---+-+", "measure": "anapaest.init"}, "line.3": {"text": "Die Raben stie\u00dfen die Fenster ein,", "tokens": ["Die", "Ra\u00b7ben", "stie\u00b7\u00dfen", "die", "Fens\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und warfen um das Bier und Wein.", "tokens": ["Und", "war\u00b7fen", "um", "das", "Bier", "und", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Die M\u00f6rder man ergriff und band,", "tokens": ["Die", "M\u00f6r\u00b7der", "man", "er\u00b7griff", "und", "band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Schuld, die haben sie bekannt;", "tokens": ["Ihr", "Schuld", ",", "die", "ha\u00b7ben", "sie", "be\u00b7kannt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und bis hin auf den Scheiterhaufen,", "tokens": ["Und", "bis", "hin", "auf", "den", "Schei\u00b7ter\u00b7hau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Raben sie wohl hakken und raufen.", "tokens": ["Die", "Ra\u00b7ben", "sie", "wohl", "hak\u00b7ken", "und", "rau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.41": {"line.1": {"text": "Der Abt zu Reichenau da h\u00f6rt,", "tokens": ["Der", "Abt", "zu", "Rei\u00b7che\u00b7nau", "da", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der fromm St. Meinrad sey erm\u00f6rdt;", "tokens": ["Der", "fromm", "St.", "Mein\u00b7rad", "sey", "er\u00b7m\u00f6rdt", ";"], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NE", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Schickt auch mit Licht und Fahn viel Br\u00fcder,", "tokens": ["Schickt", "auch", "mit", "Licht", "und", "Fahn", "viel", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu holen des St. Meinrads Glieder.", "tokens": ["Zu", "ho\u00b7len", "des", "St.", "Mein\u00b7rads", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NE", "NE", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.42": {"line.1": {"text": "Und da der Leib zum Etzel kam,", "tokens": ["Und", "da", "der", "Leib", "zum", "Et\u00b7zel", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo er gewohnt der heilge Mann;", "tokens": ["Wo", "er", "ge\u00b7wohnt", "der", "heil\u00b7ge", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da war der Sarg nicht zu bewegen,", "tokens": ["Da", "war", "der", "Sarg", "nicht", "zu", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie mu\u00dften ihn da niederlegen.", "tokens": ["Sie", "mu\u00df\u00b7ten", "ihn", "da", "nie\u00b7der\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Sein heilig Herz und Ingeweid", "tokens": ["Sein", "hei\u00b7lig", "Herz", "und", "In\u00b7ge\u00b7weid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie da begruben zu der Zeit;", "tokens": ["Sie", "da", "be\u00b7gru\u00b7ben", "zu", "der", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Leib sie dann mit Beten und Singen", "tokens": ["Den", "Leib", "sie", "dann", "mit", "Be\u00b7ten", "und", "Sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nach Reichenau zur Kirche bringen.", "tokens": ["Nach", "Rei\u00b7che\u00b7nau", "zur", "Kir\u00b7che", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Wo er gestorben und gelebt,", "tokens": ["Wo", "er", "ge\u00b7stor\u00b7ben", "und", "ge\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Kloster Einsiedeln sich erhebt;", "tokens": ["Das", "Klos\u00b7ter", "Ein\u00b7sie\u00b7deln", "sich", "er\u00b7hebt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PRF", "VVFIN", "$."], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "F\u00fcr fromme Pilger ein Wunderquelle,", "tokens": ["F\u00fcr", "from\u00b7me", "Pil\u00b7ger", "ein", "Wun\u00b7der\u00b7quel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Quillt dort in St. Meinrads Kapelle.", "tokens": ["Quillt", "dort", "in", "St.", "Mein\u00b7rads", "Ka\u00b7pel\u00b7le", "."], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NE", "NE", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.45": {"line.1": {"text": "Graf Berthold von Sulchen, der fromme Mann,", "tokens": ["Graf", "Bert\u00b7hold", "von", "Sul\u00b7chen", ",", "der", "from\u00b7me", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Er f\u00fchrt sein S\u00f6hnlein an der Hand;", "tokens": ["Er", "f\u00fchrt", "sein", "S\u00f6hn\u00b7lein", "an", "der", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Meinrad, mein S\u00f6hnlein von f\u00fcnf Jahren,", "tokens": ["Mein\u00b7rad", ",", "mein", "S\u00f6hn\u00b7lein", "von", "f\u00fcnf", "Jah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du mu\u00dft mit mir gen Reichenau fahren.", "tokens": ["Du", "mu\u00dft", "mit", "mir", "gen", "Rei\u00b7che\u00b7nau", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.46": {"line.1": {"text": "Hatto, Hatto, nimm hin das Kind,", "tokens": ["Hat\u00b7to", ",", "Hat\u00b7to", ",", "nimm", "hin", "das", "Kind", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VVIMP", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Alle liebe Engelein mit ihm sind;", "tokens": ["Al\u00b7le", "lie\u00b7be", "En\u00b7ge\u00b7lein", "mit", "ihm", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "PPER", "VAFIN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Die geistlich Zucht mag er wohl lernen,", "tokens": ["Die", "geist\u00b7lich", "Zucht", "mag", "er", "wohl", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und mag ein Spiegel der M\u00fcnche werden.", "tokens": ["Und", "mag", "ein", "Spie\u00b7gel", "der", "M\u00fcn\u00b7che", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.47": {"line.1": {"text": "Er ging zur Schul barfu\u00df ohne Schuh;", "tokens": ["Er", "ging", "zur", "Schul", "bar\u00b7fu\u00df", "oh\u00b7ne", "Schuh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und legt die geistlich Kunst sich zu;", "tokens": ["Und", "legt", "die", "geist\u00b7lich", "Kunst", "sich", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJD", "NN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Weisheit kam ihm vor der Zeit,", "tokens": ["Die", "Weis\u00b7heit", "kam", "ihm", "vor", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da ward er zu einem Priester geweiht.", "tokens": ["Da", "ward", "er", "zu", "ei\u00b7nem", "Pries\u00b7ter", "ge\u00b7weiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.48": {"line.1": {"text": "Da schickt ihn Hatto auf den Z\u00fcrcher See,", "tokens": ["Da", "schickt", "ihn", "Hat\u00b7to", "auf", "den", "Z\u00fcr\u00b7cher", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df er ins Kl\u00f6sterlein bei Jona geh;", "tokens": ["Da\u00df", "er", "ins", "Kl\u00f6s\u00b7ter\u00b7lein", "bei", "Jo\u00b7na", "geh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bei Jona zu Oberpollingen,", "tokens": ["Bei", "Jo\u00b7na", "zu", "O\u00b7ber\u00b7pol\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Da lehrt er die M\u00fcnch beten und singen.", "tokens": ["Da", "lehrt", "er", "die", "M\u00fcnch", "be\u00b7ten", "und", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "VVINF", "KON", "VVFIN", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}}, "stanza.49": {"line.1": {"text": "Da er lange ihr Schulmeister war,", "tokens": ["Da", "er", "lan\u00b7ge", "ihr", "Schul\u00b7meis\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und ihn die Br\u00fcder ehrten gar;", "tokens": ["Und", "ihn", "die", "Br\u00fc\u00b7der", "ehr\u00b7ten", "gar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Th\u00e4t er oft an dem Ufer stehen,", "tokens": ["Th\u00e4t", "er", "oft", "an", "dem", "U\u00b7fer", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und nach dem wilden Gebirg hinsehen.", "tokens": ["Und", "nach", "dem", "wil\u00b7den", "Ge\u00b7birg", "hin\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.50": {"line.1": {"text": "Sein Gewissen zog ihn zur W\u00fcste hin,", "tokens": ["Sein", "Ge\u00b7wis\u00b7sen", "zog", "ihn", "zur", "W\u00fcs\u00b7te", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zur Einsamkeit stand all sein Sinn;", "tokens": ["Zur", "Ein\u00b7sam\u00b7keit", "stand", "all", "sein", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er sprach zu einem M\u00fcnch: Mein Bruder,", "tokens": ["Er", "sprach", "zu", "ei\u00b7nem", "M\u00fcnch", ":", "Mein", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "R\u00fcst uns ein Schifflein und zwey Ruder.", "tokens": ["R\u00fcst", "uns", "ein", "Schif\u00b7flein", "und", "zwey", "Ru\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "KON", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Ueber See zur Wildni\u00df zur W\u00fcsteney,", "tokens": ["Ue\u00b7ber", "See", "zur", "Wild\u00b7ni\u00df", "zur", "W\u00fcs\u00b7te\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Hab ich geh\u00f6rt gut fischen sey;", "tokens": ["Hab", "ich", "ge\u00b7h\u00f6rt", "gut", "fi\u00b7schen", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "ADJD", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da gehn die Fischlein in den einsamen B\u00e4chen! \u2013", "tokens": ["Da", "gehn", "die", "Fisc\u00b7hlein", "in", "den", "ein\u00b7sa\u00b7men", "B\u00e4\u00b7chen", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ja Herr, mein Meister, der M\u00fcnch th\u00e4t sprechen.", "tokens": ["Ja", "Herr", ",", "mein", "Meis\u00b7ter", ",", "der", "M\u00fcnch", "th\u00e4t", "spre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.52": {"line.1": {"text": "Sie fuhren gen Rapperswyl \u00fcber See,", "tokens": ["Sie", "fuh\u00b7ren", "gen", "Rap\u00b7per\u00b7swyl", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Zu einer frommen Wittib sie da gehn;", "tokens": ["Zu", "ei\u00b7ner", "from\u00b7men", "Wit\u00b7tib", "sie", "da", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bewahr uns die Gewand, sie zu ihr sprechen,", "tokens": ["Be\u00b7wahr", "uns", "die", "Ge\u00b7wand", ",", "sie", "zu", "ihr", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df sie uns nicht in der Wildni\u00df zerbrechen.", "tokens": ["Da\u00df", "sie", "uns", "nicht", "in", "der", "Wild\u00b7ni\u00df", "zer\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.53": {"line.1": {"text": "Sankt Meinrad und der Bruder gut,", "tokens": ["Sankt", "Mein\u00b7rad", "und", "der", "Bru\u00b7der", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "ART", "NN", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sie folgten wohl der B\u00e4chlein Fluth;", "tokens": ["Sie", "folg\u00b7ten", "wohl", "der", "B\u00e4ch\u00b7lein", "Fluth", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie fischten hinan in dem Fl\u00fc\u00dflein Sille,", "tokens": ["Sie", "fischten", "hi\u00b7nan", "in", "dem", "Fl\u00fc\u00df\u00b7lein", "Sil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bis in die Alp gar wild und stille.", "tokens": ["Bis", "in", "die", "Alp", "gar", "wild", "und", "stil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ADV", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "O Herr und Meister, lieber Sankt Meinrad,", "tokens": ["O", "Herr", "und", "Meis\u00b7ter", ",", "lie\u00b7ber", "Sankt", "Mein\u00b7rad", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$,", "ADV", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wir haben Fischlein schon mehr als satt;", "tokens": ["Wir", "ha\u00b7ben", "Fisc\u00b7hlein", "schon", "mehr", "als", "satt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "PIAT", "KOKOM", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Noch nit genug Meinrad da saget,", "tokens": ["Noch", "nit", "ge\u00b7nug", "Mein\u00b7rad", "da", "sa\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Steigt wo der Finsterwald herraget.", "tokens": ["Steigt", "wo", "der", "Fins\u00b7ter\u00b7wald", "her\u00b7ra\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.55": {"line.1": {"text": "Und da sie gegangen den dritten Tag", "tokens": ["Und", "da", "sie", "ge\u00b7gan\u00b7gen", "den", "drit\u00b7ten", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVPP", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Im finstern Wald eine Matte lag;", "tokens": ["Im", "fins\u00b7tern", "Wald", "ei\u00b7ne", "Mat\u00b7te", "lag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Born da unter Steinen quillet,", "tokens": ["Ein", "Born", "da", "un\u00b7ter", "Stei\u00b7nen", "quil\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da hat Sankt Meinrad den Durst gestillet.", "tokens": ["Da", "hat", "Sankt", "Mein\u00b7rad", "den", "Durst", "ge\u00b7stil\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVFIN", "NE", "ART", "NN", "VVPP", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}}, "stanza.56": {"line.1": {"text": "Nun lieber Bruder, nun ists genug,", "tokens": ["Nun", "lie\u00b7ber", "Bru\u00b7der", ",", "nun", "ists", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "$,", "ADV", "VAFIN", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gen Rapperswyl die Fisch er trug;", "tokens": ["Gen", "Rap\u00b7per\u00b7swyl", "die", "Fisch", "er", "trug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die fromm Wittib stand vor der Pforten,", "tokens": ["Die", "fromm", "Wit\u00b7tib", "stand", "vor", "der", "Pfor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und gr\u00fc\u00dft die M\u00fcnch mit frohen Worten.", "tokens": ["Und", "gr\u00fc\u00dft", "die", "M\u00fcnch", "mit", "fro\u00b7hen", "Wor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Willkomm, willkomm ihr bleibt schier lang,", "tokens": ["Will\u00b7komm", ",", "will\u00b7komm", "ihr", "bleibt", "schier", "lang", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die rei\u00dfende Thier, die machten mich bang;", "tokens": ["Die", "rei\u00b7\u00dfen\u00b7de", "Thier", ",", "die", "mach\u00b7ten", "mich", "bang", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Fisch, die th\u00e4t sie braten und sieden,", "tokens": ["Die", "Fisch", ",", "die", "th\u00e4t", "sie", "bra\u00b7ten", "und", "sie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "PPER", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die assen sie in Gottes Frieden.", "tokens": ["Die", "as\u00b7sen", "sie", "in", "Got\u00b7tes", "Frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Frau h\u00f6rt mich an durch Gott den Herrn! \u2013", "tokens": ["Frau", "h\u00f6rt", "mich", "an", "durch", "Gott", "den", "Herrn", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "APPR", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wittib sprach: Das thu ich gern!", "tokens": ["Die", "Wit\u00b7tib", "sprach", ":", "Das", "thu", "ich", "gern", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein armer Priester hat das Begehren,", "tokens": ["Ein", "ar\u00b7mer", "Pries\u00b7ter", "hat", "das", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sein Leben im Finsterwald zu verzehren.", "tokens": ["Sein", "Le\u00b7ben", "im", "Fins\u00b7ter\u00b7wald", "zu", "ver\u00b7zeh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.59": {"line.1": {"text": "Nun sprecht ob hier ein Frommer leb,", "tokens": ["Nun", "sprecht", "ob", "hier", "ein", "From\u00b7mer", "leb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ihm ein klein Almosen geb;", "tokens": ["Der", "ihm", "ein", "klein", "Al\u00b7mo\u00b7sen", "geb", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sprach: Ich bin allein allhiere,", "tokens": ["Sie", "sprach", ":", "Ich", "bin", "al\u00b7lein", "all\u00b7hie\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich werd ihm ein Almoseniere.", "tokens": ["Ich", "werd", "ihm", "ein", "Al\u00b7mo\u00b7se\u00b7nie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Da th\u00e4t Sankt Meinrad ihr vertrauen,", "tokens": ["Da", "th\u00e4t", "Sankt", "Mein\u00b7rad", "ihr", "ver\u00b7trau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVFIN", "NE", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er sich wollt ein Zelle bauen;", "tokens": ["Da\u00df", "er", "sich", "wollt", "ein", "Zel\u00b7le", "bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und kehrt nach Oberpollingen,", "tokens": ["Und", "kehrt", "nach", "O\u00b7ber\u00b7pol\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Th\u00e4t noch ein Jahr da beten und singen.", "tokens": ["Th\u00e4t", "noch", "ein", "Jahr", "da", "be\u00b7ten", "und", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.61": {"line.1": {"text": "Aber die Einsamkeit dr\u00e4ngt ihn sehr,", "tokens": ["A\u00b7ber", "die", "Ein\u00b7sam\u00b7keit", "dr\u00e4ngt", "ihn", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Er hat kein ruhig Stund da mehr;", "tokens": ["Er", "hat", "kein", "ru\u00b7hig", "Stund", "da", "mehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJD", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und eilt nach Rapperswyl zu der Frauen,", "tokens": ["Und", "eilt", "nach", "Rap\u00b7per\u00b7swyl", "zu", "der", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die lie\u00df ihm da seine Zelle bauen.", "tokens": ["Die", "lie\u00df", "ihm", "da", "sei\u00b7ne", "Zel\u00b7le", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.62": {"line.1": {"text": "Am Etzel wohnt er sieben Jahr,", "tokens": ["Am", "Et\u00b7zel", "wohnt", "er", "sie\u00b7ben", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel fromme Leut die kamen dar;", "tokens": ["Viel", "from\u00b7me", "Leut", "die", "ka\u00b7men", "dar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ART", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Seine Heiligkeit macht gro\u00df Geschrey,", "tokens": ["Sei\u00b7ne", "Hei\u00b7lig\u00b7keit", "macht", "gro\u00df", "Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und zog da gar viel Volks herbei.", "tokens": ["Und", "zog", "da", "gar", "viel", "Volks", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Solch weltlich Ehr bracht ihm viel Schmerz,", "tokens": ["Solch", "welt\u00b7lich", "Ehr", "bracht", "ihm", "viel", "Schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sein H\u00fcttlein r\u00fcckt er waldeinw\u00e4rts;", "tokens": ["Sein", "H\u00fctt\u00b7lein", "r\u00fcckt", "er", "wal\u00b7de\u00b7in\u00b7w\u00e4rts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zum finstern Wald, wo das Br\u00fcnnlein quillet,", "tokens": ["Zum", "fins\u00b7tern", "Wald", ",", "wo", "das", "Br\u00fcnn\u00b7lein", "quil\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das ihm einst seinen Durst gestillet.", "tokens": ["Das", "ihm", "einst", "sei\u00b7nen", "Durst", "ge\u00b7stil\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Und wenn er sich das Holz abhaut,", "tokens": ["Und", "wenn", "er", "sich", "das", "Holz", "ab\u00b7haut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daraus er seine Zelle baut;", "tokens": ["Da\u00b7raus", "er", "sei\u00b7ne", "Zel\u00b7le", "baut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Findt er ein Nest mit jungen Raben,", "tokens": ["Findt", "er", "ein", "Nest", "mit", "jun\u00b7gen", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die th\u00e4t er da mit Brod erlaben.", "tokens": ["Die", "th\u00e4t", "er", "da", "mit", "Brod", "er\u00b7la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Die fromm Frau auch von Rapperswyl", "tokens": ["Die", "fromm", "Frau", "auch", "von", "Rap\u00b7per\u00b7swyl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "ADV", "APPR", "NE"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schickt ihm Almosen ein gut Theil;", "tokens": ["Schickt", "ihm", "Al\u00b7mo\u00b7sen", "ein", "gut", "Theil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So lebt er w\u00e4hrend funfzehn Jahren,", "tokens": ["So", "lebt", "er", "w\u00e4h\u00b7rend", "funf\u00b7zehn", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Freund die beiden Raben waren.", "tokens": ["Sein", "Freund", "die", "bei\u00b7den", "Ra\u00b7ben", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Von Wollrau war ein Zimmermann,", "tokens": ["Von", "Woll\u00b7rau", "war", "ein", "Zim\u00b7mer\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der kam da zu dem Wald heran;", "tokens": ["Der", "kam", "da", "zu", "dem", "Wald", "he\u00b7ran", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und bat auch den St. Meinrad eben,", "tokens": ["Und", "bat", "auch", "den", "St.", "Mein\u00b7rad", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NE", "NE", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sein Kindlein aus der Tauf zu heben.", "tokens": ["Sein", "Kin\u00b7dlein", "aus", "der", "Tauf", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Da gieng St. Meinrad hinab ins Land,", "tokens": ["Da", "gieng", "St.", "Mein\u00b7rad", "hin\u00b7ab", "ins", "Land", ","], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Zimmermann zur Taufe stand;", "tokens": ["Dem", "Zim\u00b7mer\u00b7mann", "zur", "Tau\u00b7fe", "stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kam da wieder zu vielen Ehren,", "tokens": ["Und", "kam", "da", "wie\u00b7der", "zu", "vie\u00b7len", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das th\u00e4ten zwei b\u00f6se M\u00f6rder h\u00f6ren.", "tokens": ["Das", "th\u00e4\u00b7ten", "zwei", "b\u00f6\u00b7se", "M\u00f6r\u00b7der", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "CARD", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.68": {"line.1": {"text": "Peter und Reinhard dachten wohl,", "tokens": ["Pe\u00b7ter", "und", "Rein\u00b7hard", "dach\u00b7ten", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "VVFIN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "St. Meinrads Opferstock w\u00e4r voll;", "tokens": ["St.", "Mein\u00b7rads", "Op\u00b7fer\u00b7stock", "w\u00e4r", "voll", ";"], "token_info": ["abbreviation", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie sie zum Finsterwald eintreten,", "tokens": ["Und", "wie", "sie", "zum", "Fins\u00b7ter\u00b7wald", "ein\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Raben schreien in gro\u00dfen N\u00f6then.", "tokens": ["Die", "Ra\u00b7ben", "schrei\u00b7en", "in", "gro\u00b7\u00dfen", "N\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.69": {"line.1": {"text": "St. Meinrad las' die Me\u00df zur Stund,", "tokens": ["St.", "Mein\u00b7rad", "las'", "die", "Me\u00df", "zur", "Stund", ","], "token_info": ["abbreviation", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Der Herr th\u00e4t ihm sein St\u00fcndlein kund;", "tokens": ["Der", "Herr", "th\u00e4t", "ihm", "sein", "St\u00fcnd\u00b7lein", "kund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da betet er aus ganzer Seele,", "tokens": ["Da", "be\u00b7tet", "er", "aus", "gan\u00b7zer", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ihn der Himmel auserw\u00e4hle.", "tokens": ["Da\u00df", "ihn", "der", "Him\u00b7mel", "au\u00b7ser\u00b7w\u00e4h\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Die M\u00f6rder schlagen an die Th\u00fcr:", "tokens": ["Die", "M\u00f6r\u00b7der", "schla\u00b7gen", "an", "die", "Th\u00fcr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du b\u00f6ser M\u00fcnich tret herf\u00fcr;", "tokens": ["Du", "b\u00f6\u00b7ser", "M\u00fc\u00b7nich", "tret", "her\u00b7f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Thu auf, gieb uns dein Geld zusammen,", "tokens": ["Thu", "auf", ",", "gieb", "uns", "dein", "Geld", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVIMP", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst stecken wir dein Haus in Flammen.", "tokens": ["Sonst", "ste\u00b7cken", "wir", "dein", "Haus", "in", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Im Finsterwald schallts ganz verworrn,", "tokens": ["Im", "Fins\u00b7ter\u00b7wald", "schallts", "ganz", "ver\u00b7worrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Raben mehren ihren Zorn;", "tokens": ["Die", "Ra\u00b7ben", "meh\u00b7ren", "ih\u00b7ren", "Zorn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um ihre H\u00e4upter sie w\u00fcthend kreisen,", "tokens": ["Um", "ih\u00b7re", "H\u00e4up\u00b7ter", "sie", "w\u00fct\u00b7hend", "krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nach ihren Augen hakken und bei\u00dfen.", "tokens": ["Nach", "ih\u00b7ren", "Au\u00b7gen", "hak\u00b7ken", "und", "bei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.72": {"line.1": {"text": "St. Meinrad sanft zu ihnen tritt,", "tokens": ["St.", "Mein\u00b7rad", "sanft", "zu", "ih\u00b7nen", "tritt", ","], "token_info": ["abbreviation", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bringt ihnen Brod und Wasser mit;", "tokens": ["Bringt", "ih\u00b7nen", "Brod", "und", "Was\u00b7ser", "mit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "E\u00dft, trinkt, ihr G\u00e4ste, seyd willkommen,", "tokens": ["E\u00dft", ",", "trinkt", ",", "ihr", "G\u00e4s\u00b7te", ",", "seyd", "will\u00b7kom\u00b7men", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dann thut, warum ihr hergekommen.", "tokens": ["Dann", "thut", ",", "wa\u00b7rum", "ihr", "her\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Der Reinhard sprach: Warum komm ich?", "tokens": ["Der", "Rein\u00b7hard", "sprach", ":", "Wa\u00b7rum", "komm", "ich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "St. Meinrad sprach: Zu t\u00f6dten mich;", "tokens": ["St.", "Mein\u00b7rad", "sprach", ":", "Zu", "t\u00f6d\u00b7ten", "mich", ";"], "token_info": ["abbreviation", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "PTKZU", "VVINF", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da schrien sie beide: Kannst du es wissen?", "tokens": ["Da", "schri\u00b7en", "sie", "bei\u00b7de", ":", "Kannst", "du", "es", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "$.", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So werden wirs vollbringen m\u00fcssen.", "tokens": ["So", "wer\u00b7den", "wirs", "voll\u00b7brin\u00b7gen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Nun gieb dein Silber und all dein Gut! \u2013", "tokens": ["Nun", "gieb", "dein", "Sil\u00b7ber", "und", "all", "dein", "Gut", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVIMP", "PPOSAT", "NN", "KON", "PIAT", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da schlugen sie ihn wohl aufs Blut;", "tokens": ["Da", "schlu\u00b7gen", "sie", "ihn", "wohl", "aufs", "Blut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und da sie seine Armuth sahen,", "tokens": ["Und", "da", "sie", "sei\u00b7ne", "Ar\u00b7muth", "sa\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Th\u00e4ten sie ihn zu Boden schlagen.", "tokens": ["Th\u00e4\u00b7ten", "sie", "ihn", "zu", "Bo\u00b7den", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.75": {"line.1": {"text": "Da sprach der liebe Gottesmann:", "tokens": ["Da", "sprach", "der", "lie\u00b7be", "Got\u00b7tes\u00b7mann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr lieben Freund nun h\u00f6rt mich an;", "tokens": ["Ihr", "lie\u00b7ben", "Freund", "nun", "h\u00f6rt", "mich", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Z\u00fcndt mir ein Licht zu meiner Leiche,", "tokens": ["Z\u00fcndt", "mir", "ein", "Licht", "zu", "mei\u00b7ner", "Lei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dann eilt, da\u00df euch kein Feind erreiche.", "tokens": ["Dann", "eilt", ",", "da\u00df", "euch", "kein", "Feind", "er\u00b7rei\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "Der Peter gieng da zur Kapell,", "tokens": ["Der", "Pe\u00b7ter", "gieng", "da", "zur", "Ka\u00b7pell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu z\u00fcnden an die Kerze hell;", "tokens": ["Zu", "z\u00fcn\u00b7den", "an", "die", "Ker\u00b7ze", "hell", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die th\u00e4t durch Gott von selbst erbrennen,", "tokens": ["Die", "th\u00e4t", "durch", "Gott", "von", "selbst", "er\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die M\u00f6rder da ihr Schuld erkennen.", "tokens": ["Die", "M\u00f6r\u00b7der", "da", "ihr", "Schuld", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Die Kerze brennt an seiner Seit,", "tokens": ["Die", "Ker\u00b7ze", "brennt", "an", "sei\u00b7ner", "Seit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Wohlgeruch sich auch verbreit;", "tokens": ["Ein", "Wohl\u00b7ge\u00b7ruch", "sich", "auch", "ver\u00b7breit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Seel th\u00e4t zu dem Himmel ziehen,", "tokens": ["Sein", "Seel", "th\u00e4t", "zu", "dem", "Him\u00b7mel", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die M\u00f6rder da erschrocken fliehen.", "tokens": ["Die", "M\u00f6r\u00b7der", "da", "er\u00b7schro\u00b7cken", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Aber die frommen Raben beid,", "tokens": ["A\u00b7ber", "die", "from\u00b7men", "Ra\u00b7ben", "beid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die gaben ihnen b\u00f6s Geleit;", "tokens": ["Die", "ga\u00b7ben", "ih\u00b7nen", "b\u00f6s", "Ge\u00b7leit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um ihre H\u00e4upter sie zornig kreisen,", "tokens": ["Um", "ih\u00b7re", "H\u00e4up\u00b7ter", "sie", "zor\u00b7nig", "krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und ihnen Haar und Stirn zerreissen.", "tokens": ["Und", "ih\u00b7nen", "Haar", "und", "Stirn", "zer\u00b7reis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Durch Wolrau kamen sie gerannt,", "tokens": ["Durch", "Wol\u00b7rau", "ka\u00b7men", "sie", "ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Zimmermann die Raben kannt;", "tokens": ["Der", "Zim\u00b7mer\u00b7mann", "die", "Ra\u00b7ben", "kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da th\u00e4t er seinen Bruder bitten,", "tokens": ["Da", "th\u00e4t", "er", "sei\u00b7nen", "Bru\u00b7der", "bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu folgen ihren wilden Schritten.", "tokens": ["Zu", "fol\u00b7gen", "ih\u00b7ren", "wil\u00b7den", "Schrit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Inde\u00df lief er in den Finsterwald,", "tokens": ["In\u00b7de\u00df", "lief", "er", "in", "den", "Fins\u00b7ter\u00b7wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sucht seinen lieben Gevatter bald;", "tokens": ["Sucht", "sei\u00b7nen", "lie\u00b7ben", "Ge\u00b7vat\u00b7ter", "bald", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der lag erschlagen auf gr\u00fcner Heide,", "tokens": ["Der", "lag", "er\u00b7schla\u00b7gen", "auf", "gr\u00fc\u00b7ner", "Hei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Kerze brannt an seiner Seite.", "tokens": ["Die", "Ker\u00b7ze", "brannt", "an", "sei\u00b7ner", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "Er k\u00fc\u00dft ihn auf den blutgen Mund,", "tokens": ["Er", "k\u00fc\u00dft", "ihn", "auf", "den", "blut\u00b7gen", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00fcllt in den Mantel ihn zur Stund;", "tokens": ["H\u00fcllt", "in", "den", "Man\u00b7tel", "ihn", "zur", "Stund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "APPRART", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Legt weinend ihn in die Kapelle,", "tokens": ["Legt", "wei\u00b7nend", "ihn", "in", "die", "Ka\u00b7pel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An seines heilgen Altars Schwelle.", "tokens": ["An", "sei\u00b7nes", "heil\u00b7gen", "Al\u00b7tars", "Schwel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "Und eilt herunter in das Land,", "tokens": ["Und", "eilt", "her\u00b7un\u00b7ter", "in", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Jammer allen macht bekannt;", "tokens": ["Sein", "Jam\u00b7mer", "al\u00b7len", "macht", "be\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PIAT", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schickt hinauf sein Kind und Frauen,", "tokens": ["Und", "schickt", "hin\u00b7auf", "sein", "Kind", "und", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nach ihrem heilgen Freund zu schauen.", "tokens": ["Nach", "ih\u00b7rem", "heil\u00b7gen", "Freund", "zu", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Die M\u00f6rder fand er im Wirthshaus,", "tokens": ["Die", "M\u00f6r\u00b7der", "fand", "er", "im", "Wirths\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "An der Schifflande zu Z\u00fcrich draus;", "tokens": ["An", "der", "Schif\u00b7flan\u00b7de", "zu", "Z\u00fc\u00b7rich", "draus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "PAV", "$."], "meter": "--+---+-+", "measure": "anapaest.init"}, "line.3": {"text": "Die Raben stie\u00dfen die Fenster ein,", "tokens": ["Die", "Ra\u00b7ben", "stie\u00b7\u00dfen", "die", "Fens\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und warfen um das Bier und Wein.", "tokens": ["Und", "war\u00b7fen", "um", "das", "Bier", "und", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Die M\u00f6rder man ergriff und band,", "tokens": ["Die", "M\u00f6r\u00b7der", "man", "er\u00b7griff", "und", "band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Schuld, die haben sie bekannt;", "tokens": ["Ihr", "Schuld", ",", "die", "ha\u00b7ben", "sie", "be\u00b7kannt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und bis hin auf den Scheiterhaufen,", "tokens": ["Und", "bis", "hin", "auf", "den", "Schei\u00b7ter\u00b7hau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Raben sie wohl hakken und raufen.", "tokens": ["Die", "Ra\u00b7ben", "sie", "wohl", "hak\u00b7ken", "und", "rau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.85": {"line.1": {"text": "Der Abt zu Reichenau da h\u00f6rt,", "tokens": ["Der", "Abt", "zu", "Rei\u00b7che\u00b7nau", "da", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der fromm St. Meinrad sey erm\u00f6rdt;", "tokens": ["Der", "fromm", "St.", "Mein\u00b7rad", "sey", "er\u00b7m\u00f6rdt", ";"], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NE", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Schickt auch mit Licht und Fahn viel Br\u00fcder,", "tokens": ["Schickt", "auch", "mit", "Licht", "und", "Fahn", "viel", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu holen des St. Meinrads Glieder.", "tokens": ["Zu", "ho\u00b7len", "des", "St.", "Mein\u00b7rads", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NE", "NE", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.86": {"line.1": {"text": "Und da der Leib zum Etzel kam,", "tokens": ["Und", "da", "der", "Leib", "zum", "Et\u00b7zel", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo er gewohnt der heilge Mann;", "tokens": ["Wo", "er", "ge\u00b7wohnt", "der", "heil\u00b7ge", "Mann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da war der Sarg nicht zu bewegen,", "tokens": ["Da", "war", "der", "Sarg", "nicht", "zu", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie mu\u00dften ihn da niederlegen.", "tokens": ["Sie", "mu\u00df\u00b7ten", "ihn", "da", "nie\u00b7der\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.87": {"line.1": {"text": "Sein heilig Herz und Ingeweid", "tokens": ["Sein", "hei\u00b7lig", "Herz", "und", "In\u00b7ge\u00b7weid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie da begruben zu der Zeit;", "tokens": ["Sie", "da", "be\u00b7gru\u00b7ben", "zu", "der", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Leib sie dann mit Beten und Singen", "tokens": ["Den", "Leib", "sie", "dann", "mit", "Be\u00b7ten", "und", "Sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nach Reichenau zur Kirche bringen.", "tokens": ["Nach", "Rei\u00b7che\u00b7nau", "zur", "Kir\u00b7che", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Wo er gestorben und gelebt,", "tokens": ["Wo", "er", "ge\u00b7stor\u00b7ben", "und", "ge\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Kloster Einsiedeln sich erhebt;", "tokens": ["Das", "Klos\u00b7ter", "Ein\u00b7sie\u00b7deln", "sich", "er\u00b7hebt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PRF", "VVFIN", "$."], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "F\u00fcr fromme Pilger ein Wunderquelle,", "tokens": ["F\u00fcr", "from\u00b7me", "Pil\u00b7ger", "ein", "Wun\u00b7der\u00b7quel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Quillt dort in St. Meinrads Kapelle.", "tokens": ["Quillt", "dort", "in", "St.", "Mein\u00b7rads", "Ka\u00b7pel\u00b7le", "."], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NE", "NE", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}}}}