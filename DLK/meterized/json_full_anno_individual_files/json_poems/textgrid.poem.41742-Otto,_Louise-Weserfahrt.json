{"textgrid.poem.41742": {"metadata": {"author": {"name": "Otto, Louise", "birth": "N.A.", "death": "N.A."}, "title": "Weserfahrt", "genre": "verse", "period": "N.A.", "pub_year": 1857, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und m\u00f6gen sie dichten und singen", "tokens": ["Und", "m\u00f6\u00b7gen", "sie", "dich\u00b7ten", "und", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADJA", "KON", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Vom alten deutschen Rhein.", "tokens": ["Vom", "al\u00b7ten", "deut\u00b7schen", "Rhein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mein Lied soll der Weser erklingen,", "tokens": ["Mein", "Lied", "soll", "der", "We\u00b7ser", "er\u00b7klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Soll ihr gewidmet sein!", "tokens": ["Soll", "ihr", "ge\u00b7wid\u00b7met", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Werra und Fulda, die beiden,", "tokens": ["Die", "Wer\u00b7ra", "und", "Ful\u00b7da", ",", "die", "bei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "$,", "PRELS", "PIAT", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die haben's wohl erkannt,", "tokens": ["Die", "ha\u00b7ben's", "wohl", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die wollen zusammen durchgleiten,", "tokens": ["Die", "wol\u00b7len", "zu\u00b7sam\u00b7men", "durch\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Vereint das Vaterland.", "tokens": ["Ver\u00b7eint", "das", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die wollen treu halten zusammen", "tokens": ["Die", "wol\u00b7len", "treu", "hal\u00b7ten", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ADJD", "VVINF", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Weil beid aus Germanien stammen,", "tokens": ["Weil", "beid", "aus", "Ger\u00b7ma\u00b7ni\u00b7en", "stam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem alten Vaterland! \u2013", "tokens": ["Dem", "al\u00b7ten", "Va\u00b7ter\u00b7land", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Im Land, das die Weser durchwallet,", "tokens": ["Im", "Land", ",", "das", "die", "We\u00b7ser", "durch\u00b7wal\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Erklang einst Hermanns Wort,", "tokens": ["Er\u00b7klang", "einst", "Her\u00b7manns", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Dr\u00f6hnen der Schilde erschallet,", "tokens": ["Und", "Dr\u00f6h\u00b7nen", "der", "Schil\u00b7de", "er\u00b7schal\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Schlachtruf t\u00f6nt fort und fort.", "tokens": ["Schlach\u00b7truf", "t\u00f6nt", "fort", "und", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbwir wollen uns sch\u00fctzen und schirmen", "tokens": ["\u00bb", "wir", "wol\u00b7len", "uns", "sch\u00fct\u00b7zen", "und", "schir\u00b7men"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVINF", "KON", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Vor r\u00f6mischem Uebermut!", "tokens": ["Vor", "r\u00f6\u00b7mi\u00b7schem", "Ue\u00b7ber\u00b7mut", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wir wollen Aliso erst\u00fcrmen,", "tokens": ["Wir", "wol\u00b7len", "A\u00b7li\u00b7so", "er\u00b7st\u00fcr\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vernichten R\u00f6merbrut!", "tokens": ["Ver\u00b7nich\u00b7ten", "R\u00f6\u00b7mer\u00b7brut", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Hier halle den r\u00f6mischen Heeren", "tokens": ["Hier", "hal\u00b7le", "den", "r\u00f6\u00b7mi\u00b7schen", "Hee\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Ein trotzig deutsches: Halt!", "tokens": ["Ein", "trot\u00b7zig", "deut\u00b7sches", ":", "Halt", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "$.", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hier werden die V\u00f6lker sich wehren,", "tokens": ["Hier", "wer\u00b7den", "die", "V\u00f6l\u00b7ker", "sich", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Am Weserflu\u00df und -Wald.", "tokens": ["Am", "We\u00b7ser\u00b7flu\u00df", "und", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Hier werden sie k\u00e4mpfen und stehen", "tokens": ["Hier", "wer\u00b7den", "sie", "k\u00e4mp\u00b7fen", "und", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "KON", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "F\u00fcr ihr germanisch Recht,", "tokens": ["F\u00fcr", "ihr", "ger\u00b7ma\u00b7nisch", "Recht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und werden als Sieger sich sehen", "tokens": ["Und", "wer\u00b7den", "als", "Sie\u00b7ger", "sich", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "KOUS", "NN", "PRF", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Im heiligsten Gefecht!\u00ab \u2013", "tokens": ["Im", "hei\u00b7ligs\u00b7ten", "Ge\u00b7fecht", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+---+", "measure": "dactylic.init"}}, "stanza.8": {"line.1": {"text": "Cheruskas F\u00fcrst an der Spitze,", "tokens": ["Che\u00b7rus\u00b7kas", "F\u00fcrst", "an", "der", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "So ziehen sie in den Streit,", "tokens": ["So", "zie\u00b7hen", "sie", "in", "den", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Vernichten wie r\u00e4chende Blitze", "tokens": ["Ver\u00b7nich\u00b7ten", "wie", "r\u00e4\u00b7chen\u00b7de", "Blit\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Die r\u00f6mische Herrlichkeit.", "tokens": ["Die", "r\u00f6\u00b7mi\u00b7sche", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Die R\u00f6mer, die leicht \u00fcberschritten,", "tokens": ["Die", "R\u00f6\u00b7mer", ",", "die", "leicht", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Den breiten, stolzen Rhein,", "tokens": ["Den", "brei\u00b7ten", ",", "stol\u00b7zen", "Rhein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sind nicht an der Weser gelitten.", "tokens": ["Sind", "nicht", "an", "der", "We\u00b7ser", "ge\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Die Weser kann befrein. \u2013", "tokens": ["Die", "We\u00b7ser", "kann", "be\u00b7fr\u00b7ein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "So war es vor uralten Zeiten", "tokens": ["So", "war", "es", "vor", "ur\u00b7al\u00b7ten", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als solches hier geschah.", "tokens": ["Als", "sol\u00b7ches", "hier", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wieder gilt es zu streiten \u2013,", "tokens": ["Und", "wie\u00b7der", "gilt", "es", "zu", "strei\u00b7ten", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$(", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ist denn kein Hermann da?", "tokens": ["Ist", "denn", "kein", "Her\u00b7mann", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Kein Hermann und keine Germanen", "tokens": ["Kein", "Her\u00b7mann", "und", "kei\u00b7ne", "Ger\u00b7ma\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Zu Schutz und Trutz bewehrt,", "tokens": ["Zu", "Schutz", "und", "Trutz", "be\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die heilige Freiheit der Ahnen", "tokens": ["Die", "hei\u00b7li\u00b7ge", "Frei\u00b7heit", "der", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Zu wahren mit dem Schwert?", "tokens": ["Zu", "wah\u00b7ren", "mit", "dem", "Schwert", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Die Werra und Fulda, die beiden,", "tokens": ["Die", "Wer\u00b7ra", "und", "Ful\u00b7da", ",", "die", "bei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "$,", "PRELS", "PIAT", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die haben's wohl erkannt,", "tokens": ["Die", "ha\u00b7ben's", "wohl", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die wollen zusammen durchgleiten", "tokens": ["Die", "wol\u00b7len", "zu\u00b7sam\u00b7men", "durch\u00b7glei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ADV", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Vereint das Vaterland.", "tokens": ["Ver\u00b7eint", "das", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Die sind l\u00e4ngst zusammen gezogen", "tokens": ["Die", "sind", "l\u00e4ngst", "zu\u00b7sam\u00b7men", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Durch Deutschlands Au und Hain.", "tokens": ["Durch", "Deutschlands", "Au", "und", "Hain", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "KON", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Es fl\u00fcstern und murmeln die Wogen:", "tokens": ["Es", "fl\u00fcs\u00b7tern", "und", "mur\u00b7meln", "die", "Wo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u00bbdie Weser kann befrein!\u00ab", "tokens": ["\u00bb", "die", "We\u00b7ser", "kann", "be\u00b7fr\u00b7ein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Und die an den Ufern es h\u00f6ren,", "tokens": ["Und", "die", "an", "den", "U\u00b7fern", "es", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Vertrauen ihr sich an,", "tokens": ["Ver\u00b7trau\u00b7en", "ihr", "sich", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ziehen in traurigen Ch\u00f6ren", "tokens": ["Und", "zie\u00b7hen", "in", "trau\u00b7ri\u00b7gen", "Ch\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Zu ihren Schiffen heran.", "tokens": ["Zu", "ih\u00b7ren", "Schif\u00b7fen", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Und fliehen vom heimischen Lande,", "tokens": ["Und", "flie\u00b7hen", "vom", "hei\u00b7mi\u00b7schen", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Dem fremden sich zu weihn,", "tokens": ["Dem", "frem\u00b7den", "sich", "zu", "weihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und fl\u00fcstern zum Meer noch vom Strande:", "tokens": ["Und", "fl\u00fcs\u00b7tern", "zum", "Meer", "noch", "vom", "Stran\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u00bbdie Weser kann befrein!\u00ab", "tokens": ["\u00bb", "die", "We\u00b7ser", "kann", "be\u00b7fr\u00b7ein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Leb wohl o germanische Erde,", "tokens": ["Leb", "wohl", "o", "ger\u00b7ma\u00b7ni\u00b7sche", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "FM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Uns winkt Amerika \u2013 \u2013", "tokens": ["Uns", "winkt", "A\u00b7me\u00b7ri\u00b7ka", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "NE", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie rufen's mit Trauergeb\u00e4rde \u2013 \u2013", "tokens": ["Sie", "ru\u00b7fen's", "mit", "Trau\u00b7er\u00b7ge\u00b7b\u00e4r\u00b7de", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$(", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ist denn kein Hermann da?", "tokens": ["Ist", "denn", "kein", "Her\u00b7mann", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Kein Hermann und keine Germanen,", "tokens": ["Kein", "Her\u00b7mann", "und", "kei\u00b7ne", "Ger\u00b7ma\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Da\u00df Deutschland verzweifeln mu\u00df,", "tokens": ["Da\u00df", "Deutschland", "ver\u00b7zwei\u00b7feln", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verdienen die heiligen Ahnen", "tokens": ["Ver\u00b7die\u00b7nen", "die", "hei\u00b7li\u00b7gen", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Nur einen Abschiedsgru\u00df?", "tokens": ["Nur", "ei\u00b7nen", "Ab\u00b7schieds\u00b7gru\u00df", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Und was aus uralten Zeiten", "tokens": ["Und", "was", "aus", "ur\u00b7al\u00b7ten", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die Weser noch erz\u00e4hlt \u2013!", "tokens": ["Die", "We\u00b7ser", "noch", "er\u00b7z\u00e4hlt", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr sollt es so falsch nicht deuten,", "tokens": ["Ihr", "sollt", "es", "so", "falsch", "nicht", "deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADJD", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df Ihr Auswanderung w\u00e4hlt! \u2013", "tokens": ["Da\u00df", "Ihr", "Aus\u00b7wan\u00b7de\u00b7rung", "w\u00e4hlt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.19": {"line.1": {"text": "Die Werra und Fulda, die beiden", "tokens": ["Die", "Wer\u00b7ra", "und", "Ful\u00b7da", ",", "die", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "KON", "NE", "$,", "PRELS", "PIAT"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die haben's wohl erkannt,", "tokens": ["Die", "ha\u00b7ben's", "wohl", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die m\u00f6chten vereint durchgleiten", "tokens": ["Die", "m\u00f6ch\u00b7ten", "ver\u00b7eint", "durch\u00b7glei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "VVPP", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein einig Vaterland.", "tokens": ["Ein", "ei\u00b7nig", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Und m\u00f6gen sie dichten und singen", "tokens": ["Und", "m\u00f6\u00b7gen", "sie", "dich\u00b7ten", "und", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADJA", "KON", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Vom alten deutschen Rhein.", "tokens": ["Vom", "al\u00b7ten", "deut\u00b7schen", "Rhein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mein Lied soll der Weser erklingen,", "tokens": ["Mein", "Lied", "soll", "der", "We\u00b7ser", "er\u00b7klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Soll ihr gewidmet sein!", "tokens": ["Soll", "ihr", "ge\u00b7wid\u00b7met", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Die Werra und Fulda, die beiden,", "tokens": ["Die", "Wer\u00b7ra", "und", "Ful\u00b7da", ",", "die", "bei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "$,", "PRELS", "PIAT", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die haben's wohl erkannt,", "tokens": ["Die", "ha\u00b7ben's", "wohl", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die wollen zusammen durchgleiten,", "tokens": ["Die", "wol\u00b7len", "zu\u00b7sam\u00b7men", "durch\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Vereint das Vaterland.", "tokens": ["Ver\u00b7eint", "das", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Die wollen treu halten zusammen", "tokens": ["Die", "wol\u00b7len", "treu", "hal\u00b7ten", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ADJD", "VVINF", "VVINF"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Weil beid aus Germanien stammen,", "tokens": ["Weil", "beid", "aus", "Ger\u00b7ma\u00b7ni\u00b7en", "stam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem alten Vaterland! \u2013", "tokens": ["Dem", "al\u00b7ten", "Va\u00b7ter\u00b7land", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Im Land, das die Weser durchwallet,", "tokens": ["Im", "Land", ",", "das", "die", "We\u00b7ser", "durch\u00b7wal\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Erklang einst Hermanns Wort,", "tokens": ["Er\u00b7klang", "einst", "Her\u00b7manns", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Dr\u00f6hnen der Schilde erschallet,", "tokens": ["Und", "Dr\u00f6h\u00b7nen", "der", "Schil\u00b7de", "er\u00b7schal\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Schlachtruf t\u00f6nt fort und fort.", "tokens": ["Schlach\u00b7truf", "t\u00f6nt", "fort", "und", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "\u00bbwir wollen uns sch\u00fctzen und schirmen", "tokens": ["\u00bb", "wir", "wol\u00b7len", "uns", "sch\u00fct\u00b7zen", "und", "schir\u00b7men"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVINF", "KON", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Vor r\u00f6mischem Uebermut!", "tokens": ["Vor", "r\u00f6\u00b7mi\u00b7schem", "Ue\u00b7ber\u00b7mut", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wir wollen Aliso erst\u00fcrmen,", "tokens": ["Wir", "wol\u00b7len", "A\u00b7li\u00b7so", "er\u00b7st\u00fcr\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vernichten R\u00f6merbrut!", "tokens": ["Ver\u00b7nich\u00b7ten", "R\u00f6\u00b7mer\u00b7brut", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Hier halle den r\u00f6mischen Heeren", "tokens": ["Hier", "hal\u00b7le", "den", "r\u00f6\u00b7mi\u00b7schen", "Hee\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Ein trotzig deutsches: Halt!", "tokens": ["Ein", "trot\u00b7zig", "deut\u00b7sches", ":", "Halt", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "$.", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hier werden die V\u00f6lker sich wehren,", "tokens": ["Hier", "wer\u00b7den", "die", "V\u00f6l\u00b7ker", "sich", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Am Weserflu\u00df und -Wald.", "tokens": ["Am", "We\u00b7ser\u00b7flu\u00df", "und", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Hier werden sie k\u00e4mpfen und stehen", "tokens": ["Hier", "wer\u00b7den", "sie", "k\u00e4mp\u00b7fen", "und", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "KON", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "F\u00fcr ihr germanisch Recht,", "tokens": ["F\u00fcr", "ihr", "ger\u00b7ma\u00b7nisch", "Recht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und werden als Sieger sich sehen", "tokens": ["Und", "wer\u00b7den", "als", "Sie\u00b7ger", "sich", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "KOUS", "NN", "PRF", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Im heiligsten Gefecht!\u00ab \u2013", "tokens": ["Im", "hei\u00b7ligs\u00b7ten", "Ge\u00b7fecht", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+---+", "measure": "dactylic.init"}}, "stanza.27": {"line.1": {"text": "Cheruskas F\u00fcrst an der Spitze,", "tokens": ["Che\u00b7rus\u00b7kas", "F\u00fcrst", "an", "der", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "So ziehen sie in den Streit,", "tokens": ["So", "zie\u00b7hen", "sie", "in", "den", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Vernichten wie r\u00e4chende Blitze", "tokens": ["Ver\u00b7nich\u00b7ten", "wie", "r\u00e4\u00b7chen\u00b7de", "Blit\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Die r\u00f6mische Herrlichkeit.", "tokens": ["Die", "r\u00f6\u00b7mi\u00b7sche", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.28": {"line.1": {"text": "Die R\u00f6mer, die leicht \u00fcberschritten,", "tokens": ["Die", "R\u00f6\u00b7mer", ",", "die", "leicht", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Den breiten, stolzen Rhein,", "tokens": ["Den", "brei\u00b7ten", ",", "stol\u00b7zen", "Rhein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sind nicht an der Weser gelitten.", "tokens": ["Sind", "nicht", "an", "der", "We\u00b7ser", "ge\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Die Weser kann befrein. \u2013", "tokens": ["Die", "We\u00b7ser", "kann", "be\u00b7fr\u00b7ein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "So war es vor uralten Zeiten", "tokens": ["So", "war", "es", "vor", "ur\u00b7al\u00b7ten", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als solches hier geschah.", "tokens": ["Als", "sol\u00b7ches", "hier", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wieder gilt es zu streiten \u2013,", "tokens": ["Und", "wie\u00b7der", "gilt", "es", "zu", "strei\u00b7ten", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$(", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ist denn kein Hermann da?", "tokens": ["Ist", "denn", "kein", "Her\u00b7mann", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Kein Hermann und keine Germanen", "tokens": ["Kein", "Her\u00b7mann", "und", "kei\u00b7ne", "Ger\u00b7ma\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Zu Schutz und Trutz bewehrt,", "tokens": ["Zu", "Schutz", "und", "Trutz", "be\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die heilige Freiheit der Ahnen", "tokens": ["Die", "hei\u00b7li\u00b7ge", "Frei\u00b7heit", "der", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Zu wahren mit dem Schwert?", "tokens": ["Zu", "wah\u00b7ren", "mit", "dem", "Schwert", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Die Werra und Fulda, die beiden,", "tokens": ["Die", "Wer\u00b7ra", "und", "Ful\u00b7da", ",", "die", "bei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "$,", "PRELS", "PIAT", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die haben's wohl erkannt,", "tokens": ["Die", "ha\u00b7ben's", "wohl", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die wollen zusammen durchgleiten", "tokens": ["Die", "wol\u00b7len", "zu\u00b7sam\u00b7men", "durch\u00b7glei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ADV", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Vereint das Vaterland.", "tokens": ["Ver\u00b7eint", "das", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Die sind l\u00e4ngst zusammen gezogen", "tokens": ["Die", "sind", "l\u00e4ngst", "zu\u00b7sam\u00b7men", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Durch Deutschlands Au und Hain.", "tokens": ["Durch", "Deutschlands", "Au", "und", "Hain", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "KON", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Es fl\u00fcstern und murmeln die Wogen:", "tokens": ["Es", "fl\u00fcs\u00b7tern", "und", "mur\u00b7meln", "die", "Wo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u00bbdie Weser kann befrein!\u00ab", "tokens": ["\u00bb", "die", "We\u00b7ser", "kann", "be\u00b7fr\u00b7ein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Und die an den Ufern es h\u00f6ren,", "tokens": ["Und", "die", "an", "den", "U\u00b7fern", "es", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Vertrauen ihr sich an,", "tokens": ["Ver\u00b7trau\u00b7en", "ihr", "sich", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ziehen in traurigen Ch\u00f6ren", "tokens": ["Und", "zie\u00b7hen", "in", "trau\u00b7ri\u00b7gen", "Ch\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Zu ihren Schiffen heran.", "tokens": ["Zu", "ih\u00b7ren", "Schif\u00b7fen", "he\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.34": {"line.1": {"text": "Und fliehen vom heimischen Lande,", "tokens": ["Und", "flie\u00b7hen", "vom", "hei\u00b7mi\u00b7schen", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Dem fremden sich zu weihn,", "tokens": ["Dem", "frem\u00b7den", "sich", "zu", "weihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und fl\u00fcstern zum Meer noch vom Strande:", "tokens": ["Und", "fl\u00fcs\u00b7tern", "zum", "Meer", "noch", "vom", "Stran\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u00bbdie Weser kann befrein!\u00ab", "tokens": ["\u00bb", "die", "We\u00b7ser", "kann", "be\u00b7fr\u00b7ein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Leb wohl o germanische Erde,", "tokens": ["Leb", "wohl", "o", "ger\u00b7ma\u00b7ni\u00b7sche", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "FM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Uns winkt Amerika \u2013 \u2013", "tokens": ["Uns", "winkt", "A\u00b7me\u00b7ri\u00b7ka", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "NE", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie rufen's mit Trauergeb\u00e4rde \u2013 \u2013", "tokens": ["Sie", "ru\u00b7fen's", "mit", "Trau\u00b7er\u00b7ge\u00b7b\u00e4r\u00b7de", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$(", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ist denn kein Hermann da?", "tokens": ["Ist", "denn", "kein", "Her\u00b7mann", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Kein Hermann und keine Germanen,", "tokens": ["Kein", "Her\u00b7mann", "und", "kei\u00b7ne", "Ger\u00b7ma\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Da\u00df Deutschland verzweifeln mu\u00df,", "tokens": ["Da\u00df", "Deutschland", "ver\u00b7zwei\u00b7feln", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verdienen die heiligen Ahnen", "tokens": ["Ver\u00b7die\u00b7nen", "die", "hei\u00b7li\u00b7gen", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Nur einen Abschiedsgru\u00df?", "tokens": ["Nur", "ei\u00b7nen", "Ab\u00b7schieds\u00b7gru\u00df", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Und was aus uralten Zeiten", "tokens": ["Und", "was", "aus", "ur\u00b7al\u00b7ten", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die Weser noch erz\u00e4hlt \u2013!", "tokens": ["Die", "We\u00b7ser", "noch", "er\u00b7z\u00e4hlt", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr sollt es so falsch nicht deuten,", "tokens": ["Ihr", "sollt", "es", "so", "falsch", "nicht", "deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADJD", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df Ihr Auswanderung w\u00e4hlt! \u2013", "tokens": ["Da\u00df", "Ihr", "Aus\u00b7wan\u00b7de\u00b7rung", "w\u00e4hlt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.38": {"line.1": {"text": "Die Werra und Fulda, die beiden", "tokens": ["Die", "Wer\u00b7ra", "und", "Ful\u00b7da", ",", "die", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "KON", "NE", "$,", "PRELS", "PIAT"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die haben's wohl erkannt,", "tokens": ["Die", "ha\u00b7ben's", "wohl", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die m\u00f6chten vereint durchgleiten", "tokens": ["Die", "m\u00f6ch\u00b7ten", "ver\u00b7eint", "durch\u00b7glei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "VVPP", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein einig Vaterland.", "tokens": ["Ein", "ei\u00b7nig", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}