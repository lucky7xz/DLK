{"textgrid.poem.57945": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "D\u00f6hrener Klage", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als wir man noch D\u00f6rfler waren,", "tokens": ["Als", "wir", "man", "noch", "D\u00f6rf\u00b7ler", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War es bis halb zw\u00f6lfe hell,", "tokens": ["War", "es", "bis", "halb", "zw\u00f6l\u00b7fe", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJD", "CARD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jetzo find't man schon um zehne", "tokens": ["Jet\u00b7zo", "find't", "man", "schon", "um", "zeh\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht mehr richtig von der Stell'.", "tokens": ["Nicht", "mehr", "rich\u00b7tig", "von", "der", "Stell'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Scheint kein Mond, dann ist es dunkel,", "tokens": ["Scheint", "kein", "Mond", ",", "dann", "ist", "es", "dun\u00b7kel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jeder geht mit der Latern',", "tokens": ["Je\u00b7der", "geht", "mit", "der", "La\u00b7tern'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist denn das der Gro\u00dfstadtsfortschritt,", "tokens": ["Ist", "denn", "das", "der", "Gro\u00df\u00b7stadts\u00b7fort\u00b7schritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ART", "NN", "$,"], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Ihr verehrten Rathausherr'n?", "tokens": ["Ihr", "ver\u00b7ehr\u00b7ten", "Rat\u00b7haus\u00b7herr'n", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "In Hannover brennt bis dreie", "tokens": ["In", "Han\u00b7no\u00b7ver", "brennt", "bis", "drei\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "APPR", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und noch l\u00e4nger hell das Licht,", "tokens": ["Und", "noch", "l\u00e4n\u00b7ger", "hell", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ADJD", "ART", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Damit jeder noch 'ne Kneipe", "tokens": ["Da\u00b7mit", "je\u00b7der", "noch", "'ne", "Knei\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PIS", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Finden kann. Wir k\u00f6nn'n das nicht.", "tokens": ["Fin\u00b7den", "kann", ".", "Wir", "k\u00f6nn'n", "das", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$.", "PPER", "VMFIN", "PDS", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "F\u00fcr die Damen des Asphaltes", "tokens": ["F\u00fcr", "die", "Da\u00b7men", "des", "As\u00b7phal\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spart man nicht das teure Gas,", "tokens": ["Spart", "man", "nicht", "das", "teu\u00b7re", "Gas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch dem tugendhaften Vorort", "tokens": ["Doch", "dem", "tu\u00b7gend\u00b7haf\u00b7ten", "Vor\u00b7ort"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Knapst man's ab. Wie find'n wir das?", "tokens": ["Knapst", "man's", "ab", ".", "Wie", "fin\u00b7d'n", "wir", "das", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$.", "PWAV", "VVFIN", "PPER", "PDS", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.5": {"line.1": {"text": "Dumpfes Murren herrscht im Vorort,", "tokens": ["Dum\u00b7pfes", "Mur\u00b7ren", "herrscht", "im", "Vor\u00b7ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil man es nicht recht begreift;", "tokens": ["Weil", "man", "es", "nicht", "recht", "be\u00b7greift", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist man denn nun eingemeindet,", "tokens": ["Ist", "man", "denn", "nun", "ein\u00b7ge\u00b7mein\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder ist man eingeseift?", "tokens": ["O\u00b7der", "ist", "man", "ein\u00b7ge\u00b7seift", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Als wir man noch D\u00f6rfler waren,", "tokens": ["Als", "wir", "man", "noch", "D\u00f6rf\u00b7ler", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War es bis halb zw\u00f6lfe hell,", "tokens": ["War", "es", "bis", "halb", "zw\u00f6l\u00b7fe", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJD", "CARD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jetzo find't man schon um zehne", "tokens": ["Jet\u00b7zo", "find't", "man", "schon", "um", "zeh\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "APPR", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht mehr richtig von der Stell'.", "tokens": ["Nicht", "mehr", "rich\u00b7tig", "von", "der", "Stell'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Scheint kein Mond, dann ist es dunkel,", "tokens": ["Scheint", "kein", "Mond", ",", "dann", "ist", "es", "dun\u00b7kel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jeder geht mit der Latern',", "tokens": ["Je\u00b7der", "geht", "mit", "der", "La\u00b7tern'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist denn das der Gro\u00dfstadtsfortschritt,", "tokens": ["Ist", "denn", "das", "der", "Gro\u00df\u00b7stadts\u00b7fort\u00b7schritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ART", "NN", "$,"], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Ihr verehrten Rathausherr'n?", "tokens": ["Ihr", "ver\u00b7ehr\u00b7ten", "Rat\u00b7haus\u00b7herr'n", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "In Hannover brennt bis dreie", "tokens": ["In", "Han\u00b7no\u00b7ver", "brennt", "bis", "drei\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "APPR", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und noch l\u00e4nger hell das Licht,", "tokens": ["Und", "noch", "l\u00e4n\u00b7ger", "hell", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ADJD", "ART", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Damit jeder noch 'ne Kneipe", "tokens": ["Da\u00b7mit", "je\u00b7der", "noch", "'ne", "Knei\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PIS", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Finden kann. Wir k\u00f6nn'n das nicht.", "tokens": ["Fin\u00b7den", "kann", ".", "Wir", "k\u00f6nn'n", "das", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$.", "PPER", "VMFIN", "PDS", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "F\u00fcr die Damen des Asphaltes", "tokens": ["F\u00fcr", "die", "Da\u00b7men", "des", "As\u00b7phal\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spart man nicht das teure Gas,", "tokens": ["Spart", "man", "nicht", "das", "teu\u00b7re", "Gas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch dem tugendhaften Vorort", "tokens": ["Doch", "dem", "tu\u00b7gend\u00b7haf\u00b7ten", "Vor\u00b7ort"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Knapst man's ab. Wie find'n wir das?", "tokens": ["Knapst", "man's", "ab", ".", "Wie", "fin\u00b7d'n", "wir", "das", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$.", "PWAV", "VVFIN", "PPER", "PDS", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.10": {"line.1": {"text": "Dumpfes Murren herrscht im Vorort,", "tokens": ["Dum\u00b7pfes", "Mur\u00b7ren", "herrscht", "im", "Vor\u00b7ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil man es nicht recht begreift;", "tokens": ["Weil", "man", "es", "nicht", "recht", "be\u00b7greift", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist man denn nun eingemeindet,", "tokens": ["Ist", "man", "denn", "nun", "ein\u00b7ge\u00b7mein\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder ist man eingeseift?", "tokens": ["O\u00b7der", "ist", "man", "ein\u00b7ge\u00b7seift", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}