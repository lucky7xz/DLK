{"textgrid.poem.38728": {"metadata": {"author": {"name": "Tieck, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es kam an einem Pilgerstab", "genre": "verse", "period": "N.A.", "pub_year": 1813, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es kam an einem Pilgerstab", "tokens": ["Es", "kam", "an", "ei\u00b7nem", "Pil\u00b7ger\u00b7stab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl \u00fcber's graue Meer", "tokens": ["Wohl", "\u00fc\u00b7ber's", "grau\u00b7e", "Meer"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Wandersmann in's Thal hinab,", "tokens": ["Ein", "Wan\u00b7ders\u00b7mann", "in's", "Thal", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von fremden Landen her.", "tokens": ["Von", "frem\u00b7den", "Lan\u00b7den", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Erbarmt euch meiner, rief er aus,", "tokens": ["Er\u00b7barmt", "euch", "mei\u00b7ner", ",", "rief", "er", "aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von fernem Land ich kam,", "tokens": ["Von", "fer\u00b7nem", "Land", "ich", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verloren hab' ich Gut und Haus,", "tokens": ["Ver\u00b7lo\u00b7ren", "hab'", "ich", "Gut", "und", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Anthonio ist mein Nahm'.", "tokens": ["An\u00b7tho\u00b7nio", "ist", "mein", "Nahm'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die Eltern starben mir schon lang',", "tokens": ["Die", "El\u00b7tern", "star\u00b7ben", "mir", "schon", "lang'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich war noch schwach und klein,", "tokens": ["Ich", "war", "noch", "schwach", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "War ohne Gut, war ohne Rang,", "tokens": ["War", "oh\u00b7ne", "Gut", ",", "war", "oh\u00b7ne", "Rang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "$,", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Niemand dachte mein.", "tokens": ["Und", "Nie\u00b7mand", "dach\u00b7te", "mein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da nahm ich diesen Wanderstab", "tokens": ["Da", "nahm", "ich", "die\u00b7sen", "Wan\u00b7der\u00b7stab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und trat die Reise an,", "tokens": ["Und", "trat", "die", "Rei\u00b7se", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Stieg hier in's frische Thal hinab,", "tokens": ["Stieg", "hier", "in's", "fri\u00b7sche", "Thal", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fleh' euer Mitleid an. \u2013", "tokens": ["Fleh'", "eu\u00b7er", "Mit\u00b7leid", "an", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Da ging er wohl von Th\u00fcr zu Th\u00fcr,", "tokens": ["Da", "ging", "er", "wohl", "von", "Th\u00fcr", "zu", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ging hier und wieder dort,", "tokens": ["Ging", "hier", "und", "wie\u00b7der", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ward abgewiesen dort und hier,", "tokens": ["Ward", "ab\u00b7ge\u00b7wie\u00b7sen", "dort", "und", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schlich sich weinend fort.", "tokens": ["Und", "schlich", "sich", "wei\u00b7nend", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbwas suchst du in der Fremde Gl\u00fcck?", "tokens": ["\u00bb", "was", "suchst", "du", "in", "der", "Frem\u00b7de", "Gl\u00fcck", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sind dir nicht verwandt!", "tokens": ["Wir", "sind", "dir", "nicht", "ver\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Geh, wo du herk\u00f6mmst, nur zur\u00fcck,", "tokens": ["Geh", ",", "wo", "du", "her\u00b7k\u00f6mmst", ",", "nur", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bist nicht aus unserm Land. \u2013", "tokens": ["Bist", "nicht", "aus", "un\u00b7serm", "Land", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Genug der Freunde leiden Noth,", "tokens": ["Ge\u00b7nug", "der", "Freun\u00b7de", "lei\u00b7den", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Landsmann sucht hier Trost,", "tokens": ["Der", "Lands\u00b7mann", "sucht", "hier", "Trost", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr sie nur w\u00e4chst hier Frucht und Brodt,", "tokens": ["F\u00fcr", "sie", "nur", "w\u00e4chst", "hier", "Frucht", "und", "Brodt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr sie der s\u00fc\u00dfe Most.\u00ab \u2013", "tokens": ["F\u00fcr", "sie", "der", "s\u00fc\u00b7\u00dfe", "Most", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Still und besch\u00e4mt mit Ach und O!", "tokens": ["Still", "und", "be\u00b7sch\u00e4mt", "mit", "Ach", "und", "O", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "NN", "KON", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Schlich er die Stra\u00dfe hin,", "tokens": ["Schlich", "er", "die", "Stra\u00b7\u00dfe", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da ruft es sanft: Anthonio!", "tokens": ["Da", "ruft", "es", "sanft", ":", "An\u00b7tho\u00b7nio", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein M\u00e4dchen winkt ihn hin.", "tokens": ["Ein", "M\u00e4d\u00b7chen", "winkt", "ihn", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "O nimm von meiner Armuth an,", "tokens": ["O", "nimm", "von", "mei\u00b7ner", "Ar\u00b7muth", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spricht sie mit frommen Sinn,", "tokens": ["Spricht", "sie", "mit", "from\u00b7men", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich gebe was ich geben kann,", "tokens": ["Ich", "ge\u00b7be", "was", "ich", "ge\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nimm alles, alles hin.", "tokens": ["Nimm", "al\u00b7les", ",", "al\u00b7les", "hin", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PIS", "$,", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Lucindens blaues Auge weint,", "tokens": ["Lu\u00b7cin\u00b7dens", "blau\u00b7es", "Au\u00b7ge", "weint", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er dankt mit hei\u00dfem Ku\u00df,", "tokens": ["Er", "dankt", "mit", "hei\u00b7\u00dfem", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und sieh! die Liebenden vereint", "tokens": ["Und", "sieh", "!", "die", "Lie\u00b7ben\u00b7den", "ver\u00b7eint"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein rascher Thr\u00e4nengu\u00df.", "tokens": ["Ein", "ra\u00b7scher", "Thr\u00e4\u00b7nen\u00b7gu\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Ach nein, du bist mir nicht verwandt,", "tokens": ["Ach", "nein", ",", "du", "bist", "mir", "nicht", "ver\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$,", "PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dennoch erbarm ich mich,", "tokens": ["Den\u00b7noch", "er\u00b7barm", "ich", "mich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und bist du gleich aus fremden Land',", "tokens": ["Und", "bist", "du", "gleich", "aus", "frem\u00b7den", "Land'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So lieb ich dennoch dich.", "tokens": ["So", "lieb", "ich", "den\u00b7noch", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Die Liebe kennt nicht Vaterland,", "tokens": ["Die", "Lie\u00b7be", "kennt", "nicht", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie macht uns alle gleich.", "tokens": ["Sie", "macht", "uns", "al\u00b7le", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein jedes Herz ist ihr verwandt,", "tokens": ["Ein", "je\u00b7des", "Herz", "ist", "ihr", "ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie macht den Bettler reich!", "tokens": ["Sie", "macht", "den", "Bett\u00b7ler", "reich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Es kam an einem Pilgerstab", "tokens": ["Es", "kam", "an", "ei\u00b7nem", "Pil\u00b7ger\u00b7stab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl \u00fcber's graue Meer", "tokens": ["Wohl", "\u00fc\u00b7ber's", "grau\u00b7e", "Meer"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Wandersmann in's Thal hinab,", "tokens": ["Ein", "Wan\u00b7ders\u00b7mann", "in's", "Thal", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von fremden Landen her.", "tokens": ["Von", "frem\u00b7den", "Lan\u00b7den", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Erbarmt euch meiner, rief er aus,", "tokens": ["Er\u00b7barmt", "euch", "mei\u00b7ner", ",", "rief", "er", "aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von fernem Land ich kam,", "tokens": ["Von", "fer\u00b7nem", "Land", "ich", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verloren hab' ich Gut und Haus,", "tokens": ["Ver\u00b7lo\u00b7ren", "hab'", "ich", "Gut", "und", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Anthonio ist mein Nahm'.", "tokens": ["An\u00b7tho\u00b7nio", "ist", "mein", "Nahm'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Die Eltern starben mir schon lang',", "tokens": ["Die", "El\u00b7tern", "star\u00b7ben", "mir", "schon", "lang'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich war noch schwach und klein,", "tokens": ["Ich", "war", "noch", "schwach", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "War ohne Gut, war ohne Rang,", "tokens": ["War", "oh\u00b7ne", "Gut", ",", "war", "oh\u00b7ne", "Rang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "$,", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Niemand dachte mein.", "tokens": ["Und", "Nie\u00b7mand", "dach\u00b7te", "mein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Da nahm ich diesen Wanderstab", "tokens": ["Da", "nahm", "ich", "die\u00b7sen", "Wan\u00b7der\u00b7stab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und trat die Reise an,", "tokens": ["Und", "trat", "die", "Rei\u00b7se", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Stieg hier in's frische Thal hinab,", "tokens": ["Stieg", "hier", "in's", "fri\u00b7sche", "Thal", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fleh' euer Mitleid an. \u2013", "tokens": ["Fleh'", "eu\u00b7er", "Mit\u00b7leid", "an", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Da ging er wohl von Th\u00fcr zu Th\u00fcr,", "tokens": ["Da", "ging", "er", "wohl", "von", "Th\u00fcr", "zu", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ging hier und wieder dort,", "tokens": ["Ging", "hier", "und", "wie\u00b7der", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ward abgewiesen dort und hier,", "tokens": ["Ward", "ab\u00b7ge\u00b7wie\u00b7sen", "dort", "und", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schlich sich weinend fort.", "tokens": ["Und", "schlich", "sich", "wei\u00b7nend", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "\u00bbwas suchst du in der Fremde Gl\u00fcck?", "tokens": ["\u00bb", "was", "suchst", "du", "in", "der", "Frem\u00b7de", "Gl\u00fcck", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sind dir nicht verwandt!", "tokens": ["Wir", "sind", "dir", "nicht", "ver\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Geh, wo du herk\u00f6mmst, nur zur\u00fcck,", "tokens": ["Geh", ",", "wo", "du", "her\u00b7k\u00f6mmst", ",", "nur", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bist nicht aus unserm Land. \u2013", "tokens": ["Bist", "nicht", "aus", "un\u00b7serm", "Land", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Genug der Freunde leiden Noth,", "tokens": ["Ge\u00b7nug", "der", "Freun\u00b7de", "lei\u00b7den", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Landsmann sucht hier Trost,", "tokens": ["Der", "Lands\u00b7mann", "sucht", "hier", "Trost", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr sie nur w\u00e4chst hier Frucht und Brodt,", "tokens": ["F\u00fcr", "sie", "nur", "w\u00e4chst", "hier", "Frucht", "und", "Brodt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr sie der s\u00fc\u00dfe Most.\u00ab \u2013", "tokens": ["F\u00fcr", "sie", "der", "s\u00fc\u00b7\u00dfe", "Most", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Still und besch\u00e4mt mit Ach und O!", "tokens": ["Still", "und", "be\u00b7sch\u00e4mt", "mit", "Ach", "und", "O", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "NN", "KON", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Schlich er die Stra\u00dfe hin,", "tokens": ["Schlich", "er", "die", "Stra\u00b7\u00dfe", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da ruft es sanft: Anthonio!", "tokens": ["Da", "ruft", "es", "sanft", ":", "An\u00b7tho\u00b7nio", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein M\u00e4dchen winkt ihn hin.", "tokens": ["Ein", "M\u00e4d\u00b7chen", "winkt", "ihn", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "O nimm von meiner Armuth an,", "tokens": ["O", "nimm", "von", "mei\u00b7ner", "Ar\u00b7muth", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spricht sie mit frommen Sinn,", "tokens": ["Spricht", "sie", "mit", "from\u00b7men", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich gebe was ich geben kann,", "tokens": ["Ich", "ge\u00b7be", "was", "ich", "ge\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nimm alles, alles hin.", "tokens": ["Nimm", "al\u00b7les", ",", "al\u00b7les", "hin", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PIS", "$,", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Lucindens blaues Auge weint,", "tokens": ["Lu\u00b7cin\u00b7dens", "blau\u00b7es", "Au\u00b7ge", "weint", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er dankt mit hei\u00dfem Ku\u00df,", "tokens": ["Er", "dankt", "mit", "hei\u00b7\u00dfem", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und sieh! die Liebenden vereint", "tokens": ["Und", "sieh", "!", "die", "Lie\u00b7ben\u00b7den", "ver\u00b7eint"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein rascher Thr\u00e4nengu\u00df.", "tokens": ["Ein", "ra\u00b7scher", "Thr\u00e4\u00b7nen\u00b7gu\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Ach nein, du bist mir nicht verwandt,", "tokens": ["Ach", "nein", ",", "du", "bist", "mir", "nicht", "ver\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$,", "PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dennoch erbarm ich mich,", "tokens": ["Den\u00b7noch", "er\u00b7barm", "ich", "mich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und bist du gleich aus fremden Land',", "tokens": ["Und", "bist", "du", "gleich", "aus", "frem\u00b7den", "Land'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So lieb ich dennoch dich.", "tokens": ["So", "lieb", "ich", "den\u00b7noch", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Die Liebe kennt nicht Vaterland,", "tokens": ["Die", "Lie\u00b7be", "kennt", "nicht", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie macht uns alle gleich.", "tokens": ["Sie", "macht", "uns", "al\u00b7le", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein jedes Herz ist ihr verwandt,", "tokens": ["Ein", "je\u00b7des", "Herz", "ist", "ihr", "ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie macht den Bettler reich!", "tokens": ["Sie", "macht", "den", "Bett\u00b7ler", "reich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}