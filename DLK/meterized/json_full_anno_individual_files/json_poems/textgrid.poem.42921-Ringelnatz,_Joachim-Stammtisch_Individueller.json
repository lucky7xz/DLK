{"textgrid.poem.42921": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Stammtisch Individueller", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir sitzen gediegen und ausgew\u00e4hlt", "tokens": ["Wir", "sit\u00b7zen", "ge\u00b7die\u00b7gen", "und", "aus\u00b7ge\u00b7w\u00e4hlt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVPP", "KON", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Beisammen und spielen gem\u00fctlich.", "tokens": ["Bei\u00b7sam\u00b7men", "und", "spie\u00b7len", "ge\u00b7m\u00fct\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wenn einer ernst, lustig, vom Norden erz\u00e4hlt,", "tokens": ["Wenn", "ei\u00b7ner", "ernst", ",", "lus\u00b7tig", ",", "vom", "Nor\u00b7den", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "$,", "ADJD", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-++--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Lacht jeder etwas. Und denkt s\u00fcdlich.", "tokens": ["Lacht", "je\u00b7der", "et\u00b7was", ".", "Und", "denkt", "s\u00fcd\u00b7lich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "PIS", "$.", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Zwei Kellner trotteln durch das Wirtshaus.", "tokens": ["Zwei", "Kell\u00b7ner", "trot\u00b7teln", "durch", "das", "Wirts\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zwischen ihnen steht ein Spiegel.", "tokens": ["Zwi\u00b7schen", "ih\u00b7nen", "steht", "ein", "Spie\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie popeln beide auf Teufelkommraus,", "tokens": ["Sie", "po\u00b7peln", "bei\u00b7de", "auf", "Teu\u00b7fel\u00b7komm\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein \u2013 scheinbar zwei \u2013 Schweinigel.", "tokens": ["Ein", "\u2013", "schein\u00b7bar", "zwei", "\u2013", "Schwei\u00b7ni\u00b7gel", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "$(", "ADJD", "CARD", "$(", "NN", "$."], "meter": "+--+-++", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "Was wissen die von Br\u00fccken, die", "tokens": ["Was", "wis\u00b7sen", "die", "von", "Br\u00fc\u00b7cken", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "ART", "APPR", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich selbst f\u00fcr Inseln halten?", "tokens": ["Sich", "selbst", "f\u00fcr", "In\u00b7seln", "hal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und welche Inseln meinen, sie", "tokens": ["Und", "wel\u00b7che", "In\u00b7seln", "mei\u00b7nen", ",", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWAT", "NN", "VVFIN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "K\u00f6nnten sich selbst verwalten?", "tokens": ["K\u00f6nn\u00b7ten", "sich", "selbst", "ver\u00b7wal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.4": {"line.1": {"text": "Wir wandern alle mit der Zeit", "tokens": ["Wir", "wan\u00b7dern", "al\u00b7le", "mit", "der", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dem spitzen Ende der T\u00fcte.", "tokens": ["Nach", "dem", "spit\u00b7zen", "En\u00b7de", "der", "T\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "H\u00f6flichkeit und Liebensw\u00fcrdigkeit", "tokens": ["H\u00f6f\u00b7lich\u00b7keit", "und", "Lie\u00b7bens\u00b7w\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sind noch l\u00e4ngst keine G\u00fcte.", "tokens": ["Sind", "noch", "l\u00e4ngst", "kei\u00b7ne", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wir sitzen gediegen und ausgew\u00e4hlt", "tokens": ["Wir", "sit\u00b7zen", "ge\u00b7die\u00b7gen", "und", "aus\u00b7ge\u00b7w\u00e4hlt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVPP", "KON", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Beisammen und spielen gem\u00fctlich.", "tokens": ["Bei\u00b7sam\u00b7men", "und", "spie\u00b7len", "ge\u00b7m\u00fct\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wenn einer ernst, lustig, vom Norden erz\u00e4hlt,", "tokens": ["Wenn", "ei\u00b7ner", "ernst", ",", "lus\u00b7tig", ",", "vom", "Nor\u00b7den", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "$,", "ADJD", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-++--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Lacht jeder etwas. Und denkt s\u00fcdlich.", "tokens": ["Lacht", "je\u00b7der", "et\u00b7was", ".", "Und", "denkt", "s\u00fcd\u00b7lich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "PIS", "$.", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Zwei Kellner trotteln durch das Wirtshaus.", "tokens": ["Zwei", "Kell\u00b7ner", "trot\u00b7teln", "durch", "das", "Wirts\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zwischen ihnen steht ein Spiegel.", "tokens": ["Zwi\u00b7schen", "ih\u00b7nen", "steht", "ein", "Spie\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie popeln beide auf Teufelkommraus,", "tokens": ["Sie", "po\u00b7peln", "bei\u00b7de", "auf", "Teu\u00b7fel\u00b7komm\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein \u2013 scheinbar zwei \u2013 Schweinigel.", "tokens": ["Ein", "\u2013", "schein\u00b7bar", "zwei", "\u2013", "Schwei\u00b7ni\u00b7gel", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "$(", "ADJD", "CARD", "$(", "NN", "$."], "meter": "+--+-++", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Was wissen die von Br\u00fccken, die", "tokens": ["Was", "wis\u00b7sen", "die", "von", "Br\u00fc\u00b7cken", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "ART", "APPR", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich selbst f\u00fcr Inseln halten?", "tokens": ["Sich", "selbst", "f\u00fcr", "In\u00b7seln", "hal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und welche Inseln meinen, sie", "tokens": ["Und", "wel\u00b7che", "In\u00b7seln", "mei\u00b7nen", ",", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWAT", "NN", "VVFIN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "K\u00f6nnten sich selbst verwalten?", "tokens": ["K\u00f6nn\u00b7ten", "sich", "selbst", "ver\u00b7wal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "Wir wandern alle mit der Zeit", "tokens": ["Wir", "wan\u00b7dern", "al\u00b7le", "mit", "der", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dem spitzen Ende der T\u00fcte.", "tokens": ["Nach", "dem", "spit\u00b7zen", "En\u00b7de", "der", "T\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "H\u00f6flichkeit und Liebensw\u00fcrdigkeit", "tokens": ["H\u00f6f\u00b7lich\u00b7keit", "und", "Lie\u00b7bens\u00b7w\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sind noch l\u00e4ngst keine G\u00fcte.", "tokens": ["Sind", "noch", "l\u00e4ngst", "kei\u00b7ne", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}