{"textgrid.poem.53285": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "[dv, Gott, bist ausser aller Zeit]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dv, Gott, bist ausser aller Zeit", "tokens": ["Dv", ",", "Gott", ",", "bist", "aus\u00b7ser", "al\u00b7ler", "Zeit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Ewigkeit zu Ewigkeit.", "tokens": ["Von", "E\u00b7wig\u00b7keit", "zu", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eh als die Welt gestanden,", "tokens": ["Eh", "als", "die", "Welt", "ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Warst du schon, was du jetzund bist,", "tokens": ["Warst", "du", "schon", ",", "was", "du", "je\u00b7tzund", "bist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "PWS", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd wirst, wenn alles nichts mehr ist,", "tokens": ["Vnd", "wirst", ",", "wenn", "al\u00b7les", "nichts", "mehr", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "KOUS", "PIS", "PIS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch immer seyn vorhanden.", "tokens": ["Noch", "im\u00b7mer", "seyn", "vor\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Hergegen, ach! wir Menschen sind", "tokens": ["Her\u00b7ge\u00b7gen", ",", "ach", "!", "wir", "Men\u00b7schen", "sind"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ITJ", "$.", "PPER", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verg\u00e4nglich, fl\u00fcchtig, Rauch vnd Wind!", "tokens": ["Ver\u00b7g\u00e4ng\u00b7lich", ",", "fl\u00fcch\u00b7tig", ",", "Rauch", "vnd", "Wind", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auff dein Wort sind wir kommen,", "tokens": ["Auff", "dein", "Wort", "sind", "wir", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Bekucken kaum den ErdenKrey\u00df,", "tokens": ["Be\u00b7ku\u00b7cken", "kaum", "den", "Er\u00b7den", "Krey\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd werden stracks, auff dein Gehei\u00df,", "tokens": ["Vnd", "wer\u00b7den", "stracks", ",", "auff", "dein", "Ge\u00b7hei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch wieder weggenommen.", "tokens": ["Auch", "wie\u00b7der", "weg\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wir fahren hin gleich wie ein Traum,", "tokens": ["Wir", "fah\u00b7ren", "hin", "gleich", "wie", "ein", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vergehn wie Schatten und wie Schaum,", "tokens": ["Ver\u00b7gehn", "wie", "Schat\u00b7ten", "und", "wie", "Schaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NN", "KON", "PWAV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind eine Wasser-Blase:", "tokens": ["Sind", "ei\u00b7ne", "Was\u00b7ser\u00b7Bla\u00b7se", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Zeit Gewalt eilt mit vns fort,", "tokens": ["Der", "Zeit", "Ge\u00b7walt", "eilt", "mit", "vns", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie mit den Wolcken sonst der Nort,", "tokens": ["Wie", "mit", "den", "Wol\u00b7cken", "sonst", "der", "Nort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Herbst-Lufft mit dem Grase.", "tokens": ["Die", "Herbs\u00b7tLufft", "mit", "dem", "Gra\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da dieser auch vnd der vieleicht", "tokens": ["Da", "die\u00b7ser", "auch", "vnd", "der", "vie\u00b7leicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "ADV", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein guttes Antheil Jahr erreicht,", "tokens": ["Ein", "gut\u00b7tes", "An\u00b7theil", "Jahr", "er\u00b7reicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was wird es gro\u00df verfangen", "tokens": ["Was", "wird", "es", "gro\u00df", "ver\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bey dir, dem nichts sich gleichen mag", "tokens": ["Bey", "dir", ",", "dem", "nichts", "sich", "glei\u00b7chen", "mag"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "PRELS", "PIS", "PRF", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd tausent Jahre sind ein Tag,", "tokens": ["Vnd", "tau\u00b7sent", "Jah\u00b7re", "sind", "ein", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der gestern ist vergangen?", "tokens": ["Der", "ge\u00b7stern", "ist", "ver\u00b7gan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "Wie kurtz die\u00df Leben wehren kan,", "tokens": ["Wie", "kurtz", "die\u00df", "Le\u00b7ben", "weh\u00b7ren", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PDS", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ist es dennoch vmb vnd an", "tokens": ["So", "ist", "es", "den\u00b7noch", "vmb", "vnd", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur Arbeit, Angst und Leiden:", "tokens": ["Nur", "Ar\u00b7beit", ",", "Angst", "und", "Lei\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Angst ist, was vns zur Welt gebiert,", "tokens": ["Angst", "ist", ",", "was", "vns", "zur", "Welt", "ge\u00b7biert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PWS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Angst, was vns leitet, tr\u00e4gt vnd f\u00fchrt,", "tokens": ["Angst", ",", "was", "vns", "lei\u00b7tet", ",", "tr\u00e4gt", "vnd", "f\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Angst, was vns heisset scheiden.", "tokens": ["Angst", ",", "was", "vns", "heis\u00b7set", "schei\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Erbarmt dich, Gott, die\u00df alles nicht?", "tokens": ["Er\u00b7barmt", "dich", ",", "Gott", ",", "die\u00df", "al\u00b7les", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "PDS", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was stellstu vor dein Angesicht", "tokens": ["Was", "stell\u00b7stu", "vor", "dein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Grewel vnsrer S\u00fcnden?", "tokens": ["Den", "Gre\u00b7wel", "vns\u00b7rer", "S\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ach z\u00fcrn doch nicht mit d\u00fcrrem Hew,", "tokens": ["Ach", "z\u00fcrn", "doch", "nicht", "mit", "d\u00fcr\u00b7rem", "Hew", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "PTKNEG", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Rauch vnd Staube, Dampff vnd Sprew,", "tokens": ["Mit", "Rauch", "vnd", "Stau\u00b7be", ",", "Dampff", "vnd", "Sprew", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd la\u00df vns Gnade finden.", "tokens": ["Vnd", "la\u00df", "vns", "Gna\u00b7de", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Schrey vnserm Ohr' vnd Hertzen ein", "tokens": ["Schrey", "vn\u00b7serm", "Ohr'", "vnd", "Hert\u00b7zen", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des eiteln Lebens Flucht vnd Pein,", "tokens": ["Des", "ei\u00b7teln", "Le\u00b7bens", "Flucht", "vnd", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df wir die Bo\u00dfheit fliehen,", "tokens": ["Da\u00df", "wir", "die", "Bo\u00df\u00b7heit", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Rath suchen blo\u00df bey deinem Sohn,", "tokens": ["Rath", "su\u00b7chen", "blo\u00df", "bey", "dei\u00b7nem", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Vnd Lebens-satt, wie Simeon,", "tokens": ["Vnd", "Le\u00b7bens\u00b7satt", ",", "wie", "Si\u00b7me\u00b7on", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu dir von hinnen ziehen.", "tokens": ["Zu", "dir", "von", "hin\u00b7nen", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Dv, Gott, bist ausser aller Zeit", "tokens": ["Dv", ",", "Gott", ",", "bist", "aus\u00b7ser", "al\u00b7ler", "Zeit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Ewigkeit zu Ewigkeit.", "tokens": ["Von", "E\u00b7wig\u00b7keit", "zu", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eh als die Welt gestanden,", "tokens": ["Eh", "als", "die", "Welt", "ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Warst du schon, was du jetzund bist,", "tokens": ["Warst", "du", "schon", ",", "was", "du", "je\u00b7tzund", "bist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "PWS", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd wirst, wenn alles nichts mehr ist,", "tokens": ["Vnd", "wirst", ",", "wenn", "al\u00b7les", "nichts", "mehr", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "KOUS", "PIS", "PIS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch immer seyn vorhanden.", "tokens": ["Noch", "im\u00b7mer", "seyn", "vor\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Hergegen, ach! wir Menschen sind", "tokens": ["Her\u00b7ge\u00b7gen", ",", "ach", "!", "wir", "Men\u00b7schen", "sind"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ITJ", "$.", "PPER", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verg\u00e4nglich, fl\u00fcchtig, Rauch vnd Wind!", "tokens": ["Ver\u00b7g\u00e4ng\u00b7lich", ",", "fl\u00fcch\u00b7tig", ",", "Rauch", "vnd", "Wind", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auff dein Wort sind wir kommen,", "tokens": ["Auff", "dein", "Wort", "sind", "wir", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Bekucken kaum den ErdenKrey\u00df,", "tokens": ["Be\u00b7ku\u00b7cken", "kaum", "den", "Er\u00b7den", "Krey\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd werden stracks, auff dein Gehei\u00df,", "tokens": ["Vnd", "wer\u00b7den", "stracks", ",", "auff", "dein", "Ge\u00b7hei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch wieder weggenommen.", "tokens": ["Auch", "wie\u00b7der", "weg\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Wir fahren hin gleich wie ein Traum,", "tokens": ["Wir", "fah\u00b7ren", "hin", "gleich", "wie", "ein", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vergehn wie Schatten und wie Schaum,", "tokens": ["Ver\u00b7gehn", "wie", "Schat\u00b7ten", "und", "wie", "Schaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NN", "KON", "PWAV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind eine Wasser-Blase:", "tokens": ["Sind", "ei\u00b7ne", "Was\u00b7ser\u00b7Bla\u00b7se", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Zeit Gewalt eilt mit vns fort,", "tokens": ["Der", "Zeit", "Ge\u00b7walt", "eilt", "mit", "vns", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie mit den Wolcken sonst der Nort,", "tokens": ["Wie", "mit", "den", "Wol\u00b7cken", "sonst", "der", "Nort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Herbst-Lufft mit dem Grase.", "tokens": ["Die", "Herbs\u00b7tLufft", "mit", "dem", "Gra\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da dieser auch vnd der vieleicht", "tokens": ["Da", "die\u00b7ser", "auch", "vnd", "der", "vie\u00b7leicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "ADV", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein guttes Antheil Jahr erreicht,", "tokens": ["Ein", "gut\u00b7tes", "An\u00b7theil", "Jahr", "er\u00b7reicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was wird es gro\u00df verfangen", "tokens": ["Was", "wird", "es", "gro\u00df", "ver\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bey dir, dem nichts sich gleichen mag", "tokens": ["Bey", "dir", ",", "dem", "nichts", "sich", "glei\u00b7chen", "mag"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "PRELS", "PIS", "PRF", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd tausent Jahre sind ein Tag,", "tokens": ["Vnd", "tau\u00b7sent", "Jah\u00b7re", "sind", "ein", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der gestern ist vergangen?", "tokens": ["Der", "ge\u00b7stern", "ist", "ver\u00b7gan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.12": {"line.1": {"text": "Wie kurtz die\u00df Leben wehren kan,", "tokens": ["Wie", "kurtz", "die\u00df", "Le\u00b7ben", "weh\u00b7ren", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PDS", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ist es dennoch vmb vnd an", "tokens": ["So", "ist", "es", "den\u00b7noch", "vmb", "vnd", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur Arbeit, Angst und Leiden:", "tokens": ["Nur", "Ar\u00b7beit", ",", "Angst", "und", "Lei\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Angst ist, was vns zur Welt gebiert,", "tokens": ["Angst", "ist", ",", "was", "vns", "zur", "Welt", "ge\u00b7biert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PWS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Angst, was vns leitet, tr\u00e4gt vnd f\u00fchrt,", "tokens": ["Angst", ",", "was", "vns", "lei\u00b7tet", ",", "tr\u00e4gt", "vnd", "f\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Angst, was vns heisset scheiden.", "tokens": ["Angst", ",", "was", "vns", "heis\u00b7set", "schei\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Erbarmt dich, Gott, die\u00df alles nicht?", "tokens": ["Er\u00b7barmt", "dich", ",", "Gott", ",", "die\u00df", "al\u00b7les", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "PDS", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was stellstu vor dein Angesicht", "tokens": ["Was", "stell\u00b7stu", "vor", "dein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Grewel vnsrer S\u00fcnden?", "tokens": ["Den", "Gre\u00b7wel", "vns\u00b7rer", "S\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ach z\u00fcrn doch nicht mit d\u00fcrrem Hew,", "tokens": ["Ach", "z\u00fcrn", "doch", "nicht", "mit", "d\u00fcr\u00b7rem", "Hew", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "PTKNEG", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Rauch vnd Staube, Dampff vnd Sprew,", "tokens": ["Mit", "Rauch", "vnd", "Stau\u00b7be", ",", "Dampff", "vnd", "Sprew", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd la\u00df vns Gnade finden.", "tokens": ["Vnd", "la\u00df", "vns", "Gna\u00b7de", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Schrey vnserm Ohr' vnd Hertzen ein", "tokens": ["Schrey", "vn\u00b7serm", "Ohr'", "vnd", "Hert\u00b7zen", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des eiteln Lebens Flucht vnd Pein,", "tokens": ["Des", "ei\u00b7teln", "Le\u00b7bens", "Flucht", "vnd", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df wir die Bo\u00dfheit fliehen,", "tokens": ["Da\u00df", "wir", "die", "Bo\u00df\u00b7heit", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Rath suchen blo\u00df bey deinem Sohn,", "tokens": ["Rath", "su\u00b7chen", "blo\u00df", "bey", "dei\u00b7nem", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Vnd Lebens-satt, wie Simeon,", "tokens": ["Vnd", "Le\u00b7bens\u00b7satt", ",", "wie", "Si\u00b7me\u00b7on", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu dir von hinnen ziehen.", "tokens": ["Zu", "dir", "von", "hin\u00b7nen", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}