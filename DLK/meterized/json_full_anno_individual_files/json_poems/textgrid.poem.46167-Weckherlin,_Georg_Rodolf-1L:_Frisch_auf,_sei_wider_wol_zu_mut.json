{"textgrid.poem.46167": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Frisch auf, sei wider wol zu mut", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Frisch auf, sei wider wol zu mut", "tokens": ["Frisch", "auf", ",", "sei", "wi\u00b7der", "wol", "zu", "mut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "PTKVZ", "$,", "VAFIN", "APPR", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du h\u00e4uflein zwar klein, aber gut,", "tokens": ["du", "h\u00e4uf\u00b7lein", "zwar", "klein", ",", "a\u00b7ber", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "so das ungl\u00fcck so lang betr\u00fcbet:", "tokens": ["so", "das", "un\u00b7gl\u00fcck", "so", "lang", "be\u00b7tr\u00fc\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "erquick dein herz und dein gesicht,", "tokens": ["er\u00b7quick", "dein", "herz", "und", "dein", "ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "KON", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sei wol zu mut und zweifle nicht,", "tokens": ["sei", "wol", "zu", "mut", "und", "zweif\u00b7le", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKA", "ADJD", "KON", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "dan da\u00df der h\u00f6chst dich h\u00f6chlich liebet,", "tokens": ["dan", "da\u00df", "der", "h\u00f6chst", "dich", "h\u00f6ch\u00b7lich", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "VVFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "weil Mansfeld, der gleichlose held", "tokens": ["weil", "Mans\u00b7feld", ",", "der", "gleich\u00b7lo\u00b7se", "held"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "zeucht nu widrum f\u00fcr dich zu feld.", "tokens": ["zeucht", "nu", "wid\u00b7rum", "f\u00fcr", "dich", "zu", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Dan unsre vil, nichts werte, feind", "tokens": ["Dan", "uns\u00b7re", "vil", ",", "nichts", "wer\u00b7te", ",", "feind"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "PPOSAT", "ADV", "$,", "PIS", "VVFIN", "$,", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "und wenig, doch vil werte, freind", "tokens": ["und", "we\u00b7nig", ",", "doch", "vil", "wer\u00b7te", ",", "freind"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "$,", "ADV", "ADV", "VVFIN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sein prob und lob zugleich bewehren:", "tokens": ["sein", "prob", "und", "lob", "zu\u00b7gleich", "be\u00b7weh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "KON", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "indem der einen freudentag,", "tokens": ["in\u00b7dem", "der", "ei\u00b7nen", "freu\u00b7den\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "indem der andern niderlag", "tokens": ["in\u00b7dem", "der", "an\u00b7dern", "ni\u00b7der\u00b7lag"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wird mit ungleicher stim vermehren,", "tokens": ["wird", "mit", "un\u00b7glei\u00b7cher", "stim", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df wa nu dieser werte held,", "tokens": ["da\u00df", "wa", "nu", "die\u00b7ser", "wer\u00b7te", "held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "da siget allzeit des Mans feld.", "tokens": ["da", "si\u00b7get", "all\u00b7zeit", "des", "Mans", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Er ist ja so geschwind und weis,", "tokens": ["Er", "ist", "ja", "so", "ge\u00b7schwind", "und", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ihm an kriegslist, rat, sorg, flei\u00df", "tokens": ["da\u00df", "ihm", "an", "kriegs\u00b7list", ",", "rat", ",", "sorg", ",", "flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "und kundschaft mu\u00df Ulysses weichen:", "tokens": ["und", "kund\u00b7schaft", "mu\u00df", "U\u00b7lys\u00b7ses", "wei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "NE", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "in dem scharm\u00fctzel, sturm und schlacht", "tokens": ["in", "dem", "schar\u00b7m\u00fct\u00b7zel", ",", "sturm", "und", "schlacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "KON", "VVFIN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "ist ihm an dapferkeit und macht", "tokens": ["ist", "ihm", "an", "dap\u00b7fer\u00b7keit", "und", "macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "NN", "KON", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Achilles auch nicht zu vergleichen:", "tokens": ["A\u00b7chil\u00b7les", "auch", "nicht", "zu", "ver\u00b7glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und ist mehr wert der werte held,", "tokens": ["und", "ist", "mehr", "wert", "der", "wer\u00b7te", "held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "dan andrer helden ganzes feld.", "tokens": ["dan", "an\u00b7drer", "hel\u00b7den", "gan\u00b7zes", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Ganz wunderreich ist sein verstand", "tokens": ["Ganz", "wun\u00b7der\u00b7reich", "ist", "sein", "ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und dundergleich ist seine hand,", "tokens": ["und", "dun\u00b7derg\u00b7leich", "ist", "sei\u00b7ne", "hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sie beede bringen nichts dan wunder:", "tokens": ["sie", "bee\u00b7de", "brin\u00b7gen", "nichts", "dan", "wun\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "PIS", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "durch seines anblicks wetterleich,", "tokens": ["durch", "sei\u00b7nes", "an\u00b7blicks", "wet\u00b7ter\u00b7leich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "durch seiner wafen dunderstreich", "tokens": ["durch", "sei\u00b7ner", "wa\u00b7fen", "dun\u00b7der\u00b7streich"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die stolze risen gehen under!", "tokens": ["die", "stol\u00b7ze", "ri\u00b7sen", "ge\u00b7hen", "un\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "KON", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "ja dieser k\u00fchn und kluge held", "tokens": ["ja", "die\u00b7ser", "k\u00fchn", "und", "klu\u00b7ge", "held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ist mehr dan Mars selbs in dem feld.", "tokens": ["ist", "mehr", "dan", "Mars", "selbs", "in", "dem", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die, so torecht in ihrem wohn", "tokens": ["Die", ",", "so", "to\u00b7recht", "in", "ih\u00b7rem", "wohn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "ADV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcrbilden eine sonn und mon", "tokens": ["f\u00fcr\u00b7bil\u00b7den", "ei\u00b7ne", "sonn", "und", "mon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "zu Rom und Madrit dieser erden,", "tokens": ["zu", "Rom", "und", "Mad\u00b7rit", "die\u00b7ser", "er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bekennen schon selbs, da\u00df ihr schein", "tokens": ["be\u00b7ken\u00b7nen", "schon", "selbs", ",", "da\u00df", "ihr", "schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "kan ohn sein schwert nicht v\u00f6llig sein,", "tokens": ["kan", "ohn", "sein", "schwert", "nicht", "v\u00f6l\u00b7lig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "VVFIN", "PTKNEG", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sondern mu\u00df bleich und finster werden,", "tokens": ["son\u00b7dern", "mu\u00df", "bleich", "und", "fins\u00b7ter", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "KON", "ADJD", "VAINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "dieweil die Tiber, Tais und Scheld", "tokens": ["die\u00b7weil", "die", "Ti\u00b7ber", ",", "Tais", "und", "Scheld"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NE", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "soll oft nach w\u00e4ssern des Mans feld.", "tokens": ["soll", "oft", "nach", "w\u00e4s\u00b7sern", "des", "Mans", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Wolan, o held, so zeuch nur aus,", "tokens": ["Wo\u00b7lan", ",", "o", "held", ",", "so", "zeuch", "nur", "aus", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "VVFIN", "$,", "ADV", "VVIMP", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der guten trost, der b\u00f6sen graus,", "tokens": ["der", "gu\u00b7ten", "trost", ",", "der", "b\u00f6\u00b7sen", "graus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die freiheit wider aufzurichten;", "tokens": ["die", "frei\u00b7heit", "wi\u00b7der", "auf\u00b7zu\u00b7rich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und durch dein schwert, scharf und gerecht,", "tokens": ["und", "durch", "dein", "schwert", ",", "scharf", "und", "ge\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "errettend des reichs altes recht,", "tokens": ["er\u00b7ret\u00b7tend", "des", "reichs", "al\u00b7tes", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der tyrannei macht zu vernichten,", "tokens": ["der", "ty\u00b7ran\u00b7nei", "macht", "zu", "ver\u00b7nich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df man h\u00f6r mit ernst von der welt", "tokens": ["da\u00df", "man", "h\u00f6r", "mit", "ernst", "von", "der", "welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "da\u00df Mars selbs ist in des Mans feld.", "tokens": ["da\u00df", "Mars", "selbs", "ist", "in", "des", "Mans", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "VAFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}}, "stanza.7": {"line.1": {"text": "Alsdan, Mansfeld, soll mehr und mehr", "tokens": ["Als\u00b7dan", ",", "Mans\u00b7feld", ",", "soll", "mehr", "und", "mehr"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "VMFIN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dein nam und deiner thaten ehr", "tokens": ["dein", "nam", "und", "dei\u00b7ner", "tha\u00b7ten", "ehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "klar leuchten und der welt gefallen:", "tokens": ["klar", "leuch\u00b7ten", "und", "der", "welt", "ge\u00b7fal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und alsdan soll der Musen gunst", "tokens": ["und", "als\u00b7dan", "soll", "der", "Mu\u00b7sen", "gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "ART", "NN", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "mit klarer stim und wahrer kunst", "tokens": ["mit", "kla\u00b7rer", "stim", "und", "wah\u00b7rer", "kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "dein lob von West zu Ost erschallen:", "tokens": ["dein", "lob", "von", "West", "zu", "Ost", "er\u00b7schal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "alsdan soll singen alle welt:", "tokens": ["als\u00b7dan", "soll", "sin\u00b7gen", "al\u00b7le", "welt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "gleichlos ist Grav Ernst von Mansfeld.", "tokens": ["gleich\u00b7los", "ist", "Grav", "Ernst", "von", "Mans\u00b7feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "NE", "NE", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Frisch auf, sei wider wol zu mut", "tokens": ["Frisch", "auf", ",", "sei", "wi\u00b7der", "wol", "zu", "mut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "PTKVZ", "$,", "VAFIN", "APPR", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du h\u00e4uflein zwar klein, aber gut,", "tokens": ["du", "h\u00e4uf\u00b7lein", "zwar", "klein", ",", "a\u00b7ber", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "so das ungl\u00fcck so lang betr\u00fcbet:", "tokens": ["so", "das", "un\u00b7gl\u00fcck", "so", "lang", "be\u00b7tr\u00fc\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "erquick dein herz und dein gesicht,", "tokens": ["er\u00b7quick", "dein", "herz", "und", "dein", "ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "KON", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sei wol zu mut und zweifle nicht,", "tokens": ["sei", "wol", "zu", "mut", "und", "zweif\u00b7le", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKA", "ADJD", "KON", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "dan da\u00df der h\u00f6chst dich h\u00f6chlich liebet,", "tokens": ["dan", "da\u00df", "der", "h\u00f6chst", "dich", "h\u00f6ch\u00b7lich", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "VVFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "weil Mansfeld, der gleichlose held", "tokens": ["weil", "Mans\u00b7feld", ",", "der", "gleich\u00b7lo\u00b7se", "held"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "zeucht nu widrum f\u00fcr dich zu feld.", "tokens": ["zeucht", "nu", "wid\u00b7rum", "f\u00fcr", "dich", "zu", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Dan unsre vil, nichts werte, feind", "tokens": ["Dan", "uns\u00b7re", "vil", ",", "nichts", "wer\u00b7te", ",", "feind"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "PPOSAT", "ADV", "$,", "PIS", "VVFIN", "$,", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "und wenig, doch vil werte, freind", "tokens": ["und", "we\u00b7nig", ",", "doch", "vil", "wer\u00b7te", ",", "freind"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "$,", "ADV", "ADV", "VVFIN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sein prob und lob zugleich bewehren:", "tokens": ["sein", "prob", "und", "lob", "zu\u00b7gleich", "be\u00b7weh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "KON", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "indem der einen freudentag,", "tokens": ["in\u00b7dem", "der", "ei\u00b7nen", "freu\u00b7den\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "indem der andern niderlag", "tokens": ["in\u00b7dem", "der", "an\u00b7dern", "ni\u00b7der\u00b7lag"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wird mit ungleicher stim vermehren,", "tokens": ["wird", "mit", "un\u00b7glei\u00b7cher", "stim", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df wa nu dieser werte held,", "tokens": ["da\u00df", "wa", "nu", "die\u00b7ser", "wer\u00b7te", "held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "da siget allzeit des Mans feld.", "tokens": ["da", "si\u00b7get", "all\u00b7zeit", "des", "Mans", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "Er ist ja so geschwind und weis,", "tokens": ["Er", "ist", "ja", "so", "ge\u00b7schwind", "und", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ihm an kriegslist, rat, sorg, flei\u00df", "tokens": ["da\u00df", "ihm", "an", "kriegs\u00b7list", ",", "rat", ",", "sorg", ",", "flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "und kundschaft mu\u00df Ulysses weichen:", "tokens": ["und", "kund\u00b7schaft", "mu\u00df", "U\u00b7lys\u00b7ses", "wei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "NE", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "in dem scharm\u00fctzel, sturm und schlacht", "tokens": ["in", "dem", "schar\u00b7m\u00fct\u00b7zel", ",", "sturm", "und", "schlacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "KON", "VVFIN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "ist ihm an dapferkeit und macht", "tokens": ["ist", "ihm", "an", "dap\u00b7fer\u00b7keit", "und", "macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "NN", "KON", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Achilles auch nicht zu vergleichen:", "tokens": ["A\u00b7chil\u00b7les", "auch", "nicht", "zu", "ver\u00b7glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und ist mehr wert der werte held,", "tokens": ["und", "ist", "mehr", "wert", "der", "wer\u00b7te", "held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "dan andrer helden ganzes feld.", "tokens": ["dan", "an\u00b7drer", "hel\u00b7den", "gan\u00b7zes", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Ganz wunderreich ist sein verstand", "tokens": ["Ganz", "wun\u00b7der\u00b7reich", "ist", "sein", "ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und dundergleich ist seine hand,", "tokens": ["und", "dun\u00b7derg\u00b7leich", "ist", "sei\u00b7ne", "hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sie beede bringen nichts dan wunder:", "tokens": ["sie", "bee\u00b7de", "brin\u00b7gen", "nichts", "dan", "wun\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "PIS", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "durch seines anblicks wetterleich,", "tokens": ["durch", "sei\u00b7nes", "an\u00b7blicks", "wet\u00b7ter\u00b7leich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "durch seiner wafen dunderstreich", "tokens": ["durch", "sei\u00b7ner", "wa\u00b7fen", "dun\u00b7der\u00b7streich"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die stolze risen gehen under!", "tokens": ["die", "stol\u00b7ze", "ri\u00b7sen", "ge\u00b7hen", "un\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "KON", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "ja dieser k\u00fchn und kluge held", "tokens": ["ja", "die\u00b7ser", "k\u00fchn", "und", "klu\u00b7ge", "held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ist mehr dan Mars selbs in dem feld.", "tokens": ["ist", "mehr", "dan", "Mars", "selbs", "in", "dem", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Die, so torecht in ihrem wohn", "tokens": ["Die", ",", "so", "to\u00b7recht", "in", "ih\u00b7rem", "wohn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "ADV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcrbilden eine sonn und mon", "tokens": ["f\u00fcr\u00b7bil\u00b7den", "ei\u00b7ne", "sonn", "und", "mon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "zu Rom und Madrit dieser erden,", "tokens": ["zu", "Rom", "und", "Mad\u00b7rit", "die\u00b7ser", "er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bekennen schon selbs, da\u00df ihr schein", "tokens": ["be\u00b7ken\u00b7nen", "schon", "selbs", ",", "da\u00df", "ihr", "schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "kan ohn sein schwert nicht v\u00f6llig sein,", "tokens": ["kan", "ohn", "sein", "schwert", "nicht", "v\u00f6l\u00b7lig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "VVFIN", "PTKNEG", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sondern mu\u00df bleich und finster werden,", "tokens": ["son\u00b7dern", "mu\u00df", "bleich", "und", "fins\u00b7ter", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "KON", "ADJD", "VAINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "dieweil die Tiber, Tais und Scheld", "tokens": ["die\u00b7weil", "die", "Ti\u00b7ber", ",", "Tais", "und", "Scheld"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NE", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "soll oft nach w\u00e4ssern des Mans feld.", "tokens": ["soll", "oft", "nach", "w\u00e4s\u00b7sern", "des", "Mans", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Wolan, o held, so zeuch nur aus,", "tokens": ["Wo\u00b7lan", ",", "o", "held", ",", "so", "zeuch", "nur", "aus", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "VVFIN", "$,", "ADV", "VVIMP", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der guten trost, der b\u00f6sen graus,", "tokens": ["der", "gu\u00b7ten", "trost", ",", "der", "b\u00f6\u00b7sen", "graus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die freiheit wider aufzurichten;", "tokens": ["die", "frei\u00b7heit", "wi\u00b7der", "auf\u00b7zu\u00b7rich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und durch dein schwert, scharf und gerecht,", "tokens": ["und", "durch", "dein", "schwert", ",", "scharf", "und", "ge\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "errettend des reichs altes recht,", "tokens": ["er\u00b7ret\u00b7tend", "des", "reichs", "al\u00b7tes", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der tyrannei macht zu vernichten,", "tokens": ["der", "ty\u00b7ran\u00b7nei", "macht", "zu", "ver\u00b7nich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df man h\u00f6r mit ernst von der welt", "tokens": ["da\u00df", "man", "h\u00f6r", "mit", "ernst", "von", "der", "welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "da\u00df Mars selbs ist in des Mans feld.", "tokens": ["da\u00df", "Mars", "selbs", "ist", "in", "des", "Mans", "feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "VAFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}}, "stanza.14": {"line.1": {"text": "Alsdan, Mansfeld, soll mehr und mehr", "tokens": ["Als\u00b7dan", ",", "Mans\u00b7feld", ",", "soll", "mehr", "und", "mehr"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "VMFIN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dein nam und deiner thaten ehr", "tokens": ["dein", "nam", "und", "dei\u00b7ner", "tha\u00b7ten", "ehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "klar leuchten und der welt gefallen:", "tokens": ["klar", "leuch\u00b7ten", "und", "der", "welt", "ge\u00b7fal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und alsdan soll der Musen gunst", "tokens": ["und", "als\u00b7dan", "soll", "der", "Mu\u00b7sen", "gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "ART", "NN", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "mit klarer stim und wahrer kunst", "tokens": ["mit", "kla\u00b7rer", "stim", "und", "wah\u00b7rer", "kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "dein lob von West zu Ost erschallen:", "tokens": ["dein", "lob", "von", "West", "zu", "Ost", "er\u00b7schal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "alsdan soll singen alle welt:", "tokens": ["als\u00b7dan", "soll", "sin\u00b7gen", "al\u00b7le", "welt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "gleichlos ist Grav Ernst von Mansfeld.", "tokens": ["gleich\u00b7los", "ist", "Grav", "Ernst", "von", "Mans\u00b7feld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "NE", "NE", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}