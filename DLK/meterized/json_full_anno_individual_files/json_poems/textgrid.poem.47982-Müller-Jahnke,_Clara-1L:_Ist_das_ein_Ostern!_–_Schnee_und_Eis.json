{"textgrid.poem.47982": {"metadata": {"author": {"name": "M\u00fcller-Jahnke, Clara", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ist das ein Ostern! \u2013 Schnee und Eis", "genre": "verse", "period": "N.A.", "pub_year": 1882, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist das ein Ostern! \u2013 Schnee und Eis", "tokens": ["Ist", "das", "ein", "Os\u00b7tern", "!", "\u2013", "Schnee", "und", "Eis"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN", "$.", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hielt noch die Erde fest umfangen;", "tokens": ["hielt", "noch", "die", "Er\u00b7de", "fest", "um\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "frostschauernd sind am Weidenreis", "tokens": ["frost\u00b7schau\u00b7ernd", "sind", "am", "Wei\u00b7den\u00b7reis"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die Palmenk\u00e4tzchen aufgegangen.", "tokens": ["die", "Pal\u00b7men\u00b7k\u00e4tz\u00b7chen", "auf\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Verstohlen durch den Wolkenflor", "tokens": ["Ver\u00b7stoh\u00b7len", "durch", "den", "Wol\u00b7ken\u00b7flor"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "blitzt hie und da ein Sonnenfunken \u2013", "tokens": ["blitzt", "hie", "und", "da", "ein", "Son\u00b7nen\u00b7fun\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "es war, als sei im Weihnachtstraum", "tokens": ["es", "war", ",", "als", "sei", "im", "Weih\u00b7nachts\u00b7traum"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die schlummerm\u00fcde Welt versunken.", "tokens": ["die", "schlum\u00b7mer\u00b7m\u00fc\u00b7de", "Welt", "ver\u00b7sun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es war, als sollten nimmermehr", "tokens": ["Es", "war", ",", "als", "soll\u00b7ten", "nim\u00b7mer\u00b7mehr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ins blaue Meer die Segel gehen, \u2013", "tokens": ["ins", "blau\u00b7e", "Meer", "die", "Se\u00b7gel", "ge\u00b7hen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVINF", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "im Park ert\u00f6nen Finkenschlag,", "tokens": ["im", "Park", "er\u00b7t\u00f6\u00b7nen", "Fin\u00b7ken\u00b7schlag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und Veilchenduft das Tal durchwehen. \u2013", "tokens": ["und", "Veil\u00b7chen\u00b7duft", "das", "Tal", "durch\u00b7we\u00b7hen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und dennoch, Seele, sei gewi\u00df:", "tokens": ["Und", "den\u00b7noch", ",", "See\u00b7le", ",", "sei", "ge\u00b7wi\u00df", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "NN", "$,", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie eng sich auch die Fesseln schlingen,", "tokens": ["Wie", "eng", "sich", "auch", "die", "Fes\u00b7seln", "schlin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PRF", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "es wird der Lenz, das Sonnenkind,", "tokens": ["es", "wird", "der", "Lenz", ",", "das", "Son\u00b7nen\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dem Scho\u00df der Erde sich entringen.", "tokens": ["dem", "Scho\u00df", "der", "Er\u00b7de", "sich", "ent\u00b7rin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Dann sinkt dahin wie Nebelflor", "tokens": ["Dann", "sinkt", "da\u00b7hin", "wie", "Ne\u00b7bel\u00b7flor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PAV", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "auch all dein Weh und deine Sorgen,", "tokens": ["auch", "all", "dein", "Weh", "und", "dei\u00b7ne", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und veilchen\u00e4ugig lacht dich an", "tokens": ["und", "veil\u00b7chen\u00b7\u00e4u\u00b7gig", "lacht", "dich", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein goldner Auferstehungsmorgen! \u2013", "tokens": ["ein", "gold\u00b7ner", "Auf\u00b7er\u00b7ste\u00b7hungs\u00b7mor\u00b7gen", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ist das ein Ostern! \u2013 Schnee und Eis", "tokens": ["Ist", "das", "ein", "Os\u00b7tern", "!", "\u2013", "Schnee", "und", "Eis"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN", "$.", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hielt noch die Erde fest umfangen;", "tokens": ["hielt", "noch", "die", "Er\u00b7de", "fest", "um\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "frostschauernd sind am Weidenreis", "tokens": ["frost\u00b7schau\u00b7ernd", "sind", "am", "Wei\u00b7den\u00b7reis"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die Palmenk\u00e4tzchen aufgegangen.", "tokens": ["die", "Pal\u00b7men\u00b7k\u00e4tz\u00b7chen", "auf\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Verstohlen durch den Wolkenflor", "tokens": ["Ver\u00b7stoh\u00b7len", "durch", "den", "Wol\u00b7ken\u00b7flor"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "blitzt hie und da ein Sonnenfunken \u2013", "tokens": ["blitzt", "hie", "und", "da", "ein", "Son\u00b7nen\u00b7fun\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "es war, als sei im Weihnachtstraum", "tokens": ["es", "war", ",", "als", "sei", "im", "Weih\u00b7nachts\u00b7traum"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die schlummerm\u00fcde Welt versunken.", "tokens": ["die", "schlum\u00b7mer\u00b7m\u00fc\u00b7de", "Welt", "ver\u00b7sun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es war, als sollten nimmermehr", "tokens": ["Es", "war", ",", "als", "soll\u00b7ten", "nim\u00b7mer\u00b7mehr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ins blaue Meer die Segel gehen, \u2013", "tokens": ["ins", "blau\u00b7e", "Meer", "die", "Se\u00b7gel", "ge\u00b7hen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVINF", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "im Park ert\u00f6nen Finkenschlag,", "tokens": ["im", "Park", "er\u00b7t\u00f6\u00b7nen", "Fin\u00b7ken\u00b7schlag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und Veilchenduft das Tal durchwehen. \u2013", "tokens": ["und", "Veil\u00b7chen\u00b7duft", "das", "Tal", "durch\u00b7we\u00b7hen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und dennoch, Seele, sei gewi\u00df:", "tokens": ["Und", "den\u00b7noch", ",", "See\u00b7le", ",", "sei", "ge\u00b7wi\u00df", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "NN", "$,", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie eng sich auch die Fesseln schlingen,", "tokens": ["Wie", "eng", "sich", "auch", "die", "Fes\u00b7seln", "schlin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PRF", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "es wird der Lenz, das Sonnenkind,", "tokens": ["es", "wird", "der", "Lenz", ",", "das", "Son\u00b7nen\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dem Scho\u00df der Erde sich entringen.", "tokens": ["dem", "Scho\u00df", "der", "Er\u00b7de", "sich", "ent\u00b7rin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Dann sinkt dahin wie Nebelflor", "tokens": ["Dann", "sinkt", "da\u00b7hin", "wie", "Ne\u00b7bel\u00b7flor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PAV", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "auch all dein Weh und deine Sorgen,", "tokens": ["auch", "all", "dein", "Weh", "und", "dei\u00b7ne", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und veilchen\u00e4ugig lacht dich an", "tokens": ["und", "veil\u00b7chen\u00b7\u00e4u\u00b7gig", "lacht", "dich", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein goldner Auferstehungsmorgen! \u2013", "tokens": ["ein", "gold\u00b7ner", "Auf\u00b7er\u00b7ste\u00b7hungs\u00b7mor\u00b7gen", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}