{"dta.poem.3126": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "171.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein K\u00f6nig m\u00f6cht' ich seyn, ein Herr der Morgenlande,", "tokens": ["Ein", "K\u00f6\u00b7nig", "m\u00f6cht'", "ich", "seyn", ",", "ein", "Herr", "der", "Mor\u00b7gen\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VAINF", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der so zu geben als zu nehmen w\u00e4r' im Stande.", "tokens": ["Der", "so", "zu", "ge\u00b7ben", "als", "zu", "neh\u00b7men", "w\u00e4r'", "im", "Stan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKZU", "VVINF", "KOKOM", "PTKZU", "VVINF", "VAFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der keinen vor sich lie\u00df' erscheinen ohne Gaben,", "tokens": ["Der", "kei\u00b7nen", "vor", "sich", "lie\u00df'", "er\u00b7schei\u00b7nen", "oh\u00b7ne", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "APPR", "PRF", "ADJD", "VVINF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und keinen von sich gehn, ohn' ihn beschenkt zu haben.", "tokens": ["Und", "kei\u00b7nen", "von", "sich", "gehn", ",", "ohn'", "ihn", "be\u00b7schenkt", "zu", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "APPR", "PRF", "VVINF", "$,", "KOUI", "PPER", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wer sein Geschenk empf\u00e4ngt, den wird es nicht besch\u00e4men,", "tokens": ["Wer", "sein", "Ge\u00b7schenk", "emp\u00b7f\u00e4ngt", ",", "den", "wird", "es", "nicht", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "ART", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und selber ohne Scham kann er Geschenk' annehmen;", "tokens": ["Und", "sel\u00b7ber", "oh\u00b7ne", "Scham", "kann", "er", "Ge\u00b7schen\u00b7k'", "an\u00b7neh\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Weil alles ihm geh\u00f6rt, was Menschen freut und frommt,", "tokens": ["Weil", "al\u00b7les", "ihm", "ge\u00b7h\u00f6rt", ",", "was", "Men\u00b7schen", "freut", "und", "frommt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$,", "PWS", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So einzig zu ihm geht, wie einzig von ihm kommt.", "tokens": ["So", "ein\u00b7zig", "zu", "ihm", "geht", ",", "wie", "ein\u00b7zig", "von", "ihm", "kommt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Des Gabentausches wie sollt' er sich scheun und sch\u00e4men,", "tokens": ["Des", "Ga\u00b7ben\u00b7tau\u00b7sches", "wie", "sollt'", "er", "sich", "scheun", "und", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "VMFIN", "PPER", "PRF", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da G\u00f6tter Segen streun und Opferduft annehmen?", "tokens": ["Da", "G\u00f6t\u00b7ter", "Se\u00b7gen", "streun", "und", "Op\u00b7fer\u00b7duft", "an\u00b7neh\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "VVINF", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ein solcher m\u00f6cht' ich seyn, um ohne Scheu und Bangen", "tokens": ["Ein", "sol\u00b7cher", "m\u00f6cht'", "ich", "seyn", ",", "um", "oh\u00b7ne", "Scheu", "und", "Ban\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VMFIN", "PPER", "VAINF", "$,", "KOUI", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Geschenke selbst noch mehr zu geben als empfangen;", "tokens": ["Ge\u00b7schen\u00b7ke", "selbst", "noch", "mehr", "zu", "ge\u00b7ben", "als", "emp\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Da\u00df Reichempfangenes nicht m\u00fc\u00dfte mich erniedern", "tokens": ["Da\u00df", "Rei\u00b7ch\u00b7emp\u00b7fan\u00b7ge\u00b7nes", "nicht", "m\u00fc\u00df\u00b7te", "mich", "er\u00b7nie\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "PTKNEG", "VMFIN", "PRF", "VVINF"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Durch das Gef\u00fchl, ich sei zu arm es zu erwiedern.", "tokens": ["Durch", "das", "Ge\u00b7f\u00fchl", ",", "ich", "sei", "zu", "arm", "es", "zu", "er\u00b7wie\u00b7dern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "PTKA", "ADJD", "PPER", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}}}}