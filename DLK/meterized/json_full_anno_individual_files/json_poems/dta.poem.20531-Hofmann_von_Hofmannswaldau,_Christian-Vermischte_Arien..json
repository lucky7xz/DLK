{"dta.poem.20531": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Vermischte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Weil meine kohlen v\u00f6llig glut gefangen/", "tokens": ["Weil", "mei\u00b7ne", "koh\u00b7len", "v\u00f6l\u00b7lig", "glut", "ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So m\u00fcssen sie die flammen lassen sehn/", "tokens": ["So", "m\u00fcs\u00b7sen", "sie", "die", "flam\u00b7men", "las\u00b7sen", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "VVINF", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo stein und eisen zunder kan erlangen/", "tokens": ["Wo", "stein", "und", "ei\u00b7sen", "zun\u00b7der", "kan", "er\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "VVFIN", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So mu\u00df daraus die sch\u00f6nste flamm entstehn;", "tokens": ["So", "mu\u00df", "da\u00b7raus", "die", "sch\u00f6ns\u00b7te", "flamm", "ent\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PAV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das hellste feuer brennt nicht so gut/", "tokens": ["Das", "hells\u00b7te", "feu\u00b7er", "brennt", "nicht", "so", "gut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKNEG", "ADV", "ADJD", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Als mein getreu/ doch frisches blut/", "tokens": ["Als", "mein", "ge\u00b7treu", "/", "doch", "fri\u00b7sches", "blut", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJD", "$(", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit furchtsamen/ doch steiffen muth.", "tokens": ["Mit", "furcht\u00b7sa\u00b7men", "/", "doch", "steif\u00b7fen", "muth", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "ADV", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Du bist dir ja alleine nicht gebohren/", "tokens": ["Du", "bist", "dir", "ja", "al\u00b7lei\u00b7ne", "nicht", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der purpur so die rosen-lippen deckt/", "tokens": ["Der", "pur\u00b7pur", "so", "die", "ro\u00b7sen\u00b7\u00b7lip\u00b7pen", "deckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist doch f\u00fcr andre lippen auserkohren/", "tokens": ["Ist", "doch", "f\u00fcr", "and\u00b7re", "lip\u00b7pen", "au\u00b7ser\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil keine pracht sich sonst so weit erstreckt;", "tokens": ["Weil", "kei\u00b7ne", "pracht", "sich", "sonst", "so", "weit", "er\u00b7streckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dein himmel hegt zwey sonnen zwar/", "tokens": ["Dein", "him\u00b7mel", "hegt", "zwey", "son\u00b7nen", "zwar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "CARD", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch sie verblenden gantz und gar/", "tokens": ["Doch", "sie", "ver\u00b7blen\u00b7den", "gantz", "und", "gar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "KON", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und scheinen mir nur zur gefahr.", "tokens": ["Und", "schei\u00b7nen", "mir", "nur", "zur", "ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der schnee/ der um den hal\u00df und br\u00fcste lieget/", "tokens": ["Der", "schnee", "/", "der", "um", "den", "hal\u00df", "und", "br\u00fcs\u00b7te", "lie\u00b7get", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "APPR", "ART", "NN", "KON", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die berge/ derer spitzen feurig seyn.", "tokens": ["Die", "ber\u00b7ge", "/", "de\u00b7rer", "spit\u00b7zen", "feu\u00b7rig", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "PDS", "VVFIN", "ADJD", "VAINF", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Die haben mich mit ihrer macht besieget/", "tokens": ["Die", "ha\u00b7ben", "mich", "mit", "ih\u00b7rer", "macht", "be\u00b7sie\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "PPOSAT", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bedencke/ da\u00df die nacht folg\u2019 sonnenschein/", "tokens": ["Be\u00b7den\u00b7cke", "/", "da\u00df", "die", "nacht", "fol\u00b7g'", "son\u00b7nen\u00b7schein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "ART", "NN", "VVFIN", "ADV", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Der m\u00e4y vergeht/ wie andre zeit;", "tokens": ["Der", "m\u00e4y", "ver\u00b7geht", "/", "wie", "and\u00b7re", "zeit", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$(", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum/ wenn die jugend lust anbeut/", "tokens": ["Drum", "/", "wenn", "die", "ju\u00b7gend", "lust", "an\u00b7beut", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "KOUS", "ART", "NN", "VVFIN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So brauch dich der in fr\u00f6lichkeit.", "tokens": ["So", "brauch", "dich", "der", "in", "fr\u00f6\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich \u00fcbergebe nun mein schiff den wellen;", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7ge\u00b7be", "nun", "mein", "schiff", "den", "wel\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "VVFIN", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil guter wind in meine seegel bl\u00e4st/", "tokens": ["Weil", "gu\u00b7ter", "wind", "in", "mei\u00b7ne", "see\u00b7gel", "bl\u00e4st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So will ich mich in deine hafen stellen/", "tokens": ["So", "will", "ich", "mich", "in", "dei\u00b7ne", "ha\u00b7fen", "stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo deine gunst mich nur anlenden l\u00e4st/", "tokens": ["Wo", "dei\u00b7ne", "gunst", "mich", "nur", "an\u00b7len\u00b7den", "l\u00e4st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "ADV", "VVINF", "VVFIN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die hoffnung ist mein see-compa\u00df/", "tokens": ["Die", "hoff\u00b7nung", "ist", "mein", "see\u00b7com\u00b7pa\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo die mich l\u00e4st/ so werd\u2019 ich la\u00df/", "tokens": ["Wo", "die", "mich", "l\u00e4st", "/", "so", "werd'", "ich", "la\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "PPER", "VVFIN", "$(", "ADV", "VAFIN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und d\u00fcrre wie das laub und gra\u00df.", "tokens": ["Und", "d\u00fcr\u00b7re", "wie", "das", "laub", "und", "gra\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja solte gleich mein leib den todt erdulten/", "tokens": ["Ja", "sol\u00b7te", "gleich", "mein", "leib", "den", "todt", "er\u00b7dul\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VMFIN", "ADV", "PPOSAT", "NN", "ART", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So soll mein geist um deinen mund-rubin", "tokens": ["So", "soll", "mein", "geist", "um", "dei\u00b7nen", "mun\u00b7dru\u00b7bin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Zur wache stehn/ und zahlen seine schulden/", "tokens": ["Zur", "wa\u00b7che", "stehn", "/", "und", "zah\u00b7len", "sei\u00b7ne", "schul\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVINF", "$(", "KON", "VVFIN", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und nimmermehr von diesem posten ziehn;", "tokens": ["Und", "nim\u00b7mer\u00b7mehr", "von", "die\u00b7sem", "pos\u00b7ten", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PDAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ja selbst mein staub soll meine treu", "tokens": ["Ja", "selbst", "mein", "staub", "soll", "mei\u00b7ne", "treu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "PPOSAT", "NN", "VMFIN", "PPOSAT", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bezeugen und vermelden frey/", "tokens": ["Be\u00b7zeu\u00b7gen", "und", "ver\u00b7mel\u00b7den", "frey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie das mein tod von liebe sey.", "tokens": ["Wie", "das", "mein", "tod", "von", "lie\u00b7be", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "PPOSAT", "NN", "APPR", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}