{"textgrid.poem.44539": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "[der Henker hole die Journale]", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Henker hole die Journale,", "tokens": ["Der", "Hen\u00b7ker", "ho\u00b7le", "die", "Jour\u00b7na\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sind das Brandmal unsrer neuen Welt,", "tokens": ["Sie", "sind", "das", "Brand\u00b7mal", "uns\u00b7rer", "neu\u00b7en", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der ekle Abhub von dem Wissenmahle,", "tokens": ["Der", "ek\u00b7le", "Ab\u00b7hub", "von", "dem", "Wis\u00b7sen\u00b7mah\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der, f\u00fcr die Viehmast, in die Zuber f\u00e4llt.", "tokens": ["Der", ",", "f\u00fcr", "die", "Vieh\u00b7mast", ",", "in", "die", "Zu\u00b7ber", "f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sie sind die breitgedeckten, offnen Tische,", "tokens": ["Sie", "sind", "die", "breit\u00b7ge\u00b7deck\u00b7ten", ",", "off\u00b7nen", "Ti\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo Tor und Weiser sich als Nachbar schaut,", "tokens": ["Wo", "Tor", "und", "Wei\u00b7ser", "sich", "als", "Nach\u00b7bar", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NN", "PRF", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und eines Schluckes aus dem Buntgemische", "tokens": ["Und", "ei\u00b7nes", "Schlu\u00b7ckes", "aus", "dem", "Bunt\u00b7ge\u00b7mi\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hinabschlingt ganz, woran die Menschheit kaut.", "tokens": ["Hin\u00b7ab\u00b7schlingt", "ganz", ",", "wo\u00b7ran", "die", "Menschheit", "kaut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}}, "stanza.3": {"line.1": {"text": "In einer Stunde wirst du zum Gelehrten,", "tokens": ["In", "ei\u00b7ner", "Stun\u00b7de", "wirst", "du", "zum", "Ge\u00b7lehr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nur freilich in der andern wieder dumm,", "tokens": ["Nur", "frei\u00b7lich", "in", "der", "an\u00b7dern", "wie\u00b7der", "dumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Denn von der richtgen Ansicht zur verkehrten", "tokens": ["Denn", "von", "der", "richt\u00b7gen", "An\u00b7sicht", "zur", "ver\u00b7kehr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schwingt sich der Pendel immer wechselnd um.", "tokens": ["Schwingt", "sich", "der", "Pen\u00b7del", "im\u00b7mer", "wech\u00b7selnd", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}}, "stanza.4": {"line.1": {"text": "Du brauchst nicht mehr zu wissen noch zu denken,", "tokens": ["Du", "brauchst", "nicht", "mehr", "zu", "wis\u00b7sen", "noch", "zu", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Tagblatt denkt f\u00fcr dich nach deiner Wahl,", "tokens": ["Ein", "Tag\u00b7blatt", "denkt", "f\u00fcr", "dich", "nach", "dei\u00b7ner", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Weisheit statt zu kaufen, steht zu schenken,", "tokens": ["Die", "Weis\u00b7heit", "statt", "zu", "kau\u00b7fen", ",", "steht", "zu", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$,", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu kaufen brauchst du nichts als das Journal.", "tokens": ["Zu", "kau\u00b7fen", "brauchst", "du", "nichts", "als", "das", "Jour\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "PPER", "PIS", "KOKOM", "ART", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Nun erst die K\u00f6che dieser Sudelk\u00fcche,", "tokens": ["Nun", "erst", "die", "K\u00f6\u00b7che", "die\u00b7ser", "Su\u00b7del\u00b7k\u00fc\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der T\u00e4ter gibt der Tat erst ihren Fluch.", "tokens": ["Der", "T\u00e4\u00b7ter", "gibt", "der", "Tat", "erst", "ih\u00b7ren", "Fluch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Noch \u00e4rger als der Speisen Qualmger\u00fcche", "tokens": ["Noch", "\u00e4r\u00b7ger", "als", "der", "Spei\u00b7sen", "Qualm\u00b7ge\u00b7r\u00fc\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Steht der Verfertger selber im Geruch.", "tokens": ["Steht", "der", "Ver\u00b7fert\u00b7ger", "sel\u00b7ber", "im", "Ge\u00b7ruch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.6": {"line.1": {"text": "Schon in der Schule bildet sich die Rasse,", "tokens": ["Schon", "in", "der", "Schu\u00b7le", "bil\u00b7det", "sich", "die", "Ras\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es schreibt da, wer zu lernen nicht versteht,", "tokens": ["Es", "schreibt", "da", ",", "wer", "zu", "ler\u00b7nen", "nicht", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWS", "PTKZU", "VVINF", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bis endlich eine dritte Fortgangsklasse", "tokens": ["Bis", "end\u00b7lich", "ei\u00b7ne", "drit\u00b7te", "Fort\u00b7gangs\u00b7klas\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich als Beruf zeigt und als Musaget.", "tokens": ["Sich", "als", "Be\u00b7ruf", "zeigt", "und", "als", "Mu\u00b7sa\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KOUS", "NN", "VVFIN", "KON", "KOUS", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "...", "tokens": ["..."], "token_info": ["punct"], "pos": ["$("]}}, "stanza.7": {"line.1": {"text": "Der Henker hole die Journale,", "tokens": ["Der", "Hen\u00b7ker", "ho\u00b7le", "die", "Jour\u00b7na\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sind das Brandmal unsrer neuen Welt,", "tokens": ["Sie", "sind", "das", "Brand\u00b7mal", "uns\u00b7rer", "neu\u00b7en", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der ekle Abhub von dem Wissenmahle,", "tokens": ["Der", "ek\u00b7le", "Ab\u00b7hub", "von", "dem", "Wis\u00b7sen\u00b7mah\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der, f\u00fcr die Viehmast, in die Zuber f\u00e4llt.", "tokens": ["Der", ",", "f\u00fcr", "die", "Vieh\u00b7mast", ",", "in", "die", "Zu\u00b7ber", "f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Sie sind die breitgedeckten, offnen Tische,", "tokens": ["Sie", "sind", "die", "breit\u00b7ge\u00b7deck\u00b7ten", ",", "off\u00b7nen", "Ti\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo Tor und Weiser sich als Nachbar schaut,", "tokens": ["Wo", "Tor", "und", "Wei\u00b7ser", "sich", "als", "Nach\u00b7bar", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NN", "PRF", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und eines Schluckes aus dem Buntgemische", "tokens": ["Und", "ei\u00b7nes", "Schlu\u00b7ckes", "aus", "dem", "Bunt\u00b7ge\u00b7mi\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hinabschlingt ganz, woran die Menschheit kaut.", "tokens": ["Hin\u00b7ab\u00b7schlingt", "ganz", ",", "wo\u00b7ran", "die", "Menschheit", "kaut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}}, "stanza.9": {"line.1": {"text": "In einer Stunde wirst du zum Gelehrten,", "tokens": ["In", "ei\u00b7ner", "Stun\u00b7de", "wirst", "du", "zum", "Ge\u00b7lehr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nur freilich in der andern wieder dumm,", "tokens": ["Nur", "frei\u00b7lich", "in", "der", "an\u00b7dern", "wie\u00b7der", "dumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Denn von der richtgen Ansicht zur verkehrten", "tokens": ["Denn", "von", "der", "richt\u00b7gen", "An\u00b7sicht", "zur", "ver\u00b7kehr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schwingt sich der Pendel immer wechselnd um.", "tokens": ["Schwingt", "sich", "der", "Pen\u00b7del", "im\u00b7mer", "wech\u00b7selnd", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}}, "stanza.10": {"line.1": {"text": "Du brauchst nicht mehr zu wissen noch zu denken,", "tokens": ["Du", "brauchst", "nicht", "mehr", "zu", "wis\u00b7sen", "noch", "zu", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Tagblatt denkt f\u00fcr dich nach deiner Wahl,", "tokens": ["Ein", "Tag\u00b7blatt", "denkt", "f\u00fcr", "dich", "nach", "dei\u00b7ner", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Weisheit statt zu kaufen, steht zu schenken,", "tokens": ["Die", "Weis\u00b7heit", "statt", "zu", "kau\u00b7fen", ",", "steht", "zu", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$,", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu kaufen brauchst du nichts als das Journal.", "tokens": ["Zu", "kau\u00b7fen", "brauchst", "du", "nichts", "als", "das", "Jour\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "PPER", "PIS", "KOKOM", "ART", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Nun erst die K\u00f6che dieser Sudelk\u00fcche,", "tokens": ["Nun", "erst", "die", "K\u00f6\u00b7che", "die\u00b7ser", "Su\u00b7del\u00b7k\u00fc\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der T\u00e4ter gibt der Tat erst ihren Fluch.", "tokens": ["Der", "T\u00e4\u00b7ter", "gibt", "der", "Tat", "erst", "ih\u00b7ren", "Fluch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Noch \u00e4rger als der Speisen Qualmger\u00fcche", "tokens": ["Noch", "\u00e4r\u00b7ger", "als", "der", "Spei\u00b7sen", "Qualm\u00b7ge\u00b7r\u00fc\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Steht der Verfertger selber im Geruch.", "tokens": ["Steht", "der", "Ver\u00b7fert\u00b7ger", "sel\u00b7ber", "im", "Ge\u00b7ruch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.12": {"line.1": {"text": "Schon in der Schule bildet sich die Rasse,", "tokens": ["Schon", "in", "der", "Schu\u00b7le", "bil\u00b7det", "sich", "die", "Ras\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es schreibt da, wer zu lernen nicht versteht,", "tokens": ["Es", "schreibt", "da", ",", "wer", "zu", "ler\u00b7nen", "nicht", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWS", "PTKZU", "VVINF", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bis endlich eine dritte Fortgangsklasse", "tokens": ["Bis", "end\u00b7lich", "ei\u00b7ne", "drit\u00b7te", "Fort\u00b7gangs\u00b7klas\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich als Beruf zeigt und als Musaget.", "tokens": ["Sich", "als", "Be\u00b7ruf", "zeigt", "und", "als", "Mu\u00b7sa\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KOUS", "NN", "VVFIN", "KON", "KOUS", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "...", "tokens": ["..."], "token_info": ["punct"], "pos": ["$("]}}}}}