{"textgrid.poem.40361": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Fitzebutze", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lieber \u00df\u00f6ner Hampelmann,", "tokens": ["Lie\u00b7ber", "\u00df\u00f6\u00b7ner", "Ham\u00b7pel\u00b7mann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "deine Detta sieht dich an!", "tokens": ["dei\u00b7ne", "Det\u00b7ta", "sieht", "dich", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bin dho\u00df, und Du bist tlein;", "tokens": ["Ich", "bin", "dho\u00df", ",", "und", "Du", "bist", "tlein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "$,", "KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "willst du Fitzebutze sein?", "tokens": ["willst", "du", "Fit\u00b7ze\u00b7but\u00b7ze", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Tomm!", "tokens": ["Tomm", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.2": {"line.1": {"text": "Tomm auf Haterns dho\u00dfen Tuhl,", "tokens": ["Tomm", "auf", "Ha\u00b7terns", "dho\u00b7\u00dfen", "Tuhl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vitzliputze, Blitzepul!", "tokens": ["Vitz\u00b7li\u00b7put\u00b7ze", ",", "Blit\u00b7ze\u00b7pul", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hater sagt, man wei\u00df es nicht,", "tokens": ["Ha\u00b7ter", "sagt", ",", "man", "wei\u00df", "es", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wie man deinen Namen sp'icht.", "tokens": ["wie", "man", "dei\u00b7nen", "Na\u00b7men", "sp'\u00b7icht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Pst!", "tokens": ["Pst", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.3": {"line.1": {"text": "Pst, sagt Hater, Fitzebott", "tokens": ["Pst", ",", "sagt", "Ha\u00b7ter", ",", "Fit\u00b7ze\u00b7bott"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$,", "VVFIN", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "war eimal ein lieber Dott,", "tokens": ["war", "ei\u00b7mal", "ein", "lie\u00b7ber", "Dott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "der auf einem Tuhle sa\u00df", "tokens": ["der", "auf", "ei\u00b7nem", "Tuh\u00b7le", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und sebratne Men\u00dfen a\u00df.", "tokens": ["und", "seb\u00b7rat\u00b7ne", "Men\u00b7\u00dfen", "a\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Huh!", "tokens": ["Huh", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Huh, sei dut, ich bin so tlein", "tokens": ["Huh", ",", "sei", "dut", ",", "ich", "bin", "so", "tlein"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "VAFIN", "ADJD", "$,", "PPER", "VAFIN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und will immer a'tig sein.", "tokens": ["und", "will", "im\u00b7mer", "a'\u00b7tig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Fitzebutze, du bist dho\u00df;", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "du", "bist", "dho\u00df", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "tleine Detta spa\u00dft sa bo's.", "tokens": ["tlei\u00b7ne", "Det\u00b7ta", "spa\u00dft", "sa", "bo'", "s."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sa?", "tokens": ["Sa", "?"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-", "measure": "single.down"}}, "stanza.5": {"line.1": {"text": "Sa, ich bin dir wirktlich dut!", "tokens": ["Sa", ",", "ich", "bin", "dir", "wirkt\u00b7lich", "dut", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Willst du einen neuen Hut?", "tokens": ["Willst", "du", "ei\u00b7nen", "neu\u00b7en", "Hut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tlinglingling: wer b'ingt das Band?", "tokens": ["Tling\u00b7ling\u00b7ling", ":", "wer", "ing", "das", "Band", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6nigin aus Mohrenland!", "tokens": ["T\u00f6\u00b7ni\u00b7gin", "aus", "Moh\u00b7ren\u00b7land", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Tnicks!", "tokens": ["Tnicks", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Tnix, ich bin F'au T\u00f6nidin,", "tokens": ["Tnix", ",", "ich", "bin", "F'\u00b7au", "T\u00f6\u00b7ni\u00b7din", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "NE", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "hab zvei Lippen von Zutterrosin;", "tokens": ["hab", "zvei", "Lip\u00b7pen", "von", "Zut\u00b7ter\u00b7ro\u00b7sin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "APPR", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Fitzebutze, sieh mal an,", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "sieh", "mal", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ei, wie Detta tanzen tann!", "tokens": ["ei", ",", "wie", "Det\u00b7ta", "tan\u00b7zen", "tann", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "NE", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hopp\u00df!", "tokens": ["Hopp\u00df", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.7": {"line.1": {"text": "Hop\u00dfa, hop\u00dfa, hop\u00dfassa:", "tokens": ["Hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfas\u00b7sa", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "FM.la", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "T\u00f6nigin von Af'ika!", "tokens": ["T\u00f6\u00b7ni\u00b7gin", "von", "Af'\u00b7i\u00b7ka", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flitzeputzig, Butzebein,", "tokens": ["Flit\u00b7ze\u00b7put\u00b7zig", ",", "But\u00b7ze\u00b7bein", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wann soll unse Hochzeit sein?", "tokens": ["wann", "soll", "un\u00b7se", "Hoch\u00b7zeit", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du!", "tokens": ["Du", "!"], "token_info": ["word", "punct"], "pos": ["PPER", "$."], "meter": "-", "measure": "single.down"}}, "stanza.8": {"line.1": {"text": "Du! Mein tleiner lieber Dott!", "tokens": ["Du", "!", "Mein", "tlei\u00b7ner", "lie\u00b7ber", "Dott", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du?! sonst deh ich von dir fo't! \u2013", "tokens": ["Du", "?!", "sonst", "deh", "ich", "von", "dir", "fo't", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "$.", "ADV", "VVFIN", "PPER", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, du dummer Hampelmann,", "tokens": ["Ach", ",", "du", "dum\u00b7mer", "Ham\u00b7pel\u00b7mann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "siehst ja Detta garnicht an!", "tokens": ["siehst", "ja", "Det\u00b7ta", "gar\u00b7nicht", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NE", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Marsch! \u2013", "tokens": ["Marsch", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$.", "$("], "meter": "+", "measure": "single.up"}}, "stanza.9": {"line.1": {"text": "Lieber \u00df\u00f6ner Hampelmann,", "tokens": ["Lie\u00b7ber", "\u00df\u00f6\u00b7ner", "Ham\u00b7pel\u00b7mann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "deine Detta sieht dich an!", "tokens": ["dei\u00b7ne", "Det\u00b7ta", "sieht", "dich", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bin dho\u00df, und Du bist tlein;", "tokens": ["Ich", "bin", "dho\u00df", ",", "und", "Du", "bist", "tlein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "$,", "KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "willst du Fitzebutze sein?", "tokens": ["willst", "du", "Fit\u00b7ze\u00b7but\u00b7ze", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Tomm!", "tokens": ["Tomm", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.10": {"line.1": {"text": "Tomm auf Haterns dho\u00dfen Tuhl,", "tokens": ["Tomm", "auf", "Ha\u00b7terns", "dho\u00b7\u00dfen", "Tuhl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vitzliputze, Blitzepul!", "tokens": ["Vitz\u00b7li\u00b7put\u00b7ze", ",", "Blit\u00b7ze\u00b7pul", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hater sagt, man wei\u00df es nicht,", "tokens": ["Ha\u00b7ter", "sagt", ",", "man", "wei\u00df", "es", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wie man deinen Namen sp'icht.", "tokens": ["wie", "man", "dei\u00b7nen", "Na\u00b7men", "sp'\u00b7icht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Pst!", "tokens": ["Pst", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.11": {"line.1": {"text": "Pst, sagt Hater, Fitzebott", "tokens": ["Pst", ",", "sagt", "Ha\u00b7ter", ",", "Fit\u00b7ze\u00b7bott"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$,", "VVFIN", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "war eimal ein lieber Dott,", "tokens": ["war", "ei\u00b7mal", "ein", "lie\u00b7ber", "Dott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "der auf einem Tuhle sa\u00df", "tokens": ["der", "auf", "ei\u00b7nem", "Tuh\u00b7le", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und sebratne Men\u00dfen a\u00df.", "tokens": ["und", "seb\u00b7rat\u00b7ne", "Men\u00b7\u00dfen", "a\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Huh!", "tokens": ["Huh", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.12": {"line.1": {"text": "Huh, sei dut, ich bin so tlein", "tokens": ["Huh", ",", "sei", "dut", ",", "ich", "bin", "so", "tlein"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "VAFIN", "ADJD", "$,", "PPER", "VAFIN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und will immer a'tig sein.", "tokens": ["und", "will", "im\u00b7mer", "a'\u00b7tig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Fitzebutze, du bist dho\u00df;", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "du", "bist", "dho\u00df", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "tleine Detta spa\u00dft sa bo's.", "tokens": ["tlei\u00b7ne", "Det\u00b7ta", "spa\u00dft", "sa", "bo'", "s."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sa?", "tokens": ["Sa", "?"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-", "measure": "single.down"}}, "stanza.13": {"line.1": {"text": "Sa, ich bin dir wirktlich dut!", "tokens": ["Sa", ",", "ich", "bin", "dir", "wirkt\u00b7lich", "dut", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Willst du einen neuen Hut?", "tokens": ["Willst", "du", "ei\u00b7nen", "neu\u00b7en", "Hut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tlinglingling: wer b'ingt das Band?", "tokens": ["Tling\u00b7ling\u00b7ling", ":", "wer", "ing", "das", "Band", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6nigin aus Mohrenland!", "tokens": ["T\u00f6\u00b7ni\u00b7gin", "aus", "Moh\u00b7ren\u00b7land", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Tnicks!", "tokens": ["Tnicks", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.14": {"line.1": {"text": "Tnix, ich bin F'au T\u00f6nidin,", "tokens": ["Tnix", ",", "ich", "bin", "F'\u00b7au", "T\u00f6\u00b7ni\u00b7din", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "NE", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "hab zvei Lippen von Zutterrosin;", "tokens": ["hab", "zvei", "Lip\u00b7pen", "von", "Zut\u00b7ter\u00b7ro\u00b7sin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "APPR", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Fitzebutze, sieh mal an,", "tokens": ["Fit\u00b7ze\u00b7but\u00b7ze", ",", "sieh", "mal", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ei, wie Detta tanzen tann!", "tokens": ["ei", ",", "wie", "Det\u00b7ta", "tan\u00b7zen", "tann", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "NE", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hopp\u00df!", "tokens": ["Hopp\u00df", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}}, "stanza.15": {"line.1": {"text": "Hop\u00dfa, hop\u00dfa, hop\u00dfassa:", "tokens": ["Hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfa", ",", "hop\u00b7\u00dfas\u00b7sa", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$,", "FM.la", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "T\u00f6nigin von Af'ika!", "tokens": ["T\u00f6\u00b7ni\u00b7gin", "von", "Af'\u00b7i\u00b7ka", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flitzeputzig, Butzebein,", "tokens": ["Flit\u00b7ze\u00b7put\u00b7zig", ",", "But\u00b7ze\u00b7bein", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wann soll unse Hochzeit sein?", "tokens": ["wann", "soll", "un\u00b7se", "Hoch\u00b7zeit", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du!", "tokens": ["Du", "!"], "token_info": ["word", "punct"], "pos": ["PPER", "$."], "meter": "-", "measure": "single.down"}}, "stanza.16": {"line.1": {"text": "Du! Mein tleiner lieber Dott!", "tokens": ["Du", "!", "Mein", "tlei\u00b7ner", "lie\u00b7ber", "Dott", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du?! sonst deh ich von dir fo't! \u2013", "tokens": ["Du", "?!", "sonst", "deh", "ich", "von", "dir", "fo't", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "$.", "ADV", "VVFIN", "PPER", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, du dummer Hampelmann,", "tokens": ["Ach", ",", "du", "dum\u00b7mer", "Ham\u00b7pel\u00b7mann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "siehst ja Detta garnicht an!", "tokens": ["siehst", "ja", "Det\u00b7ta", "gar\u00b7nicht", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NE", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Marsch! \u2013", "tokens": ["Marsch", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$.", "$("], "meter": "+", "measure": "single.up"}}}}}