{"textgrid.poem.44168": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gedencke von mir, was du wilst;", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gedencke von mir, was du wilst;", "tokens": ["Ge\u00b7den\u00b7cke", "von", "mir", ",", "was", "du", "wilst", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sehr du mich verwegen schilst,", "tokens": ["So", "sehr", "du", "mich", "ver\u00b7we\u00b7gen", "schilst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wenig kan ich mich entbrechen,", "tokens": ["So", "we\u00b7nig", "kan", "ich", "mich", "ent\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jezt, da mein ungewi\u00dfer Fu\u00df", "tokens": ["Jezt", ",", "da", "mein", "un\u00b7ge\u00b7wi\u00b7\u00dfer", "Fu\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Abschied nehmen soll und mu\u00df,", "tokens": ["Den", "Ab\u00b7schied", "neh\u00b7men", "soll", "und", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit dir, galantes Weib, ein redlich Wort zu sprechen.", "tokens": ["Mit", "dir", ",", "ga\u00b7lan\u00b7tes", "Weib", ",", "ein", "red\u00b7lich", "Wort", "zu", "spre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich habe von Natur ein Herz,", "tokens": ["Ich", "ha\u00b7be", "von", "Na\u00b7tur", "ein", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sonder Eigenlob und Scherz", "tokens": ["Das", "son\u00b7der", "Ei\u00b7gen\u00b7lob", "und", "Scherz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Warheit mehr als Reichthum sch\u00e4zet,", "tokens": ["Die", "War\u00b7heit", "mehr", "als", "Reicht\u00b7hum", "sch\u00e4\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Herz, das Gott und Wei\u00dfheit liebt,", "tokens": ["Ein", "Herz", ",", "das", "Gott", "und", "Wei\u00df\u00b7heit", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Wi\u00dfen keinen Mensch betr\u00fcbt", "tokens": ["Mit", "Wi\u00b7\u00dfen", "kei\u00b7nen", "Mensch", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und das sich \u00fcberall an Redligkeit erg\u00f6zet.", "tokens": ["Und", "das", "sich", "\u00fc\u00b7be\u00b7rall", "an", "Red\u00b7lig\u00b7keit", "er\u00b7g\u00f6\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PRF", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dies Herze bleibt nun dir geweiht,", "tokens": ["Dies", "Her\u00b7ze", "bleibt", "nun", "dir", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob gleich Verh\u00e4ngn\u00fc\u00df, Gl\u00fcck und Zeit", "tokens": ["Ob", "gleich", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", ",", "Gl\u00fcck", "und", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dich an ein ander Herz gebunden.", "tokens": ["Dich", "an", "ein", "an\u00b7der", "Herz", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verfluche mein Bek\u00e4ntn\u00fc\u00df nicht;", "tokens": ["Ver\u00b7flu\u00b7che", "mein", "Be\u00b7k\u00e4nt\u00b7n\u00fc\u00df", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich habe noch kein Angesicht", "tokens": ["Ich", "ha\u00b7be", "noch", "kein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und nichts so sch\u00f6n vor mich als deinen Werth gefunden.", "tokens": ["Und", "nichts", "so", "sch\u00f6n", "vor", "mich", "als", "dei\u00b7nen", "Werth", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "ADJD", "APPR", "PPER", "KOUS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Mein Vers verlezt kein keusches Ohr;", "tokens": ["Mein", "Vers", "ver\u00b7lezt", "kein", "keu\u00b7sches", "Ohr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Inde\u00dfen kan denn ich davor,", "tokens": ["In\u00b7de\u00b7\u00dfen", "kan", "denn", "ich", "da\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "KON", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dir, was ich f\u00fchle, frey zu sagen,", "tokens": ["Dir", ",", "was", "ich", "f\u00fch\u00b7le", ",", "frey", "zu", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWS", "PPER", "VVFIN", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df nehmlich, da ich bey dir sa\u00df,", "tokens": ["Da\u00df", "nehm\u00b7lich", ",", "da", "ich", "bey", "dir", "sa\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dein reizend Ein ich weis nicht was", "tokens": ["Dein", "rei\u00b7zend", "Ein", "ich", "weis", "nicht", "was"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "VVPP", "ART", "PPER", "PTKVZ", "PTKNEG", "PWS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit seiner Artigkeit mein Herze wund geschlagen?", "tokens": ["Mit", "sei\u00b7ner", "Ar\u00b7tig\u00b7keit", "mein", "Her\u00b7ze", "wund", "ge\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "VVFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Dies schw\u00f6r ich bey der Augen Macht,", "tokens": ["Dies", "schw\u00f6r", "ich", "bey", "der", "Au\u00b7gen", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wodurch dein Geist gefehrlich lacht,", "tokens": ["Wo\u00b7durch", "dein", "Geist", "ge\u00b7fehr\u00b7lich", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df, wenn ich mich vermehlen wollte,", "tokens": ["Da\u00df", ",", "wenn", "ich", "mich", "ver\u00b7meh\u00b7len", "woll\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df, sag ich, k\u00f6nt es nur geschehn,", "tokens": ["Da\u00df", ",", "sag", "ich", ",", "k\u00f6nt", "es", "nur", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Herz und Mund und hei\u00dfes Flehn", "tokens": ["Mein", "Herz", "und", "Mund", "und", "hei\u00b7\u00dfes", "Flehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein ander Weib als dich vom Himmel bitten sollte.", "tokens": ["Kein", "an\u00b7der", "Weib", "als", "dich", "vom", "Him\u00b7mel", "bit\u00b7ten", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KOUS", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "O was vor Eintracht, Scherz und Lust", "tokens": ["O", "was", "vor", "Ein\u00b7tracht", ",", "Scherz", "und", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "PWS", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verspr\u00e4ch ich mir an deiner Brust,", "tokens": ["Ver\u00b7spr\u00e4ch", "ich", "mir", "an", "dei\u00b7ner", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Tempel unverf\u00e4lschter Liebe!", "tokens": ["Dem", "Tem\u00b7pel", "un\u00b7ver\u00b7f\u00e4lschter", "Lie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wie z\u00e4rtlich wollt ich mit dir thun,", "tokens": ["Wie", "z\u00e4rt\u00b7lich", "wollt", "ich", "mit", "dir", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie sanfte d\u00e4cht ich nicht zu ruhn,", "tokens": ["Wie", "sanf\u00b7te", "d\u00e4cht", "ich", "nicht", "zu", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn dein Besiz der Lohn von meinem Flei\u00dfe bliebe!", "tokens": ["Wenn", "dein", "Be\u00b7siz", "der", "Lohn", "von", "mei\u00b7nem", "Flei\u00b7\u00dfe", "blie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ich such und finde dich in mir,", "tokens": ["Ich", "such", "und", "fin\u00b7de", "dich", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich seh und finde mich in dir,", "tokens": ["Ich", "seh", "und", "fin\u00b7de", "mich", "in", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir haben einerley Gem\u00fcthe;", "tokens": ["Wir", "ha\u00b7ben", "ei\u00b7ner\u00b7ley", "Ge\u00b7m\u00fc\u00b7the", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Paar von solcher \u00c4hnligkeit", "tokens": ["Ein", "Paar", "von", "sol\u00b7cher", "\u00c4hn\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist wohl von gr\u00f6\u00dfrer Seltenheit", "tokens": ["Ist", "wohl", "von", "gr\u00f6\u00df\u00b7rer", "Sel\u00b7ten\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als Freunde wahrer Treu und schwarze Pfirschkenbl\u00fcthe.", "tokens": ["Als", "Freun\u00b7de", "wah\u00b7rer", "Treu", "und", "schwar\u00b7ze", "Pfirschken\u00b7bl\u00fct\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Die Fruchtbarkeit von deiner Schoos", "tokens": ["Die", "Frucht\u00b7bar\u00b7keit", "von", "dei\u00b7ner", "Schoos"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist warlich nicht so reich und gro\u00df", "tokens": ["Ist", "war\u00b7lich", "nicht", "so", "reich", "und", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als deiner Mienen Geist und St\u00e4rcke.", "tokens": ["Als", "dei\u00b7ner", "Mie\u00b7nen", "Geist", "und", "St\u00e4r\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch keine Stunde geht dahin,", "tokens": ["Auch", "kei\u00b7ne", "Stun\u00b7de", "geht", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In der ich, wenn ich bey dir bin,", "tokens": ["In", "der", "ich", ",", "wenn", "ich", "bey", "dir", "bin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "$,", "KOUS", "PPER", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An dir kein neues Bild der h\u00f6chsten Tugend mercke.", "tokens": ["An", "dir", "kein", "neu\u00b7es", "Bild", "der", "h\u00f6chs\u00b7ten", "Tu\u00b7gend", "mer\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Mit Schmeicheleyen red ich nicht,", "tokens": ["Mit", "Schmei\u00b7che\u00b7le\u00b7yen", "red", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil dieses selbst die Warheit spricht:", "tokens": ["Weil", "die\u00b7ses", "selbst", "die", "War\u00b7heit", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist so artig als bescheiden", "tokens": ["Du", "bist", "so", "ar\u00b7tig", "als", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KOKOM", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und kanst den wohlverdienten Ruhm", "tokens": ["Und", "kanst", "den", "wohl\u00b7ver\u00b7dien\u00b7ten", "Ruhm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "(dies ist der Warheit Eigenthum)", "tokens": ["(", "dies", "ist", "der", "War\u00b7heit", "Ei\u00b7gen\u00b7thum", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So wenig als mein Vers das Lob des P\u00f6bels leiden.", "tokens": ["So", "we\u00b7nig", "als", "mein", "Vers", "das", "Lob", "des", "P\u00f6\u00b7bels", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die Selbstverleugnung hilft dich nichts;", "tokens": ["Die", "Selbst\u00b7ver\u00b7leug\u00b7nung", "hilft", "dich", "nichts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sch\u00f6nheit hat die Art des Lichts", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "hat", "die", "Art", "des", "Lichts"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und l\u00e4st sich nimmermehr verstecken;", "tokens": ["Und", "l\u00e4st", "sich", "nim\u00b7mer\u00b7mehr", "ver\u00b7ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Je mehr sich dein Verdienst verh\u00fcllt,", "tokens": ["Je", "mehr", "sich", "dein", "Ver\u00b7dienst", "ver\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Je be\u00dfer wird sich auch ihr Bild", "tokens": ["Je", "be\u00b7\u00dfer", "wird", "sich", "auch", "ihr", "Bild"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PRF", "ADV", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "So wie bey voller Nacht der Mondenschein entdecken.", "tokens": ["So", "wie", "bey", "vol\u00b7ler", "Nacht", "der", "Mon\u00b7den\u00b7schein", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du brauchst auch weder Puz noch Kleid,", "tokens": ["Du", "brauchst", "auch", "we\u00b7der", "Puz", "noch", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Viel minder die Beredsamkeit,", "tokens": ["Viel", "min\u00b7der", "die", "Be\u00b7red\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bey aller Welt beliebt zu werden.", "tokens": ["Bey", "al\u00b7ler", "Welt", "be\u00b7liebt", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein obenhin bewegtes Glied", "tokens": ["Ein", "o\u00b7ben\u00b7hin", "be\u00b7weg\u00b7tes", "Glied"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Erg\u00f6zt, entz\u00fcndet, reizt und zieht", "tokens": ["Er\u00b7g\u00f6zt", ",", "ent\u00b7z\u00fcn\u00b7det", ",", "reizt", "und", "zieht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVPP", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Viel Sehnsucht aus der Brust und f\u00e4ngt uns mit Gebehrden.", "tokens": ["Viel", "Sehn\u00b7sucht", "aus", "der", "Brust", "und", "f\u00e4ngt", "uns", "mit", "Ge\u00b7behr\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Die Nachwelt soll nach langer Zeit", "tokens": ["Die", "Nach\u00b7welt", "soll", "nach", "lan\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch meiner Lieder Ewigkeit", "tokens": ["Durch", "mei\u00b7ner", "Lie\u00b7der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch deines Nahmens Denckmahl lesen", "tokens": ["Auch", "dei\u00b7nes", "Nah\u00b7mens", "Denck\u00b7mahl", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und \u00fcber das Verh\u00e4ngn\u00fc\u00df schreyn", "tokens": ["Und", "\u00fc\u00b7ber", "das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "schreyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und mir zu Liebe zornig seyn,", "tokens": ["Und", "mir", "zu", "Lie\u00b7be", "zor\u00b7nig", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df du, galantes Kind, mir nicht bescheert gewesen.", "tokens": ["Da\u00df", "du", ",", "ga\u00b7lan\u00b7tes", "Kind", ",", "mir", "nicht", "be\u00b7scheert", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADJA", "NN", "$,", "PPER", "PTKNEG", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ich dencke, weil ich leb, an dich;", "tokens": ["Ich", "den\u00b7cke", ",", "weil", "ich", "leb", ",", "an", "dich", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gehab dich wohl, gedenck an mich,", "tokens": ["Ge\u00b7hab", "dich", "wohl", ",", "ge\u00b7denck", "an", "mich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "VVIMP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es geh dir ewig nach Vergn\u00fcgen.", "tokens": ["Es", "geh", "dir", "e\u00b7wig", "nach", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Viel St\u00fcrme melden sich schon an,", "tokens": ["Viel", "St\u00fcr\u00b7me", "mel\u00b7den", "sich", "schon", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nachdem ich dich nicht k\u00fc\u00dfen kan;", "tokens": ["Nach\u00b7dem", "ich", "dich", "nicht", "k\u00fc\u00b7\u00dfen", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum las mir dann und wann ein Blat zu H\u00fclfe fliegen.", "tokens": ["Drum", "las", "mir", "dann", "und", "wann", "ein", "Blat", "zu", "H\u00fcl\u00b7fe", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "KON", "PWAV", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Gedencke von mir, was du wilst;", "tokens": ["Ge\u00b7den\u00b7cke", "von", "mir", ",", "was", "du", "wilst", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sehr du mich verwegen schilst,", "tokens": ["So", "sehr", "du", "mich", "ver\u00b7we\u00b7gen", "schilst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wenig kan ich mich entbrechen,", "tokens": ["So", "we\u00b7nig", "kan", "ich", "mich", "ent\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jezt, da mein ungewi\u00dfer Fu\u00df", "tokens": ["Jezt", ",", "da", "mein", "un\u00b7ge\u00b7wi\u00b7\u00dfer", "Fu\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Abschied nehmen soll und mu\u00df,", "tokens": ["Den", "Ab\u00b7schied", "neh\u00b7men", "soll", "und", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit dir, galantes Weib, ein redlich Wort zu sprechen.", "tokens": ["Mit", "dir", ",", "ga\u00b7lan\u00b7tes", "Weib", ",", "ein", "red\u00b7lich", "Wort", "zu", "spre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ich habe von Natur ein Herz,", "tokens": ["Ich", "ha\u00b7be", "von", "Na\u00b7tur", "ein", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sonder Eigenlob und Scherz", "tokens": ["Das", "son\u00b7der", "Ei\u00b7gen\u00b7lob", "und", "Scherz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Warheit mehr als Reichthum sch\u00e4zet,", "tokens": ["Die", "War\u00b7heit", "mehr", "als", "Reicht\u00b7hum", "sch\u00e4\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Herz, das Gott und Wei\u00dfheit liebt,", "tokens": ["Ein", "Herz", ",", "das", "Gott", "und", "Wei\u00df\u00b7heit", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Wi\u00dfen keinen Mensch betr\u00fcbt", "tokens": ["Mit", "Wi\u00b7\u00dfen", "kei\u00b7nen", "Mensch", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und das sich \u00fcberall an Redligkeit erg\u00f6zet.", "tokens": ["Und", "das", "sich", "\u00fc\u00b7be\u00b7rall", "an", "Red\u00b7lig\u00b7keit", "er\u00b7g\u00f6\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PRF", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Dies Herze bleibt nun dir geweiht,", "tokens": ["Dies", "Her\u00b7ze", "bleibt", "nun", "dir", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob gleich Verh\u00e4ngn\u00fc\u00df, Gl\u00fcck und Zeit", "tokens": ["Ob", "gleich", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", ",", "Gl\u00fcck", "und", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dich an ein ander Herz gebunden.", "tokens": ["Dich", "an", "ein", "an\u00b7der", "Herz", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verfluche mein Bek\u00e4ntn\u00fc\u00df nicht;", "tokens": ["Ver\u00b7flu\u00b7che", "mein", "Be\u00b7k\u00e4nt\u00b7n\u00fc\u00df", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich habe noch kein Angesicht", "tokens": ["Ich", "ha\u00b7be", "noch", "kein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und nichts so sch\u00f6n vor mich als deinen Werth gefunden.", "tokens": ["Und", "nichts", "so", "sch\u00f6n", "vor", "mich", "als", "dei\u00b7nen", "Werth", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "ADJD", "APPR", "PPER", "KOUS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Mein Vers verlezt kein keusches Ohr;", "tokens": ["Mein", "Vers", "ver\u00b7lezt", "kein", "keu\u00b7sches", "Ohr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Inde\u00dfen kan denn ich davor,", "tokens": ["In\u00b7de\u00b7\u00dfen", "kan", "denn", "ich", "da\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "KON", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dir, was ich f\u00fchle, frey zu sagen,", "tokens": ["Dir", ",", "was", "ich", "f\u00fch\u00b7le", ",", "frey", "zu", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWS", "PPER", "VVFIN", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df nehmlich, da ich bey dir sa\u00df,", "tokens": ["Da\u00df", "nehm\u00b7lich", ",", "da", "ich", "bey", "dir", "sa\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dein reizend Ein ich weis nicht was", "tokens": ["Dein", "rei\u00b7zend", "Ein", "ich", "weis", "nicht", "was"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "VVPP", "ART", "PPER", "PTKVZ", "PTKNEG", "PWS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit seiner Artigkeit mein Herze wund geschlagen?", "tokens": ["Mit", "sei\u00b7ner", "Ar\u00b7tig\u00b7keit", "mein", "Her\u00b7ze", "wund", "ge\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "VVFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Dies schw\u00f6r ich bey der Augen Macht,", "tokens": ["Dies", "schw\u00f6r", "ich", "bey", "der", "Au\u00b7gen", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wodurch dein Geist gefehrlich lacht,", "tokens": ["Wo\u00b7durch", "dein", "Geist", "ge\u00b7fehr\u00b7lich", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df, wenn ich mich vermehlen wollte,", "tokens": ["Da\u00df", ",", "wenn", "ich", "mich", "ver\u00b7meh\u00b7len", "woll\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df, sag ich, k\u00f6nt es nur geschehn,", "tokens": ["Da\u00df", ",", "sag", "ich", ",", "k\u00f6nt", "es", "nur", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Herz und Mund und hei\u00dfes Flehn", "tokens": ["Mein", "Herz", "und", "Mund", "und", "hei\u00b7\u00dfes", "Flehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein ander Weib als dich vom Himmel bitten sollte.", "tokens": ["Kein", "an\u00b7der", "Weib", "als", "dich", "vom", "Him\u00b7mel", "bit\u00b7ten", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KOUS", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "O was vor Eintracht, Scherz und Lust", "tokens": ["O", "was", "vor", "Ein\u00b7tracht", ",", "Scherz", "und", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "PWS", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verspr\u00e4ch ich mir an deiner Brust,", "tokens": ["Ver\u00b7spr\u00e4ch", "ich", "mir", "an", "dei\u00b7ner", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Tempel unverf\u00e4lschter Liebe!", "tokens": ["Dem", "Tem\u00b7pel", "un\u00b7ver\u00b7f\u00e4lschter", "Lie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wie z\u00e4rtlich wollt ich mit dir thun,", "tokens": ["Wie", "z\u00e4rt\u00b7lich", "wollt", "ich", "mit", "dir", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie sanfte d\u00e4cht ich nicht zu ruhn,", "tokens": ["Wie", "sanf\u00b7te", "d\u00e4cht", "ich", "nicht", "zu", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn dein Besiz der Lohn von meinem Flei\u00dfe bliebe!", "tokens": ["Wenn", "dein", "Be\u00b7siz", "der", "Lohn", "von", "mei\u00b7nem", "Flei\u00b7\u00dfe", "blie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Ich such und finde dich in mir,", "tokens": ["Ich", "such", "und", "fin\u00b7de", "dich", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich seh und finde mich in dir,", "tokens": ["Ich", "seh", "und", "fin\u00b7de", "mich", "in", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir haben einerley Gem\u00fcthe;", "tokens": ["Wir", "ha\u00b7ben", "ei\u00b7ner\u00b7ley", "Ge\u00b7m\u00fc\u00b7the", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Paar von solcher \u00c4hnligkeit", "tokens": ["Ein", "Paar", "von", "sol\u00b7cher", "\u00c4hn\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist wohl von gr\u00f6\u00dfrer Seltenheit", "tokens": ["Ist", "wohl", "von", "gr\u00f6\u00df\u00b7rer", "Sel\u00b7ten\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als Freunde wahrer Treu und schwarze Pfirschkenbl\u00fcthe.", "tokens": ["Als", "Freun\u00b7de", "wah\u00b7rer", "Treu", "und", "schwar\u00b7ze", "Pfirschken\u00b7bl\u00fct\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.20": {"line.1": {"text": "Die Fruchtbarkeit von deiner Schoos", "tokens": ["Die", "Frucht\u00b7bar\u00b7keit", "von", "dei\u00b7ner", "Schoos"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist warlich nicht so reich und gro\u00df", "tokens": ["Ist", "war\u00b7lich", "nicht", "so", "reich", "und", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als deiner Mienen Geist und St\u00e4rcke.", "tokens": ["Als", "dei\u00b7ner", "Mie\u00b7nen", "Geist", "und", "St\u00e4r\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch keine Stunde geht dahin,", "tokens": ["Auch", "kei\u00b7ne", "Stun\u00b7de", "geht", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In der ich, wenn ich bey dir bin,", "tokens": ["In", "der", "ich", ",", "wenn", "ich", "bey", "dir", "bin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "$,", "KOUS", "PPER", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An dir kein neues Bild der h\u00f6chsten Tugend mercke.", "tokens": ["An", "dir", "kein", "neu\u00b7es", "Bild", "der", "h\u00f6chs\u00b7ten", "Tu\u00b7gend", "mer\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Mit Schmeicheleyen red ich nicht,", "tokens": ["Mit", "Schmei\u00b7che\u00b7le\u00b7yen", "red", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil dieses selbst die Warheit spricht:", "tokens": ["Weil", "die\u00b7ses", "selbst", "die", "War\u00b7heit", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist so artig als bescheiden", "tokens": ["Du", "bist", "so", "ar\u00b7tig", "als", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KOKOM", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und kanst den wohlverdienten Ruhm", "tokens": ["Und", "kanst", "den", "wohl\u00b7ver\u00b7dien\u00b7ten", "Ruhm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "(dies ist der Warheit Eigenthum)", "tokens": ["(", "dies", "ist", "der", "War\u00b7heit", "Ei\u00b7gen\u00b7thum", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So wenig als mein Vers das Lob des P\u00f6bels leiden.", "tokens": ["So", "we\u00b7nig", "als", "mein", "Vers", "das", "Lob", "des", "P\u00f6\u00b7bels", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Die Selbstverleugnung hilft dich nichts;", "tokens": ["Die", "Selbst\u00b7ver\u00b7leug\u00b7nung", "hilft", "dich", "nichts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sch\u00f6nheit hat die Art des Lichts", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "hat", "die", "Art", "des", "Lichts"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und l\u00e4st sich nimmermehr verstecken;", "tokens": ["Und", "l\u00e4st", "sich", "nim\u00b7mer\u00b7mehr", "ver\u00b7ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Je mehr sich dein Verdienst verh\u00fcllt,", "tokens": ["Je", "mehr", "sich", "dein", "Ver\u00b7dienst", "ver\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Je be\u00dfer wird sich auch ihr Bild", "tokens": ["Je", "be\u00b7\u00dfer", "wird", "sich", "auch", "ihr", "Bild"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PRF", "ADV", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "So wie bey voller Nacht der Mondenschein entdecken.", "tokens": ["So", "wie", "bey", "vol\u00b7ler", "Nacht", "der", "Mon\u00b7den\u00b7schein", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du brauchst auch weder Puz noch Kleid,", "tokens": ["Du", "brauchst", "auch", "we\u00b7der", "Puz", "noch", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Viel minder die Beredsamkeit,", "tokens": ["Viel", "min\u00b7der", "die", "Be\u00b7red\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bey aller Welt beliebt zu werden.", "tokens": ["Bey", "al\u00b7ler", "Welt", "be\u00b7liebt", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein obenhin bewegtes Glied", "tokens": ["Ein", "o\u00b7ben\u00b7hin", "be\u00b7weg\u00b7tes", "Glied"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Erg\u00f6zt, entz\u00fcndet, reizt und zieht", "tokens": ["Er\u00b7g\u00f6zt", ",", "ent\u00b7z\u00fcn\u00b7det", ",", "reizt", "und", "zieht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVPP", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Viel Sehnsucht aus der Brust und f\u00e4ngt uns mit Gebehrden.", "tokens": ["Viel", "Sehn\u00b7sucht", "aus", "der", "Brust", "und", "f\u00e4ngt", "uns", "mit", "Ge\u00b7behr\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Die Nachwelt soll nach langer Zeit", "tokens": ["Die", "Nach\u00b7welt", "soll", "nach", "lan\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch meiner Lieder Ewigkeit", "tokens": ["Durch", "mei\u00b7ner", "Lie\u00b7der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch deines Nahmens Denckmahl lesen", "tokens": ["Auch", "dei\u00b7nes", "Nah\u00b7mens", "Denck\u00b7mahl", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und \u00fcber das Verh\u00e4ngn\u00fc\u00df schreyn", "tokens": ["Und", "\u00fc\u00b7ber", "das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "schreyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und mir zu Liebe zornig seyn,", "tokens": ["Und", "mir", "zu", "Lie\u00b7be", "zor\u00b7nig", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df du, galantes Kind, mir nicht bescheert gewesen.", "tokens": ["Da\u00df", "du", ",", "ga\u00b7lan\u00b7tes", "Kind", ",", "mir", "nicht", "be\u00b7scheert", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADJA", "NN", "$,", "PPER", "PTKNEG", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Ich dencke, weil ich leb, an dich;", "tokens": ["Ich", "den\u00b7cke", ",", "weil", "ich", "leb", ",", "an", "dich", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gehab dich wohl, gedenck an mich,", "tokens": ["Ge\u00b7hab", "dich", "wohl", ",", "ge\u00b7denck", "an", "mich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "VVIMP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es geh dir ewig nach Vergn\u00fcgen.", "tokens": ["Es", "geh", "dir", "e\u00b7wig", "nach", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Viel St\u00fcrme melden sich schon an,", "tokens": ["Viel", "St\u00fcr\u00b7me", "mel\u00b7den", "sich", "schon", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nachdem ich dich nicht k\u00fc\u00dfen kan;", "tokens": ["Nach\u00b7dem", "ich", "dich", "nicht", "k\u00fc\u00b7\u00dfen", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum las mir dann und wann ein Blat zu H\u00fclfe fliegen.", "tokens": ["Drum", "las", "mir", "dann", "und", "wann", "ein", "Blat", "zu", "H\u00fcl\u00b7fe", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "KON", "PWAV", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}