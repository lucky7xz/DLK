{"dta.poem.8497": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Der Abschied .", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1860", "urn": "urn:nbn:de:kobv:b4-200905191007", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Das Abendroth war schon zerflossen,", "tokens": ["Das", "A\u00b7ben\u00b7droth", "war", "schon", "zer\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir standen an des Weihers Rand,", "tokens": ["Wir", "stan\u00b7den", "an", "des", "Wei\u00b7hers", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ich hielt ihre Hand geschlossen", "tokens": ["Und", "ich", "hielt", "ih\u00b7re", "Hand", "ge\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So fest in meiner kalten Hand:", "tokens": ["So", "fest", "in", "mei\u00b7ner", "kal\u00b7ten", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So m\u00fcssen wir denn morgen scheiden,", "tokens": ["So", "m\u00fcs\u00b7sen", "wir", "denn", "mor\u00b7gen", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das Schicksal w\u00fcrfelt mit uns beiden,", "tokens": ["Das", "Schick\u00b7sal", "w\u00fcr\u00b7felt", "mit", "uns", "bei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PIAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wir sind wie herrenloses Land.", "tokens": ["Wir", "sind", "wie", "her\u00b7ren\u00b7lo\u00b7ses", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Von keines Hauses Pflicht gebunden,", "tokens": ["Von", "kei\u00b7nes", "Hau\u00b7ses", "Pflicht", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Meint Jeder nur, wir seien grad", "tokens": ["Meint", "Je\u00b7der", "nur", ",", "wir", "sei\u00b7en", "grad"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "$,", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr sein Bed\u00fcrfni\u00df nur erfunden,", "tokens": ["F\u00fcr", "sein", "Be\u00b7d\u00fcrf\u00b7ni\u00df", "nur", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In Noth das h\u00fclfbereite Rad.", "tokens": ["In", "Noth", "das", "h\u00fclf\u00b7be\u00b7rei\u00b7te", "Rad", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was hilft es uns, da\u00df frei wir stehen,", "tokens": ["Was", "hilft", "es", "uns", ",", "da\u00df", "frei", "wir", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$,", "KOUS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Auf keines Menschen H\u00e4nde sehen,", "tokens": ["Auf", "kei\u00b7nes", "Men\u00b7schen", "H\u00e4n\u00b7de", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man zeichnet t\u00e4glich uns den Pfad.", "tokens": ["Man", "zeich\u00b7net", "t\u00e4g\u00b7lich", "uns", "den", "Pfad", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wo dicht die B\u00e4ume sich verzweigen,", "tokens": ["Wo", "dicht", "die", "B\u00e4u\u00b7me", "sich", "ver\u00b7zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da z\u00f6gert nicht des Wandrers Stab,", "tokens": ["Da", "z\u00f6\u00b7gert", "nicht", "des", "Wand\u00b7rers", "Stab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo tausend Nachbar\u00e4ste neigen", "tokens": ["Wo", "tau\u00b7send", "Nach\u00b7ba\u00b7r\u00e4s\u00b7te", "nei\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich sch\u00fctzend um den Stamm herab;", "tokens": ["Sich", "sch\u00fct\u00b7zend", "um", "den", "Stamm", "her\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch dr\u00fcben sieh die einzle Linde,", "tokens": ["Doch", "dr\u00fc\u00b7ben", "sieh", "die", "einz\u00b7le", "Lin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Jeder schreibt in ihre Rinde,", "tokens": ["Ein", "Je\u00b7der", "schreibt", "in", "ih\u00b7re", "Rin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und Jeder bricht ein Zweiglein ab.", "tokens": ["Und", "Je\u00b7der", "bricht", "ein", "Zwei\u00b7glein", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "O h\u00e4tten wir nur Muth zu walten", "tokens": ["O", "h\u00e4t\u00b7ten", "wir", "nur", "Muth", "zu", "wal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "ADV", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Gaben, die das Gl\u00fcck bescheert!", "tokens": ["Der", "Ga\u00b7ben", ",", "die", "das", "Gl\u00fcck", "be\u00b7scheert", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer darf uns st\u00f6ren, darf uns halten,", "tokens": ["Wer", "darf", "uns", "st\u00f6\u00b7ren", ",", "darf", "uns", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$,", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wehren uns den eignen Heerd? \u2014", "tokens": ["Und", "weh\u00b7ren", "uns", "den", "eig\u00b7nen", "Heerd", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir leiden nach dem alten Rechte,", "tokens": ["Wir", "lei\u00b7den", "nach", "dem", "al\u00b7ten", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df, der sich selber macht zum Knechte,", "tokens": ["Da\u00df", ",", "der", "sich", "sel\u00b7ber", "macht", "zum", "Knech\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PRF", "ADV", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ist nicht der goldnen Freiheit werth.", "tokens": ["Ist", "nicht", "der", "gold\u00b7nen", "Frei\u00b7heit", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Zieh\u2019 hin, wie du berufen worden,", "tokens": ["Zieh'", "hin", ",", "wie", "du", "be\u00b7ru\u00b7fen", "wor\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PWAV", "PPER", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In der Campagna Glut und Schwei\u00df,", "tokens": ["In", "der", "Cam\u00b7pag\u00b7na", "Glut", "und", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ich will steh\u2019n in meinem Norden,", "tokens": ["Und", "ich", "will", "steh'n", "in", "mei\u00b7nem", "Nor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu siechen unter Schnee und Eis.", "tokens": ["Zu", "sie\u00b7chen", "un\u00b7ter", "Schnee", "und", "Eis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht w\u00fcrdig sind wir bessrer Tage,", "tokens": ["Nicht", "w\u00fcr\u00b7dig", "sind", "wir", "bess\u00b7rer", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und da\u00df nur Keins dem Andern klage,", "tokens": ["Und", "da\u00df", "nur", "Keins", "dem", "An\u00b7dern", "kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Schweige, wer nicht zu k\u00e4mpfen wei\u00df.", "tokens": ["Schwei\u00b7ge", ",", "wer", "nicht", "zu", "k\u00e4mp\u00b7fen", "wei\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "So ward an Weihers Rand gesprochen,", "tokens": ["So", "ward", "an", "Wei\u00b7hers", "Rand", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Zorne halb und halb in Pein;", "tokens": ["Im", "Zor\u00b7ne", "halb", "und", "halb", "in", "Pein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "KON", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir h\u00e4tten gern den Stab gebrochen", "tokens": ["Wir", "h\u00e4t\u00b7ten", "gern", "den", "Stab", "ge\u00b7bro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ob all den kleinen Tyrannei\u2019n.", "tokens": ["Ob", "all", "den", "klei\u00b7nen", "Ty\u00b7ran\u00b7nei'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PIAT", "ART", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und als die Regenwolken stiegen,", "tokens": ["Und", "als", "die", "Re\u00b7gen\u00b7wol\u00b7ken", "stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da sprachen erst wir mit Vergn\u00fcgen", "tokens": ["Da", "spra\u00b7chen", "erst", "wir", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Uns in den Aerger recht hinein.", "tokens": ["Uns", "in", "den", "A\u00b7er\u00b7ger", "recht", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "So lang die Tropfen einzeln fielen,", "tokens": ["So", "lang", "die", "Trop\u00b7fen", "ein\u00b7zeln", "fie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War\u2019s Stoff ja nur f\u00fcr unsern Trutz,", "tokens": ["Wa\u00b7r's", "Stoff", "ja", "nur", "f\u00fcr", "un\u00b7sern", "Trutz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "So recht als von des Schicksals Spielen", "tokens": ["So", "recht", "als", "von", "des", "Schick\u00b7sals", "Spie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zum Schaden uns und keinem Nutz.", "tokens": ["Zum", "Scha\u00b7den", "uns", "und", "kei\u00b7nem", "Nutz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch als der Himmel Schlo\u00dfen streute,", "tokens": ["Doch", "als", "der", "Him\u00b7mel", "Schlo\u00b7\u00dfen", "streu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da machten wir\u2019s wie andre Leute", "tokens": ["Da", "mach\u00b7ten", "wir's", "wie", "and\u00b7re", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und suchten auf der Linde Schutz.", "tokens": ["Und", "such\u00b7ten", "auf", "der", "Lin\u00b7de", "Schutz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Hier stand ein H\u00e4uflein dicht beisammen,", "tokens": ["Hier", "stand", "ein", "H\u00e4uf\u00b7lein", "dicht", "bei\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich schauernd unter\u2019m Bl\u00e4tterdach;", "tokens": ["Sich", "schau\u00b7ernd", "un\u00b7ter'm", "Bl\u00e4t\u00b7ter\u00b7dach", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Wolke zuckte Schwefelflammen", "tokens": ["Die", "Wol\u00b7ke", "zuck\u00b7te", "Schwe\u00b7fel\u00b7flam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jagte Regeng\u00fcsse nach.", "tokens": ["Und", "jag\u00b7te", "Re\u00b7gen\u00b7g\u00fcs\u00b7se", "nach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir h\u00f6rten\u2019s auf den Bl\u00e4ttern rauschen", "tokens": ["Wir", "h\u00f6r\u00b7ten's", "auf", "den", "Bl\u00e4t\u00b7tern", "rau\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und konnten ganz behaglich lauschen", "tokens": ["Und", "konn\u00b7ten", "ganz", "be\u00b7hag\u00b7lich", "lau\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Aus unserm laubigen Gemach.", "tokens": ["Aus", "un\u00b7serm", "lau\u00b7bi\u00b7gen", "Ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "F\u00fcrwahr, ein armes V\u00f6lklein war es,", "tokens": ["F\u00fcr\u00b7wahr", ",", "ein", "ar\u00b7mes", "V\u00f6l\u00b7klein", "war", "es", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das hier dem Wettersturm entrann,", "tokens": ["Das", "hier", "dem", "Wet\u00b7ter\u00b7sturm", "ent\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein d\u00fcrrer Jud gebleichten Haares,", "tokens": ["Ein", "d\u00fcr\u00b7rer", "Jud", "ge\u00b7bleich\u00b7ten", "Haa\u00b7res", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit seinem Hund ein blinder Mann,", "tokens": ["Mit", "sei\u00b7nem", "Hund", "ein", "blin\u00b7der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Des Frohners Weib mit blonden L\u00f6ckchen,", "tokens": ["Des", "Froh\u00b7ners", "Weib", "mit", "blon\u00b7den", "L\u00f6ck\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und dann mit seinem alten R\u00f6ckchen", "tokens": ["Und", "dann", "mit", "sei\u00b7nem", "al\u00b7ten", "R\u00f6ck\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der kleine hinkende Johann.", "tokens": ["Der", "klei\u00b7ne", "hin\u00b7ken\u00b7de", "Jo\u00b7hann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Und alle sah\u2019n bei jedem Blitze", "tokens": ["Und", "al\u00b7le", "sah'n", "bei", "je\u00b7dem", "Blit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vertrauend an den Stamm hinauf,", "tokens": ["Ver\u00b7trau\u00b7end", "an", "den", "Stamm", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Behaglich r\u00fcckend sich im Sitze", "tokens": ["Be\u00b7hag\u00b7lich", "r\u00fc\u00b7ckend", "sich", "im", "Sit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVPP", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und dr\u00e4ngten l\u00e4chelnd sich zu Hauf;", "tokens": ["Und", "dr\u00e4ng\u00b7ten", "l\u00e4\u00b7chelnd", "sich", "zu", "Hauf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn wie gewalt\u2019ger schlug der Regen,", "tokens": ["Denn", "wie", "ge\u00b7walt'\u00b7ger", "schlug", "der", "Re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So breiter warf dem Sturm entgegen", "tokens": ["So", "brei\u00b7ter", "warf", "dem", "Sturm", "ent\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der Baum die gr\u00fcnen Schirme auf.", "tokens": ["Der", "Baum", "die", "gr\u00fc\u00b7nen", "Schir\u00b7me", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}