{"textgrid.poem.38064": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Von dem Hammen von Reystett,", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "An einem Montag es geschah,", "tokens": ["An", "ei\u00b7nem", "Mon\u00b7tag", "es", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man Hammen von Reystett reiten sah,", "tokens": ["Da\u00df", "man", "Ham\u00b7men", "von", "Reys\u00b7tett", "rei\u00b7ten", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "NN", "VVFIN", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Durch einen gr\u00fcnen Walde,", "tokens": ["Durch", "ei\u00b7nen", "gr\u00fc\u00b7nen", "Wal\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Peter von Zeitenen begegnet ihm balde.", "tokens": ["Pe\u00b7ter", "von", "Zei\u00b7te\u00b7nen", "be\u00b7geg\u00b7net", "ihm", "bal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "+--+---+--+-", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Alsbald er Junker Hammen ersah:", "tokens": ["Als\u00b7bald", "er", "Jun\u00b7ker", "Ham\u00b7men", "er\u00b7sah", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ja Hammen Gott geb dir ein guten Tag,", "tokens": ["Ja", "Ham\u00b7men", "Gott", "geb", "dir", "ein", "gu\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und einen guten Morgen,", "tokens": ["Und", "ei\u00b7nen", "gu\u00b7ten", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du reitest in grossen Sorgen.", "tokens": ["Du", "rei\u00b7test", "in", "gros\u00b7sen", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Hammen gieb dich willig darein,", "tokens": ["Ham\u00b7men", "gieb", "dich", "wil\u00b7lig", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "ADJD", "PAV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Deren von Ulm must du Gefangner seyn,", "tokens": ["De\u00b7ren", "von", "Ulm", "must", "du", "Ge\u00b7fang\u00b7ner", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NE", "VMFIN", "PPER", "NN", "VAINF", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Woltest mir mein H\u00fctlein rucken,", "tokens": ["Wol\u00b7test", "mir", "mein", "H\u00fct\u00b7lein", "ru\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das dein will ich dir zucken.", "tokens": ["Das", "dein", "will", "ich", "dir", "zu\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Peter, wenn es nicht anders mag seyn,", "tokens": ["Pe\u00b7ter", ",", "wenn", "es", "nicht", "an\u00b7ders", "mag", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "VAINF", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "So bitt ich dich durch den Adel mein,", "tokens": ["So", "bitt", "ich", "dich", "durch", "den", "A\u00b7del", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "PPOSAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zieh aus dein scharfen Degen,", "tokens": ["Zieh", "aus", "dein", "schar\u00b7fen", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nimm mir mein edles Leben.", "tokens": ["Nimm", "mir", "mein", "ed\u00b7les", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Hammen das thu ich nicht,", "tokens": ["Ham\u00b7men", "das", "thu", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Dein edles Leben nehm ich nicht,", "tokens": ["Dein", "ed\u00b7les", "Le\u00b7ben", "nehm", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will dich weder hauen noch stechen,", "tokens": ["Ich", "will", "dich", "we\u00b7der", "hau\u00b7en", "noch", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die von Ulm m\u00fcssen mich r\u00e4chen.", "tokens": ["Die", "von", "Ulm", "m\u00fcs\u00b7sen", "mich", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "VMFIN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sie banden ihm H\u00e4nd, sie banden ihm F\u00fc\u00df,", "tokens": ["Sie", "ban\u00b7den", "ihm", "H\u00e4nd", ",", "sie", "ban\u00b7den", "ihm", "F\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und warfen ihn auf ein hohes Ro\u00df,", "tokens": ["Und", "war\u00b7fen", "ihn", "auf", "ein", "ho\u00b7hes", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und eilten mit ihm sehre,", "tokens": ["Und", "eil\u00b7ten", "mit", "ihm", "seh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie furchten viel Landsherren.", "tokens": ["Sie", "furch\u00b7ten", "viel", "Lands\u00b7her\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Dem Fr\u00e4ulein von Oesterreich kam die Mehr,", "tokens": ["Dem", "Fr\u00e4u\u00b7lein", "von", "O\u00b7es\u00b7ter\u00b7reich", "kam", "die", "Mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie Hammen zu Ulm gefangen leg,", "tokens": ["Wie", "Ham\u00b7men", "zu", "Ulm", "ge\u00b7fan\u00b7gen", "leg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "NE", "VVPP", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es wollt nicht l\u00e4nger beiten,", "tokens": ["Es", "wollt", "nicht", "l\u00e4n\u00b7ger", "bei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gen Ulm wollt sie bald reiten.", "tokens": ["Gen", "Ulm", "wollt", "sie", "bald", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VMFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Da sie gen Ulm eine reit,", "tokens": ["Da", "sie", "gen", "Ulm", "ei\u00b7ne", "reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Der Burgermeister ihr entgegen schreit:", "tokens": ["Der", "Bur\u00b7ger\u00b7meis\u00b7ter", "ihr", "ent\u00b7ge\u00b7gen", "schreit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nach adelichen Sitten", "tokens": ["Nach", "a\u00b7de\u00b7li\u00b7chen", "Sit\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Werd ihr f\u00fcr Hammen bitten.", "tokens": ["Werd", "ihr", "f\u00fcr", "Ham\u00b7men", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Das Fr\u00e4ulein auf das Rathhau\u00df trat,", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "auf", "das", "Rath\u00b7hau\u00df", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der B\u00fcrgermeister neben ihr sa\u00df,", "tokens": ["Der", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter", "ne\u00b7ben", "ihr", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ihr seyd meine gn\u00e4d'gen Herren,", "tokens": ["Ihr", "seyd", "mei\u00b7ne", "gn\u00e4d'\u00b7gen", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Fr\u00e4ulein sollet ihr ehren.", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "sol\u00b7let", "ihr", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Dem Fr\u00e4ulein ward all ihr Bitt verziehen,", "tokens": ["Dem", "Fr\u00e4u\u00b7lein", "ward", "all", "ihr", "Bitt", "ver\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es blieb der ganze Rath verschwiegen,", "tokens": ["Es", "blieb", "der", "gan\u00b7ze", "Rath", "ver\u00b7schwie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Urtheil ward gegeben,", "tokens": ["Das", "Ur\u00b7theil", "ward", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df Hammen nicht blieb am Leben.", "tokens": ["Da\u00df", "Ham\u00b7men", "nicht", "blieb", "am", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Das Fr\u00e4ulein auf zum Thurme trat:", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "auf", "zum", "Thur\u00b7me", "trat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ach Hammen Gott geb dir ein guten Tag,", "tokens": ["Ach", "Ham\u00b7men", "Gott", "geb", "dir", "ein", "gu\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und einen guten Morgen,", "tokens": ["Und", "ei\u00b7nen", "gu\u00b7ten", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du liegst in grossen Sorgen.", "tokens": ["Du", "liegst", "in", "gros\u00b7sen", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Hammen gieb dich willig darein,", "tokens": ["Ham\u00b7men", "gieb", "dich", "wil\u00b7lig", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "ADJD", "PAV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es geht dir an das junge Leben dein,", "tokens": ["Es", "geht", "dir", "an", "das", "jun\u00b7ge", "Le\u00b7ben", "dein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bin vor den Rath getreten,", "tokens": ["Ich", "bin", "vor", "den", "Rath", "ge\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und hab f\u00fcr dich gebeten.", "tokens": ["Und", "hab", "f\u00fcr", "dich", "ge\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Genade mir Frau von Oesterreich,", "tokens": ["Ge\u00b7na\u00b7de", "mir", "Frau", "von", "O\u00b7es\u00b7ter\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dir werde Gott vom Himmelreich", "tokens": ["Dir", "wer\u00b7de", "Gott", "vom", "Him\u00b7mel\u00b7reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bewahr euch eure Ehre,", "tokens": ["Be\u00b7wahr", "euch", "eu\u00b7re", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Euch und andern Fr\u00e4ulein mehre.", "tokens": ["Euch", "und", "an\u00b7dern", "Fr\u00e4u\u00b7lein", "meh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Ich bitt euch also fleissiglich,", "tokens": ["Ich", "bitt", "euch", "al\u00b7so", "fleis\u00b7sig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Betet f\u00fcr mich, da\u00df man mich", "tokens": ["Be\u00b7tet", "f\u00fcr", "mich", ",", "da\u00df", "man", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPER", "$,", "KOUS", "PIS", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df einmauern, so will ich schliessen", "tokens": ["La\u00df", "ein\u00b7mau\u00b7ern", ",", "so", "will", "ich", "schlies\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "VVIZU", "$,", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Mein Leben dann mit B\u00fcssen.", "tokens": ["Mein", "Le\u00b7ben", "dann", "mit", "B\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Das Fr\u00e4ulein die Red vor die Herren bracht,", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "die", "Red", "vor", "die", "Her\u00b7ren", "bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Das Fr\u00e4ulein ward von ihnen veracht,", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "ward", "von", "ih\u00b7nen", "ver\u00b7acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Kein Gnad mocht sie erwerben:", "tokens": ["Kein", "Gnad", "mocht", "sie", "er\u00b7wer\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Jungherr Hammen mu\u00df sterben.", "tokens": ["Jung\u00b7herr", "Ham\u00b7men", "mu\u00df", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.16": {"line.1": {"text": "Da man Hammen aus dem Thurm f\u00fchrt,", "tokens": ["Da", "man", "Ham\u00b7men", "aus", "dem", "Thurm", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Man legt ihm an einen grauen Rock,", "tokens": ["Man", "legt", "ihm", "an", "ei\u00b7nen", "grau\u00b7en", "Rock", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man zog ihm aus seine Schuhe,", "tokens": ["Man", "zog", "ihm", "aus", "sei\u00b7ne", "Schu\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Seine S\u00fcnd thaten ihm sehr reuen.", "tokens": ["Sei\u00b7ne", "S\u00fcnd", "tha\u00b7ten", "ihm", "sehr", "reu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Da Hammen vor des Herrn Marterbild kam,", "tokens": ["Da", "Ham\u00b7men", "vor", "des", "Herrn", "Mar\u00b7ter\u00b7bild", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun h\u00f6ret zu was Hammen sprach,", "tokens": ["Nun", "h\u00f6\u00b7ret", "zu", "was", "Ham\u00b7men", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PRELS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er fiel nieder auf seine Knie,", "tokens": ["Er", "fiel", "nie\u00b7der", "auf", "sei\u00b7ne", "Knie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Er bat die Gemein, da\u00df man ihm verziehe.", "tokens": ["Er", "bat", "die", "Ge\u00b7mein", ",", "da\u00df", "man", "ihm", "ver\u00b7zie\u00b7he", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.18": {"line.1": {"text": "Meister la\u00df mir wohl der Weil,", "tokens": ["Meis\u00b7ter", "la\u00df", "mir", "wohl", "der", "Weil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVIMP", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meister ihr sollt mich nicht \u00fcbereiln,", "tokens": ["Meis\u00b7ter", "ihr", "sollt", "mich", "nicht", "\u00fc\u00b7be\u00b7reiln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ich will euch ritterlich halten,", "tokens": ["Ich", "will", "euch", "rit\u00b7ter\u00b7lich", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Den werthen Gott lasset walten!", "tokens": ["Den", "wert\u00b7hen", "Gott", "las\u00b7set", "wal\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Da man Hammen sein Haupt abschlug,", "tokens": ["Da", "man", "Ham\u00b7men", "sein", "Haupt", "ab\u00b7schlug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "--+--++-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Bald man ihn zu einem Borne trug,", "tokens": ["Bald", "man", "ihn", "zu", "ei\u00b7nem", "Bor\u00b7ne", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Man legt ihn dahin mit Fleisse", "tokens": ["Man", "legt", "ihn", "da\u00b7hin", "mit", "Fleis\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PAV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "In zwei Leilachen waren weisse.", "tokens": ["In", "zwei", "Lei\u00b7la\u00b7chen", "wa\u00b7ren", "weis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Man legt ihn auf einen hangenden Wagen,", "tokens": ["Man", "legt", "ihn", "auf", "ei\u00b7nen", "han\u00b7gen\u00b7den", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Man that ihn zu seinen drey Schwestern tragen,", "tokens": ["Man", "that", "ihn", "zu", "sei\u00b7nen", "drey", "Schwes\u00b7tern", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "CARD", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Durch einen gr\u00fcnen Walde,", "tokens": ["Durch", "ei\u00b7nen", "gr\u00fc\u00b7nen", "Wal\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu seinen drey Schwestern balde.", "tokens": ["Zu", "sei\u00b7nen", "drey", "Schwes\u00b7tern", "bal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "CARD", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Die j\u00fcngste Schwester das vernahm,", "tokens": ["Die", "j\u00fcngs\u00b7te", "Schwes\u00b7ter", "das", "ver\u00b7nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df da ihr todter Bruder kam,", "tokens": ["Da\u00df", "da", "ihr", "tod\u00b7ter", "Bru\u00b7der", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In einer kurzen Stunde", "tokens": ["In", "ei\u00b7ner", "kur\u00b7zen", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dreymal war ihr geschwunden.", "tokens": ["Drey\u00b7mal", "war", "ihr", "ge\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.22": {"line.1": {"text": "\u00bbihr Herren von Ulm wie ist euch so gach,", "tokens": ["\u00bb", "ihr", "Her\u00b7ren", "von", "Ulm", "wie", "ist", "euch", "so", "gach", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "APPR", "NE", "KOKOM", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "F\u00fcrchtet ihr nicht noch gr\u00f6ssre Schmach,", "tokens": ["F\u00fcrch\u00b7tet", "ihr", "nicht", "noch", "gr\u00f6ss\u00b7re", "Schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die euch daraus m\u00f6cht kommen,", "tokens": ["Die", "euch", "da\u00b7raus", "m\u00f6cht", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ueber euch und eure Frommen.", "tokens": ["Ue\u00b7ber", "euch", "und", "eu\u00b7re", "From\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ihr Herren wisset was das bedeut,", "tokens": ["Ihr", "Her\u00b7ren", "wis\u00b7set", "was", "das", "be\u00b7deut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PWS", "PDS", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Kindlein in der Wiegen leit,", "tokens": ["Das", "Kin\u00b7dlein", "in", "der", "Wie\u00b7gen", "leit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das noch kein Wort kann sprechen,", "tokens": ["Das", "noch", "kein", "Wort", "kann", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Vater den mu\u00df es r\u00e4chen.\u00ab", "tokens": ["Sein", "Va\u00b7ter", "den", "mu\u00df", "es", "r\u00e4\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "An einem Montag es geschah,", "tokens": ["An", "ei\u00b7nem", "Mon\u00b7tag", "es", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man Hammen von Reystett reiten sah,", "tokens": ["Da\u00df", "man", "Ham\u00b7men", "von", "Reys\u00b7tett", "rei\u00b7ten", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "NN", "VVFIN", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Durch einen gr\u00fcnen Walde,", "tokens": ["Durch", "ei\u00b7nen", "gr\u00fc\u00b7nen", "Wal\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Peter von Zeitenen begegnet ihm balde.", "tokens": ["Pe\u00b7ter", "von", "Zei\u00b7te\u00b7nen", "be\u00b7geg\u00b7net", "ihm", "bal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "+--+---+--+-", "measure": "dactylic.di.plus"}}, "stanza.25": {"line.1": {"text": "Alsbald er Junker Hammen ersah:", "tokens": ["Als\u00b7bald", "er", "Jun\u00b7ker", "Ham\u00b7men", "er\u00b7sah", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ja Hammen Gott geb dir ein guten Tag,", "tokens": ["Ja", "Ham\u00b7men", "Gott", "geb", "dir", "ein", "gu\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und einen guten Morgen,", "tokens": ["Und", "ei\u00b7nen", "gu\u00b7ten", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du reitest in grossen Sorgen.", "tokens": ["Du", "rei\u00b7test", "in", "gros\u00b7sen", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.26": {"line.1": {"text": "Hammen gieb dich willig darein,", "tokens": ["Ham\u00b7men", "gieb", "dich", "wil\u00b7lig", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "ADJD", "PAV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Deren von Ulm must du Gefangner seyn,", "tokens": ["De\u00b7ren", "von", "Ulm", "must", "du", "Ge\u00b7fang\u00b7ner", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NE", "VMFIN", "PPER", "NN", "VAINF", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Woltest mir mein H\u00fctlein rucken,", "tokens": ["Wol\u00b7test", "mir", "mein", "H\u00fct\u00b7lein", "ru\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das dein will ich dir zucken.", "tokens": ["Das", "dein", "will", "ich", "dir", "zu\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Peter, wenn es nicht anders mag seyn,", "tokens": ["Pe\u00b7ter", ",", "wenn", "es", "nicht", "an\u00b7ders", "mag", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "VAINF", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "So bitt ich dich durch den Adel mein,", "tokens": ["So", "bitt", "ich", "dich", "durch", "den", "A\u00b7del", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "PPOSAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zieh aus dein scharfen Degen,", "tokens": ["Zieh", "aus", "dein", "schar\u00b7fen", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nimm mir mein edles Leben.", "tokens": ["Nimm", "mir", "mein", "ed\u00b7les", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Hammen das thu ich nicht,", "tokens": ["Ham\u00b7men", "das", "thu", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Dein edles Leben nehm ich nicht,", "tokens": ["Dein", "ed\u00b7les", "Le\u00b7ben", "nehm", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will dich weder hauen noch stechen,", "tokens": ["Ich", "will", "dich", "we\u00b7der", "hau\u00b7en", "noch", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die von Ulm m\u00fcssen mich r\u00e4chen.", "tokens": ["Die", "von", "Ulm", "m\u00fcs\u00b7sen", "mich", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "VMFIN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Sie banden ihm H\u00e4nd, sie banden ihm F\u00fc\u00df,", "tokens": ["Sie", "ban\u00b7den", "ihm", "H\u00e4nd", ",", "sie", "ban\u00b7den", "ihm", "F\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und warfen ihn auf ein hohes Ro\u00df,", "tokens": ["Und", "war\u00b7fen", "ihn", "auf", "ein", "ho\u00b7hes", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und eilten mit ihm sehre,", "tokens": ["Und", "eil\u00b7ten", "mit", "ihm", "seh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie furchten viel Landsherren.", "tokens": ["Sie", "furch\u00b7ten", "viel", "Lands\u00b7her\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Dem Fr\u00e4ulein von Oesterreich kam die Mehr,", "tokens": ["Dem", "Fr\u00e4u\u00b7lein", "von", "O\u00b7es\u00b7ter\u00b7reich", "kam", "die", "Mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie Hammen zu Ulm gefangen leg,", "tokens": ["Wie", "Ham\u00b7men", "zu", "Ulm", "ge\u00b7fan\u00b7gen", "leg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "NE", "VVPP", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es wollt nicht l\u00e4nger beiten,", "tokens": ["Es", "wollt", "nicht", "l\u00e4n\u00b7ger", "bei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gen Ulm wollt sie bald reiten.", "tokens": ["Gen", "Ulm", "wollt", "sie", "bald", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VMFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Da sie gen Ulm eine reit,", "tokens": ["Da", "sie", "gen", "Ulm", "ei\u00b7ne", "reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Der Burgermeister ihr entgegen schreit:", "tokens": ["Der", "Bur\u00b7ger\u00b7meis\u00b7ter", "ihr", "ent\u00b7ge\u00b7gen", "schreit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nach adelichen Sitten", "tokens": ["Nach", "a\u00b7de\u00b7li\u00b7chen", "Sit\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Werd ihr f\u00fcr Hammen bitten.", "tokens": ["Werd", "ihr", "f\u00fcr", "Ham\u00b7men", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Das Fr\u00e4ulein auf das Rathhau\u00df trat,", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "auf", "das", "Rath\u00b7hau\u00df", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der B\u00fcrgermeister neben ihr sa\u00df,", "tokens": ["Der", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter", "ne\u00b7ben", "ihr", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ihr seyd meine gn\u00e4d'gen Herren,", "tokens": ["Ihr", "seyd", "mei\u00b7ne", "gn\u00e4d'\u00b7gen", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Fr\u00e4ulein sollet ihr ehren.", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "sol\u00b7let", "ihr", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.33": {"line.1": {"text": "Dem Fr\u00e4ulein ward all ihr Bitt verziehen,", "tokens": ["Dem", "Fr\u00e4u\u00b7lein", "ward", "all", "ihr", "Bitt", "ver\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es blieb der ganze Rath verschwiegen,", "tokens": ["Es", "blieb", "der", "gan\u00b7ze", "Rath", "ver\u00b7schwie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Urtheil ward gegeben,", "tokens": ["Das", "Ur\u00b7theil", "ward", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df Hammen nicht blieb am Leben.", "tokens": ["Da\u00df", "Ham\u00b7men", "nicht", "blieb", "am", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.34": {"line.1": {"text": "Das Fr\u00e4ulein auf zum Thurme trat:", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "auf", "zum", "Thur\u00b7me", "trat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ach Hammen Gott geb dir ein guten Tag,", "tokens": ["Ach", "Ham\u00b7men", "Gott", "geb", "dir", "ein", "gu\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und einen guten Morgen,", "tokens": ["Und", "ei\u00b7nen", "gu\u00b7ten", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du liegst in grossen Sorgen.", "tokens": ["Du", "liegst", "in", "gros\u00b7sen", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Hammen gieb dich willig darein,", "tokens": ["Ham\u00b7men", "gieb", "dich", "wil\u00b7lig", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "ADJD", "PAV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es geht dir an das junge Leben dein,", "tokens": ["Es", "geht", "dir", "an", "das", "jun\u00b7ge", "Le\u00b7ben", "dein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bin vor den Rath getreten,", "tokens": ["Ich", "bin", "vor", "den", "Rath", "ge\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und hab f\u00fcr dich gebeten.", "tokens": ["Und", "hab", "f\u00fcr", "dich", "ge\u00b7be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Genade mir Frau von Oesterreich,", "tokens": ["Ge\u00b7na\u00b7de", "mir", "Frau", "von", "O\u00b7es\u00b7ter\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dir werde Gott vom Himmelreich", "tokens": ["Dir", "wer\u00b7de", "Gott", "vom", "Him\u00b7mel\u00b7reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bewahr euch eure Ehre,", "tokens": ["Be\u00b7wahr", "euch", "eu\u00b7re", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Euch und andern Fr\u00e4ulein mehre.", "tokens": ["Euch", "und", "an\u00b7dern", "Fr\u00e4u\u00b7lein", "meh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Ich bitt euch also fleissiglich,", "tokens": ["Ich", "bitt", "euch", "al\u00b7so", "fleis\u00b7sig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Betet f\u00fcr mich, da\u00df man mich", "tokens": ["Be\u00b7tet", "f\u00fcr", "mich", ",", "da\u00df", "man", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPER", "$,", "KOUS", "PIS", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df einmauern, so will ich schliessen", "tokens": ["La\u00df", "ein\u00b7mau\u00b7ern", ",", "so", "will", "ich", "schlies\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "VVIZU", "$,", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Mein Leben dann mit B\u00fcssen.", "tokens": ["Mein", "Le\u00b7ben", "dann", "mit", "B\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Das Fr\u00e4ulein die Red vor die Herren bracht,", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "die", "Red", "vor", "die", "Her\u00b7ren", "bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Das Fr\u00e4ulein ward von ihnen veracht,", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "ward", "von", "ih\u00b7nen", "ver\u00b7acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Kein Gnad mocht sie erwerben:", "tokens": ["Kein", "Gnad", "mocht", "sie", "er\u00b7wer\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Jungherr Hammen mu\u00df sterben.", "tokens": ["Jung\u00b7herr", "Ham\u00b7men", "mu\u00df", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.39": {"line.1": {"text": "Da man Hammen aus dem Thurm f\u00fchrt,", "tokens": ["Da", "man", "Ham\u00b7men", "aus", "dem", "Thurm", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Man legt ihm an einen grauen Rock,", "tokens": ["Man", "legt", "ihm", "an", "ei\u00b7nen", "grau\u00b7en", "Rock", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man zog ihm aus seine Schuhe,", "tokens": ["Man", "zog", "ihm", "aus", "sei\u00b7ne", "Schu\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Seine S\u00fcnd thaten ihm sehr reuen.", "tokens": ["Sei\u00b7ne", "S\u00fcnd", "tha\u00b7ten", "ihm", "sehr", "reu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.40": {"line.1": {"text": "Da Hammen vor des Herrn Marterbild kam,", "tokens": ["Da", "Ham\u00b7men", "vor", "des", "Herrn", "Mar\u00b7ter\u00b7bild", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun h\u00f6ret zu was Hammen sprach,", "tokens": ["Nun", "h\u00f6\u00b7ret", "zu", "was", "Ham\u00b7men", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PRELS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er fiel nieder auf seine Knie,", "tokens": ["Er", "fiel", "nie\u00b7der", "auf", "sei\u00b7ne", "Knie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Er bat die Gemein, da\u00df man ihm verziehe.", "tokens": ["Er", "bat", "die", "Ge\u00b7mein", ",", "da\u00df", "man", "ihm", "ver\u00b7zie\u00b7he", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.41": {"line.1": {"text": "Meister la\u00df mir wohl der Weil,", "tokens": ["Meis\u00b7ter", "la\u00df", "mir", "wohl", "der", "Weil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVIMP", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meister ihr sollt mich nicht \u00fcbereiln,", "tokens": ["Meis\u00b7ter", "ihr", "sollt", "mich", "nicht", "\u00fc\u00b7be\u00b7reiln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ich will euch ritterlich halten,", "tokens": ["Ich", "will", "euch", "rit\u00b7ter\u00b7lich", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Den werthen Gott lasset walten!", "tokens": ["Den", "wert\u00b7hen", "Gott", "las\u00b7set", "wal\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.42": {"line.1": {"text": "Da man Hammen sein Haupt abschlug,", "tokens": ["Da", "man", "Ham\u00b7men", "sein", "Haupt", "ab\u00b7schlug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "--+--++-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Bald man ihn zu einem Borne trug,", "tokens": ["Bald", "man", "ihn", "zu", "ei\u00b7nem", "Bor\u00b7ne", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Man legt ihn dahin mit Fleisse", "tokens": ["Man", "legt", "ihn", "da\u00b7hin", "mit", "Fleis\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PAV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "In zwei Leilachen waren weisse.", "tokens": ["In", "zwei", "Lei\u00b7la\u00b7chen", "wa\u00b7ren", "weis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Man legt ihn auf einen hangenden Wagen,", "tokens": ["Man", "legt", "ihn", "auf", "ei\u00b7nen", "han\u00b7gen\u00b7den", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Man that ihn zu seinen drey Schwestern tragen,", "tokens": ["Man", "that", "ihn", "zu", "sei\u00b7nen", "drey", "Schwes\u00b7tern", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "CARD", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Durch einen gr\u00fcnen Walde,", "tokens": ["Durch", "ei\u00b7nen", "gr\u00fc\u00b7nen", "Wal\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu seinen drey Schwestern balde.", "tokens": ["Zu", "sei\u00b7nen", "drey", "Schwes\u00b7tern", "bal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "CARD", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.44": {"line.1": {"text": "Die j\u00fcngste Schwester das vernahm,", "tokens": ["Die", "j\u00fcngs\u00b7te", "Schwes\u00b7ter", "das", "ver\u00b7nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df da ihr todter Bruder kam,", "tokens": ["Da\u00df", "da", "ihr", "tod\u00b7ter", "Bru\u00b7der", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In einer kurzen Stunde", "tokens": ["In", "ei\u00b7ner", "kur\u00b7zen", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dreymal war ihr geschwunden.", "tokens": ["Drey\u00b7mal", "war", "ihr", "ge\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.45": {"line.1": {"text": "\u00bbihr Herren von Ulm wie ist euch so gach,", "tokens": ["\u00bb", "ihr", "Her\u00b7ren", "von", "Ulm", "wie", "ist", "euch", "so", "gach", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "APPR", "NE", "KOKOM", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "F\u00fcrchtet ihr nicht noch gr\u00f6ssre Schmach,", "tokens": ["F\u00fcrch\u00b7tet", "ihr", "nicht", "noch", "gr\u00f6ss\u00b7re", "Schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die euch daraus m\u00f6cht kommen,", "tokens": ["Die", "euch", "da\u00b7raus", "m\u00f6cht", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ueber euch und eure Frommen.", "tokens": ["Ue\u00b7ber", "euch", "und", "eu\u00b7re", "From\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Ihr Herren wisset was das bedeut,", "tokens": ["Ihr", "Her\u00b7ren", "wis\u00b7set", "was", "das", "be\u00b7deut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PWS", "PDS", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Kindlein in der Wiegen leit,", "tokens": ["Das", "Kin\u00b7dlein", "in", "der", "Wie\u00b7gen", "leit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das noch kein Wort kann sprechen,", "tokens": ["Das", "noch", "kein", "Wort", "kann", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Vater den mu\u00df es r\u00e4chen.\u00ab", "tokens": ["Sein", "Va\u00b7ter", "den", "mu\u00df", "es", "r\u00e4\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}