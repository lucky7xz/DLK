{"dta.poem.23802": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Der 72. Psalm.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Gott wird Israel erfreuen/", "tokens": ["Gott", "wird", "Is\u00b7rael", "er\u00b7freu\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NE", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wenn es Ihn von Hertzen meynt;", "tokens": ["Wenn", "es", "Ihn", "von", "Hert\u00b7zen", "meynt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sein Volck noch benedeyen/", "tokens": ["Und", "sein", "Volck", "noch", "be\u00b7ne\u00b7de\u00b7yen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ob es gleich in Aengsten weint.", "tokens": ["Ob", "es", "gleich", "in", "A\u00b7engs\u00b7ten", "weint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NE", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Das ist sicher: Unterdessen", "tokens": ["Das", "ist", "si\u00b7cher", ":", "Un\u00b7ter\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PDS", "VAFIN", "ADJD", "$.", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "H\u00e4tt\u2019 ich es bey nah vergessen/", "tokens": ["H\u00e4tt'", "ich", "es", "bey", "nah", "ver\u00b7ges\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ADJD", "VVPP", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.7": {"text": "Und gezweiffelt: Ob Er sieht", "tokens": ["Und", "ge\u00b7zweif\u00b7felt", ":", "Ob", "Er", "sieht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVPP", "$.", "KOUS", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Was auf dieser Welt geschieht.", "tokens": ["Was", "auf", "die\u00b7ser", "Welt", "ge\u00b7schieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Denn ich kont es nicht ergr\u00fcnden/", "tokens": ["Denn", "ich", "kont", "es", "nicht", "er\u00b7gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df wer dich O Sch\u00f6pffer h\u00f6hnt/", "tokens": ["Da\u00df", "wer", "dich", "O", "Sch\u00f6pf\u00b7fer", "h\u00f6hnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "PPER", "NE", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In dem h\u00f6chsten Grad der S\u00fcnden", "tokens": ["In", "dem", "h\u00f6chs\u00b7ten", "Grad", "der", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird mit lauter Gl\u00fcck bekr\u00f6hnt.", "tokens": ["Wird", "mit", "lau\u00b7ter", "Gl\u00fcck", "be\u00b7kr\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df er/ wenn er mit Vergn\u00fcgen", "tokens": ["Da\u00df", "er", "/", "wenn", "er", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$(", "KOUS", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seiner Jahre Zahl erstiegen/", "tokens": ["Sei\u00b7ner", "Jah\u00b7re", "Zahl", "er\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Endlich bl\u00e4set ohne Grau\u00df", "tokens": ["End\u00b7lich", "bl\u00e4\u00b7set", "oh\u00b7ne", "Grau\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Den verfluchten Athem aus.", "tokens": ["Den", "ver\u00b7fluch\u00b7ten", "A\u00b7them", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Er erhebt sich gleich den Zinnen/", "tokens": ["Er", "er\u00b7hebt", "sich", "gleich", "den", "Zin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die von Marmor aufgeth\u00fcrmt;", "tokens": ["Die", "von", "Mar\u00b7mor", "auf\u00b7ge\u00b7th\u00fcrmt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und verz\u00e4rtelt seine Sinnen/", "tokens": ["Und", "ver\u00b7z\u00e4r\u00b7telt", "sei\u00b7ne", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn sonst eitel Ungl\u00fcck st\u00fcrmt.", "tokens": ["Wenn", "sonst", "ei\u00b7tel", "Un\u00b7gl\u00fcck", "st\u00fcrmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn sein Wanst von Hoffart schwillet/", "tokens": ["Wenn", "sein", "Wanst", "von", "Hof\u00b7fart", "schwil\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mu\u00df sein W\u00fcnschen seyn erf\u00fcllet;", "tokens": ["Mu\u00df", "sein", "W\u00fcn\u00b7schen", "seyn", "er\u00b7f\u00fcl\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VAINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ja was er zuweilen tr\u00e4umt/", "tokens": ["Ja", "was", "er", "zu\u00b7wei\u00b7len", "tr\u00e4umt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mu\u00df ihm werden einger\u00e4umt.", "tokens": ["Mu\u00df", "ihm", "wer\u00b7den", "ein\u00b7ge\u00b7r\u00e4umt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Er verl\u00e4stert alle Sachen", "tokens": ["Er", "ver\u00b7l\u00e4s\u00b7tert", "al\u00b7le", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die nicht sein Gehirn gebiert/", "tokens": ["Die", "nicht", "sein", "Ge\u00b7hirn", "ge\u00b7biert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "PPOSAT", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und darf selbst dar\u00fcber lachen", "tokens": ["Und", "darf", "selbst", "da\u00b7r\u00fc\u00b7ber", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "PAV", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wie dein Arm den Scepter f\u00fchrt.", "tokens": ["Wie", "dein", "Arm", "den", "Scep\u00b7ter", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer mag seine Thorheit schelten?", "tokens": ["Wer", "mag", "sei\u00b7ne", "Thor\u00b7heit", "schel\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Was er schafft mu\u00df alles gelten;", "tokens": ["Was", "er", "schafft", "mu\u00df", "al\u00b7les", "gel\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und was er ihm bildet ein/", "tokens": ["Und", "was", "er", "ihm", "bil\u00b7det", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PPER", "VVFIN", "ART", "$("], "meter": "+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Sol uns ein Orakel seyn.", "tokens": ["Sol", "uns", "ein", "O\u00b7ra\u00b7kel", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Weil ihn nun kein Ziel beschrencket/", "tokens": ["Weil", "ihn", "nun", "kein", "Ziel", "be\u00b7schren\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird der P\u00f6bel irr gemacht/", "tokens": ["Wird", "der", "P\u00f6\u00b7bel", "irr", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er bey sich selber dencket:", "tokens": ["Da\u00df", "er", "bey", "sich", "sel\u00b7ber", "den\u00b7cket", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott giebt nicht auff Menschen acht/", "tokens": ["Gott", "giebt", "nicht", "auff", "Men\u00b7schen", "acht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "APPR", "NN", "CARD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er schl\u00e4fft in dem Himmel oben/", "tokens": ["Er", "schl\u00e4fft", "in", "dem", "Him\u00b7mel", "o\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und l\u00e4\u00dft den Tyrannen toben.", "tokens": ["Und", "l\u00e4\u00dft", "den", "Ty\u00b7ran\u00b7nen", "to\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Was hilfft uns die Fr\u00f6mmigkeit?", "tokens": ["Was", "hilfft", "uns", "die", "Fr\u00f6m\u00b7mig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Wir sind arm und er gedeyht.", "tokens": ["Wir", "sind", "arm", "und", "er", "ge\u00b7deyht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "HeRR/ ich mu\u00df die Warheit sagen;", "tokens": ["HeRR", "/", "ich", "mu\u00df", "die", "War\u00b7heit", "sa\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mich verdro\u00df der Lauff der Welt/", "tokens": ["Mich", "ver\u00b7dro\u00df", "der", "Lauff", "der", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich h\u00e4tte diesem Klagen", "tokens": ["Da\u00df", "ich", "h\u00e4t\u00b7te", "die\u00b7sem", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VAFIN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bald mein Ja-Wort zugesellt/", "tokens": ["Bald", "mein", "Ja\u00b7Wort", "zu\u00b7ge\u00b7sellt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und gegl\u00e4ubt: da\u00df die dich preisen/", "tokens": ["Und", "ge\u00b7gl\u00e4ubt", ":", "da\u00df", "die", "dich", "prei\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$.", "KOUS", "ART", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich mit leerer Hoffnung speisen.", "tokens": ["Sich", "mit", "lee\u00b7rer", "Hoff\u00b7nung", "spei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zwar ich dachte flei\u00dfig nach/", "tokens": ["Zwar", "ich", "dach\u00b7te", "flei\u00b7\u00dfig", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADJD", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Doch war die Vernunfft zu schwach.", "tokens": ["Doch", "war", "die", "Ver\u00b7nunfft", "zu", "schwach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Endlich ward in deinem Tempel", "tokens": ["End\u00b7lich", "ward", "in", "dei\u00b7nem", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir er\u00f6ffnet dieser Schlu\u00df:", "tokens": ["Mir", "er\u00b7\u00f6ff\u00b7net", "die\u00b7ser", "Schlu\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der b\u00f6sen ihr Exempel", "tokens": ["Da\u00df", "der", "b\u00f6\u00b7sen", "ihr", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "PPOSAT", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Nicht zur Folge dienen mu\u00df.", "tokens": ["Nicht", "zur", "Fol\u00b7ge", "die\u00b7nen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn/ o GOtt! du l\u00e4\u00dfst sie wallen/", "tokens": ["Denn", "/", "o", "Gott", "!", "du", "l\u00e4\u00df\u00b7st", "sie", "wal\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "FM", "NN", "$.", "PPER", "VVFIN", "PPER", "VVINF", "$("], "meter": "-++-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da\u00df sie desto h\u00e4rter fallen;", "tokens": ["Da\u00df", "sie", "des\u00b7to", "h\u00e4r\u00b7ter", "fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Es ist eine Zeit bestimmt/", "tokens": ["Es", "ist", "ei\u00b7ne", "Zeit", "be\u00b7stimmt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Da ihr Stoltz ein Ende nimmt.", "tokens": ["Da", "ihr", "Stoltz", "ein", "En\u00b7de", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Schrecklich werden sie verstieben/", "tokens": ["Schreck\u00b7lich", "wer\u00b7den", "sie", "ver\u00b7stie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leichter als ein Traum vergehn/", "tokens": ["Leich\u00b7ter", "als", "ein", "Traum", "ver\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was etwan \u00fcbrig blieben/", "tokens": ["Und", "was", "et\u00b7wan", "\u00fcb\u00b7rig", "blie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird in keinem Seegen stehn.", "tokens": ["Wird", "in", "kei\u00b7nem", "See\u00b7gen", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du wirst tilgen ihren Saamen/", "tokens": ["Du", "wirst", "til\u00b7gen", "ih\u00b7ren", "Saa\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und es wird auff ihren Namen/", "tokens": ["Und", "es", "wird", "auff", "ih\u00b7ren", "Na\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "(den man erst so hoch gesch\u00e4tzt)", "tokens": ["(", "den", "man", "erst", "so", "hoch", "ge\u00b7sch\u00e4tzt", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PIS", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Seyn ein steter Fluch gesetzt.", "tokens": ["Seyn", "ein", "ste\u00b7ter", "Fluch", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "War es m\u00fcglich? kont ich wancken?", "tokens": ["War", "es", "m\u00fcg\u00b7lich", "?", "kont", "ich", "wan\u00b7cken", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$.", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War ich schlaffend oder blind?", "tokens": ["War", "ich", "schlaf\u00b7fend", "o\u00b7der", "blind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch was th\u00f6richte Gedancken", "tokens": ["Durch", "was", "th\u00f6\u00b7rich\u00b7te", "Ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ADJA", "NN"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "War ich d\u00fcmmer als ein Rind?", "tokens": ["War", "ich", "d\u00fcm\u00b7mer", "als", "ein", "Rind", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich/ was du gut gefunden/", "tokens": ["Da\u00df", "ich", "/", "was", "du", "gut", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "PWS", "PPER", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zu bek\u00fcgeln mich erwunden.", "tokens": ["Zu", "be\u00b7k\u00fc\u00b7geln", "mich", "er\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Dieses was ich ausge\u00fcbt/", "tokens": ["Die\u00b7ses", "was", "ich", "aus\u00b7ge\u00b7\u00fcbt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "PWS", "PPER", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Macht mich schamroht und betr\u00fcbt.", "tokens": ["Macht", "mich", "scham\u00b7roht", "und", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "K\u00fcnfftig werd ich nicht mehr gleiten/", "tokens": ["K\u00fcnff\u00b7tig", "werd", "ich", "nicht", "mehr", "glei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herr/ von deiner Seiten ab;", "tokens": ["Herr", "/", "von", "dei\u00b7ner", "Sei\u00b7ten", "ab", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn du selber wirst mich leiten/", "tokens": ["Denn", "du", "sel\u00b7ber", "wirst", "mich", "lei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VAFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dein Raht ist mein Wander-Stab.", "tokens": ["Dein", "Raht", "ist", "mein", "Wan\u00b7der\u00b7Stab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Endlich nach viel Dornen-Hecken/", "tokens": ["End\u00b7lich", "nach", "viel", "Dor\u00b7nen\u00b7He\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wirst du mir den Ort entdecken/", "tokens": ["Wirst", "du", "mir", "den", "Ort", "ent\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da ich aller Ehren voll", "tokens": ["Da", "ich", "al\u00b7ler", "Eh\u00b7ren", "voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN", "ADJD"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Deine Wolthat r\u00fchmen soll.", "tokens": ["Dei\u00b7ne", "Wolt\u00b7hat", "r\u00fch\u00b7men", "soll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}