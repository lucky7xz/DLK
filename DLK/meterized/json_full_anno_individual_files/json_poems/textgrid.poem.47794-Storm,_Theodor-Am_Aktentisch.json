{"textgrid.poem.47794": {"metadata": {"author": {"name": "Storm, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Am Aktentisch", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da hab ich den ganzen Tag dekretiert;", "tokens": ["Da", "hab", "ich", "den", "gan\u00b7zen", "Tag", "de\u00b7kre\u00b7tiert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und es h\u00e4tte mich fast wie so manchen verf\u00fchrt:", "tokens": ["Und", "es", "h\u00e4t\u00b7te", "mich", "fast", "wie", "so", "man\u00b7chen", "ver\u00b7f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ADV", "KOKOM", "ADV", "PIS", "VVPP", "$."], "meter": "--+-+++-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Ich sp\u00fcrte das kleine dumme Vergn\u00fcgen,", "tokens": ["Ich", "sp\u00fcr\u00b7te", "das", "klei\u00b7ne", "dum\u00b7me", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was abzumachen, was fertigzukriegen.", "tokens": ["Was", "ab\u00b7zu\u00b7ma\u00b7chen", ",", "was", "fer\u00b7tig\u00b7zu\u00b7krie\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVIZU", "$,", "PWS", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Da hab ich den ganzen Tag dekretiert;", "tokens": ["Da", "hab", "ich", "den", "gan\u00b7zen", "Tag", "de\u00b7kre\u00b7tiert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und es h\u00e4tte mich fast wie so manchen verf\u00fchrt:", "tokens": ["Und", "es", "h\u00e4t\u00b7te", "mich", "fast", "wie", "so", "man\u00b7chen", "ver\u00b7f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ADV", "KOKOM", "ADV", "PIS", "VVPP", "$."], "meter": "--+-+++-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Ich sp\u00fcrte das kleine dumme Vergn\u00fcgen,", "tokens": ["Ich", "sp\u00fcr\u00b7te", "das", "klei\u00b7ne", "dum\u00b7me", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was abzumachen, was fertigzukriegen.", "tokens": ["Was", "ab\u00b7zu\u00b7ma\u00b7chen", ",", "was", "fer\u00b7tig\u00b7zu\u00b7krie\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVIZU", "$,", "PWS", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}}}}