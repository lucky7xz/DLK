{"textgrid.poem.59870": {"metadata": {"author": {"name": "Bodenstedt, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wodurch ist Schiras wohl, die Stadt,", "tokens": ["Wo\u00b7durch", "ist", "Schi\u00b7ras", "wohl", ",", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "ADV", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ber\u00fchmt mit Ros' und Wein geworden?", "tokens": ["Be\u00b7r\u00fchmt", "mit", "Ros'", "und", "Wein", "ge\u00b7wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wodurch ber\u00fchmt der Roknabad,", "tokens": ["Wo\u00b7durch", "be\u00b7r\u00fchmt", "der", "Ro\u00b7kna\u00b7bad", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ber\u00fchmt Mosellas Hain geworden?", "tokens": ["Be\u00b7r\u00fchmt", "Mo\u00b7sel\u00b7las", "Hain", "ge\u00b7wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nicht ihre Sch\u00f6nheit war der Grund,", "tokens": ["Nicht", "ih\u00b7re", "Sch\u00f6n\u00b7heit", "war", "der", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Sch\u00f6neres auf Erden gibt es \u2013", "tokens": ["Viel", "Sch\u00f6\u00b7ne\u00b7res", "auf", "Er\u00b7den", "gibt", "es", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sind ber\u00fchmt durch dein Gedicht,", "tokens": ["Sie", "sind", "be\u00b7r\u00fchmt", "durch", "dein", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch dich, Hafis! allein geworden!", "tokens": ["Durch", "dich", ",", "Ha\u00b7fis", "!", "al\u00b7lein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "NE", "$.", "ADV", "VAPP", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Das Bonzentum hast du gest\u00fcrzt,", "tokens": ["Das", "Bon\u00b7zen\u00b7tum", "hast", "du", "ge\u00b7st\u00fcrzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Schiras' Ruhm hast du gegr\u00fcndet \u2013", "tokens": ["Und", "Schi\u00b7ras'", "Ruhm", "hast", "du", "ge\u00b7gr\u00fcn\u00b7det", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist durch dich das Kleine gro\u00df,", "tokens": ["Es", "ist", "durch", "dich", "das", "Klei\u00b7ne", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ART", "ADJA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch dich das Gro\u00dfe klein geworden!", "tokens": ["Durch", "dich", "das", "Gro\u00b7\u00dfe", "klein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Verherrlicht hast du Stadt und Hain,", "tokens": ["Ver\u00b7herr\u00b7licht", "hast", "du", "Stadt", "und", "Hain", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Versch\u00f6nt den Strom und seine Ufer \u2013", "tokens": ["Ver\u00b7sch\u00f6nt", "den", "Strom", "und", "sei\u00b7ne", "U\u00b7fer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch dich ist jeder Stein der Stadt", "tokens": ["Durch", "dich", "ist", "je\u00b7der", "Stein", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VAFIN", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einem Edelstein geworden!", "tokens": ["Zu", "ei\u00b7nem", "E\u00b7del\u00b7stein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Auch Tiflis ist an Sch\u00f6nheit reich,", "tokens": ["Auch", "Tif\u00b7lis", "ist", "an", "Sch\u00f6n\u00b7heit", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Rosen, Wein und schmucke M\u00e4dchen \u2013", "tokens": ["Hat", "Ro\u00b7sen", ",", "Wein", "und", "schmu\u00b7cke", "M\u00e4d\u00b7chen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und durch dich selbst Mirza-Schaffy,", "tokens": ["Und", "durch", "dich", "selbst", "Mir\u00b7za\u00b7Schaffy", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist auch ein S\u00e4nger sein geworden!", "tokens": ["Ist", "auch", "ein", "S\u00e4n\u00b7ger", "sein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VAINF", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Drum soll, was Schiras durch Hafis,", "tokens": ["Drum", "soll", ",", "was", "Schi\u00b7ras", "durch", "Ha\u00b7fis", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "$,", "PWS", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Tiflis durch deine Lieder werden \u2013", "tokens": ["Tif\u00b7lis", "durch", "dei\u00b7ne", "Lie\u00b7der", "wer\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VAINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn aller Zubeh\u00f6r ist dir", "tokens": ["Denn", "al\u00b7ler", "Zu\u00b7be\u00b7h\u00f6r", "ist", "dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im herrlichsten Verein geworden.", "tokens": ["Im", "herr\u00b7lichs\u00b7ten", "Ver\u00b7ein", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die stromdurchrauschte Gartenstadt,", "tokens": ["Die", "strom\u00b7durc\u00b7hrauschte", "Gar\u00b7ten\u00b7stadt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Umragt von himmelhohen Bergen,", "tokens": ["Um\u00b7ragt", "von", "him\u00b7mel\u00b7ho\u00b7hen", "Ber\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und was darinnen bl\u00fcht und lebt,", "tokens": ["Und", "was", "da\u00b7rin\u00b7nen", "bl\u00fcht", "und", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mirza-Schaffy! ist dein geworden!", "tokens": ["Mir\u00b7za\u00b7Schaffy", "!", "ist", "dein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VAFIN", "PPOSAT", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ihr sch\u00f6nen M\u00e4dchen (merkt euch das!)", "tokens": ["Ihr", "sch\u00f6\u00b7nen", "M\u00e4d\u00b7chen", "(", "merkt", "euch", "das", "!", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "VVFIN", "PPER", "PDS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh\u00f6rt jetzt mir und meinem Liede!", "tokens": ["Ge\u00b7h\u00f6rt", "jetzt", "mir", "und", "mei\u00b7nem", "Lie\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein sind nun Augen, Wang' und Mund", "tokens": ["Mein", "sind", "nun", "Au\u00b7gen", ",", "Wang'", "und", "Mund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "VAFIN", "ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Samt ihrem Glanz und Schein geworden!", "tokens": ["Samt", "ih\u00b7rem", "Glanz", "und", "Schein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Zum Paradiese wird mein Lied", "tokens": ["Zum", "Pa\u00b7ra\u00b7die\u00b7se", "wird", "mein", "Lied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Sch\u00f6nheit, Blumen, Wein und Liebe \u2013", "tokens": ["F\u00fcr", "Sch\u00f6n\u00b7heit", ",", "Blu\u00b7men", ",", "Wein", "und", "Lie\u00b7be", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was eingeht in dies Paradies,", "tokens": ["Was", "ein\u00b7geht", "in", "dies", "Pa\u00b7ra\u00b7dies", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PDS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist aller S\u00fcnden rein geworden!", "tokens": ["Ist", "al\u00b7ler", "S\u00fcn\u00b7den", "rein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Doch eine H\u00f6lle wird es sein", "tokens": ["Doch", "ei\u00b7ne", "H\u00f6l\u00b7le", "wird", "es", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Bonzen, Ku\u00df- und Weinver\u00e4chter \u2013", "tokens": ["F\u00fcr", "Bon\u00b7zen", ",", "Ku\u00df", "und", "Wein\u00b7ver\u00b7\u00e4ch\u00b7ter", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "TRUNC", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr dies Geschlecht ist jeder Vers", "tokens": ["F\u00fcr", "dies", "Ge\u00b7schlecht", "ist", "je\u00b7der", "Vers"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDS", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur St\u00e4tte ewiger Pein geworden!", "tokens": ["Zur", "St\u00e4t\u00b7te", "e\u00b7wi\u00b7ger", "Pein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "So soll durch alle Lande nun,", "tokens": ["So", "soll", "durch", "al\u00b7le", "Lan\u00b7de", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mirza-Schaffy, dein Lied ert\u00f6nen \u2013", "tokens": ["Mir\u00b7za\u00b7Schaffy", ",", "dein", "Lied", "er\u00b7t\u00f6\u00b7nen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr alles sch\u00f6ne Sein und Tun", "tokens": ["F\u00fcr", "al\u00b7les", "sch\u00f6\u00b7ne", "Sein", "und", "Tun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist es ein Widerschein geworden.", "tokens": ["Ist", "es", "ein", "Wi\u00b7der\u00b7schein", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Du sandtest deine J\u00fcnger aus,", "tokens": ["Du", "sand\u00b7test", "dei\u00b7ne", "J\u00fcn\u00b7ger", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und es geschah, wie du verhei\u00dfen:", "tokens": ["Und", "es", "ge\u00b7schah", ",", "wie", "du", "ver\u00b7hei\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ber\u00fchmt ist Tiflis durch dein Lied", "tokens": ["Be\u00b7r\u00fchmt", "ist", "Tif\u00b7lis", "durch", "dein", "Lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "NE", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Kyros bis zum Rhein geworden.", "tokens": ["Vom", "Ky\u00b7ros", "bis", "zum", "Rhein", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "APPR", "APPRART", "NE", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Wodurch ist Schiras wohl, die Stadt,", "tokens": ["Wo\u00b7durch", "ist", "Schi\u00b7ras", "wohl", ",", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "ADV", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ber\u00fchmt mit Ros' und Wein geworden?", "tokens": ["Be\u00b7r\u00fchmt", "mit", "Ros'", "und", "Wein", "ge\u00b7wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wodurch ber\u00fchmt der Roknabad,", "tokens": ["Wo\u00b7durch", "be\u00b7r\u00fchmt", "der", "Ro\u00b7kna\u00b7bad", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ber\u00fchmt Mosellas Hain geworden?", "tokens": ["Be\u00b7r\u00fchmt", "Mo\u00b7sel\u00b7las", "Hain", "ge\u00b7wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Nicht ihre Sch\u00f6nheit war der Grund,", "tokens": ["Nicht", "ih\u00b7re", "Sch\u00f6n\u00b7heit", "war", "der", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Sch\u00f6neres auf Erden gibt es \u2013", "tokens": ["Viel", "Sch\u00f6\u00b7ne\u00b7res", "auf", "Er\u00b7den", "gibt", "es", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sind ber\u00fchmt durch dein Gedicht,", "tokens": ["Sie", "sind", "be\u00b7r\u00fchmt", "durch", "dein", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch dich, Hafis! allein geworden!", "tokens": ["Durch", "dich", ",", "Ha\u00b7fis", "!", "al\u00b7lein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "NE", "$.", "ADV", "VAPP", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Das Bonzentum hast du gest\u00fcrzt,", "tokens": ["Das", "Bon\u00b7zen\u00b7tum", "hast", "du", "ge\u00b7st\u00fcrzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Schiras' Ruhm hast du gegr\u00fcndet \u2013", "tokens": ["Und", "Schi\u00b7ras'", "Ruhm", "hast", "du", "ge\u00b7gr\u00fcn\u00b7det", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist durch dich das Kleine gro\u00df,", "tokens": ["Es", "ist", "durch", "dich", "das", "Klei\u00b7ne", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ART", "ADJA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch dich das Gro\u00dfe klein geworden!", "tokens": ["Durch", "dich", "das", "Gro\u00b7\u00dfe", "klein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Verherrlicht hast du Stadt und Hain,", "tokens": ["Ver\u00b7herr\u00b7licht", "hast", "du", "Stadt", "und", "Hain", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Versch\u00f6nt den Strom und seine Ufer \u2013", "tokens": ["Ver\u00b7sch\u00f6nt", "den", "Strom", "und", "sei\u00b7ne", "U\u00b7fer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch dich ist jeder Stein der Stadt", "tokens": ["Durch", "dich", "ist", "je\u00b7der", "Stein", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VAFIN", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einem Edelstein geworden!", "tokens": ["Zu", "ei\u00b7nem", "E\u00b7del\u00b7stein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Auch Tiflis ist an Sch\u00f6nheit reich,", "tokens": ["Auch", "Tif\u00b7lis", "ist", "an", "Sch\u00f6n\u00b7heit", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Rosen, Wein und schmucke M\u00e4dchen \u2013", "tokens": ["Hat", "Ro\u00b7sen", ",", "Wein", "und", "schmu\u00b7cke", "M\u00e4d\u00b7chen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und durch dich selbst Mirza-Schaffy,", "tokens": ["Und", "durch", "dich", "selbst", "Mir\u00b7za\u00b7Schaffy", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist auch ein S\u00e4nger sein geworden!", "tokens": ["Ist", "auch", "ein", "S\u00e4n\u00b7ger", "sein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VAINF", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Drum soll, was Schiras durch Hafis,", "tokens": ["Drum", "soll", ",", "was", "Schi\u00b7ras", "durch", "Ha\u00b7fis", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "$,", "PWS", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Tiflis durch deine Lieder werden \u2013", "tokens": ["Tif\u00b7lis", "durch", "dei\u00b7ne", "Lie\u00b7der", "wer\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VAINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn aller Zubeh\u00f6r ist dir", "tokens": ["Denn", "al\u00b7ler", "Zu\u00b7be\u00b7h\u00f6r", "ist", "dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im herrlichsten Verein geworden.", "tokens": ["Im", "herr\u00b7lichs\u00b7ten", "Ver\u00b7ein", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Die stromdurchrauschte Gartenstadt,", "tokens": ["Die", "strom\u00b7durc\u00b7hrauschte", "Gar\u00b7ten\u00b7stadt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Umragt von himmelhohen Bergen,", "tokens": ["Um\u00b7ragt", "von", "him\u00b7mel\u00b7ho\u00b7hen", "Ber\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und was darinnen bl\u00fcht und lebt,", "tokens": ["Und", "was", "da\u00b7rin\u00b7nen", "bl\u00fcht", "und", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mirza-Schaffy! ist dein geworden!", "tokens": ["Mir\u00b7za\u00b7Schaffy", "!", "ist", "dein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VAFIN", "PPOSAT", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Ihr sch\u00f6nen M\u00e4dchen (merkt euch das!)", "tokens": ["Ihr", "sch\u00f6\u00b7nen", "M\u00e4d\u00b7chen", "(", "merkt", "euch", "das", "!", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "VVFIN", "PPER", "PDS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh\u00f6rt jetzt mir und meinem Liede!", "tokens": ["Ge\u00b7h\u00f6rt", "jetzt", "mir", "und", "mei\u00b7nem", "Lie\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein sind nun Augen, Wang' und Mund", "tokens": ["Mein", "sind", "nun", "Au\u00b7gen", ",", "Wang'", "und", "Mund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "VAFIN", "ADV", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Samt ihrem Glanz und Schein geworden!", "tokens": ["Samt", "ih\u00b7rem", "Glanz", "und", "Schein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Zum Paradiese wird mein Lied", "tokens": ["Zum", "Pa\u00b7ra\u00b7die\u00b7se", "wird", "mein", "Lied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Sch\u00f6nheit, Blumen, Wein und Liebe \u2013", "tokens": ["F\u00fcr", "Sch\u00f6n\u00b7heit", ",", "Blu\u00b7men", ",", "Wein", "und", "Lie\u00b7be", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was eingeht in dies Paradies,", "tokens": ["Was", "ein\u00b7geht", "in", "dies", "Pa\u00b7ra\u00b7dies", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PDS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist aller S\u00fcnden rein geworden!", "tokens": ["Ist", "al\u00b7ler", "S\u00fcn\u00b7den", "rein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Doch eine H\u00f6lle wird es sein", "tokens": ["Doch", "ei\u00b7ne", "H\u00f6l\u00b7le", "wird", "es", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Bonzen, Ku\u00df- und Weinver\u00e4chter \u2013", "tokens": ["F\u00fcr", "Bon\u00b7zen", ",", "Ku\u00df", "und", "Wein\u00b7ver\u00b7\u00e4ch\u00b7ter", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "TRUNC", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr dies Geschlecht ist jeder Vers", "tokens": ["F\u00fcr", "dies", "Ge\u00b7schlecht", "ist", "je\u00b7der", "Vers"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDS", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur St\u00e4tte ewiger Pein geworden!", "tokens": ["Zur", "St\u00e4t\u00b7te", "e\u00b7wi\u00b7ger", "Pein", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "So soll durch alle Lande nun,", "tokens": ["So", "soll", "durch", "al\u00b7le", "Lan\u00b7de", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mirza-Schaffy, dein Lied ert\u00f6nen \u2013", "tokens": ["Mir\u00b7za\u00b7Schaffy", ",", "dein", "Lied", "er\u00b7t\u00f6\u00b7nen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr alles sch\u00f6ne Sein und Tun", "tokens": ["F\u00fcr", "al\u00b7les", "sch\u00f6\u00b7ne", "Sein", "und", "Tun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist es ein Widerschein geworden.", "tokens": ["Ist", "es", "ein", "Wi\u00b7der\u00b7schein", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Du sandtest deine J\u00fcnger aus,", "tokens": ["Du", "sand\u00b7test", "dei\u00b7ne", "J\u00fcn\u00b7ger", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und es geschah, wie du verhei\u00dfen:", "tokens": ["Und", "es", "ge\u00b7schah", ",", "wie", "du", "ver\u00b7hei\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ber\u00fchmt ist Tiflis durch dein Lied", "tokens": ["Be\u00b7r\u00fchmt", "ist", "Tif\u00b7lis", "durch", "dein", "Lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "NE", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Kyros bis zum Rhein geworden.", "tokens": ["Vom", "Ky\u00b7ros", "bis", "zum", "Rhein", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "APPR", "APPRART", "NE", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}