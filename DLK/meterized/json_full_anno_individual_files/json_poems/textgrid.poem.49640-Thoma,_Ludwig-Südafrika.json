{"textgrid.poem.49640": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "S\u00fcdafrika", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir h\u00f6rten schon so manches St\u00fccklein melden", "tokens": ["Wir", "h\u00f6r\u00b7ten", "schon", "so", "man\u00b7ches", "St\u00fcck\u00b7lein", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zum ewigen Ruhme der englischen Helden.", "tokens": ["Zum", "e\u00b7wi\u00b7gen", "Ruh\u00b7me", "der", "eng\u00b7li\u00b7schen", "Hel\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Das beste blieb uns noch aufgehoben,", "tokens": ["Das", "bes\u00b7te", "blieb", "uns", "noch", "auf\u00b7ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wir d\u00fcrfen sie heute aufs neue loben.", "tokens": ["Wir", "d\u00fcr\u00b7fen", "sie", "heu\u00b7te", "aufs", "neu\u00b7e", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Erbittert nach den empfindlichen Hieben,", "tokens": ["Er\u00b7bit\u00b7tert", "nach", "den", "emp\u00b7find\u00b7li\u00b7chen", "Hie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Haben sie Weiber und Kinder zusammengetrieben.", "tokens": ["Ha\u00b7ben", "sie", "Wei\u00b7ber", "und", "Kin\u00b7der", "zu\u00b7sam\u00b7men\u00b7ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.7": {"text": "Die mu\u00dften in gl\u00fchender Sonne kampieren,", "tokens": ["Die", "mu\u00df\u00b7ten", "in", "gl\u00fc\u00b7hen\u00b7der", "Son\u00b7ne", "kam\u00b7pie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Wer's nicht vermochte, der konnte krepieren.", "tokens": ["Wer's", "nicht", "ver\u00b7moch\u00b7te", ",", "der", "konn\u00b7te", "kre\u00b7pie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVFIN", "$,", "PRELS", "VMFIN", "VVINF", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.9": {"text": "Die M\u00fctter sahen die Kleinen sterben", "tokens": ["Die", "M\u00fct\u00b7ter", "sa\u00b7hen", "die", "Klei\u00b7nen", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und mu\u00dften selber langsam verderben.", "tokens": ["Und", "mu\u00df\u00b7ten", "sel\u00b7ber", "lang\u00b7sam", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Konnten nicht helfen, konnten nur bitten;", "tokens": ["Konn\u00b7ten", "nicht", "hel\u00b7fen", ",", "konn\u00b7ten", "nur", "bit\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVINF", "$,", "VMFIN", "ADV", "VVINF", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Kein Mensch mag ermessen, was sie gelitten", "tokens": ["Kein", "Mensch", "mag", "er\u00b7mes\u00b7sen", ",", "was", "sie", "ge\u00b7lit\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$,", "PRELS", "PPER", "VVPP"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Um ihre Kinder. Was taten die Armen?", "tokens": ["Um", "ih\u00b7re", "Kin\u00b7der", ".", "Was", "ta\u00b7ten", "die", "Ar\u00b7men", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "$.", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Zum Teufel mit dem dummen Erbarmen!", "tokens": ["Zum", "Teu\u00b7fel", "mit", "dem", "dum\u00b7men", "Er\u00b7bar\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Es traf die V\u00e4ter, die sich erfrechten,", "tokens": ["Es", "traf", "die", "V\u00e4\u00b7ter", ",", "die", "sich", "er\u00b7frech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PRF", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Noch immer f\u00fcr Haus und Hof zu fechten.", "tokens": ["Noch", "im\u00b7mer", "f\u00fcr", "Haus", "und", "Hof", "zu", "fech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Die es vollbrachten, sind Christen gewesen,", "tokens": ["Die", "es", "voll\u00b7brach\u00b7ten", ",", "sind", "Chris\u00b7ten", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "VAFIN", "NN", "VAPP", "$,"], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "Die den Heiland tragen zu den Chinesen,", "tokens": ["Die", "den", "Hei\u00b7land", "tra\u00b7gen", "zu", "den", "Chi\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.19": {"text": "Und die Bibel von hinten bis vorne kennen,", "tokens": ["Und", "die", "Bi\u00b7bel", "von", "hin\u00b7ten", "bis", "vor\u00b7ne", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.20": {"text": "Und den lieben Gott ihren Duzfreund nennen.", "tokens": ["Und", "den", "lie\u00b7ben", "Gott", "ih\u00b7ren", "Duz\u00b7freund", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "--+-+---+--", "measure": "anapaest.init"}, "line.21": {"text": "Das St\u00fccklein von den blutigen Hunden,", "tokens": ["Das", "St\u00fcck\u00b7lein", "von", "den", "blu\u00b7ti\u00b7gen", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Das St\u00fccklein ist wahr! Nicht hat es erfunden", "tokens": ["Das", "St\u00fcck\u00b7lein", "ist", "wahr", "!", "Nicht", "hat", "es", "er\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PTKNEG", "VAFIN", "PPER", "VVPP"], "meter": "-+-++-+--+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Ein m\u00e4rchenschreibender Zeitungslenker.", "tokens": ["Ein", "m\u00e4r\u00b7chen\u00b7schrei\u00b7ben\u00b7der", "Zei\u00b7tungs\u00b7len\u00b7ker", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+--+---", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Und der es befohlen, der Weiberhenker,", "tokens": ["Und", "der", "es", "be\u00b7foh\u00b7len", ",", "der", "Wei\u00b7ber\u00b7hen\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVPP", "$,", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "Der tapfere Roberts \u2013 die Wahrheit ist bitter \u2013", "tokens": ["Der", "tap\u00b7fe\u00b7re", "Ro\u00b7berts", "\u2013", "die", "Wahr\u00b7heit", "ist", "bit\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.26": {"text": "Ist k\u00f6niglich preu\u00dfischer Ordensritter.", "tokens": ["Ist", "k\u00f6\u00b7nig\u00b7lich", "preu\u00b7\u00dfi\u00b7scher", "Or\u00b7dens\u00b7rit\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.2": {"line.1": {"text": "Wir h\u00f6rten schon so manches St\u00fccklein melden", "tokens": ["Wir", "h\u00f6r\u00b7ten", "schon", "so", "man\u00b7ches", "St\u00fcck\u00b7lein", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zum ewigen Ruhme der englischen Helden.", "tokens": ["Zum", "e\u00b7wi\u00b7gen", "Ruh\u00b7me", "der", "eng\u00b7li\u00b7schen", "Hel\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Das beste blieb uns noch aufgehoben,", "tokens": ["Das", "bes\u00b7te", "blieb", "uns", "noch", "auf\u00b7ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wir d\u00fcrfen sie heute aufs neue loben.", "tokens": ["Wir", "d\u00fcr\u00b7fen", "sie", "heu\u00b7te", "aufs", "neu\u00b7e", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Erbittert nach den empfindlichen Hieben,", "tokens": ["Er\u00b7bit\u00b7tert", "nach", "den", "emp\u00b7find\u00b7li\u00b7chen", "Hie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Haben sie Weiber und Kinder zusammengetrieben.", "tokens": ["Ha\u00b7ben", "sie", "Wei\u00b7ber", "und", "Kin\u00b7der", "zu\u00b7sam\u00b7men\u00b7ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.7": {"text": "Die mu\u00dften in gl\u00fchender Sonne kampieren,", "tokens": ["Die", "mu\u00df\u00b7ten", "in", "gl\u00fc\u00b7hen\u00b7der", "Son\u00b7ne", "kam\u00b7pie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Wer's nicht vermochte, der konnte krepieren.", "tokens": ["Wer's", "nicht", "ver\u00b7moch\u00b7te", ",", "der", "konn\u00b7te", "kre\u00b7pie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVFIN", "$,", "PRELS", "VMFIN", "VVINF", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.9": {"text": "Die M\u00fctter sahen die Kleinen sterben", "tokens": ["Die", "M\u00fct\u00b7ter", "sa\u00b7hen", "die", "Klei\u00b7nen", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und mu\u00dften selber langsam verderben.", "tokens": ["Und", "mu\u00df\u00b7ten", "sel\u00b7ber", "lang\u00b7sam", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Konnten nicht helfen, konnten nur bitten;", "tokens": ["Konn\u00b7ten", "nicht", "hel\u00b7fen", ",", "konn\u00b7ten", "nur", "bit\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVINF", "$,", "VMFIN", "ADV", "VVINF", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Kein Mensch mag ermessen, was sie gelitten", "tokens": ["Kein", "Mensch", "mag", "er\u00b7mes\u00b7sen", ",", "was", "sie", "ge\u00b7lit\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$,", "PRELS", "PPER", "VVPP"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Um ihre Kinder. Was taten die Armen?", "tokens": ["Um", "ih\u00b7re", "Kin\u00b7der", ".", "Was", "ta\u00b7ten", "die", "Ar\u00b7men", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "$.", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Zum Teufel mit dem dummen Erbarmen!", "tokens": ["Zum", "Teu\u00b7fel", "mit", "dem", "dum\u00b7men", "Er\u00b7bar\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Es traf die V\u00e4ter, die sich erfrechten,", "tokens": ["Es", "traf", "die", "V\u00e4\u00b7ter", ",", "die", "sich", "er\u00b7frech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PRF", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Noch immer f\u00fcr Haus und Hof zu fechten.", "tokens": ["Noch", "im\u00b7mer", "f\u00fcr", "Haus", "und", "Hof", "zu", "fech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Die es vollbrachten, sind Christen gewesen,", "tokens": ["Die", "es", "voll\u00b7brach\u00b7ten", ",", "sind", "Chris\u00b7ten", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "VAFIN", "NN", "VAPP", "$,"], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "Die den Heiland tragen zu den Chinesen,", "tokens": ["Die", "den", "Hei\u00b7land", "tra\u00b7gen", "zu", "den", "Chi\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.19": {"text": "Und die Bibel von hinten bis vorne kennen,", "tokens": ["Und", "die", "Bi\u00b7bel", "von", "hin\u00b7ten", "bis", "vor\u00b7ne", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.20": {"text": "Und den lieben Gott ihren Duzfreund nennen.", "tokens": ["Und", "den", "lie\u00b7ben", "Gott", "ih\u00b7ren", "Duz\u00b7freund", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "--+-+---+--", "measure": "anapaest.init"}, "line.21": {"text": "Das St\u00fccklein von den blutigen Hunden,", "tokens": ["Das", "St\u00fcck\u00b7lein", "von", "den", "blu\u00b7ti\u00b7gen", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Das St\u00fccklein ist wahr! Nicht hat es erfunden", "tokens": ["Das", "St\u00fcck\u00b7lein", "ist", "wahr", "!", "Nicht", "hat", "es", "er\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PTKNEG", "VAFIN", "PPER", "VVPP"], "meter": "-+-++-+--+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Ein m\u00e4rchenschreibender Zeitungslenker.", "tokens": ["Ein", "m\u00e4r\u00b7chen\u00b7schrei\u00b7ben\u00b7der", "Zei\u00b7tungs\u00b7len\u00b7ker", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+--+---", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Und der es befohlen, der Weiberhenker,", "tokens": ["Und", "der", "es", "be\u00b7foh\u00b7len", ",", "der", "Wei\u00b7ber\u00b7hen\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVPP", "$,", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "Der tapfere Roberts \u2013 die Wahrheit ist bitter \u2013", "tokens": ["Der", "tap\u00b7fe\u00b7re", "Ro\u00b7berts", "\u2013", "die", "Wahr\u00b7heit", "ist", "bit\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.26": {"text": "Ist k\u00f6niglich preu\u00dfischer Ordensritter.", "tokens": ["Ist", "k\u00f6\u00b7nig\u00b7lich", "preu\u00b7\u00dfi\u00b7scher", "Or\u00b7dens\u00b7rit\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}}}}