{"dta.poem.19225": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "72.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195090", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Aus Aeu\u00dferm f\u00fchlst du dich und Innerem zusammen", "tokens": ["Aus", "A\u00b7e\u00b7u\u00b7\u00dferm", "f\u00fchlst", "du", "dich", "und", "In\u00b7ne\u00b7rem", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PRF", "KON", "NE", "PTKVZ"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Gesetzt, o Mensch, die von verschiednen Enden stammen.", "tokens": ["Ge\u00b7setzt", ",", "o", "Mensch", ",", "die", "von", "ver\u00b7schied\u00b7nen", "En\u00b7den", "stam\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "FM", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch deine Aufgab' ist, die beiden auszugleichen,", "tokens": ["Doch", "dei\u00b7ne", "Auf\u00b7gab'", "ist", ",", "die", "bei\u00b7den", "aus\u00b7zu\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "$,", "PRELS", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und weder hier vom Pfad noch dorthin auszuweichen.", "tokens": ["Und", "we\u00b7der", "hier", "vom", "Pfad", "noch", "dor\u00b7thin", "aus\u00b7zu\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KON", "ADV", "APPRART", "NN", "ADV", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Zu \u00e4u\u00dfern Inneres und Aeu\u00dfres zu verinnern,", "tokens": ["Zu", "\u00e4u\u00b7\u00dfern", "In\u00b7ne\u00b7res", "und", "A\u00b7e\u00b7u\u00df\u00b7res", "zu", "ver\u00b7in\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Das ist der Dinge Recht, der \u00e4u\u00dfern und der innern.", "tokens": ["Das", "ist", "der", "Din\u00b7ge", "Recht", ",", "der", "\u00e4u\u00b7\u00dfern", "und", "der", "in\u00b7nern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$,", "ART", "ADJA", "KON", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Zu \u00e4u\u00dfern Inneres und Aeu\u00dfres zu verinnern,", "tokens": ["Zu", "\u00e4u\u00b7\u00dfern", "In\u00b7ne\u00b7res", "und", "A\u00b7e\u00b7u\u00df\u00b7res", "zu", "ver\u00b7in\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Ist Geistes Aeu\u00dferung und geistiges Erinnern.", "tokens": ["Ist", "Geis\u00b7tes", "A\u00b7e\u00b7u\u00b7\u00dfe\u00b7rung", "und", "geis\u00b7ti\u00b7ges", "E\u00b7rin\u00b7nern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.5": {"line.1": {"text": "Sich \u00e4u\u00dfern soll der Geist, nicht aber sich ver\u00e4u\u00dfern;", "tokens": ["Sich", "\u00e4u\u00b7\u00dfern", "soll", "der", "Geist", ",", "nicht", "a\u00b7ber", "sich", "ver\u00b7\u00e4u\u00b7\u00dfern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "VMFIN", "ART", "NN", "$,", "PTKNEG", "ADV", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die innern Regungen sind nicht ein Spiel der \u00e4u\u00dfern.", "tokens": ["Die", "in\u00b7nern", "Re\u00b7gun\u00b7gen", "sind", "nicht", "ein", "Spiel", "der", "\u00e4u\u00b7\u00dfern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKNEG", "ART", "NN", "ART", "ADJA", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Dein Innres \u00fcberwiegt dem Aeu\u00dfern, das sagt sinnig", "tokens": ["Dein", "Inn\u00b7res", "\u00fc\u00b7berw\u00b7iegt", "dem", "A\u00b7e\u00b7u\u00b7\u00dfern", ",", "das", "sagt", "sin\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,", "PDS", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Die Sprache schon, die bei dem Innern gab ein Innig.", "tokens": ["Die", "Spra\u00b7che", "schon", ",", "die", "bei", "dem", "In\u00b7nern", "gab", "ein", "In\u00b7nig", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Drum h\u00fcte dich, mein Sohn, je au\u00dfer dich zu kommen;", "tokens": ["Drum", "h\u00fc\u00b7te", "dich", ",", "mein", "Sohn", ",", "je", "au\u00b7\u00dfer", "dich", "zu", "kom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ists geschehn, so wird in dich zu gehn dir frommen.", "tokens": ["Und", "ists", "ge\u00b7schehn", ",", "so", "wird", "in", "dich", "zu", "gehn", "dir", "from\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$,", "ADV", "VAFIN", "APPR", "PPER", "PTKZU", "VVINF", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Aus ihrem Innern durch Naturtrieb nimmt die Flucht", "tokens": ["Aus", "ih\u00b7rem", "In\u00b7nern", "durch", "Na\u00b7tur\u00b7trieb", "nimmt", "die", "Flucht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Pflanze, bis sie sich erinnert in der Frucht.", "tokens": ["Die", "Pflan\u00b7ze", ",", "bis", "sie", "sich", "e\u00b7rin\u00b7nert", "in", "der", "Frucht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Doch ganz ist \u00e4u\u00dferlich geworden Stein und Erz,", "tokens": ["Doch", "ganz", "ist", "\u00e4u\u00b7\u00dfer\u00b7lich", "ge\u00b7wor\u00b7den", "Stein", "und", "Erz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADJD", "VAPP", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kann nicht mehr in sich gehn, wie ein verh\u00e4rtet Herz.", "tokens": ["Kann", "nicht", "mehr", "in", "sich", "gehn", ",", "wie", "ein", "ver\u00b7h\u00e4r\u00b7tet", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "APPR", "PRF", "VVINF", "$,", "PWAV", "ART", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Darum mu\u00df \u00e4u\u00dferlich der Stein sich lassen w\u00e4lzen", "tokens": ["Da\u00b7rum", "mu\u00df", "\u00e4u\u00b7\u00dfer\u00b7lich", "der", "Stein", "sich", "las\u00b7sen", "w\u00e4l\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "ADJD", "ART", "NN", "PRF", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von Fluten, und das Erz von Feuergluten schmelzen.", "tokens": ["Von", "Flu\u00b7ten", ",", "und", "das", "Erz", "von", "Feu\u00b7er\u00b7glu\u00b7ten", "schmel\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KON", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Doch wem die \u00e4u\u00dfern gleich sind und die innern Enden,", "tokens": ["Doch", "wem", "die", "\u00e4u\u00b7\u00dfern", "gleich", "sind", "und", "die", "in\u00b7nern", "En\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "ADV", "VAFIN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der ist ein Handschuh, nach Belieben umzuwenden,", "tokens": ["Der", "ist", "ein", "Hand\u00b7schuh", ",", "nach", "Be\u00b7lie\u00b7ben", "um\u00b7zu\u00b7wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "APPR", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Und h\u00f6chstens ein Polyp, den es nicht im Behagen", "tokens": ["Und", "h\u00f6chs\u00b7tens", "ein", "Po\u00b7lyp", ",", "den", "es", "nicht", "im", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "APPRART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "St\u00f6rt, wenn sein Magen wird zur Haut, die Haut zum Magen.", "tokens": ["St\u00f6rt", ",", "wenn", "sein", "Ma\u00b7gen", "wird", "zur", "Haut", ",", "die", "Haut", "zum", "Ma\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPOSAT", "NN", "VAFIN", "APPRART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}