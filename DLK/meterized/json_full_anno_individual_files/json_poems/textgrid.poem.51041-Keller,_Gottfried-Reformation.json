{"textgrid.poem.51041": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Reformation", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Bauch der Pyramide tief begraben,", "tokens": ["Im", "Bauch", "der", "Py\u00b7ra\u00b7mi\u00b7de", "tief", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In einer Mumie schwarzer Totenhand", "tokens": ["In", "ei\u00b7ner", "Mu\u00b7mie", "schwar\u00b7zer", "To\u00b7ten\u00b7hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War's, da\u00df man alte Weizenk\u00f6rner fand,", "tokens": ["Wa\u00b7r's", ",", "da\u00df", "man", "al\u00b7te", "Wei\u00b7zen\u00b7k\u00f6r\u00b7ner", "fand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PIS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die dort Jahrtausende geschlummert haben.", "tokens": ["Die", "dort", "Jahr\u00b7tau\u00b7sen\u00b7de", "ge\u00b7schlum\u00b7mert", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Und pr\u00fcfend nahm man diese seltnen Gaben", "tokens": ["Und", "pr\u00fc\u00b7fend", "nahm", "man", "die\u00b7se", "selt\u00b7nen", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und warf sie in lebendig Ackerland,", "tokens": ["Und", "warf", "sie", "in", "le\u00b7ben\u00b7dig", "A\u00b7cker\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJD", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und siehe da! die goldne Saat erstand,", "tokens": ["Und", "sie\u00b7he", "da", "!", "die", "gold\u00b7ne", "Saat", "er\u00b7stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ADV", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Des Volkes Herz und Auge zu erlaben!", "tokens": ["Des", "Vol\u00b7kes", "Herz", "und", "Au\u00b7ge", "zu", "er\u00b7la\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "So bl\u00fcht die Frucht dem sp\u00e4ten Nachweltskinde,", "tokens": ["So", "bl\u00fcht", "die", "Frucht", "dem", "sp\u00e4\u00b7ten", "Nach\u00b7welts\u00b7kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die mit den Ahnen schlief in Grabes Scho\u00df;", "tokens": ["Die", "mit", "den", "Ah\u00b7nen", "schlief", "in", "Gra\u00b7bes", "Scho\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Sterben ist ein endlos Auferstehn.", "tokens": ["Das", "Ster\u00b7ben", "ist", "ein", "end\u00b7los", "Auf\u00b7er\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wer hindert nun, da\u00df wieder man entwinde", "tokens": ["Wer", "hin\u00b7dert", "nun", ",", "da\u00df", "wie\u00b7der", "man", "ent\u00b7win\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "ADV", "PIS", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Kirche Mumienhand, was sie verschlo\u00df,", "tokens": ["Der", "Kir\u00b7che", "Mu\u00b7mi\u00b7en\u00b7hand", ",", "was", "sie", "ver\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das Korn des Wortes, neu es auszus\u00e4n?", "tokens": ["Das", "Korn", "des", "Wor\u00b7tes", ",", "neu", "es", "aus\u00b7zu\u00b7s\u00e4n", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ADJD", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Im Bauch der Pyramide tief begraben,", "tokens": ["Im", "Bauch", "der", "Py\u00b7ra\u00b7mi\u00b7de", "tief", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In einer Mumie schwarzer Totenhand", "tokens": ["In", "ei\u00b7ner", "Mu\u00b7mie", "schwar\u00b7zer", "To\u00b7ten\u00b7hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War's, da\u00df man alte Weizenk\u00f6rner fand,", "tokens": ["Wa\u00b7r's", ",", "da\u00df", "man", "al\u00b7te", "Wei\u00b7zen\u00b7k\u00f6r\u00b7ner", "fand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PIS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die dort Jahrtausende geschlummert haben.", "tokens": ["Die", "dort", "Jahr\u00b7tau\u00b7sen\u00b7de", "ge\u00b7schlum\u00b7mert", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und pr\u00fcfend nahm man diese seltnen Gaben", "tokens": ["Und", "pr\u00fc\u00b7fend", "nahm", "man", "die\u00b7se", "selt\u00b7nen", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und warf sie in lebendig Ackerland,", "tokens": ["Und", "warf", "sie", "in", "le\u00b7ben\u00b7dig", "A\u00b7cker\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJD", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und siehe da! die goldne Saat erstand,", "tokens": ["Und", "sie\u00b7he", "da", "!", "die", "gold\u00b7ne", "Saat", "er\u00b7stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ADV", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Des Volkes Herz und Auge zu erlaben!", "tokens": ["Des", "Vol\u00b7kes", "Herz", "und", "Au\u00b7ge", "zu", "er\u00b7la\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "So bl\u00fcht die Frucht dem sp\u00e4ten Nachweltskinde,", "tokens": ["So", "bl\u00fcht", "die", "Frucht", "dem", "sp\u00e4\u00b7ten", "Nach\u00b7welts\u00b7kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die mit den Ahnen schlief in Grabes Scho\u00df;", "tokens": ["Die", "mit", "den", "Ah\u00b7nen", "schlief", "in", "Gra\u00b7bes", "Scho\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Sterben ist ein endlos Auferstehn.", "tokens": ["Das", "Ster\u00b7ben", "ist", "ein", "end\u00b7los", "Auf\u00b7er\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wer hindert nun, da\u00df wieder man entwinde", "tokens": ["Wer", "hin\u00b7dert", "nun", ",", "da\u00df", "wie\u00b7der", "man", "ent\u00b7win\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "$,", "KOUS", "ADV", "PIS", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Kirche Mumienhand, was sie verschlo\u00df,", "tokens": ["Der", "Kir\u00b7che", "Mu\u00b7mi\u00b7en\u00b7hand", ",", "was", "sie", "ver\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das Korn des Wortes, neu es auszus\u00e4n?", "tokens": ["Das", "Korn", "des", "Wor\u00b7tes", ",", "neu", "es", "aus\u00b7zu\u00b7s\u00e4n", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ADJD", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}