{"textgrid.poem.43260": {"metadata": {"author": {"name": "Christen, Ada", "birth": "N.A.", "death": "N.A."}, "title": "1L: O lacht nicht", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O lacht nicht", "tokens": ["O", "lacht", "nicht"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Und z\u00fcrnt nicht ...", "tokens": ["Und", "z\u00fcrnt", "nicht", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$("], "meter": "++-", "measure": "unknown.measure.di"}, "line.3": {"text": "Ich st\u00fcrzte mich gern", "tokens": ["Ich", "st\u00fcrz\u00b7te", "mich", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "In das rauschende Leben,", "tokens": ["In", "das", "rau\u00b7schen\u00b7de", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Ich m\u00f6chte ja gern", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ja", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Den Becher erheben,", "tokens": ["Den", "Be\u00b7cher", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Den sch\u00e4umenden Becher", "tokens": ["Den", "sch\u00e4u\u00b7men\u00b7den", "Be\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Der Daseinslust.", "tokens": ["Der", "Da\u00b7seins\u00b7lust", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.9": {"text": "Ich m\u00f6chte sprechen", "tokens": ["Ich", "m\u00f6ch\u00b7te", "spre\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "In Euren Sprachen,", "tokens": ["In", "Eu\u00b7ren", "Spra\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Ihr frohen Zecher;", "tokens": ["Ihr", "fro\u00b7hen", "Ze\u00b7cher", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Aus tiefer Brust", "tokens": ["Aus", "tie\u00b7fer", "Brust"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Nur einmal lachen,", "tokens": ["Nur", "ein\u00b7mal", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "So lachen wie Ihr ...", "tokens": ["So", "la\u00b7chen", "wie", "Ihr", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KOKOM", "PPOSAT", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Wie Ihr m\u00f6cht ich brechen", "tokens": ["Wie", "Ihr", "m\u00f6cht", "ich", "bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "Der Trauer Schranken", "tokens": ["Der", "Trau\u00b7er", "Schran\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Und in ein Vergessen", "tokens": ["Und", "in", "ein", "Ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.18": {"text": "Hin\u00fcberschwanken ...", "tokens": ["Hin\u00b7\u00fc\u00b7bersc\u00b7hwan\u00b7ken", "..."], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Ich m\u00f6chte gedankenlos-klein", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ge\u00b7dan\u00b7ken\u00b7los\u00b7klein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.20": {"text": "Nach allem Nichtigen fassen,", "tokens": ["Nach", "al\u00b7lem", "Nich\u00b7ti\u00b7gen", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "Das Unbedeutende preisen,", "tokens": ["Das", "Un\u00b7be\u00b7deu\u00b7ten\u00b7de", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.22": {"text": "Das Gro\u00dfe unbewu\u00dft hassen \u2013", "tokens": ["Das", "Gro\u00b7\u00dfe", "un\u00b7be\u00b7wu\u00dft", "has\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Wie Ihr seid, m\u00f6cht ich sein.", "tokens": ["Wie", "Ihr", "seid", ",", "m\u00f6cht", "ich", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "$,", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Doch was ich h\u00f6rte", "tokens": ["Doch", "was", "ich", "h\u00f6r\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Und was ich schaute,", "tokens": ["Und", "was", "ich", "schau\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Es macht mich einsam,", "tokens": ["Es", "macht", "mich", "ein\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Mein Geist, der beth\u00f6rte", "tokens": ["Mein", "Geist", ",", "der", "be\u00b7th\u00f6r\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Hat nicht die Laute", "tokens": ["Hat", "nicht", "die", "Lau\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Des Schmerzes gemeinsam", "tokens": ["Des", "Schmer\u00b7zes", "ge\u00b7mein\u00b7sam"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ADJD"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Mit gleichen Creaturen.", "tokens": ["Mit", "glei\u00b7chen", "Crea\u00b7tu\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Und darum f\u00fcrchte ich Alle,", "tokens": ["Und", "da\u00b7rum", "f\u00fcrch\u00b7te", "ich", "Al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es g\u00e4hnt mich drohend an", "tokens": ["Es", "g\u00e4hnt", "mich", "dro\u00b7hend", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Die feindliche Schaalheit", "tokens": ["Die", "feind\u00b7li\u00b7che", "Scha\u00b7al\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Der fremden Naturen,", "tokens": ["Der", "frem\u00b7den", "Na\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "Da\u00df ich nicht glauben kann,", "tokens": ["Da\u00df", "ich", "nicht", "glau\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Ich z\u00e4hle zu ihrer Allheit ...", "tokens": ["Ich", "z\u00e4h\u00b7le", "zu", "ih\u00b7rer", "All\u00b7heit", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Aus Euren Bahnen", "tokens": ["Aus", "Eu\u00b7ren", "Bah\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Hinausgedr\u00e4ngt,", "tokens": ["Hin\u00b7aus\u00b7ge\u00b7dr\u00e4ngt", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "In Wissen und Ahnen", "tokens": ["In", "Wis\u00b7sen", "und", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Begrenzt und beengt,", "tokens": ["Be\u00b7grenzt", "und", "be\u00b7engt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Im innersten Wesen", "tokens": ["Im", "in\u00b7ners\u00b7ten", "We\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Zerrissen ... Allein!", "tokens": ["Zer\u00b7ris\u00b7sen", "...", "Al\u00b7lein", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Und kein Genesen", "tokens": ["Und", "kein", "Ge\u00b7ne\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Von dieser Pein.", "tokens": ["Von", "die\u00b7ser", "Pein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Immer \u2013 immer \u2013 immer", "tokens": ["Im\u00b7mer", "\u2013", "im\u00b7mer", "\u2013", "im\u00b7mer"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["ADV", "$(", "ADV", "$(", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mitschleppen die Begrenzung,", "tokens": ["Mit\u00b7schlep\u00b7pen", "die", "Be\u00b7gren\u00b7zung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Den Leib, den eignen Widerpart!", "tokens": ["Den", "Leib", ",", "den", "eig\u00b7nen", "Wi\u00b7der\u00b7part", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo bleibt die Erg\u00e4nzung?", "tokens": ["Wo", "bleibt", "die", "Er\u00b7g\u00e4n\u00b7zung", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Wo bleibt die Hand,", "tokens": ["Wo", "bleibt", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Die wegfegt alle M\u00e4ngel", "tokens": ["Die", "weg\u00b7fegt", "al\u00b7le", "M\u00e4n\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und alle Halbheit einigt?", "tokens": ["Und", "al\u00b7le", "Halb\u00b7heit", "ei\u00b7nigt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die jenes Wesen, das stets", "tokens": ["Die", "je\u00b7nes", "We\u00b7sen", ",", "das", "stets"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PDAT", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Thier und Engel,", "tokens": ["Thier", "und", "En\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Zum Menschenbilde reinigt?", "tokens": ["Zum", "Men\u00b7schen\u00b7bil\u00b7de", "rei\u00b7nigt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Kann Herz und Hirn", "tokens": ["Kann", "Herz", "und", "Hirn"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Nicht tr\u00f6stend Antwort geben?", "tokens": ["Nicht", "tr\u00f6s\u00b7tend", "Ant\u00b7wort", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Nicht das Gestirn,", "tokens": ["Nicht", "das", "Ge\u00b7stirn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Das geb\u00e4rende Leben?!", "tokens": ["Das", "ge\u00b7b\u00e4\u00b7ren\u00b7de", "Le\u00b7ben", "?!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.15": {"text": ". . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.5": {"line.1": {"text": "Nein! Vertilgt ist jenes Schrittes Spur,", "tokens": ["Nein", "!", "Ver\u00b7tilgt", "ist", "je\u00b7nes", "Schrit\u00b7tes", "Spur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVPP", "VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die von dem Aether f\u00fchrt zum Staube,", "tokens": ["Die", "von", "dem", "A\u00b7e\u00b7ther", "f\u00fchrt", "zum", "Stau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Des Suchens Thorheit blieb mir nur:", "tokens": ["Des", "Su\u00b7chens", "Thor\u00b7heit", "blieb", "mir", "nur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Unwissenheit! ... Kinderglaube ...", "tokens": ["Un\u00b7wis\u00b7sen\u00b7heit", "!", "...", "Kin\u00b7der\u00b7glau\u00b7be", "..."], "token_info": ["word", "punct", "punct", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Oder trostlose Einsamkeit.", "tokens": ["O\u00b7der", "trost\u00b7lo\u00b7se", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Einsamkeit ohne Vergessenheit!", "tokens": ["Ein\u00b7sam\u00b7keit", "oh\u00b7ne", "Ver\u00b7ges\u00b7sen\u00b7heit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Ein h\u00fclfloser Schrei", "tokens": ["Ein", "h\u00fcl\u00b7flo\u00b7ser", "Schrei"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ins Leere ... ohne Erh\u00f6rung,", "tokens": ["Ins", "Lee\u00b7re", "...", "oh\u00b7ne", "Er\u00b7h\u00f6\u00b7rung", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Oder ein j\u00e4her Blitz:", "tokens": ["O\u00b7der", "ein", "j\u00e4\u00b7her", "Blitz", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Vernichtung ... Zerst\u00f6rung!", "tokens": ["Ver\u00b7nich\u00b7tung", "...", "Zer\u00b7st\u00f6\u00b7rung", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Vernichtung! Zerst\u00f6rung!", "tokens": ["Ver\u00b7nich\u00b7tung", "!", "Zer\u00b7st\u00f6\u00b7rung", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Das alte Erl\u00f6sungswort,", "tokens": ["Das", "al\u00b7te", "Er\u00b7l\u00f6\u00b7sungs\u00b7wort", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Es klingt voll s\u00fc\u00dfer Beth\u00f6rung", "tokens": ["Es", "klingt", "voll", "s\u00fc\u00b7\u00dfer", "Be\u00b7th\u00f6\u00b7rung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Durch alles Elend fort ...", "tokens": ["Durch", "al\u00b7les", "E\u00b7lend", "fort", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Wer aber wei\u00df, wie viel dann untergeht,", "tokens": ["Wer", "a\u00b7ber", "wei\u00df", ",", "wie", "viel", "dann", "un\u00b7ter\u00b7geht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ob in Atomen tausendfach zersplittert", "tokens": ["Ob", "in", "A\u00b7to\u00b7men", "tau\u00b7send\u00b7fach", "zer\u00b7split\u00b7tert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Nicht etwas K\u00f6rperloses fortbesteht,", "tokens": ["Nicht", "et\u00b7was", "K\u00f6r\u00b7per\u00b7lo\u00b7ses", "fort\u00b7be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "In dem das Lebenselend ", "tokens": ["In", "dem", "das", "Le\u00b7ben\u00b7se\u00b7lend"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Wo sind sie Alle jene Zwitterwesen,", "tokens": ["Wo", "sind", "sie", "Al\u00b7le", "je\u00b7ne", "Zwit\u00b7ter\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PIAT", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die leidensm\u00fcde riefen solche Klagen?", "tokens": ["Die", "lei\u00b7dens\u00b7m\u00fc\u00b7de", "rie\u00b7fen", "sol\u00b7che", "Kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Auf welchem Stern vermochten sie zu lesen", "tokens": ["Auf", "wel\u00b7chem", "Stern", "ver\u00b7moch\u00b7ten", "sie", "zu", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Die d\u00fcrre Antwort ihrer tollen Fragen?", "tokens": ["Die", "d\u00fcr\u00b7re", "Ant\u00b7wort", "ih\u00b7rer", "tol\u00b7len", "Fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Wenn ihnen die Vernichtung nur allein", "tokens": ["Wenn", "ih\u00b7nen", "die", "Ver\u00b7nich\u00b7tung", "nur", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Des Daseinsr\u00e4thsels L\u00f6sung konnte sagen \u2013", "tokens": ["Des", "Da\u00b7seins\u00b7r\u00e4th\u00b7sels", "L\u00f6\u00b7sung", "konn\u00b7te", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Was frommt es uns? ... Der kalte Leichenstein", "tokens": ["Was", "frommt", "es", "uns", "?", "...", "Der", "kal\u00b7te", "Lei\u00b7chen\u00b7stein"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$.", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Er k\u00fcndet Wahnsinn \u2013 oder feiges Zagen.", "tokens": ["Er", "k\u00fcn\u00b7det", "Wahn\u00b7sinn", "\u2013", "o\u00b7der", "fei\u00b7ges", "Za\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$("]}}, "stanza.7": {"line.1": {"text": "O lacht nicht", "tokens": ["O", "lacht", "nicht"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Und z\u00fcrnt nicht;", "tokens": ["Und", "z\u00fcrnt", "nicht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$."], "meter": "++-", "measure": "unknown.measure.di"}, "line.3": {"text": "Ich st\u00fcrzte mich gern", "tokens": ["Ich", "st\u00fcrz\u00b7te", "mich", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "In das rauschende Leben,", "tokens": ["In", "das", "rau\u00b7schen\u00b7de", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Ich m\u00f6chte ja gern", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ja", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Den Becher erheben,", "tokens": ["Den", "Be\u00b7cher", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Den sch\u00e4umenden Becher", "tokens": ["Den", "sch\u00e4u\u00b7men\u00b7den", "Be\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Der Lebenslust.", "tokens": ["Der", "Le\u00b7bens\u00b7lust", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Doch ich f\u00fcrchte sie Alle", "tokens": ["Doch", "ich", "f\u00fcrch\u00b7te", "sie", "Al\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PIAT"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Die frohen Zecher,", "tokens": ["Die", "fro\u00b7hen", "Ze\u00b7cher", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Denn in meiner Brust", "tokens": ["Denn", "in", "mei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.12": {"text": "Ringt Tod und Leben ...", "tokens": ["Ringt", "Tod", "und", "Le\u00b7ben", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "Ich bin allein!", "tokens": ["Ich", "bin", "al\u00b7lein", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "O lacht nicht", "tokens": ["O", "lacht", "nicht"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Und z\u00fcrnt nicht ...", "tokens": ["Und", "z\u00fcrnt", "nicht", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$("], "meter": "++-", "measure": "unknown.measure.di"}, "line.3": {"text": "Ich st\u00fcrzte mich gern", "tokens": ["Ich", "st\u00fcrz\u00b7te", "mich", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "In das rauschende Leben,", "tokens": ["In", "das", "rau\u00b7schen\u00b7de", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Ich m\u00f6chte ja gern", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ja", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Den Becher erheben,", "tokens": ["Den", "Be\u00b7cher", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Den sch\u00e4umenden Becher", "tokens": ["Den", "sch\u00e4u\u00b7men\u00b7den", "Be\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Der Daseinslust.", "tokens": ["Der", "Da\u00b7seins\u00b7lust", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.9": {"text": "Ich m\u00f6chte sprechen", "tokens": ["Ich", "m\u00f6ch\u00b7te", "spre\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "In Euren Sprachen,", "tokens": ["In", "Eu\u00b7ren", "Spra\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Ihr frohen Zecher;", "tokens": ["Ihr", "fro\u00b7hen", "Ze\u00b7cher", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Aus tiefer Brust", "tokens": ["Aus", "tie\u00b7fer", "Brust"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Nur einmal lachen,", "tokens": ["Nur", "ein\u00b7mal", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "So lachen wie Ihr ...", "tokens": ["So", "la\u00b7chen", "wie", "Ihr", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KOKOM", "PPOSAT", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Wie Ihr m\u00f6cht ich brechen", "tokens": ["Wie", "Ihr", "m\u00f6cht", "ich", "bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "Der Trauer Schranken", "tokens": ["Der", "Trau\u00b7er", "Schran\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Und in ein Vergessen", "tokens": ["Und", "in", "ein", "Ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.18": {"text": "Hin\u00fcberschwanken ...", "tokens": ["Hin\u00b7\u00fc\u00b7bersc\u00b7hwan\u00b7ken", "..."], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Ich m\u00f6chte gedankenlos-klein", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ge\u00b7dan\u00b7ken\u00b7los\u00b7klein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.20": {"text": "Nach allem Nichtigen fassen,", "tokens": ["Nach", "al\u00b7lem", "Nich\u00b7ti\u00b7gen", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "Das Unbedeutende preisen,", "tokens": ["Das", "Un\u00b7be\u00b7deu\u00b7ten\u00b7de", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.22": {"text": "Das Gro\u00dfe unbewu\u00dft hassen \u2013", "tokens": ["Das", "Gro\u00b7\u00dfe", "un\u00b7be\u00b7wu\u00dft", "has\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Wie Ihr seid, m\u00f6cht ich sein.", "tokens": ["Wie", "Ihr", "seid", ",", "m\u00f6cht", "ich", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "$,", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Doch was ich h\u00f6rte", "tokens": ["Doch", "was", "ich", "h\u00f6r\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Und was ich schaute,", "tokens": ["Und", "was", "ich", "schau\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Es macht mich einsam,", "tokens": ["Es", "macht", "mich", "ein\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Mein Geist, der beth\u00f6rte", "tokens": ["Mein", "Geist", ",", "der", "be\u00b7th\u00f6r\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Hat nicht die Laute", "tokens": ["Hat", "nicht", "die", "Lau\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Des Schmerzes gemeinsam", "tokens": ["Des", "Schmer\u00b7zes", "ge\u00b7mein\u00b7sam"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ADJD"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Mit gleichen Creaturen.", "tokens": ["Mit", "glei\u00b7chen", "Crea\u00b7tu\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Und darum f\u00fcrchte ich Alle,", "tokens": ["Und", "da\u00b7rum", "f\u00fcrch\u00b7te", "ich", "Al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es g\u00e4hnt mich drohend an", "tokens": ["Es", "g\u00e4hnt", "mich", "dro\u00b7hend", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Die feindliche Schaalheit", "tokens": ["Die", "feind\u00b7li\u00b7che", "Scha\u00b7al\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Der fremden Naturen,", "tokens": ["Der", "frem\u00b7den", "Na\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "Da\u00df ich nicht glauben kann,", "tokens": ["Da\u00df", "ich", "nicht", "glau\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Ich z\u00e4hle zu ihrer Allheit ...", "tokens": ["Ich", "z\u00e4h\u00b7le", "zu", "ih\u00b7rer", "All\u00b7heit", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Aus Euren Bahnen", "tokens": ["Aus", "Eu\u00b7ren", "Bah\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Hinausgedr\u00e4ngt,", "tokens": ["Hin\u00b7aus\u00b7ge\u00b7dr\u00e4ngt", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "In Wissen und Ahnen", "tokens": ["In", "Wis\u00b7sen", "und", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Begrenzt und beengt,", "tokens": ["Be\u00b7grenzt", "und", "be\u00b7engt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Im innersten Wesen", "tokens": ["Im", "in\u00b7ners\u00b7ten", "We\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Zerrissen ... Allein!", "tokens": ["Zer\u00b7ris\u00b7sen", "...", "Al\u00b7lein", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Und kein Genesen", "tokens": ["Und", "kein", "Ge\u00b7ne\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.8": {"text": "Von dieser Pein.", "tokens": ["Von", "die\u00b7ser", "Pein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Immer \u2013 immer \u2013 immer", "tokens": ["Im\u00b7mer", "\u2013", "im\u00b7mer", "\u2013", "im\u00b7mer"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["ADV", "$(", "ADV", "$(", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mitschleppen die Begrenzung,", "tokens": ["Mit\u00b7schlep\u00b7pen", "die", "Be\u00b7gren\u00b7zung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Den Leib, den eignen Widerpart!", "tokens": ["Den", "Leib", ",", "den", "eig\u00b7nen", "Wi\u00b7der\u00b7part", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo bleibt die Erg\u00e4nzung?", "tokens": ["Wo", "bleibt", "die", "Er\u00b7g\u00e4n\u00b7zung", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Wo bleibt die Hand,", "tokens": ["Wo", "bleibt", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Die wegfegt alle M\u00e4ngel", "tokens": ["Die", "weg\u00b7fegt", "al\u00b7le", "M\u00e4n\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und alle Halbheit einigt?", "tokens": ["Und", "al\u00b7le", "Halb\u00b7heit", "ei\u00b7nigt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die jenes Wesen, das stets", "tokens": ["Die", "je\u00b7nes", "We\u00b7sen", ",", "das", "stets"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PDAT", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Thier und Engel,", "tokens": ["Thier", "und", "En\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Zum Menschenbilde reinigt?", "tokens": ["Zum", "Men\u00b7schen\u00b7bil\u00b7de", "rei\u00b7nigt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Kann Herz und Hirn", "tokens": ["Kann", "Herz", "und", "Hirn"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Nicht tr\u00f6stend Antwort geben?", "tokens": ["Nicht", "tr\u00f6s\u00b7tend", "Ant\u00b7wort", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Nicht das Gestirn,", "tokens": ["Nicht", "das", "Ge\u00b7stirn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Das geb\u00e4rende Leben?!", "tokens": ["Das", "ge\u00b7b\u00e4\u00b7ren\u00b7de", "Le\u00b7ben", "?!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.15": {"text": ". . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.12": {"line.1": {"text": "Nein! Vertilgt ist jenes Schrittes Spur,", "tokens": ["Nein", "!", "Ver\u00b7tilgt", "ist", "je\u00b7nes", "Schrit\u00b7tes", "Spur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVPP", "VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die von dem Aether f\u00fchrt zum Staube,", "tokens": ["Die", "von", "dem", "A\u00b7e\u00b7ther", "f\u00fchrt", "zum", "Stau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Des Suchens Thorheit blieb mir nur:", "tokens": ["Des", "Su\u00b7chens", "Thor\u00b7heit", "blieb", "mir", "nur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Unwissenheit! ... Kinderglaube ...", "tokens": ["Un\u00b7wis\u00b7sen\u00b7heit", "!", "...", "Kin\u00b7der\u00b7glau\u00b7be", "..."], "token_info": ["word", "punct", "punct", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Oder trostlose Einsamkeit.", "tokens": ["O\u00b7der", "trost\u00b7lo\u00b7se", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.13": {"line.1": {"text": "Einsamkeit ohne Vergessenheit!", "tokens": ["Ein\u00b7sam\u00b7keit", "oh\u00b7ne", "Ver\u00b7ges\u00b7sen\u00b7heit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Ein h\u00fclfloser Schrei", "tokens": ["Ein", "h\u00fcl\u00b7flo\u00b7ser", "Schrei"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ins Leere ... ohne Erh\u00f6rung,", "tokens": ["Ins", "Lee\u00b7re", "...", "oh\u00b7ne", "Er\u00b7h\u00f6\u00b7rung", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Oder ein j\u00e4her Blitz:", "tokens": ["O\u00b7der", "ein", "j\u00e4\u00b7her", "Blitz", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Vernichtung ... Zerst\u00f6rung!", "tokens": ["Ver\u00b7nich\u00b7tung", "...", "Zer\u00b7st\u00f6\u00b7rung", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Vernichtung! Zerst\u00f6rung!", "tokens": ["Ver\u00b7nich\u00b7tung", "!", "Zer\u00b7st\u00f6\u00b7rung", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Das alte Erl\u00f6sungswort,", "tokens": ["Das", "al\u00b7te", "Er\u00b7l\u00f6\u00b7sungs\u00b7wort", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Es klingt voll s\u00fc\u00dfer Beth\u00f6rung", "tokens": ["Es", "klingt", "voll", "s\u00fc\u00b7\u00dfer", "Be\u00b7th\u00f6\u00b7rung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Durch alles Elend fort ...", "tokens": ["Durch", "al\u00b7les", "E\u00b7lend", "fort", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Wer aber wei\u00df, wie viel dann untergeht,", "tokens": ["Wer", "a\u00b7ber", "wei\u00df", ",", "wie", "viel", "dann", "un\u00b7ter\u00b7geht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ob in Atomen tausendfach zersplittert", "tokens": ["Ob", "in", "A\u00b7to\u00b7men", "tau\u00b7send\u00b7fach", "zer\u00b7split\u00b7tert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Nicht etwas K\u00f6rperloses fortbesteht,", "tokens": ["Nicht", "et\u00b7was", "K\u00f6r\u00b7per\u00b7lo\u00b7ses", "fort\u00b7be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "In dem das Lebenselend ", "tokens": ["In", "dem", "das", "Le\u00b7ben\u00b7se\u00b7lend"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Wo sind sie Alle jene Zwitterwesen,", "tokens": ["Wo", "sind", "sie", "Al\u00b7le", "je\u00b7ne", "Zwit\u00b7ter\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PIAT", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die leidensm\u00fcde riefen solche Klagen?", "tokens": ["Die", "lei\u00b7dens\u00b7m\u00fc\u00b7de", "rie\u00b7fen", "sol\u00b7che", "Kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Auf welchem Stern vermochten sie zu lesen", "tokens": ["Auf", "wel\u00b7chem", "Stern", "ver\u00b7moch\u00b7ten", "sie", "zu", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Die d\u00fcrre Antwort ihrer tollen Fragen?", "tokens": ["Die", "d\u00fcr\u00b7re", "Ant\u00b7wort", "ih\u00b7rer", "tol\u00b7len", "Fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Wenn ihnen die Vernichtung nur allein", "tokens": ["Wenn", "ih\u00b7nen", "die", "Ver\u00b7nich\u00b7tung", "nur", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Des Daseinsr\u00e4thsels L\u00f6sung konnte sagen \u2013", "tokens": ["Des", "Da\u00b7seins\u00b7r\u00e4th\u00b7sels", "L\u00f6\u00b7sung", "konn\u00b7te", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Was frommt es uns? ... Der kalte Leichenstein", "tokens": ["Was", "frommt", "es", "uns", "?", "...", "Der", "kal\u00b7te", "Lei\u00b7chen\u00b7stein"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$.", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Er k\u00fcndet Wahnsinn \u2013 oder feiges Zagen.", "tokens": ["Er", "k\u00fcn\u00b7det", "Wahn\u00b7sinn", "\u2013", "o\u00b7der", "fei\u00b7ges", "Za\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$("]}}, "stanza.14": {"line.1": {"text": "O lacht nicht", "tokens": ["O", "lacht", "nicht"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Und z\u00fcrnt nicht;", "tokens": ["Und", "z\u00fcrnt", "nicht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$."], "meter": "++-", "measure": "unknown.measure.di"}, "line.3": {"text": "Ich st\u00fcrzte mich gern", "tokens": ["Ich", "st\u00fcrz\u00b7te", "mich", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "In das rauschende Leben,", "tokens": ["In", "das", "rau\u00b7schen\u00b7de", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Ich m\u00f6chte ja gern", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ja", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Den Becher erheben,", "tokens": ["Den", "Be\u00b7cher", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Den sch\u00e4umenden Becher", "tokens": ["Den", "sch\u00e4u\u00b7men\u00b7den", "Be\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Der Lebenslust.", "tokens": ["Der", "Le\u00b7bens\u00b7lust", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Doch ich f\u00fcrchte sie Alle", "tokens": ["Doch", "ich", "f\u00fcrch\u00b7te", "sie", "Al\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PIAT"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Die frohen Zecher,", "tokens": ["Die", "fro\u00b7hen", "Ze\u00b7cher", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Denn in meiner Brust", "tokens": ["Denn", "in", "mei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.12": {"text": "Ringt Tod und Leben ...", "tokens": ["Ringt", "Tod", "und", "Le\u00b7ben", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "Ich bin allein!", "tokens": ["Ich", "bin", "al\u00b7lein", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}