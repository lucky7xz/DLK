{"dta.poem.5492": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Ungl\u00fcckliche Verabs\u00e4umung unserer  \n Pflichten gegen den Sch\u00f6pfer.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn wir fast von den meisten Menschen das Eigent-\nliche der Jdeen,", "tokens": ["Wenn", "wir", "fast", "von", "den", "meis\u00b7ten", "Men\u00b7schen", "das", "Ei\u00b7gent", "li\u00b7che", "der", "Jdeen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "PIAT", "NN", "ART", "TRUNC", "NN", "ART", "NN", "$,"], "meter": "--+--+-+--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Die sie sich von der GOttheit machen, mit einem ernsten", "tokens": ["Die", "sie", "sich", "von", "der", "Got\u00b7theit", "ma\u00b7chen", ",", "mit", "ei\u00b7nem", "erns\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$,", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So f\u00fcrcht\u2019 ich, da\u00df sie sich von ihr fast nichts sonst wissen", "tokens": ["So", "f\u00fcrcht'", "ich", ",", "da\u00df", "sie", "sich", "von", "ihr", "fast", "nichts", "sonst", "wis\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "APPR", "PPER", "ADV", "PIS", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als eines alten, m\u00e4chtigen, vern\u00fcnftigen Monarchens", "tokens": ["Als", "ei\u00b7nes", "al\u00b7ten", ",", "m\u00e4ch\u00b7ti\u00b7gen", ",", "ver\u00b7n\u00fcnf\u00b7ti\u00b7gen", "Mon\u00b7ar\u00b7chens"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Der mit der gr\u00f6sten Majest\u00e4t umgeben sey und angef\u00fcllt,", "tokens": ["Der", "mit", "der", "gr\u00f6s\u00b7ten", "Ma\u00b7jes\u00b7t\u00e4t", "um\u00b7ge\u00b7ben", "sey", "und", "an\u00b7ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVPP", "VAFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.6": {"text": "Ein m\u00e4cht- und eintziger Besitzer so wol des Himmels, als", "tokens": ["Ein", "m\u00e4cht", "und", "eint\u00b7zi\u00b7ger", "Be\u00b7sit\u00b7zer", "so", "wol", "des", "Him\u00b7mels", ",", "als"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "ADV", "ADV", "ART", "NN", "$,", "KOUS"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Der die erschaffene Natur vor sich gelassen walten lasse,", "tokens": ["Der", "die", "er\u00b7schaf\u00b7fe\u00b7ne", "Na\u00b7tur", "vor", "sich", "ge\u00b7las\u00b7sen", "wal\u00b7ten", "las\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "PRF", "VVPP", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.8": {"text": "Und sich, wofern nicht blos allein, doch mehrentheils, da-", "tokens": ["Und", "sich", ",", "wo\u00b7fern", "nicht", "blos", "al\u00b7lein", ",", "doch", "meh\u00b7ren\u00b7theils", ",", "da"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "PRF", "$,", "KOUS", "PTKNEG", "ADV", "ADV", "$,", "ADV", "ADV", "$,", "TRUNC"], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.9": {"text": "Best\u00e4ndig auf die Sterblichen, und ob sie etwan was", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "auf", "die", "Sterb\u00b7li\u00b7chen", ",", "und", "ob", "sie", "et\u00b7wan", "was"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "$,", "KON", "KOUS", "PPER", "ADV", "PWS"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "Damit er ihnen alsobald m\u00f6g\u2019 ein gerechtes Urtheil sprechen,", "tokens": ["Da\u00b7mit", "er", "ih\u00b7nen", "al\u00b7so\u00b7bald", "m\u00f6g'", "ein", "ge\u00b7rech\u00b7tes", "Ur\u00b7theil", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.11": {"text": "Den ernsten Blick gericht\u2019t zu haben. Von andern seinen Herr-", "tokens": ["Den", "erns\u00b7ten", "Blick", "ge\u00b7richt't", "zu", "ha\u00b7ben", ".", "Von", "an\u00b7dern", "sei\u00b7nen", "Herr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP", "PTKZU", "VAINF", "$.", "APPR", "PIS", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "Und einem Sch\u00f6pfer noch vielmehr anst\u00e4ndlichen Voll-", "tokens": ["Und", "ei\u00b7nem", "Sch\u00f6p\u00b7fer", "noch", "viel\u00b7mehr", "an\u00b7st\u00e4nd\u00b7li\u00b7chen", "Voll"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "ADV", "ADJA", "TRUNC"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "F\u00e4llt ihnen nicht leicht etwas bey. Es scheint die Eigen-", "tokens": ["F\u00e4llt", "ih\u00b7nen", "nicht", "leicht", "et\u00b7was", "bey", ".", "Es", "scheint", "die", "Ei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "PIS", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Von solchen niedrigen Gedancken die Ursach und die Quell", "tokens": ["Von", "sol\u00b7chen", "nied\u00b7ri\u00b7gen", "Ge\u00b7dan\u00b7cken", "die", "Ur\u00b7sach", "und", "die", "Quell"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.2": {"line.1": {"text": "Wir scheinen uns selbst w\u00fcrdig gnug, vom Sch\u00f6pfer Him-", "tokens": ["Wir", "schei\u00b7nen", "uns", "selbst", "w\u00fcr\u00b7dig", "gnug", ",", "vom", "Sch\u00f6p\u00b7fer", "Him"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "$,", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zur stetigen Aufmercksamkeit, die Haupt-Besch\u00e4ftigung zu", "tokens": ["Zur", "ste\u00b7ti\u00b7gen", "Auf\u00b7merck\u00b7sam\u00b7keit", ",", "die", "Haup\u00b7tBe\u00b7sch\u00e4f\u00b7ti\u00b7gung", "zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.3": {"text": "Und ob wir zwar, wenn man uns fragt, ob wir die\u00df von", "tokens": ["Und", "ob", "wir", "zwar", ",", "wenn", "man", "uns", "fragt", ",", "ob", "wir", "die\u00df", "von"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PDS", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df er auf uns allein nur achte? da\u00df wir die\u00df thun, ge-", "tokens": ["Da\u00df", "er", "auf", "uns", "al\u00b7lein", "nur", "ach\u00b7te", "?", "da\u00df", "wir", "die\u00df", "thun", ",", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "ADV", "ADJA", "$.", "KOUS", "PPER", "PDS", "VVINF", "$,", "TRUNC"], "meter": "-+---+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und uns vielleicht verwundern w\u00fcrden, da\u00df man die Mey-", "tokens": ["Und", "uns", "viel\u00b7leicht", "ver\u00b7wun\u00b7dern", "w\u00fcr\u00b7den", ",", "da\u00df", "man", "die", "Mey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "VVINF", "VAFIN", "$,", "KOUS", "PIS", "ART", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Da auch ja Prediger wol sagen: da\u00df GOtt die Welt er-", "tokens": ["Da", "auch", "ja", "Pre\u00b7di\u00b7ger", "wol", "sa\u00b7gen", ":", "da\u00df", "Gott", "die", "Welt", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "NN", "ADV", "VVINF", "$.", "KOUS", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+--++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So ist jedoch unwiedersprechlich, da\u00df, da auf G\u00f6ttliche", "tokens": ["So", "ist", "je\u00b7doch", "un\u00b7wie\u00b7der\u00b7sprech\u00b7lich", ",", "da\u00df", ",", "da", "auf", "G\u00f6tt\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "$,", "KOUS", "APPR", "NN"], "meter": "-+--+--+-++-+--", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Auf seine Weisheit in den Wercken, auf ihre Sch\u00f6nheit,", "tokens": ["Auf", "sei\u00b7ne", "Weis\u00b7heit", "in", "den", "Wer\u00b7cken", ",", "auf", "ih\u00b7re", "Sch\u00f6n\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Von welchen er durch alle Sinnen die Proben seiner Wun-", "tokens": ["Von", "wel\u00b7chen", "er", "durch", "al\u00b7le", "Sin\u00b7nen", "die", "Pro\u00b7ben", "sei\u00b7ner", "Wun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "PPER", "APPR", "PIAT", "NN", "ART", "NN", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "Uns \u00fcberall vor Augen legt, auf aller seiner G\u00fcte F\u00fchrung", "tokens": ["Uns", "\u00fc\u00b7be\u00b7rall", "vor", "Au\u00b7gen", "legt", ",", "auf", "al\u00b7ler", "sei\u00b7ner", "G\u00fc\u00b7te", "F\u00fch\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "NN", "VVFIN", "$,", "APPR", "PIAT", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.11": {"text": "Wir selten ja fast nimmer dencken, noch sie mit frohem", "tokens": ["Wir", "sel\u00b7ten", "ja", "fast", "nim\u00b7mer", "den\u00b7cken", ",", "noch", "sie", "mit", "fro\u00b7hem"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "VVINF", "$,", "ADV", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Wir selbige nicht unsers Denckens, noch der Betrachtung,", "tokens": ["Wir", "sel\u00b7bi\u00b7ge", "nicht", "un\u00b7sers", "Den\u00b7ckens", ",", "noch", "der", "Be\u00b7trach\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Und folglich, um des Sch\u00f6pfers Ehre, sehr wenig uns", "tokens": ["Und", "folg\u00b7lich", ",", "um", "des", "Sch\u00f6p\u00b7fers", "Eh\u00b7re", ",", "sehr", "we\u00b7nig", "uns"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUI", "ART", "NN", "NN", "$,", "ADV", "PIS", "PPER"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Aus dieser unserer Betrachtung scheint, sonder", "tokens": ["Aus", "die\u00b7ser", "un\u00b7se\u00b7rer", "Be\u00b7trach\u00b7tung", "scheint", ",", "son\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVFIN", "$,", "KON"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da\u00df wir, auch selbst im GOttes-Dienst, mit uns und", "tokens": ["Da\u00df", "wir", ",", "auch", "selbst", "im", "Got\u00b7tes\u00b7Dienst", ",", "mit", "uns", "und"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADV", "APPRART", "NN", "$,", "APPR", "PPER", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So eigensinnig eingenommen und dergestalt besch\u00e4ftigt", "tokens": ["So", "ei\u00b7gen\u00b7sin\u00b7nig", "ein\u00b7ge\u00b7nom\u00b7men", "und", "der\u00b7ge\u00b7stalt", "be\u00b7sch\u00e4f\u00b7tigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "KON", "ADV", "VVPP"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.4": {"line.1": {"text": "Da\u00df, wenn wir, von der GOttheit nichts, nach einer et-", "tokens": ["Da\u00df", ",", "wenn", "wir", ",", "von", "der", "Got\u00b7theit", "nichts", ",", "nach", "ei\u00b7ner", "et"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "$,", "APPR", "ART", "NN", "PIS", "$,", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu f\u00fcrchten noch zu hoffen h\u00e4tten; wir, wenn auch keine", "tokens": ["Zu", "f\u00fcrch\u00b7ten", "noch", "zu", "hof\u00b7fen", "h\u00e4t\u00b7ten", ";", "wir", ",", "wenn", "auch", "kei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADV", "PTKZU", "VVINF", "VAFIN", "$.", "PPER", "$,", "KOUS", "ADV", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Uns leicht dar\u00fcber tr\u00f6sten w\u00fcrden. Nun sagen wir hie-", "tokens": ["Uns", "leicht", "da\u00b7r\u00fc\u00b7ber", "tr\u00f6s\u00b7ten", "w\u00fcr\u00b7den", ".", "Nun", "sa\u00b7gen", "wir", "hie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "PAV", "VVINF", "VAFIN", "$.", "ADV", "VVFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da\u00df wenn wir uns um unsre Seelen mit Ernst bek\u00fcm-", "tokens": ["Da\u00df", "wenn", "wir", "uns", "um", "uns\u00b7re", "See\u00b7len", "mit", "Ernst", "be\u00b7k\u00fcm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Erlaubet, ja selbst n\u00f6thig sey; nur dieses, wenn man sol-", "tokens": ["Er\u00b7lau\u00b7bet", ",", "ja", "selbst", "n\u00f6\u00b7thig", "sey", ";", "nur", "die\u00b7ses", ",", "wenn", "man", "sol"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "ADV", "ADJD", "VAFIN", "$.", "ADV", "PDAT", "$,", "KOUS", "PIS", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "Da\u00df es, mit g\u00e4ntzlicher Vers\u00e4umung des Sch\u00f6pfers Ehr\u2019", "tokens": ["Da\u00df", "es", ",", "mit", "g\u00e4ntz\u00b7li\u00b7cher", "Ver\u00b7s\u00e4u\u00b7mung", "des", "Sch\u00f6p\u00b7fers", "Ehr'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "ADJA", "NN", "ART", "NN", "NN"], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Ist, wie michs deucht, was str\u00e4fliches. Wollt einer et-", "tokens": ["Ist", ",", "wie", "michs", "deucht", ",", "was", "str\u00e4f\u00b7li\u00b7ches", ".", "Wollt", "ei\u00b7ner", "et"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "PWS", "ADJA", "$.", "VMFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und sagen, da\u00df der Mensch die GOttheit zu ehren gar nicht", "tokens": ["Und", "sa\u00b7gen", ",", "da\u00df", "der", "Mensch", "die", "Got\u00b7theit", "zu", "eh\u00b7ren", "gar", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "$,", "KOUS", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "ADV", "PTKNEG"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und da\u00df es ihm, was alle Menschen von ihr gedencken,", "tokens": ["Und", "da\u00df", "es", "ihm", ",", "was", "al\u00b7le", "Men\u00b7schen", "von", "ihr", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "$,", "PRELS", "PIAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "So kann ich mich, das Gegentheil ihm zu erweisen, nicht", "tokens": ["So", "kann", "ich", "mich", ",", "das", "Ge\u00b7gen\u00b7theil", "ihm", "zu", "er\u00b7wei\u00b7sen", ",", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "$,", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,", "PTKNEG"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.11": {"text": "Es zeigt die heilge Schrift nicht nur, da\u00df unser GOTT,", "tokens": ["Es", "zeigt", "die", "heil\u00b7ge", "Schrift", "nicht", "nur", ",", "da\u00df", "un\u00b7ser", "GoTT", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKNEG", "ADV", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df man nach allen Kr\u00e4ften ihn verehren und ihn preisen", "tokens": ["Da\u00df", "man", "nach", "al\u00b7len", "Kr\u00e4f\u00b7ten", "ihn", "ver\u00b7eh\u00b7ren", "und", "ihn", "prei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "PIAT", "NN", "PPER", "VVFIN", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.13": {"text": "Es zeiget uns auch die Vernunft, da\u00df das vern\u00fcnftigste", "tokens": ["Es", "zei\u00b7get", "uns", "auch", "die", "Ver\u00b7nunft", ",", "da\u00df", "das", "ver\u00b7n\u00fcnf\u00b7tigs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "KOUS", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.14": {"text": "Wozu die Menschheit f\u00e4hig ist, sey, dieses unsers Geistes", "tokens": ["Wo\u00b7zu", "die", "Menschheit", "f\u00e4\u00b7hig", "ist", ",", "sey", ",", "die\u00b7ses", "un\u00b7sers", "Geis\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADJD", "VAFIN", "$,", "VAFIN", "$,", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.15": {"text": "Demjenigen, von welchem wir uns selbst und Millionen-", "tokens": ["Dem\u00b7je\u00b7ni\u00b7gen", ",", "von", "wel\u00b7chem", "wir", "uns", "selbst", "und", "Mil\u00b7li\u00b7o\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "APPR", "PRELS", "PPER", "PRF", "ADV", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.5": {"line.1": {"text": "Nach aller M\u00f6glichkeit zu Ehren und ihm allein zum Ruhm", "tokens": ["Nach", "al\u00b7ler", "M\u00f6g\u00b7lich\u00b7keit", "zu", "Eh\u00b7ren", "und", "ihm", "al\u00b7lein", "zum", "Ruhm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "NN", "KON", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Mit fr\u00f6licher Bewunderung wol anzuwenden, zu bestreben.", "tokens": ["Mit", "fr\u00f6\u00b7li\u00b7cher", "Be\u00b7wun\u00b7de\u00b7rung", "wol", "an\u00b7zu\u00b7wen\u00b7den", ",", "zu", "be\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVIZU", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.3": {"text": "Da er uns selbst den Trieb zur Ehre, als etwas edles, ein-", "tokens": ["Da", "er", "uns", "selbst", "den", "Trieb", "zur", "Eh\u00b7re", ",", "als", "et\u00b7was", "ed\u00b7les", ",", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ART", "NN", "APPRART", "NN", "$,", "KOUS", "PIAT", "ADJA", "$,", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Wovon man sonst nichts wissen w\u00fcrde, h\u00e4tt er ihn uns", "tokens": ["Wo\u00b7von", "man", "sonst", "nichts", "wis\u00b7sen", "w\u00fcr\u00b7de", ",", "h\u00e4tt", "er", "ihn", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "PIS", "VVINF", "VAFIN", "$,", "VAFIN", "PPER", "PPER", "PRF"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Die Ehre scheint der Gegenwurf und Qvell der Anmuth", "tokens": ["Die", "Eh\u00b7re", "scheint", "der", "Ge\u00b7gen\u00b7wurf", "und", "Qvell", "der", "An\u00b7muth"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "KON", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bey dem nichts Sinn-nichts C\u00f6rperlichs; die doch an an-", "tokens": ["Bey", "dem", "nichts", "Sinn\u00b7nichts", "C\u00f6r\u00b7per\u00b7lichs", ";", "die", "doch", "an", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "NE", "$.", "ART", "ADV", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So gar auch bey den Thieren selbst, nicht aber an der", "tokens": ["So", "gar", "auch", "bey", "den", "Thie\u00b7ren", "selbst", ",", "nicht", "a\u00b7ber", "an", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "APPR", "ART", "NN", "ADV", "$,", "PTKNEG", "ADV", "APPR", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Ehre nun die wir der GOttheit, nach unserm weni-", "tokens": ["Die", "Eh\u00b7re", "nun", "die", "wir", "der", "Got\u00b7theit", ",", "nach", "un\u00b7serm", "we\u00b7ni"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PRELS", "PPER", "ART", "NN", "$,", "APPR", "PPOSAT", "TRUNC"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Ist ja unstreitig dieses wol: da\u00df wir die allerherrlichste", "tokens": ["Ist", "ja", "un\u00b7strei\u00b7tig", "die\u00b7ses", "wol", ":", "da\u00df", "wir", "die", "al\u00b7ler\u00b7herr\u00b7lichs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "PDAT", "ADV", "$.", "KOUS", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.10": {"text": "Und von den menschlichen Jdeen die allerw\u00fcrdigste Jdee,", "tokens": ["Und", "von", "den", "menschli\u00b7chen", "Jdeen", "die", "al\u00b7ler\u00b7w\u00fcr\u00b7digs\u00b7te", "Jdee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.11": {"text": "Wozu wir immer f\u00e4hig sind, von Gott in unsrer Seele zeugen,", "tokens": ["Wo\u00b7zu", "wir", "im\u00b7mer", "f\u00e4\u00b7hig", "sind", ",", "von", "Gott", "in", "uns\u00b7rer", "See\u00b7le", "zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VAFIN", "$,", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.12": {"text": "Vor keiner GOttheit, die umschr\u00e4nckt und Gr\u00e4ntzen hat,", "tokens": ["Vor", "kei\u00b7ner", "Got\u00b7theit", ",", "die", "um\u00b7schr\u00e4nckt", "und", "Gr\u00e4nt\u00b7zen", "hat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "VVPP", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.13": {"text": "Und kein ihm unanst\u00e4ndig Bild, ein G\u00f6tzen-Bildni\u00df, uns", "tokens": ["Und", "kein", "ihm", "un\u00b7an\u00b7st\u00e4n\u00b7dig", "Bild", ",", "ein", "G\u00f6t\u00b7zen\u00b7Bild\u00b7ni\u00df", ",", "uns"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "PIAT", "PPER", "ADJD", "NN", "$,", "ART", "NN", "$,", "PPER"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.14": {"text": "So wieder die uns eingepflantzten, auch die uns vorgeschrieb-", "tokens": ["So", "wie\u00b7der", "die", "uns", "ein\u00b7ge\u00b7pflantz\u00b7ten", ",", "auch", "die", "uns", "vor\u00b7ge\u00b7schrie\u00b7b"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "PPER", "VVFIN", "$,", "ADV", "ART", "PPER", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.15": {"text": "Da er, von ihm kein Bild zu machen, so scharf: uns unter-", "tokens": ["Da", "er", ",", "von", "ihm", "kein", "Bild", "zu", "ma\u00b7chen", ",", "so", "scharf", ":", "uns", "un\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPER", "PIAT", "NN", "PTKZU", "VVINF", "$,", "ADV", "ADJD", "$.", "PPER", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Thut mans gleich leider unterm Bilde von einem Greisen,", "tokens": ["Thut", "mans", "gleich", "lei\u00b7der", "un\u00b7term", "Bil\u00b7de", "von", "ei\u00b7nem", "Grei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Weil wir nun zu so hohem Grad nicht selber f\u00e4hig", "tokens": ["Weil", "wir", "nun", "zu", "so", "ho\u00b7hem", "Grad", "nicht", "sel\u00b7ber", "f\u00e4\u00b7hig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADV", "ADJA", "NN", "PTKNEG", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So hat uns GOTT in seinen Wercken die sch\u00f6nste Leiter", "tokens": ["So", "hat", "uns", "GoTT", "in", "sei\u00b7nen", "Wer\u00b7cken", "die", "sch\u00f6ns\u00b7te", "Lei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NE", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wodurch wir uns auf Freuden-Stuffen nicht nur geschickt", "tokens": ["Wo\u00b7durch", "wir", "uns", "auf", "Freu\u00b7den\u00b7Stuf\u00b7fen", "nicht", "nur", "ge\u00b7schickt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "APPR", "NN", "PTKNEG", "ADV", "VVPP"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nein, immer mehr und mehr, ohn Ende, die Gr\u00f6sse seines", "tokens": ["Nein", ",", "im\u00b7mer", "mehr", "und", "mehr", ",", "ohn", "En\u00b7de", ",", "die", "Gr\u00f6s\u00b7se", "sei\u00b7nes"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "ADV", "KON", "ADV", "$,", "APPR", "NN", "$,", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Jhn ehren und ihm dancken k\u00f6nnen. Was nun die Seele", "tokens": ["Jhn", "eh\u00b7ren", "und", "ihm", "dan\u00b7cken", "k\u00f6n\u00b7nen", ".", "Was", "nun", "die", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVINF", "KON", "PPER", "VVINF", "VMINF", "$.", "PWS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "An Kr\u00e4ften, als die Lieb\u2019 und Ehrfurcht, wird dadurch", "tokens": ["An", "Kr\u00e4f\u00b7ten", ",", "als", "die", "Lieb'", "und", "Ehr\u00b7furcht", ",", "wird", "da\u00b7durch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "KOUS", "ART", "NN", "KON", "NN", "$,", "VAFIN", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wir, in fr\u00f6licher Betrachtung stets neuer Wunder,", "tokens": ["Und", "wir", ",", "in", "fr\u00f6\u00b7li\u00b7cher", "Be\u00b7trach\u00b7tung", "stets", "neu\u00b7er", "Wun\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "ADJA", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Mit immer neuer Brunst und Andacht den Liebensw\u00fcrdig-", "tokens": ["Mit", "im\u00b7mer", "neu\u00b7er", "Brunst", "und", "An\u00b7dacht", "den", "Lie\u00b7bens\u00b7w\u00fcr\u00b7dig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN", "KON", "NN", "ART", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und, weil er sonder End\u2019 und Gr\u00e4ntzen, in Ewigkeit nicht", "tokens": ["Und", ",", "weil", "er", "son\u00b7der", "End'", "und", "Gr\u00e4nt\u00b7zen", ",", "in", "E\u00b7wig\u00b7keit", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "PIAT", "NN", "KON", "NN", "$,", "APPR", "NN", "PTKNEG"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Selbst unser seeliges Vergn\u00fcgen in Ewigkeit noch zu ver-", "tokens": ["Selbst", "un\u00b7ser", "see\u00b7li\u00b7ges", "Ver\u00b7gn\u00fc\u00b7gen", "in", "E\u00b7wig\u00b7keit", "noch", "zu", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "APPR", "NN", "ADV", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.11": {"text": "Zugleich auch das, worinn die Ehre am eigentlichsten recht", "tokens": ["Zu\u00b7gleich", "auch", "das", ",", "wo\u00b7rinn", "die", "Eh\u00b7re", "am", "ei\u00b7gent\u00b7lichs\u00b7ten", "recht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PDS", "$,", "PWAV", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "Die Achtung, so die Seele f\u00fchlt, ob seines Wesens Herr-", "tokens": ["Die", "Ach\u00b7tung", ",", "so", "die", "See\u00b7le", "f\u00fchlt", ",", "ob", "sei\u00b7nes", "We\u00b7sens", "Herr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.13": {"text": "Bey andern ebenfals zu \u00e4ussern, und nach Verm\u00f6gen aus-", "tokens": ["Bey", "an\u00b7dern", "e\u00b7ben\u00b7fals", "zu", "\u00e4us\u00b7sern", ",", "und", "nach", "Ver\u00b7m\u00f6\u00b7gen", "aus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "ADV", "PTKZU", "VVINF", "$,", "KON", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}}}}