{"textgrid.poem.32319": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "5. Der Tod eines Freundes", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hat, neuer Himmelsb\u00fcrger, sich", "tokens": ["Hat", ",", "neu\u00b7er", "Him\u00b7mels\u00b7b\u00fcr\u00b7ger", ",", "sich"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["VAFIN", "$,", "ADJA", "NN", "$,", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein geistig Ohr nicht schon des Klagetons entw\u00f6hnet,", "tokens": ["Dein", "geis\u00b7tig", "Ohr", "nicht", "schon", "des", "Kla\u00b7ge\u00b7tons", "ent\u00b7w\u00f6h\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und kann ein banges Ach um dich,", "tokens": ["Und", "kann", "ein", "ban\u00b7ges", "Ach", "um", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das hier und da ein Freund bei stillen Tr\u00e4nen st\u00f6hnet,", "tokens": ["Das", "hier", "und", "da", "ein", "Freund", "bei", "stil\u00b7len", "Tr\u00e4\u00b7nen", "st\u00f6h\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "KON", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dir unterm jauchzenden Empfangen", "tokens": ["Dir", "un\u00b7term", "jauch\u00b7zen\u00b7den", "Emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der bessern Freunde h\u00f6rbar sein,", "tokens": ["Der", "bes\u00b7sern", "Freun\u00b7de", "h\u00f6r\u00b7bar", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So sei nicht f\u00fcr die Welt, mit unserm Schmerz zu prangen,", "tokens": ["So", "sei", "nicht", "f\u00fcr", "die", "Welt", ",", "mit", "un\u00b7serm", "Schmerz", "zu", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dies Lied: es sei f\u00fcr dich, f\u00fcr dich allein!", "tokens": ["Dies", "Lied", ":", "es", "sei", "f\u00fcr", "dich", ",", "f\u00fcr", "dich", "al\u00b7lein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$.", "PPER", "VAFIN", "APPR", "PPER", "$,", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wann war es, da auch dich noch junge Rosen zierten?", "tokens": ["Wann", "war", "es", ",", "da", "auch", "dich", "noch", "jun\u00b7ge", "Ro\u00b7sen", "zier\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "KOUS", "ADV", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(doch nein, die Rosen ziertest du!)", "tokens": ["(", "doch", "nein", ",", "die", "Ro\u00b7sen", "zier\u00b7test", "du", "!", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "PTKANT", "$,", "ART", "NN", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da Freud' und Unschuld dich, im Tal der Hoffnung, f\u00fchrten", "tokens": ["Da", "Freud'", "und", "Un\u00b7schuld", "dich", ",", "im", "Tal", "der", "Hoff\u00b7nung", ",", "f\u00fchr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "$,", "APPRART", "NN", "ART", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Alter und der Tugend zu?", "tokens": ["Dem", "Al\u00b7ter", "und", "der", "Tu\u00b7gend", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gesichert folgten wir: als schnell aus schlauen Hecken,", "tokens": ["Ge\u00b7si\u00b7chert", "folg\u00b7ten", "wir", ":", "als", "schnell", "aus", "schlau\u00b7en", "He\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "$.", "KOUS", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Unerbittliche sich wies,", "tokens": ["Der", "Un\u00b7er\u00b7bitt\u00b7li\u00b7che", "sich", "wies", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und dich, den Besten, uns zu schrecken,", "tokens": ["Und", "dich", ",", "den", "Bes\u00b7ten", ",", "uns", "zu", "schre\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht dich zu strafen, von uns ri\u00df.", "tokens": ["Nicht", "dich", "zu", "stra\u00b7fen", ",", "von", "uns", "ri\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "PTKZU", "VVINF", "$,", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie ein geliebtes Weib vom steilen Ufer blicket", "tokens": ["Wie", "ein", "ge\u00b7lieb\u00b7tes", "Weib", "vom", "stei\u00b7len", "U\u00b7fer", "bli\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Schiffe nach, das ihre Kron' entrei\u00dft:", "tokens": ["Dem", "Schif\u00b7fe", "nach", ",", "das", "ih\u00b7re", "Kron'", "ent\u00b7rei\u00dft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie steht, ein Marmorbild, zu Stunden unverr\u00fccket;", "tokens": ["Sie", "steht", ",", "ein", "Mar\u00b7mor\u00b7bild", ",", "zu", "Stun\u00b7den", "un\u00b7ver\u00b7r\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "$,", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Augen ist ihr ganzer Geist:", "tokens": ["In", "Au\u00b7gen", "ist", "ihr", "gan\u00b7zer", "Geist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So standen wir bet\u00e4ubt und angeheftet,", "tokens": ["So", "stan\u00b7den", "wir", "be\u00b7t\u00e4ubt", "und", "an\u00b7ge\u00b7hef\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und sannen dir mit starren Sinnen nach,", "tokens": ["Und", "san\u00b7nen", "dir", "mit", "star\u00b7ren", "Sin\u00b7nen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Bis sich der Schmerz durch Schmerz entkr\u00e4ftet,", "tokens": ["Bis", "sich", "der", "Schmerz", "durch", "Schmerz", "ent\u00b7kr\u00e4f\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und str\u00f6mend durch die Augen brach.", "tokens": ["Und", "str\u00f6\u00b7mend", "durch", "die", "Au\u00b7gen", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was weinen wir? Gleich einer Weibersage,", "tokens": ["Was", "wei\u00b7nen", "wir", "?", "Gleich", "ei\u00b7ner", "Wei\u00b7ber\u00b7sa\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die im Entstehn schon halb vergessen ist,", "tokens": ["Die", "im", "Ent\u00b7stehn", "schon", "halb", "ver\u00b7ges\u00b7sen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ADV", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Flohst du dahin! \u2013 Geduld! noch wenig Tage,", "tokens": ["Flohst", "du", "da\u00b7hin", "!", "\u2013", "Ge\u00b7duld", "!", "noch", "we\u00b7nig", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$.", "$(", "NN", "$.", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wenige dazu, so sind wir, was du bist.", "tokens": ["Und", "we\u00b7ni\u00b7ge", "da\u00b7zu", ",", "so", "sind", "wir", ",", "was", "du", "bist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PAV", "$,", "ADV", "VAFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja, wenn der Himmel uns die Palme leicht erringen,", "tokens": ["Ja", ",", "wenn", "der", "Him\u00b7mel", "uns", "die", "Pal\u00b7me", "leicht", "er\u00b7rin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ART", "NN", "PPER", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Krone leicht ersiegen l\u00e4\u00dft,", "tokens": ["Die", "Kro\u00b7ne", "leicht", "er\u00b7sie\u00b7gen", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So werden wir, wie du, das Alter \u00fcberspringen,", "tokens": ["So", "wer\u00b7den", "wir", ",", "wie", "du", ",", "das", "Al\u00b7ter", "\u00fc\u00b7bers\u00b7prin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "PPER", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Des Lebens unschmackhaften Rest.", "tokens": ["Des", "Le\u00b7bens", "un\u00b7schmack\u00b7haf\u00b7ten", "Rest", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was wartet unser? \u2013 Ach! ein unbelohnter Schwei\u00df,", "tokens": ["Was", "war\u00b7tet", "un\u00b7ser", "?", "\u2013", "Ach", "!", "ein", "un\u00b7be\u00b7lohn\u00b7ter", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "$.", "$(", "ITJ", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im Joch des Amts bei reifen Jahren,", "tokens": ["Im", "Joch", "des", "Amts", "bei", "rei\u00b7fen", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr andrer Wohl ersch\u00f6pft, als unbrauchbarer Greis", "tokens": ["F\u00fcr", "an\u00b7drer", "Wohl", "er\u00b7sch\u00f6pft", ",", "als", "un\u00b7brauch\u00b7ba\u00b7rer", "Greis"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hinunter in die Gruft zu fahren.", "tokens": ["Hin\u00b7un\u00b7ter", "in", "die", "Gruft", "zu", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch deiner wartet? \u2013 \u2013 Nein! was kannst du noch erwarten", "tokens": ["Doch", "dei\u00b7ner", "war\u00b7tet", "?", "\u2013", "\u2013", "Nein", "!", "was", "kannst", "du", "noch", "er\u00b7war\u00b7ten"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "VVFIN", "$.", "$(", "$(", "PTKANT", "$.", "PWS", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im Scho\u00df der vollen Seligkeit?", "tokens": ["Im", "Scho\u00df", "der", "vol\u00b7len", "Se\u00b7lig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nur wir, auf blindes Gl\u00fcck, als Schiffer ohne Karten,", "tokens": ["Nur", "wir", ",", "auf", "blin\u00b7des", "Gl\u00fcck", ",", "als", "Schif\u00b7fer", "oh\u00b7ne", "Kar\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "KOUS", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Durchkreuzen ihn, den faulen Pfuhl der Zeit.", "tokens": ["Durch\u00b7kreu\u00b7zen", "ihn", ",", "den", "fau\u00b7len", "Pfuhl", "der", "Zeit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Vielleicht \u2013 noch ehe du dein Gl\u00fccke wirst gewohnen,", "tokens": ["Viel\u00b7leicht", "\u2013", "noch", "e\u00b7he", "du", "dein", "Gl\u00fc\u00b7cke", "wirst", "ge\u00b7woh\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch ehe du es durchempfunden hast \u2013", "tokens": ["Noch", "e\u00b7he", "du", "es", "dur\u00b7ch\u00b7em\u00b7pfun\u00b7den", "hast", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PPER", "VVPP", "VAFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Flieht einer von uns nach in die verkl\u00e4rten Zonen,", "tokens": ["Flieht", "ei\u00b7ner", "von", "uns", "nach", "in", "die", "ver\u00b7kl\u00e4r\u00b7ten", "Zo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "APPR", "PPER", "APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "F\u00fcr dich ein alter Freund, und dort ein neuer Gast.", "tokens": ["F\u00fcr", "dich", "ein", "al\u00b7ter", "Freund", ",", "und", "dort", "ein", "neu\u00b7er", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wen wird \u2013 verborgner Rat! \u2013 die nahe Reise treffen", "tokens": ["Wen", "wird", "\u2013", "ver\u00b7borg\u00b7ner", "Rat", "!", "\u2013", "die", "na\u00b7he", "Rei\u00b7se", "tref\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$(", "ADJA", "NN", "$.", "$(", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Aus unsrer jetzt noch frischen Schar?", "tokens": ["Aus", "uns\u00b7rer", "jetzt", "noch", "fri\u00b7schen", "Schar", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O Freunde, la\u00dft euch nicht von s\u00fc\u00dfer Hoffnung \u00e4ffen!", "tokens": ["O", "Freun\u00b7de", ",", "la\u00dft", "euch", "nicht", "von", "s\u00fc\u00b7\u00dfer", "Hoff\u00b7nung", "\u00e4f\u00b7fen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVIMP", "PPER", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zum Wachsamsein verbarg Gott die Gefahr.", "tokens": ["Zum", "Wach\u00b7sam\u00b7sein", "ver\u00b7barg", "Gott", "die", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Komm ihm, wer er auch sei, verkl\u00e4rter Geist, entgegen,", "tokens": ["Komm", "ihm", ",", "wer", "er", "auch", "sei", ",", "ver\u00b7kl\u00e4r\u00b7ter", "Geist", ",", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWS", "PPER", "ADV", "VAFIN", "$,", "ADJA", "NN", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis an das Tor der bessern Welt,", "tokens": ["Bis", "an", "das", "Tor", "der", "bes\u00b7sern", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und f\u00fchr' ihn schnell, auf dir dann schon bekannten Wegen,", "tokens": ["Und", "f\u00fchr'", "ihn", "schnell", ",", "auf", "dir", "dann", "schon", "be\u00b7kann\u00b7ten", "We\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$,", "APPR", "PPER", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hin, wo die Huld Gerichte h\u00e4lt.", "tokens": ["Hin", ",", "wo", "die", "Huld", "Ge\u00b7rich\u00b7te", "h\u00e4lt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wo um der Weisheit Thron der Freundschaft Urbild schwebet,", "tokens": ["Wo", "um", "der", "Weis\u00b7heit", "Thron", "der", "Freund\u00b7schaft", "Ur\u00b7bild", "schwe\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In seraphinschem Glanze schwebt,", "tokens": ["In", "se\u00b7ra\u00b7phin\u00b7schem", "Glan\u00b7ze", "schwebt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verkn\u00fcpft uns einst ein Band, ein Band von ihr gewebet;", "tokens": ["Ver\u00b7kn\u00fcpft", "uns", "einst", "ein", "Band", ",", "ein", "Band", "von", "ihr", "ge\u00b7we\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zur ew'gen Dauer fest gewebt!", "tokens": ["Zur", "ew'\u00b7gen", "Dau\u00b7er", "fest", "ge\u00b7webt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Hat, neuer Himmelsb\u00fcrger, sich", "tokens": ["Hat", ",", "neu\u00b7er", "Him\u00b7mels\u00b7b\u00fcr\u00b7ger", ",", "sich"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["VAFIN", "$,", "ADJA", "NN", "$,", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein geistig Ohr nicht schon des Klagetons entw\u00f6hnet,", "tokens": ["Dein", "geis\u00b7tig", "Ohr", "nicht", "schon", "des", "Kla\u00b7ge\u00b7tons", "ent\u00b7w\u00f6h\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und kann ein banges Ach um dich,", "tokens": ["Und", "kann", "ein", "ban\u00b7ges", "Ach", "um", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das hier und da ein Freund bei stillen Tr\u00e4nen st\u00f6hnet,", "tokens": ["Das", "hier", "und", "da", "ein", "Freund", "bei", "stil\u00b7len", "Tr\u00e4\u00b7nen", "st\u00f6h\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "KON", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dir unterm jauchzenden Empfangen", "tokens": ["Dir", "un\u00b7term", "jauch\u00b7zen\u00b7den", "Emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der bessern Freunde h\u00f6rbar sein,", "tokens": ["Der", "bes\u00b7sern", "Freun\u00b7de", "h\u00f6r\u00b7bar", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So sei nicht f\u00fcr die Welt, mit unserm Schmerz zu prangen,", "tokens": ["So", "sei", "nicht", "f\u00fcr", "die", "Welt", ",", "mit", "un\u00b7serm", "Schmerz", "zu", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dies Lied: es sei f\u00fcr dich, f\u00fcr dich allein!", "tokens": ["Dies", "Lied", ":", "es", "sei", "f\u00fcr", "dich", ",", "f\u00fcr", "dich", "al\u00b7lein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$.", "PPER", "VAFIN", "APPR", "PPER", "$,", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Wann war es, da auch dich noch junge Rosen zierten?", "tokens": ["Wann", "war", "es", ",", "da", "auch", "dich", "noch", "jun\u00b7ge", "Ro\u00b7sen", "zier\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "KOUS", "ADV", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(doch nein, die Rosen ziertest du!)", "tokens": ["(", "doch", "nein", ",", "die", "Ro\u00b7sen", "zier\u00b7test", "du", "!", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "PTKANT", "$,", "ART", "NN", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da Freud' und Unschuld dich, im Tal der Hoffnung, f\u00fchrten", "tokens": ["Da", "Freud'", "und", "Un\u00b7schuld", "dich", ",", "im", "Tal", "der", "Hoff\u00b7nung", ",", "f\u00fchr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "$,", "APPRART", "NN", "ART", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Alter und der Tugend zu?", "tokens": ["Dem", "Al\u00b7ter", "und", "der", "Tu\u00b7gend", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gesichert folgten wir: als schnell aus schlauen Hecken,", "tokens": ["Ge\u00b7si\u00b7chert", "folg\u00b7ten", "wir", ":", "als", "schnell", "aus", "schlau\u00b7en", "He\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "$.", "KOUS", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Unerbittliche sich wies,", "tokens": ["Der", "Un\u00b7er\u00b7bitt\u00b7li\u00b7che", "sich", "wies", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und dich, den Besten, uns zu schrecken,", "tokens": ["Und", "dich", ",", "den", "Bes\u00b7ten", ",", "uns", "zu", "schre\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht dich zu strafen, von uns ri\u00df.", "tokens": ["Nicht", "dich", "zu", "stra\u00b7fen", ",", "von", "uns", "ri\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "PTKZU", "VVINF", "$,", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wie ein geliebtes Weib vom steilen Ufer blicket", "tokens": ["Wie", "ein", "ge\u00b7lieb\u00b7tes", "Weib", "vom", "stei\u00b7len", "U\u00b7fer", "bli\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Schiffe nach, das ihre Kron' entrei\u00dft:", "tokens": ["Dem", "Schif\u00b7fe", "nach", ",", "das", "ih\u00b7re", "Kron'", "ent\u00b7rei\u00dft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie steht, ein Marmorbild, zu Stunden unverr\u00fccket;", "tokens": ["Sie", "steht", ",", "ein", "Mar\u00b7mor\u00b7bild", ",", "zu", "Stun\u00b7den", "un\u00b7ver\u00b7r\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "$,", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Augen ist ihr ganzer Geist:", "tokens": ["In", "Au\u00b7gen", "ist", "ihr", "gan\u00b7zer", "Geist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So standen wir bet\u00e4ubt und angeheftet,", "tokens": ["So", "stan\u00b7den", "wir", "be\u00b7t\u00e4ubt", "und", "an\u00b7ge\u00b7hef\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und sannen dir mit starren Sinnen nach,", "tokens": ["Und", "san\u00b7nen", "dir", "mit", "star\u00b7ren", "Sin\u00b7nen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Bis sich der Schmerz durch Schmerz entkr\u00e4ftet,", "tokens": ["Bis", "sich", "der", "Schmerz", "durch", "Schmerz", "ent\u00b7kr\u00e4f\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und str\u00f6mend durch die Augen brach.", "tokens": ["Und", "str\u00f6\u00b7mend", "durch", "die", "Au\u00b7gen", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was weinen wir? Gleich einer Weibersage,", "tokens": ["Was", "wei\u00b7nen", "wir", "?", "Gleich", "ei\u00b7ner", "Wei\u00b7ber\u00b7sa\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die im Entstehn schon halb vergessen ist,", "tokens": ["Die", "im", "Ent\u00b7stehn", "schon", "halb", "ver\u00b7ges\u00b7sen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ADV", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Flohst du dahin! \u2013 Geduld! noch wenig Tage,", "tokens": ["Flohst", "du", "da\u00b7hin", "!", "\u2013", "Ge\u00b7duld", "!", "noch", "we\u00b7nig", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$.", "$(", "NN", "$.", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wenige dazu, so sind wir, was du bist.", "tokens": ["Und", "we\u00b7ni\u00b7ge", "da\u00b7zu", ",", "so", "sind", "wir", ",", "was", "du", "bist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PAV", "$,", "ADV", "VAFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja, wenn der Himmel uns die Palme leicht erringen,", "tokens": ["Ja", ",", "wenn", "der", "Him\u00b7mel", "uns", "die", "Pal\u00b7me", "leicht", "er\u00b7rin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ART", "NN", "PPER", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Krone leicht ersiegen l\u00e4\u00dft,", "tokens": ["Die", "Kro\u00b7ne", "leicht", "er\u00b7sie\u00b7gen", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So werden wir, wie du, das Alter \u00fcberspringen,", "tokens": ["So", "wer\u00b7den", "wir", ",", "wie", "du", ",", "das", "Al\u00b7ter", "\u00fc\u00b7bers\u00b7prin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWAV", "PPER", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Des Lebens unschmackhaften Rest.", "tokens": ["Des", "Le\u00b7bens", "un\u00b7schmack\u00b7haf\u00b7ten", "Rest", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Was wartet unser? \u2013 Ach! ein unbelohnter Schwei\u00df,", "tokens": ["Was", "war\u00b7tet", "un\u00b7ser", "?", "\u2013", "Ach", "!", "ein", "un\u00b7be\u00b7lohn\u00b7ter", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "$.", "$(", "ITJ", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im Joch des Amts bei reifen Jahren,", "tokens": ["Im", "Joch", "des", "Amts", "bei", "rei\u00b7fen", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr andrer Wohl ersch\u00f6pft, als unbrauchbarer Greis", "tokens": ["F\u00fcr", "an\u00b7drer", "Wohl", "er\u00b7sch\u00f6pft", ",", "als", "un\u00b7brauch\u00b7ba\u00b7rer", "Greis"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hinunter in die Gruft zu fahren.", "tokens": ["Hin\u00b7un\u00b7ter", "in", "die", "Gruft", "zu", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch deiner wartet? \u2013 \u2013 Nein! was kannst du noch erwarten", "tokens": ["Doch", "dei\u00b7ner", "war\u00b7tet", "?", "\u2013", "\u2013", "Nein", "!", "was", "kannst", "du", "noch", "er\u00b7war\u00b7ten"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "VVFIN", "$.", "$(", "$(", "PTKANT", "$.", "PWS", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im Scho\u00df der vollen Seligkeit?", "tokens": ["Im", "Scho\u00df", "der", "vol\u00b7len", "Se\u00b7lig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nur wir, auf blindes Gl\u00fcck, als Schiffer ohne Karten,", "tokens": ["Nur", "wir", ",", "auf", "blin\u00b7des", "Gl\u00fcck", ",", "als", "Schif\u00b7fer", "oh\u00b7ne", "Kar\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "KOUS", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Durchkreuzen ihn, den faulen Pfuhl der Zeit.", "tokens": ["Durch\u00b7kreu\u00b7zen", "ihn", ",", "den", "fau\u00b7len", "Pfuhl", "der", "Zeit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Vielleicht \u2013 noch ehe du dein Gl\u00fccke wirst gewohnen,", "tokens": ["Viel\u00b7leicht", "\u2013", "noch", "e\u00b7he", "du", "dein", "Gl\u00fc\u00b7cke", "wirst", "ge\u00b7woh\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch ehe du es durchempfunden hast \u2013", "tokens": ["Noch", "e\u00b7he", "du", "es", "dur\u00b7ch\u00b7em\u00b7pfun\u00b7den", "hast", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PPER", "VVPP", "VAFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Flieht einer von uns nach in die verkl\u00e4rten Zonen,", "tokens": ["Flieht", "ei\u00b7ner", "von", "uns", "nach", "in", "die", "ver\u00b7kl\u00e4r\u00b7ten", "Zo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "APPR", "PPER", "APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "F\u00fcr dich ein alter Freund, und dort ein neuer Gast.", "tokens": ["F\u00fcr", "dich", "ein", "al\u00b7ter", "Freund", ",", "und", "dort", "ein", "neu\u00b7er", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wen wird \u2013 verborgner Rat! \u2013 die nahe Reise treffen", "tokens": ["Wen", "wird", "\u2013", "ver\u00b7borg\u00b7ner", "Rat", "!", "\u2013", "die", "na\u00b7he", "Rei\u00b7se", "tref\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$(", "ADJA", "NN", "$.", "$(", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Aus unsrer jetzt noch frischen Schar?", "tokens": ["Aus", "uns\u00b7rer", "jetzt", "noch", "fri\u00b7schen", "Schar", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O Freunde, la\u00dft euch nicht von s\u00fc\u00dfer Hoffnung \u00e4ffen!", "tokens": ["O", "Freun\u00b7de", ",", "la\u00dft", "euch", "nicht", "von", "s\u00fc\u00b7\u00dfer", "Hoff\u00b7nung", "\u00e4f\u00b7fen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVIMP", "PPER", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zum Wachsamsein verbarg Gott die Gefahr.", "tokens": ["Zum", "Wach\u00b7sam\u00b7sein", "ver\u00b7barg", "Gott", "die", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Komm ihm, wer er auch sei, verkl\u00e4rter Geist, entgegen,", "tokens": ["Komm", "ihm", ",", "wer", "er", "auch", "sei", ",", "ver\u00b7kl\u00e4r\u00b7ter", "Geist", ",", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWS", "PPER", "ADV", "VAFIN", "$,", "ADJA", "NN", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis an das Tor der bessern Welt,", "tokens": ["Bis", "an", "das", "Tor", "der", "bes\u00b7sern", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und f\u00fchr' ihn schnell, auf dir dann schon bekannten Wegen,", "tokens": ["Und", "f\u00fchr'", "ihn", "schnell", ",", "auf", "dir", "dann", "schon", "be\u00b7kann\u00b7ten", "We\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$,", "APPR", "PPER", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hin, wo die Huld Gerichte h\u00e4lt.", "tokens": ["Hin", ",", "wo", "die", "Huld", "Ge\u00b7rich\u00b7te", "h\u00e4lt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wo um der Weisheit Thron der Freundschaft Urbild schwebet,", "tokens": ["Wo", "um", "der", "Weis\u00b7heit", "Thron", "der", "Freund\u00b7schaft", "Ur\u00b7bild", "schwe\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In seraphinschem Glanze schwebt,", "tokens": ["In", "se\u00b7ra\u00b7phin\u00b7schem", "Glan\u00b7ze", "schwebt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verkn\u00fcpft uns einst ein Band, ein Band von ihr gewebet;", "tokens": ["Ver\u00b7kn\u00fcpft", "uns", "einst", "ein", "Band", ",", "ein", "Band", "von", "ihr", "ge\u00b7we\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zur ew'gen Dauer fest gewebt!", "tokens": ["Zur", "ew'\u00b7gen", "Dau\u00b7er", "fest", "ge\u00b7webt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}