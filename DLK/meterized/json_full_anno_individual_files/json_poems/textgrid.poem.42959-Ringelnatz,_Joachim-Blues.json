{"textgrid.poem.42959": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Blues", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn du nicht froh kannst denken,", "tokens": ["Wenn", "du", "nicht", "froh", "kannst", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Obwohl nichts Hartes dich bedr\u00fcckt,", "tokens": ["Ob\u00b7wohl", "nichts", "Har\u00b7tes", "dich", "be\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sollst du ein Bl\u00fcmchen verschenken,", "tokens": ["Sollst", "du", "ein", "Bl\u00fcm\u00b7chen", "ver\u00b7schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Aufs Geratewohl von dir gepfl\u00fcckt.", "tokens": ["Aufs", "Ge\u00b7ra\u00b7te\u00b7wohl", "von", "dir", "ge\u00b7pfl\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Irgendein staubiger, gelber, \u2013", "tokens": ["Ir\u00b7gend\u00b7ein", "stau\u00b7bi\u00b7ger", ",", "gel\u00b7ber", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "$,", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Sei's Hahnenfu\u00df \u2013 vom Wegesrand.", "tokens": ["Sei's", "Hah\u00b7nen\u00b7fu\u00df", "\u2013", "vom", "We\u00b7ges\u00b7rand", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schenke das Bl\u00fcmchen dir selber", "tokens": ["Und", "schen\u00b7ke", "das", "Bl\u00fcm\u00b7chen", "dir", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PPER", "ADV"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Aus linker Hand an die rechte Hand.", "tokens": ["Aus", "lin\u00b7ker", "Hand", "an", "die", "rech\u00b7te", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Und mache dir eine Verbeugung", "tokens": ["Und", "ma\u00b7che", "dir", "ei\u00b7ne", "Ver\u00b7beu\u00b7gung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Im Spiegel und sage: \u00bbDu,", "tokens": ["Im", "Spie\u00b7gel", "und", "sa\u00b7ge", ":", "\u00bb", "Du", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["APPRART", "NN", "KON", "VVFIN", "$.", "$(", "PPER", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich bin der \u00dcberzeugung,", "tokens": ["Ich", "bin", "der", "\u00dc\u00b7berz\u00b7eu\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dir setzt man einzig schrecklich zu.", "tokens": ["Dir", "setzt", "man", "ein\u00b7zig", "schreck\u00b7lich", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie w\u00e4r's, wenn du jetzt mal sachlich", "tokens": ["Wie", "w\u00e4r's", ",", "wenn", "du", "jetzt", "mal", "sach\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Flei\u00dfig einfach arbeiten t\u00e4tst?", "tokens": ["Flei\u00b7\u00dfig", "ein\u00b7fach", "ar\u00b7bei\u00b7ten", "t\u00e4tst", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVINF", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Sp\u00e4ter prahle nicht und jetzt lach nicht,", "tokens": ["Sp\u00e4\u00b7ter", "prah\u00b7le", "nicht", "und", "jetzt", "lach", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PTKNEG", "KON", "ADV", "VVFIN", "PTKNEG", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Da\u00df du nicht in \u00dcbermut ger\u00e4tst.\u00ab", "tokens": ["Da\u00df", "du", "nicht", "in", "\u00dc\u00b7ber\u00b7mut", "ge\u00b7r\u00e4tst", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Wenn du nicht froh kannst denken,", "tokens": ["Wenn", "du", "nicht", "froh", "kannst", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Obwohl nichts Hartes dich bedr\u00fcckt,", "tokens": ["Ob\u00b7wohl", "nichts", "Har\u00b7tes", "dich", "be\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sollst du ein Bl\u00fcmchen verschenken,", "tokens": ["Sollst", "du", "ein", "Bl\u00fcm\u00b7chen", "ver\u00b7schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Aufs Geratewohl von dir gepfl\u00fcckt.", "tokens": ["Aufs", "Ge\u00b7ra\u00b7te\u00b7wohl", "von", "dir", "ge\u00b7pfl\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Irgendein staubiger, gelber, \u2013", "tokens": ["Ir\u00b7gend\u00b7ein", "stau\u00b7bi\u00b7ger", ",", "gel\u00b7ber", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "$,", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Sei's Hahnenfu\u00df \u2013 vom Wegesrand.", "tokens": ["Sei's", "Hah\u00b7nen\u00b7fu\u00df", "\u2013", "vom", "We\u00b7ges\u00b7rand", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schenke das Bl\u00fcmchen dir selber", "tokens": ["Und", "schen\u00b7ke", "das", "Bl\u00fcm\u00b7chen", "dir", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PPER", "ADV"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Aus linker Hand an die rechte Hand.", "tokens": ["Aus", "lin\u00b7ker", "Hand", "an", "die", "rech\u00b7te", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Und mache dir eine Verbeugung", "tokens": ["Und", "ma\u00b7che", "dir", "ei\u00b7ne", "Ver\u00b7beu\u00b7gung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Im Spiegel und sage: \u00bbDu,", "tokens": ["Im", "Spie\u00b7gel", "und", "sa\u00b7ge", ":", "\u00bb", "Du", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["APPRART", "NN", "KON", "VVFIN", "$.", "$(", "PPER", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich bin der \u00dcberzeugung,", "tokens": ["Ich", "bin", "der", "\u00dc\u00b7berz\u00b7eu\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dir setzt man einzig schrecklich zu.", "tokens": ["Dir", "setzt", "man", "ein\u00b7zig", "schreck\u00b7lich", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie w\u00e4r's, wenn du jetzt mal sachlich", "tokens": ["Wie", "w\u00e4r's", ",", "wenn", "du", "jetzt", "mal", "sach\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Flei\u00dfig einfach arbeiten t\u00e4tst?", "tokens": ["Flei\u00b7\u00dfig", "ein\u00b7fach", "ar\u00b7bei\u00b7ten", "t\u00e4tst", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVINF", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Sp\u00e4ter prahle nicht und jetzt lach nicht,", "tokens": ["Sp\u00e4\u00b7ter", "prah\u00b7le", "nicht", "und", "jetzt", "lach", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PTKNEG", "KON", "ADV", "VVFIN", "PTKNEG", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Da\u00df du nicht in \u00dcbermut ger\u00e4tst.\u00ab", "tokens": ["Da\u00df", "du", "nicht", "in", "\u00dc\u00b7ber\u00b7mut", "ge\u00b7r\u00e4tst", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}