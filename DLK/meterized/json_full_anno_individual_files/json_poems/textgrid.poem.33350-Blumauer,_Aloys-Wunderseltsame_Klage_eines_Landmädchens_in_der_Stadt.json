{"textgrid.poem.33350": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Wunderseltsame Klage eines Landm\u00e4dchens in der Stadt", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du lieber Gott, bald dankt' ich dir", "tokens": ["Du", "lie\u00b7ber", "Gott", ",", "bald", "dankt'", "ich", "dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl nicht f\u00fcr deine Gabe;", "tokens": ["Wohl", "nicht", "f\u00fcr", "dei\u00b7ne", "Ga\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Noch nie war mir's so \u00e4rgerlich,", "tokens": ["Noch", "nie", "war", "mir's", "so", "\u00e4r\u00b7ger\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als in der grossen Stadt, da\u00df ich", "tokens": ["Als", "in", "der", "gros\u00b7sen", "Stadt", ",", "da\u00df", "ich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein h\u00fcbsch Gesichtchen habe.", "tokens": ["Ein", "h\u00fcbsch", "Ge\u00b7sicht\u00b7chen", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Schon sechzehn Sommer trug ich es", "tokens": ["Schon", "sech\u00b7zehn", "Som\u00b7mer", "trug", "ich", "es"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Haus, doch niemand nannte", "tokens": ["Zu", "Haus", ",", "doch", "nie\u00b7mand", "nann\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So engelsch\u00f6n mein Angesicht,", "tokens": ["So", "en\u00b7gel\u00b7sch\u00f6n", "mein", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch hatt' ich all die Plagen nicht,", "tokens": ["Auch", "hatt'", "ich", "all", "die", "Pla\u00b7gen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als hier bei meiner Tante.", "tokens": ["Als", "hier", "bei", "mei\u00b7ner", "Tan\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Kaum steh' ich auf, so bin ich schon", "tokens": ["Kaum", "steh'", "ich", "auf", ",", "so", "bin", "ich", "schon"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An's Putztischlein gebunden,", "tokens": ["An's", "Putz\u00b7tisc\u00b7hlein", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Tante Jungfer pudert, schmiert,", "tokens": ["Der", "Tan\u00b7te", "Jung\u00b7fer", "pu\u00b7dert", ",", "schmiert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gl\u00e4ttet, nadelt, faltet, schn\u00fcrt", "tokens": ["Und", "gl\u00e4t\u00b7tet", ",", "na\u00b7delt", ",", "fal\u00b7tet", ",", "schn\u00fcrt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zwei lange, lange Stunden.", "tokens": ["Zwei", "lan\u00b7ge", ",", "lan\u00b7ge", "Stun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die Tante will, es soll mein Kopf", "tokens": ["Die", "Tan\u00b7te", "will", ",", "es", "soll", "mein", "Kopf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "$,", "PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Damenk\u00f6pfen gleichen:", "tokens": ["Den", "Da\u00b7men\u00b7k\u00f6p\u00b7fen", "glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da l\u00e4\u00dft sie meiner Wangen Roth,", "tokens": ["Da", "l\u00e4\u00dft", "sie", "mei\u00b7ner", "Wan\u00b7gen", "Roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das du mir gabst, du lieber Gott,", "tokens": ["Das", "du", "mir", "gabst", ",", "du", "lie\u00b7ber", "Gott", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVFIN", "$,", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Mennig \u00fcberstreichen.", "tokens": ["Mit", "Men\u00b7nig", "\u00fc\u00b7bers\u00b7trei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich durfte sonst von \u00bbBauch hinein!\u00ab", "tokens": ["Ich", "durf\u00b7te", "sonst", "von", "\u00bb", "Bauch", "hin\u00b7ein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "$(", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u00bbBrust heraus!\u00ab nichts wissen;", "tokens": ["Und", "\u00bb", "Brust", "he\u00b7raus", "!", "\u00ab", "nichts", "wis\u00b7sen", ";"], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "$(", "NN", "PTKVZ", "$.", "$(", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch hier geh'n M\u00e4dchen ja so schwer,", "tokens": ["Doch", "hier", "geh'n", "M\u00e4d\u00b7chen", "ja", "so", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So steif und schnurgerad' einher.", "tokens": ["So", "steif", "und", "schnur\u00b7ge\u00b7rad'", "ein\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als stecken sie an Spiessen.", "tokens": ["Als", "ste\u00b7cken", "sie", "an", "Spies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wie frei konnt' ich zu Haus herum", "tokens": ["Wie", "frei", "konnt'", "ich", "zu", "Haus", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "APPR", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Feld und Anger gehen!", "tokens": ["Auf", "Feld", "und", "An\u00b7ger", "ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hier gafft und schielet man nach mir,", "tokens": ["Hier", "gafft", "und", "schie\u00b7let", "man", "nach", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wie nach einem Wunderthier,", "tokens": ["Als", "wie", "nach", "ei\u00b7nem", "Wun\u00b7der\u00b7thier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das man f\u00fcr Geld l\u00e4\u00dft sehen. \u2013", "tokens": ["Das", "man", "f\u00fcr", "Geld", "l\u00e4\u00dft", "se\u00b7hen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PIS", "APPR", "NN", "VVFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die Herren in Gesellschaft sind", "tokens": ["Die", "Her\u00b7ren", "in", "Ge\u00b7sell\u00b7schaft", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gar unversch\u00e4mt im Scherzen,", "tokens": ["Gar", "un\u00b7ver\u00b7sch\u00e4mt", "im", "Scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Betheuern zuversichtlich mir,", "tokens": ["Be\u00b7theu\u00b7ern", "zu\u00b7ver\u00b7sicht\u00b7lich", "mir", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Cupido sa\u00df' im Auge hier,", "tokens": ["Cu\u00b7pi\u00b7do", "sa\u00df'", "im", "Au\u00b7ge", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ziele nach dem Herzen.", "tokens": ["Und", "zie\u00b7le", "nach", "dem", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ich w\u00fc\u00dfte nicht, da\u00df so ein Ding", "tokens": ["Ich", "w\u00fc\u00df\u00b7te", "nicht", ",", "da\u00df", "so", "ein", "Ding"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir je in's Aug' gekrochen,", "tokens": ["Mir", "je", "in's", "Aug'", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und doch behaupten alle k\u00fchn,", "tokens": ["Und", "doch", "be\u00b7haup\u00b7ten", "al\u00b7le", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Pfeil und Bogen s\u00e4\u00df' er d'rin", "tokens": ["Mit", "Pfeil", "und", "Bo\u00b7gen", "s\u00e4\u00df'", "er", "d'\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "NE"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.5": {"text": "Und habe sie gestochen.", "tokens": ["Und", "ha\u00b7be", "sie", "ge\u00b7sto\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Oft seh'n sie gar \u2013 Gott wei\u00df, woraus", "tokens": ["Oft", "seh'n", "sie", "gar", "\u2013", "Gott", "wei\u00df", ",", "wo\u00b7raus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "NN", "VVFIN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie solche L\u00fcgen saugen \u2013", "tokens": ["Sie", "sol\u00b7che", "L\u00fc\u00b7gen", "sau\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf meinen Wangen Rosen steh'n", "tokens": ["Auf", "mei\u00b7nen", "Wan\u00b7gen", "Ro\u00b7sen", "steh'n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf meiner Stirne Lilien,", "tokens": ["Auf", "mei\u00b7ner", "Stir\u00b7ne", "Li\u00b7li\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Sonnen in den Augen.", "tokens": ["Und", "Son\u00b7nen", "in", "den", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Da werd' ich kurios, beseh'", "tokens": ["Da", "werd'", "ich", "ku\u00b7ri\u00b7os", ",", "be\u00b7seh'"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Spiegel mich, und finde", "tokens": ["Im", "Spie\u00b7gel", "mich", ",", "und", "fin\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "PPER", "$,", "KON", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von allen diesem keine Spur:", "tokens": ["Von", "al\u00b7len", "die\u00b7sem", "kei\u00b7ne", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDAT", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gewi\u00df, die Herren l\u00fcgen nur,", "tokens": ["Ge\u00b7wi\u00df", ",", "die", "Her\u00b7ren", "l\u00fc\u00b7gen", "nur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und l\u00fcgen ist doch S\u00fcnde.", "tokens": ["Und", "l\u00fc\u00b7gen", "ist", "doch", "S\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Gar unausstehlich ist's, wenn sie \u2013", "tokens": ["Gar", "un\u00b7aus\u00b7steh\u00b7lich", "ist's", ",", "wenn", "sie", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie nennen's, glaub' ich \u2013 schmachten", "tokens": ["Sie", "nen\u00b7nen's", ",", "glaub'", "ich", "\u2013", "schmach\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$(", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da thun sie so erb\u00e4rmlich klein", "tokens": ["Da", "thun", "sie", "so", "er\u00b7b\u00e4rm\u00b7lich", "klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ohrh\u00e4ngen, wie die Eselein,", "tokens": ["Ohr\u00b7h\u00e4n\u00b7gen", ",", "wie", "die", "E\u00b7sel\u00b7ein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man sie mu\u00df verachten.", "tokens": ["Da\u00df", "man", "sie", "mu\u00df", "ver\u00b7ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VMFIN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Da schneiden sie vor Liebesgram", "tokens": ["Da", "schnei\u00b7den", "sie", "vor", "Lie\u00b7bes\u00b7gram"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gesichter zum erschrecken;", "tokens": ["Ge\u00b7sich\u00b7ter", "zum", "er\u00b7schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sind doch wei\u00df und roth, wie ich,", "tokens": ["Und", "sind", "doch", "wei\u00df", "und", "roth", ",", "wie", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "KON", "ADJD", "$,", "PWAV", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lassen Trank und Speise sich,", "tokens": ["Und", "las\u00b7sen", "Trank", "und", "Spei\u00b7se", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie and're Menschen schmecken.", "tokens": ["Wie", "an\u00b7d'\u00b7re", "Men\u00b7schen", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Oft kommen sie herangeh\u00fcpft,", "tokens": ["Oft", "kom\u00b7men", "sie", "her\u00b7an\u00b7ge\u00b7h\u00fcpft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So recht als wie die Hasen,", "tokens": ["So", "recht", "als", "wie", "die", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und seufzen ein's von Liebesqual,", "tokens": ["Und", "seuf\u00b7zen", "ein's", "von", "Lie\u00b7bes\u00b7qual", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wischen sich wohl hundertmal", "tokens": ["Und", "wi\u00b7schen", "sich", "wohl", "hun\u00b7dert\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "An meiner Hand die Nasen.", "tokens": ["An", "mei\u00b7ner", "Hand", "die", "Na\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Doch kehret oft im Augenblick", "tokens": ["Doch", "keh\u00b7ret", "oft", "im", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Muthwill' unvermuthet:", "tokens": ["Ihr", "Muthwill'", "un\u00b7ver\u00b7mu\u00b7thet", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Dann spitzen sie das Z\u00fcngelchen,", "tokens": ["Dann", "spit\u00b7zen", "sie", "das", "Z\u00fcn\u00b7gel\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Und schimpfen auf die H\u00e4\u00dflichen,", "tokens": ["Und", "schimp\u00b7fen", "auf", "die", "H\u00e4\u00df\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Da\u00df mir die Seele blutet.", "tokens": ["Da\u00df", "mir", "die", "See\u00b7le", "blu\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Ist etwa mein Gesichtchen Schuld", "tokens": ["Ist", "et\u00b7wa", "mein", "Ge\u00b7sicht\u00b7chen", "Schuld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An allen diesen S\u00fcnden,", "tokens": ["An", "al\u00b7len", "die\u00b7sen", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du lieber Gott, so mache! da\u00df", "tokens": ["Du", "lie\u00b7ber", "Gott", ",", "so", "ma\u00b7che", "!", "da\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "ADV", "NN", "$,", "ADV", "VVFIN", "$.", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich h\u00e4\u00dflich werde, oder la\u00df", "tokens": ["Ich", "h\u00e4\u00df\u00b7lich", "wer\u00b7de", ",", "o\u00b7der", "la\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADJD", "VAFIN", "$,", "KON", "VVIMP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Herren all' erblinden.", "tokens": ["Die", "Her\u00b7ren", "all'", "er\u00b7blin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Du lieber Gott, bald dankt' ich dir", "tokens": ["Du", "lie\u00b7ber", "Gott", ",", "bald", "dankt'", "ich", "dir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl nicht f\u00fcr deine Gabe;", "tokens": ["Wohl", "nicht", "f\u00fcr", "dei\u00b7ne", "Ga\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Noch nie war mir's so \u00e4rgerlich,", "tokens": ["Noch", "nie", "war", "mir's", "so", "\u00e4r\u00b7ger\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als in der grossen Stadt, da\u00df ich", "tokens": ["Als", "in", "der", "gros\u00b7sen", "Stadt", ",", "da\u00df", "ich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein h\u00fcbsch Gesichtchen habe.", "tokens": ["Ein", "h\u00fcbsch", "Ge\u00b7sicht\u00b7chen", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Schon sechzehn Sommer trug ich es", "tokens": ["Schon", "sech\u00b7zehn", "Som\u00b7mer", "trug", "ich", "es"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Haus, doch niemand nannte", "tokens": ["Zu", "Haus", ",", "doch", "nie\u00b7mand", "nann\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So engelsch\u00f6n mein Angesicht,", "tokens": ["So", "en\u00b7gel\u00b7sch\u00f6n", "mein", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch hatt' ich all die Plagen nicht,", "tokens": ["Auch", "hatt'", "ich", "all", "die", "Pla\u00b7gen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als hier bei meiner Tante.", "tokens": ["Als", "hier", "bei", "mei\u00b7ner", "Tan\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Kaum steh' ich auf, so bin ich schon", "tokens": ["Kaum", "steh'", "ich", "auf", ",", "so", "bin", "ich", "schon"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An's Putztischlein gebunden,", "tokens": ["An's", "Putz\u00b7tisc\u00b7hlein", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Tante Jungfer pudert, schmiert,", "tokens": ["Der", "Tan\u00b7te", "Jung\u00b7fer", "pu\u00b7dert", ",", "schmiert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gl\u00e4ttet, nadelt, faltet, schn\u00fcrt", "tokens": ["Und", "gl\u00e4t\u00b7tet", ",", "na\u00b7delt", ",", "fal\u00b7tet", ",", "schn\u00fcrt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zwei lange, lange Stunden.", "tokens": ["Zwei", "lan\u00b7ge", ",", "lan\u00b7ge", "Stun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Die Tante will, es soll mein Kopf", "tokens": ["Die", "Tan\u00b7te", "will", ",", "es", "soll", "mein", "Kopf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "$,", "PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Damenk\u00f6pfen gleichen:", "tokens": ["Den", "Da\u00b7men\u00b7k\u00f6p\u00b7fen", "glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da l\u00e4\u00dft sie meiner Wangen Roth,", "tokens": ["Da", "l\u00e4\u00dft", "sie", "mei\u00b7ner", "Wan\u00b7gen", "Roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das du mir gabst, du lieber Gott,", "tokens": ["Das", "du", "mir", "gabst", ",", "du", "lie\u00b7ber", "Gott", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVFIN", "$,", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Mennig \u00fcberstreichen.", "tokens": ["Mit", "Men\u00b7nig", "\u00fc\u00b7bers\u00b7trei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Ich durfte sonst von \u00bbBauch hinein!\u00ab", "tokens": ["Ich", "durf\u00b7te", "sonst", "von", "\u00bb", "Bauch", "hin\u00b7ein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "$(", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u00bbBrust heraus!\u00ab nichts wissen;", "tokens": ["Und", "\u00bb", "Brust", "he\u00b7raus", "!", "\u00ab", "nichts", "wis\u00b7sen", ";"], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "$(", "NN", "PTKVZ", "$.", "$(", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch hier geh'n M\u00e4dchen ja so schwer,", "tokens": ["Doch", "hier", "geh'n", "M\u00e4d\u00b7chen", "ja", "so", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So steif und schnurgerad' einher.", "tokens": ["So", "steif", "und", "schnur\u00b7ge\u00b7rad'", "ein\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als stecken sie an Spiessen.", "tokens": ["Als", "ste\u00b7cken", "sie", "an", "Spies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Wie frei konnt' ich zu Haus herum", "tokens": ["Wie", "frei", "konnt'", "ich", "zu", "Haus", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "APPR", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Feld und Anger gehen!", "tokens": ["Auf", "Feld", "und", "An\u00b7ger", "ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hier gafft und schielet man nach mir,", "tokens": ["Hier", "gafft", "und", "schie\u00b7let", "man", "nach", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wie nach einem Wunderthier,", "tokens": ["Als", "wie", "nach", "ei\u00b7nem", "Wun\u00b7der\u00b7thier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das man f\u00fcr Geld l\u00e4\u00dft sehen. \u2013", "tokens": ["Das", "man", "f\u00fcr", "Geld", "l\u00e4\u00dft", "se\u00b7hen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PIS", "APPR", "NN", "VVFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Die Herren in Gesellschaft sind", "tokens": ["Die", "Her\u00b7ren", "in", "Ge\u00b7sell\u00b7schaft", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gar unversch\u00e4mt im Scherzen,", "tokens": ["Gar", "un\u00b7ver\u00b7sch\u00e4mt", "im", "Scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Betheuern zuversichtlich mir,", "tokens": ["Be\u00b7theu\u00b7ern", "zu\u00b7ver\u00b7sicht\u00b7lich", "mir", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Cupido sa\u00df' im Auge hier,", "tokens": ["Cu\u00b7pi\u00b7do", "sa\u00df'", "im", "Au\u00b7ge", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ziele nach dem Herzen.", "tokens": ["Und", "zie\u00b7le", "nach", "dem", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Ich w\u00fc\u00dfte nicht, da\u00df so ein Ding", "tokens": ["Ich", "w\u00fc\u00df\u00b7te", "nicht", ",", "da\u00df", "so", "ein", "Ding"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir je in's Aug' gekrochen,", "tokens": ["Mir", "je", "in's", "Aug'", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und doch behaupten alle k\u00fchn,", "tokens": ["Und", "doch", "be\u00b7haup\u00b7ten", "al\u00b7le", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Pfeil und Bogen s\u00e4\u00df' er d'rin", "tokens": ["Mit", "Pfeil", "und", "Bo\u00b7gen", "s\u00e4\u00df'", "er", "d'\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "NE"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.5": {"text": "Und habe sie gestochen.", "tokens": ["Und", "ha\u00b7be", "sie", "ge\u00b7sto\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Oft seh'n sie gar \u2013 Gott wei\u00df, woraus", "tokens": ["Oft", "seh'n", "sie", "gar", "\u2013", "Gott", "wei\u00df", ",", "wo\u00b7raus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "NN", "VVFIN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie solche L\u00fcgen saugen \u2013", "tokens": ["Sie", "sol\u00b7che", "L\u00fc\u00b7gen", "sau\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf meinen Wangen Rosen steh'n", "tokens": ["Auf", "mei\u00b7nen", "Wan\u00b7gen", "Ro\u00b7sen", "steh'n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf meiner Stirne Lilien,", "tokens": ["Auf", "mei\u00b7ner", "Stir\u00b7ne", "Li\u00b7li\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Sonnen in den Augen.", "tokens": ["Und", "Son\u00b7nen", "in", "den", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Da werd' ich kurios, beseh'", "tokens": ["Da", "werd'", "ich", "ku\u00b7ri\u00b7os", ",", "be\u00b7seh'"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Spiegel mich, und finde", "tokens": ["Im", "Spie\u00b7gel", "mich", ",", "und", "fin\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "PPER", "$,", "KON", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von allen diesem keine Spur:", "tokens": ["Von", "al\u00b7len", "die\u00b7sem", "kei\u00b7ne", "Spur", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDAT", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gewi\u00df, die Herren l\u00fcgen nur,", "tokens": ["Ge\u00b7wi\u00df", ",", "die", "Her\u00b7ren", "l\u00fc\u00b7gen", "nur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und l\u00fcgen ist doch S\u00fcnde.", "tokens": ["Und", "l\u00fc\u00b7gen", "ist", "doch", "S\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Gar unausstehlich ist's, wenn sie \u2013", "tokens": ["Gar", "un\u00b7aus\u00b7steh\u00b7lich", "ist's", ",", "wenn", "sie", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie nennen's, glaub' ich \u2013 schmachten", "tokens": ["Sie", "nen\u00b7nen's", ",", "glaub'", "ich", "\u2013", "schmach\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$(", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da thun sie so erb\u00e4rmlich klein", "tokens": ["Da", "thun", "sie", "so", "er\u00b7b\u00e4rm\u00b7lich", "klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ohrh\u00e4ngen, wie die Eselein,", "tokens": ["Ohr\u00b7h\u00e4n\u00b7gen", ",", "wie", "die", "E\u00b7sel\u00b7ein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man sie mu\u00df verachten.", "tokens": ["Da\u00df", "man", "sie", "mu\u00df", "ver\u00b7ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VMFIN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Da schneiden sie vor Liebesgram", "tokens": ["Da", "schnei\u00b7den", "sie", "vor", "Lie\u00b7bes\u00b7gram"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gesichter zum erschrecken;", "tokens": ["Ge\u00b7sich\u00b7ter", "zum", "er\u00b7schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sind doch wei\u00df und roth, wie ich,", "tokens": ["Und", "sind", "doch", "wei\u00df", "und", "roth", ",", "wie", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "KON", "ADJD", "$,", "PWAV", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lassen Trank und Speise sich,", "tokens": ["Und", "las\u00b7sen", "Trank", "und", "Spei\u00b7se", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie and're Menschen schmecken.", "tokens": ["Wie", "an\u00b7d'\u00b7re", "Men\u00b7schen", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.28": {"line.1": {"text": "Oft kommen sie herangeh\u00fcpft,", "tokens": ["Oft", "kom\u00b7men", "sie", "her\u00b7an\u00b7ge\u00b7h\u00fcpft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So recht als wie die Hasen,", "tokens": ["So", "recht", "als", "wie", "die", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und seufzen ein's von Liebesqual,", "tokens": ["Und", "seuf\u00b7zen", "ein's", "von", "Lie\u00b7bes\u00b7qual", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wischen sich wohl hundertmal", "tokens": ["Und", "wi\u00b7schen", "sich", "wohl", "hun\u00b7dert\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "An meiner Hand die Nasen.", "tokens": ["An", "mei\u00b7ner", "Hand", "die", "Na\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Doch kehret oft im Augenblick", "tokens": ["Doch", "keh\u00b7ret", "oft", "im", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Muthwill' unvermuthet:", "tokens": ["Ihr", "Muthwill'", "un\u00b7ver\u00b7mu\u00b7thet", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Dann spitzen sie das Z\u00fcngelchen,", "tokens": ["Dann", "spit\u00b7zen", "sie", "das", "Z\u00fcn\u00b7gel\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Und schimpfen auf die H\u00e4\u00dflichen,", "tokens": ["Und", "schimp\u00b7fen", "auf", "die", "H\u00e4\u00df\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Da\u00df mir die Seele blutet.", "tokens": ["Da\u00df", "mir", "die", "See\u00b7le", "blu\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Ist etwa mein Gesichtchen Schuld", "tokens": ["Ist", "et\u00b7wa", "mein", "Ge\u00b7sicht\u00b7chen", "Schuld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An allen diesen S\u00fcnden,", "tokens": ["An", "al\u00b7len", "die\u00b7sen", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du lieber Gott, so mache! da\u00df", "tokens": ["Du", "lie\u00b7ber", "Gott", ",", "so", "ma\u00b7che", "!", "da\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "ADV", "NN", "$,", "ADV", "VVFIN", "$.", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich h\u00e4\u00dflich werde, oder la\u00df", "tokens": ["Ich", "h\u00e4\u00df\u00b7lich", "wer\u00b7de", ",", "o\u00b7der", "la\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADJD", "VAFIN", "$,", "KON", "VVIMP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Herren all' erblinden.", "tokens": ["Die", "Her\u00b7ren", "all'", "er\u00b7blin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}