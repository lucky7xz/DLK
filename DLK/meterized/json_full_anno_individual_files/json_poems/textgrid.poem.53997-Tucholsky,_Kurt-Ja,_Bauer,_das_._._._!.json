{"textgrid.poem.53997": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Ja, Bauer, das . . . !", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "S\u00e4mtliche Buchh\u00e4ndlerfenster sind voll", "tokens": ["S\u00e4mt\u00b7li\u00b7che", "Buch\u00b7h\u00e4nd\u00b7ler\u00b7fens\u00b7ter", "sind", "voll"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "ADJD"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "von Kriegsb\u00fcchern und Romanen.", "tokens": ["von", "Kriegs\u00b7b\u00fc\u00b7chern", "und", "Ro\u00b7ma\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Die Presse war schuld! Der Kaiser war toll!", "tokens": ["Die", "Pres\u00b7se", "war", "schuld", "!", "Der", "Kai\u00b7ser", "war", "toll", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Man hat uns mit allen Schikanen", "tokens": ["Man", "hat", "uns", "mit", "al\u00b7len", "Schi\u00b7ka\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "belogen,", "tokens": ["be\u00b7lo\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "betrogen,", "tokens": ["be\u00b7tro\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "dumm gemacht,", "tokens": ["dumm", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "ums Denken gebracht \u2013", "tokens": ["ums", "Den\u00b7ken", "ge\u00b7bracht", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Gro\u00dfer Katzenjammer.", "tokens": ["Gro\u00b7\u00dfer", "Kat\u00b7zen\u00b7jam\u00b7mer", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Nat\u00fcrlich hat es sich nicht gelohnt.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "hat", "es", "sich", "nicht", "ge\u00b7lohnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.11": {"text": "Nat\u00fcrlich h\u00e4tten wir die andern geschont.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "h\u00e4t\u00b7ten", "wir", "die", "an\u00b7dern", "ge\u00b7schont", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Nat\u00fcrlich ist alles ganz falsch gewesen.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "ist", "al\u00b7les", "ganz", "falsch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "ADJD", "VAPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Nat\u00fcrlich ist unschuldig deutsches Wesen.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "ist", "un\u00b7schul\u00b7dig", "deut\u00b7sches", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Auf ein Mal", "tokens": ["Auf", "ein", "Mal"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "sind sie sentimental,", "tokens": ["sind", "sie", "sen\u00b7ti\u00b7men\u00b7tal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.16": {"text": "gef\u00fchlvoll, pathetisch und Kriegsverdammer.", "tokens": ["ge\u00b7f\u00fchl\u00b7voll", ",", "pa\u00b7the\u00b7tisch", "und", "Kriegs\u00b7ver\u00b7dam\u00b7mer", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Gro\u00dfer Katzenjammer.", "tokens": ["Gro\u00b7\u00dfer", "Kat\u00b7zen\u00b7jam\u00b7mer", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Aber \u2013:", "tokens": ["A\u00b7ber", "\u2013", ":"], "token_info": ["word", "punct", "punct"], "pos": ["KON", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Geht das morgen wieder los,", "tokens": ["Geht", "das", "mor\u00b7gen", "wie\u00b7der", "los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "vertauschst du nur die Farben,", "tokens": ["ver\u00b7tauschst", "du", "nur", "die", "Far\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "dann erleiden Millionen ein schlimmeres Los \u2013", "tokens": ["dann", "er\u00b7lei\u00b7den", "Mil\u00b7lion\u00b7en", "ein", "schlim\u00b7me\u00b7res", "Los", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ART", "ADJA", "NN", "$("], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.5": {"text": "vergessen, wie andere starben.", "tokens": ["ver\u00b7ges\u00b7sen", ",", "wie", "an\u00b7de\u00b7re", "star\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Polen zum Beispiel . . . der Korridor . . .", "tokens": ["Po\u00b7len", "zum", "Bei\u00b7spiel", ".", ".", ".", "der", "Kor\u00b7ri\u00b7dor", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "APPRART", "NN", "$.", "$.", "$.", "ART", "NN", "$.", "$.", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Da st\u00fcrmen zehntausend Freiwillige vor . . .", "tokens": ["Da", "st\u00fcr\u00b7men", "zehn\u00b7tau\u00b7send", "Frei\u00b7wil\u00b7li\u00b7ge", "vor", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "PTKVZ", "$.", "$.", "$."], "meter": "-+--+-+---+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "da knattern die neuen Fahnen im Wind;", "tokens": ["da", "knat\u00b7tern", "die", "neu\u00b7en", "Fah\u00b7nen", "im", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "da bilden Gro\u00dfvater und Enkelkind", "tokens": ["da", "bil\u00b7den", "Gro\u00df\u00b7va\u00b7ter", "und", "En\u00b7kel\u00b7kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.10": {"text": "das von ihrer Zeitung befohlene Spalier!", "tokens": ["das", "von", "ih\u00b7rer", "Zei\u00b7tung", "be\u00b7foh\u00b7le\u00b7ne", "Spa\u00b7lier", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+--+--+---+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Deutschland seis Panier!", "tokens": ["Deutschland", "seis", "Pa\u00b7nier", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.12": {"text": "Flaggen! Geflaggt ist jedes Haus.", "tokens": ["Flag\u00b7gen", "!", "Ge\u00b7flaggt", "ist", "je\u00b7des", "Haus", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVPP", "VAFIN", "PIAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Burschen heraus!", "tokens": ["Bur\u00b7schen", "he\u00b7raus", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Und du h\u00f6rst im Knallen des Salamanders:", "tokens": ["Und", "du", "h\u00f6rst", "im", "Knal\u00b7len", "des", "Sa\u00b7la\u00b7man\u00b7ders", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.15": {"text": "Ja, Bauer, das ist ganz was anders \u2013!", "tokens": ["Ja", ",", "Bau\u00b7er", ",", "das", "ist", "ganz", "was", "an\u00b7ders", "\u2013", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "PDS", "VAFIN", "ADV", "PWS", "ADV", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "S\u00e4mtliche Buchh\u00e4ndlerfenster sind voll", "tokens": ["S\u00e4mt\u00b7li\u00b7che", "Buch\u00b7h\u00e4nd\u00b7ler\u00b7fens\u00b7ter", "sind", "voll"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "ADJD"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "von Kriegsb\u00fcchern und Romanen.", "tokens": ["von", "Kriegs\u00b7b\u00fc\u00b7chern", "und", "Ro\u00b7ma\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Die Presse war schuld! Der Kaiser war toll!", "tokens": ["Die", "Pres\u00b7se", "war", "schuld", "!", "Der", "Kai\u00b7ser", "war", "toll", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Man hat uns mit allen Schikanen", "tokens": ["Man", "hat", "uns", "mit", "al\u00b7len", "Schi\u00b7ka\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "belogen,", "tokens": ["be\u00b7lo\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "betrogen,", "tokens": ["be\u00b7tro\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "dumm gemacht,", "tokens": ["dumm", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "ums Denken gebracht \u2013", "tokens": ["ums", "Den\u00b7ken", "ge\u00b7bracht", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Gro\u00dfer Katzenjammer.", "tokens": ["Gro\u00b7\u00dfer", "Kat\u00b7zen\u00b7jam\u00b7mer", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Nat\u00fcrlich hat es sich nicht gelohnt.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "hat", "es", "sich", "nicht", "ge\u00b7lohnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.11": {"text": "Nat\u00fcrlich h\u00e4tten wir die andern geschont.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "h\u00e4t\u00b7ten", "wir", "die", "an\u00b7dern", "ge\u00b7schont", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Nat\u00fcrlich ist alles ganz falsch gewesen.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "ist", "al\u00b7les", "ganz", "falsch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "ADJD", "VAPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Nat\u00fcrlich ist unschuldig deutsches Wesen.", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "ist", "un\u00b7schul\u00b7dig", "deut\u00b7sches", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Auf ein Mal", "tokens": ["Auf", "ein", "Mal"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "sind sie sentimental,", "tokens": ["sind", "sie", "sen\u00b7ti\u00b7men\u00b7tal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.16": {"text": "gef\u00fchlvoll, pathetisch und Kriegsverdammer.", "tokens": ["ge\u00b7f\u00fchl\u00b7voll", ",", "pa\u00b7the\u00b7tisch", "und", "Kriegs\u00b7ver\u00b7dam\u00b7mer", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Gro\u00dfer Katzenjammer.", "tokens": ["Gro\u00b7\u00dfer", "Kat\u00b7zen\u00b7jam\u00b7mer", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Aber \u2013:", "tokens": ["A\u00b7ber", "\u2013", ":"], "token_info": ["word", "punct", "punct"], "pos": ["KON", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Geht das morgen wieder los,", "tokens": ["Geht", "das", "mor\u00b7gen", "wie\u00b7der", "los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "vertauschst du nur die Farben,", "tokens": ["ver\u00b7tauschst", "du", "nur", "die", "Far\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "dann erleiden Millionen ein schlimmeres Los \u2013", "tokens": ["dann", "er\u00b7lei\u00b7den", "Mil\u00b7lion\u00b7en", "ein", "schlim\u00b7me\u00b7res", "Los", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ART", "ADJA", "NN", "$("], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.5": {"text": "vergessen, wie andere starben.", "tokens": ["ver\u00b7ges\u00b7sen", ",", "wie", "an\u00b7de\u00b7re", "star\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Polen zum Beispiel . . . der Korridor . . .", "tokens": ["Po\u00b7len", "zum", "Bei\u00b7spiel", ".", ".", ".", "der", "Kor\u00b7ri\u00b7dor", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "APPRART", "NN", "$.", "$.", "$.", "ART", "NN", "$.", "$.", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Da st\u00fcrmen zehntausend Freiwillige vor . . .", "tokens": ["Da", "st\u00fcr\u00b7men", "zehn\u00b7tau\u00b7send", "Frei\u00b7wil\u00b7li\u00b7ge", "vor", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "PTKVZ", "$.", "$.", "$."], "meter": "-+--+-+---+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "da knattern die neuen Fahnen im Wind;", "tokens": ["da", "knat\u00b7tern", "die", "neu\u00b7en", "Fah\u00b7nen", "im", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "da bilden Gro\u00dfvater und Enkelkind", "tokens": ["da", "bil\u00b7den", "Gro\u00df\u00b7va\u00b7ter", "und", "En\u00b7kel\u00b7kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.10": {"text": "das von ihrer Zeitung befohlene Spalier!", "tokens": ["das", "von", "ih\u00b7rer", "Zei\u00b7tung", "be\u00b7foh\u00b7le\u00b7ne", "Spa\u00b7lier", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+--+--+---+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Deutschland seis Panier!", "tokens": ["Deutschland", "seis", "Pa\u00b7nier", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.12": {"text": "Flaggen! Geflaggt ist jedes Haus.", "tokens": ["Flag\u00b7gen", "!", "Ge\u00b7flaggt", "ist", "je\u00b7des", "Haus", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVPP", "VAFIN", "PIAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Burschen heraus!", "tokens": ["Bur\u00b7schen", "he\u00b7raus", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Und du h\u00f6rst im Knallen des Salamanders:", "tokens": ["Und", "du", "h\u00f6rst", "im", "Knal\u00b7len", "des", "Sa\u00b7la\u00b7man\u00b7ders", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.15": {"text": "Ja, Bauer, das ist ganz was anders \u2013!", "tokens": ["Ja", ",", "Bau\u00b7er", ",", "das", "ist", "ganz", "was", "an\u00b7ders", "\u2013", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "PDS", "VAFIN", "ADV", "PWS", "ADV", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}