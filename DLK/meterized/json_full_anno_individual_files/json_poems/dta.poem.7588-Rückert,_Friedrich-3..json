{"dta.poem.7588": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "3.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1836", "urn": "urn:nbn:de:kobv:b4-200905195073", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich war im fremden Land in Sklaverei gekommen,", "tokens": ["Ich", "war", "im", "frem\u00b7den", "Land", "in", "Skla\u00b7ve\u00b7rei", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da hat ein frommer Herr sich meiner angenommen.", "tokens": ["Da", "hat", "ein", "from\u00b7mer", "Herr", "sich", "mei\u00b7ner", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PRF", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich dient' ihm treu ein Jahr, da gab er schon mich frei,", "tokens": ["Ich", "dient'", "ihm", "treu", "ein", "Jahr", ",", "da", "gab", "er", "schon", "mich", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mir als Lohn dazu der Silberst\u00fccke zwei.", "tokens": ["Und", "mir", "als", "Lohn", "da\u00b7zu", "der", "Sil\u00b7ber\u00b7st\u00fc\u00b7cke", "zwei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "KOUS", "NN", "PAV", "ART", "NN", "CARD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Sogleich gelobt' ich eins zur Heimreis' anzuwenden,", "tokens": ["Sog\u00b7leich", "ge\u00b7lobt'", "ich", "eins", "zur", "Heim\u00b7reis'", "an\u00b7zu\u00b7wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "APPRART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das andre dankbar als Almosen auszuspenden.", "tokens": ["Das", "and\u00b7re", "dank\u00b7bar", "als", "Al\u00b7mo\u00b7sen", "aus\u00b7zu\u00b7spen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "KOKOM", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Da kam ich \u00fcber'n Markt, und nahm im K\u00e4fich wahr,", "tokens": ["Da", "kam", "ich", "\u00fc\u00b7ber'n", "Markt", ",", "und", "nahm", "im", "K\u00e4\u00b7fich", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom F\u00e4nger zum Verkauf gestellt, ein Vogelpaar.", "tokens": ["Vom", "F\u00e4n\u00b7ger", "zum", "Ver\u00b7kauf", "ge\u00b7stellt", ",", "ein", "Vo\u00b7gel\u00b7paar", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "NN", "VVPP", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Was ist f\u00fcr einen der Gefangenschaft entgangnen", "tokens": ["Was", "ist", "f\u00fcr", "ei\u00b7nen", "der", "Ge\u00b7fan\u00b7gen\u00b7schaft", "ent\u00b7gang\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "APPR", "ART", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verdienstlicher als frei zu kaufen die Gefangnen?", "tokens": ["Ver\u00b7dienst\u00b7li\u00b7cher", "als", "frei", "zu", "kau\u00b7fen", "die", "Ge\u00b7fang\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADJD", "PTKZU", "VVINF", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "F\u00fcr beide forderte der Mann zwei Silberst\u00fccke;", "tokens": ["F\u00fcr", "bei\u00b7de", "for\u00b7der\u00b7te", "der", "Mann", "zwei", "Sil\u00b7ber\u00b7st\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "ART", "NN", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch eins behielt' ich selbst zur Reise gern zur\u00fccke.", "tokens": ["Doch", "eins", "be\u00b7hielt'", "ich", "selbst", "zur", "Rei\u00b7se", "gern", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ich bot ihm auf die zwei ein St\u00fcck, nicht wollt' er's thun.", "tokens": ["Ich", "bot", "ihm", "auf", "die", "zwei", "ein", "St\u00fcck", ",", "nicht", "wollt'", "er's", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "CARD", "ART", "NN", "$,", "PTKNEG", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So kauf' ich also los von beiden einen nun?", "tokens": ["So", "kauf'", "ich", "al\u00b7so", "los", "von", "bei\u00b7den", "ei\u00b7nen", "nun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "PIAT", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Allein sie sind vielleicht ein Paar, sollt' ich sie scheiden?", "tokens": ["Al\u00b7lein", "sie", "sind", "viel\u00b7leicht", "ein", "Paar", ",", "sollt'", "ich", "sie", "schei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "ART", "NN", "$,", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da blieben besser in Gefangenschaft die beiden.", "tokens": ["Da", "blie\u00b7ben", "bes\u00b7ser", "in", "Ge\u00b7fan\u00b7gen\u00b7schaft", "die", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "APPR", "NN", "ART", "PIAT", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Doch wollt' er f\u00fcr die zwei durchaus zwei Silberst\u00fccke;", "tokens": ["Doch", "wollt'", "er", "f\u00fcr", "die", "zwei", "durc\u00b7haus", "zwei", "Sil\u00b7ber\u00b7st\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "CARD", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die beiden gab ich hin, und mir blieb keins zur\u00fccke.", "tokens": ["Die", "bei\u00b7den", "gab", "ich", "hin", ",", "und", "mir", "blieb", "keins", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Der diese speist und tr\u00e4nkt, wird tr\u00e4nken dich und speisen,", "tokens": ["Der", "die\u00b7se", "speist", "und", "tr\u00e4nkt", ",", "wird", "tr\u00e4n\u00b7ken", "dich", "und", "spei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "VVFIN", "KON", "VVFIN", "$,", "VAFIN", "VVFIN", "PPER", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er wird wie ihnen dir den Weg zur Heimat weisen.", "tokens": ["Er", "wird", "wie", "ih\u00b7nen", "dir", "den", "Weg", "zur", "Hei\u00b7mat", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "PPER", "PPER", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Doch lie\u00df' ich hier euch los in der euch fremden Stadt,", "tokens": ["Doch", "lie\u00df'", "ich", "hier", "euch", "los", "in", "der", "euch", "frem\u00b7den", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPER", "PTKVZ", "APPR", "PRELS", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo gastlich euch empf\u00e4ngt kein Baum mit gr\u00fcnem Blatt?", "tokens": ["Wo", "gast\u00b7lich", "euch", "emp\u00b7f\u00e4ngt", "kein", "Baum", "mit", "gr\u00fc\u00b7nem", "Blatt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVFIN", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Von neuem w\u00fcrden hier euch fangen bald die B\u00f6sen,", "tokens": ["Von", "neu\u00b7em", "w\u00fcr\u00b7den", "hier", "euch", "fan\u00b7gen", "bald", "die", "B\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VAFIN", "ADV", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und einer fehlte dann vielleicht um euch zu l\u00f6sen.", "tokens": ["Und", "ei\u00b7ner", "fehl\u00b7te", "dann", "viel\u00b7leicht", "um", "euch", "zu", "l\u00f6\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "So trug ich sie hinaus zur Stadt, hinaus vom Weg,", "tokens": ["So", "trug", "ich", "sie", "hin\u00b7aus", "zur", "Stadt", ",", "hin\u00b7aus", "vom", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APZR", "APPRART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ins unzug\u00e4nglichste Waldeinsamkeitsgeheg.", "tokens": ["Ins", "un\u00b7zu\u00b7g\u00e4ng\u00b7lichs\u00b7te", "Wal\u00b7de\u00b7in\u00b7sam\u00b7keits\u00b7ge\u00b7heg", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "Und lie\u00df sie los, und wie sie froh empor sich schwangen,", "tokens": ["Und", "lie\u00df", "sie", "los", ",", "und", "wie", "sie", "froh", "em\u00b7por", "sich", "schwan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PWAV", "PPER", "ADJD", "PTKVZ", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "H\u00f6rt' ich, wie unter sich sie sprachen oder sangen:", "tokens": ["H\u00f6rt'", "ich", ",", "wie", "un\u00b7ter", "sich", "sie", "spra\u00b7chen", "o\u00b7der", "san\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "APPR", "PRF", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Womit vergelten wir dem Manne, der sein Geld", "tokens": ["Wo\u00b7mit", "ver\u00b7gel\u00b7ten", "wir", "dem", "Man\u00b7ne", ",", "der", "sein", "Geld"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Daran verwendet, uns zu bringen frei ins Feld?", "tokens": ["Da\u00b7ran", "ver\u00b7wen\u00b7det", ",", "uns", "zu", "brin\u00b7gen", "frei", "ins", "Feld", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVPP", "$,", "PPER", "PTKZU", "VVINF", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "M\u00f6g' ein geliebtes Weib er sein in Zukunft nennen,", "tokens": ["M\u00f6g'", "ein", "ge\u00b7lieb\u00b7tes", "Weib", "er", "sein", "in", "Zu\u00b7kunft", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "PPER", "VAINF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df er ein Vogelpaar nicht grausam wollte trennen.", "tokens": ["Da\u00df", "er", "ein", "Vo\u00b7gel\u00b7paar", "nicht", "grau\u00b7sam", "woll\u00b7te", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Wir kennen Weg und Steg, wir kennen Land und Stadt,", "tokens": ["Wir", "ken\u00b7nen", "Weg", "und", "Steg", ",", "wir", "ken\u00b7nen", "Land", "und", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und w\u00fcrden Boten gern, wenn er sie n\u00f6thig hat.", "tokens": ["Und", "w\u00fcr\u00b7den", "Bo\u00b7ten", "gern", ",", "wenn", "er", "sie", "n\u00f6\u00b7thig", "hat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "ADV", "$,", "KOUS", "PPER", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Doch lieber sollten wir ihm einen F\u00fchrer geben,", "tokens": ["Doch", "lie\u00b7ber", "soll\u00b7ten", "wir", "ihm", "ei\u00b7nen", "F\u00fch\u00b7rer", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An dessen Hand der Mensch am liebsten geht durchs Leben.", "tokens": ["An", "des\u00b7sen", "Hand", "der", "Mensch", "am", "liebs\u00b7ten", "geht", "durchs", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "ART", "NN", "PTKA", "ADJD", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Kennst du nicht einen Platz, kennst du nicht einen Schatz,", "tokens": ["Kennst", "du", "nicht", "ei\u00b7nen", "Platz", ",", "kennst", "du", "nicht", "ei\u00b7nen", "Schatz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der k\u00f6nnte dienen ihm zum Reisegeld-Ersatz?", "tokens": ["Der", "k\u00f6nn\u00b7te", "die\u00b7nen", "ihm", "zum", "Rei\u00b7se\u00b7geld\u00b7Er\u00b7satz", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VVINF", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Dort unter jenem Baum dem d\u00fcrren soll er graben,", "tokens": ["Dort", "un\u00b7ter", "je\u00b7nem", "Baum", "dem", "d\u00fcr\u00b7ren", "soll", "er", "gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "ART", "VVINF", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dort liegt aus alter Zeit ein Silberschrein vergraben.", "tokens": ["Dort", "liegt", "aus", "al\u00b7ter", "Zeit", "ein", "Sil\u00b7ber\u00b7schrein", "ver\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Daraus nehm' er soviel um unterwegs zu zehren,", "tokens": ["Da\u00b7raus", "nehm'", "er", "so\u00b7viel", "um", "un\u00b7ter\u00b7wegs", "zu", "zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mehr, um seiner Braut daheim es zu verehren. \u2014", "tokens": ["Und", "mehr", ",", "um", "sei\u00b7ner", "Braut", "da\u00b7heim", "es", "zu", "ver\u00b7eh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "$,", "KOUI", "PPOSAT", "NN", "ADV", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Sie schwangen sich hinweg, und ich sah nach und dachte:", "tokens": ["Sie", "schwan\u00b7gen", "sich", "hin\u00b7weg", ",", "und", "ich", "sah", "nach", "und", "dach\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APZR", "$,", "KON", "PPER", "VVFIN", "APPR", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ob ich die Schw\u00e4tzerei der Losen wohl beachte?", "tokens": ["Ob", "ich", "die", "Schw\u00e4t\u00b7ze\u00b7rei", "der", "Lo\u00b7sen", "wohl", "be\u00b7ach\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "In L\u00fcften fliegen sie, und wollen sich geberden,", "tokens": ["In", "L\u00fcf\u00b7ten", "flie\u00b7gen", "sie", ",", "und", "wol\u00b7len", "sich", "ge\u00b7ber\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$,", "KON", "VMFIN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verborgne Heimlichkeit zu wissen in der Erden.", "tokens": ["Ver\u00b7borg\u00b7ne", "Heim\u00b7lich\u00b7keit", "zu", "wis\u00b7sen", "in", "der", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Wie h\u00e4tten einen Schatz gesehn die M\u00fc\u00dfigg\u00e4nger,", "tokens": ["Wie", "h\u00e4t\u00b7ten", "ei\u00b7nen", "Schatz", "ge\u00b7sehn", "die", "M\u00fc\u00b7\u00dfig\u00b7g\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die nicht die Schlinge sahn, gelegt vom Vogelf\u00e4nger?", "tokens": ["Die", "nicht", "die", "Schlin\u00b7ge", "sahn", ",", "ge\u00b7legt", "vom", "Vo\u00b7gel\u00b7f\u00e4n\u00b7ger", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ART", "NN", "VVFIN", "$,", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Doch blind und sehend macht, zum Frommen und zum Schaden,", "tokens": ["Doch", "blind", "und", "se\u00b7hend", "macht", ",", "zum", "From\u00b7men", "und", "zum", "Scha\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVFIN", "$,", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Schicksal, es ist gro\u00df, doch gr\u00f6\u00dfer Gottes Gnaden.", "tokens": ["Das", "Schick\u00b7sal", ",", "es", "ist", "gro\u00df", ",", "doch", "gr\u00f6\u00b7\u00dfer", "Got\u00b7tes", "Gna\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VAFIN", "ADJD", "$,", "ADV", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "In Gottes Namen denn am angewies'nen Platz", "tokens": ["In", "Got\u00b7tes", "Na\u00b7men", "denn", "am", "an\u00b7ge\u00b7wies'\u00b7nen", "Platz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "NN", "KON", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fieng ich zu graben an, und fand den Silberschatz.", "tokens": ["Fi\u00b7eng", "ich", "zu", "gra\u00b7ben", "an", ",", "und", "fand", "den", "Sil\u00b7ber\u00b7schatz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "PTKVZ", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.27": {"line.1": {"text": "Ich fand f\u00fcr meine zwei soviele Silberst\u00fccke,", "tokens": ["Ich", "fand", "f\u00fcr", "mei\u00b7ne", "zwei", "so\u00b7vie\u00b7le", "Sil\u00b7ber\u00b7st\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "CARD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ich davon nach Haus baun k\u00f6nnte Weg und Br\u00fccke.", "tokens": ["Da\u00df", "ich", "da\u00b7von", "nach", "Haus", "baun", "k\u00f6nn\u00b7te", "Weg", "und", "Br\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "APPR", "NN", "VVINF", "VMFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Doch Weg und Br\u00fccke war gebahnt schon und gebaut;", "tokens": ["Doch", "Weg", "und", "Br\u00fc\u00b7cke", "war", "ge\u00b7bahnt", "schon", "und", "ge\u00b7baut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "VVPP", "ADV", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich nahm nur wenig mit zum Schatz f\u00fcr meine Braut.", "tokens": ["Ich", "nahm", "nur", "we\u00b7nig", "mit", "zum", "Schatz", "f\u00fcr", "mei\u00b7ne", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "APPR", "APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}