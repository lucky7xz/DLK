{"dta.poem.1559": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Sieghaffte Best\u00fcrm- und Eroberung des T\u00fcrcki-  \n schen Lagers bey Senta an der Theisse/ den  \n 11. Septembr. An. 1697.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "T\u00f6chter/ auff Triumph zu singen! ", "tokens": ["T\u00f6ch\u00b7ter", "/", "auff", "Tri\u00b7umph", "zu", "sin\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hebt eur schilfficht Haubt empor/", "tokens": ["Hebt", "eur", "schilf\u00b7ficht", "Haubt", "em\u00b7por", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasst der feuchten Nimphen Chor", "tokens": ["Lasst", "der", "feuch\u00b7ten", "Nim\u00b7phen", "Chor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Siegs- und Freuden Lieder klingen!", "tokens": ["Siegs", "und", "Freu\u00b7den", "Lie\u00b7der", "klin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lasst eur Silber heller fliessen", "tokens": ["Lasst", "eur", "Sil\u00b7ber", "hel\u00b7ler", "flies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Pannons Auen zu begiessen.", "tokens": ["Pan\u00b7nons", "Au\u00b7en", "zu", "be\u00b7gies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "O\u00dfmann wagt sich/ meinen Flutten/", "tokens": ["O\u00df\u00b7mann", "wagt", "sich", "/", "mei\u00b7nen", "Flut\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "$(", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welche frey in Thetis Reich", "tokens": ["Wel\u00b7che", "frey", "in", "The\u00b7tis", "Reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "APPR", "NE", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Flossen vor und hinter euch/", "tokens": ["Flos\u00b7sen", "vor", "und", "hin\u00b7ter", "euch", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "APPR", "PPER", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Zaum und F\u00e4ssel anzumutten;", "tokens": ["Zaum", "und", "F\u00e4s\u00b7sel", "an\u00b7zu\u00b7mut\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber deutsche Helden Sinnen", "tokens": ["A\u00b7ber", "deut\u00b7sche", "Hel\u00b7den", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Halten seinen Hochmutt innen.", "tokens": ["Hal\u00b7ten", "sei\u00b7nen", "Hoch\u00b7mutt", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Schwestern/ lasst mich in dem Reyhen", "tokens": ["Schwes\u00b7tern", "/", "lasst", "mich", "in", "dem", "Rey\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An der ersten Stelle seyn!", "tokens": ["An", "der", "ers\u00b7ten", "Stel\u00b7le", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser Sieges-Tag ist mein/", "tokens": ["Die\u00b7ser", "Sie\u00b7ges\u00b7Tag", "ist", "mein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "PPOSAT", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der uns alle kan erfreuen.", "tokens": ["Der", "uns", "al\u00b7le", "kan", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIS", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Von der T\u00fcrcken Stoltz und Zagen", "tokens": ["Von", "der", "T\u00fcr\u00b7cken", "Stoltz", "und", "Za\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Kan ich euch am besten sagen.", "tokens": ["Kan", "ich", "euch", "am", "bes\u00b7ten", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PTKA", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Meinen Strom hielt fest gezwungen", "tokens": ["Mei\u00b7nen", "Strom", "hielt", "fest", "ge\u00b7zwun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mechmets ungest\u00fcmer Schwarm/", "tokens": ["Mech\u00b7mets", "un\u00b7ge\u00b7st\u00fc\u00b7mer", "Schwarm", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber k\u00fchner Christen-Arm", "tokens": ["A\u00b7ber", "k\u00fch\u00b7ner", "Chris\u00b7ten\u00b7Arm"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat den tollen Feind verdrungen:", "tokens": ["Hat", "den", "tol\u00b7len", "Feind", "ver\u00b7drun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seinen unverzagten Streichen", "tokens": ["Sei\u00b7nen", "un\u00b7ver\u00b7zag\u00b7ten", "Strei\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Musten Get und Parthen weichen.", "tokens": ["Mus\u00b7ten", "Get", "und", "Par\u00b7then", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wall und Gr\u00e4ben sind erstiegen/", "tokens": ["Wall", "und", "Gr\u00e4\u00b7ben", "sind", "er\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo der freche Janitschar", "tokens": ["Wo", "der", "fre\u00b7che", "Ja\u00b7nit\u00b7schar"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner Brust gesichert war/", "tokens": ["Sei\u00b7ner", "Brust", "ge\u00b7si\u00b7chert", "war", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sieht man ihn entkr\u00e4fftet liegen;", "tokens": ["Sieht", "man", "ihn", "ent\u00b7kr\u00e4ff\u00b7tet", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So viel T\u00fcrcken-K\u00f6pff als Fische", "tokens": ["So", "viel", "T\u00fcr\u00b7cken\u00b7K\u00f6pff", "als", "Fi\u00b7sche"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schick ich Hecaten zu Tische.", "tokens": ["Schick", "ich", "He\u00b7ca\u00b7ten", "zu", "Ti\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Thei\u00dfe/ du warst noch zur\u00fccke:", "tokens": ["Thei\u00b7\u00dfe", "/", "du", "warst", "noch", "zu\u00b7r\u00fc\u00b7cke", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Nun dir dieser T\u00fcrcken-Krieg", "tokens": ["Nun", "dir", "die\u00b7ser", "T\u00fcr\u00b7cken\u00b7Krieg"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPER", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch geg\u00f6nnet solchen Sieg/", "tokens": ["Auch", "ge\u00b7g\u00f6n\u00b7net", "sol\u00b7chen", "Sieg", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PIAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fcnsch ich dir von Hertzen Gl\u00fccke:", "tokens": ["W\u00fcnsch", "ich", "dir", "von", "Hert\u00b7zen", "Gl\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ich sah f\u00fcr etlich Jahren", "tokens": ["Was", "ich", "sah", "f\u00fcr", "et\u00b7lich", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "La\u00df uns GOtt noch offt erfahren!", "tokens": ["La\u00df", "uns", "Gott", "noch", "offt", "er\u00b7fah\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Temes/ schicke dich bey Zeiten", "tokens": ["Te\u00b7mes", "/", "schi\u00b7cke", "dich", "bey", "Zei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "VVFIN", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unserm Gro\u00dfem LEOPOLD/", "tokens": ["Un\u00b7serm", "Gro\u00b7\u00dfem", "LeO\u00b7POLD", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Der die F\u00e4ssel kehrt in Gold/", "tokens": ["Der", "die", "F\u00e4s\u00b7sel", "kehrt", "in", "Gold", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Furth und Pforten zu bereiten!", "tokens": ["Furth", "und", "Pfor\u00b7ten", "zu", "be\u00b7rei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was vergangnes Jahr verschoben", "tokens": ["Was", "ver\u00b7gang\u00b7nes", "Jahr", "ver\u00b7scho\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist darum nicht auffgehoben.", "tokens": ["Ist", "da\u00b7rum", "nicht", "auff\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Kommt ihr treuen Reichsgenossen/", "tokens": ["Kommt", "ihr", "treu\u00b7en", "Reichs\u00b7ge\u00b7nos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fchrt zum fernen Pont Euxin", "tokens": ["F\u00fchrt", "zum", "fer\u00b7nen", "Pont", "Eu\u00b7xin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Derer Helden Nachruhm hin/", "tokens": ["De\u00b7rer", "Hel\u00b7den", "Nach\u00b7ruhm", "hin", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die f\u00fcr uns ihr Blutt vergossen.", "tokens": ["Die", "f\u00fcr", "uns", "ihr", "Blutt", "ver\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Last mit unsern frischen Wellen", "tokens": ["Last", "mit", "un\u00b7sern", "fri\u00b7schen", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stets ihr Lob von neuem quellen.", "tokens": ["Stets", "ihr", "Lob", "von", "neu\u00b7em", "quel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "So viel Tropffen in uns fliessen/", "tokens": ["So", "viel", "Tropf\u00b7fen", "in", "uns", "flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel Stauden um uns stehu/", "tokens": ["So", "viel", "Stau\u00b7den", "um", "uns", "ste\u00b7hu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "So viel Heyl und Wohlergehn", "tokens": ["So", "viel", "Heyl", "und", "Woh\u00b7ler\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll/ der uns befreyt/ gen\u00fcssen!", "tokens": ["Soll", "/", "der", "uns", "be\u00b7freyt", "/", "ge\u00b7n\u00fcs\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "$(", "PRELS", "PPER", "VVPP", "$(", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "LeOPOLDS und JOSEPHS Gl\u00fccke", "tokens": ["LeO\u00b7POLDS", "und", "Jo\u00b7SE\u00b7PHS", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NE", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Geh nicht eh als wir zur\u00fccke!", "tokens": ["Geh", "nicht", "eh", "als", "wir", "zu\u00b7r\u00fc\u00b7cke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "KOUS", "KOUS", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}