{"textgrid.poem.62928": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer warst du auf dem Narrenrund?", "genre": "verse", "period": "N.A.", "pub_year": 1779, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer warst du auf dem Narrenrund?", "tokens": ["Wer", "warst", "du", "auf", "dem", "Nar\u00b7ren\u00b7rund", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach Minos einst im Richtertone", "tokens": ["Sprach", "Mi\u00b7nos", "einst", "im", "Rich\u00b7ter\u00b7to\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "ADV", "APPRART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Zu weiland einem Erdensohne,", "tokens": ["Zu", "wei\u00b7land", "ei\u00b7nem", "Er\u00b7den\u00b7soh\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der bla\u00df vor seinem Sopha stund.", "tokens": ["Der", "bla\u00df", "vor", "sei\u00b7nem", "So\u00b7pha", "stund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Narr mit: erwiedert ihm der Schatten;", "tokens": ["Narr", "mit", ":", "er\u00b7wie\u00b7dert", "ihm", "der", "Schat\u00b7ten", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Doch ach! zu sp\u00e4t ward ichs gewahr;", "tokens": ["Doch", "ach", "!", "zu", "sp\u00e4t", "ward", "ichs", "ge\u00b7wahr", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PTKA", "ADJD", "VAFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Von zw\u00f6lf Talenten, die mir baar", "tokens": ["Von", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", ",", "die", "mir", "baar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "$,", "PRELS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Eltern hinterlassen hatten,", "tokens": ["Die", "El\u00b7tern", "hin\u00b7ter\u00b7las\u00b7sen", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Verflog, als ich kaum m\u00fcndig war,", "tokens": ["Ver\u00b7flog", ",", "als", "ich", "kaum", "m\u00fcn\u00b7dig", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Halbscheid auf gelehrten Reisen", "tokens": ["Die", "Halb\u00b7scheid", "auf", "ge\u00b7lehr\u00b7ten", "Rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Nach Cypern, Paphos, Amathunt.", "tokens": ["Nach", "Cy\u00b7pern", ",", "Pa\u00b7phos", ",", "A\u00b7mat\u00b7hunt", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "$,", "NE", "$,", "NE", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Ein blaues Aug, ein rother Mund", "tokens": ["Ein", "blau\u00b7es", "Aug", ",", "ein", "ro\u00b7ther", "Mund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Beth\u00f6rten schon die gr\u00f6\u00dften Weisen;", "tokens": ["Be\u00b7th\u00f6r\u00b7ten", "schon", "die", "gr\u00f6\u00df\u00b7ten", "Wei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Warum nicht mich? Aspasia", "tokens": ["Wa\u00b7rum", "nicht", "mich", "?", "As\u00b7pa\u00b7sia"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PWAV", "PTKNEG", "PPER", "$.", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Von Guidos, eine junge Dirne,", "tokens": ["Von", "Gui\u00b7dos", ",", "ei\u00b7ne", "jun\u00b7ge", "Dir\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Die ich auf einem Balle sah,", "tokens": ["Die", "ich", "auf", "ei\u00b7nem", "Bal\u00b7le", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Verr\u00fcckte stracks mir das Gehirne.", "tokens": ["Ver\u00b7r\u00fcck\u00b7te", "stracks", "mir", "das", "Ge\u00b7hir\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Arm war sie zwar wie Diogen,", "tokens": ["Arm", "war", "sie", "zwar", "wie", "Dio\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "KOKOM", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Doch wie Cythere schlau und sch\u00f6n,", "tokens": ["Doch", "wie", "Cy\u00b7the\u00b7re", "schlau", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "ADJD", "KON", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.20": {"text": "Und \u2013 kurz, ich lie\u00df mich mit ihr trauen", "tokens": ["Und", "\u2013", "kurz", ",", "ich", "lie\u00df", "mich", "mit", "ihr", "trau\u00b7en"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "ADJD", "$,", "PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Und f\u00fchrte siegreich sie nach Haus.", "tokens": ["Und", "f\u00fchr\u00b7te", "sieg\u00b7reich", "sie", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Da lebten wir in Saus und Braus;", "tokens": ["Da", "leb\u00b7ten", "wir", "in", "Saus", "und", "Braus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Sie war die pr\u00e4chtigste der Frauen", "tokens": ["Sie", "war", "die", "pr\u00e4ch\u00b7tigs\u00b7te", "der", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und ich war der galantste Mann.", "tokens": ["Und", "ich", "war", "der", "ga\u00b7lants\u00b7te", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.25": {"text": "Doch lange gieng der Spa\u00df nicht an:", "tokens": ["Doch", "lan\u00b7ge", "gieng", "der", "Spa\u00df", "nicht", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "In Schm\u00e4usen, Spielen, Maskeraden,", "tokens": ["In", "Schm\u00e4u\u00b7sen", ",", "Spie\u00b7len", ",", "Mas\u00b7ke\u00b7ra\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Juwelen, Salben und Brokaden", "tokens": ["Ju\u00b7we\u00b7len", ",", "Sal\u00b7ben", "und", "Bro\u00b7ka\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.28": {"text": "Zerschmolz der Rest von meinem Gold,", "tokens": ["Zer\u00b7schmolz", "der", "Rest", "von", "mei\u00b7nem", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Mit ihm die Liebe meines G\u00f6tzen.", "tokens": ["Mit", "ihm", "die", "Lie\u00b7be", "mei\u00b7nes", "G\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Um ihren Aufwand fortzusetzen", "tokens": ["Um", "ih\u00b7ren", "Auf\u00b7wand", "fort\u00b7zu\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Begab sie sich in fremden Sold,", "tokens": ["Be\u00b7gab", "sie", "sich", "in", "frem\u00b7den", "Sold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Und ich \u2013 hier grif er nach der Stirne \u2013", "tokens": ["Und", "ich", "\u2013", "hier", "grif", "er", "nach", "der", "Stir\u00b7ne", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Herr Minos, du verstehst mich schon;", "tokens": ["Herr", "Mi\u00b7nos", ",", "du", "ver\u00b7stehst", "mich", "schon", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.34": {"text": "Wo lebt der Ehmann, der nicht z\u00fcrne,", "tokens": ["Wo", "lebt", "der", "Eh\u00b7mann", ",", "der", "nicht", "z\u00fcr\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,", "PRELS", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Wenn diese j\u00fcckt? ... Mit Flehn und Drohn", "tokens": ["Wenn", "die\u00b7se", "j\u00fcckt", "?", "...", "Mit", "Flehn", "und", "Drohn"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "VVFIN", "$.", "$(", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Bat ich mein Weib, sich zu bekehren.", "tokens": ["Bat", "ich", "mein", "Weib", ",", "sich", "zu", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Umsonst, sie wollte mich nicht h\u00f6ren;", "tokens": ["Um\u00b7sonst", ",", "sie", "woll\u00b7te", "mich", "nicht", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Und als es einst zu P\u00fcffen kam,", "tokens": ["Und", "als", "es", "einst", "zu", "P\u00fcf\u00b7fen", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Schlug sie vier Z\u00e4hne mir in Rachen.", "tokens": ["Schlug", "sie", "vier", "Z\u00e4h\u00b7ne", "mir", "in", "Ra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Nun \u00fcbernahm mich Wuth und Gram;", "tokens": ["Nun", "\u00fc\u00b7bern\u00b7ahm", "mich", "Wuth", "und", "Gram", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Ich ri\u00df vom Putztisch meines Drachen", "tokens": ["Ich", "ri\u00df", "vom", "Putz\u00b7tisch", "mei\u00b7nes", "Dra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Ein Pudermesser und erstach \u2013 \u2013", "tokens": ["Ein", "Pu\u00b7der\u00b7mes\u00b7ser", "und", "er\u00b7stach", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Das Weib? \u2013 Dazu war ich zu schwach;", "tokens": ["Das", "Weib", "?", "\u2013", "Da\u00b7zu", "war", "ich", "zu", "schwach", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "PAV", "VAFIN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Mich selbst \u2013 ich Pinsel! aber ach!", "tokens": ["Mich", "selbst", "\u2013", "ich", "Pin\u00b7sel", "!", "a\u00b7ber", "ach", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "PPER", "NN", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "K\u00f6nnt ich ins Leben wiederkehren,", "tokens": ["K\u00f6nnt", "ich", "ins", "Le\u00b7ben", "wie\u00b7der\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Ich lie\u00dfe mich nicht mehr beth\u00f6ren.", "tokens": ["Ich", "lie\u00b7\u00dfe", "mich", "nicht", "mehr", "be\u00b7th\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wolan, ich nehme dich beym Wort,", "tokens": ["Wo\u00b7lan", ",", "ich", "neh\u00b7me", "dich", "beym", "Wort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach Minos, hier ist ein Pa\u00dfport", "tokens": ["Sprach", "Mi\u00b7nos", ",", "hier", "ist", "ein", "Pa\u00df\u00b7port"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "ADV", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An Charon; hier ein Bankozettel", "tokens": ["An", "Cha\u00b7ron", ";", "hier", "ein", "Ban\u00b7ko\u00b7zet\u00b7tel"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$.", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An Plutus. Deine Frau, die Vettel,", "tokens": ["An", "Plu\u00b7tus", ".", "Dei\u00b7ne", "Frau", ",", "die", "Vet\u00b7tel", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$.", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Schifft wirklich auf dem H\u00f6llenflu\u00df.", "tokens": ["Schifft", "wirk\u00b7lich", "auf", "dem", "H\u00f6l\u00b7len\u00b7flu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geh hin, den Dank will ich dir sparen.", "tokens": ["Geh", "hin", ",", "den", "Dank", "will", "ich", "dir", "spa\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "ART", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So schnell mu\u00df kein Karthaunenschu\u00df", "tokens": ["So", "schnell", "mu\u00df", "kein", "Kar\u00b7thau\u00b7nen\u00b7schu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VMFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Zevs die schwarze Luft durchfahren,", "tokens": ["Des", "Zevs", "die", "schwar\u00b7ze", "Luft", "durch\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als unser Mann den Tartarus.", "tokens": ["Als", "un\u00b7ser", "Mann", "den", "Tar\u00b7ta\u00b7rus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schon k\u00fc\u00dft er die erstaunten Br\u00fcder", "tokens": ["Schon", "k\u00fc\u00dft", "er", "die", "er\u00b7staun\u00b7ten", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Im dichtern Kleid des ersten Leibs,", "tokens": ["Im", "dich\u00b7tern", "Kleid", "des", "ers\u00b7ten", "Leibs", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und fand wie Hiob alles wieder,", "tokens": ["Und", "fand", "wie", "Hiob", "al\u00b7les", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "NE", "PIS", "ADV", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Noch mehr \u2013 die Urne seines Weibs.", "tokens": ["Noch", "mehr", "\u2013", "die", "Ur\u00b7ne", "sei\u00b7nes", "Weibs", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nun l\u00e4\u00dft er auf dem Land sich nieder,", "tokens": ["Nun", "l\u00e4\u00dft", "er", "auf", "dem", "Land", "sich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Kauft B\u00fccher, wird ein Philosoph", "tokens": ["Kauft", "B\u00fc\u00b7cher", ",", "wird", "ein", "Phi\u00b7lo\u00b7soph"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und schw\u00f6rt nur bey den weisen Alten.", "tokens": ["Und", "schw\u00f6rt", "nur", "bey", "den", "wei\u00b7sen", "Al\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Er giebt sein Gold nebst Haus und Hof", "tokens": ["Er", "giebt", "sein", "Gold", "nebst", "Haus", "und", "Hof"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Zween Epikurern zu verwalten,", "tokens": ["Zween", "E\u00b7pi\u00b7ku\u00b7rern", "zu", "ver\u00b7wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die, w\u00e4hrend er Systeme liest,", "tokens": ["Die", ",", "w\u00e4h\u00b7rend", "er", "Sys\u00b7te\u00b7me", "liest", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.14": {"text": "So treulich mit dem Gute schalten,", "tokens": ["So", "treu\u00b7lich", "mit", "dem", "Gu\u00b7te", "schal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Da\u00df eh das vierte Jahr verflie\u00dft,", "tokens": ["Da\u00df", "eh", "das", "vier\u00b7te", "Jahr", "ver\u00b7flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Nur B\u00fccher noch die Schr\u00e4nke f\u00fcllen.", "tokens": ["Nur", "B\u00fc\u00b7cher", "noch", "die", "Schr\u00e4n\u00b7ke", "f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ey, ey, das h\u00e4tt ich nicht gedacht!", "tokens": ["Ey", ",", "ey", ",", "das", "h\u00e4tt", "ich", "nicht", "ge\u00b7dacht", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rief er best\u00fcrzt. Doch weg ihr Grillen!", "tokens": ["Rief", "er", "be\u00b7st\u00fcrzt", ".", "Doch", "weg", "ihr", "Gril\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$.", "KON", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Weib mit zw\u00f6lf Talenten macht", "tokens": ["Ein", "Weib", "mit", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", "macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich dieses Ungl\u00fcck leicht vergessen.", "tokens": ["Mich", "die\u00b7ses", "Un\u00b7gl\u00fcck", "leicht", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nun reist er auf die Freyerey,", "tokens": ["Nun", "reist", "er", "auf", "die", "Frey\u00b7e\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Just wie der Kaufmann auf die Messen.", "tokens": ["Just", "wie", "der", "Kauf\u00b7mann", "auf", "die", "Mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Fortuna steht den Narren bey;", "tokens": ["For\u00b7tu\u00b7na", "steht", "den", "Nar\u00b7ren", "bey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er fand das Weib mit zw\u00f6lf Talenten,", "tokens": ["Er", "fand", "das", "Weib", "mit", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Wittib eines Hofagenten,", "tokens": ["Die", "Wit\u00b7tib", "ei\u00b7nes", "Ho\u00b7fa\u00b7gen\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zwar runzlicht, schielend, taub und lahm,", "tokens": ["Zwar", "runz\u00b7licht", ",", "schie\u00b7lend", ",", "taub", "und", "lahm", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADJD", "$,", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Doch wer sieht das bey zw\u00f6lf Talenten?", "tokens": ["Doch", "wer", "sieht", "das", "bey", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "APPR", "CARD", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Nun tr\u00e4umt der frohe Br\u00e4utigam", "tokens": ["Nun", "tr\u00e4umt", "der", "fro\u00b7he", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Von nichts als seinen fetten Renten.", "tokens": ["Von", "nichts", "als", "sei\u00b7nen", "fet\u00b7ten", "Ren\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch eh der zweyte Monat kam,", "tokens": ["Doch", "eh", "der", "zwey\u00b7te", "Mo\u00b7nat", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sprach er von nichts als neuem Kreuze,", "tokens": ["Sprach", "er", "von", "nichts", "als", "neu\u00b7em", "Kreu\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PIS", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Von seiner Dame harter Zucht,", "tokens": ["Von", "sei\u00b7ner", "Da\u00b7me", "har\u00b7ter", "Zucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Von ihrer blinden Eifersucht,", "tokens": ["Von", "ih\u00b7rer", "blin\u00b7den", "Ei\u00b7fer\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Von ihrem unerh\u00f6rten Geize.", "tokens": ["Von", "ih\u00b7rem", "un\u00b7er\u00b7h\u00f6r\u00b7ten", "Gei\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Kurz Irus selbst war nicht so arm,", "tokens": ["Kurz", "I\u00b7rus", "selbst", "war", "nicht", "so", "arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NE", "ADV", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Und Socrates trug minder Plagen", "tokens": ["Und", "So\u00b7cra\u00b7tes", "trug", "min\u00b7der", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "ADV", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "Als er. Die weisen Alten sagen:", "tokens": ["Als", "er", ".", "Die", "wei\u00b7sen", "Al\u00b7ten", "sa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$.", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Der Wein vertreibt der Grillen Schwarm.", "tokens": ["Der", "Wein", "ver\u00b7treibt", "der", "Gril\u00b7len", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Er glaubts und will das Mittel wagen;", "tokens": ["Er", "glaubts", "und", "will", "das", "Mit\u00b7tel", "wa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Doch kaum k\u00f6mmt er berauscht nach Haus,", "tokens": ["Doch", "kaum", "k\u00f6mmt", "er", "be\u00b7rauscht", "nach", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.25": {"text": "So st\u00f6\u00dft sein D\u00e4mon mit der Kr\u00fccke", "tokens": ["So", "st\u00f6\u00dft", "sein", "D\u00e4\u00b7mon", "mit", "der", "Kr\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Zum Stubenfenster ihn hinaus.", "tokens": ["Zum", "Stu\u00b7ben\u00b7fens\u00b7ter", "ihn", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Der arme Tropf brach das Genicke;", "tokens": ["Der", "ar\u00b7me", "Tropf", "brach", "das", "Ge\u00b7ni\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und als er vor den H\u00f6llenrath", "tokens": ["Und", "als", "er", "vor", "den", "H\u00f6l\u00b7len\u00b7rath"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Zum andern Mal mit scheuem Blicke", "tokens": ["Zum", "an\u00b7dern", "Mal", "mit", "scheu\u00b7em", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und marmoriertem Sch\u00e4del trat,", "tokens": ["Und", "mar\u00b7mo\u00b7rier\u00b7tem", "Sch\u00e4\u00b7del", "trat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Sprach Minos: traut ihn mit Meg\u00e4ren!", "tokens": ["Sprach", "Mi\u00b7nos", ":", "traut", "ihn", "mit", "Me\u00b7g\u00e4\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Die strafe seinen Selbstbetrug;", "tokens": ["Die", "stra\u00b7fe", "sei\u00b7nen", "Selbst\u00b7be\u00b7trug", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Nur Weise kann Erfahrung lehren,", "tokens": ["Nur", "Wei\u00b7se", "kann", "Er\u00b7fah\u00b7rung", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Die Narren macht sie niemals klug.", "tokens": ["Die", "Nar\u00b7ren", "macht", "sie", "nie\u00b7mals", "klug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wer warst du auf dem Narrenrund?", "tokens": ["Wer", "warst", "du", "auf", "dem", "Nar\u00b7ren\u00b7rund", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach Minos einst im Richtertone", "tokens": ["Sprach", "Mi\u00b7nos", "einst", "im", "Rich\u00b7ter\u00b7to\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "ADV", "APPRART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Zu weiland einem Erdensohne,", "tokens": ["Zu", "wei\u00b7land", "ei\u00b7nem", "Er\u00b7den\u00b7soh\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der bla\u00df vor seinem Sopha stund.", "tokens": ["Der", "bla\u00df", "vor", "sei\u00b7nem", "So\u00b7pha", "stund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Narr mit: erwiedert ihm der Schatten;", "tokens": ["Narr", "mit", ":", "er\u00b7wie\u00b7dert", "ihm", "der", "Schat\u00b7ten", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Doch ach! zu sp\u00e4t ward ichs gewahr;", "tokens": ["Doch", "ach", "!", "zu", "sp\u00e4t", "ward", "ichs", "ge\u00b7wahr", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PTKA", "ADJD", "VAFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Von zw\u00f6lf Talenten, die mir baar", "tokens": ["Von", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", ",", "die", "mir", "baar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "$,", "PRELS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Eltern hinterlassen hatten,", "tokens": ["Die", "El\u00b7tern", "hin\u00b7ter\u00b7las\u00b7sen", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Verflog, als ich kaum m\u00fcndig war,", "tokens": ["Ver\u00b7flog", ",", "als", "ich", "kaum", "m\u00fcn\u00b7dig", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Halbscheid auf gelehrten Reisen", "tokens": ["Die", "Halb\u00b7scheid", "auf", "ge\u00b7lehr\u00b7ten", "Rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Nach Cypern, Paphos, Amathunt.", "tokens": ["Nach", "Cy\u00b7pern", ",", "Pa\u00b7phos", ",", "A\u00b7mat\u00b7hunt", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "$,", "NE", "$,", "NE", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Ein blaues Aug, ein rother Mund", "tokens": ["Ein", "blau\u00b7es", "Aug", ",", "ein", "ro\u00b7ther", "Mund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Beth\u00f6rten schon die gr\u00f6\u00dften Weisen;", "tokens": ["Be\u00b7th\u00f6r\u00b7ten", "schon", "die", "gr\u00f6\u00df\u00b7ten", "Wei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Warum nicht mich? Aspasia", "tokens": ["Wa\u00b7rum", "nicht", "mich", "?", "As\u00b7pa\u00b7sia"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PWAV", "PTKNEG", "PPER", "$.", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Von Guidos, eine junge Dirne,", "tokens": ["Von", "Gui\u00b7dos", ",", "ei\u00b7ne", "jun\u00b7ge", "Dir\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Die ich auf einem Balle sah,", "tokens": ["Die", "ich", "auf", "ei\u00b7nem", "Bal\u00b7le", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Verr\u00fcckte stracks mir das Gehirne.", "tokens": ["Ver\u00b7r\u00fcck\u00b7te", "stracks", "mir", "das", "Ge\u00b7hir\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Arm war sie zwar wie Diogen,", "tokens": ["Arm", "war", "sie", "zwar", "wie", "Dio\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "KOKOM", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Doch wie Cythere schlau und sch\u00f6n,", "tokens": ["Doch", "wie", "Cy\u00b7the\u00b7re", "schlau", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "ADJD", "KON", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.20": {"text": "Und \u2013 kurz, ich lie\u00df mich mit ihr trauen", "tokens": ["Und", "\u2013", "kurz", ",", "ich", "lie\u00df", "mich", "mit", "ihr", "trau\u00b7en"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "ADJD", "$,", "PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Und f\u00fchrte siegreich sie nach Haus.", "tokens": ["Und", "f\u00fchr\u00b7te", "sieg\u00b7reich", "sie", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Da lebten wir in Saus und Braus;", "tokens": ["Da", "leb\u00b7ten", "wir", "in", "Saus", "und", "Braus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Sie war die pr\u00e4chtigste der Frauen", "tokens": ["Sie", "war", "die", "pr\u00e4ch\u00b7tigs\u00b7te", "der", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und ich war der galantste Mann.", "tokens": ["Und", "ich", "war", "der", "ga\u00b7lants\u00b7te", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.25": {"text": "Doch lange gieng der Spa\u00df nicht an:", "tokens": ["Doch", "lan\u00b7ge", "gieng", "der", "Spa\u00df", "nicht", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "In Schm\u00e4usen, Spielen, Maskeraden,", "tokens": ["In", "Schm\u00e4u\u00b7sen", ",", "Spie\u00b7len", ",", "Mas\u00b7ke\u00b7ra\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Juwelen, Salben und Brokaden", "tokens": ["Ju\u00b7we\u00b7len", ",", "Sal\u00b7ben", "und", "Bro\u00b7ka\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.28": {"text": "Zerschmolz der Rest von meinem Gold,", "tokens": ["Zer\u00b7schmolz", "der", "Rest", "von", "mei\u00b7nem", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Mit ihm die Liebe meines G\u00f6tzen.", "tokens": ["Mit", "ihm", "die", "Lie\u00b7be", "mei\u00b7nes", "G\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Um ihren Aufwand fortzusetzen", "tokens": ["Um", "ih\u00b7ren", "Auf\u00b7wand", "fort\u00b7zu\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Begab sie sich in fremden Sold,", "tokens": ["Be\u00b7gab", "sie", "sich", "in", "frem\u00b7den", "Sold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Und ich \u2013 hier grif er nach der Stirne \u2013", "tokens": ["Und", "ich", "\u2013", "hier", "grif", "er", "nach", "der", "Stir\u00b7ne", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Herr Minos, du verstehst mich schon;", "tokens": ["Herr", "Mi\u00b7nos", ",", "du", "ver\u00b7stehst", "mich", "schon", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.34": {"text": "Wo lebt der Ehmann, der nicht z\u00fcrne,", "tokens": ["Wo", "lebt", "der", "Eh\u00b7mann", ",", "der", "nicht", "z\u00fcr\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,", "PRELS", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Wenn diese j\u00fcckt? ... Mit Flehn und Drohn", "tokens": ["Wenn", "die\u00b7se", "j\u00fcckt", "?", "...", "Mit", "Flehn", "und", "Drohn"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "VVFIN", "$.", "$(", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Bat ich mein Weib, sich zu bekehren.", "tokens": ["Bat", "ich", "mein", "Weib", ",", "sich", "zu", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Umsonst, sie wollte mich nicht h\u00f6ren;", "tokens": ["Um\u00b7sonst", ",", "sie", "woll\u00b7te", "mich", "nicht", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Und als es einst zu P\u00fcffen kam,", "tokens": ["Und", "als", "es", "einst", "zu", "P\u00fcf\u00b7fen", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Schlug sie vier Z\u00e4hne mir in Rachen.", "tokens": ["Schlug", "sie", "vier", "Z\u00e4h\u00b7ne", "mir", "in", "Ra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Nun \u00fcbernahm mich Wuth und Gram;", "tokens": ["Nun", "\u00fc\u00b7bern\u00b7ahm", "mich", "Wuth", "und", "Gram", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Ich ri\u00df vom Putztisch meines Drachen", "tokens": ["Ich", "ri\u00df", "vom", "Putz\u00b7tisch", "mei\u00b7nes", "Dra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Ein Pudermesser und erstach \u2013 \u2013", "tokens": ["Ein", "Pu\u00b7der\u00b7mes\u00b7ser", "und", "er\u00b7stach", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Das Weib? \u2013 Dazu war ich zu schwach;", "tokens": ["Das", "Weib", "?", "\u2013", "Da\u00b7zu", "war", "ich", "zu", "schwach", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "PAV", "VAFIN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Mich selbst \u2013 ich Pinsel! aber ach!", "tokens": ["Mich", "selbst", "\u2013", "ich", "Pin\u00b7sel", "!", "a\u00b7ber", "ach", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "PPER", "NN", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "K\u00f6nnt ich ins Leben wiederkehren,", "tokens": ["K\u00f6nnt", "ich", "ins", "Le\u00b7ben", "wie\u00b7der\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Ich lie\u00dfe mich nicht mehr beth\u00f6ren.", "tokens": ["Ich", "lie\u00b7\u00dfe", "mich", "nicht", "mehr", "be\u00b7th\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wolan, ich nehme dich beym Wort,", "tokens": ["Wo\u00b7lan", ",", "ich", "neh\u00b7me", "dich", "beym", "Wort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach Minos, hier ist ein Pa\u00dfport", "tokens": ["Sprach", "Mi\u00b7nos", ",", "hier", "ist", "ein", "Pa\u00df\u00b7port"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "ADV", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An Charon; hier ein Bankozettel", "tokens": ["An", "Cha\u00b7ron", ";", "hier", "ein", "Ban\u00b7ko\u00b7zet\u00b7tel"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$.", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An Plutus. Deine Frau, die Vettel,", "tokens": ["An", "Plu\u00b7tus", ".", "Dei\u00b7ne", "Frau", ",", "die", "Vet\u00b7tel", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$.", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Schifft wirklich auf dem H\u00f6llenflu\u00df.", "tokens": ["Schifft", "wirk\u00b7lich", "auf", "dem", "H\u00f6l\u00b7len\u00b7flu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geh hin, den Dank will ich dir sparen.", "tokens": ["Geh", "hin", ",", "den", "Dank", "will", "ich", "dir", "spa\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "ART", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So schnell mu\u00df kein Karthaunenschu\u00df", "tokens": ["So", "schnell", "mu\u00df", "kein", "Kar\u00b7thau\u00b7nen\u00b7schu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VMFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Zevs die schwarze Luft durchfahren,", "tokens": ["Des", "Zevs", "die", "schwar\u00b7ze", "Luft", "durch\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als unser Mann den Tartarus.", "tokens": ["Als", "un\u00b7ser", "Mann", "den", "Tar\u00b7ta\u00b7rus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schon k\u00fc\u00dft er die erstaunten Br\u00fcder", "tokens": ["Schon", "k\u00fc\u00dft", "er", "die", "er\u00b7staun\u00b7ten", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Im dichtern Kleid des ersten Leibs,", "tokens": ["Im", "dich\u00b7tern", "Kleid", "des", "ers\u00b7ten", "Leibs", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und fand wie Hiob alles wieder,", "tokens": ["Und", "fand", "wie", "Hiob", "al\u00b7les", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "NE", "PIS", "ADV", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Noch mehr \u2013 die Urne seines Weibs.", "tokens": ["Noch", "mehr", "\u2013", "die", "Ur\u00b7ne", "sei\u00b7nes", "Weibs", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nun l\u00e4\u00dft er auf dem Land sich nieder,", "tokens": ["Nun", "l\u00e4\u00dft", "er", "auf", "dem", "Land", "sich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Kauft B\u00fccher, wird ein Philosoph", "tokens": ["Kauft", "B\u00fc\u00b7cher", ",", "wird", "ein", "Phi\u00b7lo\u00b7soph"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und schw\u00f6rt nur bey den weisen Alten.", "tokens": ["Und", "schw\u00f6rt", "nur", "bey", "den", "wei\u00b7sen", "Al\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Er giebt sein Gold nebst Haus und Hof", "tokens": ["Er", "giebt", "sein", "Gold", "nebst", "Haus", "und", "Hof"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Zween Epikurern zu verwalten,", "tokens": ["Zween", "E\u00b7pi\u00b7ku\u00b7rern", "zu", "ver\u00b7wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die, w\u00e4hrend er Systeme liest,", "tokens": ["Die", ",", "w\u00e4h\u00b7rend", "er", "Sys\u00b7te\u00b7me", "liest", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.14": {"text": "So treulich mit dem Gute schalten,", "tokens": ["So", "treu\u00b7lich", "mit", "dem", "Gu\u00b7te", "schal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Da\u00df eh das vierte Jahr verflie\u00dft,", "tokens": ["Da\u00df", "eh", "das", "vier\u00b7te", "Jahr", "ver\u00b7flie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Nur B\u00fccher noch die Schr\u00e4nke f\u00fcllen.", "tokens": ["Nur", "B\u00fc\u00b7cher", "noch", "die", "Schr\u00e4n\u00b7ke", "f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ey, ey, das h\u00e4tt ich nicht gedacht!", "tokens": ["Ey", ",", "ey", ",", "das", "h\u00e4tt", "ich", "nicht", "ge\u00b7dacht", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rief er best\u00fcrzt. Doch weg ihr Grillen!", "tokens": ["Rief", "er", "be\u00b7st\u00fcrzt", ".", "Doch", "weg", "ihr", "Gril\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$.", "KON", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Weib mit zw\u00f6lf Talenten macht", "tokens": ["Ein", "Weib", "mit", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", "macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich dieses Ungl\u00fcck leicht vergessen.", "tokens": ["Mich", "die\u00b7ses", "Un\u00b7gl\u00fcck", "leicht", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nun reist er auf die Freyerey,", "tokens": ["Nun", "reist", "er", "auf", "die", "Frey\u00b7e\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Just wie der Kaufmann auf die Messen.", "tokens": ["Just", "wie", "der", "Kauf\u00b7mann", "auf", "die", "Mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Fortuna steht den Narren bey;", "tokens": ["For\u00b7tu\u00b7na", "steht", "den", "Nar\u00b7ren", "bey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er fand das Weib mit zw\u00f6lf Talenten,", "tokens": ["Er", "fand", "das", "Weib", "mit", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Wittib eines Hofagenten,", "tokens": ["Die", "Wit\u00b7tib", "ei\u00b7nes", "Ho\u00b7fa\u00b7gen\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zwar runzlicht, schielend, taub und lahm,", "tokens": ["Zwar", "runz\u00b7licht", ",", "schie\u00b7lend", ",", "taub", "und", "lahm", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADJD", "$,", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Doch wer sieht das bey zw\u00f6lf Talenten?", "tokens": ["Doch", "wer", "sieht", "das", "bey", "zw\u00f6lf", "Ta\u00b7len\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "APPR", "CARD", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Nun tr\u00e4umt der frohe Br\u00e4utigam", "tokens": ["Nun", "tr\u00e4umt", "der", "fro\u00b7he", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Von nichts als seinen fetten Renten.", "tokens": ["Von", "nichts", "als", "sei\u00b7nen", "fet\u00b7ten", "Ren\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch eh der zweyte Monat kam,", "tokens": ["Doch", "eh", "der", "zwey\u00b7te", "Mo\u00b7nat", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sprach er von nichts als neuem Kreuze,", "tokens": ["Sprach", "er", "von", "nichts", "als", "neu\u00b7em", "Kreu\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PIS", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Von seiner Dame harter Zucht,", "tokens": ["Von", "sei\u00b7ner", "Da\u00b7me", "har\u00b7ter", "Zucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Von ihrer blinden Eifersucht,", "tokens": ["Von", "ih\u00b7rer", "blin\u00b7den", "Ei\u00b7fer\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Von ihrem unerh\u00f6rten Geize.", "tokens": ["Von", "ih\u00b7rem", "un\u00b7er\u00b7h\u00f6r\u00b7ten", "Gei\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Kurz Irus selbst war nicht so arm,", "tokens": ["Kurz", "I\u00b7rus", "selbst", "war", "nicht", "so", "arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NE", "ADV", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Und Socrates trug minder Plagen", "tokens": ["Und", "So\u00b7cra\u00b7tes", "trug", "min\u00b7der", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "ADV", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.21": {"text": "Als er. Die weisen Alten sagen:", "tokens": ["Als", "er", ".", "Die", "wei\u00b7sen", "Al\u00b7ten", "sa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$.", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Der Wein vertreibt der Grillen Schwarm.", "tokens": ["Der", "Wein", "ver\u00b7treibt", "der", "Gril\u00b7len", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Er glaubts und will das Mittel wagen;", "tokens": ["Er", "glaubts", "und", "will", "das", "Mit\u00b7tel", "wa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Doch kaum k\u00f6mmt er berauscht nach Haus,", "tokens": ["Doch", "kaum", "k\u00f6mmt", "er", "be\u00b7rauscht", "nach", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.25": {"text": "So st\u00f6\u00dft sein D\u00e4mon mit der Kr\u00fccke", "tokens": ["So", "st\u00f6\u00dft", "sein", "D\u00e4\u00b7mon", "mit", "der", "Kr\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Zum Stubenfenster ihn hinaus.", "tokens": ["Zum", "Stu\u00b7ben\u00b7fens\u00b7ter", "ihn", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Der arme Tropf brach das Genicke;", "tokens": ["Der", "ar\u00b7me", "Tropf", "brach", "das", "Ge\u00b7ni\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und als er vor den H\u00f6llenrath", "tokens": ["Und", "als", "er", "vor", "den", "H\u00f6l\u00b7len\u00b7rath"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Zum andern Mal mit scheuem Blicke", "tokens": ["Zum", "an\u00b7dern", "Mal", "mit", "scheu\u00b7em", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und marmoriertem Sch\u00e4del trat,", "tokens": ["Und", "mar\u00b7mo\u00b7rier\u00b7tem", "Sch\u00e4\u00b7del", "trat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Sprach Minos: traut ihn mit Meg\u00e4ren!", "tokens": ["Sprach", "Mi\u00b7nos", ":", "traut", "ihn", "mit", "Me\u00b7g\u00e4\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Die strafe seinen Selbstbetrug;", "tokens": ["Die", "stra\u00b7fe", "sei\u00b7nen", "Selbst\u00b7be\u00b7trug", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Nur Weise kann Erfahrung lehren,", "tokens": ["Nur", "Wei\u00b7se", "kann", "Er\u00b7fah\u00b7rung", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Die Narren macht sie niemals klug.", "tokens": ["Die", "Nar\u00b7ren", "macht", "sie", "nie\u00b7mals", "klug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}