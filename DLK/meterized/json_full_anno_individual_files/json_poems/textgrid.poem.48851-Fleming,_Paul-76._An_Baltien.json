{"textgrid.poem.48851": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "76. An Baltien", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Darf, edle ", "tokens": ["Darf", ",", "ed\u00b7le"], "token_info": ["word", "punct", "word"], "pos": ["VMFIN", "$,", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "weil dieser kleine Brief sehr weit zu reisen hat,", "tokens": ["weil", "die\u00b7ser", "klei\u00b7ne", "Brief", "sehr", "weit", "zu", "rei\u00b7sen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da List zu Felde liegt mit Neide fr\u00fch' und spat,", "tokens": ["da", "List", "zu", "Fel\u00b7de", "liegt", "mit", "Nei\u00b7de", "fr\u00fch'", "und", "spat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "VVFIN", "APPR", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da Vorwitz und Betrug den schmalen Pa\u00df berennen,", "tokens": ["da", "Vor\u00b7witz", "und", "Be\u00b7trug", "den", "schma\u00b7len", "Pa\u00df", "be\u00b7ren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "so wirst du aus der Hand doch meinen Namen kennen,", "tokens": ["so", "wirst", "du", "aus", "der", "Hand", "doch", "mei\u00b7nen", "Na\u00b7men", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die du wie deine kennst. Sie, meines Herzens Rat", "tokens": ["die", "du", "wie", "dei\u00b7ne", "kennst", ".", "Sie", ",", "mei\u00b7nes", "Her\u00b7zens", "Rat"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "KOKOM", "PPOSAT", "VVFIN", "$.", "PPER", "$,", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und stumme Rednerin, bezeugt dirs in der Tat,", "tokens": ["und", "stum\u00b7me", "Red\u00b7ne\u00b7rin", ",", "be\u00b7zeugt", "dirs", "in", "der", "Tat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wie ich von deiner Brunst nicht lasse nach zu brennen.", "tokens": ["wie", "ich", "von", "dei\u00b7ner", "Brunst", "nicht", "las\u00b7se", "nach", "zu", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "PTKNEG", "VVFIN", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Bist, du, wie ich, gesinnt, so bleibst du unverwandt,", "tokens": ["Bist", ",", "du", ",", "wie", "ich", ",", "ge\u00b7sinnt", ",", "so", "bleibst", "du", "un\u00b7ver\u00b7wandt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PPER", "$,", "PWAV", "PPER", "$,", "VVPP", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "beh\u00e4ltst mir deine Gunst, bis da\u00df ich deine Hand,", "tokens": ["be\u00b7h\u00e4ltst", "mir", "dei\u00b7ne", "Gunst", ",", "bis", "da\u00df", "ich", "dei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "KON", "KOUS", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die zarte, dermaleins hinwieder werde k\u00fc\u00dfen.", "tokens": ["die", "zar\u00b7te", ",", "der\u00b7ma\u00b7leins", "hin\u00b7wie\u00b7der", "wer\u00b7de", "k\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Itzt mu\u00df ich weiter fort. Doch solst du, meine Zier,", "tokens": ["Itzt", "mu\u00df", "ich", "wei\u00b7ter", "fort", ".", "Doch", "solst", "du", ",", "mei\u00b7ne", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKVZ", "$.", "KON", "VMFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "noch dieses wahre Wort von mir zu letzte wi\u00dfen,", "tokens": ["noch", "die\u00b7ses", "wah\u00b7re", "Wort", "von", "mir", "zu", "letz\u00b7te", "wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "APPR", "PPER", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "je weiter ich mich mach', je n\u00e4her k\u00f6mst du mir.", "tokens": ["je", "wei\u00b7ter", "ich", "mich", "mach'", ",", "je", "n\u00e4\u00b7her", "k\u00f6mst", "du", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "VVFIN", "$,", "ADV", "ADJD", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Darf, edle ", "tokens": ["Darf", ",", "ed\u00b7le"], "token_info": ["word", "punct", "word"], "pos": ["VMFIN", "$,", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "weil dieser kleine Brief sehr weit zu reisen hat,", "tokens": ["weil", "die\u00b7ser", "klei\u00b7ne", "Brief", "sehr", "weit", "zu", "rei\u00b7sen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da List zu Felde liegt mit Neide fr\u00fch' und spat,", "tokens": ["da", "List", "zu", "Fel\u00b7de", "liegt", "mit", "Nei\u00b7de", "fr\u00fch'", "und", "spat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "VVFIN", "APPR", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da Vorwitz und Betrug den schmalen Pa\u00df berennen,", "tokens": ["da", "Vor\u00b7witz", "und", "Be\u00b7trug", "den", "schma\u00b7len", "Pa\u00df", "be\u00b7ren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "so wirst du aus der Hand doch meinen Namen kennen,", "tokens": ["so", "wirst", "du", "aus", "der", "Hand", "doch", "mei\u00b7nen", "Na\u00b7men", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die du wie deine kennst. Sie, meines Herzens Rat", "tokens": ["die", "du", "wie", "dei\u00b7ne", "kennst", ".", "Sie", ",", "mei\u00b7nes", "Her\u00b7zens", "Rat"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "KOKOM", "PPOSAT", "VVFIN", "$.", "PPER", "$,", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und stumme Rednerin, bezeugt dirs in der Tat,", "tokens": ["und", "stum\u00b7me", "Red\u00b7ne\u00b7rin", ",", "be\u00b7zeugt", "dirs", "in", "der", "Tat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wie ich von deiner Brunst nicht lasse nach zu brennen.", "tokens": ["wie", "ich", "von", "dei\u00b7ner", "Brunst", "nicht", "las\u00b7se", "nach", "zu", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "PTKNEG", "VVFIN", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Bist, du, wie ich, gesinnt, so bleibst du unverwandt,", "tokens": ["Bist", ",", "du", ",", "wie", "ich", ",", "ge\u00b7sinnt", ",", "so", "bleibst", "du", "un\u00b7ver\u00b7wandt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PPER", "$,", "PWAV", "PPER", "$,", "VVPP", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "beh\u00e4ltst mir deine Gunst, bis da\u00df ich deine Hand,", "tokens": ["be\u00b7h\u00e4ltst", "mir", "dei\u00b7ne", "Gunst", ",", "bis", "da\u00df", "ich", "dei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "KON", "KOUS", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die zarte, dermaleins hinwieder werde k\u00fc\u00dfen.", "tokens": ["die", "zar\u00b7te", ",", "der\u00b7ma\u00b7leins", "hin\u00b7wie\u00b7der", "wer\u00b7de", "k\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Itzt mu\u00df ich weiter fort. Doch solst du, meine Zier,", "tokens": ["Itzt", "mu\u00df", "ich", "wei\u00b7ter", "fort", ".", "Doch", "solst", "du", ",", "mei\u00b7ne", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKVZ", "$.", "KON", "VMFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "noch dieses wahre Wort von mir zu letzte wi\u00dfen,", "tokens": ["noch", "die\u00b7ses", "wah\u00b7re", "Wort", "von", "mir", "zu", "letz\u00b7te", "wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "APPR", "PPER", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "je weiter ich mich mach', je n\u00e4her k\u00f6mst du mir.", "tokens": ["je", "wei\u00b7ter", "ich", "mich", "mach'", ",", "je", "n\u00e4\u00b7her", "k\u00f6mst", "du", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "VVFIN", "$,", "ADV", "ADJD", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}