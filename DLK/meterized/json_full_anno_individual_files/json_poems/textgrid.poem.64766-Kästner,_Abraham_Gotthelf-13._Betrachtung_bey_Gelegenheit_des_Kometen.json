{"textgrid.poem.64766": {"metadata": {"author": {"name": "K\u00e4stner, Abraham Gotthelf", "birth": "N.A.", "death": "N.A."}, "title": "13. Betrachtung bey Gelegenheit des Kometen", "genre": "verse", "period": "N.A.", "pub_year": 1742, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durch Glas, das unsre schwachen Blicke", "tokens": ["Durch", "Glas", ",", "das", "uns\u00b7re", "schwa\u00b7chen", "Bli\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zur Kenntni\u00df ferner Welten st\u00e4rkt,", "tokens": ["Zur", "Kennt\u00b7ni\u00df", "fer\u00b7ner", "Wel\u00b7ten", "st\u00e4rkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ward gestern, mit verschiednem Gl\u00fccke,", "tokens": ["Ward", "ge\u00b7stern", ",", "mit", "ver\u00b7schied\u00b7nem", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Der Erdball, der jetzt brennt, bemerkt.", "tokens": ["Der", "Erd\u00b7ball", ",", "der", "jetzt", "brennt", ",", "be\u00b7merkt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Des heitern Himmels blaues Leere", "tokens": ["Des", "hei\u00b7tern", "Him\u00b7mels", "blau\u00b7es", "Lee\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stellt sich des Einen Auge dar;", "tokens": ["Stellt", "sich", "des", "Ei\u00b7nen", "Au\u00b7ge", "dar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der findet in dem Sternenheere,", "tokens": ["Der", "fin\u00b7det", "in", "dem", "Ster\u00b7nen\u00b7hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Statt des Kometen, den Polar.", "tokens": ["Statt", "des", "Ko\u00b7me\u00b7ten", ",", "den", "Po\u00b7lar", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wohl! endlich hab ich ihn gefunden,", "tokens": ["Wohl", "!", "end\u00b7lich", "hab", "ich", "ihn", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So ruft der Dritte halb entz\u00fcckt;", "tokens": ["So", "ruft", "der", "Drit\u00b7te", "halb", "ent\u00b7z\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ruft, und sieht sein Gl\u00fcck verschwunden,", "tokens": ["Er", "ruft", ",", "und", "sieht", "sein", "Gl\u00fcck", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Indem die Hand das Rohr verr\u00fcckt.", "tokens": ["In\u00b7dem", "die", "Hand", "das", "Rohr", "ver\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Sch\u00f6nen W\u00fcnschen und Bem\u00fchen", "tokens": ["Der", "Sch\u00f6\u00b7nen", "W\u00fcn\u00b7schen", "und", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt selbst den Unbestand nicht fest;", "tokens": ["H\u00e4lt", "selbst", "den", "Un\u00b7be\u00b7stand", "nicht", "fest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sehn ihn durch die Gl\u00e4ser fliehen,", "tokens": ["Sie", "sehn", "ihn", "durch", "die", "Gl\u00e4\u00b7ser", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie er das Rohr, das wankt, verl\u00e4\u00dft.", "tokens": ["Wie", "er", "das", "Rohr", ",", "das", "wankt", ",", "ver\u00b7l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "$,", "PDS", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was macht den Stern vor uns verschwinden?", "tokens": ["Was", "macht", "den", "Stern", "vor", "uns", "ver\u00b7schwin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Aefft unsern Flei\u00df wohl sein Betrug?", "tokens": ["A\u00b7efft", "un\u00b7sern", "Flei\u00df", "wohl", "sein", "Be\u00b7trug", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Nein, ihn gewi\u00df durchs Rohr zu finden,", "tokens": ["Nein", ",", "ihn", "ge\u00b7wi\u00df", "durchs", "Rohr", "zu", "fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind wir nur nicht geschickt genug.", "tokens": ["Sind", "wir", "nur", "nicht", "ge\u00b7schickt", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Geschichte, du sollst mir jetzt zeigen,", "tokens": ["Ge\u00b7schich\u00b7te", ",", "du", "sollst", "mir", "jetzt", "zei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Was wir in keiner Fabel sehn.", "tokens": ["Was", "wir", "in", "kei\u00b7ner", "Fa\u00b7bel", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hei\u00df' M\u00e4nner von dem Laster schweigen,", "tokens": ["Hei\u00df'", "M\u00e4n\u00b7ner", "von", "dem", "Las\u00b7ter", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit welchem sie die Sch\u00f6nen schm\u00e4hn.", "tokens": ["Mit", "wel\u00b7chem", "sie", "die", "Sch\u00f6\u00b7nen", "schm\u00e4hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Man braucht nicht lange nachzusinnen,", "tokens": ["Man", "braucht", "nicht", "lan\u00b7ge", "nach\u00b7zu\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn Mancher sie f\u00fcr falsch erkl\u00e4rt;", "tokens": ["Wenn", "Man\u00b7cher", "sie", "f\u00fcr", "falsch", "er\u00b7kl\u00e4rt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Herz zu kennen, zu gewinnen,", "tokens": ["Ihr", "Herz", "zu", "ken\u00b7nen", ",", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fehlt ihm Geschicklichkeit und Werth.", "tokens": ["Fehlt", "ihm", "Ge\u00b7schick\u00b7lich\u00b7keit", "und", "Werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Durch Glas, das unsre schwachen Blicke", "tokens": ["Durch", "Glas", ",", "das", "uns\u00b7re", "schwa\u00b7chen", "Bli\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zur Kenntni\u00df ferner Welten st\u00e4rkt,", "tokens": ["Zur", "Kennt\u00b7ni\u00df", "fer\u00b7ner", "Wel\u00b7ten", "st\u00e4rkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ward gestern, mit verschiednem Gl\u00fccke,", "tokens": ["Ward", "ge\u00b7stern", ",", "mit", "ver\u00b7schied\u00b7nem", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Der Erdball, der jetzt brennt, bemerkt.", "tokens": ["Der", "Erd\u00b7ball", ",", "der", "jetzt", "brennt", ",", "be\u00b7merkt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Des heitern Himmels blaues Leere", "tokens": ["Des", "hei\u00b7tern", "Him\u00b7mels", "blau\u00b7es", "Lee\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stellt sich des Einen Auge dar;", "tokens": ["Stellt", "sich", "des", "Ei\u00b7nen", "Au\u00b7ge", "dar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der findet in dem Sternenheere,", "tokens": ["Der", "fin\u00b7det", "in", "dem", "Ster\u00b7nen\u00b7hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Statt des Kometen, den Polar.", "tokens": ["Statt", "des", "Ko\u00b7me\u00b7ten", ",", "den", "Po\u00b7lar", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wohl! endlich hab ich ihn gefunden,", "tokens": ["Wohl", "!", "end\u00b7lich", "hab", "ich", "ihn", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So ruft der Dritte halb entz\u00fcckt;", "tokens": ["So", "ruft", "der", "Drit\u00b7te", "halb", "ent\u00b7z\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ruft, und sieht sein Gl\u00fcck verschwunden,", "tokens": ["Er", "ruft", ",", "und", "sieht", "sein", "Gl\u00fcck", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Indem die Hand das Rohr verr\u00fcckt.", "tokens": ["In\u00b7dem", "die", "Hand", "das", "Rohr", "ver\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Sch\u00f6nen W\u00fcnschen und Bem\u00fchen", "tokens": ["Der", "Sch\u00f6\u00b7nen", "W\u00fcn\u00b7schen", "und", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt selbst den Unbestand nicht fest;", "tokens": ["H\u00e4lt", "selbst", "den", "Un\u00b7be\u00b7stand", "nicht", "fest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie sehn ihn durch die Gl\u00e4ser fliehen,", "tokens": ["Sie", "sehn", "ihn", "durch", "die", "Gl\u00e4\u00b7ser", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie er das Rohr, das wankt, verl\u00e4\u00dft.", "tokens": ["Wie", "er", "das", "Rohr", ",", "das", "wankt", ",", "ver\u00b7l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "$,", "PDS", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Was macht den Stern vor uns verschwinden?", "tokens": ["Was", "macht", "den", "Stern", "vor", "uns", "ver\u00b7schwin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Aefft unsern Flei\u00df wohl sein Betrug?", "tokens": ["A\u00b7efft", "un\u00b7sern", "Flei\u00df", "wohl", "sein", "Be\u00b7trug", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Nein, ihn gewi\u00df durchs Rohr zu finden,", "tokens": ["Nein", ",", "ihn", "ge\u00b7wi\u00df", "durchs", "Rohr", "zu", "fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind wir nur nicht geschickt genug.", "tokens": ["Sind", "wir", "nur", "nicht", "ge\u00b7schickt", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Geschichte, du sollst mir jetzt zeigen,", "tokens": ["Ge\u00b7schich\u00b7te", ",", "du", "sollst", "mir", "jetzt", "zei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Was wir in keiner Fabel sehn.", "tokens": ["Was", "wir", "in", "kei\u00b7ner", "Fa\u00b7bel", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hei\u00df' M\u00e4nner von dem Laster schweigen,", "tokens": ["Hei\u00df'", "M\u00e4n\u00b7ner", "von", "dem", "Las\u00b7ter", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit welchem sie die Sch\u00f6nen schm\u00e4hn.", "tokens": ["Mit", "wel\u00b7chem", "sie", "die", "Sch\u00f6\u00b7nen", "schm\u00e4hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Man braucht nicht lange nachzusinnen,", "tokens": ["Man", "braucht", "nicht", "lan\u00b7ge", "nach\u00b7zu\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn Mancher sie f\u00fcr falsch erkl\u00e4rt;", "tokens": ["Wenn", "Man\u00b7cher", "sie", "f\u00fcr", "falsch", "er\u00b7kl\u00e4rt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Herz zu kennen, zu gewinnen,", "tokens": ["Ihr", "Herz", "zu", "ken\u00b7nen", ",", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fehlt ihm Geschicklichkeit und Werth.", "tokens": ["Fehlt", "ihm", "Ge\u00b7schick\u00b7lich\u00b7keit", "und", "Werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}