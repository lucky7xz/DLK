{"dta.poem.4423": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  Der Geschmack.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1727", "urn": "urn:nbn:de:kobv:b4-200905198599", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da wir dieses Sinnes Gaben", "tokens": ["Da", "wir", "die\u00b7ses", "Sin\u00b7nes", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch betrachtet, werden wir", "tokens": ["Auch", "be\u00b7trach\u00b7tet", ",", "wer\u00b7den", "wir"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "VVPP", "$,", "VAFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den Geschmack zu pr\u00fcfen haben,", "tokens": ["Den", "Ge\u00b7schmack", "zu", "pr\u00fc\u00b7fen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Drin ich neue Wunder sp\u00fcr,", "tokens": ["Drin", "ich", "neu\u00b7e", "Wun\u00b7der", "sp\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die nichts minder sind, wie jene.", "tokens": ["Die", "nichts", "min\u00b7der", "sind", ",", "wie", "je\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VAFIN", "$,", "PWAV", "PDS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn der Mund, die Zung\u2019 und Z\u00e4hne,", "tokens": ["Denn", "der", "Mund", ",", "die", "Zung'", "und", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Gaum und Lippen, K\u00e4l\u2019 und Schlund", "tokens": ["Gaum", "und", "Lip\u00b7pen", ",", "K\u00e4l'", "und", "Schlund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Machen selt\u2019ne Sachen kund.", "tokens": ["Ma\u00b7chen", "selt'\u00b7ne", "Sa\u00b7chen", "kund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "In der regen Zunge stecket", "tokens": ["In", "der", "re\u00b7gen", "Zun\u00b7ge", "ste\u00b7cket"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Eine Kraft, so wunderbar,", "tokens": ["Ei\u00b7ne", "Kraft", ",", "so", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil sie f\u00fclet, redet, schmecket,", "tokens": ["Weil", "sie", "f\u00fc\u00b7let", ",", "re\u00b7det", ",", "schme\u00b7cket", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rauh und glatt ist, ja so gar", "tokens": ["Rauh", "und", "glatt", "ist", ",", "ja", "so", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "ADJD", "VAFIN", "$,", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sich auf tausend Ahrten reget,", "tokens": ["Sich", "auf", "tau\u00b7send", "Ahr\u00b7ten", "re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sauget, lecket, Speichel heget.", "tokens": ["Sau\u00b7get", ",", "le\u00b7cket", ",", "Spei\u00b7chel", "he\u00b7get", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Gott hat sie, wie man es sp\u00fcr\u2019t,", "tokens": ["Gott", "hat", "sie", ",", "wie", "man", "es", "sp\u00fcr't", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PWAV", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Recht verwunderlich formir\u2019t.", "tokens": ["Recht", "ver\u00b7wun\u00b7der\u00b7lich", "for\u00b7mir'", "t."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["NN", "ADJD", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ausw\u00e4rts trifft man mit Ergetzen", "tokens": ["Aus\u00b7w\u00e4rts", "trifft", "man", "mit", "Er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kleine spitze W\u00e4rzgen an,", "tokens": ["Klei\u00b7ne", "spit\u00b7ze", "W\u00e4rz\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche sich im Speichel netzen,", "tokens": ["Wel\u00b7che", "sich", "im", "Spei\u00b7chel", "net\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der durch sie leicht sch\u00e4umen kann.", "tokens": ["Der", "durch", "sie", "leicht", "sch\u00e4u\u00b7men", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn nun die, sich zu erfrischen,", "tokens": ["Wenn", "nun", "die", ",", "sich", "zu", "er\u00b7fri\u00b7schen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Speisen mit dem Speichel mischen,", "tokens": ["Spei\u00b7sen", "mit", "dem", "Spei\u00b7chel", "mi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "F\u00fcl\u2019t die Sel\u2019 es gar geschwind,", "tokens": ["F\u00fcl't", "die", "Sel'", "es", "gar", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weil es lauter Nervgen sind.", "tokens": ["Weil", "es", "lau\u00b7ter", "Nerv\u00b7gen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Der zerk\u00e4uten Speise Teile", "tokens": ["Der", "zer\u00b7k\u00e4u\u00b7ten", "Spei\u00b7se", "Tei\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind teils glatt, gelind\u2019 und rund,", "tokens": ["Sind", "teils", "glatt", ",", "ge\u00b7lind'", "und", "rund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Teils recht spitz wie kleine Pfeile,", "tokens": ["Teils", "recht", "spitz", "wie", "klei\u00b7ne", "Pfei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "KOKOM", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wodurch, wann sie Zung\u2019 und Mund", "tokens": ["Wo\u00b7durch", ",", "wann", "sie", "Zung'", "und", "Mund"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "PWAV", "PPER", "NN", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Mit verschied\u2019ner Sch\u00e4rfe r\u00fchren,", "tokens": ["Mit", "ver\u00b7schie\u00b7d'\u00b7ner", "Sch\u00e4r\u00b7fe", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Wir was saur- und herbes sp\u00fcren,", "tokens": ["Wir", "was", "saur", "und", "her\u00b7bes", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PWS", "TRUNC", "KON", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da, was rund, was weich und leicht,", "tokens": ["Da", ",", "was", "rund", ",", "was", "weich", "und", "leicht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "ADJD", "$,", "PRELS", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Uns hingegen s\u00fcsse deucht.", "tokens": ["Uns", "hin\u00b7ge\u00b7gen", "s\u00fcs\u00b7se", "deucht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ungeschmackt sind alle Sachen,", "tokens": ["Un\u00b7ge\u00b7schmackt", "sind", "al\u00b7le", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die zu fl\u00fcssig und zu fest,", "tokens": ["Die", "zu", "fl\u00fcs\u00b7sig", "und", "zu", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKA", "ADJD", "KON", "PTKZU", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil sie keinen Eindruck machen,", "tokens": ["Weil", "sie", "kei\u00b7nen", "Ein\u00b7druck", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da sich die\u00df nicht l\u00f6sen l\u00e4sst,", "tokens": ["Da", "sich", "die\u00df", "nicht", "l\u00f6\u00b7sen", "l\u00e4sst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PDS", "PTKNEG", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und das feuchte kein Bewegen", "tokens": ["Und", "das", "feuch\u00b7te", "kein", "Be\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In den Nerven kann erregen;", "tokens": ["In", "den", "Ner\u00b7ven", "kann", "er\u00b7re\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Aber Salz schmeckt allen wol,", "tokens": ["A\u00b7ber", "Salz", "schmeckt", "al\u00b7len", "wol", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PIS", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weil es zarter Spitzen voll.", "tokens": ["Weil", "es", "zar\u00b7ter", "Spit\u00b7zen", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Da\u00df die innerlichen Flammen", "tokens": ["Da\u00df", "die", "in\u00b7ner\u00b7li\u00b7chen", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Uns nicht t\u00f6dten vor der Zeit,", "tokens": ["Uns", "nicht", "t\u00f6d\u00b7ten", "vor", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zieht sich in den Mund zusammen", "tokens": ["Zieht", "sich", "in", "den", "Mund", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine laue Feuchtigkeit,", "tokens": ["Ei\u00b7ne", "lau\u00b7e", "Feuch\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche diese Hitze lindert,", "tokens": ["Wel\u00b7che", "die\u00b7se", "Hit\u00b7ze", "lin\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und die heisse Brunst vermindert,", "tokens": ["Und", "die", "heis\u00b7se", "Brunst", "ver\u00b7min\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df des Menschen fl\u00fcssigs Blut", "tokens": ["Da\u00df", "des", "Men\u00b7schen", "fl\u00fcs\u00b7sigs", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nicht gerinne von der Gluht.", "tokens": ["Nicht", "ge\u00b7rin\u00b7ne", "von", "der", "Gluht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "In des Mundes Purpur-H\u00f6le,", "tokens": ["In", "des", "Mun\u00b7des", "Pur\u00b7pur\u00b7H\u00f6le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die das Par der Lippen schliess\u2019t,", "tokens": ["Die", "das", "Par", "der", "Lip\u00b7pen", "schliess't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zeiget sich die kluge Sele,", "tokens": ["Zei\u00b7get", "sich", "die", "klu\u00b7ge", "Se\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die in s\u00fcsse Worte fliess\u2019t,", "tokens": ["Die", "in", "s\u00fcs\u00b7se", "Wor\u00b7te", "fliess't", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und in diesen engen Schranken", "tokens": ["Und", "in", "die\u00b7sen", "en\u00b7gen", "Schran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nemen geistige Gedanken,", "tokens": ["Ne\u00b7men", "geis\u00b7ti\u00b7ge", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn wir reden, C\u00f6rper an;", "tokens": ["Wenn", "wir", "re\u00b7den", ",", "C\u00f6r\u00b7per", "an", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$,", "NE", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Da\u00df man sie begreifen kann.", "tokens": ["Da\u00df", "man", "sie", "be\u00b7grei\u00b7fen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wer erstaunt nicht, wenn er denket,", "tokens": ["Wer", "er\u00b7staunt", "nicht", ",", "wenn", "er", "den\u00b7ket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie der Zunge Fertigkeit", "tokens": ["Wie", "der", "Zun\u00b7ge", "Fer\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich auf tausend Ahrten lenket,", "tokens": ["Sich", "auf", "tau\u00b7send", "Ahr\u00b7ten", "len\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um der Selen Unterscheid", "tokens": ["Um", "der", "Se\u00b7len", "Un\u00b7ter\u00b7scheid"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wunder-w\u00fcrdig zu formiren,", "tokens": ["Wun\u00b7der\u00b7w\u00fcr\u00b7dig", "zu", "for\u00b7mi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df von andern auch zu sp\u00fcren,", "tokens": ["Da\u00df", "von", "an\u00b7dern", "auch", "zu", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PIS", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wie, was hier der Geist gedacht,", "tokens": ["Wie", ",", "was", "hier", "der", "Geist", "ge\u00b7dacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "C\u00f6rperlich wird kund gemacht?", "tokens": ["C\u00f6r\u00b7per\u00b7lich", "wird", "kund", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Glied, das uns durch sein Erz\u00e4len", "tokens": ["Glied", ",", "das", "uns", "durch", "sein", "Er\u00b7z\u00e4\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fremde Geister einverleibt,", "tokens": ["Frem\u00b7de", "Geis\u00b7ter", "ein\u00b7ver\u00b7leibt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rege Feder uns\u2019rer Selen,", "tokens": ["Re\u00b7ge", "Fe\u00b7der", "un\u00b7s'\u00b7rer", "Se\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Die mit lauten Schriften schreibt,", "tokens": ["Die", "mit", "lau\u00b7ten", "Schrif\u00b7ten", "schreibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der Gedanken Zaum und Riegel,", "tokens": ["Der", "Ge\u00b7dan\u00b7ken", "Zaum", "und", "Rie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wunder-Pinsel, G\u00f6ttlichs Siegel,", "tokens": ["Wun\u00b7der\u00b7Pin\u00b7sel", ",", "G\u00f6tt\u00b7lichs", "Sie\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das, was unsre Sele heg\u2019t,", "tokens": ["Das", ",", "was", "uns\u00b7re", "Se\u00b7le", "heg't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Andern in die Sele pr\u00e4g\u2019t!", "tokens": ["An\u00b7dern", "in", "die", "Se\u00b7le", "pr\u00e4g't", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Merket, wie sie sich zu regen,", "tokens": ["Mer\u00b7ket", ",", "wie", "sie", "sich", "zu", "re\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "PRF", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und zum sprechen fertig sey,", "tokens": ["Und", "zum", "spre\u00b7chen", "fer\u00b7tig", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "VVFIN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn zehn Muskeln sie bewegen,", "tokens": ["Wenn", "zehn", "Mus\u00b7keln", "sie", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deren immer zwey und zwey", "tokens": ["De\u00b7ren", "im\u00b7mer", "zwey", "und", "zwey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "CARD", "KON", "CARD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hinter, vor, zu beyden Seiten,", "tokens": ["Hin\u00b7ter", ",", "vor", ",", "zu", "bey\u00b7den", "Sei\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auf- und niederw\u00e4rts sie leiten,", "tokens": ["Auf", "und", "nie\u00b7der\u00b7w\u00e4rts", "sie", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und ein angewachs\u2019ner Zaum", "tokens": ["Und", "ein", "an\u00b7ge\u00b7wachs'\u00b7ner", "Zaum"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "L\u00e4sst ihr nicht zu weiten Raum.", "tokens": ["L\u00e4sst", "ihr", "nicht", "zu", "wei\u00b7ten", "Raum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PTKZU", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Dieses Glied recht zu bewahren,", "tokens": ["Die\u00b7ses", "Glied", "recht", "zu", "be\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat es die Natur versehn,", "tokens": ["Hat", "es", "die", "Na\u00b7tur", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df stets, wie geharn\u2019schte Scharen,", "tokens": ["Da\u00df", "stets", ",", "wie", "ge\u00b7harn'schte", "Scha\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Rings um sie die Z\u00e4hne stehn.", "tokens": ["Rings", "um", "sie", "die", "Z\u00e4h\u00b7ne", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese kleine Marmor-Klippen", "tokens": ["Die\u00b7se", "klei\u00b7ne", "Mar\u00b7mor\u00b7Klip\u00b7pen"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Decken wiederum die Lippen,", "tokens": ["De\u00b7cken", "wie\u00b7de\u00b7rum", "die", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Unter deren Schutz\u2019 und Hut", "tokens": ["Un\u00b7ter", "de\u00b7ren", "Schutz'", "und", "Hut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Uns\u2019re Zung\u2019 auf Polstern ruht.", "tokens": ["Un\u00b7s'\u00b7re", "Zung'", "auf", "Pols\u00b7tern", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "An der Zung\u2019 ist noch zu preisen,", "tokens": ["An", "der", "Zung'", "ist", "noch", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df derselben rege Kraft", "tokens": ["Da\u00df", "der\u00b7sel\u00b7ben", "re\u00b7ge", "Kraft"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns in so viel tausend Speisen", "tokens": ["Uns", "in", "so", "viel", "tau\u00b7send", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADV", "ADV", "CARD", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Tausendfache Lust verschafft.", "tokens": ["Tau\u00b7send\u00b7fa\u00b7che", "Lust", "ver\u00b7schafft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie kann durch ihr forschend Schmecken", "tokens": ["Sie", "kann", "durch", "ihr", "for\u00b7schend", "Schme\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "VVPP", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Solch Vergn\u00fcgen uns erwecken,", "tokens": ["Solch", "Ver\u00b7gn\u00fc\u00b7gen", "uns", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df so gar der Geist versp\u00fcr\u2019t,", "tokens": ["Da\u00df", "so", "gar", "der", "Geist", "ver\u00b7sp\u00fcr't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wie ein s\u00fcsser Trieb ihn r\u00fchrt.", "tokens": ["Wie", "ein", "s\u00fcs\u00b7ser", "Trieb", "ihn", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Herbe sind nicht reife Fr\u00fcchte;", "tokens": ["Her\u00b7be", "sind", "nicht", "rei\u00b7fe", "Fr\u00fcch\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00e4urlich-s\u00fc\u00df ist guter Wein;", "tokens": ["S\u00e4ur\u00b7lich\u00b7s\u00fc\u00df", "ist", "gu\u00b7ter", "Wein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bitter-s\u00fc\u00df sind viele Fr\u00fcchte,", "tokens": ["Bit\u00b7ter\u00b7s\u00fc\u00df", "sind", "vie\u00b7le", "Fr\u00fcch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Oliven \u00e4hnlich seyn;", "tokens": ["Die", "O\u00b7li\u00b7ven", "\u00e4hn\u00b7lich", "seyn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Saur sind Saurampf und Citronen;", "tokens": ["Saur", "sind", "Sau\u00b7rampf", "und", "Cit\u00b7ro\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "KON", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "S\u00fc\u00df hingegen sind Melonen,", "tokens": ["S\u00fc\u00df", "hin\u00b7ge\u00b7gen", "sind", "Me\u00b7lo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Honig, Zucker, Milch und Most.", "tokens": ["Ho\u00b7nig", ",", "Zu\u00b7cker", ",", "Milch", "und", "Most", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mark und Oel sind fette Kost.", "tokens": ["Mark", "und", "O\u00b7el", "sind", "fet\u00b7te", "Kost", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.14": {"line.1": {"text": "Wo uns eine Sach\u2019 auf Erden", "tokens": ["Wo", "uns", "ei\u00b7ne", "Sach'", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsers Sch\u00f6pfers Liebe weis\u2019t,", "tokens": ["Un\u00b7sers", "Sch\u00f6p\u00b7fers", "Lie\u00b7be", "weis't", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist es, da verbunden werden", "tokens": ["Ist", "es", ",", "da", "ver\u00b7bun\u00b7den", "wer\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "ADV", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "(wenn sich unser C\u00f6rper speis\u2019t)", "tokens": ["(", "wenn", "sich", "un\u00b7ser", "C\u00f6r\u00b7per", "speis't", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mit der Not so s\u00fcsse L\u00fcste.", "tokens": ["Mit", "der", "Not", "so", "s\u00fcs\u00b7se", "L\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn man ekelnd speisen m\u00fcste;", "tokens": ["Wenn", "man", "e\u00b7kelnd", "spei\u00b7sen", "m\u00fcs\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "W\u00fcrd\u2019 es, wie wir gern gestehn,", "tokens": ["W\u00fcrd'", "es", ",", "wie", "wir", "gern", "ge\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nie zu rechter Zeit geschehn.", "tokens": ["Nie", "zu", "rech\u00b7ter", "Zeit", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Was die unverdross\u2019nen Bienen", "tokens": ["Was", "die", "un\u00b7ver\u00b7dross'\u00b7nen", "Bie\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und was der verbrannte Mor", "tokens": ["Und", "was", "der", "ver\u00b7brann\u00b7te", "Mor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zieh\u2019n aus Rosen und Jesminen", "tokens": ["Zieh'n", "aus", "Ro\u00b7sen", "und", "Jes\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Maderens Zucker-Ror,", "tokens": ["Und", "Ma\u00b7de\u00b7rens", "Zu\u00b7cke\u00b7rRor", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Alle S\u00fcssigkeit der Reben", "tokens": ["Al\u00b7le", "S\u00fcs\u00b7sig\u00b7keit", "der", "Re\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00e4r der Welt umsonst gegeben,", "tokens": ["W\u00e4r", "der", "Welt", "um\u00b7sonst", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Schmeckte nicht der Zungen Kraft", "tokens": ["Schmeck\u00b7te", "nicht", "der", "Zun\u00b7gen", "Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Jedes Dinges Eigenschaft.", "tokens": ["Je\u00b7des", "Din\u00b7ges", "Ei\u00b7gen\u00b7schaft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Mensch, erw\u00e4ge doch und merke,", "tokens": ["Mensch", ",", "er\u00b7w\u00e4\u00b7ge", "doch", "und", "mer\u00b7ke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ADV", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn dein Mund was gutes schmeckt,", "tokens": ["Wenn", "dein", "Mund", "was", "gu\u00b7tes", "schmeckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PWS", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deines Sch\u00f6pfers Wunder-Werke!", "tokens": ["Dei\u00b7nes", "Sch\u00f6p\u00b7fers", "Wun\u00b7der\u00b7Wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was darin f\u00fcr Weisheit steckt,", "tokens": ["Was", "da\u00b7rin", "f\u00fcr", "Weis\u00b7heit", "steckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PAV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist nicht leichtlich zu ermessen,", "tokens": ["Ist", "nicht", "leicht\u00b7lich", "zu", "er\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da Er nicht nur in das Essen", "tokens": ["Da", "Er", "nicht", "nur", "in", "das", "Es\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und in alles, was uns tr\u00e4nkt,", "tokens": ["Und", "in", "al\u00b7les", ",", "was", "uns", "tr\u00e4nkt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "So verschied\u2019nen Saft gesenkt;", "tokens": ["So", "ver\u00b7schie\u00b7d'\u00b7nen", "Saft", "ge\u00b7senkt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVPP", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.17": {"line.1": {"text": "Sondern auch in deinem Munde", "tokens": ["Son\u00b7dern", "auch", "in", "dei\u00b7nem", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gaum und Zunge so gemacht,", "tokens": ["Gaum", "und", "Zun\u00b7ge", "so", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df, recht eben in dem Schlunde,", "tokens": ["Da\u00df", ",", "recht", "e\u00b7ben", "in", "dem", "Schlun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn man es genau betracht\u2019t,", "tokens": ["Wenn", "man", "es", "ge\u00b7nau", "be\u00b7tracht't", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Uns die Speis\u2019 erst Anmut bringet,", "tokens": ["Uns", "die", "Speis'", "erst", "An\u00b7mut", "brin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eben wenn man\u2019s nieder schlinget;", "tokens": ["E\u00b7ben", "wenn", "man's", "nie\u00b7der", "schlin\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "PTKVZ", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist demnach, mehr als man meint,", "tokens": ["Ist", "dem\u00b7nach", ",", "mehr", "als", "man", "meint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "$,", "ADV", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Narung, Nutz und Lust vereint.", "tokens": ["Na\u00b7rung", ",", "Nutz", "und", "Lust", "ver\u00b7eint", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Denke doch, wenn Schmerz und Fieber", "tokens": ["Den\u00b7ke", "doch", ",", "wenn", "Schmerz", "und", "Fie\u00b7ber"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "$,", "KOUS", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Uns in Blut und Adern steckt,", "tokens": ["Uns", "in", "Blut", "und", "A\u00b7dern", "steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie erb\u00e4rmlich uns dar\u00fcber,", "tokens": ["Wie", "er\u00b7b\u00e4rm\u00b7lich", "uns", "da\u00b7r\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PAV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was man isst und trinket, schmeckt!", "tokens": ["Was", "man", "isst", "und", "trin\u00b7ket", ",", "schmeckt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mu\u00df der Ekel vor den Speisen", "tokens": ["Mu\u00df", "der", "E\u00b7kel", "vor", "den", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns nicht augenscheinlich weisen,", "tokens": ["Uns", "nicht", "au\u00b7gen\u00b7schein\u00b7lich", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df man nie sein Gl\u00fcck ermisst,", "tokens": ["Da\u00df", "man", "nie", "sein", "Gl\u00fcck", "er\u00b7misst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wenn uns schmecket, was man isst?", "tokens": ["Wenn", "uns", "schme\u00b7cket", ",", "was", "man", "isst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Ew\u2019ge Liebe, sey gepriesen,", "tokens": ["Ew'\u00b7ge", "Lie\u00b7be", ",", "sey", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dir sey Ehre, Lob und Dank,", "tokens": ["Dir", "sey", "Eh\u00b7re", ",", "Lob", "und", "Dank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da Du solche Huld gewiesen", "tokens": ["Da", "Du", "sol\u00b7che", "Huld", "ge\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jm Geschmack, in Speis\u2019 und Trank!", "tokens": ["Jm", "Ge\u00b7schmack", ",", "in", "Speis'", "und", "Trank", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gib, da\u00df wir, so oft wir essen,", "tokens": ["Gib", ",", "da\u00df", "wir", ",", "so", "oft", "wir", "es\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "$,", "ADV", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Deine Wunder-Kraft ermessen,", "tokens": ["Dei\u00b7ne", "Wun\u00b7der\u00b7Kraft", "er\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die uns nicht nur Kost bescher\u2019t,", "tokens": ["Die", "uns", "nicht", "nur", "Kost", "be\u00b7scher't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "ADV", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sondern auch mit Lust uns n\u00e4r\u2019t.", "tokens": ["Son\u00b7dern", "auch", "mit", "Lust", "uns", "n\u00e4r'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "ADV", "APPR", "NN", "PPER", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Sprich, verwildertes Gem\u00fcte,", "tokens": ["Sprich", ",", "ver\u00b7wil\u00b7der\u00b7tes", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommt die Zung\u2019 auch ungefehr,", "tokens": ["Kommt", "die", "Zung'", "auch", "un\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder aus der Macht und G\u00fcte", "tokens": ["O\u00b7der", "aus", "der", "Macht", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eines weisen Wesens her?", "tokens": ["Ei\u00b7nes", "wei\u00b7sen", "We\u00b7sens", "her", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sprich: verdienen solche Werke", "tokens": ["Sprich", ":", "ver\u00b7die\u00b7nen", "sol\u00b7che", "Wer\u00b7ke"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVIMP", "$.", "VVFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht so viel, da\u00df man sie merke?", "tokens": ["Nicht", "so", "viel", ",", "da\u00df", "man", "sie", "mer\u00b7ke", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wers Gesch\u00f6pfe nicht betracht\u2019t,", "tokens": ["Wers", "Ge\u00b7sch\u00f6p\u00b7fe", "nicht", "be\u00b7tracht't", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sch\u00e4ndet seines Sch\u00f6pfers Macht.", "tokens": ["Sch\u00e4n\u00b7det", "sei\u00b7nes", "Sch\u00f6p\u00b7fers", "Macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}