{"textgrid.poem.47823": {"metadata": {"author": {"name": "Storm, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Einer Braut am Polterabend", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bringe dir ein leeres wei\u00dfes Buch,", "tokens": ["Ich", "brin\u00b7ge", "dir", "ein", "lee\u00b7res", "wei\u00b7\u00dfes", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Bl\u00e4tter drin noch ohne Bild und Spruch.", "tokens": ["Die", "Bl\u00e4t\u00b7ter", "drin", "noch", "oh\u00b7ne", "Bild", "und", "Spruch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sie sollen einst, wenn sie beschrieben sind,", "tokens": ["Sie", "sol\u00b7len", "einst", ",", "wenn", "sie", "be\u00b7schrie\u00b7ben", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dir bringen ein Erinnern hold und lind;", "tokens": ["Dir", "brin\u00b7gen", "ein", "E\u00b7rin\u00b7nern", "hold", "und", "lind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "An liebe Worte, die man zu dir sprach,", "tokens": ["An", "lie\u00b7be", "Wor\u00b7te", ",", "die", "man", "zu", "dir", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An treue Augen, die dir blickten nach. \u2013", "tokens": ["An", "treu\u00b7e", "Au\u00b7gen", ",", "die", "dir", "blick\u00b7ten", "nach", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Drauf log ich dir von dunklem Myrtenreis", "tokens": ["Drauf", "log", "ich", "dir", "von", "dunk\u00b7lem", "Myr\u00b7ten\u00b7reis"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den gr\u00fcnen Kranz, der aller Kr\u00e4nze Preis.", "tokens": ["Den", "gr\u00fc\u00b7nen", "Kranz", ",", "der", "al\u00b7ler", "Kr\u00e4n\u00b7ze", "Preis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Nimm ihn getrost! Denn mu\u00df ich auch gestehn,", "tokens": ["Nimm", "ihn", "ge\u00b7trost", "!", "Denn", "mu\u00df", "ich", "auch", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVPP", "$.", "KON", "VMFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er wird wie alles Laub dereinst vergehn,", "tokens": ["Er", "wird", "wie", "al\u00b7les", "Laub", "de\u00b7reinst", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "So wei\u00df ich doch, wenn Tag um Tag verschwand,", "tokens": ["So", "wei\u00df", "ich", "doch", ",", "wenn", "Tag", "um", "Tag", "ver\u00b7schwand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "H\u00e4ltst du den Zweig mit Fr\u00fcchten in der Hand.", "tokens": ["H\u00e4ltst", "du", "den", "Zweig", "mit", "Fr\u00fcch\u00b7ten", "in", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ich bringe dir ein leeres wei\u00dfes Buch,", "tokens": ["Ich", "brin\u00b7ge", "dir", "ein", "lee\u00b7res", "wei\u00b7\u00dfes", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Bl\u00e4tter drin noch ohne Bild und Spruch.", "tokens": ["Die", "Bl\u00e4t\u00b7ter", "drin", "noch", "oh\u00b7ne", "Bild", "und", "Spruch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Sie sollen einst, wenn sie beschrieben sind,", "tokens": ["Sie", "sol\u00b7len", "einst", ",", "wenn", "sie", "be\u00b7schrie\u00b7ben", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dir bringen ein Erinnern hold und lind;", "tokens": ["Dir", "brin\u00b7gen", "ein", "E\u00b7rin\u00b7nern", "hold", "und", "lind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "An liebe Worte, die man zu dir sprach,", "tokens": ["An", "lie\u00b7be", "Wor\u00b7te", ",", "die", "man", "zu", "dir", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An treue Augen, die dir blickten nach. \u2013", "tokens": ["An", "treu\u00b7e", "Au\u00b7gen", ",", "die", "dir", "blick\u00b7ten", "nach", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Drauf log ich dir von dunklem Myrtenreis", "tokens": ["Drauf", "log", "ich", "dir", "von", "dunk\u00b7lem", "Myr\u00b7ten\u00b7reis"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den gr\u00fcnen Kranz, der aller Kr\u00e4nze Preis.", "tokens": ["Den", "gr\u00fc\u00b7nen", "Kranz", ",", "der", "al\u00b7ler", "Kr\u00e4n\u00b7ze", "Preis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Nimm ihn getrost! Denn mu\u00df ich auch gestehn,", "tokens": ["Nimm", "ihn", "ge\u00b7trost", "!", "Denn", "mu\u00df", "ich", "auch", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVPP", "$.", "KON", "VMFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er wird wie alles Laub dereinst vergehn,", "tokens": ["Er", "wird", "wie", "al\u00b7les", "Laub", "de\u00b7reinst", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "So wei\u00df ich doch, wenn Tag um Tag verschwand,", "tokens": ["So", "wei\u00df", "ich", "doch", ",", "wenn", "Tag", "um", "Tag", "ver\u00b7schwand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "H\u00e4ltst du den Zweig mit Fr\u00fcchten in der Hand.", "tokens": ["H\u00e4ltst", "du", "den", "Zweig", "mit", "Fr\u00fcch\u00b7ten", "in", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}