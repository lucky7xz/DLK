{"dta.poem.20286": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "An Flavien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.85", "en:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ach edle Flavia! ich wei\u00df nicht wo ich bin/", "tokens": ["Ach", "ed\u00b7le", "Fla\u00b7via", "!", "ich", "wei\u00df", "nicht", "wo", "ich", "bin", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$.", "PPER", "VVFIN", "PTKNEG", "PWAV", "PPER", "VAFIN", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich schreib/ und wei\u00df nicht was/ dein schertzen macht mir schmertzen/", "tokens": ["Ich", "schreib", "/", "und", "wei\u00df", "nicht", "was", "/", "dein", "schert\u00b7zen", "macht", "mir", "schmert\u00b7zen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KON", "VVFIN", "PTKNEG", "PWS", "$(", "PPOSAT", "VVINF", "VVFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein stern der freundlichkeit reist meine freyheit hin/", "tokens": ["Dein", "stern", "der", "freund\u00b7lich\u00b7keit", "reist", "mei\u00b7ne", "frey\u00b7heit", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du schickst mir einen brieff/ und greiffst mir nach den hertzen.", "tokens": ["Du", "schickst", "mir", "ei\u00b7nen", "brieff", "/", "und", "greiffst", "mir", "nach", "den", "hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$(", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ach ein vergebner brieff! du hast es ja bey dir/", "tokens": ["Ach", "ein", "ver\u00b7geb\u00b7ner", "brieff", "!", "du", "hast", "es", "ja", "bey", "dir", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ART", "ADJA", "NN", "$.", "PPER", "VAFIN", "PPER", "ADV", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und mir ist nur davon ein kleiner rest erlaubet;", "tokens": ["Und", "mir", "ist", "nur", "da\u00b7von", "ein", "klei\u00b7ner", "rest", "er\u00b7lau\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn seine schalen sind zwar/ wie es scheint/ bey mir/", "tokens": ["Denn", "sei\u00b7ne", "scha\u00b7len", "sind", "zwar", "/", "wie", "es", "scheint", "/", "bey", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "VAFIN", "ADV", "$(", "PWAV", "PPER", "VVFIN", "$(", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du aber hast mir l\u00e4ngst den kern davon geraubet.", "tokens": ["Du", "a\u00b7ber", "hast", "mir", "l\u00e4ngst", "den", "kern", "da\u00b7von", "ge\u00b7rau\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich schreibe sehr verwirrt: Denn wer so lebt/ wie ich/", "tokens": ["Ich", "schrei\u00b7be", "sehr", "ver\u00b7wirrt", ":", "Denn", "wer", "so", "lebt", "/", "wie", "ich", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$.", "KON", "PWS", "ADV", "VVFIN", "$(", "PWAV", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und ohne hertze schreibt/ dem taumeln geist und sinnen.", "tokens": ["Und", "oh\u00b7ne", "hert\u00b7ze", "schreibt", "/", "dem", "tau\u00b7meln", "geist", "und", "sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "$(", "ART", "ADJA", "NN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verdirbt mir dieser brieff/ so schrey ich \u00fcber dich/", "tokens": ["Ver\u00b7dirbt", "mir", "die\u00b7ser", "brieff", "/", "so", "schrey", "ich", "\u00fc\u00b7ber", "dich", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "VVFIN", "$(", "ADV", "ADJD", "PPER", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was solt ich ohne hertz itzt wohl vollbringen k\u00f6nnen?", "tokens": ["Was", "solt", "ich", "oh\u00b7ne", "hertz", "itzt", "wohl", "voll\u00b7brin\u00b7gen", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "NN", "ADV", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch schreib ich/ wie ich kan/ als sclave deiner hand;", "tokens": ["Doch", "schreib", "ich", "/", "wie", "ich", "kan", "/", "als", "scla\u00b7ve", "dei\u00b7ner", "hand", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "PWAV", "PPER", "VMFIN", "$(", "KOKOM", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die fehler meiner schrifft sind deine sieges-zeichen.", "tokens": ["Die", "feh\u00b7ler", "mei\u00b7ner", "schrifft", "sind", "dei\u00b7ne", "sie\u00b7ges\u00b7zei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Reicht Critons dienstbarkeit dir hier kein besser pfand/", "tokens": ["Reicht", "Cri\u00b7tons", "dienst\u00b7bar\u00b7keit", "dir", "hier", "kein", "bes\u00b7ser", "pfand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "PPER", "ADV", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So denck/ ein schwacher kan nicht/ was er will/ erreichen;", "tokens": ["So", "denck", "/", "ein", "schwa\u00b7cher", "kan", "nicht", "/", "was", "er", "will", "/", "er\u00b7rei\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVIMP", "$(", "ART", "ADJA", "VMFIN", "PTKNEG", "$(", "PWS", "PPER", "VMFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und rechte liebe will nicht reich verbr\u00e4met seyn/", "tokens": ["Und", "rech\u00b7te", "lie\u00b7be", "will", "nicht", "reich", "ver\u00b7br\u00e4\u00b7met", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "VVFIN", "VMFIN", "PTKNEG", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sie will nicht allemahl mit purpur sich bedecken/", "tokens": ["Sie", "will", "nicht", "al\u00b7le\u00b7mahl", "mit", "pur\u00b7pur", "sich", "be\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "APPR", "ADJD", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sie stellt nicht selten sich in schlechter kleidung ein/", "tokens": ["Sie", "stellt", "nicht", "sel\u00b7ten", "sich", "in", "schlech\u00b7ter", "klei\u00b7dung", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "PRF", "APPR", "ADJA", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und meynt/ da\u00df schminck und schmuck nicht zieren sonder flecken.", "tokens": ["Und", "meynt", "/", "da\u00df", "schminck", "und", "schmuck", "nicht", "zie\u00b7ren", "son\u00b7der", "fle\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "ADJD", "KON", "ADJD", "PTKNEG", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Du aber/ Flavia/ gebrauchst verschwenderey/", "tokens": ["Du", "a\u00b7ber", "/", "Fla\u00b7via", "/", "ge\u00b7brauchst", "ver\u00b7schwen\u00b7de\u00b7rey", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "NE", "$(", "VVFIN", "PTKVZ", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Du thust mir deine gunst durch einen brieff zuwissen/", "tokens": ["Du", "thust", "mir", "dei\u00b7ne", "gunst", "durch", "ei\u00b7nen", "brieff", "zu\u00b7wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und da\u00df ich auch davon noch mehr versichert sey/", "tokens": ["Und", "da\u00df", "ich", "auch", "da\u00b7von", "noch", "mehr", "ver\u00b7si\u00b7chert", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PAV", "ADV", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So wilst du bald darauff mein schlechtes haus begr\u00fcssen.", "tokens": ["So", "wilst", "du", "bald", "dar\u00b7auff", "mein", "schlech\u00b7tes", "haus", "be\u00b7gr\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PAV", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ach freundin! das gel\u00fcck und dessen freuden-fest", "tokens": ["Ach", "freun\u00b7din", "!", "das", "ge\u00b7l\u00fcck", "und", "des\u00b7sen", "freu\u00b7den\u00b7fest"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "$.", "ART", "NN", "KON", "PDS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Speist die verliebten offt mit leeren fleisch-pasteten/", "tokens": ["Speist", "die", "ver\u00b7lieb\u00b7ten", "offt", "mit", "lee\u00b7ren", "fleischpas\u00b7te\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "++-+-+-+-+--", "measure": "unknown.measure.hexa"}, "line.27": {"text": "Und ob es seinen wein gleich etwas schmecken l\u00e4st/", "tokens": ["Und", "ob", "es", "sei\u00b7nen", "wein", "gleich", "et\u00b7was", "schme\u00b7cken", "l\u00e4st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "PIS", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So flie\u00dft er mehrentheils nur unsre lust zu t\u00f6dten.", "tokens": ["So", "flie\u00dft", "er", "meh\u00b7ren\u00b7theils", "nur", "uns\u00b7re", "lust", "zu", "t\u00f6d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Es dr\u00fccket das gel\u00fcck uns freundlich an die brust/", "tokens": ["Es", "dr\u00fc\u00b7cket", "das", "ge\u00b7l\u00fcck", "uns", "freund\u00b7lich", "an", "die", "brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und kratzet unvermerckt bey falschen liebes-k\u00fcssen/", "tokens": ["Und", "krat\u00b7zet", "un\u00b7ver\u00b7merckt", "bey", "fal\u00b7schen", "lie\u00b7bes\u00b7k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Es zeigt uns sein betrug den zucker reiner lust/", "tokens": ["Es", "zeigt", "uns", "sein", "be\u00b7trug", "den", "zu\u00b7cker", "rei\u00b7ner", "lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und raubt uns/ als ein feind/ die nahrungs-reichen bissen.", "tokens": ["Und", "raubt", "uns", "/", "als", "ein", "feind", "/", "die", "nah\u00b7rungs\u00b7rei\u00b7chen", "bis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "KOUS", "ART", "NN", "$(", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Der krantz/ den seine hand auff unsre scheitel setzt", "tokens": ["Der", "krantz", "/", "den", "sei\u00b7ne", "hand", "auff", "uns\u00b7re", "schei\u00b7tel", "setzt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Ist mehrentheils mit dorn und disteln unterwunden.", "tokens": ["Ist", "meh\u00b7ren\u00b7theils", "mit", "dorn", "und", "dis\u00b7teln", "un\u00b7ter\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NE", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Sein becher hat uns offt bi\u00df auff den tod verletzt:", "tokens": ["Sein", "be\u00b7cher", "hat", "uns", "offt", "bi\u00df", "auff", "den", "tod", "ver\u00b7letzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Nicht selten hat man hier ein spinnen-gifft gefunden.", "tokens": ["Nicht", "sel\u00b7ten", "hat", "man", "hier", "ein", "spin\u00b7nen\u00b7gifft", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAFIN", "PIS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ich r\u00fchr in meiner noth nicht fremden unfall an/", "tokens": ["Ich", "r\u00fchr", "in", "mei\u00b7ner", "noth", "nicht", "frem\u00b7den", "un\u00b7fall", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKNEG", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Ich kenne das gel\u00fcck und dessen falsche waaren/", "tokens": ["Ich", "ken\u00b7ne", "das", "ge\u00b7l\u00fcck", "und", "des\u00b7sen", "fal\u00b7sche", "waa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "PDS", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und wie sich dessen lust in list verstellen kan.", "tokens": ["Und", "wie", "sich", "des\u00b7sen", "lust", "in", "list", "ver\u00b7stel\u00b7len", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PDS", "VVFIN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Denn was ich hier ber\u00fchrt/ das hab ich auch erfahren:", "tokens": ["Denn", "was", "ich", "hier", "be\u00b7r\u00fchrt", "/", "das", "hab", "ich", "auch", "er\u00b7fah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVPP", "$(", "PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Es stund mein treuer sinn in steiffer zuversicht/", "tokens": ["Es", "stund", "mein", "treu\u00b7er", "sinn", "in", "steif\u00b7fer", "zu\u00b7ver\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "In meinem hause dich/ als freundin/ zu umfangen;", "tokens": ["In", "mei\u00b7nem", "hau\u00b7se", "dich", "/", "als", "freun\u00b7din", "/", "zu", "um\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "$(", "KOUS", "NN", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Ach blumen ohne frucht! Ich armer fand dich nicht/", "tokens": ["Ach", "blu\u00b7men", "oh\u00b7ne", "frucht", "!", "Ich", "ar\u00b7mer", "fand", "dich", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "APPR", "NN", "$.", "PPER", "ADJA", "VVFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Du warst zu meiner noth mir allzubald entgangen/", "tokens": ["Du", "warst", "zu", "mei\u00b7ner", "noth", "mir", "all\u00b7zu\u00b7bald", "ent\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Dein helles auge war vor mich ein donnerstrahl/", "tokens": ["Dein", "hel\u00b7les", "au\u00b7ge", "war", "vor", "mich", "ein", "don\u00b7ner\u00b7strahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "APPR", "PRF", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Als ich/ du weist ja wo/ dich unverhofft erblickte/", "tokens": ["Als", "ich", "/", "du", "weist", "ja", "wo", "/", "dich", "un\u00b7ver\u00b7hofft", "er\u00b7blick\u00b7te", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "PPER", "VVFIN", "ADV", "PWAV", "$(", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Kein pinsel kan allhier bezeichnen meine qvaal/", "tokens": ["Kein", "pin\u00b7sel", "kan", "all\u00b7hier", "be\u00b7zeich\u00b7nen", "mei\u00b7ne", "qvaal", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Die tausend seuffzer dir nach deinen hertzen schickte.", "tokens": ["Die", "tau\u00b7send", "seuff\u00b7zer", "dir", "nach", "dei\u00b7nen", "hert\u00b7zen", "schick\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Mein gr\u00f6\u00dfter kummer war zu bergen meine pein/", "tokens": ["Mein", "gr\u00f6\u00df\u00b7ter", "kum\u00b7mer", "war", "zu", "ber\u00b7gen", "mei\u00b7ne", "pein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PTKZU", "VVINF", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Mein blut stund schon ger\u00fcst/ verr\u00e4therey zu \u00fcben/", "tokens": ["Mein", "blut", "stund", "schon", "ge\u00b7r\u00fcst", "/", "ver\u00b7r\u00e4\u00b7the\u00b7rey", "zu", "\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "VVPP", "$(", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Doch must ich in der noth als ei\u00df gefrohren seyn.", "tokens": ["Doch", "must", "ich", "in", "der", "noth", "als", "ei\u00df", "ge\u00b7froh\u00b7ren", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "NN", "KOUS", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Wie \u00fcbel paart sich doch behutsamkeit und lieben!", "tokens": ["Wie", "\u00fc\u00b7bel", "paart", "sich", "doch", "be\u00b7hut\u00b7sam\u00b7keit", "und", "lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PRF", "ADV", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Wie der verdru\u00df hernach mir meinen tisch gedeckt/", "tokens": ["Wie", "der", "ver\u00b7dru\u00df", "her\u00b7nach", "mir", "mei\u00b7nen", "tisch", "ge\u00b7deckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "PPER", "VVFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Wie nichts als traurigkeit mir oben an gesessen/", "tokens": ["Wie", "nichts", "als", "trau\u00b7rig\u00b7keit", "mir", "o\u00b7ben", "an", "ge\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "KOKOM", "VVFIN", "PPER", "ADV", "APZR", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Wie bitter mir hierauff das mittags-mahl geschmeckt/", "tokens": ["Wie", "bit\u00b7ter", "mir", "hier\u00b7auff", "das", "mit\u00b7tags\u00b7mahl", "ge\u00b7schmeckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PAV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Das kanst du/ liebst du mich/ auch vor dich selbst ermessen.", "tokens": ["Das", "kanst", "du", "/", "liebst", "du", "mich", "/", "auch", "vor", "dich", "selbst", "er\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "$(", "VVFIN", "PPER", "PRF", "$(", "ADV", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Es schlo\u00df der unmuth mir die heisse k\u00e4hle zu;", "tokens": ["Es", "schlo\u00df", "der", "un\u00b7muth", "mir", "die", "heis\u00b7se", "k\u00e4h\u00b7le", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Mich h\u00e4tte der verdru\u00df auch endlich selbst erstecket/", "tokens": ["Mich", "h\u00e4t\u00b7te", "der", "ver\u00b7dru\u00df", "auch", "end\u00b7lich", "selbst", "er\u00b7ste\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Und l\u00e4ge wohl vielleicht itzt in der bleichen ruh/", "tokens": ["Und", "l\u00e4\u00b7ge", "wohl", "viel\u00b7leicht", "itzt", "in", "der", "blei\u00b7chen", "ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Wann nicht mein hoffnungs-stern mich wieder auffgewecket.", "tokens": ["Wann", "nicht", "mein", "hoff\u00b7nungs\u00b7stern", "mich", "wie\u00b7der", "auff\u00b7ge\u00b7we\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "PPOSAT", "NN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Ist eine wehmuth noch vor mich in dieser welt/", "tokens": ["Ist", "ei\u00b7ne", "weh\u00b7muth", "noch", "vor", "mich", "in", "die\u00b7ser", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPR", "PRF", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "So trockne/ Flavia/ mir meine nasse wangen;", "tokens": ["So", "trock\u00b7ne", "/", "Fla\u00b7via", "/", "mir", "mei\u00b7ne", "nas\u00b7se", "wan\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "$(", "NE", "$(", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.63": {"text": "Du weist es/ da\u00df mir doch kein ander tuch gef\u00e4llt/", "tokens": ["Du", "weist", "es", "/", "da\u00df", "mir", "doch", "kein", "an\u00b7der", "tuch", "ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "KOUS", "PPER", "ADV", "PIAT", "ADJD", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Als das ich armer kan aus deiner hand erlangen.", "tokens": ["Als", "das", "ich", "ar\u00b7mer", "kan", "aus", "dei\u00b7ner", "hand", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "ADJA", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Schau meine liebe nicht als wollust-sprossen an/", "tokens": ["Schau", "mei\u00b7ne", "lie\u00b7be", "nicht", "als", "wol\u00b7lust\u00b7spros\u00b7sen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "VVFIN", "PTKNEG", "KOUS", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Die aus dem hertzen nichts als geile bl\u00fcthe treiben/", "tokens": ["Die", "aus", "dem", "hert\u00b7zen", "nichts", "als", "gei\u00b7le", "bl\u00fc\u00b7the", "trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PIS", "KOKOM", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Du weist es/ da\u00df man auch vern\u00fcnfftig lieben kan/", "tokens": ["Du", "weist", "es", "/", "da\u00df", "man", "auch", "ver\u00b7n\u00fcnff\u00b7tig", "lie\u00b7ben", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "KOUS", "PIS", "ADV", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Und lieb und tugend wohl geschwister k\u00f6nnen bleiben.", "tokens": ["Und", "lieb", "und", "tu\u00b7gend", "wohl", "ge\u00b7schwis\u00b7ter", "k\u00f6n\u00b7nen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "NN", "ADV", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Ich schliesse meinen brieff/ doch meine hoffnung nicht/", "tokens": ["Ich", "schlies\u00b7se", "mei\u00b7nen", "brieff", "/", "doch", "mei\u00b7ne", "hoff\u00b7nung", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$(", "ADV", "PPOSAT", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Dich/ liebste Flavia/ in kurtzer zeit zu schauen;", "tokens": ["Dich", "/", "liebs\u00b7te", "Fla\u00b7via", "/", "in", "kurt\u00b7zer", "zeit", "zu", "schau\u00b7en", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "VVFIN", "NE", "$(", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.71": {"text": "Und so der himmel uns nicht allen f\u00fcrsatz bricht/", "tokens": ["Und", "so", "der", "him\u00b7mel", "uns", "nicht", "al\u00b7len", "f\u00fcr\u00b7satz", "bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "PPER", "PTKNEG", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "So wollen wir ein haus von zucker-rosen bauen.", "tokens": ["So", "wol\u00b7len", "wir", "ein", "haus", "von", "zu\u00b7cke\u00b7rro\u00b7sen", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Doch weil du rose bist/ so will ich biene seyn/", "tokens": ["Doch", "weil", "du", "ro\u00b7se", "bist", "/", "so", "will", "ich", "bie\u00b7ne", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJA", "VAFIN", "$(", "ADV", "VMFIN", "PPER", "VVFIN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Die bienen m\u00f6gen sich in bl\u00e4tter ja verstecken;", "tokens": ["Die", "bie\u00b7nen", "m\u00f6\u00b7gen", "sich", "in", "bl\u00e4t\u00b7ter", "ja", "ver\u00b7ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "PRF", "APPR", "ADJA", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Vielleicht f\u00e4llt dir/ wie mir/ noch der gedancken ein/", "tokens": ["Viel\u00b7leicht", "f\u00e4llt", "dir", "/", "wie", "mir", "/", "noch", "der", "ge\u00b7dan\u00b7cken", "ein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWAV", "PPER", "$(", "ADV", "ART", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Da\u00df bienen zwar ein blat ber\u00fchren/ nicht beflecken.", "tokens": ["Da\u00df", "bie\u00b7nen", "zwar", "ein", "blat", "be\u00b7r\u00fch\u00b7ren", "/", "nicht", "be\u00b7fle\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADV", "ART", "NN", "VVINF", "$(", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}