{"textgrid.poem.49690": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Zweikampf", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie wollen mich, Verehrtester, befragen,", "tokens": ["Sie", "wol\u00b7len", "mich", ",", "Ver\u00b7ehr\u00b7tes\u00b7ter", ",", "be\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "$,", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie ich mich eigentlich zum Zweikampf stelle?", "tokens": ["Wie", "ich", "mich", "ei\u00b7gent\u00b7lich", "zum", "Zwei\u00b7kampf", "stel\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Nun ja, ich sag' es rund heraus, ich sch\u00e4tze", "tokens": ["Nun", "ja", ",", "ich", "sag'", "es", "rund", "he\u00b7raus", ",", "ich", "sch\u00e4t\u00b7ze"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "$,", "PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als Mensch von guter Bildung die Duelle.", "tokens": ["Als", "Mensch", "von", "gu\u00b7ter", "Bil\u00b7dung", "die", "Du\u00b7el\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sie murmeln etwas vom Gebote Gottes?", "tokens": ["Sie", "mur\u00b7meln", "et\u00b7was", "vom", "Ge\u00b7bo\u00b7te", "Got\u00b7tes", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und da\u00df geschrieben steht: Du sollst nicht t\u00f6ten?", "tokens": ["Und", "da\u00df", "ge\u00b7schrie\u00b7ben", "steht", ":", "Du", "sollst", "nicht", "t\u00f6\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VVPP", "VVFIN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Hand aufs Herz, mein Bester, ohne Pathos,", "tokens": ["Die", "Hand", "aufs", "Herz", ",", "mein", "Bes\u00b7ter", ",", "oh\u00b7ne", "Pa\u00b7thos", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "PPOSAT", "NN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Macht der Appell an Gott Sie nicht err\u00f6ten?", "tokens": ["Macht", "der", "Ap\u00b7pell", "an", "Gott", "Sie", "nicht", "er\u00b7r\u00f6\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.3": {"line.1": {"text": "Gebote Gottes! Unsre frommen Priester,", "tokens": ["Ge\u00b7bo\u00b7te", "Got\u00b7tes", "!", "Uns\u00b7re", "from\u00b7men", "Pries\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die immer feine Unterschiede machten,", "tokens": ["Die", "im\u00b7mer", "fei\u00b7ne", "Un\u00b7ter\u00b7schie\u00b7de", "mach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie sprechen je nachdem vom Gott des Friedens", "tokens": ["Sie", "spre\u00b7chen", "je", "nach\u00b7dem", "vom", "Gott", "des", "Frie\u00b7dens"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KOUS", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und von dem h\u00f6chsten Lenker blut'ger Schlachten.", "tokens": ["Und", "von", "dem", "h\u00f6chs\u00b7ten", "Len\u00b7ker", "blut'\u00b7ger", "Schlach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Es geht von alters her in Gottes Namen", "tokens": ["Es", "geht", "von", "al\u00b7ters", "her", "in", "Got\u00b7tes", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "ADV", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das herdenweise Morden, Sengen, Schinden.", "tokens": ["Das", "her\u00b7den\u00b7wei\u00b7se", "Mor\u00b7den", ",", "Sen\u00b7gen", ",", "Schin\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Warum nicht, wenn sich zwei das Fell durchl\u00f6chern?", "tokens": ["Wa\u00b7rum", "nicht", ",", "wenn", "sich", "zwei", "das", "Fell", "durch\u00b7l\u00f6\u00b7chern", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "KOUS", "PRF", "CARD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "L\u00e4\u00dft sich daf\u00fcr kein frommes Spr\u00fcchlein finden?", "tokens": ["L\u00e4\u00dft", "sich", "da\u00b7f\u00fcr", "kein", "from\u00b7mes", "Spr\u00fcch\u00b7lein", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "\u00bbdu sollst nur t\u00f6ten, wenn die F\u00fcrsten pfeifen,\u00ab", "tokens": ["\u00bb", "du", "sollst", "nur", "t\u00f6\u00b7ten", ",", "wenn", "die", "F\u00fcrs\u00b7ten", "pfei\u00b7fen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "VVINF", "$,", "KOUS", "ART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Steht so geschrieben in der Christen Lehre?", "tokens": ["Steht", "so", "ge\u00b7schrie\u00b7ben", "in", "der", "Chris\u00b7ten", "Leh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVPP", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und dann, mein Herr, Sie d\u00fcrfen nicht vergessen,", "tokens": ["Und", "dann", ",", "mein", "Herr", ",", "Sie", "d\u00fcr\u00b7fen", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das H\u00f6chste, was der Mensch hat, ist die ", "tokens": ["Das", "H\u00f6chs\u00b7te", ",", "was", "der", "Mensch", "hat", ",", "ist", "die"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "ART", "NN", "VAFIN", "$,", "VAFIN", "ART"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}}, "stanza.6": {"line.1": {"text": "Sie ist es wert, da\u00df wir f\u00fcr sie das Leben", "tokens": ["Sie", "ist", "es", "wert", ",", "da\u00df", "wir", "f\u00fcr", "sie", "das", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Gut und Blut und alles daran setzen.", "tokens": ["Und", "Gut", "und", "Blut", "und", "al\u00b7les", "da\u00b7ran", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "NN", "KON", "PIS", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Worin sie liegt? Das wei\u00df kein Mensch zu sagen,", "tokens": ["Wo\u00b7rin", "sie", "liegt", "?", "Das", "wei\u00df", "kein", "Mensch", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$.", "PDS", "VVFIN", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Man kennt sie erst, wenn andre sie verletzen.", "tokens": ["Man", "kennt", "sie", "erst", ",", "wenn", "and\u00b7re", "sie", "ver\u00b7let\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und wer sie hat? Das l\u00e4\u00dft sich nicht erkl\u00e4ren;", "tokens": ["Und", "wer", "sie", "hat", "?", "Das", "l\u00e4\u00dft", "sich", "nicht", "er\u00b7kl\u00e4\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VAFIN", "$.", "PDS", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nur wer sie ", "tokens": ["Nur", "wer", "sie"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PWS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Die sich und andern t\u00e4glich Brot verdienen", "tokens": ["Die", "sich", "und", "an\u00b7dern", "t\u00e4g\u00b7lich", "Brot", "ver\u00b7die\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "KON", "ADJA", "ADJD", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und von der Arbeit w\u00fcste Schwielen tragen.", "tokens": ["Und", "von", "der", "Ar\u00b7beit", "w\u00fcs\u00b7te", "Schwie\u00b7len", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Sie wollen mich, Verehrtester, befragen,", "tokens": ["Sie", "wol\u00b7len", "mich", ",", "Ver\u00b7ehr\u00b7tes\u00b7ter", ",", "be\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "$,", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie ich mich eigentlich zum Zweikampf stelle?", "tokens": ["Wie", "ich", "mich", "ei\u00b7gent\u00b7lich", "zum", "Zwei\u00b7kampf", "stel\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Nun ja, ich sag' es rund heraus, ich sch\u00e4tze", "tokens": ["Nun", "ja", ",", "ich", "sag'", "es", "rund", "he\u00b7raus", ",", "ich", "sch\u00e4t\u00b7ze"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "$,", "PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als Mensch von guter Bildung die Duelle.", "tokens": ["Als", "Mensch", "von", "gu\u00b7ter", "Bil\u00b7dung", "die", "Du\u00b7el\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Sie murmeln etwas vom Gebote Gottes?", "tokens": ["Sie", "mur\u00b7meln", "et\u00b7was", "vom", "Ge\u00b7bo\u00b7te", "Got\u00b7tes", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und da\u00df geschrieben steht: Du sollst nicht t\u00f6ten?", "tokens": ["Und", "da\u00df", "ge\u00b7schrie\u00b7ben", "steht", ":", "Du", "sollst", "nicht", "t\u00f6\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VVPP", "VVFIN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Hand aufs Herz, mein Bester, ohne Pathos,", "tokens": ["Die", "Hand", "aufs", "Herz", ",", "mein", "Bes\u00b7ter", ",", "oh\u00b7ne", "Pa\u00b7thos", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "PPOSAT", "NN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Macht der Appell an Gott Sie nicht err\u00f6ten?", "tokens": ["Macht", "der", "Ap\u00b7pell", "an", "Gott", "Sie", "nicht", "er\u00b7r\u00f6\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.10": {"line.1": {"text": "Gebote Gottes! Unsre frommen Priester,", "tokens": ["Ge\u00b7bo\u00b7te", "Got\u00b7tes", "!", "Uns\u00b7re", "from\u00b7men", "Pries\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die immer feine Unterschiede machten,", "tokens": ["Die", "im\u00b7mer", "fei\u00b7ne", "Un\u00b7ter\u00b7schie\u00b7de", "mach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie sprechen je nachdem vom Gott des Friedens", "tokens": ["Sie", "spre\u00b7chen", "je", "nach\u00b7dem", "vom", "Gott", "des", "Frie\u00b7dens"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KOUS", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und von dem h\u00f6chsten Lenker blut'ger Schlachten.", "tokens": ["Und", "von", "dem", "h\u00f6chs\u00b7ten", "Len\u00b7ker", "blut'\u00b7ger", "Schlach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Es geht von alters her in Gottes Namen", "tokens": ["Es", "geht", "von", "al\u00b7ters", "her", "in", "Got\u00b7tes", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "ADV", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das herdenweise Morden, Sengen, Schinden.", "tokens": ["Das", "her\u00b7den\u00b7wei\u00b7se", "Mor\u00b7den", ",", "Sen\u00b7gen", ",", "Schin\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Warum nicht, wenn sich zwei das Fell durchl\u00f6chern?", "tokens": ["Wa\u00b7rum", "nicht", ",", "wenn", "sich", "zwei", "das", "Fell", "durch\u00b7l\u00f6\u00b7chern", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "KOUS", "PRF", "CARD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "L\u00e4\u00dft sich daf\u00fcr kein frommes Spr\u00fcchlein finden?", "tokens": ["L\u00e4\u00dft", "sich", "da\u00b7f\u00fcr", "kein", "from\u00b7mes", "Spr\u00fcch\u00b7lein", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "\u00bbdu sollst nur t\u00f6ten, wenn die F\u00fcrsten pfeifen,\u00ab", "tokens": ["\u00bb", "du", "sollst", "nur", "t\u00f6\u00b7ten", ",", "wenn", "die", "F\u00fcrs\u00b7ten", "pfei\u00b7fen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "VVINF", "$,", "KOUS", "ART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Steht so geschrieben in der Christen Lehre?", "tokens": ["Steht", "so", "ge\u00b7schrie\u00b7ben", "in", "der", "Chris\u00b7ten", "Leh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVPP", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und dann, mein Herr, Sie d\u00fcrfen nicht vergessen,", "tokens": ["Und", "dann", ",", "mein", "Herr", ",", "Sie", "d\u00fcr\u00b7fen", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das H\u00f6chste, was der Mensch hat, ist die ", "tokens": ["Das", "H\u00f6chs\u00b7te", ",", "was", "der", "Mensch", "hat", ",", "ist", "die"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "ART", "NN", "VAFIN", "$,", "VAFIN", "ART"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}}, "stanza.13": {"line.1": {"text": "Sie ist es wert, da\u00df wir f\u00fcr sie das Leben", "tokens": ["Sie", "ist", "es", "wert", ",", "da\u00df", "wir", "f\u00fcr", "sie", "das", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Gut und Blut und alles daran setzen.", "tokens": ["Und", "Gut", "und", "Blut", "und", "al\u00b7les", "da\u00b7ran", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "NN", "KON", "PIS", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Worin sie liegt? Das wei\u00df kein Mensch zu sagen,", "tokens": ["Wo\u00b7rin", "sie", "liegt", "?", "Das", "wei\u00df", "kein", "Mensch", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$.", "PDS", "VVFIN", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Man kennt sie erst, wenn andre sie verletzen.", "tokens": ["Man", "kennt", "sie", "erst", ",", "wenn", "and\u00b7re", "sie", "ver\u00b7let\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und wer sie hat? Das l\u00e4\u00dft sich nicht erkl\u00e4ren;", "tokens": ["Und", "wer", "sie", "hat", "?", "Das", "l\u00e4\u00dft", "sich", "nicht", "er\u00b7kl\u00e4\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VAFIN", "$.", "PDS", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nur wer sie ", "tokens": ["Nur", "wer", "sie"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PWS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Die sich und andern t\u00e4glich Brot verdienen", "tokens": ["Die", "sich", "und", "an\u00b7dern", "t\u00e4g\u00b7lich", "Brot", "ver\u00b7die\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "KON", "ADJA", "ADJD", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und von der Arbeit w\u00fcste Schwielen tragen.", "tokens": ["Und", "von", "der", "Ar\u00b7beit", "w\u00fcs\u00b7te", "Schwie\u00b7len", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}