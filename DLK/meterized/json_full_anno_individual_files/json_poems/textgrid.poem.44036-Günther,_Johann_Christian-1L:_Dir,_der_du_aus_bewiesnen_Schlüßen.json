{"textgrid.poem.44036": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dir, der du aus bewiesnen Schl\u00fc\u00dfen", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dir, der du aus bewiesnen Schl\u00fc\u00dfen", "tokens": ["Dir", ",", "der", "du", "aus", "be\u00b7wi\u00b7es\u00b7nen", "Schl\u00fc\u00b7\u00dfen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Recht, Ordnung und Natur verstehst", "tokens": ["Recht", ",", "Ord\u00b7nung", "und", "Na\u00b7tur", "ver\u00b7stehst"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mit Vernunft dem Joch entgehst,", "tokens": ["Und", "mit", "Ver\u00b7nunft", "dem", "Joch", "ent\u00b7gehst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Neid und P\u00f6bel tragen m\u00fc\u00dfen,", "tokens": ["Das", "Neid", "und", "P\u00f6\u00b7bel", "tra\u00b7gen", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dir, edler Freund, vertraut mein Kiel", "tokens": ["Dir", ",", "ed\u00b7ler", "Freund", ",", "ver\u00b7traut", "mein", "Kiel"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ADJA", "NN", "$,", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Gl\u00fcckes langes Trauerspiel,", "tokens": ["Des", "Gl\u00fc\u00b7ckes", "lan\u00b7ges", "Trau\u00b7er\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wodurch ich \u00c4rmster auf der Erde", "tokens": ["Wo\u00b7durch", "ich", "\u00c4rms\u00b7ter", "auf", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "(die Thr\u00e4nen brechen Reim und Wort", "tokens": ["(", "die", "Thr\u00e4\u00b7nen", "bre\u00b7chen", "Reim", "und", "Wort"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und schie\u00dfen mit der Hofnung fort)", "tokens": ["Und", "schie\u00b7\u00dfen", "mit", "der", "Hof\u00b7nung", "fort", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Leuten zum Gel\u00e4chter werde.", "tokens": ["Den", "Leu\u00b7ten", "zum", "Ge\u00b7l\u00e4ch\u00b7ter", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das Leben ist der Rest der G\u00fcter,", "tokens": ["Das", "Le\u00b7ben", "ist", "der", "Rest", "der", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wovon mich Ha\u00df und Glut entbl\u00f6\u00dft;", "tokens": ["Wo\u00b7von", "mich", "Ha\u00df", "und", "Glut", "ent\u00b7bl\u00f6\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Vaters Eigensinn verst\u00f6\u00dft", "tokens": ["Des", "Va\u00b7ters", "Ei\u00b7gen\u00b7sinn", "ver\u00b7st\u00f6\u00dft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Reizung giftiger Gem\u00fcther.", "tokens": ["Auf", "Rei\u00b7zung", "gif\u00b7ti\u00b7ger", "Ge\u00b7m\u00fc\u00b7ther", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier ist kein Weg zur alten Treu;", "tokens": ["Hier", "ist", "kein", "Weg", "zur", "al\u00b7ten", "Treu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Be\u00dfrung h\u00e4lt er Heucheley,", "tokens": ["Die", "Be\u00df\u00b7rung", "h\u00e4lt", "er", "Heu\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Weib, Pfafen, Neid und Aberglauben", "tokens": ["Weib", ",", "Pfa\u00b7fen", ",", "Neid", "und", "A\u00b7berg\u00b7lau\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Befl\u00fcgeln seines Eifers Lauf", "tokens": ["Be\u00b7fl\u00fc\u00b7geln", "sei\u00b7nes", "Ei\u00b7fers", "Lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und w\u00fchlen meine Lieder auf,", "tokens": ["Und", "w\u00fch\u00b7len", "mei\u00b7ne", "Lie\u00b7der", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Aus Vorwiz, Gift herauszuklauben.", "tokens": ["Aus", "Vor\u00b7wiz", ",", "Gift", "her\u00b7aus\u00b7zu\u00b7klau\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So bin ich auf den Bo\u00dfheitsb\u00fchnen", "tokens": ["So", "bin", "ich", "auf", "den", "Bo\u00df\u00b7heits\u00b7b\u00fch\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geschleppt, gerichtet und verdammt.", "tokens": ["Ge\u00b7schleppt", ",", "ge\u00b7rich\u00b7tet", "und", "ver\u00b7dammt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "L\u00e4st Gott sein hohes Richteramt", "tokens": ["L\u00e4st", "Gott", "sein", "ho\u00b7hes", "Rich\u00b7ter\u00b7amt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Thoren zum Gesp\u00f6tte dienen?", "tokens": ["Den", "Tho\u00b7ren", "zum", "Ge\u00b7sp\u00f6t\u00b7te", "die\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So mancher, dem ich in Gefahr,", "tokens": ["So", "man\u00b7cher", ",", "dem", "ich", "in", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "PRELS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Himmel kennt ihn, dienlich war,", "tokens": ["Der", "Him\u00b7mel", "kennt", "ihn", ",", "dien\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bezahlt mir Treu und Flei\u00df mit Lachen.", "tokens": ["Be\u00b7zahlt", "mir", "Treu", "und", "Flei\u00df", "mit", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dies f\u00e4hrt und fri\u00dft wie Salz ins Marck", "tokens": ["Dies", "f\u00e4hrt", "und", "fri\u00dft", "wie", "Salz", "ins", "Marck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "KOKOM", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und zieht die Sehnen noch so starck,", "tokens": ["Und", "zieht", "die", "Seh\u00b7nen", "noch", "so", "starck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als m\u00fcst ich auf der Folter wachen.", "tokens": ["Als", "m\u00fcst", "ich", "auf", "der", "Fol\u00b7ter", "wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "In Juvenals gewi\u00dfem Dichten", "tokens": ["In", "Ju\u00b7ve\u00b7nals", "ge\u00b7wi\u00b7\u00dfem", "Dich\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stehn Leute, derer Lastergeist", "tokens": ["Stehn", "Leu\u00b7te", ",", "de\u00b7rer", "Las\u00b7ter\u00b7geist"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$,", "PDS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich mit Gewalt zur S\u00fcnde rei\u00dft,", "tokens": ["Sich", "mit", "Ge\u00b7walt", "zur", "S\u00fcn\u00b7de", "rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Nechsten, Gott und alles richten:", "tokens": ["Die", "Nechs\u00b7ten", ",", "Gott", "und", "al\u00b7les", "rich\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die, so des keuschen Ehstands Frucht", "tokens": ["Die", ",", "so", "des", "keu\u00b7schen", "Eh\u00b7stands", "Frucht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "ADV", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit B\u00e4dern zu verhalten sucht,", "tokens": ["Mit", "B\u00e4\u00b7dern", "zu", "ver\u00b7hal\u00b7ten", "sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der, welcher Wais- und Wittwen dr\u00e4nget,", "tokens": ["Der", ",", "wel\u00b7cher", "Wais", "und", "Witt\u00b7wen", "dr\u00e4n\u00b7get", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAT", "TRUNC", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der, so vom Opfergelde spielt,", "tokens": ["Der", ",", "so", "vom", "Op\u00b7fer\u00b7gel\u00b7de", "spielt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein andrer, der sein Amt bestiehlt", "tokens": ["Ein", "an\u00b7drer", ",", "der", "sein", "Amt", "be\u00b7stiehlt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und H\u00fcttenrauch in Perlen menget.", "tokens": ["Und", "H\u00fct\u00b7ten\u00b7rauch", "in", "Per\u00b7len", "men\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die fluchen noch mit fr\u00f6mmsten Scheine", "tokens": ["Die", "flu\u00b7chen", "noch", "mit", "fr\u00f6mms\u00b7ten", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Jugend, die sich leicht vergeht;", "tokens": ["Der", "Ju\u00b7gend", ",", "die", "sich", "leicht", "ver\u00b7geht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn irgendwo ein Gl\u00fcck entsteht,", "tokens": ["Wenn", "ir\u00b7gend\u00b7wo", "ein", "Gl\u00fcck", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wirft ihr Zorn den Weg voll Steine.", "tokens": ["So", "wirft", "ihr", "Zorn", "den", "Weg", "voll", "Stei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich weis, ich fehl in mancher That;", "tokens": ["Ich", "weis", ",", "ich", "fehl", "in", "man\u00b7cher", "That", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch k\u00f6nten H\u00fclfe, Zeit und Rath", "tokens": ["Doch", "k\u00f6n\u00b7ten", "H\u00fcl\u00b7fe", ",", "Zeit", "und", "Rath"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VMFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Freund und Alter alles z\u00e4hmen.", "tokens": ["Und", "Freund", "und", "Al\u00b7ter", "al\u00b7les", "z\u00e4h\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mein Herz, das gern von andern schweigt,", "tokens": ["Mein", "Herz", ",", "das", "gern", "von", "an\u00b7dern", "schweigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ist ja so ehrlich als geneigt,", "tokens": ["Ist", "ja", "so", "ehr\u00b7lich", "als", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vernunft und Warnung anzunehmen.", "tokens": ["Ver\u00b7nunft", "und", "War\u00b7nung", "an\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich weis nicht, ob ich mein Geschicke", "tokens": ["Ich", "weis", "nicht", ",", "ob", "ich", "mein", "Ge\u00b7schi\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mehr schelten als bewundern kan.", "tokens": ["Mehr", "schel\u00b7ten", "als", "be\u00b7wun\u00b7dern", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "KOKOM", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich seh es hier- und dortnaus an,", "tokens": ["Ich", "seh", "es", "hier", "und", "dort\u00b7naus", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "TRUNC", "KON", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So seh ich gleich- und saure Blicke;", "tokens": ["So", "seh", "ich", "gleich", "und", "sau\u00b7re", "Bli\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich komm in allen Scenen blind.", "tokens": ["Ich", "komm", "in", "al\u00b7len", "Sce\u00b7nen", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So klug mein Ernst und Anschlag sind,", "tokens": ["So", "klug", "mein", "Ernst", "und", "An\u00b7schlag", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wenig bringt die Hofnung Fr\u00fcchte.", "tokens": ["So", "we\u00b7nig", "bringt", "die", "Hof\u00b7nung", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Tr\u00e4f alles noch so k\u00fcnstlich ein,", "tokens": ["Tr\u00e4f", "al\u00b7les", "noch", "so", "k\u00fcnst\u00b7lich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADV", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wird leztlich stets ein Umstand seyn,", "tokens": ["Wird", "lezt\u00b7lich", "stets", "ein", "Um\u00b7stand", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der schlechterdings die M\u00fch vernichte.", "tokens": ["Der", "schlech\u00b7ter\u00b7dings", "die", "M\u00fch", "ver\u00b7nich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Erschien ein Engel auf der Erden", "tokens": ["Er\u00b7schien", "ein", "En\u00b7gel", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und schw\u00fcr er mir sein Mitleid zu,", "tokens": ["Und", "schw\u00fcr", "er", "mir", "sein", "Mit\u00b7leid", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Schickung lies ihm keine Ruh,", "tokens": ["Die", "Schi\u00b7ckung", "lies", "ihm", "kei\u00b7ne", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er m\u00fcst an mir zum Satan werden.", "tokens": ["Er", "m\u00fcst", "an", "mir", "zum", "Sa\u00b7tan", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dies meinte Scarron so wie ich.", "tokens": ["Dies", "mein\u00b7te", "Scar\u00b7ron", "so", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "ADV", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr G\u00f6nner, last und meidet mich,", "tokens": ["Ihr", "G\u00f6n\u00b7ner", ",", "last", "und", "mei\u00b7det", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo nicht, so seyd ihr schon verloren;", "tokens": ["Wo", "nicht", ",", "so", "seyd", "ihr", "schon", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Denn was nur mir erst Gunst verspricht,", "tokens": ["Denn", "was", "nur", "mir", "erst", "Gunst", "ver\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PPER", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "(wie viel Exempel hab ich nicht!)", "tokens": ["(", "wie", "viel", "Ex\u00b7em\u00b7pel", "hab", "ich", "nicht", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOKOM", "PIAT", "NN", "VAFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das ist gewis zum Fall erkohren.", "tokens": ["Das", "ist", "ge\u00b7wis", "zum", "Fall", "er\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Man spricht, ich sey zu blind gewandelt.", "tokens": ["Man", "spricht", ",", "ich", "sey", "zu", "blind", "ge\u00b7wan\u00b7delt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VAFIN", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer zeigt mir nun die rechte Spur?", "tokens": ["Wer", "zeigt", "mir", "nun", "die", "rech\u00b7te", "Spur", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bin ich allein die Creatur,", "tokens": ["Bin", "ich", "al\u00b7lein", "die", "Crea\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die sich zur Strafe th\u00f6richt handelt?", "tokens": ["Die", "sich", "zur", "Stra\u00b7fe", "th\u00f6\u00b7richt", "han\u00b7delt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich liege furcht- und grillenvoll", "tokens": ["Ich", "lie\u00b7ge", "furcht", "und", "gril\u00b7len\u00b7voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "TRUNC", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und weis nicht, was ich glauben soll.", "tokens": ["Und", "weis", "nicht", ",", "was", "ich", "glau\u00b7ben", "soll", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "PTKNEG", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Sch\u00f6pfer, leb ich dir zur Schande,", "tokens": ["Mein", "Sch\u00f6p\u00b7fer", ",", "leb", "ich", "dir", "zur", "Schan\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dein Keil ist ja noch wohl so hei\u00df,", "tokens": ["Dein", "Keil", "ist", "ja", "noch", "wohl", "so", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was giebstu mich den Feinden preis,", "tokens": ["Was", "giebs\u00b7tu", "mich", "den", "Fein\u00b7den", "preis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und warum irr ich in dem Lande?", "tokens": ["Und", "wa\u00b7rum", "irr", "ich", "in", "dem", "Lan\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Du schl\u00e4gst mich unter fremden Leuten", "tokens": ["Du", "schl\u00e4gst", "mich", "un\u00b7ter", "frem\u00b7den", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bey allgemeiner Armuth lahm,", "tokens": ["Bey", "all\u00b7ge\u00b7mei\u00b7ner", "Ar\u00b7muth", "lahm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als w\u00fcrde mir nicht so der Gram", "tokens": ["Als", "w\u00fcr\u00b7de", "mir", "nicht", "so", "der", "Gram"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Ein schnelles Grabmahl zubereiten.", "tokens": ["Ein", "schnel\u00b7les", "Grab\u00b7mahl", "zu\u00b7be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, aber bin ich nicht ein Thor,", "tokens": ["Ach", ",", "a\u00b7ber", "bin", "ich", "nicht", "ein", "Thor", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was kan des H\u00f6chsten Arm davor?", "tokens": ["Was", "kan", "des", "H\u00f6chs\u00b7ten", "Arm", "da\u00b7vor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Wesen giebt die Folgerungen.", "tokens": ["Mein", "We\u00b7sen", "giebt", "die", "Fol\u00b7ge\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Verzeih, mein Freund, der Ungedult;", "tokens": ["Ver\u00b7zeih", ",", "mein", "Freund", ",", "der", "Un\u00b7ge\u00b7dult", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du siehst, sie ist nicht meine Schuld,", "tokens": ["Du", "siehst", ",", "sie", "ist", "nicht", "mei\u00b7ne", "Schuld", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Doch hab ich Trost, woher? gezwungen.", "tokens": ["Doch", "hab", "ich", "Trost", ",", "wo\u00b7her", "?", "ge\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NN", "$,", "PWAV", "$.", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Dir, der du aus bewiesnen Schl\u00fc\u00dfen", "tokens": ["Dir", ",", "der", "du", "aus", "be\u00b7wi\u00b7es\u00b7nen", "Schl\u00fc\u00b7\u00dfen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Recht, Ordnung und Natur verstehst", "tokens": ["Recht", ",", "Ord\u00b7nung", "und", "Na\u00b7tur", "ver\u00b7stehst"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mit Vernunft dem Joch entgehst,", "tokens": ["Und", "mit", "Ver\u00b7nunft", "dem", "Joch", "ent\u00b7gehst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Neid und P\u00f6bel tragen m\u00fc\u00dfen,", "tokens": ["Das", "Neid", "und", "P\u00f6\u00b7bel", "tra\u00b7gen", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dir, edler Freund, vertraut mein Kiel", "tokens": ["Dir", ",", "ed\u00b7ler", "Freund", ",", "ver\u00b7traut", "mein", "Kiel"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ADJA", "NN", "$,", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Gl\u00fcckes langes Trauerspiel,", "tokens": ["Des", "Gl\u00fc\u00b7ckes", "lan\u00b7ges", "Trau\u00b7er\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wodurch ich \u00c4rmster auf der Erde", "tokens": ["Wo\u00b7durch", "ich", "\u00c4rms\u00b7ter", "auf", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "(die Thr\u00e4nen brechen Reim und Wort", "tokens": ["(", "die", "Thr\u00e4\u00b7nen", "bre\u00b7chen", "Reim", "und", "Wort"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und schie\u00dfen mit der Hofnung fort)", "tokens": ["Und", "schie\u00b7\u00dfen", "mit", "der", "Hof\u00b7nung", "fort", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Leuten zum Gel\u00e4chter werde.", "tokens": ["Den", "Leu\u00b7ten", "zum", "Ge\u00b7l\u00e4ch\u00b7ter", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Das Leben ist der Rest der G\u00fcter,", "tokens": ["Das", "Le\u00b7ben", "ist", "der", "Rest", "der", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wovon mich Ha\u00df und Glut entbl\u00f6\u00dft;", "tokens": ["Wo\u00b7von", "mich", "Ha\u00df", "und", "Glut", "ent\u00b7bl\u00f6\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Vaters Eigensinn verst\u00f6\u00dft", "tokens": ["Des", "Va\u00b7ters", "Ei\u00b7gen\u00b7sinn", "ver\u00b7st\u00f6\u00dft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Reizung giftiger Gem\u00fcther.", "tokens": ["Auf", "Rei\u00b7zung", "gif\u00b7ti\u00b7ger", "Ge\u00b7m\u00fc\u00b7ther", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier ist kein Weg zur alten Treu;", "tokens": ["Hier", "ist", "kein", "Weg", "zur", "al\u00b7ten", "Treu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Be\u00dfrung h\u00e4lt er Heucheley,", "tokens": ["Die", "Be\u00df\u00b7rung", "h\u00e4lt", "er", "Heu\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Weib, Pfafen, Neid und Aberglauben", "tokens": ["Weib", ",", "Pfa\u00b7fen", ",", "Neid", "und", "A\u00b7berg\u00b7lau\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Befl\u00fcgeln seines Eifers Lauf", "tokens": ["Be\u00b7fl\u00fc\u00b7geln", "sei\u00b7nes", "Ei\u00b7fers", "Lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und w\u00fchlen meine Lieder auf,", "tokens": ["Und", "w\u00fch\u00b7len", "mei\u00b7ne", "Lie\u00b7der", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Aus Vorwiz, Gift herauszuklauben.", "tokens": ["Aus", "Vor\u00b7wiz", ",", "Gift", "her\u00b7aus\u00b7zu\u00b7klau\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "So bin ich auf den Bo\u00dfheitsb\u00fchnen", "tokens": ["So", "bin", "ich", "auf", "den", "Bo\u00df\u00b7heits\u00b7b\u00fch\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geschleppt, gerichtet und verdammt.", "tokens": ["Ge\u00b7schleppt", ",", "ge\u00b7rich\u00b7tet", "und", "ver\u00b7dammt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "L\u00e4st Gott sein hohes Richteramt", "tokens": ["L\u00e4st", "Gott", "sein", "ho\u00b7hes", "Rich\u00b7ter\u00b7amt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Thoren zum Gesp\u00f6tte dienen?", "tokens": ["Den", "Tho\u00b7ren", "zum", "Ge\u00b7sp\u00f6t\u00b7te", "die\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So mancher, dem ich in Gefahr,", "tokens": ["So", "man\u00b7cher", ",", "dem", "ich", "in", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "PRELS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Himmel kennt ihn, dienlich war,", "tokens": ["Der", "Him\u00b7mel", "kennt", "ihn", ",", "dien\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bezahlt mir Treu und Flei\u00df mit Lachen.", "tokens": ["Be\u00b7zahlt", "mir", "Treu", "und", "Flei\u00df", "mit", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dies f\u00e4hrt und fri\u00dft wie Salz ins Marck", "tokens": ["Dies", "f\u00e4hrt", "und", "fri\u00dft", "wie", "Salz", "ins", "Marck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "KOKOM", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und zieht die Sehnen noch so starck,", "tokens": ["Und", "zieht", "die", "Seh\u00b7nen", "noch", "so", "starck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als m\u00fcst ich auf der Folter wachen.", "tokens": ["Als", "m\u00fcst", "ich", "auf", "der", "Fol\u00b7ter", "wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "In Juvenals gewi\u00dfem Dichten", "tokens": ["In", "Ju\u00b7ve\u00b7nals", "ge\u00b7wi\u00b7\u00dfem", "Dich\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stehn Leute, derer Lastergeist", "tokens": ["Stehn", "Leu\u00b7te", ",", "de\u00b7rer", "Las\u00b7ter\u00b7geist"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$,", "PDS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich mit Gewalt zur S\u00fcnde rei\u00dft,", "tokens": ["Sich", "mit", "Ge\u00b7walt", "zur", "S\u00fcn\u00b7de", "rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Nechsten, Gott und alles richten:", "tokens": ["Die", "Nechs\u00b7ten", ",", "Gott", "und", "al\u00b7les", "rich\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die, so des keuschen Ehstands Frucht", "tokens": ["Die", ",", "so", "des", "keu\u00b7schen", "Eh\u00b7stands", "Frucht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "ADV", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit B\u00e4dern zu verhalten sucht,", "tokens": ["Mit", "B\u00e4\u00b7dern", "zu", "ver\u00b7hal\u00b7ten", "sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der, welcher Wais- und Wittwen dr\u00e4nget,", "tokens": ["Der", ",", "wel\u00b7cher", "Wais", "und", "Witt\u00b7wen", "dr\u00e4n\u00b7get", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAT", "TRUNC", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der, so vom Opfergelde spielt,", "tokens": ["Der", ",", "so", "vom", "Op\u00b7fer\u00b7gel\u00b7de", "spielt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein andrer, der sein Amt bestiehlt", "tokens": ["Ein", "an\u00b7drer", ",", "der", "sein", "Amt", "be\u00b7stiehlt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und H\u00fcttenrauch in Perlen menget.", "tokens": ["Und", "H\u00fct\u00b7ten\u00b7rauch", "in", "Per\u00b7len", "men\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Die fluchen noch mit fr\u00f6mmsten Scheine", "tokens": ["Die", "flu\u00b7chen", "noch", "mit", "fr\u00f6mms\u00b7ten", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Jugend, die sich leicht vergeht;", "tokens": ["Der", "Ju\u00b7gend", ",", "die", "sich", "leicht", "ver\u00b7geht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn irgendwo ein Gl\u00fcck entsteht,", "tokens": ["Wenn", "ir\u00b7gend\u00b7wo", "ein", "Gl\u00fcck", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wirft ihr Zorn den Weg voll Steine.", "tokens": ["So", "wirft", "ihr", "Zorn", "den", "Weg", "voll", "Stei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich weis, ich fehl in mancher That;", "tokens": ["Ich", "weis", ",", "ich", "fehl", "in", "man\u00b7cher", "That", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch k\u00f6nten H\u00fclfe, Zeit und Rath", "tokens": ["Doch", "k\u00f6n\u00b7ten", "H\u00fcl\u00b7fe", ",", "Zeit", "und", "Rath"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VMFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Freund und Alter alles z\u00e4hmen.", "tokens": ["Und", "Freund", "und", "Al\u00b7ter", "al\u00b7les", "z\u00e4h\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mein Herz, das gern von andern schweigt,", "tokens": ["Mein", "Herz", ",", "das", "gern", "von", "an\u00b7dern", "schweigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ist ja so ehrlich als geneigt,", "tokens": ["Ist", "ja", "so", "ehr\u00b7lich", "als", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vernunft und Warnung anzunehmen.", "tokens": ["Ver\u00b7nunft", "und", "War\u00b7nung", "an\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich weis nicht, ob ich mein Geschicke", "tokens": ["Ich", "weis", "nicht", ",", "ob", "ich", "mein", "Ge\u00b7schi\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mehr schelten als bewundern kan.", "tokens": ["Mehr", "schel\u00b7ten", "als", "be\u00b7wun\u00b7dern", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "KOKOM", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich seh es hier- und dortnaus an,", "tokens": ["Ich", "seh", "es", "hier", "und", "dort\u00b7naus", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "TRUNC", "KON", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So seh ich gleich- und saure Blicke;", "tokens": ["So", "seh", "ich", "gleich", "und", "sau\u00b7re", "Bli\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich komm in allen Scenen blind.", "tokens": ["Ich", "komm", "in", "al\u00b7len", "Sce\u00b7nen", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So klug mein Ernst und Anschlag sind,", "tokens": ["So", "klug", "mein", "Ernst", "und", "An\u00b7schlag", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wenig bringt die Hofnung Fr\u00fcchte.", "tokens": ["So", "we\u00b7nig", "bringt", "die", "Hof\u00b7nung", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Tr\u00e4f alles noch so k\u00fcnstlich ein,", "tokens": ["Tr\u00e4f", "al\u00b7les", "noch", "so", "k\u00fcnst\u00b7lich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADV", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wird leztlich stets ein Umstand seyn,", "tokens": ["Wird", "lezt\u00b7lich", "stets", "ein", "Um\u00b7stand", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der schlechterdings die M\u00fch vernichte.", "tokens": ["Der", "schlech\u00b7ter\u00b7dings", "die", "M\u00fch", "ver\u00b7nich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Erschien ein Engel auf der Erden", "tokens": ["Er\u00b7schien", "ein", "En\u00b7gel", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und schw\u00fcr er mir sein Mitleid zu,", "tokens": ["Und", "schw\u00fcr", "er", "mir", "sein", "Mit\u00b7leid", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Schickung lies ihm keine Ruh,", "tokens": ["Die", "Schi\u00b7ckung", "lies", "ihm", "kei\u00b7ne", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er m\u00fcst an mir zum Satan werden.", "tokens": ["Er", "m\u00fcst", "an", "mir", "zum", "Sa\u00b7tan", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dies meinte Scarron so wie ich.", "tokens": ["Dies", "mein\u00b7te", "Scar\u00b7ron", "so", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "ADV", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr G\u00f6nner, last und meidet mich,", "tokens": ["Ihr", "G\u00f6n\u00b7ner", ",", "last", "und", "mei\u00b7det", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo nicht, so seyd ihr schon verloren;", "tokens": ["Wo", "nicht", ",", "so", "seyd", "ihr", "schon", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Denn was nur mir erst Gunst verspricht,", "tokens": ["Denn", "was", "nur", "mir", "erst", "Gunst", "ver\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PPER", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "(wie viel Exempel hab ich nicht!)", "tokens": ["(", "wie", "viel", "Ex\u00b7em\u00b7pel", "hab", "ich", "nicht", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOKOM", "PIAT", "NN", "VAFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das ist gewis zum Fall erkohren.", "tokens": ["Das", "ist", "ge\u00b7wis", "zum", "Fall", "er\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Man spricht, ich sey zu blind gewandelt.", "tokens": ["Man", "spricht", ",", "ich", "sey", "zu", "blind", "ge\u00b7wan\u00b7delt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VAFIN", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer zeigt mir nun die rechte Spur?", "tokens": ["Wer", "zeigt", "mir", "nun", "die", "rech\u00b7te", "Spur", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bin ich allein die Creatur,", "tokens": ["Bin", "ich", "al\u00b7lein", "die", "Crea\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die sich zur Strafe th\u00f6richt handelt?", "tokens": ["Die", "sich", "zur", "Stra\u00b7fe", "th\u00f6\u00b7richt", "han\u00b7delt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPRART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich liege furcht- und grillenvoll", "tokens": ["Ich", "lie\u00b7ge", "furcht", "und", "gril\u00b7len\u00b7voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "TRUNC", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und weis nicht, was ich glauben soll.", "tokens": ["Und", "weis", "nicht", ",", "was", "ich", "glau\u00b7ben", "soll", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "PTKNEG", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Sch\u00f6pfer, leb ich dir zur Schande,", "tokens": ["Mein", "Sch\u00f6p\u00b7fer", ",", "leb", "ich", "dir", "zur", "Schan\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dein Keil ist ja noch wohl so hei\u00df,", "tokens": ["Dein", "Keil", "ist", "ja", "noch", "wohl", "so", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was giebstu mich den Feinden preis,", "tokens": ["Was", "giebs\u00b7tu", "mich", "den", "Fein\u00b7den", "preis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und warum irr ich in dem Lande?", "tokens": ["Und", "wa\u00b7rum", "irr", "ich", "in", "dem", "Lan\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Du schl\u00e4gst mich unter fremden Leuten", "tokens": ["Du", "schl\u00e4gst", "mich", "un\u00b7ter", "frem\u00b7den", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bey allgemeiner Armuth lahm,", "tokens": ["Bey", "all\u00b7ge\u00b7mei\u00b7ner", "Ar\u00b7muth", "lahm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als w\u00fcrde mir nicht so der Gram", "tokens": ["Als", "w\u00fcr\u00b7de", "mir", "nicht", "so", "der", "Gram"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Ein schnelles Grabmahl zubereiten.", "tokens": ["Ein", "schnel\u00b7les", "Grab\u00b7mahl", "zu\u00b7be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, aber bin ich nicht ein Thor,", "tokens": ["Ach", ",", "a\u00b7ber", "bin", "ich", "nicht", "ein", "Thor", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was kan des H\u00f6chsten Arm davor?", "tokens": ["Was", "kan", "des", "H\u00f6chs\u00b7ten", "Arm", "da\u00b7vor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Wesen giebt die Folgerungen.", "tokens": ["Mein", "We\u00b7sen", "giebt", "die", "Fol\u00b7ge\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Verzeih, mein Freund, der Ungedult;", "tokens": ["Ver\u00b7zeih", ",", "mein", "Freund", ",", "der", "Un\u00b7ge\u00b7dult", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du siehst, sie ist nicht meine Schuld,", "tokens": ["Du", "siehst", ",", "sie", "ist", "nicht", "mei\u00b7ne", "Schuld", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Doch hab ich Trost, woher? gezwungen.", "tokens": ["Doch", "hab", "ich", "Trost", ",", "wo\u00b7her", "?", "ge\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NN", "$,", "PWAV", "$.", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}