{"textgrid.poem.32404": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "82. Das M\u00e4dchen", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zum M\u00e4dchen w\u00fcnscht' ich mir \u2013 und wollt' es, ha! recht lieben \u2013", "tokens": ["Zum", "M\u00e4d\u00b7chen", "w\u00fcnscht'", "ich", "mir", "\u2013", "und", "wollt'", "es", ",", "ha", "!", "recht", "lie\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PPER", "$(", "KON", "VMFIN", "PPER", "$,", "ITJ", "$.", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein junges, nettes, tolles Ding,", "tokens": ["Ein", "jun\u00b7ges", ",", "net\u00b7tes", ",", "tol\u00b7les", "Ding", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Leicht zu erfreun, schwer zu betr\u00fcben,", "tokens": ["Leicht", "zu", "er\u00b7freun", ",", "schwer", "zu", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Am Wuchse schlank, im Gange flink,", "tokens": ["Am", "Wuch\u00b7se", "schlank", ",", "im", "Gan\u00b7ge", "flink", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Aug' ein Falk,", "tokens": ["Von", "Aug'", "ein", "Falk", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Von Mien' ein Schalk;", "tokens": ["Von", "Mien'", "ein", "Schalk", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Das flei\u00dfig, flei\u00dfig liest:", "tokens": ["Das", "flei\u00b7\u00dfig", ",", "flei\u00b7\u00dfig", "liest", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADJD", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Weil alles, was es liest,", "tokens": ["Weil", "al\u00b7les", ",", "was", "es", "liest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Sein einzig Buch \u2013 der Spiegel ist;", "tokens": ["Sein", "ein\u00b7zig", "Buch", "\u2013", "der", "Spie\u00b7gel", "ist", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$(", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das immer gaukelt, immer spricht,", "tokens": ["Das", "im\u00b7mer", "gau\u00b7kelt", ",", "im\u00b7mer", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und spricht und spricht von tausend Sachen,", "tokens": ["Und", "spricht", "und", "spricht", "von", "tau\u00b7send", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Versteht es gleich das Zehnte nicht", "tokens": ["Ver\u00b7steht", "es", "gleich", "das", "Zehn\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Von allen diesen tausend Sachen:", "tokens": ["Von", "al\u00b7len", "die\u00b7sen", "tau\u00b7send", "Sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDAT", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Genug, es spricht mit Lachen,", "tokens": ["Ge\u00b7nug", ",", "es", "spricht", "mit", "La\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Und kann sehr reizend lachen.", "tokens": ["Und", "kann", "sehr", "rei\u00b7zend", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Solch M\u00e4dchen w\u00fcnscht' ich mir! \u2013 Du, Freund, magst deine Zeit", "tokens": ["Solch", "M\u00e4d\u00b7chen", "w\u00fcnscht'", "ich", "mir", "!", "\u2013", "Du", ",", "Freund", ",", "magst", "dei\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PPER", "$.", "$(", "PPER", "$,", "NN", "$,", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur immerhin bei sch\u00f6ner Sittsamkeit,", "tokens": ["Nur", "im\u00b7mer\u00b7hin", "bei", "sch\u00f6\u00b7ner", "Sitt\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nicht ohne seraphin'sche Tr\u00e4nen,", "tokens": ["Nicht", "oh\u00b7ne", "se\u00b7ra\u00b7phin'\u00b7sche", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bei Tugend und Verstand verg\u00e4hnen.", "tokens": ["Bei", "Tu\u00b7gend", "und", "Ver\u00b7stand", "ver\u00b7g\u00e4h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Solch einen Engel", "tokens": ["Solch", "ei\u00b7nen", "En\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["PIS", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Ohn' alle M\u00e4ngel", "tokens": ["Ohn'", "al\u00b7le", "M\u00e4n\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Zum M\u00e4dchen haben:", "tokens": ["Zum", "M\u00e4d\u00b7chen", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Das hie\u00df' ein M\u00e4dchen haben? \u2013", "tokens": ["Das", "hie\u00df'", "ein", "M\u00e4d\u00b7chen", "ha\u00b7ben", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Hei\u00dft eingesegnet sein, und Weib und Hausstand haben.", "tokens": ["Hei\u00dft", "ein\u00b7ge\u00b7seg\u00b7net", "sein", ",", "und", "Weib", "und", "Haus\u00b7stand", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "VAINF", "$,", "KON", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Zum M\u00e4dchen w\u00fcnscht' ich mir \u2013 und wollt' es, ha! recht lieben \u2013", "tokens": ["Zum", "M\u00e4d\u00b7chen", "w\u00fcnscht'", "ich", "mir", "\u2013", "und", "wollt'", "es", ",", "ha", "!", "recht", "lie\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PPER", "$(", "KON", "VMFIN", "PPER", "$,", "ITJ", "$.", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein junges, nettes, tolles Ding,", "tokens": ["Ein", "jun\u00b7ges", ",", "net\u00b7tes", ",", "tol\u00b7les", "Ding", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Leicht zu erfreun, schwer zu betr\u00fcben,", "tokens": ["Leicht", "zu", "er\u00b7freun", ",", "schwer", "zu", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Am Wuchse schlank, im Gange flink,", "tokens": ["Am", "Wuch\u00b7se", "schlank", ",", "im", "Gan\u00b7ge", "flink", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Aug' ein Falk,", "tokens": ["Von", "Aug'", "ein", "Falk", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Von Mien' ein Schalk;", "tokens": ["Von", "Mien'", "ein", "Schalk", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Das flei\u00dfig, flei\u00dfig liest:", "tokens": ["Das", "flei\u00b7\u00dfig", ",", "flei\u00b7\u00dfig", "liest", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADJD", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Weil alles, was es liest,", "tokens": ["Weil", "al\u00b7les", ",", "was", "es", "liest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Sein einzig Buch \u2013 der Spiegel ist;", "tokens": ["Sein", "ein\u00b7zig", "Buch", "\u2013", "der", "Spie\u00b7gel", "ist", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$(", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das immer gaukelt, immer spricht,", "tokens": ["Das", "im\u00b7mer", "gau\u00b7kelt", ",", "im\u00b7mer", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und spricht und spricht von tausend Sachen,", "tokens": ["Und", "spricht", "und", "spricht", "von", "tau\u00b7send", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Versteht es gleich das Zehnte nicht", "tokens": ["Ver\u00b7steht", "es", "gleich", "das", "Zehn\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Von allen diesen tausend Sachen:", "tokens": ["Von", "al\u00b7len", "die\u00b7sen", "tau\u00b7send", "Sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDAT", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Genug, es spricht mit Lachen,", "tokens": ["Ge\u00b7nug", ",", "es", "spricht", "mit", "La\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Und kann sehr reizend lachen.", "tokens": ["Und", "kann", "sehr", "rei\u00b7zend", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Solch M\u00e4dchen w\u00fcnscht' ich mir! \u2013 Du, Freund, magst deine Zeit", "tokens": ["Solch", "M\u00e4d\u00b7chen", "w\u00fcnscht'", "ich", "mir", "!", "\u2013", "Du", ",", "Freund", ",", "magst", "dei\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PPER", "$.", "$(", "PPER", "$,", "NN", "$,", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur immerhin bei sch\u00f6ner Sittsamkeit,", "tokens": ["Nur", "im\u00b7mer\u00b7hin", "bei", "sch\u00f6\u00b7ner", "Sitt\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nicht ohne seraphin'sche Tr\u00e4nen,", "tokens": ["Nicht", "oh\u00b7ne", "se\u00b7ra\u00b7phin'\u00b7sche", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bei Tugend und Verstand verg\u00e4hnen.", "tokens": ["Bei", "Tu\u00b7gend", "und", "Ver\u00b7stand", "ver\u00b7g\u00e4h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Solch einen Engel", "tokens": ["Solch", "ei\u00b7nen", "En\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["PIS", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Ohn' alle M\u00e4ngel", "tokens": ["Ohn'", "al\u00b7le", "M\u00e4n\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Zum M\u00e4dchen haben:", "tokens": ["Zum", "M\u00e4d\u00b7chen", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Das hie\u00df' ein M\u00e4dchen haben? \u2013", "tokens": ["Das", "hie\u00df'", "ein", "M\u00e4d\u00b7chen", "ha\u00b7ben", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Hei\u00dft eingesegnet sein, und Weib und Hausstand haben.", "tokens": ["Hei\u00dft", "ein\u00b7ge\u00b7seg\u00b7net", "sein", ",", "und", "Weib", "und", "Haus\u00b7stand", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "VAINF", "$,", "KON", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}