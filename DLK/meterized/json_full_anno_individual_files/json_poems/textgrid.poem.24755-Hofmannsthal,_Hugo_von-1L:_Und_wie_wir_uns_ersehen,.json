{"textgrid.poem.24755": {"metadata": {"author": {"name": "Hofmannsthal, Hugo von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und wie wir uns ersehen,", "genre": "verse", "period": "N.A.", "pub_year": 1899, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und wie wir uns ersehen,", "tokens": ["Und", "wie", "wir", "uns", "er\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Tief eins ins andre gehen,", "tokens": ["Tief", "eins", "ins", "and\u00b7re", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "APPRART", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es bleibt doch nicht bestehen:", "tokens": ["Es", "bleibt", "doch", "nicht", "be\u00b7ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So wenig wie ein Ku\u00df.", "tokens": ["So", "we\u00b7nig", "wie", "ein", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Es bleibt um Brust und Wangen", "tokens": ["Es", "bleibt", "um", "Brust", "und", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nichts von so viel Verlangen,", "tokens": ["Nichts", "von", "so", "viel", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kein Zeichen bleibet hangen", "tokens": ["Kein", "Zei\u00b7chen", "blei\u00b7bet", "han\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch von so vielem Gl\u00fcck.", "tokens": ["Auch", "von", "so", "vie\u00b7lem", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "PIS", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und tr\u00fcgest du ein Zeichen,", "tokens": ["Und", "tr\u00fc\u00b7gest", "du", "ein", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein purpurrotes Zeichen,", "tokens": ["Ein", "pur\u00b7pur\u00b7ro\u00b7tes", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es m\u00fc\u00dfte auch verbleichen,", "tokens": ["Es", "m\u00fc\u00df\u00b7te", "auch", "ver\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es ginge auch dahin!", "tokens": ["Es", "gin\u00b7ge", "auch", "da\u00b7hin", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und wie wir uns ersehen,", "tokens": ["Und", "wie", "wir", "uns", "er\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Tief eins ins andre gehen,", "tokens": ["Tief", "eins", "ins", "and\u00b7re", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "APPRART", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es bleibt doch nicht bestehen:", "tokens": ["Es", "bleibt", "doch", "nicht", "be\u00b7ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So wenig wie ein Ku\u00df.", "tokens": ["So", "we\u00b7nig", "wie", "ein", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es bleibt um Brust und Wangen", "tokens": ["Es", "bleibt", "um", "Brust", "und", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nichts von so viel Verlangen,", "tokens": ["Nichts", "von", "so", "viel", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kein Zeichen bleibet hangen", "tokens": ["Kein", "Zei\u00b7chen", "blei\u00b7bet", "han\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch von so vielem Gl\u00fcck.", "tokens": ["Auch", "von", "so", "vie\u00b7lem", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "PIS", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und tr\u00fcgest du ein Zeichen,", "tokens": ["Und", "tr\u00fc\u00b7gest", "du", "ein", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein purpurrotes Zeichen,", "tokens": ["Ein", "pur\u00b7pur\u00b7ro\u00b7tes", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es m\u00fc\u00dfte auch verbleichen,", "tokens": ["Es", "m\u00fc\u00df\u00b7te", "auch", "ver\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es ginge auch dahin!", "tokens": ["Es", "gin\u00b7ge", "auch", "da\u00b7hin", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}