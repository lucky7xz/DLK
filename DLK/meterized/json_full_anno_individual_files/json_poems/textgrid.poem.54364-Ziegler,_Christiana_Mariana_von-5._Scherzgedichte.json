{"textgrid.poem.54364": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "5. Scherzgedichte", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Herr Orontes denk er doch,", "tokens": ["Mein", "Herr", "O\u00b7ron\u00b7tes", "denk", "er", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kukuck plagt mich immer noch", "tokens": ["Der", "Ku\u00b7kuck", "plagt", "mich", "im\u00b7mer", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Leipzig weg zubleiben,", "tokens": ["Von", "Leip\u00b7zig", "weg", "zu\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was aber ist wohl Schuld daran?", "tokens": ["Was", "a\u00b7ber", "ist", "wohl", "Schuld", "da\u00b7ran", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dies, da\u00df ich jeden Tag mir kann", "tokens": ["Dies", ",", "da\u00df", "ich", "je\u00b7den", "Tag", "mir", "kann"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "KOUS", "PPER", "PIAT", "NN", "PPER", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So gut, als dort vertreiben.", "tokens": ["So", "gut", ",", "als", "dort", "ver\u00b7trei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich find auch gute Freunde hier,", "tokens": ["Ich", "find", "auch", "gu\u00b7te", "Freun\u00b7de", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daneben Caffe, Wein und Bier,", "tokens": ["Da\u00b7ne\u00b7ben", "Caf\u00b7fe", ",", "Wein", "und", "Bier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und was man nur will haben.", "tokens": ["Und", "was", "man", "nur", "will", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Lomberkarte neu und frisch", "tokens": ["Die", "Lom\u00b7ber\u00b7kar\u00b7te", "neu", "und", "frisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Liegt t\u00e4glich richtig auf dem Tisch,", "tokens": ["Liegt", "t\u00e4g\u00b7lich", "rich\u00b7tig", "auf", "dem", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns Aug und Herz zu laben.", "tokens": ["Uns", "Aug", "und", "Herz", "zu", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wir sitzen recht im Paradies;", "tokens": ["Wir", "sit\u00b7zen", "recht", "im", "Pa\u00b7ra\u00b7dies", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Eva vor dem Apfelbi\u00df", "tokens": ["Wie", "E\u00b7va", "vor", "dem", "Ap\u00b7fel\u00b7bi\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Unschuld konnte leben,", "tokens": ["In", "Un\u00b7schuld", "konn\u00b7te", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So bl\u00fcht auch manche sch\u00f6ne Frucht,", "tokens": ["So", "bl\u00fcht", "auch", "man\u00b7che", "sch\u00f6\u00b7ne", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die unserm Gaum und Z\u00e4hnen sucht", "tokens": ["Die", "un\u00b7serm", "Gaum", "und", "Z\u00e4h\u00b7nen", "sucht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was schmackbares zu geben.", "tokens": ["Was", "schmack\u00b7ba\u00b7res", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Verk\u00fcrzte Stunden, Zeit und Tag,", "tokens": ["Ver\u00b7k\u00fcrz\u00b7te", "Stun\u00b7den", ",", "Zeit", "und", "Tag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und was man sich nur w\u00fcnschen mag,", "tokens": ["Und", "was", "man", "sich", "nur", "w\u00fcn\u00b7schen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PRF", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist sicher hier zu finden.", "tokens": ["Ist", "si\u00b7cher", "hier", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Scherz und Reim gilt hier auch viel,", "tokens": ["Ein", "Scherz", "und", "Reim", "gilt", "hier", "auch", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und endiget sich dieses Spiel,", "tokens": ["Und", "en\u00b7di\u00b7get", "sich", "die\u00b7ses", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Spatziert man um die Linden.", "tokens": ["Spat\u00b7ziert", "man", "um", "die", "Lin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Da denk ich an die Lindenstadt;", "tokens": ["Da", "denk", "ich", "an", "die", "Lin\u00b7den\u00b7stadt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und regt sich nur das schw\u00e4chste Blat,", "tokens": ["Und", "regt", "sich", "nur", "das", "schw\u00e4chs\u00b7te", "Blat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Zephyr sucht zu k\u00fcssen,", "tokens": ["Das", "Ze\u00b7phyr", "sucht", "zu", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So spricht die Wirthin Lobesan,", "tokens": ["So", "spricht", "die", "Wirt\u00b7hin", "Lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da k\u00f6mmt gewi\u00df ein Landsmann an,", "tokens": ["Da", "k\u00f6mmt", "ge\u00b7wi\u00df", "ein", "Lands\u00b7mann", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der euch nicht kann vermissen.", "tokens": ["Der", "euch", "nicht", "kann", "ver\u00b7mis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Allein sie fehlt; doch bringt dies mich", "tokens": ["Al\u00b7lein", "sie", "fehlt", ";", "doch", "bringt", "dies", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$.", "ADV", "VVFIN", "PDS", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf andere gute Freund und dich,", "tokens": ["Auf", "an\u00b7de\u00b7re", "gu\u00b7te", "Freund", "und", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "KON", "PPER", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die mich entfernet gr\u00fcssen.", "tokens": ["Die", "mich", "ent\u00b7fer\u00b7net", "gr\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hat gleich der Raub, so mich betrifft", "tokens": ["Hat", "gleich", "der", "Raub", ",", "so", "mich", "be\u00b7tr\u00b7ifft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "ADV", "PPER", "VVFIN"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.5": {"text": "Viel Schmerz und Sehnsucht hier gestift,", "tokens": ["Viel", "Schmerz", "und", "Sehn\u00b7sucht", "hier", "ge\u00b7stift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Will ich nicht l\u00e4nger b\u00fcssen.", "tokens": ["Will", "ich", "nicht", "l\u00e4n\u00b7ger", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Man mag hier bitten, flehn und schreyn,", "tokens": ["Man", "mag", "hier", "bit\u00b7ten", ",", "flehn", "und", "schreyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "VVINF", "$,", "VVINF", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So pack ich doch schon heimlich ein,", "tokens": ["So", "pack", "ich", "doch", "schon", "heim\u00b7lich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Heymath zu begr\u00fcssen,", "tokens": ["Die", "Hey\u00b7math", "zu", "be\u00b7gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nunmehr h\u00e4lt mich nichts weiter auf,", "tokens": ["Nun\u00b7mehr", "h\u00e4lt", "mich", "nichts", "wei\u00b7ter", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sollt man zu hemmen meinen Lauf,", "tokens": ["Sollt", "man", "zu", "hem\u00b7men", "mei\u00b7nen", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKZU", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich auch in Ketten schliessen.", "tokens": ["Mich", "auch", "in", "Ket\u00b7ten", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wie w\u00fcrd es um die Schule stehn,", "tokens": ["Wie", "w\u00fcrd", "es", "um", "die", "Schu\u00b7le", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wollt ich noch l\u00e4nger m\u00fcssig gehn?", "tokens": ["Wollt", "ich", "noch", "l\u00e4n\u00b7ger", "m\u00fcs\u00b7sig", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was spr\u00e4ch der Musenorden?", "tokens": ["Was", "spr\u00e4ch", "der", "Mu\u00b7se\u00b7nor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Herr Schulmeister Phoebus rief:", "tokens": ["Der", "Herr", "Schul\u00b7meis\u00b7ter", "Phoe\u00b7bus", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich w\u00e4r, wenn ich die Zeit verschlief,", "tokens": ["Ich", "w\u00e4r", ",", "wenn", "ich", "die", "Zeit", "ver\u00b7schlief", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur Mammeluckin worden.", "tokens": ["Zur", "Mam\u00b7me\u00b7lu\u00b7ckin", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Nein, diese stehen oben an,", "tokens": ["Nein", ",", "die\u00b7se", "ste\u00b7hen", "o\u00b7ben", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie man gar leichte denken kann,", "tokens": ["Wie", "man", "gar", "leich\u00b7te", "den\u00b7ken", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADJA", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In meiner Freunde Rollen.", "tokens": ["In", "mei\u00b7ner", "Freun\u00b7de", "Rol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit dieser Schaar verderb ichs nicht,", "tokens": ["Mit", "die\u00b7ser", "Schaar", "ver\u00b7derb", "ichs", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PIS", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weil sie durch ihren Unterricht", "tokens": ["Weil", "sie", "durch", "ih\u00b7ren", "Un\u00b7ter\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus mir was schnitzen sollen.", "tokens": ["Aus", "mir", "was", "schnit\u00b7zen", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Drum zehl ich alle Stunden schon,", "tokens": ["Drum", "zehl", "ich", "al\u00b7le", "Stun\u00b7den", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis da\u00df ich euren Helicon", "tokens": ["Bis", "da\u00df", "ich", "eu\u00b7ren", "He\u00b7li\u00b7con"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kann wiederum erblicken.", "tokens": ["Kann", "wie\u00b7de\u00b7rum", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie wird das Posthorn mich erfreun,", "tokens": ["Wie", "wird", "das", "Post\u00b7horn", "mich", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das mich nach langem Aussenseyn", "tokens": ["Das", "mich", "nach", "lan\u00b7gem", "Aus\u00b7sen\u00b7seyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur\u00fcck soll wieder schicken.", "tokens": ["Zu\u00b7r\u00fcck", "soll", "wie\u00b7der", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Mein Herr Orontes denk er doch,", "tokens": ["Mein", "Herr", "O\u00b7ron\u00b7tes", "denk", "er", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kukuck plagt mich immer noch", "tokens": ["Der", "Ku\u00b7kuck", "plagt", "mich", "im\u00b7mer", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Leipzig weg zubleiben,", "tokens": ["Von", "Leip\u00b7zig", "weg", "zu\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was aber ist wohl Schuld daran?", "tokens": ["Was", "a\u00b7ber", "ist", "wohl", "Schuld", "da\u00b7ran", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dies, da\u00df ich jeden Tag mir kann", "tokens": ["Dies", ",", "da\u00df", "ich", "je\u00b7den", "Tag", "mir", "kann"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "KOUS", "PPER", "PIAT", "NN", "PPER", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So gut, als dort vertreiben.", "tokens": ["So", "gut", ",", "als", "dort", "ver\u00b7trei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Ich find auch gute Freunde hier,", "tokens": ["Ich", "find", "auch", "gu\u00b7te", "Freun\u00b7de", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daneben Caffe, Wein und Bier,", "tokens": ["Da\u00b7ne\u00b7ben", "Caf\u00b7fe", ",", "Wein", "und", "Bier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und was man nur will haben.", "tokens": ["Und", "was", "man", "nur", "will", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Lomberkarte neu und frisch", "tokens": ["Die", "Lom\u00b7ber\u00b7kar\u00b7te", "neu", "und", "frisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Liegt t\u00e4glich richtig auf dem Tisch,", "tokens": ["Liegt", "t\u00e4g\u00b7lich", "rich\u00b7tig", "auf", "dem", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns Aug und Herz zu laben.", "tokens": ["Uns", "Aug", "und", "Herz", "zu", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wir sitzen recht im Paradies;", "tokens": ["Wir", "sit\u00b7zen", "recht", "im", "Pa\u00b7ra\u00b7dies", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Eva vor dem Apfelbi\u00df", "tokens": ["Wie", "E\u00b7va", "vor", "dem", "Ap\u00b7fel\u00b7bi\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Unschuld konnte leben,", "tokens": ["In", "Un\u00b7schuld", "konn\u00b7te", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So bl\u00fcht auch manche sch\u00f6ne Frucht,", "tokens": ["So", "bl\u00fcht", "auch", "man\u00b7che", "sch\u00f6\u00b7ne", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die unserm Gaum und Z\u00e4hnen sucht", "tokens": ["Die", "un\u00b7serm", "Gaum", "und", "Z\u00e4h\u00b7nen", "sucht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was schmackbares zu geben.", "tokens": ["Was", "schmack\u00b7ba\u00b7res", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Verk\u00fcrzte Stunden, Zeit und Tag,", "tokens": ["Ver\u00b7k\u00fcrz\u00b7te", "Stun\u00b7den", ",", "Zeit", "und", "Tag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und was man sich nur w\u00fcnschen mag,", "tokens": ["Und", "was", "man", "sich", "nur", "w\u00fcn\u00b7schen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PRF", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist sicher hier zu finden.", "tokens": ["Ist", "si\u00b7cher", "hier", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Scherz und Reim gilt hier auch viel,", "tokens": ["Ein", "Scherz", "und", "Reim", "gilt", "hier", "auch", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und endiget sich dieses Spiel,", "tokens": ["Und", "en\u00b7di\u00b7get", "sich", "die\u00b7ses", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Spatziert man um die Linden.", "tokens": ["Spat\u00b7ziert", "man", "um", "die", "Lin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Da denk ich an die Lindenstadt;", "tokens": ["Da", "denk", "ich", "an", "die", "Lin\u00b7den\u00b7stadt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und regt sich nur das schw\u00e4chste Blat,", "tokens": ["Und", "regt", "sich", "nur", "das", "schw\u00e4chs\u00b7te", "Blat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Zephyr sucht zu k\u00fcssen,", "tokens": ["Das", "Ze\u00b7phyr", "sucht", "zu", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So spricht die Wirthin Lobesan,", "tokens": ["So", "spricht", "die", "Wirt\u00b7hin", "Lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da k\u00f6mmt gewi\u00df ein Landsmann an,", "tokens": ["Da", "k\u00f6mmt", "ge\u00b7wi\u00df", "ein", "Lands\u00b7mann", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der euch nicht kann vermissen.", "tokens": ["Der", "euch", "nicht", "kann", "ver\u00b7mis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Allein sie fehlt; doch bringt dies mich", "tokens": ["Al\u00b7lein", "sie", "fehlt", ";", "doch", "bringt", "dies", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "$.", "ADV", "VVFIN", "PDS", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf andere gute Freund und dich,", "tokens": ["Auf", "an\u00b7de\u00b7re", "gu\u00b7te", "Freund", "und", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "KON", "PPER", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die mich entfernet gr\u00fcssen.", "tokens": ["Die", "mich", "ent\u00b7fer\u00b7net", "gr\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hat gleich der Raub, so mich betrifft", "tokens": ["Hat", "gleich", "der", "Raub", ",", "so", "mich", "be\u00b7tr\u00b7ifft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "ADV", "PPER", "VVFIN"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.5": {"text": "Viel Schmerz und Sehnsucht hier gestift,", "tokens": ["Viel", "Schmerz", "und", "Sehn\u00b7sucht", "hier", "ge\u00b7stift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Will ich nicht l\u00e4nger b\u00fcssen.", "tokens": ["Will", "ich", "nicht", "l\u00e4n\u00b7ger", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Man mag hier bitten, flehn und schreyn,", "tokens": ["Man", "mag", "hier", "bit\u00b7ten", ",", "flehn", "und", "schreyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "VVINF", "$,", "VVINF", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So pack ich doch schon heimlich ein,", "tokens": ["So", "pack", "ich", "doch", "schon", "heim\u00b7lich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Heymath zu begr\u00fcssen,", "tokens": ["Die", "Hey\u00b7math", "zu", "be\u00b7gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nunmehr h\u00e4lt mich nichts weiter auf,", "tokens": ["Nun\u00b7mehr", "h\u00e4lt", "mich", "nichts", "wei\u00b7ter", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sollt man zu hemmen meinen Lauf,", "tokens": ["Sollt", "man", "zu", "hem\u00b7men", "mei\u00b7nen", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKZU", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich auch in Ketten schliessen.", "tokens": ["Mich", "auch", "in", "Ket\u00b7ten", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Wie w\u00fcrd es um die Schule stehn,", "tokens": ["Wie", "w\u00fcrd", "es", "um", "die", "Schu\u00b7le", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wollt ich noch l\u00e4nger m\u00fcssig gehn?", "tokens": ["Wollt", "ich", "noch", "l\u00e4n\u00b7ger", "m\u00fcs\u00b7sig", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was spr\u00e4ch der Musenorden?", "tokens": ["Was", "spr\u00e4ch", "der", "Mu\u00b7se\u00b7nor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Herr Schulmeister Phoebus rief:", "tokens": ["Der", "Herr", "Schul\u00b7meis\u00b7ter", "Phoe\u00b7bus", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich w\u00e4r, wenn ich die Zeit verschlief,", "tokens": ["Ich", "w\u00e4r", ",", "wenn", "ich", "die", "Zeit", "ver\u00b7schlief", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur Mammeluckin worden.", "tokens": ["Zur", "Mam\u00b7me\u00b7lu\u00b7ckin", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Nein, diese stehen oben an,", "tokens": ["Nein", ",", "die\u00b7se", "ste\u00b7hen", "o\u00b7ben", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie man gar leichte denken kann,", "tokens": ["Wie", "man", "gar", "leich\u00b7te", "den\u00b7ken", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADJA", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In meiner Freunde Rollen.", "tokens": ["In", "mei\u00b7ner", "Freun\u00b7de", "Rol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit dieser Schaar verderb ichs nicht,", "tokens": ["Mit", "die\u00b7ser", "Schaar", "ver\u00b7derb", "ichs", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PIS", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weil sie durch ihren Unterricht", "tokens": ["Weil", "sie", "durch", "ih\u00b7ren", "Un\u00b7ter\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus mir was schnitzen sollen.", "tokens": ["Aus", "mir", "was", "schnit\u00b7zen", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Drum zehl ich alle Stunden schon,", "tokens": ["Drum", "zehl", "ich", "al\u00b7le", "Stun\u00b7den", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis da\u00df ich euren Helicon", "tokens": ["Bis", "da\u00df", "ich", "eu\u00b7ren", "He\u00b7li\u00b7con"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kann wiederum erblicken.", "tokens": ["Kann", "wie\u00b7de\u00b7rum", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie wird das Posthorn mich erfreun,", "tokens": ["Wie", "wird", "das", "Post\u00b7horn", "mich", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das mich nach langem Aussenseyn", "tokens": ["Das", "mich", "nach", "lan\u00b7gem", "Aus\u00b7sen\u00b7seyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur\u00fcck soll wieder schicken.", "tokens": ["Zu\u00b7r\u00fcck", "soll", "wie\u00b7der", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}