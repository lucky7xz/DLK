{"textgrid.poem.64212": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Der Adler", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Nachbar dr\u00fcben, \u00fcber'm Strom,", "tokens": ["Mein", "Nach\u00b7bar", "dr\u00fc\u00b7ben", ",", "\u00fc\u00b7ber'm", "Strom", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Abt der Schotten, h\u00e4lt zu Rom.", "tokens": ["Der", "Abt", "der", "Schot\u00b7ten", ",", "h\u00e4lt", "zu", "Rom", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und wie du, Wald, stets neu mich labst,", "tokens": ["Und", "wie", "du", ",", "Wald", ",", "stets", "neu", "mich", "labst", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "$,", "NN", "$,", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Labt ihn stets neu \u2013 ein Brief vom Papst.", "tokens": ["Labt", "ihn", "stets", "neu", "\u2013", "ein", "Brief", "vom", "Papst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$(", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich g\u00f6nn' es ihm! \u2013 Doch j\u00fcngst geschah", "tokens": ["Ich", "g\u00f6nn'", "es", "ihm", "!", "\u2013", "Doch", "j\u00fcngst", "ge\u00b7schah"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "$.", "$(", "KON", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Streich ihm, den ich gerne sah.", "tokens": ["Ein", "Streich", "ihm", ",", "den", "ich", "ger\u00b7ne", "sah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Den V\u00f6glein stellt er nach mit Netzen,", "tokens": ["Den", "V\u00f6\u00b7glein", "stellt", "er", "nach", "mit", "Net\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht, ihrer Lieder sich zu letzen,", "tokens": ["Nicht", ",", "ih\u00b7rer", "Lie\u00b7der", "sich", "zu", "let\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PPOSAT", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nein, weil er sie gebraten fri\u00dft,", "tokens": ["Nein", ",", "weil", "er", "sie", "ge\u00b7bra\u00b7ten", "fri\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PPER", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wann just nicht grade Fasttag ist.", "tokens": ["Wann", "just", "nicht", "gra\u00b7de", "Fast\u00b7tag", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Oft nehm' ich unbemerkt und leise", "tokens": ["Oft", "nehm'", "ich", "un\u00b7be\u00b7merkt", "und", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm aus dem Garn die frevle Speise,", "tokens": ["Ihm", "aus", "dem", "Garn", "die", "frev\u00b7le", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und Drossel, Fink und H\u00e4nfling froh", "tokens": ["Und", "Dros\u00b7sel", ",", "Fink", "und", "H\u00e4nf\u00b7ling", "froh"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entfliegen ihm mit Jubilo.", "tokens": ["Ent\u00b7flie\u00b7gen", "ihm", "mit", "Ju\u00b7bi\u00b7lo", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Doch j\u00fcngst kam \u00fcber ihn ein andrer,", "tokens": ["Doch", "j\u00fcngst", "kam", "\u00fc\u00b7ber", "ihn", "ein", "an\u00b7drer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "PPER", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein sturmgewalt'ger Wolkenwandrer:", "tokens": ["Ein", "sturm\u00b7ge\u00b7walt'\u00b7ger", "Wol\u00b7ken\u00b7wand\u00b7rer", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Verfolgend eine Dolenschar,", "tokens": ["Ver\u00b7fol\u00b7gend", "ei\u00b7ne", "Do\u00b7len\u00b7schar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Strich \u00fcber'n Main der K\u00f6nigsaar,", "tokens": ["Strich", "\u00fc\u00b7ber'n", "Main", "der", "K\u00f6\u00b7nig\u00b7saar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Und flog, \u2013 er sah den Lockherd nicht, \u2013", "tokens": ["Und", "flog", ",", "\u2013", "er", "sah", "den", "Lock\u00b7herd", "nicht", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$,", "$(", "PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Flog mitten in die Netze dicht.", "tokens": ["Flog", "mit\u00b7ten", "in", "die", "Net\u00b7ze", "dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Da lief mit lautem Siegsgeschrei", "tokens": ["Da", "lief", "mit", "lau\u00b7tem", "Siegs\u00b7ge\u00b7schrei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der dicke Abt zum Fang herbei.", "tokens": ["Der", "di\u00b7cke", "Abt", "zum", "Fang", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch, als er schon ganz nahe war,", "tokens": ["Doch", ",", "als", "er", "schon", "ganz", "na\u00b7he", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zerri\u00df das ganze Garn der Aar", "tokens": ["Zer\u00b7ri\u00df", "das", "gan\u00b7ze", "Garn", "der", "Aar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und flog so ungest\u00fcm hin dann, \u2013", "tokens": ["Und", "flog", "so", "un\u00b7ge\u00b7st\u00fcm", "hin", "dann", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "ADV", "ADV", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Boden, schreiend, fiel der Mann!", "tokens": ["Zu", "Bo\u00b7den", ",", "schrei\u00b7end", ",", "fiel", "der", "Mann", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJD", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Und mit den arg zerfetzten Netzen", "tokens": ["Und", "mit", "den", "arg", "zer\u00b7fetz\u00b7ten", "Net\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wird er kein V\u00f6glein mehr verletzen.", "tokens": ["Wird", "er", "kein", "V\u00f6\u00b7glein", "mehr", "ver\u00b7let\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Merk: Garn, f\u00fcr Gimpel stark genug,", "tokens": ["Merk", ":", "Garn", ",", "f\u00fcr", "Gim\u00b7pel", "stark", "ge\u00b7nug", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "NN", "$,", "APPR", "NE", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hemmt nicht des K\u00f6nigsadlers Flug.", "tokens": ["Hemmt", "nicht", "des", "K\u00f6\u00b7ni\u00b7gsad\u00b7lers", "Flug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Mein Nachbar dr\u00fcben, \u00fcber'm Strom,", "tokens": ["Mein", "Nach\u00b7bar", "dr\u00fc\u00b7ben", ",", "\u00fc\u00b7ber'm", "Strom", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Abt der Schotten, h\u00e4lt zu Rom.", "tokens": ["Der", "Abt", "der", "Schot\u00b7ten", ",", "h\u00e4lt", "zu", "Rom", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Und wie du, Wald, stets neu mich labst,", "tokens": ["Und", "wie", "du", ",", "Wald", ",", "stets", "neu", "mich", "labst", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "$,", "NN", "$,", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Labt ihn stets neu \u2013 ein Brief vom Papst.", "tokens": ["Labt", "ihn", "stets", "neu", "\u2013", "ein", "Brief", "vom", "Papst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$(", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ich g\u00f6nn' es ihm! \u2013 Doch j\u00fcngst geschah", "tokens": ["Ich", "g\u00f6nn'", "es", "ihm", "!", "\u2013", "Doch", "j\u00fcngst", "ge\u00b7schah"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "$.", "$(", "KON", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Streich ihm, den ich gerne sah.", "tokens": ["Ein", "Streich", "ihm", ",", "den", "ich", "ger\u00b7ne", "sah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Den V\u00f6glein stellt er nach mit Netzen,", "tokens": ["Den", "V\u00f6\u00b7glein", "stellt", "er", "nach", "mit", "Net\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht, ihrer Lieder sich zu letzen,", "tokens": ["Nicht", ",", "ih\u00b7rer", "Lie\u00b7der", "sich", "zu", "let\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PPOSAT", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Nein, weil er sie gebraten fri\u00dft,", "tokens": ["Nein", ",", "weil", "er", "sie", "ge\u00b7bra\u00b7ten", "fri\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PPER", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wann just nicht grade Fasttag ist.", "tokens": ["Wann", "just", "nicht", "gra\u00b7de", "Fast\u00b7tag", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PTKNEG", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Oft nehm' ich unbemerkt und leise", "tokens": ["Oft", "nehm'", "ich", "un\u00b7be\u00b7merkt", "und", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm aus dem Garn die frevle Speise,", "tokens": ["Ihm", "aus", "dem", "Garn", "die", "frev\u00b7le", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Und Drossel, Fink und H\u00e4nfling froh", "tokens": ["Und", "Dros\u00b7sel", ",", "Fink", "und", "H\u00e4nf\u00b7ling", "froh"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entfliegen ihm mit Jubilo.", "tokens": ["Ent\u00b7flie\u00b7gen", "ihm", "mit", "Ju\u00b7bi\u00b7lo", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Doch j\u00fcngst kam \u00fcber ihn ein andrer,", "tokens": ["Doch", "j\u00fcngst", "kam", "\u00fc\u00b7ber", "ihn", "ein", "an\u00b7drer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "PPER", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein sturmgewalt'ger Wolkenwandrer:", "tokens": ["Ein", "sturm\u00b7ge\u00b7walt'\u00b7ger", "Wol\u00b7ken\u00b7wand\u00b7rer", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Verfolgend eine Dolenschar,", "tokens": ["Ver\u00b7fol\u00b7gend", "ei\u00b7ne", "Do\u00b7len\u00b7schar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Strich \u00fcber'n Main der K\u00f6nigsaar,", "tokens": ["Strich", "\u00fc\u00b7ber'n", "Main", "der", "K\u00f6\u00b7nig\u00b7saar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Und flog, \u2013 er sah den Lockherd nicht, \u2013", "tokens": ["Und", "flog", ",", "\u2013", "er", "sah", "den", "Lock\u00b7herd", "nicht", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$,", "$(", "PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Flog mitten in die Netze dicht.", "tokens": ["Flog", "mit\u00b7ten", "in", "die", "Net\u00b7ze", "dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Da lief mit lautem Siegsgeschrei", "tokens": ["Da", "lief", "mit", "lau\u00b7tem", "Siegs\u00b7ge\u00b7schrei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der dicke Abt zum Fang herbei.", "tokens": ["Der", "di\u00b7cke", "Abt", "zum", "Fang", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Doch, als er schon ganz nahe war,", "tokens": ["Doch", ",", "als", "er", "schon", "ganz", "na\u00b7he", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zerri\u00df das ganze Garn der Aar", "tokens": ["Zer\u00b7ri\u00df", "das", "gan\u00b7ze", "Garn", "der", "Aar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Und flog so ungest\u00fcm hin dann, \u2013", "tokens": ["Und", "flog", "so", "un\u00b7ge\u00b7st\u00fcm", "hin", "dann", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "ADV", "ADV", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Boden, schreiend, fiel der Mann!", "tokens": ["Zu", "Bo\u00b7den", ",", "schrei\u00b7end", ",", "fiel", "der", "Mann", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJD", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Und mit den arg zerfetzten Netzen", "tokens": ["Und", "mit", "den", "arg", "zer\u00b7fetz\u00b7ten", "Net\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wird er kein V\u00f6glein mehr verletzen.", "tokens": ["Wird", "er", "kein", "V\u00f6\u00b7glein", "mehr", "ver\u00b7let\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Merk: Garn, f\u00fcr Gimpel stark genug,", "tokens": ["Merk", ":", "Garn", ",", "f\u00fcr", "Gim\u00b7pel", "stark", "ge\u00b7nug", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "NN", "$,", "APPR", "NE", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hemmt nicht des K\u00f6nigsadlers Flug.", "tokens": ["Hemmt", "nicht", "des", "K\u00f6\u00b7ni\u00b7gsad\u00b7lers", "Flug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}