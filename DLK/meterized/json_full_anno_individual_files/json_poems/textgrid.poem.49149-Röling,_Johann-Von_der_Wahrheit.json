{"textgrid.poem.49149": {"metadata": {"author": {"name": "R\u00f6ling, Johann", "birth": "N.A.", "death": "N.A."}, "title": "Von der Wahrheit", "genre": "verse", "period": "N.A.", "pub_year": 1656, "urn": "N.A.", "language": ["de:0.85", "fr:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Euer Wort sey Ja und Nein,", "tokens": ["Eu\u00b7er", "Wort", "sey", "Ja", "und", "Nein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "KON", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bindest du uns, Jesu, ein.", "tokens": ["Bin\u00b7dest", "du", "uns", ",", "Je\u00b7su", ",", "ein", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "$,", "NE", "$,", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja sey ja, und nein sey nein,", "tokens": ["Ja", "sey", "ja", ",", "und", "nein", "sey", "nein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "ADV", "$,", "KON", "PTKANT", "VAFIN", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn doch dies so m\u00f6chte seyn!", "tokens": ["Wenn", "doch", "dies", "so", "m\u00f6ch\u00b7te", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDS", "ADV", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Nun sieht hierauff nicht die Welt,", "tokens": ["Nun", "sieht", "hier\u00b7auff", "nicht", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wer itzt nichts von Farben h\u00e4lt,", "tokens": ["Wer", "itzt", "nichts", "von", "Far\u00b7ben", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Worte schminken kan,", "tokens": ["Und", "die", "Wor\u00b7te", "schmin\u00b7ken", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist f\u00fcr unsre Zeit kein Mann.", "tokens": ["Ist", "f\u00fcr", "uns\u00b7re", "Zeit", "kein", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Was ist Wahrheit, frug man dich,", "tokens": ["Was", "ist", "Wahr\u00b7heit", ",", "frug", "man", "dich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NN", "$,", "VVFIN", "PIS", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die in dir mit von uns wich.", "tokens": ["Die", "in", "dir", "mit", "von", "uns", "wich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "APPR", "APPR", "PPER", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Frag nun uns, o Bild der Treu,", "tokens": ["Frag", "nun", "uns", ",", "o", "Bild", "der", "Treu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPER", "$,", "FM", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo bey uns die Wahrheit sey.", "tokens": ["Wo", "bey", "uns", "die", "Wahr\u00b7heit", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Meere sind es, die man h\u00f6rt,", "tokens": ["Mee\u00b7re", "sind", "es", ",", "die", "man", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da man auff dem Trucknen fehrt,", "tokens": ["Da", "man", "auff", "dem", "Truck\u00b7nen", "fehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Berge, welche man verspricht,", "tokens": ["Ber\u00b7ge", ",", "wel\u00b7che", "man", "ver\u00b7spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und man kriegt kein Sandkorn nicht.", "tokens": ["Und", "man", "kriegt", "kein", "Sand\u00b7korn", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PIAT", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wolken, die am gr\u00f6sten sind,", "tokens": ["Wol\u00b7ken", ",", "die", "am", "gr\u00f6s\u00b7ten", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "APPRART", "ADJA", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Geben meist f\u00fcr Regen Wind;", "tokens": ["Ge\u00b7ben", "meist", "f\u00fcr", "Re\u00b7gen", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "NN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Wer die reichsten Worte hat,", "tokens": ["Wer", "die", "reichs\u00b7ten", "Wor\u00b7te", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Ist der \u00c4rmste mit der That.", "tokens": ["Ist", "der", "\u00c4rms\u00b7te", "mit", "der", "That", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Auff den sch\u00f6nsten Morgen-Schein", "tokens": ["Auff", "den", "sch\u00f6ns\u00b7ten", "Mor\u00b7gen\u00b7Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4llt das schlechtste Wetter ein;", "tokens": ["F\u00e4llt", "das", "schlechts\u00b7te", "Wet\u00b7ter", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sich erst so heilig stellt,", "tokens": ["Wer", "sich", "erst", "so", "hei\u00b7lig", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist, der selbst zuletzt uns f\u00e4llt.", "tokens": ["Ist", ",", "der", "selbst", "zu\u00b7letzt", "uns", "f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "ADV", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "So thust du, mein Heyland, nicht;", "tokens": ["So", "thust", "du", ",", "mein", "Hey\u00b7land", ",", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "PTKNEG", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was dein s\u00fc\u00dfer Mund verspricht,", "tokens": ["Was", "dein", "s\u00fc\u00b7\u00dfer", "Mund", "ver\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist offt widrig, wie es scheint,", "tokens": ["Ist", "offt", "wid\u00b7rig", ",", "wie", "es", "scheint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ist dennoch gut gemeint.", "tokens": ["Und", "ist", "den\u00b7noch", "gut", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.8": {"line.1": {"text": "Wenig sagstu, schaffest viel,", "tokens": ["We\u00b7nig", "sags\u00b7tu", ",", "schaf\u00b7fest", "viel", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Nutzen ist dein Ziel,", "tokens": ["Un\u00b7ser", "Nut\u00b7zen", "ist", "dein", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stellst dich feind und liebst dennoch,", "tokens": ["Stellst", "dich", "feind", "und", "liebst", "den\u00b7noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja, versagst, und giebst es doch.", "tokens": ["Ja", ",", "ver\u00b7sagst", ",", "und", "giebst", "es", "doch", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Liebster Bruder, treuster Freund,", "tokens": ["Liebs\u00b7ter", "Bru\u00b7der", ",", "treus\u00b7ter", "Freund", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jesu, der es treuer meint,", "tokens": ["Je\u00b7su", ",", "der", "es", "treu\u00b7er", "meint", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als kein Bruder oder Freund", "tokens": ["Als", "kein", "Bru\u00b7der", "o\u00b7der", "Freund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimmer es auff Erden meint,", "tokens": ["Nim\u00b7mer", "es", "auff", "Er\u00b7den", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "La\u00df mein Wort nur Ja und Nein,", "tokens": ["La\u00df", "mein", "Wort", "nur", "Ja", "und", "Nein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADV", "PTKANT", "KON", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kurtz und desto wahrer seyn;", "tokens": ["Kurtz", "und", "des\u00b7to", "wah\u00b7rer", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rufft die Welt, so la\u00df es Nein,", "tokens": ["Rufft", "die", "Welt", ",", "so", "la\u00df", "es", "Nein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ADV", "VVIMP", "PPER", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ruffest du, ein Ja stets seyn.", "tokens": ["Ruf\u00b7fest", "du", ",", "ein", "Ja", "stets", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Euer Wort sey Ja und Nein,", "tokens": ["Eu\u00b7er", "Wort", "sey", "Ja", "und", "Nein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "KON", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bindest du uns, Jesu, ein.", "tokens": ["Bin\u00b7dest", "du", "uns", ",", "Je\u00b7su", ",", "ein", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "$,", "NE", "$,", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja sey ja, und nein sey nein,", "tokens": ["Ja", "sey", "ja", ",", "und", "nein", "sey", "nein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "ADV", "$,", "KON", "PTKANT", "VAFIN", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn doch dies so m\u00f6chte seyn!", "tokens": ["Wenn", "doch", "dies", "so", "m\u00f6ch\u00b7te", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDS", "ADV", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Nun sieht hierauff nicht die Welt,", "tokens": ["Nun", "sieht", "hier\u00b7auff", "nicht", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wer itzt nichts von Farben h\u00e4lt,", "tokens": ["Wer", "itzt", "nichts", "von", "Far\u00b7ben", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Worte schminken kan,", "tokens": ["Und", "die", "Wor\u00b7te", "schmin\u00b7ken", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist f\u00fcr unsre Zeit kein Mann.", "tokens": ["Ist", "f\u00fcr", "uns\u00b7re", "Zeit", "kein", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Was ist Wahrheit, frug man dich,", "tokens": ["Was", "ist", "Wahr\u00b7heit", ",", "frug", "man", "dich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NN", "$,", "VVFIN", "PIS", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die in dir mit von uns wich.", "tokens": ["Die", "in", "dir", "mit", "von", "uns", "wich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "APPR", "APPR", "PPER", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Frag nun uns, o Bild der Treu,", "tokens": ["Frag", "nun", "uns", ",", "o", "Bild", "der", "Treu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPER", "$,", "FM", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo bey uns die Wahrheit sey.", "tokens": ["Wo", "bey", "uns", "die", "Wahr\u00b7heit", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Meere sind es, die man h\u00f6rt,", "tokens": ["Mee\u00b7re", "sind", "es", ",", "die", "man", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da man auff dem Trucknen fehrt,", "tokens": ["Da", "man", "auff", "dem", "Truck\u00b7nen", "fehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Berge, welche man verspricht,", "tokens": ["Ber\u00b7ge", ",", "wel\u00b7che", "man", "ver\u00b7spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und man kriegt kein Sandkorn nicht.", "tokens": ["Und", "man", "kriegt", "kein", "Sand\u00b7korn", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PIAT", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Wolken, die am gr\u00f6sten sind,", "tokens": ["Wol\u00b7ken", ",", "die", "am", "gr\u00f6s\u00b7ten", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "APPRART", "ADJA", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Geben meist f\u00fcr Regen Wind;", "tokens": ["Ge\u00b7ben", "meist", "f\u00fcr", "Re\u00b7gen", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "NN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Wer die reichsten Worte hat,", "tokens": ["Wer", "die", "reichs\u00b7ten", "Wor\u00b7te", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Ist der \u00c4rmste mit der That.", "tokens": ["Ist", "der", "\u00c4rms\u00b7te", "mit", "der", "That", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Auff den sch\u00f6nsten Morgen-Schein", "tokens": ["Auff", "den", "sch\u00f6ns\u00b7ten", "Mor\u00b7gen\u00b7Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4llt das schlechtste Wetter ein;", "tokens": ["F\u00e4llt", "das", "schlechts\u00b7te", "Wet\u00b7ter", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sich erst so heilig stellt,", "tokens": ["Wer", "sich", "erst", "so", "hei\u00b7lig", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist, der selbst zuletzt uns f\u00e4llt.", "tokens": ["Ist", ",", "der", "selbst", "zu\u00b7letzt", "uns", "f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "ADV", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "So thust du, mein Heyland, nicht;", "tokens": ["So", "thust", "du", ",", "mein", "Hey\u00b7land", ",", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "PTKNEG", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was dein s\u00fc\u00dfer Mund verspricht,", "tokens": ["Was", "dein", "s\u00fc\u00b7\u00dfer", "Mund", "ver\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist offt widrig, wie es scheint,", "tokens": ["Ist", "offt", "wid\u00b7rig", ",", "wie", "es", "scheint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ist dennoch gut gemeint.", "tokens": ["Und", "ist", "den\u00b7noch", "gut", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.18": {"line.1": {"text": "Wenig sagstu, schaffest viel,", "tokens": ["We\u00b7nig", "sags\u00b7tu", ",", "schaf\u00b7fest", "viel", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Nutzen ist dein Ziel,", "tokens": ["Un\u00b7ser", "Nut\u00b7zen", "ist", "dein", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stellst dich feind und liebst dennoch,", "tokens": ["Stellst", "dich", "feind", "und", "liebst", "den\u00b7noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja, versagst, und giebst es doch.", "tokens": ["Ja", ",", "ver\u00b7sagst", ",", "und", "giebst", "es", "doch", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Liebster Bruder, treuster Freund,", "tokens": ["Liebs\u00b7ter", "Bru\u00b7der", ",", "treus\u00b7ter", "Freund", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jesu, der es treuer meint,", "tokens": ["Je\u00b7su", ",", "der", "es", "treu\u00b7er", "meint", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als kein Bruder oder Freund", "tokens": ["Als", "kein", "Bru\u00b7der", "o\u00b7der", "Freund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimmer es auff Erden meint,", "tokens": ["Nim\u00b7mer", "es", "auff", "Er\u00b7den", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "La\u00df mein Wort nur Ja und Nein,", "tokens": ["La\u00df", "mein", "Wort", "nur", "Ja", "und", "Nein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADV", "PTKANT", "KON", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kurtz und desto wahrer seyn;", "tokens": ["Kurtz", "und", "des\u00b7to", "wah\u00b7rer", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rufft die Welt, so la\u00df es Nein,", "tokens": ["Rufft", "die", "Welt", ",", "so", "la\u00df", "es", "Nein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ADV", "VVIMP", "PPER", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ruffest du, ein Ja stets seyn.", "tokens": ["Ruf\u00b7fest", "du", ",", "ein", "Ja", "stets", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}