{"textgrid.poem.34334": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "62.", "genre": "verse", "period": "N.A.", "pub_year": 1775, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hasch ihn, Muse, den erhabenen Gedanken \u2013", "tokens": ["Hasch", "ihn", ",", "Mu\u00b7se", ",", "den", "er\u00b7ha\u00b7be\u00b7nen", "Ge\u00b7dan\u00b7ken", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "NN", "$,", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Es sind ihrer nicht mehr,", "tokens": ["Es", "sind", "ih\u00b7rer", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihre Schwestern haben die Griechen und R\u00f6mer", "tokens": ["Ih\u00b7re", "Schwes\u00b7tern", "ha\u00b7ben", "die", "Grie\u00b7chen", "und", "R\u00f6\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "KON", "NN"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und die Hetrurier weggehascht,", "tokens": ["Und", "die", "Het\u00b7ru\u00b7rier", "weg\u00b7ge\u00b7hascht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und die meisten ergriffen die k\u00fchnen Britten,", "tokens": ["Und", "die", "meis\u00b7ten", "er\u00b7grif\u00b7fen", "die", "k\u00fch\u00b7nen", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Und Shakespeare an ihrer Spitze,", "tokens": ["Und", "Sha\u00b7ke\u00b7spe\u00b7a\u00b7re", "an", "ih\u00b7rer", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und trugen sie alle fort wie der Sabiner sein M\u00e4dchen.", "tokens": ["Und", "tru\u00b7gen", "sie", "al\u00b7le", "fort", "wie", "der", "Sa\u00b7bi\u00b7ner", "sein", "M\u00e4d\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKVZ", "KOKOM", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.8": {"text": "Mancher brauchte sie zum andernmal,", "tokens": ["Man\u00b7cher", "brauch\u00b7te", "sie", "zum", "an\u00b7dern\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPRART", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Aber sie waren nicht mehr Jungfraun.", "tokens": ["A\u00b7ber", "sie", "wa\u00b7ren", "nicht", "mehr", "Jung\u00b7fraun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "$."], "meter": "+--+--+--", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "O traure, traure Deutschland,", "tokens": ["O", "trau\u00b7re", ",", "trau\u00b7re", "Deutschland", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ungl\u00fccklich Land! zu lange brach gelegen!", "tokens": ["Un\u00b7gl\u00fcck\u00b7lich", "Land", "!", "zu", "lan\u00b7ge", "brach", "ge\u00b7le\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$.", "APPR", "ADV", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Deine Nachbarinnen bl\u00fchen um dich her voll Fr\u00fcchte", "tokens": ["Dei\u00b7ne", "Nach\u00b7ba\u00b7rin\u00b7nen", "bl\u00fc\u00b7hen", "um", "dich", "her", "voll", "Fr\u00fcch\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PRF", "APZR", "ADJD", "NN"], "meter": "+-+-+-+---+-+-", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Wie goldbeladne H\u00fcgel um einen Morast,", "tokens": ["Wie", "gold\u00b7be\u00b7lad\u00b7ne", "H\u00fc\u00b7gel", "um", "ei\u00b7nen", "Mo\u00b7rast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wie junge kinderreiche Weiber", "tokens": ["Wie", "jun\u00b7ge", "kin\u00b7der\u00b7rei\u00b7che", "Wei\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Um ihre \u00e4lteste Schwester,", "tokens": ["Um", "ih\u00b7re", "\u00e4l\u00b7tes\u00b7te", "Schwes\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Die alte Jungfer blieb.", "tokens": ["Die", "al\u00b7te", "Jung\u00b7fer", "blieb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "O Homer, o Ossian, o Shakespeare,", "tokens": ["O", "Ho\u00b7mer", ",", "o", "Os\u00b7si\u00b7an", ",", "o", "Sha\u00b7ke\u00b7spe\u00b7a\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "NE", "$,", "FM", "NE", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "O Dante, o Ariosto, o Petrarcha,", "tokens": ["O", "Dan\u00b7te", ",", "o", "A\u00b7rios\u00b7to", ",", "o", "Pe\u00b7trar\u00b7cha", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "NE", "$,", "FM", "FM", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "O Sophokles, o Milton, o ihr untern Geister \u2013", "tokens": ["O", "So\u00b7phok\u00b7les", ",", "o", "Mil\u00b7ton", ",", "o", "ihr", "un\u00b7tern", "Geis\u00b7ter", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "NE", "$,", "FM", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "O ihr Pope, ihr Horaz, ihr Polizian, ihr Prior, ihr Waller!", "tokens": ["O", "ihr", "Po\u00b7pe", ",", "ihr", "Ho\u00b7raz", ",", "ihr", "Po\u00b7li\u00b7zi\u00b7an", ",", "ihr", "Pri\u00b7or", ",", "ihr", "Wal\u00b7ler", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "---+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Gebt mir tausend Zungen f\u00fcr die tausend Namen,", "tokens": ["Gebt", "mir", "tau\u00b7send", "Zun\u00b7gen", "f\u00fcr", "die", "tau\u00b7send", "Na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "CARD", "NN", "APPR", "ART", "CARD", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Und jeder Name ist ein k\u00fchner Gedanke \u2013", "tokens": ["Und", "je\u00b7der", "Na\u00b7me", "ist", "ein", "k\u00fch\u00b7ner", "Ge\u00b7dan\u00b7ke", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Ein Gedanke \u2013 tausend Gedanken", "tokens": ["Ein", "Ge\u00b7dan\u00b7ke", "\u2013", "tau\u00b7send", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "CARD", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Unsrer heutigen Dichter werth.", "tokens": ["Uns\u00b7rer", "heu\u00b7ti\u00b7gen", "Dich\u00b7ter", "werth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Deutschland, armes Deutschland,", "tokens": ["Deutschland", ",", "ar\u00b7mes", "Deutschland", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Die Kunst trieb kranke Stengel aus deinem Boden,", "tokens": ["Die", "Kunst", "trieb", "kran\u00b7ke", "Sten\u00b7gel", "aus", "dei\u00b7nem", "Bo\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "H\u00f6chstens matte Bl\u00fcthen,", "tokens": ["H\u00f6chs\u00b7tens", "mat\u00b7te", "Bl\u00fc\u00b7then", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die an den Aehren hingen vom Winde zerstreut,", "tokens": ["Die", "an", "den", "A\u00b7eh\u00b7ren", "hin\u00b7gen", "vom", "Win\u00b7de", "zer\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und in der H\u00fclse, wenns hoch kam,", "tokens": ["Und", "in", "der", "H\u00fcl\u00b7se", ",", "wenns", "hoch", "kam", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "KOUS", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Zwei K\u00f6rner Genie:", "tokens": ["Zwei", "K\u00f6r\u00b7ner", "Ge\u00b7nie", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Wenn ich dichte und \u2013 \u2013", "tokens": ["Wenn", "ich", "dich\u00b7te", "und", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "$(", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "O ich schmeichelte mir viel,", "tokens": ["O", "ich", "schmei\u00b7chel\u00b7te", "mir", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als nur dunkles Morgenroth", "tokens": ["Als", "nur", "dunk\u00b7les", "Mor\u00b7gen\u00b7roth"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von dem braunen Himmel um mich lachte.", "tokens": ["Von", "dem", "brau\u00b7nen", "Him\u00b7mel", "um", "mich", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Junge Blume, so dacht' ich,", "tokens": ["Jun\u00b7ge", "Blu\u00b7me", ",", "so", "dacht'", "ich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "O was f\u00fchlst du f\u00fcr S\u00e4fte emporsteigen,", "tokens": ["O", "was", "f\u00fchlst", "du", "f\u00fcr", "S\u00e4f\u00b7te", "em\u00b7por\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Welche Blume wirst du bl\u00fchen am Tage,", "tokens": ["Wel\u00b7che", "Blu\u00b7me", "wirst", "du", "bl\u00fc\u00b7hen", "am", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VAFIN", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Deutschlands Freude und Lieflands Stolz.", "tokens": ["Deutschlands", "Freu\u00b7de", "und", "Lie\u00b7flands", "Stolz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Als es aber Tag um mich ward,", "tokens": ["Als", "es", "a\u00b7ber", "Tag", "um", "mich", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "APPR", "PPER", "VAFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Kroch meine Bl\u00fcthe voll Schaam zur\u00fcck,", "tokens": ["Kroch", "mei\u00b7ne", "Bl\u00fc\u00b7the", "voll", "Schaam", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADJD", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Denn ich sah neben mir auf meinen Beeten Schwestern", "tokens": ["Denn", "ich", "sah", "ne\u00b7ben", "mir", "auf", "mei\u00b7nen", "Bee\u00b7ten", "Schwes\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Mit wohlriechenden Busen d\u00fcften,", "tokens": ["Mit", "wohl\u00b7rie\u00b7chen\u00b7den", "Bu\u00b7sen", "d\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Mit bescheidener R\u00f6the l\u00e4cheln.", "tokens": ["Mit", "be\u00b7schei\u00b7de\u00b7ner", "R\u00f6\u00b7the", "l\u00e4\u00b7cheln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Aber als der Mittag nieder auf mich sah,", "tokens": ["A\u00b7ber", "als", "der", "Mit\u00b7tag", "nie\u00b7der", "auf", "mich", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PTKVZ", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und ich auf benachbarten Beeten", "tokens": ["Und", "ich", "auf", "be\u00b7nach\u00b7bar\u00b7ten", "Bee\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Fremder Blumen himmlische Zier", "tokens": ["Frem\u00b7der", "Blu\u00b7men", "himm\u00b7li\u00b7sche", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit englischem Aushauch verbunden erblickte,", "tokens": ["Mit", "eng\u00b7li\u00b7schem", "Aus\u00b7hauch", "ver\u00b7bun\u00b7den", "er\u00b7blick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Wunder den Augen, der Nase, den Sinnen,", "tokens": ["Wun\u00b7der", "den", "Au\u00b7gen", ",", "der", "Na\u00b7se", ",", "den", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.6": {"text": "S\u00fc\u00dfes Wunder selbst dem stolzen kalten Verstande.", "tokens": ["S\u00fc\u00b7\u00dfes", "Wun\u00b7der", "selbst", "dem", "stol\u00b7zen", "kal\u00b7ten", "Ver\u00b7stan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}}, "stanza.8": {"line.1": {"text": "O da f\u00fchlt ich auf einem Sandkorn", "tokens": ["O", "da", "f\u00fchlt", "ich", "auf", "ei\u00b7nem", "Sand\u00b7korn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stehn eine Wurzel, ein Regentropfe", "tokens": ["Stehn", "ei\u00b7ne", "Wur\u00b7zel", ",", "ein", "Re\u00b7gen\u00b7trop\u00b7fe"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Seyn alle meine S\u00e4fte, ein Schmetterlingsfl\u00fcgelst\u00e4ubchen", "tokens": ["Seyn", "al\u00b7le", "mei\u00b7ne", "S\u00e4f\u00b7te", ",", "ein", "Schmet\u00b7ter\u00b7lings\u00b7fl\u00fc\u00b7gel\u00b7st\u00e4ub\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "PIAT", "PPOSAT", "NN", "$,", "ART", "NN"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Aller meiner Sch\u00f6nheit Zier! \u2013", "tokens": ["Al\u00b7ler", "mei\u00b7ner", "Sch\u00f6n\u00b7heit", "Zier", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nehmt sie an meine Zither", "tokens": ["Nehmt", "sie", "an", "mei\u00b7ne", "Zi\u00b7ther"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Eichen von Deutschland und la\u00dft von Petrarchen", "tokens": ["Ei\u00b7chen", "von", "Deutschland", "und", "la\u00dft", "von", "Pe\u00b7trar\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "KON", "VVFIN", "APPR", "NE"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Einen Ton ihre schnarrenden Sayten ber\u00fchren,", "tokens": ["Ei\u00b7nen", "Ton", "ih\u00b7re", "schnar\u00b7ren\u00b7den", "Say\u00b7ten", "be\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Da\u00df er mir ein Grablied singe \u2013!", "tokens": ["Da\u00df", "er", "mir", "ein", "Grab\u00b7lied", "sin\u00b7ge", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "$(", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unber\u00fchmt will ich sterben,", "tokens": ["Un\u00b7be\u00b7r\u00fchmt", "will", "ich", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Will in \u00f6dester W\u00fcste im schwarzen Thale mein Haupt hin", "tokens": ["Will", "in", "\u00f6\u00b7des\u00b7ter", "W\u00fcs\u00b7te", "im", "schwar\u00b7zen", "Tha\u00b7le", "mein", "Haupt", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJA", "NN", "APPRART", "ADJA", "NN", "PPOSAT", "NN", "PTKVZ"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.7": {"text": "Legen in Nacht, \u2013 kein Chor der J\u00fcnglinge soll um das Grab des J\u00fcnglings", "tokens": ["Le\u00b7gen", "in", "Nacht", ",", "\u2013", "kein", "Chor", "der", "J\u00fcng\u00b7lin\u00b7ge", "soll", "um", "das", "Grab", "des", "J\u00fcng\u00b7lings"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "$,", "$(", "PIAT", "NN", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+--+--+-+-", "measure": "iambic.septa.invert"}, "line.8": {"text": "Tanzen, keine M\u00e4dchen Blumen darauf gie\u00dfen,", "tokens": ["Tan\u00b7zen", ",", "kei\u00b7ne", "M\u00e4d\u00b7chen", "Blu\u00b7men", "da\u00b7rauf", "gie\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIAT", "NN", "NN", "PAV", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Kein Mensch soll drauf weinen Tr\u00e4nen voll Nachruhm,", "tokens": ["Kein", "Mensch", "soll", "drauf", "wei\u00b7nen", "Tr\u00e4\u00b7nen", "voll", "Nach\u00b7ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PAV", "ADJA", "NN", "ADJD", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Weil ich so verwegen, \u2013 so tollk\u00fchn gewesen", "tokens": ["Weil", "ich", "so", "ver\u00b7we\u00b7gen", ",", "\u2013", "so", "toll\u00b7k\u00fchn", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "$(", "ADV", "ADJD", "VAPP"], "meter": "-+--+-+++-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Weil auch ich es gewagt, zu dichten!", "tokens": ["Weil", "auch", "ich", "es", "ge\u00b7wagt", ",", "zu", "dich\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PPER", "VVPP", "$,", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Und du, mein Genius, wenn Gott mich w\u00fcrdig hielt", "tokens": ["Und", "du", ",", "mein", "Ge\u00b7nius", ",", "wenn", "Gott", "mich", "w\u00fcr\u00b7dig", "hielt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "PPOSAT", "NN", "$,", "KOUS", "NN", "PPER", "ADJD", "VVFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Einen mir zum Geleit zu geben,", "tokens": ["Ei\u00b7nen", "mir", "zum", "Ge\u00b7leit", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sch\u00fctze, treuer Gef\u00e4hrte des Lebens,", "tokens": ["Sch\u00fct\u00b7ze", ",", "treu\u00b7er", "Ge\u00b7f\u00e4hr\u00b7te", "des", "Le\u00b7bens", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sch\u00fctze mein einsames Grab,", "tokens": ["Sch\u00fct\u00b7ze", "mein", "ein\u00b7sa\u00b7mes", "Grab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df kein Blick aus dem Reiche der Seeligen", "tokens": ["Da\u00df", "kein", "Blick", "aus", "dem", "Rei\u00b7che", "der", "See\u00b7li\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "APPR", "ART", "NE", "ART", "NN"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Von Shakespeares brennendem Auge,", "tokens": ["Von", "Sha\u00b7ke\u00b7spe\u00b7a\u00b7res", "bren\u00b7nen\u00b7dem", "Au\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Oder dem d\u00fcsterleuchtenden Auge Ossians,", "tokens": ["O\u00b7der", "dem", "d\u00fcs\u00b7ter\u00b7leuch\u00b7ten\u00b7den", "Au\u00b7ge", "Os\u00b7si\u00b7ans", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Oder dem rothblitzenden Auge Homers,", "tokens": ["O\u00b7der", "dem", "roth\u00b7blit\u00b7zen\u00b7den", "Au\u00b7ge", "Ho\u00b7mers", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.9": {"text": "Sich auf dasselbe verirre,", "tokens": ["Sich", "auf", "das\u00b7sel\u00b7be", "ver\u00b7ir\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PDAT", "ADJA", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Damit sich meine Asche im Grabe nicht emp\u00f6re", "tokens": ["Da\u00b7mit", "sich", "mei\u00b7ne", "A\u00b7sche", "im", "Gra\u00b7be", "nicht", "em\u00b7p\u00f6\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "APPRART", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "F\u00fcr Schaam, da\u00df auch ich einst wagte zu dichten!", "tokens": ["F\u00fcr", "Schaam", ",", "da\u00df", "auch", "ich", "einst", "wag\u00b7te", "zu", "dich\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "ADV", "PPER", "ADV", "VVFIN", "APPR", "ADJA", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Hasch ihn, Muse, den erhabenen Gedanken \u2013", "tokens": ["Hasch", "ihn", ",", "Mu\u00b7se", ",", "den", "er\u00b7ha\u00b7be\u00b7nen", "Ge\u00b7dan\u00b7ken", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "NN", "$,", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Es sind ihrer nicht mehr,", "tokens": ["Es", "sind", "ih\u00b7rer", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihre Schwestern haben die Griechen und R\u00f6mer", "tokens": ["Ih\u00b7re", "Schwes\u00b7tern", "ha\u00b7ben", "die", "Grie\u00b7chen", "und", "R\u00f6\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "KON", "NN"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und die Hetrurier weggehascht,", "tokens": ["Und", "die", "Het\u00b7ru\u00b7rier", "weg\u00b7ge\u00b7hascht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und die meisten ergriffen die k\u00fchnen Britten,", "tokens": ["Und", "die", "meis\u00b7ten", "er\u00b7grif\u00b7fen", "die", "k\u00fch\u00b7nen", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Und Shakespeare an ihrer Spitze,", "tokens": ["Und", "Sha\u00b7ke\u00b7spe\u00b7a\u00b7re", "an", "ih\u00b7rer", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und trugen sie alle fort wie der Sabiner sein M\u00e4dchen.", "tokens": ["Und", "tru\u00b7gen", "sie", "al\u00b7le", "fort", "wie", "der", "Sa\u00b7bi\u00b7ner", "sein", "M\u00e4d\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKVZ", "KOKOM", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.8": {"text": "Mancher brauchte sie zum andernmal,", "tokens": ["Man\u00b7cher", "brauch\u00b7te", "sie", "zum", "an\u00b7dern\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPRART", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Aber sie waren nicht mehr Jungfraun.", "tokens": ["A\u00b7ber", "sie", "wa\u00b7ren", "nicht", "mehr", "Jung\u00b7fraun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "$."], "meter": "+--+--+--", "measure": "dactylic.tri"}}, "stanza.12": {"line.1": {"text": "O traure, traure Deutschland,", "tokens": ["O", "trau\u00b7re", ",", "trau\u00b7re", "Deutschland", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ungl\u00fccklich Land! zu lange brach gelegen!", "tokens": ["Un\u00b7gl\u00fcck\u00b7lich", "Land", "!", "zu", "lan\u00b7ge", "brach", "ge\u00b7le\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$.", "APPR", "ADV", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Deine Nachbarinnen bl\u00fchen um dich her voll Fr\u00fcchte", "tokens": ["Dei\u00b7ne", "Nach\u00b7ba\u00b7rin\u00b7nen", "bl\u00fc\u00b7hen", "um", "dich", "her", "voll", "Fr\u00fcch\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PRF", "APZR", "ADJD", "NN"], "meter": "+-+-+-+---+-+-", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Wie goldbeladne H\u00fcgel um einen Morast,", "tokens": ["Wie", "gold\u00b7be\u00b7lad\u00b7ne", "H\u00fc\u00b7gel", "um", "ei\u00b7nen", "Mo\u00b7rast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wie junge kinderreiche Weiber", "tokens": ["Wie", "jun\u00b7ge", "kin\u00b7der\u00b7rei\u00b7che", "Wei\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Um ihre \u00e4lteste Schwester,", "tokens": ["Um", "ih\u00b7re", "\u00e4l\u00b7tes\u00b7te", "Schwes\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Die alte Jungfer blieb.", "tokens": ["Die", "al\u00b7te", "Jung\u00b7fer", "blieb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "O Homer, o Ossian, o Shakespeare,", "tokens": ["O", "Ho\u00b7mer", ",", "o", "Os\u00b7si\u00b7an", ",", "o", "Sha\u00b7ke\u00b7spe\u00b7a\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "NE", "$,", "FM", "NE", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "O Dante, o Ariosto, o Petrarcha,", "tokens": ["O", "Dan\u00b7te", ",", "o", "A\u00b7rios\u00b7to", ",", "o", "Pe\u00b7trar\u00b7cha", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "NE", "$,", "FM", "FM", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "O Sophokles, o Milton, o ihr untern Geister \u2013", "tokens": ["O", "So\u00b7phok\u00b7les", ",", "o", "Mil\u00b7ton", ",", "o", "ihr", "un\u00b7tern", "Geis\u00b7ter", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "FM", "NE", "$,", "FM", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "O ihr Pope, ihr Horaz, ihr Polizian, ihr Prior, ihr Waller!", "tokens": ["O", "ihr", "Po\u00b7pe", ",", "ihr", "Ho\u00b7raz", ",", "ihr", "Po\u00b7li\u00b7zi\u00b7an", ",", "ihr", "Pri\u00b7or", ",", "ihr", "Wal\u00b7ler", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "---+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Gebt mir tausend Zungen f\u00fcr die tausend Namen,", "tokens": ["Gebt", "mir", "tau\u00b7send", "Zun\u00b7gen", "f\u00fcr", "die", "tau\u00b7send", "Na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "CARD", "NN", "APPR", "ART", "CARD", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Und jeder Name ist ein k\u00fchner Gedanke \u2013", "tokens": ["Und", "je\u00b7der", "Na\u00b7me", "ist", "ein", "k\u00fch\u00b7ner", "Ge\u00b7dan\u00b7ke", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Ein Gedanke \u2013 tausend Gedanken", "tokens": ["Ein", "Ge\u00b7dan\u00b7ke", "\u2013", "tau\u00b7send", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "CARD", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Unsrer heutigen Dichter werth.", "tokens": ["Uns\u00b7rer", "heu\u00b7ti\u00b7gen", "Dich\u00b7ter", "werth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.14": {"line.1": {"text": "Deutschland, armes Deutschland,", "tokens": ["Deutschland", ",", "ar\u00b7mes", "Deutschland", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Die Kunst trieb kranke Stengel aus deinem Boden,", "tokens": ["Die", "Kunst", "trieb", "kran\u00b7ke", "Sten\u00b7gel", "aus", "dei\u00b7nem", "Bo\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "H\u00f6chstens matte Bl\u00fcthen,", "tokens": ["H\u00f6chs\u00b7tens", "mat\u00b7te", "Bl\u00fc\u00b7then", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die an den Aehren hingen vom Winde zerstreut,", "tokens": ["Die", "an", "den", "A\u00b7eh\u00b7ren", "hin\u00b7gen", "vom", "Win\u00b7de", "zer\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und in der H\u00fclse, wenns hoch kam,", "tokens": ["Und", "in", "der", "H\u00fcl\u00b7se", ",", "wenns", "hoch", "kam", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "KOUS", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Zwei K\u00f6rner Genie:", "tokens": ["Zwei", "K\u00f6r\u00b7ner", "Ge\u00b7nie", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Wenn ich dichte und \u2013 \u2013", "tokens": ["Wenn", "ich", "dich\u00b7te", "und", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "$(", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "O ich schmeichelte mir viel,", "tokens": ["O", "ich", "schmei\u00b7chel\u00b7te", "mir", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als nur dunkles Morgenroth", "tokens": ["Als", "nur", "dunk\u00b7les", "Mor\u00b7gen\u00b7roth"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von dem braunen Himmel um mich lachte.", "tokens": ["Von", "dem", "brau\u00b7nen", "Him\u00b7mel", "um", "mich", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Junge Blume, so dacht' ich,", "tokens": ["Jun\u00b7ge", "Blu\u00b7me", ",", "so", "dacht'", "ich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "O was f\u00fchlst du f\u00fcr S\u00e4fte emporsteigen,", "tokens": ["O", "was", "f\u00fchlst", "du", "f\u00fcr", "S\u00e4f\u00b7te", "em\u00b7por\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Welche Blume wirst du bl\u00fchen am Tage,", "tokens": ["Wel\u00b7che", "Blu\u00b7me", "wirst", "du", "bl\u00fc\u00b7hen", "am", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VAFIN", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Deutschlands Freude und Lieflands Stolz.", "tokens": ["Deutschlands", "Freu\u00b7de", "und", "Lie\u00b7flands", "Stolz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Als es aber Tag um mich ward,", "tokens": ["Als", "es", "a\u00b7ber", "Tag", "um", "mich", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "APPR", "PPER", "VAFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Kroch meine Bl\u00fcthe voll Schaam zur\u00fcck,", "tokens": ["Kroch", "mei\u00b7ne", "Bl\u00fc\u00b7the", "voll", "Schaam", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADJD", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Denn ich sah neben mir auf meinen Beeten Schwestern", "tokens": ["Denn", "ich", "sah", "ne\u00b7ben", "mir", "auf", "mei\u00b7nen", "Bee\u00b7ten", "Schwes\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Mit wohlriechenden Busen d\u00fcften,", "tokens": ["Mit", "wohl\u00b7rie\u00b7chen\u00b7den", "Bu\u00b7sen", "d\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Mit bescheidener R\u00f6the l\u00e4cheln.", "tokens": ["Mit", "be\u00b7schei\u00b7de\u00b7ner", "R\u00f6\u00b7the", "l\u00e4\u00b7cheln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Aber als der Mittag nieder auf mich sah,", "tokens": ["A\u00b7ber", "als", "der", "Mit\u00b7tag", "nie\u00b7der", "auf", "mich", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PTKVZ", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und ich auf benachbarten Beeten", "tokens": ["Und", "ich", "auf", "be\u00b7nach\u00b7bar\u00b7ten", "Bee\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Fremder Blumen himmlische Zier", "tokens": ["Frem\u00b7der", "Blu\u00b7men", "himm\u00b7li\u00b7sche", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit englischem Aushauch verbunden erblickte,", "tokens": ["Mit", "eng\u00b7li\u00b7schem", "Aus\u00b7hauch", "ver\u00b7bun\u00b7den", "er\u00b7blick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Wunder den Augen, der Nase, den Sinnen,", "tokens": ["Wun\u00b7der", "den", "Au\u00b7gen", ",", "der", "Na\u00b7se", ",", "den", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.6": {"text": "S\u00fc\u00dfes Wunder selbst dem stolzen kalten Verstande.", "tokens": ["S\u00fc\u00b7\u00dfes", "Wun\u00b7der", "selbst", "dem", "stol\u00b7zen", "kal\u00b7ten", "Ver\u00b7stan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}}, "stanza.18": {"line.1": {"text": "O da f\u00fchlt ich auf einem Sandkorn", "tokens": ["O", "da", "f\u00fchlt", "ich", "auf", "ei\u00b7nem", "Sand\u00b7korn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stehn eine Wurzel, ein Regentropfe", "tokens": ["Stehn", "ei\u00b7ne", "Wur\u00b7zel", ",", "ein", "Re\u00b7gen\u00b7trop\u00b7fe"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Seyn alle meine S\u00e4fte, ein Schmetterlingsfl\u00fcgelst\u00e4ubchen", "tokens": ["Seyn", "al\u00b7le", "mei\u00b7ne", "S\u00e4f\u00b7te", ",", "ein", "Schmet\u00b7ter\u00b7lings\u00b7fl\u00fc\u00b7gel\u00b7st\u00e4ub\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "PIAT", "PPOSAT", "NN", "$,", "ART", "NN"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Aller meiner Sch\u00f6nheit Zier! \u2013", "tokens": ["Al\u00b7ler", "mei\u00b7ner", "Sch\u00f6n\u00b7heit", "Zier", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Nehmt sie an meine Zither", "tokens": ["Nehmt", "sie", "an", "mei\u00b7ne", "Zi\u00b7ther"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Eichen von Deutschland und la\u00dft von Petrarchen", "tokens": ["Ei\u00b7chen", "von", "Deutschland", "und", "la\u00dft", "von", "Pe\u00b7trar\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "KON", "VVFIN", "APPR", "NE"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Einen Ton ihre schnarrenden Sayten ber\u00fchren,", "tokens": ["Ei\u00b7nen", "Ton", "ih\u00b7re", "schnar\u00b7ren\u00b7den", "Say\u00b7ten", "be\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Da\u00df er mir ein Grablied singe \u2013!", "tokens": ["Da\u00df", "er", "mir", "ein", "Grab\u00b7lied", "sin\u00b7ge", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "$(", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unber\u00fchmt will ich sterben,", "tokens": ["Un\u00b7be\u00b7r\u00fchmt", "will", "ich", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Will in \u00f6dester W\u00fcste im schwarzen Thale mein Haupt hin", "tokens": ["Will", "in", "\u00f6\u00b7des\u00b7ter", "W\u00fcs\u00b7te", "im", "schwar\u00b7zen", "Tha\u00b7le", "mein", "Haupt", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJA", "NN", "APPRART", "ADJA", "NN", "PPOSAT", "NN", "PTKVZ"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.7": {"text": "Legen in Nacht, \u2013 kein Chor der J\u00fcnglinge soll um das Grab des J\u00fcnglings", "tokens": ["Le\u00b7gen", "in", "Nacht", ",", "\u2013", "kein", "Chor", "der", "J\u00fcng\u00b7lin\u00b7ge", "soll", "um", "das", "Grab", "des", "J\u00fcng\u00b7lings"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "$,", "$(", "PIAT", "NN", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+--+--+-+-", "measure": "iambic.septa.invert"}, "line.8": {"text": "Tanzen, keine M\u00e4dchen Blumen darauf gie\u00dfen,", "tokens": ["Tan\u00b7zen", ",", "kei\u00b7ne", "M\u00e4d\u00b7chen", "Blu\u00b7men", "da\u00b7rauf", "gie\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIAT", "NN", "NN", "PAV", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Kein Mensch soll drauf weinen Tr\u00e4nen voll Nachruhm,", "tokens": ["Kein", "Mensch", "soll", "drauf", "wei\u00b7nen", "Tr\u00e4\u00b7nen", "voll", "Nach\u00b7ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PAV", "ADJA", "NN", "ADJD", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Weil ich so verwegen, \u2013 so tollk\u00fchn gewesen", "tokens": ["Weil", "ich", "so", "ver\u00b7we\u00b7gen", ",", "\u2013", "so", "toll\u00b7k\u00fchn", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "$(", "ADV", "ADJD", "VAPP"], "meter": "-+--+-+++-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Weil auch ich es gewagt, zu dichten!", "tokens": ["Weil", "auch", "ich", "es", "ge\u00b7wagt", ",", "zu", "dich\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PPER", "VVPP", "$,", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Und du, mein Genius, wenn Gott mich w\u00fcrdig hielt", "tokens": ["Und", "du", ",", "mein", "Ge\u00b7nius", ",", "wenn", "Gott", "mich", "w\u00fcr\u00b7dig", "hielt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "PPOSAT", "NN", "$,", "KOUS", "NN", "PPER", "ADJD", "VVFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Einen mir zum Geleit zu geben,", "tokens": ["Ei\u00b7nen", "mir", "zum", "Ge\u00b7leit", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sch\u00fctze, treuer Gef\u00e4hrte des Lebens,", "tokens": ["Sch\u00fct\u00b7ze", ",", "treu\u00b7er", "Ge\u00b7f\u00e4hr\u00b7te", "des", "Le\u00b7bens", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sch\u00fctze mein einsames Grab,", "tokens": ["Sch\u00fct\u00b7ze", "mein", "ein\u00b7sa\u00b7mes", "Grab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df kein Blick aus dem Reiche der Seeligen", "tokens": ["Da\u00df", "kein", "Blick", "aus", "dem", "Rei\u00b7che", "der", "See\u00b7li\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "APPR", "ART", "NE", "ART", "NN"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Von Shakespeares brennendem Auge,", "tokens": ["Von", "Sha\u00b7ke\u00b7spe\u00b7a\u00b7res", "bren\u00b7nen\u00b7dem", "Au\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Oder dem d\u00fcsterleuchtenden Auge Ossians,", "tokens": ["O\u00b7der", "dem", "d\u00fcs\u00b7ter\u00b7leuch\u00b7ten\u00b7den", "Au\u00b7ge", "Os\u00b7si\u00b7ans", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Oder dem rothblitzenden Auge Homers,", "tokens": ["O\u00b7der", "dem", "roth\u00b7blit\u00b7zen\u00b7den", "Au\u00b7ge", "Ho\u00b7mers", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.9": {"text": "Sich auf dasselbe verirre,", "tokens": ["Sich", "auf", "das\u00b7sel\u00b7be", "ver\u00b7ir\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PDAT", "ADJA", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Damit sich meine Asche im Grabe nicht emp\u00f6re", "tokens": ["Da\u00b7mit", "sich", "mei\u00b7ne", "A\u00b7sche", "im", "Gra\u00b7be", "nicht", "em\u00b7p\u00f6\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "APPRART", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "F\u00fcr Schaam, da\u00df auch ich einst wagte zu dichten!", "tokens": ["F\u00fcr", "Schaam", ",", "da\u00df", "auch", "ich", "einst", "wag\u00b7te", "zu", "dich\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "ADV", "PPER", "ADV", "VVFIN", "APPR", "ADJA", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}}}}