{"textgrid.poem.42070": {"metadata": {"author": {"name": "Weissmann, Maria Luise", "birth": "N.A.", "death": "N.A."}, "title": "Robinson findet Spuren der Kannibalen", "genre": "verse", "period": "N.A.", "pub_year": 1914, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O Insel: fa\u00df ich dich zum ersten Mal?!", "tokens": ["O", "In\u00b7sel", ":", "fa\u00df", "ich", "dich", "zum", "ers\u00b7ten", "Mal", "?!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "VVFIN", "PPER", "PRF", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Eiland mit Flu\u00df, mit Bergen, einem Tal", "tokens": ["Ei\u00b7land", "mit", "Flu\u00df", ",", "mit", "Ber\u00b7gen", ",", "ei\u00b7nem", "Tal"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "NN", "$,", "APPR", "NN", "$,", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und Wasser ringsum, Wasser ringsumher.", "tokens": ["Und", "Was\u00b7ser", "ring\u00b7sum", ",", "Was\u00b7ser", "rings\u00b7um\u00b7her", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$,", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mein Schritt versinkt, mein armer Schritt wird schwer,", "tokens": ["Mein", "Schritt", "ver\u00b7sinkt", ",", "mein", "ar\u00b7mer", "Schritt", "wird", "schwer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mein Schritt bricht noch durch Grund in lauter Wasser ein.", "tokens": ["Mein", "Schritt", "bricht", "noch", "durch", "Grund", "in", "lau\u00b7ter", "Was\u00b7ser", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie pries ich Land: die Steppe, W\u00fcstenein!", "tokens": ["Wie", "pries", "ich", "Land", ":", "die", "Step\u00b7pe", ",", "W\u00fcs\u00b7ten\u00b7ein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "NN", "$.", "ART", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich lief und liefe. Da\u00df die Horizonte", "tokens": ["Ich", "lief", "und", "lie\u00b7fe", ".", "Da\u00df", "die", "Ho\u00b7ri\u00b7zon\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sich t\u00fcrmten hinter mir. Ich lief durch Monde,", "tokens": ["Sich", "t\u00fcrm\u00b7ten", "hin\u00b7ter", "mir", ".", "Ich", "lief", "durch", "Mon\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Durch Jahre lief ich so... Hier steh ich, Stein.", "tokens": ["Durch", "Jah\u00b7re", "lief", "ich", "so", "...", "Hier", "steh", "ich", ",", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "$(", "ADV", "VVFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wem eine Insel wurde, da zu sein,", "tokens": ["Wem", "ei\u00b7ne", "In\u00b7sel", "wur\u00b7de", ",", "da", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VAFIN", "$,", "ADV", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Der wird nicht weit vor dem Entsetzen weichen,", "tokens": ["Der", "wird", "nicht", "weit", "vor", "dem", "Ent\u00b7set\u00b7zen", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Es wird zuletzt ihn irgendwo erreichen", "tokens": ["Es", "wird", "zu\u00b7letzt", "ihn", "ir\u00b7gend\u00b7wo", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Im schmalen Rund: Er mu\u00df benachbart stehn", "tokens": ["Im", "schma\u00b7len", "Rund", ":", "Er", "mu\u00df", "be\u00b7nach\u00b7bart", "stehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$.", "PPER", "VMFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Jedweder Tat. Ihr nahes Antlitz sehn.", "tokens": ["Jed\u00b7we\u00b7der", "Tat", ".", "Ihr", "na\u00b7hes", "Ant\u00b7litz", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "O Insel: fa\u00df ich dich zum ersten Mal?!", "tokens": ["O", "In\u00b7sel", ":", "fa\u00df", "ich", "dich", "zum", "ers\u00b7ten", "Mal", "?!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "VVFIN", "PPER", "PRF", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Eiland mit Flu\u00df, mit Bergen, einem Tal", "tokens": ["Ei\u00b7land", "mit", "Flu\u00df", ",", "mit", "Ber\u00b7gen", ",", "ei\u00b7nem", "Tal"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "NN", "$,", "APPR", "NN", "$,", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und Wasser ringsum, Wasser ringsumher.", "tokens": ["Und", "Was\u00b7ser", "ring\u00b7sum", ",", "Was\u00b7ser", "rings\u00b7um\u00b7her", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$,", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mein Schritt versinkt, mein armer Schritt wird schwer,", "tokens": ["Mein", "Schritt", "ver\u00b7sinkt", ",", "mein", "ar\u00b7mer", "Schritt", "wird", "schwer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mein Schritt bricht noch durch Grund in lauter Wasser ein.", "tokens": ["Mein", "Schritt", "bricht", "noch", "durch", "Grund", "in", "lau\u00b7ter", "Was\u00b7ser", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie pries ich Land: die Steppe, W\u00fcstenein!", "tokens": ["Wie", "pries", "ich", "Land", ":", "die", "Step\u00b7pe", ",", "W\u00fcs\u00b7ten\u00b7ein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "NN", "$.", "ART", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich lief und liefe. Da\u00df die Horizonte", "tokens": ["Ich", "lief", "und", "lie\u00b7fe", ".", "Da\u00df", "die", "Ho\u00b7ri\u00b7zon\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sich t\u00fcrmten hinter mir. Ich lief durch Monde,", "tokens": ["Sich", "t\u00fcrm\u00b7ten", "hin\u00b7ter", "mir", ".", "Ich", "lief", "durch", "Mon\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Durch Jahre lief ich so... Hier steh ich, Stein.", "tokens": ["Durch", "Jah\u00b7re", "lief", "ich", "so", "...", "Hier", "steh", "ich", ",", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "$(", "ADV", "VVFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wem eine Insel wurde, da zu sein,", "tokens": ["Wem", "ei\u00b7ne", "In\u00b7sel", "wur\u00b7de", ",", "da", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VAFIN", "$,", "ADV", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Der wird nicht weit vor dem Entsetzen weichen,", "tokens": ["Der", "wird", "nicht", "weit", "vor", "dem", "Ent\u00b7set\u00b7zen", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Es wird zuletzt ihn irgendwo erreichen", "tokens": ["Es", "wird", "zu\u00b7letzt", "ihn", "ir\u00b7gend\u00b7wo", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Im schmalen Rund: Er mu\u00df benachbart stehn", "tokens": ["Im", "schma\u00b7len", "Rund", ":", "Er", "mu\u00df", "be\u00b7nach\u00b7bart", "stehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$.", "PPER", "VMFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Jedweder Tat. Ihr nahes Antlitz sehn.", "tokens": ["Jed\u00b7we\u00b7der", "Tat", ".", "Ihr", "na\u00b7hes", "Ant\u00b7litz", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}