{"textgrid.poem.37381": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ach, wie vieles mu\u00df man r\u00fcgen,", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach, wie vieles mu\u00df man r\u00fcgen,", "tokens": ["Ach", ",", "wie", "vie\u00b7les", "mu\u00df", "man", "r\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "PIS", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil es s\u00fcndlich und gemein,", "tokens": ["Weil", "es", "s\u00fcnd\u00b7lich", "und", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So zum Beispiel das Vergn\u00fcgen,", "tokens": ["So", "zum", "Bei\u00b7spiel", "das", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zuzusehn bei Pr\u00fcgelein.", "tokens": ["Zu\u00b7zu\u00b7sehn", "bei", "Pr\u00fc\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Noch vor kurzem hab ich selber", "tokens": ["Noch", "vor", "kur\u00b7zem", "hab", "ich", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir zwei Gockel angesehn,", "tokens": ["Mir", "zwei", "Go\u00b7ckel", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier ein schwarzer, da ein gelber,", "tokens": ["Hier", "ein", "schwar\u00b7zer", ",", "da", "ein", "gel\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "KOUS", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die nicht gut zusammenstehn.", "tokens": ["Die", "nicht", "gut", "zu\u00b7sam\u00b7men\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Pl\u00f6tzlich kam es zum Skandale,", "tokens": ["Pl\u00f6tz\u00b7lich", "kam", "es", "zum", "Skan\u00b7da\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "Denn der schwarze macht die Kur,", "tokens": ["Denn", "der", "schwar\u00b7ze", "macht", "die", "Kur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was dem gelben alle Male", "tokens": ["Was", "dem", "gel\u00b7ben", "al\u00b7le", "Ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Peinlich durch die Seele fuhr.", "tokens": ["Pein\u00b7lich", "durch", "die", "See\u00b7le", "fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Mit den Krallen, mit den Sporen,", "tokens": ["Mit", "den", "Kral\u00b7len", ",", "mit", "den", "Spo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit dem Schnabel, scharf gewetzt,", "tokens": ["Mit", "dem", "Schna\u00b7bel", ",", "scharf", "ge\u00b7wetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit den Fl\u00fcgeln um die Ohren", "tokens": ["Mit", "den", "Fl\u00fc\u00b7geln", "um", "die", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat es Hieb auf Hieb gesetzt.", "tokens": ["Hat", "es", "Hieb", "auf", "Hieb", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Manche Feder aus dem Leder", "tokens": ["Man\u00b7che", "Fe\u00b7der", "aus", "dem", "Le\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rei\u00dfen und zerschlei\u00dfen sie,", "tokens": ["Rei\u00b7\u00dfen", "und", "zer\u00b7schlei\u00b7\u00dfen", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zum Schlusse ruft ein jeder", "tokens": ["Und", "zum", "Schlus\u00b7se", "ruft", "ein", "je\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "ART", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Triumphierend Kikriki!", "tokens": ["Tri\u00b7um\u00b7phie\u00b7rend", "Kik\u00b7ri\u00b7ki", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Voller Freude und mit wahrem", "tokens": ["Vol\u00b7ler", "Freu\u00b7de", "und", "mit", "wah\u00b7rem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eifer sah ich diesen Zwist,", "tokens": ["Ei\u00b7fer", "sah", "ich", "die\u00b7sen", "Zwist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend jedes Huhn im Harem", "tokens": ["W\u00e4h\u00b7rend", "je\u00b7des", "Huhn", "im", "Ha\u00b7rem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00f6chst gelassen weiterfri\u00dft.", "tokens": ["H\u00f6chst", "ge\u00b7las\u00b7sen", "wei\u00b7ter\u00b7fri\u00dft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Solch ein Weibervolk mit Fl\u00fcgeln", "tokens": ["Solch", "ein", "Wei\u00b7ber\u00b7volk", "mit", "Fl\u00fc\u00b7geln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meint, wenn Gockel fr\u00fch und sp\u00e4t", "tokens": ["Meint", ",", "wenn", "Go\u00b7ckel", "fr\u00fch", "und", "sp\u00e4t"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "NN", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seinetwegen sich verpr\u00fcgeln,", "tokens": ["Sei\u00b7net\u00b7we\u00b7gen", "sich", "ver\u00b7pr\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sich das von selbst versteht.", "tokens": ["Da\u00df", "sich", "das", "von", "selbst", "ver\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ach, wie vieles mu\u00df man r\u00fcgen,", "tokens": ["Ach", ",", "wie", "vie\u00b7les", "mu\u00df", "man", "r\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "PIS", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil es s\u00fcndlich und gemein,", "tokens": ["Weil", "es", "s\u00fcnd\u00b7lich", "und", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So zum Beispiel das Vergn\u00fcgen,", "tokens": ["So", "zum", "Bei\u00b7spiel", "das", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zuzusehn bei Pr\u00fcgelein.", "tokens": ["Zu\u00b7zu\u00b7sehn", "bei", "Pr\u00fc\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Noch vor kurzem hab ich selber", "tokens": ["Noch", "vor", "kur\u00b7zem", "hab", "ich", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir zwei Gockel angesehn,", "tokens": ["Mir", "zwei", "Go\u00b7ckel", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier ein schwarzer, da ein gelber,", "tokens": ["Hier", "ein", "schwar\u00b7zer", ",", "da", "ein", "gel\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "KOUS", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die nicht gut zusammenstehn.", "tokens": ["Die", "nicht", "gut", "zu\u00b7sam\u00b7men\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Pl\u00f6tzlich kam es zum Skandale,", "tokens": ["Pl\u00f6tz\u00b7lich", "kam", "es", "zum", "Skan\u00b7da\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "Denn der schwarze macht die Kur,", "tokens": ["Denn", "der", "schwar\u00b7ze", "macht", "die", "Kur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was dem gelben alle Male", "tokens": ["Was", "dem", "gel\u00b7ben", "al\u00b7le", "Ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Peinlich durch die Seele fuhr.", "tokens": ["Pein\u00b7lich", "durch", "die", "See\u00b7le", "fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Mit den Krallen, mit den Sporen,", "tokens": ["Mit", "den", "Kral\u00b7len", ",", "mit", "den", "Spo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit dem Schnabel, scharf gewetzt,", "tokens": ["Mit", "dem", "Schna\u00b7bel", ",", "scharf", "ge\u00b7wetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit den Fl\u00fcgeln um die Ohren", "tokens": ["Mit", "den", "Fl\u00fc\u00b7geln", "um", "die", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat es Hieb auf Hieb gesetzt.", "tokens": ["Hat", "es", "Hieb", "auf", "Hieb", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Manche Feder aus dem Leder", "tokens": ["Man\u00b7che", "Fe\u00b7der", "aus", "dem", "Le\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rei\u00dfen und zerschlei\u00dfen sie,", "tokens": ["Rei\u00b7\u00dfen", "und", "zer\u00b7schlei\u00b7\u00dfen", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zum Schlusse ruft ein jeder", "tokens": ["Und", "zum", "Schlus\u00b7se", "ruft", "ein", "je\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "ART", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Triumphierend Kikriki!", "tokens": ["Tri\u00b7um\u00b7phie\u00b7rend", "Kik\u00b7ri\u00b7ki", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Voller Freude und mit wahrem", "tokens": ["Vol\u00b7ler", "Freu\u00b7de", "und", "mit", "wah\u00b7rem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eifer sah ich diesen Zwist,", "tokens": ["Ei\u00b7fer", "sah", "ich", "die\u00b7sen", "Zwist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend jedes Huhn im Harem", "tokens": ["W\u00e4h\u00b7rend", "je\u00b7des", "Huhn", "im", "Ha\u00b7rem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "H\u00f6chst gelassen weiterfri\u00dft.", "tokens": ["H\u00f6chst", "ge\u00b7las\u00b7sen", "wei\u00b7ter\u00b7fri\u00dft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Solch ein Weibervolk mit Fl\u00fcgeln", "tokens": ["Solch", "ein", "Wei\u00b7ber\u00b7volk", "mit", "Fl\u00fc\u00b7geln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meint, wenn Gockel fr\u00fch und sp\u00e4t", "tokens": ["Meint", ",", "wenn", "Go\u00b7ckel", "fr\u00fch", "und", "sp\u00e4t"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "NN", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seinetwegen sich verpr\u00fcgeln,", "tokens": ["Sei\u00b7net\u00b7we\u00b7gen", "sich", "ver\u00b7pr\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sich das von selbst versteht.", "tokens": ["Da\u00df", "sich", "das", "von", "selbst", "ver\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}