{"textgrid.poem.64142": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zw\u00f6lf K\u00f6nige herrschten in Norgeland:", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zw\u00f6lf K\u00f6nige herrschten in Norgeland:", "tokens": ["Zw\u00f6lf", "K\u00f6\u00b7ni\u00b7ge", "herrschten", "in", "Nor\u00b7ge\u00b7land", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "NE", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das waren um elf zu viel:", "tokens": ["Das", "wa\u00b7ren", "um", "elf", "zu", "viel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "CARD", "PTKA", "PIS", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie Harald die andern \u00fcberwand,", "tokens": ["Wie", "Ha\u00b7rald", "die", "an\u00b7dern", "\u00fc\u00b7ber\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das singt man zu Harfenspiel. \u2013", "tokens": ["Das", "singt", "man", "zu", "Har\u00b7fen\u00b7spiel", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "NE", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Zwolfk\u00f6nig Harald von Hadaland,", "tokens": ["Zwolf\u00b7k\u00f6\u00b7nig", "Ha\u00b7rald", "von", "Ha\u00b7da\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Zu jagen ritt er nach Mochter:", "tokens": ["Zu", "ja\u00b7gen", "ritt", "er", "nach", "Moch\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sch\u00f6n Gydha vor ihrem Hoftor stand,", "tokens": ["Sch\u00f6n", "Gy\u00b7dha", "vor", "ih\u00b7rem", "Hof\u00b7tor", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Des Odalbauern Tochter.", "tokens": ["Des", "O\u00b7dal\u00b7bau\u00b7ern", "Toch\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die schlanken H\u00fcften ihr stolz umfing", "tokens": ["Die", "schlan\u00b7ken", "H\u00fcf\u00b7ten", "ihr", "stolz", "um\u00b7fing"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPER", "ADJD", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Goldg\u00fcrtel, an Steinen reich:", "tokens": ["Gold\u00b7g\u00fcr\u00b7tel", ",", "an", "Stei\u00b7nen", "reich", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Noch goldener gl\u00e4nzte des Goldhaars Ring", "tokens": ["Noch", "gol\u00b7de\u00b7ner", "gl\u00e4nz\u00b7te", "des", "Gold\u00b7ha\u00b7ars", "Ring"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Auf der Stirn ihr kronengleich. \u2013", "tokens": ["Auf", "der", "Stirn", "ihr", "kro\u00b7nen\u00b7gleich", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Vom Rotro\u00df staunend da Harald sprang", "tokens": ["Vom", "Rot\u00b7ro\u00df", "stau\u00b7nend", "da", "Ha\u00b7rald", "sprang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "ADV", "NE", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und hielt die Hand vor die Augen:", "tokens": ["Und", "hielt", "die", "Hand", "vor", "die", "Au\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbwie blendest du! Zu der Helden Empfang", "tokens": ["\u00bb", "wie", "blen\u00b7dest", "du", "!", "Zu", "der", "Hel\u00b7den", "Emp\u00b7fang"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "$.", "APPR", "ART", "NN", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In Walhall w\u00fcrdest du taugen.", "tokens": ["In", "Wal\u00b7hall", "w\u00fcr\u00b7dest", "du", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Zu den Schildjungfrauen wohl z\u00e4hlst du, Kind?\u00ab", "tokens": ["Zu", "den", "Schild\u00b7jung\u00b7frau\u00b7en", "wohl", "z\u00e4hlst", "du", ",", "Kind", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "PPER", "$,", "NN", "$.", "$("], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbmein Vater, der Bauer, hie\u00df Steinn:", "tokens": ["\u00bb", "mein", "Va\u00b7ter", ",", "der", "Bau\u00b7er", ",", "hie\u00df", "Steinn", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "VVFIN", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Ich herrsch' im Hof hier \u2013 allein.\u00ab", "tokens": ["Ich", "herr\u00b7sch'", "im", "Hof", "hier", "\u2013", "al\u00b7lein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "$(", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Da strich sich Harald langsam den Bart", "tokens": ["Da", "strich", "sich", "Ha\u00b7rald", "lang\u00b7sam", "den", "Bart"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "NE", "ADJD", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und die Stirne furcht' er mit Sinnen:", "tokens": ["Und", "die", "Stir\u00b7ne", "furcht'", "er", "mit", "Sin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch Gydha spreitete, wei\u00df und zart,", "tokens": ["Doch", "Gy\u00b7dha", "sprei\u00b7te\u00b7te", ",", "wei\u00df", "und", "zart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf den Birkentisch das Linnen.", "tokens": ["Auf", "den", "Bir\u00b7ken\u00b7tisch", "das", "Lin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und sie winkt den M\u00e4gden: die tragen heran", "tokens": ["Und", "sie", "winkt", "den", "M\u00e4g\u00b7den", ":", "die", "tra\u00b7gen", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$.", "ART", "NN", "PTKVZ"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In gehenkelten Kr\u00fcgen den Meth:", "tokens": ["In", "ge\u00b7hen\u00b7kel\u00b7ten", "Kr\u00fc\u00b7gen", "den", "Me\u00b7th", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch der Wirtin nur achtet der gastende Mann,", "tokens": ["Doch", "der", "Wir\u00b7tin", "nur", "ach\u00b7tet", "der", "gas\u00b7ten\u00b7de", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Die schweigend die Spule dreht.", "tokens": ["Die", "schwei\u00b7gend", "die", "Spu\u00b7le", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbwie hei\u00dft du?\u00ab \u00bbGydha!\u00ab \u00bbNun, Gydha, sprich,", "tokens": ["\u00bb", "wie", "hei\u00dft", "du", "?", "\u00ab", "\u00bb", "Gy\u00b7dha", "!", "\u00ab", "\u00bb", "Nun", ",", "Gy\u00b7dha", ",", "sprich", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "$.", "$(", "$(", "NE", "$.", "$(", "$(", "ADV", "$,", "NE", "$,", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus dem Bauernstaube dich rei\u00df' ich:", "tokens": ["Aus", "dem", "Bau\u00b7ern\u00b7stau\u00b7be", "dich", "rei\u00df'", "ich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Zu meiner K\u00f6nigin k\u00fcr' ich dich,", "tokens": ["Zu", "mei\u00b7ner", "K\u00f6\u00b7ni\u00b7gin", "k\u00fcr'", "ich", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Harald von Hadaland hei\u00df' ich.", "tokens": ["Ha\u00b7rald", "von", "Ha\u00b7da\u00b7land", "hei\u00df'", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "VVFIN", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.9": {"line.1": {"text": "Ich biete dir meine goldene Kron'", "tokens": ["Ich", "bie\u00b7te", "dir", "mei\u00b7ne", "gol\u00b7de\u00b7ne", "Kron'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "F\u00fcr den G\u00fcrtel um deinen Leib.\u00ab", "tokens": ["F\u00fcr", "den", "G\u00fcr\u00b7tel", "um", "dei\u00b7nen", "Leib", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Aufstand und sprach da mit stolzem Hohn", "tokens": ["Auf\u00b7stand", "und", "sprach", "da", "mit", "stol\u00b7zem", "Hohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Und mit blitzenden Augen das Weib:", "tokens": ["Und", "mit", "blit\u00b7zen\u00b7den", "Au\u00b7gen", "das", "Weib", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.10": {"line.1": {"text": "\u00bbmein G\u00fcrtel, Zw\u00f6lfk\u00f6nig, ist ganz und voll:", "tokens": ["\u00bb", "mein", "G\u00fcr\u00b7tel", ",", "Zw\u00f6lf\u00b7k\u00f6\u00b7nig", ",", "ist", "ganz", "und", "voll", ":"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "NN", "$,", "VAFIN", "ADV", "KON", "ADJD", "$."], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.2": {"text": "Er tr\u00e4gt zw\u00f6lf strahlende Steine:", "tokens": ["Er", "tr\u00e4gt", "zw\u00f6lf", "strah\u00b7len\u00b7de", "Stei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Draus schenk' ich dir einen: das ist dein Zoll", "tokens": ["Draus", "schenk'", "ich", "dir", "ei\u00b7nen", ":", "das", "ist", "dein", "Zoll"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ART", "$.", "PDS", "VAFIN", "PPOSAT", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "F\u00fcr die Zw\u00f6lfteilskrone, die deine.", "tokens": ["F\u00fcr", "die", "Zw\u00f6lf\u00b7teils\u00b7kro\u00b7ne", ",", "die", "dei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Du tr\u00e4gst es, Norge vergehen in Harm", "tokens": ["Du", "tr\u00e4gst", "es", ",", "Nor\u00b7ge", "ver\u00b7ge\u00b7hen", "in", "Harm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NN", "VVINF", "APPR", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu schau'n, in Zerrissenheit \u2013", "tokens": ["Zu", "schau'n", ",", "in", "Zer\u00b7ris\u00b7sen\u00b7heit", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "APPR", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Doch du \u2013 jagst und verjagest die Zeit.", "tokens": ["Doch", "du", "\u2013", "jagst", "und", "ver\u00b7ja\u00b7gest", "die", "Zeit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.12": {"line.1": {"text": "Mein G\u00fcrtel, Harald, ist ganz und Eins:", "tokens": ["Mein", "G\u00fcr\u00b7tel", ",", "Ha\u00b7rald", ",", "ist", "ganz", "und", "Eins", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "$,", "VAFIN", "ADV", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Deine Kron' ist nicht w\u00fcrdig meiner:", "tokens": ["Dei\u00b7ne", "Kron'", "ist", "nicht", "w\u00fcr\u00b7dig", "mei\u00b7ner", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ADJD", "PPOSAT", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ein ganzes Reich und Herz, oder keins \u2013", "tokens": ["Ein", "gan\u00b7zes", "Reich", "und", "Herz", ",", "o\u00b7der", "keins", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,", "KON", "PIAT", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein Zw\u00f6lftel K\u00f6nig ist \u2013 keiner!\u00ab", "tokens": ["Ein", "Zw\u00f6lf\u00b7tel", "K\u00f6\u00b7nig", "ist", "\u2013", "kei\u00b7ner", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$(", "PIS", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Und sie wandte den R\u00fccken und schritt ins Tor", "tokens": ["Und", "sie", "wand\u00b7te", "den", "R\u00fc\u00b7cken", "und", "schritt", "ins", "Tor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPRART", "NN"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und warf den Riegel ins Schlo\u00df:", "tokens": ["Und", "warf", "den", "Rie\u00b7gel", "ins", "Schlo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und der Gast sprang j\u00e4h von der Bank empor", "tokens": ["Und", "der", "Gast", "sprang", "j\u00e4h", "von", "der", "Bank", "em\u00b7por"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "PTKVZ"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und im Sturm trug fort ihn das Ro\u00df.", "tokens": ["Und", "im", "Sturm", "trug", "fort", "ihn", "das", "Ro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ", "PPER", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "Drei Sommer kamen und dreimal schlug", "tokens": ["Drei", "Som\u00b7mer", "ka\u00b7men", "und", "drei\u00b7mal", "schlug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "KON", "ADV", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Drei K\u00f6nige Harald tot:", "tokens": ["Drei", "K\u00f6\u00b7ni\u00b7ge", "Ha\u00b7rald", "tot", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NE", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da hatten die letzten beiden genug", "tokens": ["Da", "hat\u00b7ten", "die", "letz\u00b7ten", "bei\u00b7den", "ge\u00b7nug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "PIAT", "ADV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und nahmen als Jarle sein Brot.", "tokens": ["Und", "nah\u00b7men", "als", "Jar\u00b7le", "sein", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "NE", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.15": {"line.1": {"text": "\u00bbnun bin ich K\u00f6nig von Hadaland,", "tokens": ["\u00bb", "nun", "bin", "ich", "K\u00f6\u00b7nig", "von", "Ha\u00b7da\u00b7land", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ranriki und Thrandheim, dem starken", "tokens": ["Ran\u00b7ri\u00b7ki", "und", "Thr\u00b7and\u00b7heim", ",", "dem", "star\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Von Raumariki und Westfoldstrand,", "tokens": ["Von", "Rau\u00b7ma\u00b7ri\u00b7ki", "und", "West\u00b7fold\u00b7strand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Heid-Wingul- und Thelamarken.", "tokens": ["Hei\u00b7dWin\u00b7gul", "und", "The\u00b7la\u00b7mar\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Und K\u00f6nig bin ich von Gudbrandsreid,", "tokens": ["Und", "K\u00f6\u00b7nig", "bin", "ich", "von", "Gud\u00b7brands\u00b7reid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von Upland, Midland und Dal: \u2013", "tokens": ["Von", "Up\u00b7land", ",", "Mid\u00b7land", "und", "Dal", ":", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "$,", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Vom ganzen Norge, schmal und breit,", "tokens": ["Vom", "gan\u00b7zen", "Nor\u00b7ge", ",", "schmal", "und", "breit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bin ich K\u00f6nig nun zumal.\u00ab", "tokens": ["Bin", "ich", "K\u00f6\u00b7nig", "nun", "zu\u00b7mal", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "NN", "ADV", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Da lie\u00df er sich schmieden goldene Kron',", "tokens": ["Da", "lie\u00df", "er", "sich", "schmie\u00b7den", "gol\u00b7de\u00b7ne", "Kron'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die trug zw\u00f6lf silberne Zacken,", "tokens": ["Die", "trug", "zw\u00f6lf", "sil\u00b7ber\u00b7ne", "Za\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Aufs Rotro\u00df sprang er mit stummem Drohn", "tokens": ["Aufs", "Rot\u00b7ro\u00df", "sprang", "er", "mit", "stum\u00b7mem", "Drohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und warf das Gelock in den Nacken.", "tokens": ["Und", "warf", "das", "Ge\u00b7lock", "in", "den", "Na\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.18": {"line.1": {"text": "Und als er vor Mochters Hoftor stand, \u2013", "tokens": ["Und", "als", "er", "vor", "Moch\u00b7ters", "Hof\u00b7tor", "stand", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "NN", "VVFIN", "$,", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schritt Gydha draus hervor,", "tokens": ["Schritt", "Gy\u00b7dha", "draus", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Trug ihren G\u00fcrtel in der Hand,", "tokens": ["Trug", "ih\u00b7ren", "G\u00fcr\u00b7tel", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "War sch\u00f6ner als je zuvor.", "tokens": ["War", "sch\u00f6\u00b7ner", "als", "je", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KOKOM", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Statt herben Hohnes s\u00fc\u00dfe Scham", "tokens": ["Statt", "her\u00b7ben", "Hoh\u00b7nes", "s\u00fc\u00b7\u00dfe", "Scham"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Umgo\u00df sie mit rosigem Scheine \u2013", "tokens": ["Um\u00b7go\u00df", "sie", "mit", "ro\u00b7si\u00b7gem", "Schei\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Auf den Birkentisch \u2013 wie wundersam! \u2013", "tokens": ["Auf", "den", "Bir\u00b7ken\u00b7tisch", "\u2013", "wie", "wun\u00b7der\u00b7sam", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$(", "PWAV", "ADJD", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sie warf elf strahlende Steine:", "tokens": ["Sie", "warf", "elf", "strah\u00b7len\u00b7de", "Stei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "\u00bbheil, K\u00f6nig Harald \u2013 Vollk\u00f6nig! \u2013 dir,", "tokens": ["\u00bb", "heil", ",", "K\u00f6\u00b7nig", "Ha\u00b7rald", "\u2013", "Voll\u00b7k\u00f6\u00b7nig", "!", "\u2013", "dir", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NE", "NE", "$(", "NN", "$.", "$(", "PPER", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Heil, Norges Herr und Held:", "tokens": ["Heil", ",", "Nor\u00b7ges", "Herr", "und", "Held", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Elf Steine l\u00f6st' ich vom G\u00fcrtel mir,", "tokens": ["Elf", "Stei\u00b7ne", "l\u00f6st'", "ich", "vom", "G\u00fcr\u00b7tel", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "APPRART", "NN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie du K\u00f6nig auf K\u00f6nig gef\u00e4llt.", "tokens": ["Wie", "du", "K\u00f6\u00b7nig", "auf", "K\u00f6\u00b7nig", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "APPR", "NN", "VVPP", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.21": {"line.1": {"text": "Nicht verschm\u00e4he den letzten: \u2013 der rote Rubin", "tokens": ["Nicht", "ver\u00b7schm\u00e4\u00b7he", "den", "letz\u00b7ten", ":", "\u2013", "der", "ro\u00b7te", "Ru\u00b7bin"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "ART", "ADJA", "$.", "$(", "ART", "ADJA", "NE"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Soll Gydha selber bedeuten.\u00ab", "tokens": ["Soll", "Gy\u00b7dha", "sel\u00b7ber", "be\u00b7deu\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "NE", "ADV", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch er zog sie ans Herz von gebeugten Knien \u2013:", "tokens": ["Doch", "er", "zog", "sie", "ans", "Herz", "von", "ge\u00b7beug\u00b7ten", "Kni\u00b7en", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPRART", "NN", "APPR", "ADJA", "NN", "$(", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "\u00bbknien ziemt nicht K\u00f6nigsbr\u00e4uten.", "tokens": ["\u00bb", "kni\u00b7en", "ziemt", "nicht", "K\u00f6\u00b7nigs\u00b7br\u00e4u\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "VVFIN", "PTKNEG", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Das wisse ganz Norge, das wisse die Welt:", "tokens": ["Das", "wis\u00b7se", "ganz", "Nor\u00b7ge", ",", "das", "wis\u00b7se", "die", "Welt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "NN", "$,", "PDS", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wenn den Hader ich niedergestreckt", "tokens": ["Wenn", "den", "Ha\u00b7der", "ich", "nie\u00b7der\u00b7ge\u00b7streckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und den Frieden geschafft und die V\u00f6lker gesellt \u2013:", "tokens": ["Und", "den", "Frie\u00b7den", "ge\u00b7schafft", "und", "die", "V\u00f6l\u00b7ker", "ge\u00b7sellt", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "KON", "ART", "NN", "VVPP", "$(", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Mein Weib hat dazu mich geweckt.\u00ab", "tokens": ["Mein", "Weib", "hat", "da\u00b7zu", "mich", "ge\u00b7weckt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PAV", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Zw\u00f6lf K\u00f6nige herrschten in Norgeland:", "tokens": ["Zw\u00f6lf", "K\u00f6\u00b7ni\u00b7ge", "herrschten", "in", "Nor\u00b7ge\u00b7land", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "NE", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das waren um elf zu viel:", "tokens": ["Das", "wa\u00b7ren", "um", "elf", "zu", "viel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "CARD", "PTKA", "PIS", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie Harald die andern \u00fcberwand,", "tokens": ["Wie", "Ha\u00b7rald", "die", "an\u00b7dern", "\u00fc\u00b7ber\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das singt man zu Harfenspiel. \u2013", "tokens": ["Das", "singt", "man", "zu", "Har\u00b7fen\u00b7spiel", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "NE", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "Zwolfk\u00f6nig Harald von Hadaland,", "tokens": ["Zwolf\u00b7k\u00f6\u00b7nig", "Ha\u00b7rald", "von", "Ha\u00b7da\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Zu jagen ritt er nach Mochter:", "tokens": ["Zu", "ja\u00b7gen", "ritt", "er", "nach", "Moch\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sch\u00f6n Gydha vor ihrem Hoftor stand,", "tokens": ["Sch\u00f6n", "Gy\u00b7dha", "vor", "ih\u00b7rem", "Hof\u00b7tor", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Des Odalbauern Tochter.", "tokens": ["Des", "O\u00b7dal\u00b7bau\u00b7ern", "Toch\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Die schlanken H\u00fcften ihr stolz umfing", "tokens": ["Die", "schlan\u00b7ken", "H\u00fcf\u00b7ten", "ihr", "stolz", "um\u00b7fing"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPER", "ADJD", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Goldg\u00fcrtel, an Steinen reich:", "tokens": ["Gold\u00b7g\u00fcr\u00b7tel", ",", "an", "Stei\u00b7nen", "reich", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Noch goldener gl\u00e4nzte des Goldhaars Ring", "tokens": ["Noch", "gol\u00b7de\u00b7ner", "gl\u00e4nz\u00b7te", "des", "Gold\u00b7ha\u00b7ars", "Ring"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Auf der Stirn ihr kronengleich. \u2013", "tokens": ["Auf", "der", "Stirn", "ihr", "kro\u00b7nen\u00b7gleich", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Vom Rotro\u00df staunend da Harald sprang", "tokens": ["Vom", "Rot\u00b7ro\u00df", "stau\u00b7nend", "da", "Ha\u00b7rald", "sprang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "ADV", "NE", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und hielt die Hand vor die Augen:", "tokens": ["Und", "hielt", "die", "Hand", "vor", "die", "Au\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbwie blendest du! Zu der Helden Empfang", "tokens": ["\u00bb", "wie", "blen\u00b7dest", "du", "!", "Zu", "der", "Hel\u00b7den", "Emp\u00b7fang"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "$.", "APPR", "ART", "NN", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In Walhall w\u00fcrdest du taugen.", "tokens": ["In", "Wal\u00b7hall", "w\u00fcr\u00b7dest", "du", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.27": {"line.1": {"text": "Zu den Schildjungfrauen wohl z\u00e4hlst du, Kind?\u00ab", "tokens": ["Zu", "den", "Schild\u00b7jung\u00b7frau\u00b7en", "wohl", "z\u00e4hlst", "du", ",", "Kind", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "PPER", "$,", "NN", "$.", "$("], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbmein Vater, der Bauer, hie\u00df Steinn:", "tokens": ["\u00bb", "mein", "Va\u00b7ter", ",", "der", "Bau\u00b7er", ",", "hie\u00df", "Steinn", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "VVFIN", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Ich herrsch' im Hof hier \u2013 allein.\u00ab", "tokens": ["Ich", "herr\u00b7sch'", "im", "Hof", "hier", "\u2013", "al\u00b7lein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "$(", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Da strich sich Harald langsam den Bart", "tokens": ["Da", "strich", "sich", "Ha\u00b7rald", "lang\u00b7sam", "den", "Bart"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "NE", "ADJD", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und die Stirne furcht' er mit Sinnen:", "tokens": ["Und", "die", "Stir\u00b7ne", "furcht'", "er", "mit", "Sin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch Gydha spreitete, wei\u00df und zart,", "tokens": ["Doch", "Gy\u00b7dha", "sprei\u00b7te\u00b7te", ",", "wei\u00df", "und", "zart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf den Birkentisch das Linnen.", "tokens": ["Auf", "den", "Bir\u00b7ken\u00b7tisch", "das", "Lin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Und sie winkt den M\u00e4gden: die tragen heran", "tokens": ["Und", "sie", "winkt", "den", "M\u00e4g\u00b7den", ":", "die", "tra\u00b7gen", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$.", "ART", "NN", "PTKVZ"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In gehenkelten Kr\u00fcgen den Meth:", "tokens": ["In", "ge\u00b7hen\u00b7kel\u00b7ten", "Kr\u00fc\u00b7gen", "den", "Me\u00b7th", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch der Wirtin nur achtet der gastende Mann,", "tokens": ["Doch", "der", "Wir\u00b7tin", "nur", "ach\u00b7tet", "der", "gas\u00b7ten\u00b7de", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Die schweigend die Spule dreht.", "tokens": ["Die", "schwei\u00b7gend", "die", "Spu\u00b7le", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.30": {"line.1": {"text": "\u00bbwie hei\u00dft du?\u00ab \u00bbGydha!\u00ab \u00bbNun, Gydha, sprich,", "tokens": ["\u00bb", "wie", "hei\u00dft", "du", "?", "\u00ab", "\u00bb", "Gy\u00b7dha", "!", "\u00ab", "\u00bb", "Nun", ",", "Gy\u00b7dha", ",", "sprich", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "$.", "$(", "$(", "NE", "$.", "$(", "$(", "ADV", "$,", "NE", "$,", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus dem Bauernstaube dich rei\u00df' ich:", "tokens": ["Aus", "dem", "Bau\u00b7ern\u00b7stau\u00b7be", "dich", "rei\u00df'", "ich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Zu meiner K\u00f6nigin k\u00fcr' ich dich,", "tokens": ["Zu", "mei\u00b7ner", "K\u00f6\u00b7ni\u00b7gin", "k\u00fcr'", "ich", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Harald von Hadaland hei\u00df' ich.", "tokens": ["Ha\u00b7rald", "von", "Ha\u00b7da\u00b7land", "hei\u00df'", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "VVFIN", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.31": {"line.1": {"text": "Ich biete dir meine goldene Kron'", "tokens": ["Ich", "bie\u00b7te", "dir", "mei\u00b7ne", "gol\u00b7de\u00b7ne", "Kron'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "F\u00fcr den G\u00fcrtel um deinen Leib.\u00ab", "tokens": ["F\u00fcr", "den", "G\u00fcr\u00b7tel", "um", "dei\u00b7nen", "Leib", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Aufstand und sprach da mit stolzem Hohn", "tokens": ["Auf\u00b7stand", "und", "sprach", "da", "mit", "stol\u00b7zem", "Hohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Und mit blitzenden Augen das Weib:", "tokens": ["Und", "mit", "blit\u00b7zen\u00b7den", "Au\u00b7gen", "das", "Weib", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.32": {"line.1": {"text": "\u00bbmein G\u00fcrtel, Zw\u00f6lfk\u00f6nig, ist ganz und voll:", "tokens": ["\u00bb", "mein", "G\u00fcr\u00b7tel", ",", "Zw\u00f6lf\u00b7k\u00f6\u00b7nig", ",", "ist", "ganz", "und", "voll", ":"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "NN", "$,", "VAFIN", "ADV", "KON", "ADJD", "$."], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.2": {"text": "Er tr\u00e4gt zw\u00f6lf strahlende Steine:", "tokens": ["Er", "tr\u00e4gt", "zw\u00f6lf", "strah\u00b7len\u00b7de", "Stei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Draus schenk' ich dir einen: das ist dein Zoll", "tokens": ["Draus", "schenk'", "ich", "dir", "ei\u00b7nen", ":", "das", "ist", "dein", "Zoll"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ART", "$.", "PDS", "VAFIN", "PPOSAT", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "F\u00fcr die Zw\u00f6lfteilskrone, die deine.", "tokens": ["F\u00fcr", "die", "Zw\u00f6lf\u00b7teils\u00b7kro\u00b7ne", ",", "die", "dei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.33": {"line.1": {"text": "Du tr\u00e4gst es, Norge vergehen in Harm", "tokens": ["Du", "tr\u00e4gst", "es", ",", "Nor\u00b7ge", "ver\u00b7ge\u00b7hen", "in", "Harm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NN", "VVINF", "APPR", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu schau'n, in Zerrissenheit \u2013", "tokens": ["Zu", "schau'n", ",", "in", "Zer\u00b7ris\u00b7sen\u00b7heit", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "APPR", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Doch du \u2013 jagst und verjagest die Zeit.", "tokens": ["Doch", "du", "\u2013", "jagst", "und", "ver\u00b7ja\u00b7gest", "die", "Zeit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.34": {"line.1": {"text": "Mein G\u00fcrtel, Harald, ist ganz und Eins:", "tokens": ["Mein", "G\u00fcr\u00b7tel", ",", "Ha\u00b7rald", ",", "ist", "ganz", "und", "Eins", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "$,", "VAFIN", "ADV", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Deine Kron' ist nicht w\u00fcrdig meiner:", "tokens": ["Dei\u00b7ne", "Kron'", "ist", "nicht", "w\u00fcr\u00b7dig", "mei\u00b7ner", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ADJD", "PPOSAT", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ein ganzes Reich und Herz, oder keins \u2013", "tokens": ["Ein", "gan\u00b7zes", "Reich", "und", "Herz", ",", "o\u00b7der", "keins", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,", "KON", "PIAT", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein Zw\u00f6lftel K\u00f6nig ist \u2013 keiner!\u00ab", "tokens": ["Ein", "Zw\u00f6lf\u00b7tel", "K\u00f6\u00b7nig", "ist", "\u2013", "kei\u00b7ner", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$(", "PIS", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.35": {"line.1": {"text": "Und sie wandte den R\u00fccken und schritt ins Tor", "tokens": ["Und", "sie", "wand\u00b7te", "den", "R\u00fc\u00b7cken", "und", "schritt", "ins", "Tor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPRART", "NN"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und warf den Riegel ins Schlo\u00df:", "tokens": ["Und", "warf", "den", "Rie\u00b7gel", "ins", "Schlo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und der Gast sprang j\u00e4h von der Bank empor", "tokens": ["Und", "der", "Gast", "sprang", "j\u00e4h", "von", "der", "Bank", "em\u00b7por"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "PTKVZ"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und im Sturm trug fort ihn das Ro\u00df.", "tokens": ["Und", "im", "Sturm", "trug", "fort", "ihn", "das", "Ro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ", "PPER", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.36": {"line.1": {"text": "Drei Sommer kamen und dreimal schlug", "tokens": ["Drei", "Som\u00b7mer", "ka\u00b7men", "und", "drei\u00b7mal", "schlug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "KON", "ADV", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Drei K\u00f6nige Harald tot:", "tokens": ["Drei", "K\u00f6\u00b7ni\u00b7ge", "Ha\u00b7rald", "tot", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NE", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da hatten die letzten beiden genug", "tokens": ["Da", "hat\u00b7ten", "die", "letz\u00b7ten", "bei\u00b7den", "ge\u00b7nug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "PIAT", "ADV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und nahmen als Jarle sein Brot.", "tokens": ["Und", "nah\u00b7men", "als", "Jar\u00b7le", "sein", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "NE", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.37": {"line.1": {"text": "\u00bbnun bin ich K\u00f6nig von Hadaland,", "tokens": ["\u00bb", "nun", "bin", "ich", "K\u00f6\u00b7nig", "von", "Ha\u00b7da\u00b7land", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ranriki und Thrandheim, dem starken", "tokens": ["Ran\u00b7ri\u00b7ki", "und", "Thr\u00b7and\u00b7heim", ",", "dem", "star\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Von Raumariki und Westfoldstrand,", "tokens": ["Von", "Rau\u00b7ma\u00b7ri\u00b7ki", "und", "West\u00b7fold\u00b7strand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Heid-Wingul- und Thelamarken.", "tokens": ["Hei\u00b7dWin\u00b7gul", "und", "The\u00b7la\u00b7mar\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Und K\u00f6nig bin ich von Gudbrandsreid,", "tokens": ["Und", "K\u00f6\u00b7nig", "bin", "ich", "von", "Gud\u00b7brands\u00b7reid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von Upland, Midland und Dal: \u2013", "tokens": ["Von", "Up\u00b7land", ",", "Mid\u00b7land", "und", "Dal", ":", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "$,", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Vom ganzen Norge, schmal und breit,", "tokens": ["Vom", "gan\u00b7zen", "Nor\u00b7ge", ",", "schmal", "und", "breit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bin ich K\u00f6nig nun zumal.\u00ab", "tokens": ["Bin", "ich", "K\u00f6\u00b7nig", "nun", "zu\u00b7mal", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "NN", "ADV", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Da lie\u00df er sich schmieden goldene Kron',", "tokens": ["Da", "lie\u00df", "er", "sich", "schmie\u00b7den", "gol\u00b7de\u00b7ne", "Kron'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die trug zw\u00f6lf silberne Zacken,", "tokens": ["Die", "trug", "zw\u00f6lf", "sil\u00b7ber\u00b7ne", "Za\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Aufs Rotro\u00df sprang er mit stummem Drohn", "tokens": ["Aufs", "Rot\u00b7ro\u00df", "sprang", "er", "mit", "stum\u00b7mem", "Drohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und warf das Gelock in den Nacken.", "tokens": ["Und", "warf", "das", "Ge\u00b7lock", "in", "den", "Na\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.40": {"line.1": {"text": "Und als er vor Mochters Hoftor stand, \u2013", "tokens": ["Und", "als", "er", "vor", "Moch\u00b7ters", "Hof\u00b7tor", "stand", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "NN", "VVFIN", "$,", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schritt Gydha draus hervor,", "tokens": ["Schritt", "Gy\u00b7dha", "draus", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Trug ihren G\u00fcrtel in der Hand,", "tokens": ["Trug", "ih\u00b7ren", "G\u00fcr\u00b7tel", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "War sch\u00f6ner als je zuvor.", "tokens": ["War", "sch\u00f6\u00b7ner", "als", "je", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KOKOM", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.41": {"line.1": {"text": "Statt herben Hohnes s\u00fc\u00dfe Scham", "tokens": ["Statt", "her\u00b7ben", "Hoh\u00b7nes", "s\u00fc\u00b7\u00dfe", "Scham"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Umgo\u00df sie mit rosigem Scheine \u2013", "tokens": ["Um\u00b7go\u00df", "sie", "mit", "ro\u00b7si\u00b7gem", "Schei\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Auf den Birkentisch \u2013 wie wundersam! \u2013", "tokens": ["Auf", "den", "Bir\u00b7ken\u00b7tisch", "\u2013", "wie", "wun\u00b7der\u00b7sam", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$(", "PWAV", "ADJD", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sie warf elf strahlende Steine:", "tokens": ["Sie", "warf", "elf", "strah\u00b7len\u00b7de", "Stei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.42": {"line.1": {"text": "\u00bbheil, K\u00f6nig Harald \u2013 Vollk\u00f6nig! \u2013 dir,", "tokens": ["\u00bb", "heil", ",", "K\u00f6\u00b7nig", "Ha\u00b7rald", "\u2013", "Voll\u00b7k\u00f6\u00b7nig", "!", "\u2013", "dir", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NE", "NE", "$(", "NN", "$.", "$(", "PPER", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Heil, Norges Herr und Held:", "tokens": ["Heil", ",", "Nor\u00b7ges", "Herr", "und", "Held", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Elf Steine l\u00f6st' ich vom G\u00fcrtel mir,", "tokens": ["Elf", "Stei\u00b7ne", "l\u00f6st'", "ich", "vom", "G\u00fcr\u00b7tel", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "APPRART", "NN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie du K\u00f6nig auf K\u00f6nig gef\u00e4llt.", "tokens": ["Wie", "du", "K\u00f6\u00b7nig", "auf", "K\u00f6\u00b7nig", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "APPR", "NN", "VVPP", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.43": {"line.1": {"text": "Nicht verschm\u00e4he den letzten: \u2013 der rote Rubin", "tokens": ["Nicht", "ver\u00b7schm\u00e4\u00b7he", "den", "letz\u00b7ten", ":", "\u2013", "der", "ro\u00b7te", "Ru\u00b7bin"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "ART", "ADJA", "$.", "$(", "ART", "ADJA", "NE"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Soll Gydha selber bedeuten.\u00ab", "tokens": ["Soll", "Gy\u00b7dha", "sel\u00b7ber", "be\u00b7deu\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "NE", "ADV", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch er zog sie ans Herz von gebeugten Knien \u2013:", "tokens": ["Doch", "er", "zog", "sie", "ans", "Herz", "von", "ge\u00b7beug\u00b7ten", "Kni\u00b7en", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPRART", "NN", "APPR", "ADJA", "NN", "$(", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "\u00bbknien ziemt nicht K\u00f6nigsbr\u00e4uten.", "tokens": ["\u00bb", "kni\u00b7en", "ziemt", "nicht", "K\u00f6\u00b7nigs\u00b7br\u00e4u\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "VVFIN", "PTKNEG", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Das wisse ganz Norge, das wisse die Welt:", "tokens": ["Das", "wis\u00b7se", "ganz", "Nor\u00b7ge", ",", "das", "wis\u00b7se", "die", "Welt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "NN", "$,", "PDS", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wenn den Hader ich niedergestreckt", "tokens": ["Wenn", "den", "Ha\u00b7der", "ich", "nie\u00b7der\u00b7ge\u00b7streckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und den Frieden geschafft und die V\u00f6lker gesellt \u2013:", "tokens": ["Und", "den", "Frie\u00b7den", "ge\u00b7schafft", "und", "die", "V\u00f6l\u00b7ker", "ge\u00b7sellt", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "KON", "ART", "NN", "VVPP", "$(", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Mein Weib hat dazu mich geweckt.\u00ab", "tokens": ["Mein", "Weib", "hat", "da\u00b7zu", "mich", "ge\u00b7weckt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PAV", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}