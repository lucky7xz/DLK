{"textgrid.poem.66591": {"metadata": {"author": {"name": "Roquette, Otto", "birth": "N.A.", "death": "N.A."}, "title": "1L: Autographensammelseuche!", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Autographensammelseuche!", "tokens": ["Au\u00b7to\u00b7gra\u00b7phen\u00b7sam\u00b7mel\u00b7seu\u00b7che", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Bub' und Backfisch leiden dran,", "tokens": ["Bub'", "und", "Back\u00b7fisch", "lei\u00b7den", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und begehn der Modebr\u00e4uche", "tokens": ["Und", "be\u00b7gehn", "der", "Mo\u00b7de\u00b7br\u00e4u\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Neusten heut, wie Jedermann.", "tokens": ["Neus\u00b7ten", "heut", ",", "wie", "Je\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hunderttausend Briefe klopfen", "tokens": ["Hun\u00b7dert\u00b7tau\u00b7send", "Brie\u00b7fe", "klop\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00fc\u00df an jedes Tintefa\u00df,", "tokens": ["S\u00fc\u00df", "an", "je\u00b7des", "Tin\u00b7te\u00b7fa\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das nur jemals einen Tropfen", "tokens": ["Das", "nur", "je\u00b7mals", "ei\u00b7nen", "Trop\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr die Druckerschw\u00e4rze ma\u00df.", "tokens": ["F\u00fcr", "die", "Dru\u00b7cker\u00b7schw\u00e4r\u00b7ze", "ma\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ob man garnichts von ihm w\u00fc\u00dfte,", "tokens": ["Ob", "man", "gar\u00b7nichts", "von", "ihm", "w\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Den man ausersehen hat,", "tokens": ["Den", "man", "au\u00b7ser\u00b7se\u00b7hen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVIZU", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Steht sein Name auf der Liste,", "tokens": ["Steht", "sein", "Na\u00b7me", "auf", "der", "Lis\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So verlangt man auch sein Blatt.", "tokens": ["So", "ver\u00b7langt", "man", "auch", "sein", "Blatt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und so geht das Hausgebettel", "tokens": ["Und", "so", "geht", "das", "Haus\u00b7ge\u00b7bet\u00b7tel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Bildung Dur und Moll:", "tokens": ["In", "der", "Bil\u00b7dung", "Dur", "und", "Moll", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir 'nen Zettel, dir 'nen Zettel,", "tokens": ["Mir", "'nen", "Zet\u00b7tel", ",", "dir", "'nen", "Zet\u00b7tel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kritzelsammelschwindeltoll!", "tokens": ["Krit\u00b7zel\u00b7sam\u00b7mel\u00b7schwin\u00b7del\u00b7toll", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Autographensammelseuche!", "tokens": ["Au\u00b7to\u00b7gra\u00b7phen\u00b7sam\u00b7mel\u00b7seu\u00b7che", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Bub' und Backfisch leiden dran,", "tokens": ["Bub'", "und", "Back\u00b7fisch", "lei\u00b7den", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und begehn der Modebr\u00e4uche", "tokens": ["Und", "be\u00b7gehn", "der", "Mo\u00b7de\u00b7br\u00e4u\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Neusten heut, wie Jedermann.", "tokens": ["Neus\u00b7ten", "heut", ",", "wie", "Je\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Hunderttausend Briefe klopfen", "tokens": ["Hun\u00b7dert\u00b7tau\u00b7send", "Brie\u00b7fe", "klop\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00fc\u00df an jedes Tintefa\u00df,", "tokens": ["S\u00fc\u00df", "an", "je\u00b7des", "Tin\u00b7te\u00b7fa\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das nur jemals einen Tropfen", "tokens": ["Das", "nur", "je\u00b7mals", "ei\u00b7nen", "Trop\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr die Druckerschw\u00e4rze ma\u00df.", "tokens": ["F\u00fcr", "die", "Dru\u00b7cker\u00b7schw\u00e4r\u00b7ze", "ma\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ob man garnichts von ihm w\u00fc\u00dfte,", "tokens": ["Ob", "man", "gar\u00b7nichts", "von", "ihm", "w\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Den man ausersehen hat,", "tokens": ["Den", "man", "au\u00b7ser\u00b7se\u00b7hen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVIZU", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Steht sein Name auf der Liste,", "tokens": ["Steht", "sein", "Na\u00b7me", "auf", "der", "Lis\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So verlangt man auch sein Blatt.", "tokens": ["So", "ver\u00b7langt", "man", "auch", "sein", "Blatt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und so geht das Hausgebettel", "tokens": ["Und", "so", "geht", "das", "Haus\u00b7ge\u00b7bet\u00b7tel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Bildung Dur und Moll:", "tokens": ["In", "der", "Bil\u00b7dung", "Dur", "und", "Moll", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir 'nen Zettel, dir 'nen Zettel,", "tokens": ["Mir", "'nen", "Zet\u00b7tel", ",", "dir", "'nen", "Zet\u00b7tel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kritzelsammelschwindeltoll!", "tokens": ["Krit\u00b7zel\u00b7sam\u00b7mel\u00b7schwin\u00b7del\u00b7toll", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}