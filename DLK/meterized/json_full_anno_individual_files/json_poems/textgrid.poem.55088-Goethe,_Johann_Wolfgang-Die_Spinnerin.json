{"textgrid.poem.55088": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Die Spinnerin", "genre": "verse", "period": "N.A.", "pub_year": 1795, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich still und ruhig spann,", "tokens": ["Als", "ich", "still", "und", "ru\u00b7hig", "spann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ohne nur zu stocken,", "tokens": ["Oh\u00b7ne", "nur", "zu", "sto\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trat ein sch\u00f6ner junger Mann", "tokens": ["Trat", "ein", "sch\u00f6\u00b7ner", "jun\u00b7ger", "Mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nahe mir zum Rocken.", "tokens": ["Na\u00b7he", "mir", "zum", "Ro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Lobte, was zu loben war,", "tokens": ["Lob\u00b7te", ",", "was", "zu", "lo\u00b7ben", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sollte das was schaden?", "tokens": ["Soll\u00b7te", "das", "was", "scha\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mein dem Flachse gleiches Haar", "tokens": ["Mein", "dem", "Flach\u00b7se", "glei\u00b7ches", "Haar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und den gleichen Faden.", "tokens": ["Und", "den", "glei\u00b7chen", "Fa\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Ruhig war er nicht dabei,", "tokens": ["Ru\u00b7hig", "war", "er", "nicht", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PTKNEG", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lie\u00df es nicht beim alten;", "tokens": ["Lie\u00df", "es", "nicht", "beim", "al\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPRART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und der Faden ri\u00df entzwei,", "tokens": ["Und", "der", "Fa\u00b7den", "ri\u00df", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den ich lang' erhalten.", "tokens": ["Den", "ich", "lang'", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Und des Flachses Steingewicht", "tokens": ["Und", "des", "Flach\u00b7ses", "Stein\u00b7ge\u00b7wicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gab noch viele Zahlen;", "tokens": ["Gab", "noch", "vie\u00b7le", "Zah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Aber ach, ich konnte nicht", "tokens": ["A\u00b7ber", "ach", ",", "ich", "konn\u00b7te", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PPER", "VMFIN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehr mit ihnen prahlen.", "tokens": ["Mehr", "mit", "ih\u00b7nen", "prah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Als ich sie zum Weber trug,", "tokens": ["Als", "ich", "sie", "zum", "We\u00b7ber", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fchlt ich was sich regen,", "tokens": ["F\u00fchlt", "ich", "was", "sich", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRELS", "PRF", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mein armes Herze schlug", "tokens": ["Und", "mein", "ar\u00b7mes", "Her\u00b7ze", "schlug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit geschwindern Schlagen.", "tokens": ["Mit", "ge\u00b7schwin\u00b7dern", "Schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Nun, beim hei\u00dfen Sonnenstich,", "tokens": ["Nun", ",", "beim", "hei\u00b7\u00dfen", "Son\u00b7nen\u00b7stich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bring ich's auf die Bleiche,", "tokens": ["Bring", "ich's", "auf", "die", "Blei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mit M\u00fche b\u00fcck ich mich", "tokens": ["Und", "mit", "M\u00fc\u00b7he", "b\u00fcck", "ich", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach dem n\u00e4chsten Teiche.", "tokens": ["Nach", "dem", "n\u00e4chs\u00b7ten", "Tei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Was ich in dem K\u00e4mmerlein", "tokens": ["Was", "ich", "in", "dem", "K\u00e4m\u00b7mer\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Still und fein gesponnen,", "tokens": ["Still", "und", "fein", "ge\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kommt \u2013 wie kann es anders sein? \u2013", "tokens": ["Kommt", "\u2013", "wie", "kann", "es", "an\u00b7ders", "sein", "?", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "$(", "PWAV", "VMFIN", "PPER", "ADV", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Endlich an die Sonnen.", "tokens": ["End\u00b7lich", "an", "die", "Son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Als ich still und ruhig spann,", "tokens": ["Als", "ich", "still", "und", "ru\u00b7hig", "spann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ohne nur zu stocken,", "tokens": ["Oh\u00b7ne", "nur", "zu", "sto\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trat ein sch\u00f6ner junger Mann", "tokens": ["Trat", "ein", "sch\u00f6\u00b7ner", "jun\u00b7ger", "Mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nahe mir zum Rocken.", "tokens": ["Na\u00b7he", "mir", "zum", "Ro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Lobte, was zu loben war,", "tokens": ["Lob\u00b7te", ",", "was", "zu", "lo\u00b7ben", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sollte das was schaden?", "tokens": ["Soll\u00b7te", "das", "was", "scha\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mein dem Flachse gleiches Haar", "tokens": ["Mein", "dem", "Flach\u00b7se", "glei\u00b7ches", "Haar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und den gleichen Faden.", "tokens": ["Und", "den", "glei\u00b7chen", "Fa\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Ruhig war er nicht dabei,", "tokens": ["Ru\u00b7hig", "war", "er", "nicht", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PTKNEG", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lie\u00df es nicht beim alten;", "tokens": ["Lie\u00df", "es", "nicht", "beim", "al\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPRART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und der Faden ri\u00df entzwei,", "tokens": ["Und", "der", "Fa\u00b7den", "ri\u00df", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den ich lang' erhalten.", "tokens": ["Den", "ich", "lang'", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Und des Flachses Steingewicht", "tokens": ["Und", "des", "Flach\u00b7ses", "Stein\u00b7ge\u00b7wicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gab noch viele Zahlen;", "tokens": ["Gab", "noch", "vie\u00b7le", "Zah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Aber ach, ich konnte nicht", "tokens": ["A\u00b7ber", "ach", ",", "ich", "konn\u00b7te", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PPER", "VMFIN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehr mit ihnen prahlen.", "tokens": ["Mehr", "mit", "ih\u00b7nen", "prah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Als ich sie zum Weber trug,", "tokens": ["Als", "ich", "sie", "zum", "We\u00b7ber", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fchlt ich was sich regen,", "tokens": ["F\u00fchlt", "ich", "was", "sich", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRELS", "PRF", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mein armes Herze schlug", "tokens": ["Und", "mein", "ar\u00b7mes", "Her\u00b7ze", "schlug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit geschwindern Schlagen.", "tokens": ["Mit", "ge\u00b7schwin\u00b7dern", "Schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Nun, beim hei\u00dfen Sonnenstich,", "tokens": ["Nun", ",", "beim", "hei\u00b7\u00dfen", "Son\u00b7nen\u00b7stich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bring ich's auf die Bleiche,", "tokens": ["Bring", "ich's", "auf", "die", "Blei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mit M\u00fche b\u00fcck ich mich", "tokens": ["Und", "mit", "M\u00fc\u00b7he", "b\u00fcck", "ich", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach dem n\u00e4chsten Teiche.", "tokens": ["Nach", "dem", "n\u00e4chs\u00b7ten", "Tei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Was ich in dem K\u00e4mmerlein", "tokens": ["Was", "ich", "in", "dem", "K\u00e4m\u00b7mer\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Still und fein gesponnen,", "tokens": ["Still", "und", "fein", "ge\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kommt \u2013 wie kann es anders sein? \u2013", "tokens": ["Kommt", "\u2013", "wie", "kann", "es", "an\u00b7ders", "sein", "?", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "$(", "PWAV", "VMFIN", "PPER", "ADV", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Endlich an die Sonnen.", "tokens": ["End\u00b7lich", "an", "die", "Son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}