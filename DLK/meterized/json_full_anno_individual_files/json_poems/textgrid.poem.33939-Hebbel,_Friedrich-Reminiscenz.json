{"textgrid.poem.33939": {"metadata": {"author": {"name": "Hebbel, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Reminiscenz", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Millionen \u00f6de Jahre", "tokens": ["Mil\u00b7lion\u00b7en", "\u00f6\u00b7de", "Jah\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Lag ich schon in dumpfem Schlaf,", "tokens": ["Lag", "ich", "schon", "in", "dum\u00b7pfem", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als aus einem Augenpaare", "tokens": ["Als", "aus", "ei\u00b7nem", "Au\u00b7gen\u00b7paa\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mich der Stralen erster traf.", "tokens": ["Mich", "der", "Stra\u00b7len", "ers\u00b7ter", "traf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Da begann ich, mich zu regen,", "tokens": ["Da", "be\u00b7gann", "ich", ",", "mich", "zu", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PRF", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich empfand des Werdens Schmerz,", "tokens": ["Ich", "emp\u00b7fand", "des", "Wer\u00b7dens", "Schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit ungewissen Schl\u00e4gen", "tokens": ["Und", "mit", "un\u00b7ge\u00b7wis\u00b7sen", "Schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Setzte sich in mir ein Herz.", "tokens": ["Setz\u00b7te", "sich", "in", "mir", "ein", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "In die allerfernste Ferne", "tokens": ["In", "die", "al\u00b7ler\u00b7ferns\u00b7te", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wich das Augenpaar zur\u00fcck,", "tokens": ["Wich", "das", "Au\u00b7gen\u00b7paar", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch als zwei vereinte Sterne", "tokens": ["Doch", "als", "zwei", "ver\u00b7ein\u00b7te", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Flimmt es noch in meinen Blick.", "tokens": ["Flimmt", "es", "noch", "in", "mei\u00b7nen", "Blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Nehmt, o nehmt den Funken wieder,", "tokens": ["Nehmt", ",", "o", "nehmt", "den", "Fun\u00b7ken", "wie\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "FM", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der zu euch zur\u00fcck begehrt!", "tokens": ["Der", "zu", "euch", "zu\u00b7r\u00fcck", "be\u00b7gehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PTKVZ", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fchl' ich's doch, o neigt euch nieder,", "tokens": ["F\u00fchl'", "ich's", "doch", ",", "o", "neigt", "euch", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "$,", "FM", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ihr selbst ihn still entbehrt.", "tokens": ["Da\u00df", "ihr", "selbst", "ihn", "still", "ent\u00b7behrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Dieses D\u00e4mmersein auf Erden,", "tokens": ["Die\u00b7ses", "D\u00e4m\u00b7mer\u00b7sein", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4hnt ihr, es erlischt zu bald?", "tokens": ["W\u00e4hnt", "ihr", ",", "es", "er\u00b7lischt", "zu", "bald", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VVFIN", "APPR", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, der Wunsch, verzehrt zu werden,", "tokens": ["Ach", ",", "der", "Wunsch", ",", "ver\u00b7zehrt", "zu", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "$,", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist sein einziger Gehalt!", "tokens": ["Ist", "sein", "ein\u00b7zi\u00b7ger", "Ge\u00b7halt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Millionen \u00f6de Jahre", "tokens": ["Mil\u00b7lion\u00b7en", "\u00f6\u00b7de", "Jah\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Lag ich schon in dumpfem Schlaf,", "tokens": ["Lag", "ich", "schon", "in", "dum\u00b7pfem", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als aus einem Augenpaare", "tokens": ["Als", "aus", "ei\u00b7nem", "Au\u00b7gen\u00b7paa\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mich der Stralen erster traf.", "tokens": ["Mich", "der", "Stra\u00b7len", "ers\u00b7ter", "traf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Da begann ich, mich zu regen,", "tokens": ["Da", "be\u00b7gann", "ich", ",", "mich", "zu", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PRF", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich empfand des Werdens Schmerz,", "tokens": ["Ich", "emp\u00b7fand", "des", "Wer\u00b7dens", "Schmerz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit ungewissen Schl\u00e4gen", "tokens": ["Und", "mit", "un\u00b7ge\u00b7wis\u00b7sen", "Schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Setzte sich in mir ein Herz.", "tokens": ["Setz\u00b7te", "sich", "in", "mir", "ein", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "In die allerfernste Ferne", "tokens": ["In", "die", "al\u00b7ler\u00b7ferns\u00b7te", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wich das Augenpaar zur\u00fcck,", "tokens": ["Wich", "das", "Au\u00b7gen\u00b7paar", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch als zwei vereinte Sterne", "tokens": ["Doch", "als", "zwei", "ver\u00b7ein\u00b7te", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Flimmt es noch in meinen Blick.", "tokens": ["Flimmt", "es", "noch", "in", "mei\u00b7nen", "Blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nehmt, o nehmt den Funken wieder,", "tokens": ["Nehmt", ",", "o", "nehmt", "den", "Fun\u00b7ken", "wie\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "FM", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der zu euch zur\u00fcck begehrt!", "tokens": ["Der", "zu", "euch", "zu\u00b7r\u00fcck", "be\u00b7gehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "PTKVZ", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fchl' ich's doch, o neigt euch nieder,", "tokens": ["F\u00fchl'", "ich's", "doch", ",", "o", "neigt", "euch", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "$,", "FM", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df ihr selbst ihn still entbehrt.", "tokens": ["Da\u00df", "ihr", "selbst", "ihn", "still", "ent\u00b7behrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Dieses D\u00e4mmersein auf Erden,", "tokens": ["Die\u00b7ses", "D\u00e4m\u00b7mer\u00b7sein", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4hnt ihr, es erlischt zu bald?", "tokens": ["W\u00e4hnt", "ihr", ",", "es", "er\u00b7lischt", "zu", "bald", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VVFIN", "APPR", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, der Wunsch, verzehrt zu werden,", "tokens": ["Ach", ",", "der", "Wunsch", ",", "ver\u00b7zehrt", "zu", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "$,", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist sein einziger Gehalt!", "tokens": ["Ist", "sein", "ein\u00b7zi\u00b7ger", "Ge\u00b7halt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}