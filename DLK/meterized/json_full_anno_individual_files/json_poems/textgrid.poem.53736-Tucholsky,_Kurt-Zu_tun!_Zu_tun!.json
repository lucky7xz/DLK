{"textgrid.poem.53736": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Zu tun! Zu tun!", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Heute lese ich da in der Zeitung:", "tokens": ["Heu\u00b7te", "le\u00b7se", "ich", "da", "in", "der", "Zei\u00b7tung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "In Los Angeles gibts einen Schnapsverein,", "tokens": ["In", "Los", "An\u00b7ge\u00b7les", "gibts", "ei\u00b7nen", "Schnaps\u00b7ver\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "und man bef\u00fcrchtet seine Verbreitung", "tokens": ["und", "man", "be\u00b7f\u00fcrch\u00b7tet", "sei\u00b7ne", "Ver\u00b7brei\u00b7tung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "in dem \u00fcbrigen Land \u2013 dabei f\u00e4llt mir ein:", "tokens": ["in", "dem", "\u00fcb\u00b7ri\u00b7gen", "Land", "\u2013", "da\u00b7bei", "f\u00e4llt", "mir", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "PAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Ich sollte mal wieder an Edith schreiben", "tokens": ["Ich", "soll\u00b7te", "mal", "wie\u00b7der", "an", "E\u00b7dith", "schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "NE", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "(in Kalifornien) \u2013 seit Januar", "tokens": ["(", "in", "Ka\u00b7li\u00b7for\u00b7ni\u00b7en", ")", "\u2013", "seit", "Ja\u00b7nu\u00b7ar"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "APPR", "NE", "$(", "$(", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "liegt der Brief da, und ich la\u00df es bleiben", "tokens": ["liegt", "der", "Brief", "da", ",", "und", "ich", "la\u00df", "es", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADV", "$,", "KON", "PPER", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "und verschieb es nun schon ein halbes Jahr.", "tokens": ["und", "ver\u00b7schieb", "es", "nun", "schon", "ein", "hal\u00b7bes", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Das ist nicht richtig. Es nimmt mir die Ruh.", "tokens": ["Das", "ist", "nicht", "rich\u00b7tig", ".", "Es", "nimmt", "mir", "die", "Ruh", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Aber . . . ich komme nicht dazu.", "tokens": ["A\u00b7ber", ".", ".", ".", "ich", "kom\u00b7me", "nicht", "da\u00b7zu", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "$.", "$.", "PPER", "VVFIN", "PTKNEG", "PAV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Der Arzt sagt, ich soll mir Bewegung machen.", "tokens": ["Der", "Arzt", "sagt", ",", "ich", "soll", "mir", "Be\u00b7we\u00b7gung", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da gibt es so eine Schule f\u00fcr Sport . . .", "tokens": ["Da", "gibt", "es", "so", "ei\u00b7ne", "Schu\u00b7le", "f\u00fcr", "Sport", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auf dem Boden liegen noch alte Sachen,", "tokens": ["Auf", "dem", "Bo\u00b7den", "lie\u00b7gen", "noch", "al\u00b7te", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "die sollten doch l\u00e4ngst f\u00fcr die Armen fort!", "tokens": ["die", "soll\u00b7ten", "doch", "l\u00e4ngst", "f\u00fcr", "die", "Ar\u00b7men", "fort", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Bin ich an Vaterns Grab gewesen?", "tokens": ["Bin", "ich", "an", "Va\u00b7terns", "Grab", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich nehm es mir vor \u2013 und dabei wirds nie.", "tokens": ["Ich", "nehm", "es", "mir", "vor", "\u2013", "und", "da\u00b7bei", "wirds", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "PTKVZ", "$(", "KON", "PAV", "VAFIN", "ADV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Das Gelbbuch wollte ich immer mal lesen,", "tokens": ["Das", "Gelb\u00b7buch", "woll\u00b7te", "ich", "im\u00b7mer", "mal", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "das und Simmels Soziologie.", "tokens": ["das", "und", "Sim\u00b7mels", "So\u00b7zi\u00b7o\u00b7lo\u00b7gie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "NE", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Wie oft wollt ich schon nach Friedrichsruh!", "tokens": ["Wie", "oft", "wollt", "ich", "schon", "nach", "Fried\u00b7richs\u00b7ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "ADV", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Aber . . . ich komme nicht dazu.", "tokens": ["A\u00b7ber", ".", ".", ".", "ich", "kom\u00b7me", "nicht", "da\u00b7zu", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "$.", "$.", "PPER", "VVFIN", "PTKNEG", "PAV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "Einstmals, wenn die Posaunen schallen,", "tokens": ["Einst\u00b7mals", ",", "wenn", "die", "Po\u00b7sau\u00b7nen", "schal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "steigt auf der Berliner aus seinem Grab.", "tokens": ["steigt", "auf", "der", "Ber\u00b7li\u00b7ner", "aus", "sei\u00b7nem", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und er steht in der ersten Reihe vor allen \u2013", "tokens": ["Und", "er", "steht", "in", "der", "ers\u00b7ten", "Rei\u00b7he", "vor", "al\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "APPR", "PIAT", "$("], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "(\u00bbWeil ich doch meine Beziehungen hab!\u00ab)", "tokens": ["(", "\u00bb", "Weil", "ich", "doch", "mei\u00b7ne", "Be\u00b7zie\u00b7hun\u00b7gen", "hab", "!", "\u00ab", ")"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "$(", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "VAFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Gott, der Herr, mild und voll Frieden,", "tokens": ["Gott", ",", "der", "Herr", ",", "mild", "und", "voll", "Frie\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der \u00fcber allen Gew\u00e4ssern schwebt,", "tokens": ["der", "\u00fc\u00b7ber", "al\u00b7len", "Ge\u00b7w\u00e4s\u00b7sern", "schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "spricht: \u00bbBerliner! Was tatst du hienieden?", "tokens": ["spricht", ":", "\u00bb", "Ber\u00b7li\u00b7ner", "!", "Was", "tatst", "du", "hien\u00b7ie\u00b7den", "?"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "ADJA", "$.", "PWS", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Menschenskind! Wie hast du gelebt \u2013?\u00ab", "tokens": ["Men\u00b7schen\u00b7skind", "!", "Wie", "hast", "du", "ge\u00b7lebt", "\u2013", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$.", "PWAV", "VAFIN", "PPER", "VVPP", "$(", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Und der Berliner sagt darauf verschwommen:", "tokens": ["Und", "der", "Ber\u00b7li\u00b7ner", "sagt", "da\u00b7rauf", "ver\u00b7schwom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PAV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "\u00bbich . . . bin leider nicht dazu gekommen.\u00ab", "tokens": ["\u00bb", "ich", ".", ".", ".", "bin", "lei\u00b7der", "nicht", "da\u00b7zu", "ge\u00b7kom\u00b7men", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$.", "$.", "$.", "VAFIN", "ADV", "PTKNEG", "PAV", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Heute lese ich da in der Zeitung:", "tokens": ["Heu\u00b7te", "le\u00b7se", "ich", "da", "in", "der", "Zei\u00b7tung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "In Los Angeles gibts einen Schnapsverein,", "tokens": ["In", "Los", "An\u00b7ge\u00b7les", "gibts", "ei\u00b7nen", "Schnaps\u00b7ver\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "und man bef\u00fcrchtet seine Verbreitung", "tokens": ["und", "man", "be\u00b7f\u00fcrch\u00b7tet", "sei\u00b7ne", "Ver\u00b7brei\u00b7tung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "in dem \u00fcbrigen Land \u2013 dabei f\u00e4llt mir ein:", "tokens": ["in", "dem", "\u00fcb\u00b7ri\u00b7gen", "Land", "\u2013", "da\u00b7bei", "f\u00e4llt", "mir", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "PAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Ich sollte mal wieder an Edith schreiben", "tokens": ["Ich", "soll\u00b7te", "mal", "wie\u00b7der", "an", "E\u00b7dith", "schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "NE", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "(in Kalifornien) \u2013 seit Januar", "tokens": ["(", "in", "Ka\u00b7li\u00b7for\u00b7ni\u00b7en", ")", "\u2013", "seit", "Ja\u00b7nu\u00b7ar"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "APPR", "NE", "$(", "$(", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "liegt der Brief da, und ich la\u00df es bleiben", "tokens": ["liegt", "der", "Brief", "da", ",", "und", "ich", "la\u00df", "es", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADV", "$,", "KON", "PPER", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "und verschieb es nun schon ein halbes Jahr.", "tokens": ["und", "ver\u00b7schieb", "es", "nun", "schon", "ein", "hal\u00b7bes", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Das ist nicht richtig. Es nimmt mir die Ruh.", "tokens": ["Das", "ist", "nicht", "rich\u00b7tig", ".", "Es", "nimmt", "mir", "die", "Ruh", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Aber . . . ich komme nicht dazu.", "tokens": ["A\u00b7ber", ".", ".", ".", "ich", "kom\u00b7me", "nicht", "da\u00b7zu", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "$.", "$.", "PPER", "VVFIN", "PTKNEG", "PAV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Der Arzt sagt, ich soll mir Bewegung machen.", "tokens": ["Der", "Arzt", "sagt", ",", "ich", "soll", "mir", "Be\u00b7we\u00b7gung", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da gibt es so eine Schule f\u00fcr Sport . . .", "tokens": ["Da", "gibt", "es", "so", "ei\u00b7ne", "Schu\u00b7le", "f\u00fcr", "Sport", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auf dem Boden liegen noch alte Sachen,", "tokens": ["Auf", "dem", "Bo\u00b7den", "lie\u00b7gen", "noch", "al\u00b7te", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "die sollten doch l\u00e4ngst f\u00fcr die Armen fort!", "tokens": ["die", "soll\u00b7ten", "doch", "l\u00e4ngst", "f\u00fcr", "die", "Ar\u00b7men", "fort", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Bin ich an Vaterns Grab gewesen?", "tokens": ["Bin", "ich", "an", "Va\u00b7terns", "Grab", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich nehm es mir vor \u2013 und dabei wirds nie.", "tokens": ["Ich", "nehm", "es", "mir", "vor", "\u2013", "und", "da\u00b7bei", "wirds", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "PTKVZ", "$(", "KON", "PAV", "VAFIN", "ADV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Das Gelbbuch wollte ich immer mal lesen,", "tokens": ["Das", "Gelb\u00b7buch", "woll\u00b7te", "ich", "im\u00b7mer", "mal", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "das und Simmels Soziologie.", "tokens": ["das", "und", "Sim\u00b7mels", "So\u00b7zi\u00b7o\u00b7lo\u00b7gie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "NE", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Wie oft wollt ich schon nach Friedrichsruh!", "tokens": ["Wie", "oft", "wollt", "ich", "schon", "nach", "Fried\u00b7richs\u00b7ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "ADV", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Aber . . . ich komme nicht dazu.", "tokens": ["A\u00b7ber", ".", ".", ".", "ich", "kom\u00b7me", "nicht", "da\u00b7zu", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "$.", "$.", "PPER", "VVFIN", "PTKNEG", "PAV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Einstmals, wenn die Posaunen schallen,", "tokens": ["Einst\u00b7mals", ",", "wenn", "die", "Po\u00b7sau\u00b7nen", "schal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "steigt auf der Berliner aus seinem Grab.", "tokens": ["steigt", "auf", "der", "Ber\u00b7li\u00b7ner", "aus", "sei\u00b7nem", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und er steht in der ersten Reihe vor allen \u2013", "tokens": ["Und", "er", "steht", "in", "der", "ers\u00b7ten", "Rei\u00b7he", "vor", "al\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "APPR", "PIAT", "$("], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "(\u00bbWeil ich doch meine Beziehungen hab!\u00ab)", "tokens": ["(", "\u00bb", "Weil", "ich", "doch", "mei\u00b7ne", "Be\u00b7zie\u00b7hun\u00b7gen", "hab", "!", "\u00ab", ")"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "$(", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "VAFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Gott, der Herr, mild und voll Frieden,", "tokens": ["Gott", ",", "der", "Herr", ",", "mild", "und", "voll", "Frie\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der \u00fcber allen Gew\u00e4ssern schwebt,", "tokens": ["der", "\u00fc\u00b7ber", "al\u00b7len", "Ge\u00b7w\u00e4s\u00b7sern", "schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "spricht: \u00bbBerliner! Was tatst du hienieden?", "tokens": ["spricht", ":", "\u00bb", "Ber\u00b7li\u00b7ner", "!", "Was", "tatst", "du", "hien\u00b7ie\u00b7den", "?"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "ADJA", "$.", "PWS", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Menschenskind! Wie hast du gelebt \u2013?\u00ab", "tokens": ["Men\u00b7schen\u00b7skind", "!", "Wie", "hast", "du", "ge\u00b7lebt", "\u2013", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$.", "PWAV", "VAFIN", "PPER", "VVPP", "$(", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Und der Berliner sagt darauf verschwommen:", "tokens": ["Und", "der", "Ber\u00b7li\u00b7ner", "sagt", "da\u00b7rauf", "ver\u00b7schwom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PAV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "\u00bbich . . . bin leider nicht dazu gekommen.\u00ab", "tokens": ["\u00bb", "ich", ".", ".", ".", "bin", "lei\u00b7der", "nicht", "da\u00b7zu", "ge\u00b7kom\u00b7men", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "$.", "$.", "$.", "VAFIN", "ADV", "PTKNEG", "PAV", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}