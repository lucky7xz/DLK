{"dta.poem.9620": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Abschieds-lied.  \n S. D.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein hertz enth\u00e4lt sich kaum/ es will und mu\u00df zerbrechen/", "tokens": ["Mein", "hertz", "ent\u00b7h\u00e4lt", "sich", "kaum", "/", "es", "will", "und", "mu\u00df", "zer\u00b7bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "ADV", "$(", "PPER", "VMFIN", "KON", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein geist geht in der irr/ und kennt sich selbst nicht wohl/", "tokens": ["Mein", "geist", "geht", "in", "der", "irr", "/", "und", "kennt", "sich", "selbst", "nicht", "wohl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$(", "KON", "VVFIN", "PRF", "ADV", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil ich nicht wei\u00df/ mein lieb/ wenn ich euch werde sprechen/", "tokens": ["Weil", "ich", "nicht", "wei\u00df", "/", "mein", "lieb", "/", "wenn", "ich", "euch", "wer\u00b7de", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$(", "PPOSAT", "ADJD", "$(", "KOUS", "PPER", "PPER", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Indem ich itzt so weit von hinnen ziehen soll.", "tokens": ["In\u00b7dem", "ich", "itzt", "so", "weit", "von", "hin\u00b7nen", "zie\u00b7hen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "APPR", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Jhr winde/ kehret um/ und stellt euch mir zu wieder/", "tokens": ["Ihr", "win\u00b7de", "/", "keh\u00b7ret", "um", "/", "und", "stellt", "euch", "mir", "zu", "wie\u00b7der", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "APPR", "$(", "KON", "VVFIN", "PPER", "PPER", "PTKA", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bi\u00df da\u00df ich sie/ gleich wie sie mich/ gesegnet hat!", "tokens": ["Bi\u00df", "da\u00df", "ich", "sie", "/", "gleich", "wie", "sie", "mich", "/", "ge\u00b7seg\u00b7net", "hat", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PPER", "$(", "ADV", "KOKOM", "PPER", "PPER", "$(", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr segel haltet an/ legt euren hochmuth nieder!", "tokens": ["Ihr", "se\u00b7gel", "hal\u00b7tet", "an", "/", "legt", "eu\u00b7ren", "hoch\u00b7muth", "nie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$(", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir letzen uns noch erst/ und weinen uns recht salt.", "tokens": ["Wir", "let\u00b7zen", "uns", "noch", "erst", "/", "und", "wei\u00b7nen", "uns", "recht", "salt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$(", "KON", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Last ab/ mein\u2019 Argine/ und schonet eurer thr\u00e4nen/", "tokens": ["Last", "ab", "/", "mein'", "Ar\u00b7gi\u00b7ne", "/", "und", "scho\u00b7net", "eu\u00b7rer", "thr\u00e4\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$(", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was schw\u00e4cht ihr eu\u2019r gesicht/ ich mu\u00df doch endlich fort!", "tokens": ["Was", "schw\u00e4cht", "ihr", "eu'r", "ge\u00b7sicht", "/", "ich", "mu\u00df", "doch", "end\u00b7lich", "fort", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "VVPP", "$(", "PPER", "VMFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Je mehr ihr weint/ ie mehr werd\u2019 ich mich nach euch sehnen/", "tokens": ["Je", "mehr", "ihr", "weint", "/", "ie", "mehr", "werd'", "ich", "mich", "nach", "euch", "seh\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "$(", "ADV", "ADV", "VAFIN", "PPER", "PRF", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und irren ohne trost dort um den fremden port.", "tokens": ["Und", "ir\u00b7ren", "oh\u00b7ne", "trost", "dort", "um", "den", "frem\u00b7den", "port", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ich will in meine seel ein kleines hau\u00df euch bauen/", "tokens": ["Ich", "will", "in", "mei\u00b7ne", "seel", "ein", "klei\u00b7nes", "hau\u00df", "euch", "bau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In welches eure stets soll eingeschlossen seyn/", "tokens": ["In", "wel\u00b7ches", "eu\u00b7re", "stets", "soll", "ein\u00b7ge\u00b7schlos\u00b7sen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "ADV", "VMFIN", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und will hergegen euch auch meine seele trauen/", "tokens": ["Und", "will", "her\u00b7ge\u00b7gen", "euch", "auch", "mei\u00b7ne", "see\u00b7le", "trau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die hebt euch auff/ und schliest sie eurer seelen ein.", "tokens": ["Die", "hebt", "euch", "auff", "/", "und", "schliest", "sie", "eu\u00b7rer", "see\u00b7len", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "$(", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Kein thr\u00e4nlein fliesset ietzt von euren bleichen wangen/", "tokens": ["Kein", "thr\u00e4n\u00b7lein", "flies\u00b7set", "ietzt", "von", "eu\u00b7ren", "blei\u00b7chen", "wan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mu\u00df kein seuffzer auch aus eurem hertzen gehn/", "tokens": ["Und", "mu\u00df", "kein", "seuff\u00b7zer", "auch", "aus", "eu\u00b7rem", "hert\u00b7zen", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich habe sie mit flei\u00df zur beylag auffgefangen/", "tokens": ["Ich", "ha\u00b7be", "sie", "mit", "flei\u00df", "zur", "bey\u00b7lag", "auff\u00b7ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und lasse meine seel hiemit gef\u00fcllet stehn.", "tokens": ["Und", "las\u00b7se", "mei\u00b7ne", "seel", "hie\u00b7mit", "ge\u00b7f\u00fcl\u00b7let", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PAV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die sollen mit mir ziehn durch wetter/ wind und wellen/", "tokens": ["Die", "sol\u00b7len", "mit", "mir", "ziehn", "durch", "wet\u00b7ter", "/", "wind", "und", "wel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "PPER", "VVFIN", "APPR", "NN", "$(", "XY", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich nehme sie f\u00fcr euch zu meiner liebsten an/", "tokens": ["Ich", "neh\u00b7me", "sie", "f\u00fcr", "euch", "zu", "mei\u00b7ner", "liebs\u00b7ten", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "APPR", "PPOSAT", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auff da\u00df sie euer bild mir stets f\u00fcr augen stellen/", "tokens": ["Auff", "da\u00df", "sie", "eu\u00b7er", "bild", "mir", "stets", "f\u00fcr", "au\u00b7gen", "stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PPOSAT", "NN", "PPER", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und tragen/ was ich selbst nicht mit mir nehmen kan.", "tokens": ["Und", "tra\u00b7gen", "/", "was", "ich", "selbst", "nicht", "mit", "mir", "neh\u00b7men", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "PWS", "PPER", "ADV", "PTKNEG", "APPR", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Mit ihnen will ich mich besprechen und ergetzen/", "tokens": ["Mit", "ih\u00b7nen", "will", "ich", "mich", "be\u00b7spre\u00b7chen", "und", "er\u00b7get\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PPER", "PRF", "VVINF", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie sollen seyn mein trost in noth und traurigkeit;", "tokens": ["Sie", "sol\u00b7len", "seyn", "mein", "trost", "in", "noth", "und", "trau\u00b7rig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VAINF", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein gl\u00fcck/ kein b\u00f6ser fall soll mir di\u00df volck verletzen/", "tokens": ["Kein", "gl\u00fcck", "/", "kein", "b\u00f6\u00b7ser", "fall", "soll", "mir", "di\u00df", "volck", "ver\u00b7let\u00b7zen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "PIAT", "ADJA", "NN", "VMFIN", "PPER", "PDS", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein sturm und wilde fluth/ auch keiner winde streit/", "tokens": ["Kein", "sturm", "und", "wil\u00b7de", "fluth", "/", "auch", "kei\u00b7ner", "win\u00b7de", "streit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "ADJA", "NN", "$(", "ADV", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Kein frembdes weib soll sie durch ihre gunst vertreiben/", "tokens": ["Kein", "fremb\u00b7des", "weib", "soll", "sie", "durch", "ih\u00b7re", "gunst", "ver\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie sollen (hilfft mir Gott gesund hie zu euch her/)", "tokens": ["Sie", "sol\u00b7len", "(", "hilfft", "mir", "Gott", "ge\u00b7sund", "hie", "zu", "euch", "her", "/", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "$(", "VVFIN", "PPER", "NN", "ADJD", "ADV", "APPR", "PPER", "PTKVZ", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bezeugen meine treu und mein best\u00e4ndig-bleiben/", "tokens": ["Be\u00b7zeu\u00b7gen", "mei\u00b7ne", "treu", "und", "mein", "be\u00b7st\u00e4n\u00b7dig\u00b7blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJD", "KON", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sagen/ wie ich nie ein ander lieb begehr.", "tokens": ["Und", "sa\u00b7gen", "/", "wie", "ich", "nie", "ein", "an\u00b7der", "lieb", "be\u00b7gehr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "PWAV", "PPER", "ADV", "ART", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Jhr werdet selbst alsdann es an mir k\u00f6nnen schliessen/", "tokens": ["Ihr", "wer\u00b7det", "selbst", "als\u00b7dann", "es", "an", "mir", "k\u00f6n\u00b7nen", "schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPER", "APPR", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn dieses euer pfand durch meiner augen bach", "tokens": ["Wenn", "die\u00b7ses", "eu\u00b7er", "pfand", "durch", "mei\u00b7ner", "au\u00b7gen", "bach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aus lieb und fr\u00f6ligkeit euch wird entgegen fliessen/", "tokens": ["Aus", "lieb", "und", "fr\u00f6\u00b7lig\u00b7keit", "euch", "wird", "ent\u00b7ge\u00b7gen", "flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "NN", "PPER", "VAFIN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und r\u00fchmen meinen sinn/ mein lieben vor und nach.", "tokens": ["Und", "r\u00fch\u00b7men", "mei\u00b7nen", "sinn", "/", "mein", "lie\u00b7ben", "vor", "und", "nach", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$(", "PPOSAT", "ADJA", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Mit dem bedinge nun geh ich von euch zu scheiden.", "tokens": ["Mit", "dem", "be\u00b7din\u00b7ge", "nun", "geh", "ich", "von", "euch", "zu", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "ADV", "VVFIN", "PPER", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du/ Venus/ die du uns zusammen hast gef\u00fchrt/", "tokens": ["Du", "/", "Ve\u00b7nus", "/", "die", "du", "uns", "zu\u00b7sam\u00b7men", "hast", "ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "NE", "$(", "PRELS", "PPER", "PRF", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Komm abentlich zu steur mit deinem licht uns beyden/", "tokens": ["Komm", "a\u00b7bent\u00b7lich", "zu", "steur", "mit", "dei\u00b7nem", "licht", "uns", "bey\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKA", "ADJD", "APPR", "PPOSAT", "NN", "PPER", "PIAT", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was sie und mich betrifft/ werd auch an dir gesp\u00fchrt.", "tokens": ["Was", "sie", "und", "mich", "be\u00b7tr\u00b7ifft", "/", "werd", "auch", "an", "dir", "ge\u00b7sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "KON", "PPER", "VVFIN", "$(", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-++--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Traur ich wo/ oder sie/ so zeige deine wangen", "tokens": ["Traur", "ich", "wo", "/", "o\u00b7der", "sie", "/", "so", "zei\u00b7ge", "dei\u00b7ne", "wan\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PWAV", "$(", "KON", "PPER", "$(", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erblast/ als w\u00e4rest du auch neben uns in noth:", "tokens": ["Er\u00b7blast", "/", "als", "w\u00e4\u00b7rest", "du", "auch", "ne\u00b7ben", "uns", "in", "noth", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOKOM", "VAFIN", "PPER", "ADV", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Stehts wohl um sie und mich/ so solt du/ g\u00f6ldne/ prangen", "tokens": ["Stehts", "wohl", "um", "sie", "und", "mich", "/", "so", "solt", "du", "/", "g\u00f6ld\u00b7ne", "/", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "ADV", "APPR", "PPER", "KON", "PPER", "$(", "ADV", "VMFIN", "PPER", "$(", "ADJA", "$(", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit deinem besten glantz gemahlet rosen-roth.", "tokens": ["Mit", "dei\u00b7nem", "bes\u00b7ten", "glantz", "ge\u00b7mah\u00b7let", "ro\u00b7sen\u00b7roth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Und wo mir je mein lieb will etwas sagen lassen/", "tokens": ["Und", "wo", "mir", "je", "mein", "lieb", "will", "et\u00b7was", "sa\u00b7gen", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "PPOSAT", "ADJD", "VMFIN", "PIS", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So schick dein liebes volck f\u00fcr ihren zarten mund/", "tokens": ["So", "schick", "dein", "lie\u00b7bes", "volck", "f\u00fcr", "ih\u00b7ren", "zar\u00b7ten", "mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die meiner liebsten red\u2019 in ihre k\u00f6cher fassen/", "tokens": ["Die", "mei\u00b7ner", "liebs\u00b7ten", "red'", "in", "ih\u00b7re", "k\u00f6\u00b7cher", "fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "VVFIN", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und thun sie nachmahls mir vom hohen himmel kund.", "tokens": ["Und", "thun", "sie", "nach\u00b7mahls", "mir", "vom", "ho\u00b7hen", "him\u00b7mel", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPER", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Mu\u00df gleich das wilde meer uns von einander trennen/", "tokens": ["Mu\u00df", "gleich", "das", "wil\u00b7de", "meer", "uns", "von", "ein\u00b7an\u00b7der", "tren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "PPER", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So wollen wir durch dich dennoch beysammen seyn/", "tokens": ["So", "wol\u00b7len", "wir", "durch", "dich", "den\u00b7noch", "bey\u00b7sam\u00b7men", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPER", "ADV", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und unser beyder thun und leben stets erkennen/", "tokens": ["Und", "un\u00b7ser", "bey\u00b7der", "thun", "und", "le\u00b7ben", "stets", "er\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "KON", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns freuen in dem gl\u00fcck und tr\u00f6sten in der pein.", "tokens": ["Uns", "freu\u00b7en", "in", "dem", "gl\u00fcck", "und", "tr\u00f6s\u00b7ten", "in", "der", "pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}