{"dta.poem.19892": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Notgedrungene Epistel  \n des  \n ber\u00fchmten Schneiders  \n  Johannes Schere  \n an  \n Seinen Grosg\u00fcnstigen M\u00e4zen .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1778", "urn": "urn:nbn:de:kobv:b4-20090519672", "language": ["de:0.99"], "booktitle": "B\u00fcrger, Gottfried August: Gedichte. G\u00f6ttingen, 1778."}, "poem": {"stanza.1": {"line.1": {"text": "Wie k\u00fcmmerlich, troz seiner G\u00f6ttlichkeit,               ", "tokens": ["Wie", "k\u00fcm\u00b7mer\u00b7lich", ",", "troz", "sei\u00b7ner", "G\u00f6tt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sich oft Genie hier unterm Monde n\u00e4hre,", "tokens": ["Sich", "oft", "Ge\u00b7nie", "hier", "un\u00b7term", "Mon\u00b7de", "n\u00e4h\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "NN", "ADV", "APPRART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Beweisen uns die Keppler, die Homere,", "tokens": ["Be\u00b7wei\u00b7sen", "uns", "die", "Kepp\u00b7ler", ",", "die", "Ho\u00b7me\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und hundert grosse Geister, jeder Zeit,", "tokens": ["Und", "hun\u00b7dert", "gros\u00b7se", "Geis\u00b7ter", ",", "je\u00b7der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "CARD", "ADJA", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und jeder Erdenzone, weit und breit:", "tokens": ["Und", "je\u00b7der", "Er\u00b7den\u00b7zo\u00b7ne", ",", "weit", "und", "breit", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Doch warlich nicht zu sonderlicher Ehre", "tokens": ["Doch", "war\u00b7lich", "nicht", "zu", "son\u00b7der\u00b7li\u00b7cher", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "PTKZU", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Der undankbaren Menschlichkeit,", "tokens": ["Der", "un\u00b7dank\u00b7ba\u00b7ren", "Menschlich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die ihnen sp\u00e4te Dankalt\u00e4re", "tokens": ["Die", "ih\u00b7nen", "sp\u00e4\u00b7te", "Dan\u00b7kal\u00b7t\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und Opfer nach dem Tod\u2019 erst weiht.", "tokens": ["Und", "Op\u00b7fer", "nach", "dem", "Tod'", "erst", "weiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Auch mir verlieh, durch Schere, Zwirn und Nadel,", "tokens": ["Auch", "mir", "ver\u00b7lieh", ",", "durch", "Sche\u00b7re", ",", "Zwirn", "und", "Na\u00b7del", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Minerva Kunst und nicht gemeinen Adel.", "tokens": ["Mi\u00b7ner\u00b7va", "Kunst", "und", "nicht", "ge\u00b7mei\u00b7nen", "A\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "PTKNEG", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Allein der Lohn, f\u00fcr meine Treflichkeit,", "tokens": ["Al\u00b7lein", "der", "Lohn", ",", "f\u00fcr", "mei\u00b7ne", "Tref\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ist Hungersnot, ein Haderlumpenkleid,", "tokens": ["Ist", "Hun\u00b7gers\u00b7not", ",", "ein", "Ha\u00b7der\u00b7lum\u00b7pen\u00b7kleid", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ist obenein der schwachen Seelen Tadel,", "tokens": ["Ist", "o\u00b7be\u00b7nein", "der", "schwa\u00b7chen", "See\u00b7len", "Ta\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und dann einmal, nach Ablauf d\u00fcrrer Zeit,", "tokens": ["Und", "dann", "ein\u00b7mal", ",", "nach", "Ab\u00b7lauf", "d\u00fcr\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Des Namens Ruhm und Ewigkeit.", "tokens": ["Des", "Na\u00b7mens", "Ruhm", "und", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Allein was hilft\u2019s, wenn nach dem Tode,", "tokens": ["Al\u00b7lein", "was", "hilft's", ",", "wenn", "nach", "dem", "To\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mich Leichenpredigt oder Ode", "tokens": ["Mich", "Lei\u00b7chen\u00b7pre\u00b7digt", "o\u00b7der", "O\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den gr\u00f6sten aller Schneider nent,", "tokens": ["Den", "gr\u00f6s\u00b7ten", "al\u00b7ler", "Schnei\u00b7der", "nent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ein verg\u00fcldet Marmormonument,", "tokens": ["Und", "ein", "ver\u00b7g\u00fcl\u00b7det", "Mar\u00b7mor\u00b7mo\u00b7nu\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "An welchem Schere, Zwirn und Nadel hangen,", "tokens": ["An", "wel\u00b7chem", "Sche\u00b7re", ",", "Zwirn", "und", "Na\u00b7del", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und Fingerhut und B\u00fcgeleisen prangen,", "tokens": ["Und", "Fin\u00b7ger\u00b7hut", "und", "B\u00fc\u00b7ge\u00b7lei\u00b7sen", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Der sp\u00e4ten Nachwelt dies bekent?", "tokens": ["Der", "sp\u00e4\u00b7ten", "Nach\u00b7welt", "dies", "be\u00b7kent", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PDS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn lebend mich mein Zeitgenosse", "tokens": ["Wenn", "le\u00b7bend", "mich", "mein", "Zeit\u00b7ge\u00b7nos\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zu Stalle, gleich dem edlen Rosse,", "tokens": ["Zu", "Stal\u00b7le", ",", "gleich", "dem", "ed\u00b7len", "Ros\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Auf Stroh zu schlafen, von sich st\u00f6st,", "tokens": ["Auf", "Stroh", "zu", "schla\u00b7fen", ",", "von", "sich", "st\u00f6st", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$,", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und nackend gehn und hungern l\u00e4st?", "tokens": ["Und", "na\u00b7ckend", "gehn", "und", "hun\u00b7gern", "l\u00e4st", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "KON", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der St\u00fcmper, der zu meinen F\u00fcssen kreucht,", "tokens": ["Der", "St\u00fcm\u00b7per", ",", "der", "zu", "mei\u00b7nen", "F\u00fcs\u00b7sen", "kreucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Beschmizet zwar mit seines Neides Geifer,", "tokens": ["Be\u00b7schmi\u00b7zet", "zwar", "mit", "sei\u00b7nes", "Nei\u00b7des", "Gei\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weil nicht sein Blick an meine H\u00f6he reicht,", "tokens": ["Weil", "nicht", "sein", "Blick", "an", "mei\u00b7ne", "H\u00f6\u00b7he", "reicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Oft meinen Ruhm, und schreit: Ich w\u00e4r\u2019 ein S\u00e4ufer,", "tokens": ["Oft", "mei\u00b7nen", "Ruhm", ",", "und", "schreit", ":", "Ich", "w\u00e4r'", "ein", "S\u00e4u\u00b7fer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "KON", "ADJD", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und stets bedacht, mein G\u00fctchen zu verthun,", "tokens": ["Und", "stets", "be\u00b7dacht", ",", "mein", "G\u00fct\u00b7chen", "zu", "ver\u00b7thun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und liess\u2019 inde\u00df die edle Nadel ruhn.", "tokens": ["Und", "liess'", "in\u00b7de\u00df", "die", "ed\u00b7le", "Na\u00b7del", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "O schn\u00f6der Neid! Denn \u00fcberlegt man\u2019s reifer,", "tokens": ["O", "schn\u00f6\u00b7der", "Neid", "!", "Denn", "\u00fc\u00b7ber\u00b7legt", "man's", "rei\u00b7fer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "KON", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gesezt den Fal, die L\u00e4sierung sey wahr,", "tokens": ["Ge\u00b7sezt", "den", "Fal", ",", "die", "L\u00e4\u00b7sie\u00b7rung", "sey", "wahr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "So ist dabei doch ausgemacht und klar,", "tokens": ["So", "ist", "da\u00b7bei", "doch", "aus\u00b7ge\u00b7macht", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PAV", "ADV", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und es best\u00e4tigt dies die Menge der Exempel,", "tokens": ["Und", "es", "be\u00b7st\u00e4\u00b7tigt", "dies", "die", "Men\u00b7ge", "der", "Ex\u00b7em\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PDS", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Da\u00df solch ein Zug von je und je im Stempel", "tokens": ["Da\u00df", "solch", "ein", "Zug", "von", "je", "und", "je", "im", "Stem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "ART", "NN", "APPR", "ADV", "KON", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Erhabener Genieen war.", "tokens": ["Er\u00b7ha\u00b7be\u00b7ner", "Ge\u00b7ni\u00b7e\u00b7en", "war", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Sie binden sich nicht sklavisch an die Regel", "tokens": ["Sie", "bin\u00b7den", "sich", "nicht", "skla\u00b7visch", "an", "die", "Re\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "PTKNEG", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Lebensart, und fahren auf gut Gl\u00fck,", "tokens": ["Der", "Le\u00b7ben\u00b7sart", ",", "und", "fah\u00b7ren", "auf", "gut", "Gl\u00fck", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "VVFIN", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So wie der Wind der Laun\u2019 in ihre Segel", "tokens": ["So", "wie", "der", "Wind", "der", "Laun'", "in", "ih\u00b7re", "Se\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Just stossen mag, bald vorw\u00e4rts bald zur\u00fck,", "tokens": ["Just", "stos\u00b7sen", "mag", ",", "bald", "vor\u00b7w\u00e4rts", "bald", "zu\u00b7r\u00fck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VMFIN", "$,", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und lassen das gemeine Volk laviren.", "tokens": ["Und", "las\u00b7sen", "das", "ge\u00b7mei\u00b7ne", "Volk", "la\u00b7vi\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sie haben vor den seltnen Wunderthieren", "tokens": ["Sie", "ha\u00b7ben", "vor", "den", "selt\u00b7nen", "Wun\u00b7der\u00b7thie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein St\u00e4rkerrecht, da\u00df man sie sorgsam hegt,", "tokens": ["Ein", "St\u00e4r\u00b7ker\u00b7recht", ",", "da\u00df", "man", "sie", "sorg\u00b7sam", "hegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dankbar bekleidet und verpflegt,", "tokens": ["Dank\u00b7bar", "be\u00b7klei\u00b7det", "und", "ver\u00b7pflegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zu hoch und frei, sich selber zu geniren.", "tokens": ["Zu", "hoch", "und", "frei", ",", "sich", "sel\u00b7ber", "zu", "ge\u00b7ni\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "KON", "ADJD", "$,", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Und, wenn der Ueberflus verkehrter Welt", "tokens": ["Und", ",", "wenn", "der", "Ue\u00b7ber\u00b7flus", "ver\u00b7kehr\u00b7ter", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Oft Affen, Murmelthier\u2019 und Raben,", "tokens": ["Oft", "Af\u00b7fen", ",", "Mur\u00b7mel\u00b7thier'", "und", "Ra\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und Kakadu, und Papagei erh\u00e4lt:", "tokens": ["Und", "Ka\u00b7ka\u00b7du", ",", "und", "Pa\u00b7pa\u00b7gei", "er\u00b7h\u00e4lt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So solten sie den Leckerbissen haben,", "tokens": ["So", "sol\u00b7ten", "sie", "den", "Le\u00b7cker\u00b7bis\u00b7sen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Der von des Reichen Tische f\u00e4lt.", "tokens": ["Der", "von", "des", "Rei\u00b7chen", "Ti\u00b7sche", "f\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Allein wie karg ist die verkehrte Welt,", "tokens": ["Al\u00b7lein", "wie", "karg", "ist", "die", "ver\u00b7kehr\u00b7te", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "F\u00fcr ein Genie, mit ihren Gaben!", "tokens": ["F\u00fcr", "ein", "Ge\u00b7nie", ",", "mit", "ih\u00b7ren", "Ga\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wilst du davon ein redend Beispiel sehn,", "tokens": ["Wilst", "du", "da\u00b7von", "ein", "re\u00b7dend", "Bei\u00b7spiel", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PAV", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "So schau auf mich, grosg\u00fcnstiger M\u00e4zen,", "tokens": ["So", "schau", "auf", "mich", ",", "gros\u00b7g\u00fcns\u00b7ti\u00b7ger", "M\u00e4\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So guck\u2019 einmal, nebst deinem theuren Weibe,", "tokens": ["So", "guck'", "ein\u00b7mal", ",", "nebst", "dei\u00b7nem", "theu\u00b7ren", "Wei\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Auf meinen Rok, durch deines Fensters Scheibe,", "tokens": ["Auf", "mei\u00b7nen", "Rok", ",", "durch", "dei\u00b7nes", "Fens\u00b7ters", "Schei\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und sieh die Luft in hundert Hadern wehn,", "tokens": ["Und", "sieh", "die", "Luft", "in", "hun\u00b7dert", "Ha\u00b7dern", "wehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und meinen Leib dem Winter offen stehn!", "tokens": ["Und", "mei\u00b7nen", "Leib", "dem", "Win\u00b7ter", "of\u00b7fen", "stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sprich selbst einmal, ist\u2019s nicht die gr\u00f6ste Schande,", "tokens": ["Sprich", "selbst", "ein\u00b7mal", ",", "ist's", "nicht", "die", "gr\u00f6s\u00b7te", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "$,", "VAFIN", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Da\u00df mich, der ich mit seidenem Gewande", "tokens": ["Da\u00df", "mich", ",", "der", "ich", "mit", "sei\u00b7de\u00b7nem", "Ge\u00b7wan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "So oft bekleidete des Landes Grazien,", "tokens": ["So", "oft", "be\u00b7klei\u00b7de\u00b7te", "des", "Lan\u00b7des", "Gra\u00b7zi\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Welt nun l\u00e4st in Haderlumpen gehn?", "tokens": ["Die", "Welt", "nun", "l\u00e4st", "in", "Ha\u00b7der\u00b7lum\u00b7pen", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Kan dies dich nicht zu mildem Mitleid reizen,", "tokens": ["Kan", "dies", "dich", "nicht", "zu", "mil\u00b7dem", "Mit\u00b7leid", "rei\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "PRF", "PTKNEG", "PTKZU", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Mit einer Kleinigkeit mir h\u00fclfreich beizustehn,", "tokens": ["Mit", "ei\u00b7ner", "Klei\u00b7nig\u00b7keit", "mir", "h\u00fclf\u00b7reich", "bei\u00b7zu\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Zur Menschheit Ehre nicht zu geizen? \u2014", "tokens": ["Zur", "Menschheit", "Eh\u00b7re", "nicht", "zu", "gei\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "NN", "PTKNEG", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "O ja! Ich kan auf deine G\u00fcte baun!", "tokens": ["O", "ja", "!", "Ich", "kan", "auf", "dei\u00b7ne", "G\u00fc\u00b7te", "baun", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Mich st\u00e4rkt manch Beispiel deiner Liebesthaten,", "tokens": ["Mich", "st\u00e4rkt", "manch", "Bei\u00b7spiel", "dei\u00b7ner", "Lie\u00b7best\u00b7ha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Und h\u00e4lt allein, mein wankendes Vertraun.", "tokens": ["Und", "h\u00e4lt", "al\u00b7lein", ",", "mein", "wan\u00b7ken\u00b7des", "Ver\u00b7traun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Sonst w\u00fcst\u2019 ich mich f\u00fcrwahr nicht zu berathen.", "tokens": ["Sonst", "w\u00fcst'", "ich", "mich", "f\u00fcr\u00b7wahr", "nicht", "zu", "be\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Drum borge du mir, f\u00fcr ein besser Kleid,", "tokens": ["Drum", "bor\u00b7ge", "du", "mir", ",", "f\u00fcr", "ein", "bes\u00b7ser", "Kleid", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Zu Schuz und Truz, in dieser rauhen Zeit,", "tokens": ["Zu", "Schuz", "und", "Truz", ",", "in", "die\u00b7ser", "rau\u00b7hen", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Nur Einen lumpigen Dukaten!", "tokens": ["Nur", "Ei\u00b7nen", "lum\u00b7pi\u00b7gen", "Du\u00b7ka\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Mit Dank bin ich ihn jederzeit,", "tokens": ["Mit", "Dank", "bin", "ich", "ihn", "je\u00b7der\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Durch k\u00fcnstliche und dauerhafte Nathen,", "tokens": ["Durch", "k\u00fcnst\u00b7li\u00b7che", "und", "dau\u00b7er\u00b7haf\u00b7te", "Na\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Abzuverdienen gern bereit.", "tokens": ["Ab\u00b7zu\u00b7ver\u00b7die\u00b7nen", "gern", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}