{"textgrid.poem.62612": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Als der Leichnam des Wohlgebohrnen Herrn von Milwitz in der Heil. Wipperts-Kirchen zu Erfurt beerdiget, und von denen R.R.P.P. Augustinern die solennen Exequien gehalten wurden.", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die hohe Allmachts-Hand, die alles mit Bedacht", "tokens": ["Die", "ho\u00b7he", "All\u00b7machts\u00b7Hand", ",", "die", "al\u00b7les", "mit", "Be\u00b7dacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sehr wei\u00dflich und sehr sch\u00f6n und wundervoll gemacht,", "tokens": ["Sehr", "wei\u00df\u00b7lich", "und", "sehr", "sch\u00f6n", "und", "wun\u00b7der\u00b7voll", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat auch beym Anfang gleich da kaum die Welt geworden,", "tokens": ["Hat", "auch", "beym", "An\u00b7fang", "gleich", "da", "kaum", "die", "Welt", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "ADV", "ADV", "ADV", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Menschen sich gemehrt, verschiedne St\u00e4nd und Orden", "tokens": ["Und", "Men\u00b7schen", "sich", "ge\u00b7mehrt", ",", "ver\u00b7schied\u00b7ne", "St\u00e4nd", "und", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "PRF", "VVPP", "$,", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gemacht und eingesetzt. Dem einen gab sie viel", "tokens": ["Ge\u00b7macht", "und", "ein\u00b7ge\u00b7setzt", ".", "Dem", "ei\u00b7nen", "gab", "sie", "viel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "$.", "ART", "PIS", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von Weisheit und Verstand, so, da\u00df sein Wort das Ziel", "tokens": ["Von", "Weis\u00b7heit", "und", "Ver\u00b7stand", ",", "so", ",", "da\u00df", "sein", "Wort", "das", "Ziel"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ADV", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und auch die Regel war, wornach in allen Dingen", "tokens": ["Und", "auch", "die", "Re\u00b7gel", "war", ",", "wor\u00b7nach", "in", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "$,", "PWAV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die andern sich gericht, und nach demselben giengen.", "tokens": ["Die", "an\u00b7dern", "sich", "ge\u00b7richt", ",", "und", "nach", "dem\u00b7sel\u00b7ben", "gien\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PRF", "VVPP", "$,", "KON", "APPR", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dem andern legte sie viel Geld und G\u00fcter bey,", "tokens": ["Dem", "an\u00b7dern", "leg\u00b7te", "sie", "viel", "Geld", "und", "G\u00fc\u00b7ter", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PIAT", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Damit er m\u00e4chtiger als wie sein Mitknecht sey.", "tokens": ["Da\u00b7mit", "er", "m\u00e4ch\u00b7ti\u00b7ger", "als", "wie", "sein", "Mit\u00b7knecht", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "KOUS", "KOKOM", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den dritten cr\u00f6nte sie mit Herrlichkeit und Ehre,", "tokens": ["Den", "drit\u00b7ten", "cr\u00f6n\u00b7te", "sie", "mit", "Herr\u00b7lich\u00b7keit", "und", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Damit ein Unterschied in denen St\u00e4nden w\u00e4re.", "tokens": ["Da\u00b7mit", "ein", "Un\u00b7ter\u00b7schied", "in", "de\u00b7nen", "St\u00e4n\u00b7den", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "APPR", "PRELS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und diese Ordnung steht auch jetzo noch so fest,", "tokens": ["Und", "die\u00b7se", "Ord\u00b7nung", "steht", "auch", "jet\u00b7zo", "noch", "so", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ADV", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und so gewi\u00df, als sich in Ost, S\u00fcd, Nord und West", "tokens": ["Und", "so", "ge\u00b7wi\u00df", ",", "als", "sich", "in", "Ost", ",", "S\u00fcd", ",", "Nord", "und", "West"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "$,", "KOUS", "PRF", "APPR", "NE", "$,", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ein Element bewegt, und sein Gesch\u00e4fte treibet.", "tokens": ["Ein", "E\u00b7le\u00b7ment", "be\u00b7wegt", ",", "und", "sein", "Ge\u00b7sch\u00e4f\u00b7te", "trei\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ja, da\u00df die Republic in Flor und Ordnung bleibet,", "tokens": ["Ja", ",", "da\u00df", "die", "Re\u00b7pub\u00b7lic", "in", "Flor", "und", "Ord\u00b7nung", "blei\u00b7bet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So mu\u00df ein Unterschied in denen St\u00e4nden seyn.", "tokens": ["So", "mu\u00df", "ein", "Un\u00b7ter\u00b7schied", "in", "de\u00b7nen", "St\u00e4n\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "APPR", "PRELS", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch sind die St\u00e4nde nicht in allem \u00fcberein:", "tokens": ["Doch", "sind", "die", "St\u00e4n\u00b7de", "nicht", "in", "al\u00b7lem", "\u00fc\u00b7be\u00b7re\u00b7in", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKNEG", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Der ziert den Richter-Stab und tr\u00e4gt ihn ohne Tadel.", "tokens": ["Der", "ziert", "den", "Rich\u00b7ter\u00b7Stab", "und", "tr\u00e4gt", "ihn", "oh\u00b7ne", "Ta\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den andern aber schm\u00fcckt Helm, Degen, Wappen, Adel.", "tokens": ["Den", "an\u00b7dern", "a\u00b7ber", "schm\u00fcckt", "Helm", ",", "De\u00b7gen", ",", "Wap\u00b7pen", ",", "A\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn ob man wohl nicht leicht auf die Gedanken f\u00e4llt,", "tokens": ["Denn", "ob", "man", "wohl", "nicht", "leicht", "auf", "die", "Ge\u00b7dan\u00b7ken", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "PTKNEG", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und zu behaupten sucht, da\u00df in der ersten Welt", "tokens": ["Und", "zu", "be\u00b7haup\u00b7ten", "sucht", ",", "da\u00df", "in", "der", "ers\u00b7ten", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKZU", "VVINF", "VVFIN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Adel, wie wir ihn zu unsern Zeiten sehen,", "tokens": ["Der", "A\u00b7del", ",", "wie", "wir", "ihn", "zu", "un\u00b7sern", "Zei\u00b7ten", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auch eingesetzet w\u00e4r; indem die\u00df erst geschehen,", "tokens": ["Auch", "ein\u00b7ge\u00b7set\u00b7zet", "w\u00e4r", ";", "in\u00b7dem", "die\u00df", "erst", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$.", "KOUS", "PDS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als man die Tugenden aus jener dunklen Nacht", "tokens": ["Als", "man", "die", "Tu\u00b7gen\u00b7den", "aus", "je\u00b7ner", "dunk\u00b7len", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "NN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit Flei\u00df hervor gesucht, und an das Licht gebracht;", "tokens": ["Mit", "Flei\u00df", "her\u00b7vor", "ge\u00b7sucht", ",", "und", "an", "das", "Licht", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "VVPP", "$,", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So ist uns doch bewust, das in den ersten Zeiten,", "tokens": ["So", "ist", "uns", "doch", "be\u00b7wust", ",", "das", "in", "den", "ers\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$,", "PRELS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Eins vor dem anderen besondre Herrlichkeiten", "tokens": ["Eins", "vor", "dem", "an\u00b7de\u00b7ren", "be\u00b7sond\u00b7re", "Herr\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und W\u00fcrde \u00fcberkam: Die warlich merklich leicht,", "tokens": ["Und", "W\u00fcr\u00b7de", "\u00fc\u00b7ber\u00b7kam", ":", "Die", "war\u00b7lich", "merk\u00b7lich", "leicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$.", "ART", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und auch dem Adel-Stand an Schmuck und Ehre gleicht,", "tokens": ["Und", "auch", "dem", "A\u00b7del\u00b7Stand", "an", "Schmuck", "und", "Eh\u00b7re", "gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Es mu\u00df der Adel-Stand wohl freylich auf der Erden,", "tokens": ["Es", "mu\u00df", "der", "A\u00b7del\u00b7Stand", "wohl", "frey\u00b7lich", "auf", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nicht etwa obenhin, so schlecht betrachtet werden;", "tokens": ["Nicht", "et\u00b7wa", "o\u00b7ben\u00b7hin", ",", "so", "schlecht", "be\u00b7trach\u00b7tet", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "$,", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Sein Purpur, Feder, Helm, Schild, Wappen, Fahn und Stahl,", "tokens": ["Sein", "Pur\u00b7pur", ",", "Fe\u00b7der", ",", "Helm", ",", "Schild", ",", "Wap\u00b7pen", ",", "Fahn", "und", "Stahl", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und was man sonst noch nennt, bezeugen allzumahl,", "tokens": ["Und", "was", "man", "sonst", "noch", "nennt", ",", "be\u00b7zeu\u00b7gen", "all\u00b7zu\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "ADV", "VVFIN", "$,", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie hoch sein Glanz und Ruhm und Ansehn ist gestiegen,", "tokens": ["Wie", "hoch", "sein", "Glanz", "und", "Ruhm", "und", "An\u00b7sehn", "ist", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "KON", "NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und was er vor ein Recht des Vorzugs muste kriegen.", "tokens": ["Und", "was", "er", "vor", "ein", "Recht", "des", "Vor\u00b7zugs", "mus\u00b7te", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der Ahnen sch\u00f6ne Reih bef\u00f6rdert seine Ehr,", "tokens": ["Der", "Ah\u00b7nen", "sch\u00f6\u00b7ne", "Reih", "be\u00b7f\u00f6r\u00b7dert", "sei\u00b7ne", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Vergr\u00f6ssert seine Pracht und Sch\u00f6nheit desto mehr.", "tokens": ["Ver\u00b7gr\u00f6s\u00b7sert", "sei\u00b7ne", "Pracht", "und", "Sch\u00f6n\u00b7heit", "des\u00b7to", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Allein, was ist doch wohl der hocherh\u00f6hte Adel", "tokens": ["Al\u00b7lein", ",", "was", "ist", "doch", "wohl", "der", "ho\u00b7cher\u00b7h\u00f6h\u00b7te", "A\u00b7del"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn er nicht Tugend hat? Ein Compa\u00df ohne Nadel,", "tokens": ["Wenn", "er", "nicht", "Tu\u00b7gend", "hat", "?", "Ein", "Com\u00b7pa\u00df", "oh\u00b7ne", "Na\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "VAFIN", "$.", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Licht, das keinen Schein und Nutzen von sich giebt.", "tokens": ["Ein", "Licht", ",", "das", "kei\u00b7nen", "Schein", "und", "Nut\u00b7zen", "von", "sich", "giebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer vom Geschlechte nicht die \u00e4chte Tugend liebt,", "tokens": ["Wer", "vom", "Ge\u00b7schlech\u00b7te", "nicht", "die", "\u00e4ch\u00b7te", "Tu\u00b7gend", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der kan sich nicht mit Recht ber\u00fchmt und edel nennen.", "tokens": ["Der", "kan", "sich", "nicht", "mit", "Recht", "be\u00b7r\u00fchmt", "und", "e\u00b7del", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PRF", "PTKNEG", "APPR", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So viele Tugenden mu\u00df er als eigen kennen,", "tokens": ["So", "vie\u00b7le", "Tu\u00b7gen\u00b7den", "mu\u00df", "er", "als", "ei\u00b7gen", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VMFIN", "PPER", "KOUS", "ADJD", "VVINF", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "So viel er Ahnen w\u00fcnscht und auch wohl zehlen kan:", "tokens": ["So", "viel", "er", "Ah\u00b7nen", "w\u00fcnscht", "und", "auch", "wohl", "zeh\u00b7len", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "NN", "VVFIN", "KON", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dann hei\u00dft er erst mit Recht ein wahrer Edelmann.", "tokens": ["Dann", "hei\u00dft", "er", "erst", "mit", "Recht", "ein", "wah\u00b7rer", "E\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein solcher kunte wohl ", "tokens": ["Ein", "sol\u00b7cher", "kun\u00b7te", "wohl"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIAT", "VMFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Er suchte nicht zum Pracht die Ahnen aufzuweisen,", "tokens": ["Er", "such\u00b7te", "nicht", "zum", "Pracht", "die", "Ah\u00b7nen", "auf\u00b7zu\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Noch da\u00df Er Prahlerisch dieselben her erzehlt!", "tokens": ["Noch", "da\u00df", "Er", "Prah\u00b7le\u00b7risch", "die\u00b7sel\u00b7ben", "her", "er\u00b7zehlt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "NN", "PDAT", "APZR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Tugend hatte Er mit selbigen verm\u00e4hlt.", "tokens": ["Die", "Tu\u00b7gend", "hat\u00b7te", "Er", "mit", "sel\u00b7bi\u00b7gen", "ver\u00b7m\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die kunten nie den Grund zu eingen Hochmuth legen.", "tokens": ["Die", "kun\u00b7ten", "nie", "den", "Grund", "zu", "ein\u00b7gen", "Hoch\u00b7muth", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er war dem Ehrgeiz feind, er war der Wollust gram,", "tokens": ["Er", "war", "dem", "Ehr\u00b7geiz", "feind", ",", "er", "war", "der", "Wol\u00b7lust", "gram", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die auch kein freches Thun und Wesen an sich nahm.", "tokens": ["Die", "auch", "kein", "fre\u00b7ches", "Thun", "und", "We\u00b7sen", "an", "sich", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "ADJA", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Er liebte seinen Gott, die Demuth war sein Wissen,", "tokens": ["Er", "lieb\u00b7te", "sei\u00b7nen", "Gott", ",", "die", "De\u00b7muth", "war", "sein", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Indem er sich nur stets der Eitelkeit entrissen.", "tokens": ["In\u00b7dem", "er", "sich", "nur", "stets", "der", "Ei\u00b7tel\u00b7keit", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Er wu\u00dfte nichts von Schein, Betrug und Heucheley,", "tokens": ["Er", "wu\u00df\u00b7te", "nichts", "von", "Schein", ",", "Be\u00b7trug", "und", "Heu\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er war ein Redlicher nach alter Deutschen Treu.", "tokens": ["Er", "war", "ein", "Red\u00b7li\u00b7cher", "nach", "al\u00b7ter", "Deut\u00b7schen", "Treu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "O! da\u00df die ewge Macht beym Anfang aller Sachen", "tokens": ["O", "!", "da\u00df", "die", "ew\u00b7ge", "Macht", "beym", "An\u00b7fang", "al\u00b7ler", "Sa\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So einen festen Bund zugleich beliebt zu machen,", "tokens": ["So", "ei\u00b7nen", "fes\u00b7ten", "Bund", "zu\u00b7gleich", "be\u00b7liebt", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der alles Fleisch betrift, und der uns sterblich macht:", "tokens": ["Der", "al\u00b7les", "Fleisch", "be\u00b7trift", ",", "und", "der", "uns", "sterb\u00b7lich", "macht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "KON", "ART", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Hier wird kein Reichthum nicht noch Adel-Stand betracht.", "tokens": ["Hier", "wird", "kein", "Reicht\u00b7hum", "nicht", "noch", "A\u00b7del\u00b7Stand", "be\u00b7tracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PTKNEG", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der Tod nimmt nicht nur die zu sich in seine Kammer,", "tokens": ["Der", "Tod", "nimmt", "nicht", "nur", "die", "zu", "sich", "in", "sei\u00b7ne", "Kam\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ADV", "ART", "APPR", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die arm und elend seyn, die nichts als Angst und Jammer", "tokens": ["Die", "arm", "und", "e\u00b7lend", "seyn", ",", "die", "nichts", "als", "Angst", "und", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAINF", "$,", "PRELS", "PIS", "KOKOM", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "An jedem Morgen sehn; er reist auch die mit fort,", "tokens": ["An", "je\u00b7dem", "Mor\u00b7gen", "sehn", ";", "er", "reist", "auch", "die", "mit", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$.", "PPER", "VVFIN", "ADV", "ART", "APPR", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die reich und vornehm sind. Des Todes ernstes Wort", "tokens": ["Die", "reich", "und", "vor\u00b7nehm", "sind", ".", "Des", "To\u00b7des", "erns\u00b7tes", "Wort"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ergehet auch an den, der nach der Tugend wandelt,", "tokens": ["Er\u00b7ge\u00b7het", "auch", "an", "den", ",", "der", "nach", "der", "Tu\u00b7gend", "wan\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.29": {"text": "Und bey erh\u00f6hten Stand und Reichthum redlich handelt.", "tokens": ["Und", "bey", "er\u00b7h\u00f6h\u00b7ten", "Stand", "und", "Reicht\u00b7hum", "red\u00b7lich", "han\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "KON", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "O Tod! wie hast du dich so k\u00fchn und unverzagt,", "tokens": ["O", "Tod", "!", "wie", "hast", "du", "dich", "so", "k\u00fchn", "und", "un\u00b7ver\u00b7zagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWAV", "VAFIN", "PPER", "PRF", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Auch an das Lebens-Schif des ", "tokens": ["Auch", "an", "das", "Le\u00b7bens\u00b7Schif", "des"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "Mu\u00df seines Leibes-Bau zerbrechen und zerschellen?", "tokens": ["Mu\u00df", "sei\u00b7nes", "Lei\u00b7bes\u00b7Bau", "zer\u00b7bre\u00b7chen", "und", "zer\u00b7schel\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wie? hast du noch ", "tokens": ["Wie", "?", "hast", "du", "noch"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.34": {"text": "Du rei\u00dft das Adliche ber\u00fchmte Wappen ab,", "tokens": ["Du", "rei\u00dft", "das", "Ad\u00b7li\u00b7che", "be\u00b7r\u00fchm\u00b7te", "Wap\u00b7pen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und wirfst es neben ihm zerbrochen in das Grab", "tokens": ["Und", "wirfst", "es", "ne\u00b7ben", "ihm", "zer\u00b7bro\u00b7chen", "in", "das", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPER", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So ists in dieser Welt, Einmahl ist uns das Leben,", "tokens": ["So", "ists", "in", "die\u00b7ser", "Welt", ",", "Ein\u00b7mahl", "ist", "uns", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PDAT", "NN", "$,", "ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom Herrn der Creatur auf eine Zeit gegeben,", "tokens": ["Vom", "Herrn", "der", "Crea\u00b7tur", "auf", "ei\u00b7ne", "Zeit", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ist nun dieselbe um, so thut des Todes Hand,", "tokens": ["Ist", "nun", "die\u00b7sel\u00b7be", "um", ",", "so", "thut", "des", "To\u00b7des", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein Reichthum, kein Geschlecht den kleinsten Widerstand.", "tokens": ["Kein", "Reicht\u00b7hum", ",", "kein", "Ge\u00b7schlecht", "den", "kleins\u00b7ten", "Wi\u00b7der\u00b7stand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der H\u00f6chste h\u00e4lt es so, er hei\u00dft die Menschen sterben.", "tokens": ["Der", "H\u00f6chs\u00b7te", "h\u00e4lt", "es", "so", ",", "er", "hei\u00dft", "die", "Men\u00b7schen", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier baut er ein Geschlecht, dort l\u00e4\u00dft er eins verderben.", "tokens": ["Hier", "baut", "er", "ein", "Ge\u00b7schlecht", ",", "dort", "l\u00e4\u00dft", "er", "eins", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Schau-Platz ist die Welt. Man legt die Kleider an,", "tokens": ["Ein", "Schau\u00b7Platz", "ist", "die", "Welt", ".", "Man", "legt", "die", "Klei\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$.", "PIS", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Jetzt tritt ein J\u00fcngling auf, und diesem folgt ein Mann,", "tokens": ["Jetzt", "tritt", "ein", "J\u00fcng\u00b7ling", "auf", ",", "und", "die\u00b7sem", "folgt", "ein", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "PDS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und spielt die Rolle weg, und gehet dann zur\u00fccke.", "tokens": ["Und", "spielt", "die", "Rol\u00b7le", "weg", ",", "und", "ge\u00b7het", "dann", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wer nun mit Vorbedacht, mit Sch\u00f6nheit, Witz und Gl\u00fccke", "tokens": ["Wer", "nun", "mit", "Vor\u00b7be\u00b7dacht", ",", "mit", "Sch\u00f6n\u00b7heit", ",", "Witz", "und", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Rolle durchgespielt. Ich meine, wer mit Flei\u00df", "tokens": ["Die", "Rol\u00b7le", "durch\u00b7ge\u00b7spielt", ".", "Ich", "mei\u00b7ne", ",", "wer", "mit", "Flei\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PPER", "VVFIN", "$,", "PWS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nach denen Tugenden und g\u00f6ttlichem Gehei\u00df", "tokens": ["Nach", "de\u00b7nen", "Tu\u00b7gen\u00b7den", "und", "g\u00f6tt\u00b7li\u00b7chem", "Ge\u00b7hei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "NN", "KON", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Sein Leben angestellt, und sich so aufgef\u00fchret,", "tokens": ["Sein", "Le\u00b7ben", "an\u00b7ge\u00b7stellt", ",", "und", "sich", "so", "auf\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "KON", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df jedermann von ihm was l\u00f6bliches gesp\u00fchret,", "tokens": ["Da\u00df", "je\u00b7der\u00b7mann", "von", "ihm", "was", "l\u00f6b\u00b7li\u00b7ches", "ge\u00b7sp\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "PIS", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und gehet dann davon und l\u00e4\u00dft den Schau-Platz stehn,", "tokens": ["Und", "ge\u00b7het", "dann", "da\u00b7von", "und", "l\u00e4\u00dft", "den", "Schau\u00b7Platz", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "KON", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Dem suchet Ehr und Ruhm auf ewig nachzugehn.", "tokens": ["Dem", "su\u00b7chet", "Ehr", "und", "Ruhm", "auf", "e\u00b7wig", "nach\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "KON", "NN", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Nun hat ", "tokens": ["Nun", "hat"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.18": {"text": "Den Schau-Platz dieser Welt mit vielem Ruhm verlassen:", "tokens": ["Den", "Schau\u00b7Platz", "die\u00b7ser", "Welt", "mit", "vie\u00b7lem", "Ruhm", "ver\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "APPR", "PIS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Drum wird man Prei\u00df und Lob auf seine Bahre streun,", "tokens": ["Drum", "wird", "man", "Prei\u00df", "und", "Lob", "auf", "sei\u00b7ne", "Bah\u00b7re", "streun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PIS", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Sein holdes Angedenk mu\u00df unverge\u00dflich seyn.", "tokens": ["Sein", "hol\u00b7des", "An\u00b7ge\u00b7denk", "mu\u00df", "un\u00b7ver\u00b7ge\u00df\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sein Hingang aus der Zeit nach jenen finstern Bogen,", "tokens": ["Sein", "Hin\u00b7gang", "aus", "der", "Zeit", "nach", "je\u00b7nen", "fins\u00b7tern", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Hat manche Traurigkeit und Seufzer nachgezogen.", "tokens": ["Hat", "man\u00b7che", "Trau\u00b7rig\u00b7keit", "und", "Seuf\u00b7zer", "nach\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So, wie sein Todes-Fall so manche Brust erschreckt,", "tokens": ["So", ",", "wie", "sein", "To\u00b7des\u00b7Fall", "so", "man\u00b7che", "Brust", "er\u00b7schreckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So viel Verwunderung hat er zugleich erweckt.", "tokens": ["So", "viel", "Ver\u00b7wun\u00b7de\u00b7rung", "hat", "er", "zu\u00b7gleich", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "Denn der, so ihm das Ziel des Lebens auserkohren,", "tokens": ["Denn", "der", ",", "so", "ihm", "das", "Ziel", "des", "Le\u00b7bens", "au\u00b7ser\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "ADV", "PPER", "ART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der, so die Stunde rief, darinn er ward gebohren.", "tokens": ["Der", ",", "so", "die", "Stun\u00b7de", "rief", ",", "da\u00b7rinn", "er", "ward", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ART", "NN", "VVFIN", "$,", "PAV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Der hat es gleichfals auch beschlossen und bestellt,", "tokens": ["Der", "hat", "es", "gleich\u00b7fals", "auch", "be\u00b7schlos\u00b7sen", "und", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da\u00df er zu gleicher Zeit und Stunde auch die Welt", "tokens": ["Da\u00df", "er", "zu", "glei\u00b7cher", "Zeit", "und", "Stun\u00b7de", "auch", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "KON", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hinwieder lassen soll. Die Nacht, in der er kommen", "tokens": ["Hin\u00b7wie\u00b7der", "las\u00b7sen", "soll", ".", "Die", "Nacht", ",", "in", "der", "er", "kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVINF", "VMFIN", "$.", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Hat ihn auch ebenfals das Leben weggenommen.", "tokens": ["Hat", "ihn", "auch", "e\u00b7ben\u00b7fals", "das", "Le\u00b7ben", "weg\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wie wunderbar ist doch der Rath der Ewigkeit!", "tokens": ["Wie", "wun\u00b7der\u00b7bar", "ist", "doch", "der", "Rath", "der", "E\u00b7wig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zeigt das Verh\u00e4ngni\u00df nicht die gr\u00f6\u00dfte Seltenheit?", "tokens": ["Zeigt", "das", "Ver\u00b7h\u00e4ng\u00b7ni\u00df", "nicht", "die", "gr\u00f6\u00df\u00b7te", "Sel\u00b7ten\u00b7heit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn dieses l\u00e4sset jetzt auch dem ", "tokens": ["Denn", "die\u00b7ses", "l\u00e4s\u00b7set", "jetzt", "auch", "dem"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ADV", "ART"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was andern schon vorher auf gleiche Art geschehen.", "tokens": ["Was", "an\u00b7dern", "schon", "vor\u00b7her", "auf", "glei\u00b7che", "Art", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Pompejus und zugleich Philippens grosser Sohn,", "tokens": ["Pom\u00b7pe\u00b7jus", "und", "zu\u00b7gleich", "Phil\u00b7ip\u00b7pens", "gros\u00b7ser", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und C\u00e4sar musten auch ihr Scepter, Reich und Kron", "tokens": ["Und", "C\u00e4\u00b7sar", "mus\u00b7ten", "auch", "ihr", "Scep\u00b7ter", ",", "Reich", "und", "Kron"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "VMFIN", "ADV", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Am Tage, der sie gab, und auch zugleich das Leben,", "tokens": ["Am", "Ta\u00b7ge", ",", "der", "sie", "gab", ",", "und", "auch", "zu\u00b7gleich", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der strengen Todes-Faust auf ewig \u00fcbergeben.", "tokens": ["Der", "stren\u00b7gen", "To\u00b7des\u00b7Faust", "auf", "e\u00b7wig", "\u00fc\u00b7ber\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Starb nicht auch Caracal auf seinem Lebens-Tag?", "tokens": ["Starb", "nicht", "auch", "Ca\u00b7ra\u00b7cal", "auf", "sei\u00b7nem", "Le\u00b7bens\u00b7Tag", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ja, da\u00df man noch etwas von andern sagen mag.", "tokens": ["Ja", ",", "da\u00df", "man", "noch", "et\u00b7was", "von", "an\u00b7dern", "sa\u00b7gen", "mag."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PTKANT", "$,", "KOUS", "PIS", "ADV", "ADV", "APPR", "PIS", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "So ist auch Plato selbst an diesem Tag im Frieden,", "tokens": ["So", "ist", "auch", "Pla\u00b7to", "selbst", "an", "die\u00b7sem", "Tag", "im", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NE", "ADV", "APPR", "PDAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie auch Sidonius von dieser Welt geschieden.", "tokens": ["Wie", "auch", "Si\u00b7do\u00b7ni\u00b7us", "von", "die\u00b7ser", "Welt", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NE", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Albinus gab am Tag, der ihn ans Licht gebracht,", "tokens": ["Al\u00b7bi\u00b7nus", "gab", "am", "Tag", ",", "der", "ihn", "ans", "Licht", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Hinwiederum der Welt auf ewig gute Nacht.", "tokens": ["Hin\u00b7wie\u00b7de\u00b7rum", "der", "Welt", "auf", "e\u00b7wig", "gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Es hat Altingius in seinen Lebens-Stunden,", "tokens": ["Es", "hat", "Al\u00b7tin\u00b7gi\u00b7us", "in", "sei\u00b7nen", "Le\u00b7bens\u00b7Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So, wie Labadie den Sterbens-Tag gefunden.", "tokens": ["So", ",", "wie", "La\u00b7ba\u00b7die", "den", "Ster\u00b7bens\u00b7Tag", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.6": {"line.1": {"text": "Hier aber f\u00e4llt mir nun noch diese Frage bey:", "tokens": ["Hier", "a\u00b7ber", "f\u00e4llt", "mir", "nun", "noch", "die\u00b7se", "Fra\u00b7ge", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADV", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Welch unter beyden wohl der beste Tag doch sey?", "tokens": ["Welch", "un\u00b7ter", "bey\u00b7den", "wohl", "der", "bes\u00b7te", "Tag", "doch", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "PIAT", "ADV", "ART", "ADJA", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hierauf kan Salomon die beste Antwort stellen,", "tokens": ["Hier\u00b7auf", "kan", "Sa\u00b7lo\u00b7mon", "die", "bes\u00b7te", "Ant\u00b7wort", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "NE", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und das gerechteste und kl\u00fcgste Urtheil f\u00e4llen.", "tokens": ["Und", "das", "ge\u00b7rech\u00b7tes\u00b7te", "und", "kl\u00fcgs\u00b7te", "Ur\u00b7theil", "f\u00e4l\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er hat bereits gesagt: der Tag des Todes ist,", "tokens": ["Er", "hat", "be\u00b7reits", "ge\u00b7sagt", ":", "der", "Tag", "des", "To\u00b7des", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$.", "ART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weit besser als der Tag, da uns das Leben gr\u00fc\u00dft,", "tokens": ["Weit", "bes\u00b7ser", "als", "der", "Tag", ",", "da", "uns", "das", "Le\u00b7ben", "gr\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KOKOM", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und uns geschenket wird. So bald wir nur gebohren,", "tokens": ["Und", "uns", "ge\u00b7schen\u00b7ket", "wird", ".", "So", "bald", "wir", "nur", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "VAFIN", "$.", "ADV", "ADV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So geht das Elend an. Es hat den Eyd geschworen,", "tokens": ["So", "geht", "das", "E\u00b7lend", "an", ".", "Es", "hat", "den", "Eyd", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df uns von M\u00fch und Quaal nichts als die Sterbens Zeit,", "tokens": ["Da\u00df", "uns", "von", "M\u00fch", "und", "Qua\u00b7al", "nichts", "als", "die", "Ster\u00b7bens", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "KON", "NN", "PIS", "KOKOM", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Und unser Todes Tag erl\u00f6set und befreyt.", "tokens": ["Und", "un\u00b7ser", "To\u00b7des", "Tag", "er\u00b7l\u00f6\u00b7set", "und", "be\u00b7freyt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So kans nicht anders seyn, Gott hat es wohl gef\u00fcget", "tokens": ["So", "kans", "nicht", "an\u00b7ders", "seyn", ",", "Gott", "hat", "es", "wohl", "ge\u00b7f\u00fc\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PTKNEG", "ADV", "VAINF", "$,", "NN", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da dich dein Sterbe-Tag nun ewiglich vergn\u00fcget.", "tokens": ["Da", "dich", "dein", "Ster\u00b7be\u00b7Tag", "nun", "e\u00b7wig\u00b7lich", "ver\u00b7gn\u00fc\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ruh wohl in deiner Gruft und schlafe sanft und sch\u00f6n,", "tokens": ["Ruh", "wohl", "in", "dei\u00b7ner", "Gruft", "und", "schla\u00b7fe", "sanft", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis dich der Lebens-F\u00fcrst heist wieder auferstehn.", "tokens": ["Bis", "dich", "der", "Le\u00b7bens\u00b7F\u00fcrst", "heist", "wie\u00b7der", "auf\u00b7er\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indessen danken wir dir noch vor alle Liebe,", "tokens": ["In\u00b7des\u00b7sen", "dan\u00b7ken", "wir", "dir", "noch", "vor", "al\u00b7le", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vor deine Redlichkeit und Freundschaftsvolle Triebe.", "tokens": ["Vor", "dei\u00b7ne", "Red\u00b7lich\u00b7keit", "und", "Freund\u00b7schafts\u00b7vol\u00b7le", "Trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die hohe Allmachts-Hand, die alles mit Bedacht", "tokens": ["Die", "ho\u00b7he", "All\u00b7machts\u00b7Hand", ",", "die", "al\u00b7les", "mit", "Be\u00b7dacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sehr wei\u00dflich und sehr sch\u00f6n und wundervoll gemacht,", "tokens": ["Sehr", "wei\u00df\u00b7lich", "und", "sehr", "sch\u00f6n", "und", "wun\u00b7der\u00b7voll", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat auch beym Anfang gleich da kaum die Welt geworden,", "tokens": ["Hat", "auch", "beym", "An\u00b7fang", "gleich", "da", "kaum", "die", "Welt", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "ADV", "ADV", "ADV", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Menschen sich gemehrt, verschiedne St\u00e4nd und Orden", "tokens": ["Und", "Men\u00b7schen", "sich", "ge\u00b7mehrt", ",", "ver\u00b7schied\u00b7ne", "St\u00e4nd", "und", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "PRF", "VVPP", "$,", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gemacht und eingesetzt. Dem einen gab sie viel", "tokens": ["Ge\u00b7macht", "und", "ein\u00b7ge\u00b7setzt", ".", "Dem", "ei\u00b7nen", "gab", "sie", "viel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "$.", "ART", "PIS", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von Weisheit und Verstand, so, da\u00df sein Wort das Ziel", "tokens": ["Von", "Weis\u00b7heit", "und", "Ver\u00b7stand", ",", "so", ",", "da\u00df", "sein", "Wort", "das", "Ziel"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ADV", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und auch die Regel war, wornach in allen Dingen", "tokens": ["Und", "auch", "die", "Re\u00b7gel", "war", ",", "wor\u00b7nach", "in", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "$,", "PWAV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die andern sich gericht, und nach demselben giengen.", "tokens": ["Die", "an\u00b7dern", "sich", "ge\u00b7richt", ",", "und", "nach", "dem\u00b7sel\u00b7ben", "gien\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PRF", "VVPP", "$,", "KON", "APPR", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dem andern legte sie viel Geld und G\u00fcter bey,", "tokens": ["Dem", "an\u00b7dern", "leg\u00b7te", "sie", "viel", "Geld", "und", "G\u00fc\u00b7ter", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PIAT", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Damit er m\u00e4chtiger als wie sein Mitknecht sey.", "tokens": ["Da\u00b7mit", "er", "m\u00e4ch\u00b7ti\u00b7ger", "als", "wie", "sein", "Mit\u00b7knecht", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "KOUS", "KOKOM", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den dritten cr\u00f6nte sie mit Herrlichkeit und Ehre,", "tokens": ["Den", "drit\u00b7ten", "cr\u00f6n\u00b7te", "sie", "mit", "Herr\u00b7lich\u00b7keit", "und", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Damit ein Unterschied in denen St\u00e4nden w\u00e4re.", "tokens": ["Da\u00b7mit", "ein", "Un\u00b7ter\u00b7schied", "in", "de\u00b7nen", "St\u00e4n\u00b7den", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "APPR", "PRELS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und diese Ordnung steht auch jetzo noch so fest,", "tokens": ["Und", "die\u00b7se", "Ord\u00b7nung", "steht", "auch", "jet\u00b7zo", "noch", "so", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ADV", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und so gewi\u00df, als sich in Ost, S\u00fcd, Nord und West", "tokens": ["Und", "so", "ge\u00b7wi\u00df", ",", "als", "sich", "in", "Ost", ",", "S\u00fcd", ",", "Nord", "und", "West"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "$,", "KOUS", "PRF", "APPR", "NE", "$,", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ein Element bewegt, und sein Gesch\u00e4fte treibet.", "tokens": ["Ein", "E\u00b7le\u00b7ment", "be\u00b7wegt", ",", "und", "sein", "Ge\u00b7sch\u00e4f\u00b7te", "trei\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ja, da\u00df die Republic in Flor und Ordnung bleibet,", "tokens": ["Ja", ",", "da\u00df", "die", "Re\u00b7pub\u00b7lic", "in", "Flor", "und", "Ord\u00b7nung", "blei\u00b7bet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So mu\u00df ein Unterschied in denen St\u00e4nden seyn.", "tokens": ["So", "mu\u00df", "ein", "Un\u00b7ter\u00b7schied", "in", "de\u00b7nen", "St\u00e4n\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "APPR", "PRELS", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Doch sind die St\u00e4nde nicht in allem \u00fcberein:", "tokens": ["Doch", "sind", "die", "St\u00e4n\u00b7de", "nicht", "in", "al\u00b7lem", "\u00fc\u00b7be\u00b7re\u00b7in", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKNEG", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Der ziert den Richter-Stab und tr\u00e4gt ihn ohne Tadel.", "tokens": ["Der", "ziert", "den", "Rich\u00b7ter\u00b7Stab", "und", "tr\u00e4gt", "ihn", "oh\u00b7ne", "Ta\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den andern aber schm\u00fcckt Helm, Degen, Wappen, Adel.", "tokens": ["Den", "an\u00b7dern", "a\u00b7ber", "schm\u00fcckt", "Helm", ",", "De\u00b7gen", ",", "Wap\u00b7pen", ",", "A\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn ob man wohl nicht leicht auf die Gedanken f\u00e4llt,", "tokens": ["Denn", "ob", "man", "wohl", "nicht", "leicht", "auf", "die", "Ge\u00b7dan\u00b7ken", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "PTKNEG", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und zu behaupten sucht, da\u00df in der ersten Welt", "tokens": ["Und", "zu", "be\u00b7haup\u00b7ten", "sucht", ",", "da\u00df", "in", "der", "ers\u00b7ten", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKZU", "VVINF", "VVFIN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Adel, wie wir ihn zu unsern Zeiten sehen,", "tokens": ["Der", "A\u00b7del", ",", "wie", "wir", "ihn", "zu", "un\u00b7sern", "Zei\u00b7ten", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auch eingesetzet w\u00e4r; indem die\u00df erst geschehen,", "tokens": ["Auch", "ein\u00b7ge\u00b7set\u00b7zet", "w\u00e4r", ";", "in\u00b7dem", "die\u00df", "erst", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$.", "KOUS", "PDS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als man die Tugenden aus jener dunklen Nacht", "tokens": ["Als", "man", "die", "Tu\u00b7gen\u00b7den", "aus", "je\u00b7ner", "dunk\u00b7len", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "NN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit Flei\u00df hervor gesucht, und an das Licht gebracht;", "tokens": ["Mit", "Flei\u00df", "her\u00b7vor", "ge\u00b7sucht", ",", "und", "an", "das", "Licht", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "VVPP", "$,", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So ist uns doch bewust, das in den ersten Zeiten,", "tokens": ["So", "ist", "uns", "doch", "be\u00b7wust", ",", "das", "in", "den", "ers\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$,", "PRELS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Eins vor dem anderen besondre Herrlichkeiten", "tokens": ["Eins", "vor", "dem", "an\u00b7de\u00b7ren", "be\u00b7sond\u00b7re", "Herr\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und W\u00fcrde \u00fcberkam: Die warlich merklich leicht,", "tokens": ["Und", "W\u00fcr\u00b7de", "\u00fc\u00b7ber\u00b7kam", ":", "Die", "war\u00b7lich", "merk\u00b7lich", "leicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$.", "ART", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und auch dem Adel-Stand an Schmuck und Ehre gleicht,", "tokens": ["Und", "auch", "dem", "A\u00b7del\u00b7Stand", "an", "Schmuck", "und", "Eh\u00b7re", "gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Es mu\u00df der Adel-Stand wohl freylich auf der Erden,", "tokens": ["Es", "mu\u00df", "der", "A\u00b7del\u00b7Stand", "wohl", "frey\u00b7lich", "auf", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nicht etwa obenhin, so schlecht betrachtet werden;", "tokens": ["Nicht", "et\u00b7wa", "o\u00b7ben\u00b7hin", ",", "so", "schlecht", "be\u00b7trach\u00b7tet", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "$,", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Sein Purpur, Feder, Helm, Schild, Wappen, Fahn und Stahl,", "tokens": ["Sein", "Pur\u00b7pur", ",", "Fe\u00b7der", ",", "Helm", ",", "Schild", ",", "Wap\u00b7pen", ",", "Fahn", "und", "Stahl", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und was man sonst noch nennt, bezeugen allzumahl,", "tokens": ["Und", "was", "man", "sonst", "noch", "nennt", ",", "be\u00b7zeu\u00b7gen", "all\u00b7zu\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "ADV", "VVFIN", "$,", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie hoch sein Glanz und Ruhm und Ansehn ist gestiegen,", "tokens": ["Wie", "hoch", "sein", "Glanz", "und", "Ruhm", "und", "An\u00b7sehn", "ist", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "KON", "NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und was er vor ein Recht des Vorzugs muste kriegen.", "tokens": ["Und", "was", "er", "vor", "ein", "Recht", "des", "Vor\u00b7zugs", "mus\u00b7te", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der Ahnen sch\u00f6ne Reih bef\u00f6rdert seine Ehr,", "tokens": ["Der", "Ah\u00b7nen", "sch\u00f6\u00b7ne", "Reih", "be\u00b7f\u00f6r\u00b7dert", "sei\u00b7ne", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Vergr\u00f6ssert seine Pracht und Sch\u00f6nheit desto mehr.", "tokens": ["Ver\u00b7gr\u00f6s\u00b7sert", "sei\u00b7ne", "Pracht", "und", "Sch\u00f6n\u00b7heit", "des\u00b7to", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Allein, was ist doch wohl der hocherh\u00f6hte Adel", "tokens": ["Al\u00b7lein", ",", "was", "ist", "doch", "wohl", "der", "ho\u00b7cher\u00b7h\u00f6h\u00b7te", "A\u00b7del"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn er nicht Tugend hat? Ein Compa\u00df ohne Nadel,", "tokens": ["Wenn", "er", "nicht", "Tu\u00b7gend", "hat", "?", "Ein", "Com\u00b7pa\u00df", "oh\u00b7ne", "Na\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "VAFIN", "$.", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Licht, das keinen Schein und Nutzen von sich giebt.", "tokens": ["Ein", "Licht", ",", "das", "kei\u00b7nen", "Schein", "und", "Nut\u00b7zen", "von", "sich", "giebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer vom Geschlechte nicht die \u00e4chte Tugend liebt,", "tokens": ["Wer", "vom", "Ge\u00b7schlech\u00b7te", "nicht", "die", "\u00e4ch\u00b7te", "Tu\u00b7gend", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der kan sich nicht mit Recht ber\u00fchmt und edel nennen.", "tokens": ["Der", "kan", "sich", "nicht", "mit", "Recht", "be\u00b7r\u00fchmt", "und", "e\u00b7del", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PRF", "PTKNEG", "APPR", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So viele Tugenden mu\u00df er als eigen kennen,", "tokens": ["So", "vie\u00b7le", "Tu\u00b7gen\u00b7den", "mu\u00df", "er", "als", "ei\u00b7gen", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VMFIN", "PPER", "KOUS", "ADJD", "VVINF", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "So viel er Ahnen w\u00fcnscht und auch wohl zehlen kan:", "tokens": ["So", "viel", "er", "Ah\u00b7nen", "w\u00fcnscht", "und", "auch", "wohl", "zeh\u00b7len", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "NN", "VVFIN", "KON", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dann hei\u00dft er erst mit Recht ein wahrer Edelmann.", "tokens": ["Dann", "hei\u00dft", "er", "erst", "mit", "Recht", "ein", "wah\u00b7rer", "E\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein solcher kunte wohl ", "tokens": ["Ein", "sol\u00b7cher", "kun\u00b7te", "wohl"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIAT", "VMFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Er suchte nicht zum Pracht die Ahnen aufzuweisen,", "tokens": ["Er", "such\u00b7te", "nicht", "zum", "Pracht", "die", "Ah\u00b7nen", "auf\u00b7zu\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Noch da\u00df Er Prahlerisch dieselben her erzehlt!", "tokens": ["Noch", "da\u00df", "Er", "Prah\u00b7le\u00b7risch", "die\u00b7sel\u00b7ben", "her", "er\u00b7zehlt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "NN", "PDAT", "APZR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Tugend hatte Er mit selbigen verm\u00e4hlt.", "tokens": ["Die", "Tu\u00b7gend", "hat\u00b7te", "Er", "mit", "sel\u00b7bi\u00b7gen", "ver\u00b7m\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die kunten nie den Grund zu eingen Hochmuth legen.", "tokens": ["Die", "kun\u00b7ten", "nie", "den", "Grund", "zu", "ein\u00b7gen", "Hoch\u00b7muth", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er war dem Ehrgeiz feind, er war der Wollust gram,", "tokens": ["Er", "war", "dem", "Ehr\u00b7geiz", "feind", ",", "er", "war", "der", "Wol\u00b7lust", "gram", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die auch kein freches Thun und Wesen an sich nahm.", "tokens": ["Die", "auch", "kein", "fre\u00b7ches", "Thun", "und", "We\u00b7sen", "an", "sich", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "ADJA", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Er liebte seinen Gott, die Demuth war sein Wissen,", "tokens": ["Er", "lieb\u00b7te", "sei\u00b7nen", "Gott", ",", "die", "De\u00b7muth", "war", "sein", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Indem er sich nur stets der Eitelkeit entrissen.", "tokens": ["In\u00b7dem", "er", "sich", "nur", "stets", "der", "Ei\u00b7tel\u00b7keit", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Er wu\u00dfte nichts von Schein, Betrug und Heucheley,", "tokens": ["Er", "wu\u00df\u00b7te", "nichts", "von", "Schein", ",", "Be\u00b7trug", "und", "Heu\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er war ein Redlicher nach alter Deutschen Treu.", "tokens": ["Er", "war", "ein", "Red\u00b7li\u00b7cher", "nach", "al\u00b7ter", "Deut\u00b7schen", "Treu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "O! da\u00df die ewge Macht beym Anfang aller Sachen", "tokens": ["O", "!", "da\u00df", "die", "ew\u00b7ge", "Macht", "beym", "An\u00b7fang", "al\u00b7ler", "Sa\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So einen festen Bund zugleich beliebt zu machen,", "tokens": ["So", "ei\u00b7nen", "fes\u00b7ten", "Bund", "zu\u00b7gleich", "be\u00b7liebt", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der alles Fleisch betrift, und der uns sterblich macht:", "tokens": ["Der", "al\u00b7les", "Fleisch", "be\u00b7trift", ",", "und", "der", "uns", "sterb\u00b7lich", "macht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "KON", "ART", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Hier wird kein Reichthum nicht noch Adel-Stand betracht.", "tokens": ["Hier", "wird", "kein", "Reicht\u00b7hum", "nicht", "noch", "A\u00b7del\u00b7Stand", "be\u00b7tracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PTKNEG", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der Tod nimmt nicht nur die zu sich in seine Kammer,", "tokens": ["Der", "Tod", "nimmt", "nicht", "nur", "die", "zu", "sich", "in", "sei\u00b7ne", "Kam\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ADV", "ART", "APPR", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die arm und elend seyn, die nichts als Angst und Jammer", "tokens": ["Die", "arm", "und", "e\u00b7lend", "seyn", ",", "die", "nichts", "als", "Angst", "und", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAINF", "$,", "PRELS", "PIS", "KOKOM", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "An jedem Morgen sehn; er reist auch die mit fort,", "tokens": ["An", "je\u00b7dem", "Mor\u00b7gen", "sehn", ";", "er", "reist", "auch", "die", "mit", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$.", "PPER", "VVFIN", "ADV", "ART", "APPR", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die reich und vornehm sind. Des Todes ernstes Wort", "tokens": ["Die", "reich", "und", "vor\u00b7nehm", "sind", ".", "Des", "To\u00b7des", "erns\u00b7tes", "Wort"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ergehet auch an den, der nach der Tugend wandelt,", "tokens": ["Er\u00b7ge\u00b7het", "auch", "an", "den", ",", "der", "nach", "der", "Tu\u00b7gend", "wan\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.29": {"text": "Und bey erh\u00f6hten Stand und Reichthum redlich handelt.", "tokens": ["Und", "bey", "er\u00b7h\u00f6h\u00b7ten", "Stand", "und", "Reicht\u00b7hum", "red\u00b7lich", "han\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "KON", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "O Tod! wie hast du dich so k\u00fchn und unverzagt,", "tokens": ["O", "Tod", "!", "wie", "hast", "du", "dich", "so", "k\u00fchn", "und", "un\u00b7ver\u00b7zagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWAV", "VAFIN", "PPER", "PRF", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Auch an das Lebens-Schif des ", "tokens": ["Auch", "an", "das", "Le\u00b7bens\u00b7Schif", "des"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "Mu\u00df seines Leibes-Bau zerbrechen und zerschellen?", "tokens": ["Mu\u00df", "sei\u00b7nes", "Lei\u00b7bes\u00b7Bau", "zer\u00b7bre\u00b7chen", "und", "zer\u00b7schel\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wie? hast du noch ", "tokens": ["Wie", "?", "hast", "du", "noch"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.34": {"text": "Du rei\u00dft das Adliche ber\u00fchmte Wappen ab,", "tokens": ["Du", "rei\u00dft", "das", "Ad\u00b7li\u00b7che", "be\u00b7r\u00fchm\u00b7te", "Wap\u00b7pen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und wirfst es neben ihm zerbrochen in das Grab", "tokens": ["Und", "wirfst", "es", "ne\u00b7ben", "ihm", "zer\u00b7bro\u00b7chen", "in", "das", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPER", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "So ists in dieser Welt, Einmahl ist uns das Leben,", "tokens": ["So", "ists", "in", "die\u00b7ser", "Welt", ",", "Ein\u00b7mahl", "ist", "uns", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PDAT", "NN", "$,", "ADV", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom Herrn der Creatur auf eine Zeit gegeben,", "tokens": ["Vom", "Herrn", "der", "Crea\u00b7tur", "auf", "ei\u00b7ne", "Zeit", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ist nun dieselbe um, so thut des Todes Hand,", "tokens": ["Ist", "nun", "die\u00b7sel\u00b7be", "um", ",", "so", "thut", "des", "To\u00b7des", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein Reichthum, kein Geschlecht den kleinsten Widerstand.", "tokens": ["Kein", "Reicht\u00b7hum", ",", "kein", "Ge\u00b7schlecht", "den", "kleins\u00b7ten", "Wi\u00b7der\u00b7stand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der H\u00f6chste h\u00e4lt es so, er hei\u00dft die Menschen sterben.", "tokens": ["Der", "H\u00f6chs\u00b7te", "h\u00e4lt", "es", "so", ",", "er", "hei\u00dft", "die", "Men\u00b7schen", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier baut er ein Geschlecht, dort l\u00e4\u00dft er eins verderben.", "tokens": ["Hier", "baut", "er", "ein", "Ge\u00b7schlecht", ",", "dort", "l\u00e4\u00dft", "er", "eins", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Schau-Platz ist die Welt. Man legt die Kleider an,", "tokens": ["Ein", "Schau\u00b7Platz", "ist", "die", "Welt", ".", "Man", "legt", "die", "Klei\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$.", "PIS", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Jetzt tritt ein J\u00fcngling auf, und diesem folgt ein Mann,", "tokens": ["Jetzt", "tritt", "ein", "J\u00fcng\u00b7ling", "auf", ",", "und", "die\u00b7sem", "folgt", "ein", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "PDS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und spielt die Rolle weg, und gehet dann zur\u00fccke.", "tokens": ["Und", "spielt", "die", "Rol\u00b7le", "weg", ",", "und", "ge\u00b7het", "dann", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wer nun mit Vorbedacht, mit Sch\u00f6nheit, Witz und Gl\u00fccke", "tokens": ["Wer", "nun", "mit", "Vor\u00b7be\u00b7dacht", ",", "mit", "Sch\u00f6n\u00b7heit", ",", "Witz", "und", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Rolle durchgespielt. Ich meine, wer mit Flei\u00df", "tokens": ["Die", "Rol\u00b7le", "durch\u00b7ge\u00b7spielt", ".", "Ich", "mei\u00b7ne", ",", "wer", "mit", "Flei\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PPER", "VVFIN", "$,", "PWS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nach denen Tugenden und g\u00f6ttlichem Gehei\u00df", "tokens": ["Nach", "de\u00b7nen", "Tu\u00b7gen\u00b7den", "und", "g\u00f6tt\u00b7li\u00b7chem", "Ge\u00b7hei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "NN", "KON", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Sein Leben angestellt, und sich so aufgef\u00fchret,", "tokens": ["Sein", "Le\u00b7ben", "an\u00b7ge\u00b7stellt", ",", "und", "sich", "so", "auf\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "KON", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df jedermann von ihm was l\u00f6bliches gesp\u00fchret,", "tokens": ["Da\u00df", "je\u00b7der\u00b7mann", "von", "ihm", "was", "l\u00f6b\u00b7li\u00b7ches", "ge\u00b7sp\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "PIS", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und gehet dann davon und l\u00e4\u00dft den Schau-Platz stehn,", "tokens": ["Und", "ge\u00b7het", "dann", "da\u00b7von", "und", "l\u00e4\u00dft", "den", "Schau\u00b7Platz", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "KON", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Dem suchet Ehr und Ruhm auf ewig nachzugehn.", "tokens": ["Dem", "su\u00b7chet", "Ehr", "und", "Ruhm", "auf", "e\u00b7wig", "nach\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "KON", "NN", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Nun hat ", "tokens": ["Nun", "hat"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.18": {"text": "Den Schau-Platz dieser Welt mit vielem Ruhm verlassen:", "tokens": ["Den", "Schau\u00b7Platz", "die\u00b7ser", "Welt", "mit", "vie\u00b7lem", "Ruhm", "ver\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "APPR", "PIS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Drum wird man Prei\u00df und Lob auf seine Bahre streun,", "tokens": ["Drum", "wird", "man", "Prei\u00df", "und", "Lob", "auf", "sei\u00b7ne", "Bah\u00b7re", "streun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PIS", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Sein holdes Angedenk mu\u00df unverge\u00dflich seyn.", "tokens": ["Sein", "hol\u00b7des", "An\u00b7ge\u00b7denk", "mu\u00df", "un\u00b7ver\u00b7ge\u00df\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sein Hingang aus der Zeit nach jenen finstern Bogen,", "tokens": ["Sein", "Hin\u00b7gang", "aus", "der", "Zeit", "nach", "je\u00b7nen", "fins\u00b7tern", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Hat manche Traurigkeit und Seufzer nachgezogen.", "tokens": ["Hat", "man\u00b7che", "Trau\u00b7rig\u00b7keit", "und", "Seuf\u00b7zer", "nach\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So, wie sein Todes-Fall so manche Brust erschreckt,", "tokens": ["So", ",", "wie", "sein", "To\u00b7des\u00b7Fall", "so", "man\u00b7che", "Brust", "er\u00b7schreckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So viel Verwunderung hat er zugleich erweckt.", "tokens": ["So", "viel", "Ver\u00b7wun\u00b7de\u00b7rung", "hat", "er", "zu\u00b7gleich", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "Denn der, so ihm das Ziel des Lebens auserkohren,", "tokens": ["Denn", "der", ",", "so", "ihm", "das", "Ziel", "des", "Le\u00b7bens", "au\u00b7ser\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "ADV", "PPER", "ART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der, so die Stunde rief, darinn er ward gebohren.", "tokens": ["Der", ",", "so", "die", "Stun\u00b7de", "rief", ",", "da\u00b7rinn", "er", "ward", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ART", "NN", "VVFIN", "$,", "PAV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Der hat es gleichfals auch beschlossen und bestellt,", "tokens": ["Der", "hat", "es", "gleich\u00b7fals", "auch", "be\u00b7schlos\u00b7sen", "und", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da\u00df er zu gleicher Zeit und Stunde auch die Welt", "tokens": ["Da\u00df", "er", "zu", "glei\u00b7cher", "Zeit", "und", "Stun\u00b7de", "auch", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "KON", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hinwieder lassen soll. Die Nacht, in der er kommen", "tokens": ["Hin\u00b7wie\u00b7der", "las\u00b7sen", "soll", ".", "Die", "Nacht", ",", "in", "der", "er", "kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVINF", "VMFIN", "$.", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Hat ihn auch ebenfals das Leben weggenommen.", "tokens": ["Hat", "ihn", "auch", "e\u00b7ben\u00b7fals", "das", "Le\u00b7ben", "weg\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wie wunderbar ist doch der Rath der Ewigkeit!", "tokens": ["Wie", "wun\u00b7der\u00b7bar", "ist", "doch", "der", "Rath", "der", "E\u00b7wig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zeigt das Verh\u00e4ngni\u00df nicht die gr\u00f6\u00dfte Seltenheit?", "tokens": ["Zeigt", "das", "Ver\u00b7h\u00e4ng\u00b7ni\u00df", "nicht", "die", "gr\u00f6\u00df\u00b7te", "Sel\u00b7ten\u00b7heit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn dieses l\u00e4sset jetzt auch dem ", "tokens": ["Denn", "die\u00b7ses", "l\u00e4s\u00b7set", "jetzt", "auch", "dem"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ADV", "ART"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was andern schon vorher auf gleiche Art geschehen.", "tokens": ["Was", "an\u00b7dern", "schon", "vor\u00b7her", "auf", "glei\u00b7che", "Art", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Pompejus und zugleich Philippens grosser Sohn,", "tokens": ["Pom\u00b7pe\u00b7jus", "und", "zu\u00b7gleich", "Phil\u00b7ip\u00b7pens", "gros\u00b7ser", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und C\u00e4sar musten auch ihr Scepter, Reich und Kron", "tokens": ["Und", "C\u00e4\u00b7sar", "mus\u00b7ten", "auch", "ihr", "Scep\u00b7ter", ",", "Reich", "und", "Kron"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "VMFIN", "ADV", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Am Tage, der sie gab, und auch zugleich das Leben,", "tokens": ["Am", "Ta\u00b7ge", ",", "der", "sie", "gab", ",", "und", "auch", "zu\u00b7gleich", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der strengen Todes-Faust auf ewig \u00fcbergeben.", "tokens": ["Der", "stren\u00b7gen", "To\u00b7des\u00b7Faust", "auf", "e\u00b7wig", "\u00fc\u00b7ber\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Starb nicht auch Caracal auf seinem Lebens-Tag?", "tokens": ["Starb", "nicht", "auch", "Ca\u00b7ra\u00b7cal", "auf", "sei\u00b7nem", "Le\u00b7bens\u00b7Tag", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ja, da\u00df man noch etwas von andern sagen mag.", "tokens": ["Ja", ",", "da\u00df", "man", "noch", "et\u00b7was", "von", "an\u00b7dern", "sa\u00b7gen", "mag."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PTKANT", "$,", "KOUS", "PIS", "ADV", "ADV", "APPR", "PIS", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "So ist auch Plato selbst an diesem Tag im Frieden,", "tokens": ["So", "ist", "auch", "Pla\u00b7to", "selbst", "an", "die\u00b7sem", "Tag", "im", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NE", "ADV", "APPR", "PDAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie auch Sidonius von dieser Welt geschieden.", "tokens": ["Wie", "auch", "Si\u00b7do\u00b7ni\u00b7us", "von", "die\u00b7ser", "Welt", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NE", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Albinus gab am Tag, der ihn ans Licht gebracht,", "tokens": ["Al\u00b7bi\u00b7nus", "gab", "am", "Tag", ",", "der", "ihn", "ans", "Licht", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Hinwiederum der Welt auf ewig gute Nacht.", "tokens": ["Hin\u00b7wie\u00b7de\u00b7rum", "der", "Welt", "auf", "e\u00b7wig", "gu\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Es hat Altingius in seinen Lebens-Stunden,", "tokens": ["Es", "hat", "Al\u00b7tin\u00b7gi\u00b7us", "in", "sei\u00b7nen", "Le\u00b7bens\u00b7Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So, wie Labadie den Sterbens-Tag gefunden.", "tokens": ["So", ",", "wie", "La\u00b7ba\u00b7die", "den", "Ster\u00b7bens\u00b7Tag", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.13": {"line.1": {"text": "Hier aber f\u00e4llt mir nun noch diese Frage bey:", "tokens": ["Hier", "a\u00b7ber", "f\u00e4llt", "mir", "nun", "noch", "die\u00b7se", "Fra\u00b7ge", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADV", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Welch unter beyden wohl der beste Tag doch sey?", "tokens": ["Welch", "un\u00b7ter", "bey\u00b7den", "wohl", "der", "bes\u00b7te", "Tag", "doch", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "PIAT", "ADV", "ART", "ADJA", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hierauf kan Salomon die beste Antwort stellen,", "tokens": ["Hier\u00b7auf", "kan", "Sa\u00b7lo\u00b7mon", "die", "bes\u00b7te", "Ant\u00b7wort", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "NE", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und das gerechteste und kl\u00fcgste Urtheil f\u00e4llen.", "tokens": ["Und", "das", "ge\u00b7rech\u00b7tes\u00b7te", "und", "kl\u00fcgs\u00b7te", "Ur\u00b7theil", "f\u00e4l\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er hat bereits gesagt: der Tag des Todes ist,", "tokens": ["Er", "hat", "be\u00b7reits", "ge\u00b7sagt", ":", "der", "Tag", "des", "To\u00b7des", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$.", "ART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weit besser als der Tag, da uns das Leben gr\u00fc\u00dft,", "tokens": ["Weit", "bes\u00b7ser", "als", "der", "Tag", ",", "da", "uns", "das", "Le\u00b7ben", "gr\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KOKOM", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und uns geschenket wird. So bald wir nur gebohren,", "tokens": ["Und", "uns", "ge\u00b7schen\u00b7ket", "wird", ".", "So", "bald", "wir", "nur", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "VAFIN", "$.", "ADV", "ADV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So geht das Elend an. Es hat den Eyd geschworen,", "tokens": ["So", "geht", "das", "E\u00b7lend", "an", ".", "Es", "hat", "den", "Eyd", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df uns von M\u00fch und Quaal nichts als die Sterbens Zeit,", "tokens": ["Da\u00df", "uns", "von", "M\u00fch", "und", "Qua\u00b7al", "nichts", "als", "die", "Ster\u00b7bens", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "KON", "NN", "PIS", "KOKOM", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Und unser Todes Tag erl\u00f6set und befreyt.", "tokens": ["Und", "un\u00b7ser", "To\u00b7des", "Tag", "er\u00b7l\u00f6\u00b7set", "und", "be\u00b7freyt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So kans nicht anders seyn, Gott hat es wohl gef\u00fcget", "tokens": ["So", "kans", "nicht", "an\u00b7ders", "seyn", ",", "Gott", "hat", "es", "wohl", "ge\u00b7f\u00fc\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PTKNEG", "ADV", "VAINF", "$,", "NN", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da dich dein Sterbe-Tag nun ewiglich vergn\u00fcget.", "tokens": ["Da", "dich", "dein", "Ster\u00b7be\u00b7Tag", "nun", "e\u00b7wig\u00b7lich", "ver\u00b7gn\u00fc\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ruh wohl in deiner Gruft und schlafe sanft und sch\u00f6n,", "tokens": ["Ruh", "wohl", "in", "dei\u00b7ner", "Gruft", "und", "schla\u00b7fe", "sanft", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis dich der Lebens-F\u00fcrst heist wieder auferstehn.", "tokens": ["Bis", "dich", "der", "Le\u00b7bens\u00b7F\u00fcrst", "heist", "wie\u00b7der", "auf\u00b7er\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indessen danken wir dir noch vor alle Liebe,", "tokens": ["In\u00b7des\u00b7sen", "dan\u00b7ken", "wir", "dir", "noch", "vor", "al\u00b7le", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vor deine Redlichkeit und Freundschaftsvolle Triebe.", "tokens": ["Vor", "dei\u00b7ne", "Red\u00b7lich\u00b7keit", "und", "Freund\u00b7schafts\u00b7vol\u00b7le", "Trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}