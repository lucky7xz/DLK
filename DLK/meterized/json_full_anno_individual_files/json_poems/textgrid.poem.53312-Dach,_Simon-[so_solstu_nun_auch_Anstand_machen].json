{"textgrid.poem.53312": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "[so solstu nun auch Anstand machen]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So solstu nun auch Anstand machen", "tokens": ["So", "sols\u00b7tu", "nun", "auch", "An\u00b7stand", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit deinen Reimen, hub ich an,", "tokens": ["Mit", "dei\u00b7nen", "Rei\u00b7men", ",", "hub", "ich", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd vor dich nehmen andre Sachen,", "tokens": ["Vnd", "vor", "dich", "neh\u00b7men", "and\u00b7re", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRF", "VVINF", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df Lieder schreiben wer da kan.", "tokens": ["La\u00df", "Lie\u00b7der", "schrei\u00b7ben", "wer", "da", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "VVFIN", "PWS", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gewaltig Lob wird dir es bringen,", "tokens": ["Ge\u00b7wal\u00b7tig", "Lob", "wird", "dir", "es", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sich dein Flei\u00df so dienstbar h\u00e4lt,", "tokens": ["Da\u00df", "sich", "dein", "Flei\u00df", "so", "dienst\u00b7bar", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd alle Leichen mu\u00df besingen,", "tokens": ["Vnd", "al\u00b7le", "Lei\u00b7chen", "mu\u00df", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als w\u00e4hrstu hierzu nur bestellt.", "tokens": ["Als", "w\u00e4hrs\u00b7tu", "hier\u00b7zu", "nur", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PAV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Leg hin die Feder, vnd la\u00df bleiben", "tokens": ["Leg", "hin", "die", "Fe\u00b7der", ",", "vnd", "la\u00df", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "$,", "KON", "VVIMP", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was dir nicht grosses Vortheil giebt,", "tokens": ["Was", "dir", "nicht", "gros\u00b7ses", "Vor\u00b7theil", "giebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd wiltu denn ja etwas schreiben,", "tokens": ["Vnd", "wil\u00b7tu", "denn", "ja", "et\u00b7was", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erheb den Helden der dich liebt.", "tokens": ["Er\u00b7heb", "den", "Hel\u00b7den", "der", "dich", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Vnd hievon w\u00e4hr ich nicht gewichen,", "tokens": ["Vnd", "hie\u00b7von", "w\u00e4hr", "ich", "nicht", "ge\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als hierauff mir zu Ohren f\u00e4hrt,", "tokens": ["Als", "hier\u00b7auff", "mir", "zu", "Oh\u00b7ren", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Herr Schmitner ist anjetzt verblichen,", "tokens": ["Herr", "Schmit\u00b7ner", "ist", "an\u00b7jetzt", "ver\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist Er nicht eines Liedes wehrt?", "tokens": ["Ist", "Er", "nicht", "ei\u00b7nes", "Lie\u00b7des", "wehrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sol Er von dir kein Denckmal haben,", "tokens": ["Sol", "Er", "von", "dir", "kein", "Denck\u00b7mal", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sol gleich der Aschen vnd Gebein", "tokens": ["Sol", "gleich", "der", "A\u00b7schen", "vnd", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch sein Verdienst vnd wehrte Gaben", "tokens": ["Auch", "sein", "Ver\u00b7dienst", "vnd", "wehr\u00b7te", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In ein Grab mit verschorren seyn?", "tokens": ["In", "ein", "Grab", "mit", "ver\u00b7schor\u00b7ren", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "VVPP", "VAINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Worzu wird anders euch Poeten", "tokens": ["Wor\u00b7zu", "wird", "an\u00b7ders", "euch", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "PPER", "NN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Der Geist vom Himmel selbs ger\u00fchrt,", "tokens": ["Der", "Geist", "vom", "Him\u00b7mel", "selbs", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als da\u00df jhr aus den SterbensN\u00f6then", "tokens": ["Als", "da\u00df", "jhr", "aus", "den", "Ster\u00b7bens", "N\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Das Lob der wahren Tugend f\u00fchrt?", "tokens": ["Das", "Lob", "der", "wah\u00b7ren", "Tu\u00b7gend", "f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ihr sollt Fluch, Todt vnd Helle drewen", "tokens": ["Ihr", "sollt", "Fluch", ",", "Todt", "vnd", "Hel\u00b7le", "dre\u00b7wen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "NN", "KON", "NN", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Lastern der verkehrten Zeit,", "tokens": ["Den", "Las\u00b7tern", "der", "ver\u00b7kehr\u00b7ten", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Vnschuld aber auch erfrewen", "tokens": ["Die", "Vn\u00b7schuld", "a\u00b7ber", "auch", "er\u00b7fre\u00b7wen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Lobe, Danck vnd Seeligheit.", "tokens": ["Mit", "Lo\u00b7be", ",", "Danck", "vnd", "See\u00b7lig\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was solt' ich thun? durch meine Lieder", "tokens": ["Was", "solt'", "ich", "thun", "?", "durch", "mei\u00b7ne", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Empfind ich auch sonst Lieb vnd Trew,", "tokens": ["Emp\u00b7find", "ich", "auch", "sonst", "Lieb", "vnd", "Trew", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich stimme meine Seiten wieder", "tokens": ["Ich", "stim\u00b7me", "mei\u00b7ne", "Sei\u00b7ten", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In eine Trawer-Melodey.", "tokens": ["In", "ei\u00b7ne", "Tra\u00b7wer\u00b7Me\u00b7lo\u00b7dey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ist, sing ich, Schmitner auch gestorben,", "tokens": ["Ist", ",", "sing", "ich", ",", "Schmit\u00b7ner", "auch", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "$,", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Redligheit vnd Vnschuld Pfandt,", "tokens": ["Der", "Red\u00b7lig\u00b7heit", "vnd", "Vn\u00b7schuld", "Pfandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der hie so sch\u00f6nes Lob erworben", "tokens": ["Der", "hie", "so", "sch\u00f6\u00b7nes", "Lob", "er\u00b7wor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch seine Trew vnd milde Handt?", "tokens": ["Durch", "sei\u00b7ne", "Trew", "vnd", "mil\u00b7de", "Handt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Hat Den der Todt, wie andre Leichen,", "tokens": ["Hat", "Den", "der", "Todt", ",", "wie", "and\u00b7re", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ART", "NN", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gantz vntter seine Pflicht gebracht,", "tokens": ["Gantz", "vnt\u00b7ter", "sei\u00b7ne", "Pflicht", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der so viel Walds vnd wilder Eichen", "tokens": ["Der", "so", "viel", "Walds", "vnd", "wil\u00b7der", "Ei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PIAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm vntterth\u00e4nig hat gemacht?", "tokens": ["Ihm", "vnt\u00b7ter\u00b7th\u00e4\u00b7nig", "hat", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Schaw auff den Strom der krummen Deimen,", "tokens": ["Schaw", "auff", "den", "Strom", "der", "krum\u00b7men", "Dei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Er rinnt nicht mehr so gr\u00fcn verdeckt", "tokens": ["Er", "rinnt", "nicht", "mehr", "so", "gr\u00fcn", "ver\u00b7deckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Wolcken-an gewachsnen B\u00e4umen,", "tokens": ["Mit", "Wol\u00b7cken\u00b7an", "ge\u00b7wachs\u00b7nen", "B\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Labiaw vmbher fast bleckt.", "tokens": ["Da\u00df", "La\u00b7biaw", "vm\u00b7bher", "fast", "bleckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Er bl\u00f6sste nicht allein Lauckisken,", "tokens": ["Er", "bl\u00f6ss\u00b7te", "nicht", "al\u00b7lein", "Lauc\u00b7kis\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So weit es jhm nur gut ged\u00fcnckt,", "tokens": ["So", "weit", "es", "jhm", "nur", "gut", "ge\u00b7d\u00fcnckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er z\u00e4hmte weiter noch Crupisken,", "tokens": ["Er", "z\u00e4hm\u00b7te", "wei\u00b7ter", "noch", "Cru\u00b7pis\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das aus der klaren Inster trinckt.", "tokens": ["Das", "aus", "der", "kla\u00b7ren", "Ins\u00b7ter", "trinckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Es trug kein Holtz so dicke Schwarten,", "tokens": ["Es", "trug", "kein", "Holtz", "so", "di\u00b7cke", "Schwar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Flei\u00df hat es grundaus versehrt,", "tokens": ["Sein", "Flei\u00df", "hat", "es", "grun\u00b7daus", "ver\u00b7sehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "So da\u00df man seine Beil vnd Barten", "tokens": ["So", "da\u00df", "man", "sei\u00b7ne", "Beil", "vnd", "Bar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PIS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fern vmb die Tilsit hat geh\u00f6rt.", "tokens": ["Fern", "vmb", "die", "Til\u00b7sit", "hat", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Der Beer vnd P\u00fcffel sind erschrocken,", "tokens": ["Der", "Beer", "vnd", "P\u00fcf\u00b7fel", "sind", "er\u00b7schro\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sicher sie vorhin gelebt,", "tokens": ["Wie", "si\u00b7cher", "sie", "vor\u00b7hin", "ge\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist der gro\u00df vnd kleine Rocken", "tokens": ["Es", "ist", "der", "gro\u00df", "vnd", "klei\u00b7ne", "Ro\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr seinem Arbeits-Volck erbebt.", "tokens": ["F\u00fcr", "sei\u00b7nem", "Ar\u00b7beits\u00b7Volck", "er\u00b7bebt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Was Holtz er da herumb geschlagen", "tokens": ["Was", "Holtz", "er", "da", "he\u00b7rumb", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "PPER", "ADV", "APZR", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weis nicht allein der Memel-Flu\u00df", "tokens": ["Weis", "nicht", "al\u00b7lein", "der", "Me\u00b7mel\u00b7Flu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sampt Rangnit, sondern auch zusagen", "tokens": ["Sampt", "Rang\u00b7nit", ",", "son\u00b7dern", "auch", "zu\u00b7sa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "KON", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die dreyzehn-str\u00f6mig-reiche Ru\u00df!", "tokens": ["Die", "drey\u00b7zehn\u00b7str\u00f6\u00b7mig\u00b7rei\u00b7che", "Ru\u00df", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "O manche Ficht' vnd stoltze Linde,", "tokens": ["O", "man\u00b7che", "Ficht'", "vnd", "stolt\u00b7ze", "Lin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "KON", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie hoch sie sonst den Gipffel tr\u00e4gt,", "tokens": ["Wie", "hoch", "sie", "sonst", "den", "Gipf\u00b7fel", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der V\u00f6gel Sitz, vnd Schertz der Winde,", "tokens": ["Der", "V\u00f6\u00b7gel", "Sitz", ",", "vnd", "Schertz", "der", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Ihm zum F\u00fcssen sich gelegt.", "tokens": ["Hat", "Ihm", "zum", "F\u00fcs\u00b7sen", "sich", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Jetzt liegt er selbs hie vmbgehawen,", "tokens": ["Jetzt", "liegt", "er", "selbs", "hie", "vmb\u00b7ge\u00b7ha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nicht Leben, nicht gestalt, noch Muth", "tokens": ["Nicht", "Le\u00b7ben", ",", "nicht", "ge\u00b7stalt", ",", "noch", "Muth"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "NN", "$,", "PTKNEG", "VVPP", "$,", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist in vnd an Ihm mehr zu schawen,", "tokens": ["Ist", "in", "vnd", "an", "Ihm", "mehr", "zu", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "KON", "APPR", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Seht was des Todes Macht nicht thut!", "tokens": ["Seht", "was", "des", "To\u00b7des", "Macht", "nicht", "thut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ART", "NN", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sein Holtz vnd Asch vnd andre Wahren", "tokens": ["Sein", "Holtz", "vnd", "Asch", "vnd", "and\u00b7re", "Wah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Seind jetzt noch manchem Lande wehrt,", "tokens": ["Seind", "jetzt", "noch", "man\u00b7chem", "Lan\u00b7de", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie schnell vnd gantz ist Er verfahren,", "tokens": ["Wie", "schnell", "vnd", "gantz", "ist", "Er", "ver\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd wird von W\u00fcrmern auffgezehrt!", "tokens": ["Vnd", "wird", "von", "W\u00fcr\u00b7mern", "auff\u00b7ge\u00b7zehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Heisst das sich sawer lassen werden", "tokens": ["Heisst", "das", "sich", "sa\u00b7wer", "las\u00b7sen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "PRF", "ADJD", "VVINF", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In Hitz vnd Frost, in M\u00fch vnd Pein,", "tokens": ["In", "Hitz", "vnd", "Frost", ",", "in", "M\u00fch", "vnd", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So bald sich legen in die Erden,", "tokens": ["So", "bald", "sich", "le\u00b7gen", "in", "die", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd eine Kost der Motten seyn?", "tokens": ["Vnd", "ei\u00b7ne", "Kost", "der", "Mot\u00b7ten", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Nach gutten Lebens-Mitteln ringen,", "tokens": ["Nach", "gut\u00b7ten", "Le\u00b7bens\u00b7Mit\u00b7teln", "rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erfahren das, was Er erfuhr,", "tokens": ["Er\u00b7fah\u00b7ren", "das", ",", "was", "Er", "er\u00b7fuhr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nichts aber mehr von hinnen bringen,", "tokens": ["Nichts", "a\u00b7ber", "mehr", "von", "hin\u00b7nen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als einen Sarg vnd Kittel nur?", "tokens": ["Als", "ei\u00b7nen", "Sarg", "vnd", "Kit\u00b7tel", "nur", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Wie seelig ist, wer, Gott ergeben,", "tokens": ["Wie", "see\u00b7lig", "ist", ",", "wer", ",", "Gott", "er\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "PWS", "$,", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihn f\u00fcr sein Theil vnd Reichthum h\u00e4lt,", "tokens": ["Ihn", "f\u00fcr", "sein", "Theil", "vnd", "Reicht\u00b7hum", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd Sch\u00e4tze sucht in jenem Leben,", "tokens": ["Vnd", "Sch\u00e4t\u00b7ze", "sucht", "in", "je\u00b7nem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der hat auch gnug nach dieser Welt.", "tokens": ["Der", "hat", "auch", "gnug", "nach", "die\u00b7ser", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Hie hat Herr Schmitner nach getrachtet,", "tokens": ["Hie", "hat", "Herr", "Schmit\u00b7ner", "nach", "ge\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Fiel jhm gleich endlich Reichthum zu,", "tokens": ["Fiel", "jhm", "gleich", "end\u00b7lich", "Reicht\u00b7hum", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hat er wenig sein geachtet,", "tokens": ["So", "hat", "er", "we\u00b7nig", "sein", "ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd dort gestrebt nach Gn\u00fcg vnd Rhu.", "tokens": ["Vnd", "dort", "ge\u00b7strebt", "nach", "Gn\u00fcg", "vnd", "Rhu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "APPR", "NE", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Wie V\u00e4terlich hat Er gerahten", "tokens": ["Wie", "V\u00e4\u00b7ter\u00b7lich", "hat", "Er", "ge\u00b7rah\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Seinen? wie mit reicher Handt?", "tokens": ["Den", "Sei\u00b7nen", "?", "wie", "mit", "rei\u00b7cher", "Handt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSS", "$.", "PWAV", "APPR", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Er dem Armut auch zustatten", "tokens": ["Wie", "Er", "dem", "Ar\u00b7mut", "auch", "zu\u00b7stat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sey kommen, ist vns gnug bekant.", "tokens": ["Sey", "kom\u00b7men", ",", "ist", "vns", "gnug", "be\u00b7kant", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Sonst ist Sein gantzer Lebens-Wandel", "tokens": ["Sonst", "ist", "Sein", "gant\u00b7zer", "Le\u00b7bens\u00b7Wan\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gewesen ohn betrug vnd Streit,", "tokens": ["Ge\u00b7we\u00b7sen", "ohn", "be\u00b7trug", "vnd", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er trieb in Gottesfurcht den Handel,", "tokens": ["Er", "trieb", "in", "Got\u00b7tes\u00b7furcht", "den", "Han\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd liebte nur Gerechtigheit.", "tokens": ["Vnd", "lieb\u00b7te", "nur", "Ge\u00b7rech\u00b7tig\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Wie solt Er solcher sch\u00f6nen Gaben", "tokens": ["Wie", "solt", "Er", "sol\u00b7cher", "sch\u00f6\u00b7nen", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht ewig nehmen Prei\u00df vnd danck", "tokens": ["Nicht", "e\u00b7wig", "neh\u00b7men", "Prei\u00df", "vnd", "danck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VVINF", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bey Gott, der nichts vmbsonst wil haben,", "tokens": ["Bey", "Gott", ",", "der", "nichts", "vmbsonst", "wil", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PIS", "ADV", "VMFIN", "VAINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Auch keinen kaltten Wassers-Tranck?", "tokens": ["Auch", "kei\u00b7nen", "kalt\u00b7ten", "Was\u00b7ser\u00b7sTranck", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Hie hat er reichlich ausgestrewet,", "tokens": ["Hie", "hat", "er", "reich\u00b7lich", "aus\u00b7ge\u00b7stre\u00b7wet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort sammlet Er nun Garben ein", "tokens": ["Dort", "samm\u00b7let", "Er", "nun", "Gar\u00b7ben", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Himmels G\u00fcttern sat erfrewet,", "tokens": ["Mit", "Him\u00b7mels", "G\u00fct\u00b7tern", "sat", "er\u00b7fre\u00b7wet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dort kan Er hoch vnd Edel seyn.", "tokens": ["Dort", "kan", "Er", "hoch", "vnd", "E\u00b7del", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "La\u00df N\u00fcrnbergk sein Geschlecht auffweisen", "tokens": ["La\u00df", "N\u00fcrn\u00b7bergk", "sein", "Ge\u00b7schlecht", "auf\u00b7fwei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "NE", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von hundert Jahren vnd noch mehr,", "tokens": ["Von", "hun\u00b7dert", "Jah\u00b7ren", "vnd", "noch", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df Welschland Seine Vettern preisen", "tokens": ["La\u00df", "Wel\u00b7schland", "Sei\u00b7ne", "Vet\u00b7tern", "prei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "NN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr tapffer Hertz, Ihr Lob vnd Ehr!", "tokens": ["Ihr", "tapf\u00b7fer", "Hertz", ",", "Ihr", "Lob", "vnd", "Ehr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Er ist zu gr\u00f6sser Hoheit kommen,", "tokens": ["Er", "ist", "zu", "gr\u00f6s\u00b7ser", "Ho\u00b7heit", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schwebt vmb des Allerh\u00f6chsten Throhn,", "tokens": ["Schwebt", "vmb", "des", "Al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "Thr\u00b7ohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd ist in seine Huld genommen,", "tokens": ["Vnd", "ist", "in", "sei\u00b7ne", "Huld", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd tr\u00e4gt die ewig' EhrenKrohn!", "tokens": ["Vnd", "tr\u00e4gt", "die", "e\u00b7wig'", "Eh\u00b7ren", "Krohn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Ihr denen Reichthum zugefallen,", "tokens": ["Ihr", "de\u00b7nen", "Reicht\u00b7hum", "zu\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein wendet ewer Gut recht an,", "tokens": ["Mein", "wen\u00b7det", "e\u00b7wer", "Gut", "recht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "PPOSAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Seht, da\u00df der Mammon dort f\u00fcr allen", "tokens": ["Seht", ",", "da\u00df", "der", "Mam\u00b7mon", "dort", "f\u00fcr", "al\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Euch gute Freunde machen kan.", "tokens": ["Euch", "gu\u00b7te", "Freun\u00b7de", "ma\u00b7chen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Da\u00df, wenn Ihr endlich m\u00fcsst von hinnen", "tokens": ["Da\u00df", ",", "wenn", "Ihr", "end\u00b7lich", "m\u00fcsst", "von", "hin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ADV", "VMFIN", "APPR", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nackt, als die nichts zur Welt gebracht,", "tokens": ["Nackt", ",", "als", "die", "nichts", "zur", "Welt", "ge\u00b7bracht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "ART", "PIS", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort m\u00f6gt das wahre Gut gewinnen,", "tokens": ["Dort", "m\u00f6gt", "das", "wah\u00b7re", "Gut", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das ewig Reich vnd seelig macht!", "tokens": ["Das", "e\u00b7wig", "Reich", "vnd", "see\u00b7lig", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "NN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "So solstu nun auch Anstand machen", "tokens": ["So", "sols\u00b7tu", "nun", "auch", "An\u00b7stand", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit deinen Reimen, hub ich an,", "tokens": ["Mit", "dei\u00b7nen", "Rei\u00b7men", ",", "hub", "ich", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd vor dich nehmen andre Sachen,", "tokens": ["Vnd", "vor", "dich", "neh\u00b7men", "and\u00b7re", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRF", "VVINF", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df Lieder schreiben wer da kan.", "tokens": ["La\u00df", "Lie\u00b7der", "schrei\u00b7ben", "wer", "da", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "VVFIN", "PWS", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Gewaltig Lob wird dir es bringen,", "tokens": ["Ge\u00b7wal\u00b7tig", "Lob", "wird", "dir", "es", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sich dein Flei\u00df so dienstbar h\u00e4lt,", "tokens": ["Da\u00df", "sich", "dein", "Flei\u00df", "so", "dienst\u00b7bar", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd alle Leichen mu\u00df besingen,", "tokens": ["Vnd", "al\u00b7le", "Lei\u00b7chen", "mu\u00df", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als w\u00e4hrstu hierzu nur bestellt.", "tokens": ["Als", "w\u00e4hrs\u00b7tu", "hier\u00b7zu", "nur", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PAV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Leg hin die Feder, vnd la\u00df bleiben", "tokens": ["Leg", "hin", "die", "Fe\u00b7der", ",", "vnd", "la\u00df", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "$,", "KON", "VVIMP", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was dir nicht grosses Vortheil giebt,", "tokens": ["Was", "dir", "nicht", "gros\u00b7ses", "Vor\u00b7theil", "giebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd wiltu denn ja etwas schreiben,", "tokens": ["Vnd", "wil\u00b7tu", "denn", "ja", "et\u00b7was", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erheb den Helden der dich liebt.", "tokens": ["Er\u00b7heb", "den", "Hel\u00b7den", "der", "dich", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Vnd hievon w\u00e4hr ich nicht gewichen,", "tokens": ["Vnd", "hie\u00b7von", "w\u00e4hr", "ich", "nicht", "ge\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als hierauff mir zu Ohren f\u00e4hrt,", "tokens": ["Als", "hier\u00b7auff", "mir", "zu", "Oh\u00b7ren", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Herr Schmitner ist anjetzt verblichen,", "tokens": ["Herr", "Schmit\u00b7ner", "ist", "an\u00b7jetzt", "ver\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist Er nicht eines Liedes wehrt?", "tokens": ["Ist", "Er", "nicht", "ei\u00b7nes", "Lie\u00b7des", "wehrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Sol Er von dir kein Denckmal haben,", "tokens": ["Sol", "Er", "von", "dir", "kein", "Denck\u00b7mal", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sol gleich der Aschen vnd Gebein", "tokens": ["Sol", "gleich", "der", "A\u00b7schen", "vnd", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch sein Verdienst vnd wehrte Gaben", "tokens": ["Auch", "sein", "Ver\u00b7dienst", "vnd", "wehr\u00b7te", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In ein Grab mit verschorren seyn?", "tokens": ["In", "ein", "Grab", "mit", "ver\u00b7schor\u00b7ren", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "VVPP", "VAINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.36": {"line.1": {"text": "Worzu wird anders euch Poeten", "tokens": ["Wor\u00b7zu", "wird", "an\u00b7ders", "euch", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "PPER", "NN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Der Geist vom Himmel selbs ger\u00fchrt,", "tokens": ["Der", "Geist", "vom", "Him\u00b7mel", "selbs", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als da\u00df jhr aus den SterbensN\u00f6then", "tokens": ["Als", "da\u00df", "jhr", "aus", "den", "Ster\u00b7bens", "N\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Das Lob der wahren Tugend f\u00fchrt?", "tokens": ["Das", "Lob", "der", "wah\u00b7ren", "Tu\u00b7gend", "f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Ihr sollt Fluch, Todt vnd Helle drewen", "tokens": ["Ihr", "sollt", "Fluch", ",", "Todt", "vnd", "Hel\u00b7le", "dre\u00b7wen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "NN", "KON", "NN", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Lastern der verkehrten Zeit,", "tokens": ["Den", "Las\u00b7tern", "der", "ver\u00b7kehr\u00b7ten", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Vnschuld aber auch erfrewen", "tokens": ["Die", "Vn\u00b7schuld", "a\u00b7ber", "auch", "er\u00b7fre\u00b7wen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Lobe, Danck vnd Seeligheit.", "tokens": ["Mit", "Lo\u00b7be", ",", "Danck", "vnd", "See\u00b7lig\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Was solt' ich thun? durch meine Lieder", "tokens": ["Was", "solt'", "ich", "thun", "?", "durch", "mei\u00b7ne", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Empfind ich auch sonst Lieb vnd Trew,", "tokens": ["Emp\u00b7find", "ich", "auch", "sonst", "Lieb", "vnd", "Trew", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich stimme meine Seiten wieder", "tokens": ["Ich", "stim\u00b7me", "mei\u00b7ne", "Sei\u00b7ten", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In eine Trawer-Melodey.", "tokens": ["In", "ei\u00b7ne", "Tra\u00b7wer\u00b7Me\u00b7lo\u00b7dey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Ist, sing ich, Schmitner auch gestorben,", "tokens": ["Ist", ",", "sing", "ich", ",", "Schmit\u00b7ner", "auch", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "$,", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Redligheit vnd Vnschuld Pfandt,", "tokens": ["Der", "Red\u00b7lig\u00b7heit", "vnd", "Vn\u00b7schuld", "Pfandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der hie so sch\u00f6nes Lob erworben", "tokens": ["Der", "hie", "so", "sch\u00f6\u00b7nes", "Lob", "er\u00b7wor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch seine Trew vnd milde Handt?", "tokens": ["Durch", "sei\u00b7ne", "Trew", "vnd", "mil\u00b7de", "Handt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Hat Den der Todt, wie andre Leichen,", "tokens": ["Hat", "Den", "der", "Todt", ",", "wie", "and\u00b7re", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ART", "NN", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gantz vntter seine Pflicht gebracht,", "tokens": ["Gantz", "vnt\u00b7ter", "sei\u00b7ne", "Pflicht", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der so viel Walds vnd wilder Eichen", "tokens": ["Der", "so", "viel", "Walds", "vnd", "wil\u00b7der", "Ei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PIAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm vntterth\u00e4nig hat gemacht?", "tokens": ["Ihm", "vnt\u00b7ter\u00b7th\u00e4\u00b7nig", "hat", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Schaw auff den Strom der krummen Deimen,", "tokens": ["Schaw", "auff", "den", "Strom", "der", "krum\u00b7men", "Dei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Er rinnt nicht mehr so gr\u00fcn verdeckt", "tokens": ["Er", "rinnt", "nicht", "mehr", "so", "gr\u00fcn", "ver\u00b7deckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Wolcken-an gewachsnen B\u00e4umen,", "tokens": ["Mit", "Wol\u00b7cken\u00b7an", "ge\u00b7wachs\u00b7nen", "B\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Labiaw vmbher fast bleckt.", "tokens": ["Da\u00df", "La\u00b7biaw", "vm\u00b7bher", "fast", "bleckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.42": {"line.1": {"text": "Er bl\u00f6sste nicht allein Lauckisken,", "tokens": ["Er", "bl\u00f6ss\u00b7te", "nicht", "al\u00b7lein", "Lauc\u00b7kis\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So weit es jhm nur gut ged\u00fcnckt,", "tokens": ["So", "weit", "es", "jhm", "nur", "gut", "ge\u00b7d\u00fcnckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er z\u00e4hmte weiter noch Crupisken,", "tokens": ["Er", "z\u00e4hm\u00b7te", "wei\u00b7ter", "noch", "Cru\u00b7pis\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das aus der klaren Inster trinckt.", "tokens": ["Das", "aus", "der", "kla\u00b7ren", "Ins\u00b7ter", "trinckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Es trug kein Holtz so dicke Schwarten,", "tokens": ["Es", "trug", "kein", "Holtz", "so", "di\u00b7cke", "Schwar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Flei\u00df hat es grundaus versehrt,", "tokens": ["Sein", "Flei\u00df", "hat", "es", "grun\u00b7daus", "ver\u00b7sehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "So da\u00df man seine Beil vnd Barten", "tokens": ["So", "da\u00df", "man", "sei\u00b7ne", "Beil", "vnd", "Bar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PIS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fern vmb die Tilsit hat geh\u00f6rt.", "tokens": ["Fern", "vmb", "die", "Til\u00b7sit", "hat", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Der Beer vnd P\u00fcffel sind erschrocken,", "tokens": ["Der", "Beer", "vnd", "P\u00fcf\u00b7fel", "sind", "er\u00b7schro\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sicher sie vorhin gelebt,", "tokens": ["Wie", "si\u00b7cher", "sie", "vor\u00b7hin", "ge\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist der gro\u00df vnd kleine Rocken", "tokens": ["Es", "ist", "der", "gro\u00df", "vnd", "klei\u00b7ne", "Ro\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr seinem Arbeits-Volck erbebt.", "tokens": ["F\u00fcr", "sei\u00b7nem", "Ar\u00b7beits\u00b7Volck", "er\u00b7bebt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Was Holtz er da herumb geschlagen", "tokens": ["Was", "Holtz", "er", "da", "he\u00b7rumb", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "PPER", "ADV", "APZR", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weis nicht allein der Memel-Flu\u00df", "tokens": ["Weis", "nicht", "al\u00b7lein", "der", "Me\u00b7mel\u00b7Flu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sampt Rangnit, sondern auch zusagen", "tokens": ["Sampt", "Rang\u00b7nit", ",", "son\u00b7dern", "auch", "zu\u00b7sa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "KON", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die dreyzehn-str\u00f6mig-reiche Ru\u00df!", "tokens": ["Die", "drey\u00b7zehn\u00b7str\u00f6\u00b7mig\u00b7rei\u00b7che", "Ru\u00df", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "O manche Ficht' vnd stoltze Linde,", "tokens": ["O", "man\u00b7che", "Ficht'", "vnd", "stolt\u00b7ze", "Lin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "KON", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie hoch sie sonst den Gipffel tr\u00e4gt,", "tokens": ["Wie", "hoch", "sie", "sonst", "den", "Gipf\u00b7fel", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der V\u00f6gel Sitz, vnd Schertz der Winde,", "tokens": ["Der", "V\u00f6\u00b7gel", "Sitz", ",", "vnd", "Schertz", "der", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Ihm zum F\u00fcssen sich gelegt.", "tokens": ["Hat", "Ihm", "zum", "F\u00fcs\u00b7sen", "sich", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Jetzt liegt er selbs hie vmbgehawen,", "tokens": ["Jetzt", "liegt", "er", "selbs", "hie", "vmb\u00b7ge\u00b7ha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nicht Leben, nicht gestalt, noch Muth", "tokens": ["Nicht", "Le\u00b7ben", ",", "nicht", "ge\u00b7stalt", ",", "noch", "Muth"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "NN", "$,", "PTKNEG", "VVPP", "$,", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist in vnd an Ihm mehr zu schawen,", "tokens": ["Ist", "in", "vnd", "an", "Ihm", "mehr", "zu", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "KON", "APPR", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Seht was des Todes Macht nicht thut!", "tokens": ["Seht", "was", "des", "To\u00b7des", "Macht", "nicht", "thut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ART", "NN", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Sein Holtz vnd Asch vnd andre Wahren", "tokens": ["Sein", "Holtz", "vnd", "Asch", "vnd", "and\u00b7re", "Wah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Seind jetzt noch manchem Lande wehrt,", "tokens": ["Seind", "jetzt", "noch", "man\u00b7chem", "Lan\u00b7de", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie schnell vnd gantz ist Er verfahren,", "tokens": ["Wie", "schnell", "vnd", "gantz", "ist", "Er", "ver\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd wird von W\u00fcrmern auffgezehrt!", "tokens": ["Vnd", "wird", "von", "W\u00fcr\u00b7mern", "auff\u00b7ge\u00b7zehrt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Heisst das sich sawer lassen werden", "tokens": ["Heisst", "das", "sich", "sa\u00b7wer", "las\u00b7sen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "PRF", "ADJD", "VVINF", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In Hitz vnd Frost, in M\u00fch vnd Pein,", "tokens": ["In", "Hitz", "vnd", "Frost", ",", "in", "M\u00fch", "vnd", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So bald sich legen in die Erden,", "tokens": ["So", "bald", "sich", "le\u00b7gen", "in", "die", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd eine Kost der Motten seyn?", "tokens": ["Vnd", "ei\u00b7ne", "Kost", "der", "Mot\u00b7ten", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Nach gutten Lebens-Mitteln ringen,", "tokens": ["Nach", "gut\u00b7ten", "Le\u00b7bens\u00b7Mit\u00b7teln", "rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erfahren das, was Er erfuhr,", "tokens": ["Er\u00b7fah\u00b7ren", "das", ",", "was", "Er", "er\u00b7fuhr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nichts aber mehr von hinnen bringen,", "tokens": ["Nichts", "a\u00b7ber", "mehr", "von", "hin\u00b7nen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als einen Sarg vnd Kittel nur?", "tokens": ["Als", "ei\u00b7nen", "Sarg", "vnd", "Kit\u00b7tel", "nur", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Wie seelig ist, wer, Gott ergeben,", "tokens": ["Wie", "see\u00b7lig", "ist", ",", "wer", ",", "Gott", "er\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "PWS", "$,", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihn f\u00fcr sein Theil vnd Reichthum h\u00e4lt,", "tokens": ["Ihn", "f\u00fcr", "sein", "Theil", "vnd", "Reicht\u00b7hum", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd Sch\u00e4tze sucht in jenem Leben,", "tokens": ["Vnd", "Sch\u00e4t\u00b7ze", "sucht", "in", "je\u00b7nem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der hat auch gnug nach dieser Welt.", "tokens": ["Der", "hat", "auch", "gnug", "nach", "die\u00b7ser", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Hie hat Herr Schmitner nach getrachtet,", "tokens": ["Hie", "hat", "Herr", "Schmit\u00b7ner", "nach", "ge\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Fiel jhm gleich endlich Reichthum zu,", "tokens": ["Fiel", "jhm", "gleich", "end\u00b7lich", "Reicht\u00b7hum", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hat er wenig sein geachtet,", "tokens": ["So", "hat", "er", "we\u00b7nig", "sein", "ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd dort gestrebt nach Gn\u00fcg vnd Rhu.", "tokens": ["Vnd", "dort", "ge\u00b7strebt", "nach", "Gn\u00fcg", "vnd", "Rhu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "APPR", "NE", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Wie V\u00e4terlich hat Er gerahten", "tokens": ["Wie", "V\u00e4\u00b7ter\u00b7lich", "hat", "Er", "ge\u00b7rah\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Seinen? wie mit reicher Handt?", "tokens": ["Den", "Sei\u00b7nen", "?", "wie", "mit", "rei\u00b7cher", "Handt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSS", "$.", "PWAV", "APPR", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Er dem Armut auch zustatten", "tokens": ["Wie", "Er", "dem", "Ar\u00b7mut", "auch", "zu\u00b7stat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sey kommen, ist vns gnug bekant.", "tokens": ["Sey", "kom\u00b7men", ",", "ist", "vns", "gnug", "be\u00b7kant", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Sonst ist Sein gantzer Lebens-Wandel", "tokens": ["Sonst", "ist", "Sein", "gant\u00b7zer", "Le\u00b7bens\u00b7Wan\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gewesen ohn betrug vnd Streit,", "tokens": ["Ge\u00b7we\u00b7sen", "ohn", "be\u00b7trug", "vnd", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er trieb in Gottesfurcht den Handel,", "tokens": ["Er", "trieb", "in", "Got\u00b7tes\u00b7furcht", "den", "Han\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd liebte nur Gerechtigheit.", "tokens": ["Vnd", "lieb\u00b7te", "nur", "Ge\u00b7rech\u00b7tig\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Wie solt Er solcher sch\u00f6nen Gaben", "tokens": ["Wie", "solt", "Er", "sol\u00b7cher", "sch\u00f6\u00b7nen", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht ewig nehmen Prei\u00df vnd danck", "tokens": ["Nicht", "e\u00b7wig", "neh\u00b7men", "Prei\u00df", "vnd", "danck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VVINF", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bey Gott, der nichts vmbsonst wil haben,", "tokens": ["Bey", "Gott", ",", "der", "nichts", "vmbsonst", "wil", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PIS", "ADV", "VMFIN", "VAINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Auch keinen kaltten Wassers-Tranck?", "tokens": ["Auch", "kei\u00b7nen", "kalt\u00b7ten", "Was\u00b7ser\u00b7sTranck", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Hie hat er reichlich ausgestrewet,", "tokens": ["Hie", "hat", "er", "reich\u00b7lich", "aus\u00b7ge\u00b7stre\u00b7wet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort sammlet Er nun Garben ein", "tokens": ["Dort", "samm\u00b7let", "Er", "nun", "Gar\u00b7ben", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Himmels G\u00fcttern sat erfrewet,", "tokens": ["Mit", "Him\u00b7mels", "G\u00fct\u00b7tern", "sat", "er\u00b7fre\u00b7wet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dort kan Er hoch vnd Edel seyn.", "tokens": ["Dort", "kan", "Er", "hoch", "vnd", "E\u00b7del", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "La\u00df N\u00fcrnbergk sein Geschlecht auffweisen", "tokens": ["La\u00df", "N\u00fcrn\u00b7bergk", "sein", "Ge\u00b7schlecht", "auf\u00b7fwei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "NE", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von hundert Jahren vnd noch mehr,", "tokens": ["Von", "hun\u00b7dert", "Jah\u00b7ren", "vnd", "noch", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df Welschland Seine Vettern preisen", "tokens": ["La\u00df", "Wel\u00b7schland", "Sei\u00b7ne", "Vet\u00b7tern", "prei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "NN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr tapffer Hertz, Ihr Lob vnd Ehr!", "tokens": ["Ihr", "tapf\u00b7fer", "Hertz", ",", "Ihr", "Lob", "vnd", "Ehr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Er ist zu gr\u00f6sser Hoheit kommen,", "tokens": ["Er", "ist", "zu", "gr\u00f6s\u00b7ser", "Ho\u00b7heit", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schwebt vmb des Allerh\u00f6chsten Throhn,", "tokens": ["Schwebt", "vmb", "des", "Al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "Thr\u00b7ohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd ist in seine Huld genommen,", "tokens": ["Vnd", "ist", "in", "sei\u00b7ne", "Huld", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd tr\u00e4gt die ewig' EhrenKrohn!", "tokens": ["Vnd", "tr\u00e4gt", "die", "e\u00b7wig'", "Eh\u00b7ren", "Krohn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Ihr denen Reichthum zugefallen,", "tokens": ["Ihr", "de\u00b7nen", "Reicht\u00b7hum", "zu\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein wendet ewer Gut recht an,", "tokens": ["Mein", "wen\u00b7det", "e\u00b7wer", "Gut", "recht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "PPOSAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Seht, da\u00df der Mammon dort f\u00fcr allen", "tokens": ["Seht", ",", "da\u00df", "der", "Mam\u00b7mon", "dort", "f\u00fcr", "al\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Euch gute Freunde machen kan.", "tokens": ["Euch", "gu\u00b7te", "Freun\u00b7de", "ma\u00b7chen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Da\u00df, wenn Ihr endlich m\u00fcsst von hinnen", "tokens": ["Da\u00df", ",", "wenn", "Ihr", "end\u00b7lich", "m\u00fcsst", "von", "hin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ADV", "VMFIN", "APPR", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nackt, als die nichts zur Welt gebracht,", "tokens": ["Nackt", ",", "als", "die", "nichts", "zur", "Welt", "ge\u00b7bracht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "ART", "PIS", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort m\u00f6gt das wahre Gut gewinnen,", "tokens": ["Dort", "m\u00f6gt", "das", "wah\u00b7re", "Gut", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das ewig Reich vnd seelig macht!", "tokens": ["Das", "e\u00b7wig", "Reich", "vnd", "see\u00b7lig", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "NN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}