{"textgrid.poem.57521": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: So geht und tretet denn auf die geweihten Stuffen,", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So geht und tretet denn auf die geweihten Stuffen,", "tokens": ["So", "geht", "und", "tre\u00b7tet", "denn", "auf", "die", "ge\u00b7weih\u00b7ten", "Stuf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dahin euch Gl\u00fcck und Recht, ihr werthen Freunde! ruffen.", "tokens": ["Da\u00b7hin", "euch", "Gl\u00fcck", "und", "Recht", ",", "ihr", "wert\u00b7hen", "Freun\u00b7de", "!", "ruf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "PPER", "NN", "KON", "NN", "$,", "PPER", "VVFIN", "NN", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Empfanget nach Verdienst der Lorberzweige Schmuck.", "tokens": ["Emp\u00b7fan\u00b7get", "nach", "Ver\u00b7dienst", "der", "Lor\u00b7ber\u00b7zwei\u00b7ge", "Schmuck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer sie so w\u00fcrdig tr\u00e4gt, der tr\u00e4gt sie w\u00fcrdig gnug;", "tokens": ["Wer", "sie", "so", "w\u00fcr\u00b7dig", "tr\u00e4gt", ",", "der", "tr\u00e4gt", "sie", "w\u00fcr\u00b7dig", "gnug", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dem darf auch Momus nicht den bittern Vorwurf dr\u00e4uen,", "tokens": ["Dem", "darf", "auch", "Mo\u00b7mus", "nicht", "den", "bit\u00b7tern", "Vor\u00b7wurf", "dr\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NE", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den andre sonst mit Recht bey neuen Titeln scheuen.", "tokens": ["Den", "and\u00b7re", "sonst", "mit", "Recht", "bey", "neu\u00b7en", "Ti\u00b7teln", "scheu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "APPR", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Allein, verzeihet mir, wenn euch die\u00df Blatt erkl\u00e4rt,", "tokens": ["Al\u00b7lein", ",", "ver\u00b7zei\u00b7het", "mir", ",", "wenn", "euch", "die\u00df", "Blatt", "er\u00b7kl\u00e4rt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was Pallas eurer Stirn f\u00fcr einen Kranz gew\u00e4hrt?", "tokens": ["Was", "Pal\u00b7las", "eu\u00b7rer", "Stirn", "f\u00fcr", "ei\u00b7nen", "Kranz", "ge\u00b7w\u00e4hrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PPOSAT", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und was es hei\u00dfen soll, wenn sie von ihren S\u00f6hnen", "tokens": ["Und", "was", "es", "hei\u00b7\u00dfen", "soll", ",", "wenn", "sie", "von", "ih\u00b7ren", "S\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Anstalt machen l\u00e4\u00dft, euch \u00f6ffentlich zu kr\u00f6nen?", "tokens": ["Die", "An\u00b7stalt", "ma\u00b7chen", "l\u00e4\u00dft", ",", "euch", "\u00f6f\u00b7fent\u00b7lich", "zu", "kr\u00f6\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie mancher kennt dabey nicht sie, nicht seine Pflicht,", "tokens": ["Wie", "man\u00b7cher", "kennt", "da\u00b7bey", "nicht", "sie", ",", "nicht", "sei\u00b7ne", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PAV", "PTKNEG", "PPER", "$,", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ja selbst den hohen Werth von dieser W\u00fcrde nicht;", "tokens": ["Ja", "selbst", "den", "ho\u00b7hen", "Werth", "von", "die\u00b7ser", "W\u00fcr\u00b7de", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und geht und eilt und l\u00e4uft, mit ungewaschnen H\u00e4nden,", "tokens": ["Und", "geht", "und", "eilt", "und", "l\u00e4uft", ",", "mit", "un\u00b7ge\u00b7waschnen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Minervens Heiligthum und G\u00f6tterhayn zu sch\u00e4nden.", "tokens": ["Mi\u00b7ner\u00b7vens", "Hei\u00b7lig\u00b7thum", "und", "G\u00f6t\u00b7ter\u00b7hayn", "zu", "sch\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Doch, wenn es ihm gelingt, so bleibt er, wer er war.", "tokens": ["Doch", ",", "wenn", "es", "ihm", "ge\u00b7lingt", ",", "so", "bleibt", "er", ",", "wer", "er", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Kein Werk, kein halbes Werk, kein einzig Wort so gar,", "tokens": ["Kein", "Werk", ",", "kein", "hal\u00b7bes", "Werk", ",", "kein", "ein\u00b7zig", "Wort", "so", "gar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "ADJA", "NN", "$,", "PIAT", "ADJD", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Entdeckt hernach von ihm, da\u00df er im Lehrerorden,", "tokens": ["Ent\u00b7deckt", "her\u00b7nach", "von", "ihm", ",", "da\u00df", "er", "im", "Leh\u00b7rer\u00b7or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "$,", "KOUS", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den er vergr\u00f6\u00dfert hat, ein t\u00fcchtig Glied geworden.", "tokens": ["Den", "er", "ver\u00b7gr\u00f6\u00b7\u00dfert", "hat", ",", "ein", "t\u00fcch\u00b7tig", "Glied", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,", "ART", "ADJD", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ihr, Freunde! wi\u00dft es zwar, und habt es l\u00e4ngst bedacht,", "tokens": ["Ihr", ",", "Freun\u00b7de", "!", "wi\u00dft", "es", "zwar", ",", "und", "habt", "es", "l\u00e4ngst", "be\u00b7dacht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$.", "VVFIN", "PPER", "ADV", "$,", "KON", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was euren blauen Hut so ehrenw\u00fcrdig macht;", "tokens": ["Was", "eu\u00b7ren", "blau\u00b7en", "Hut", "so", "eh\u00b7ren\u00b7w\u00fcr\u00b7dig", "macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ja selber euch gescheut, mit allzuk\u00fchnen Spr\u00fcngen,", "tokens": ["Ja", "sel\u00b7ber", "euch", "ge\u00b7scheut", ",", "mit", "all\u00b7zu\u00b7k\u00fch\u00b7nen", "Spr\u00fcn\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "KON", "PPER", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Euch auf den hohen Sitz der Lehrenden zu schwingen.", "tokens": ["Euch", "auf", "den", "ho\u00b7hen", "Sitz", "der", "Leh\u00b7ren\u00b7den", "zu", "schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich weis es gar zu wohl. Doch h\u00f6rt mich die\u00dfmal an;", "tokens": ["Ich", "weis", "es", "gar", "zu", "wohl", ".", "Doch", "h\u00f6rt", "mich", "die\u00df\u00b7mal", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPER", "ADV", "APPR", "ADV", "$.", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Weil das, was ihr schon wi\u00dft, doch andern nutzen kann.", "tokens": ["Weil", "das", ",", "was", "ihr", "schon", "wi\u00dft", ",", "doch", "an\u00b7dern", "nut\u00b7zen", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,", "ADV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und wie? gefiel euch sonst mein treugesinntes Lehren,", "tokens": ["Und", "wie", "?", "ge\u00b7fiel", "euch", "sonst", "mein", "treu\u00b7ge\u00b7sinn\u00b7tes", "Leh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$.", "VVFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So sch\u00e4mt euch heute nicht den Schlu\u00df davon zu h\u00f6ren.", "tokens": ["So", "sch\u00e4mt", "euch", "heu\u00b7te", "nicht", "den", "Schlu\u00df", "da\u00b7von", "zu", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Weisheit, der ihr hold, ja ganz ergeben seyd,", "tokens": ["Die", "Weis\u00b7heit", ",", "der", "ihr", "hold", ",", "ja", "ganz", "er\u00b7ge\u00b7ben", "seyd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "$,", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist nicht ein schn\u00f6des Spiel der Unbedachtsamkeit,", "tokens": ["Ist", "nicht", "ein", "schn\u00f6\u00b7des", "Spiel", "der", "Un\u00b7be\u00b7dacht\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist nicht ein Tockenwerk der unge\u00fcbten Jugend:", "tokens": ["Ist", "nicht", "ein", "To\u00b7cken\u00b7werk", "der", "un\u00b7ge\u00b7\u00fcb\u00b7ten", "Ju\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr Werk ist Wissenschaft, Gelehrsamkeit und Tugend.", "tokens": ["Ihr", "Werk", "ist", "Wis\u00b7sen\u00b7schaft", ",", "Ge\u00b7lehr\u00b7sam\u00b7keit", "und", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Minerva gleicht f\u00fcrwahr den frechen Dirnen nicht,", "tokens": ["Mi\u00b7ner\u00b7va", "gleicht", "f\u00fcr\u00b7wahr", "den", "fre\u00b7chen", "Dir\u00b7nen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKNEG", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Die den gemahlten Gips auf ihrem Angesicht", "tokens": ["Die", "den", "ge\u00b7mahl\u00b7ten", "Gips", "auf", "ih\u00b7rem", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit unversch\u00e4mter Stirn, den j\u00fcngsten Buhlern zeigen,", "tokens": ["Mit", "un\u00b7ver\u00b7sch\u00e4m\u00b7ter", "Stirn", ",", "den", "j\u00fcng\u00b7sten", "Buh\u00b7lern", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und jedem, der es w\u00fcnscht, ins geile Lager steigen.", "tokens": ["Und", "je\u00b7dem", ",", "der", "es", "w\u00fcnscht", ",", "ins", "gei\u00b7le", "La\u00b7ger", "stei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man haut kein pr\u00e4chtig Bild aus jedem Kieselstein:", "tokens": ["Man", "haut", "kein", "pr\u00e4ch\u00b7tig", "Bild", "aus", "je\u00b7dem", "Kie\u00b7sel\u00b7stein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "ADJD", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Kein niedertr\u00e4chtig Herz kann ihre Wohnung seyn.", "tokens": ["Kein", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "Herz", "kann", "ih\u00b7re", "Woh\u00b7nung", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Es mu\u00df ein edler Geist von ungemeinen Gaben,", "tokens": ["Es", "mu\u00df", "ein", "ed\u00b7ler", "Geist", "von", "un\u00b7ge\u00b7mei\u00b7nen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von seltnen Kr\u00e4ften seyn, der sie zur Freundinn haben,", "tokens": ["Von", "selt\u00b7nen", "Kr\u00e4f\u00b7ten", "seyn", ",", "der", "sie", "zur", "Freun\u00b7dinn", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAINF", "$,", "PRELS", "PPER", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ihr Herz gewinnen will. Wer nicht die Wahrheit liebt,", "tokens": ["Ihr", "Herz", "ge\u00b7win\u00b7nen", "will", ".", "Wer", "nicht", "die", "Wahr\u00b7heit", "liebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$.", "PWS", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Des P\u00f6bels Thorheit ha\u00dft, der Einfalt Abschied giebt,", "tokens": ["Des", "P\u00f6\u00b7bels", "Thor\u00b7heit", "ha\u00dft", ",", "der", "Ein\u00b7falt", "Ab\u00b7schied", "giebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Vernunft und Klugheit mehr, als Geld und Wollust achtet,", "tokens": ["Ver\u00b7nunft", "und", "Klug\u00b7heit", "mehr", ",", "als", "Geld", "und", "Wol\u00b7lust", "ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Dinge Grund erforscht, den Bau der Welt betrachtet,", "tokens": ["Der", "Din\u00b7ge", "Grund", "er\u00b7forscht", ",", "den", "Bau", "der", "Welt", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sich selber ausstudirt; und dann auf dieser Spur", "tokens": ["Sich", "sel\u00b7ber", "aus\u00b7stu\u00b7dirt", ";", "und", "dann", "auf", "die\u00b7ser", "Spur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADV", "VVPP", "$.", "KON", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den unumschr\u00e4nkten Geist, den Meister der Natur,", "tokens": ["Den", "un\u00b7um\u00b7schr\u00e4nk\u00b7ten", "Geist", ",", "den", "Meis\u00b7ter", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "In seinen Werken sucht, ergr\u00fcndet und entdecket;", "tokens": ["In", "sei\u00b7nen", "Wer\u00b7ken", "sucht", ",", "er\u00b7gr\u00fcn\u00b7det", "und", "ent\u00b7de\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wem nicht ein gro\u00dfes Herz in starken Br\u00fcsten stecket,", "tokens": ["Wem", "nicht", "ein", "gro\u00b7\u00dfes", "Herz", "in", "star\u00b7ken", "Br\u00fcs\u00b7ten", "ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So sich der Tugend weiht, die L\u00fcste niederschl\u00e4gt,", "tokens": ["So", "sich", "der", "Tu\u00b7gend", "weiht", ",", "die", "L\u00fcs\u00b7te", "nie\u00b7der\u00b7schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der Menschen Bestes sucht, zu allen Liebe tr\u00e4gt;", "tokens": ["Der", "Men\u00b7schen", "Bes\u00b7tes", "sucht", ",", "zu", "al\u00b7len", "Lie\u00b7be", "tr\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Vor keinem Unfall bebt, von keinem Misvergn\u00fcgen,", "tokens": ["Vor", "kei\u00b7nem", "Un\u00b7fall", "bebt", ",", "von", "kei\u00b7nem", "Mis\u00b7ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Verdru\u00df und Kummer weis, im Ungl\u00fcck nicht erliegen,", "tokens": ["Ver\u00b7dru\u00df", "und", "Kum\u00b7mer", "weis", ",", "im", "Un\u00b7gl\u00fcck", "nicht", "er\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$,", "APPRART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Nicht einmal wanken kann; wer nicht nach Ehre strebt,", "tokens": ["Nicht", "ein\u00b7mal", "wan\u00b7ken", "kann", ";", "wer", "nicht", "nach", "Eh\u00b7re", "strebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "VMFIN", "$.", "PWS", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die aus der Tugend k\u00f6mmt, kurz, wer nicht denkt und lebt,", "tokens": ["Die", "aus", "der", "Tu\u00b7gend", "k\u00f6mmt", ",", "kurz", ",", "wer", "nicht", "denkt", "und", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "ADJD", "$,", "PWS", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie weise M\u00e4nner thun; der irrt bey offnen Sinnen,", "tokens": ["Wie", "wei\u00b7se", "M\u00e4n\u00b7ner", "thun", ";", "der", "irrt", "bey", "off\u00b7nen", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$.", "ART", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und schm\u00e4uchelt sich umsonst die G\u00f6ttinn zu gewinnen.", "tokens": ["Und", "schm\u00e4u\u00b7chelt", "sich", "um\u00b7sonst", "die", "G\u00f6t\u00b7tinn", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So, so war ", "tokens": ["So", ",", "so", "war"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADV", "$,", "ADV", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "So war auch ", "tokens": ["So", "war", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Der darinn nur gefehlt, da\u00df er die weiten Bogen", "tokens": ["Der", "da\u00b7rinn", "nur", "ge\u00b7fehlt", ",", "da\u00df", "er", "die", "wei\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PAV", "ADV", "VVPP", "$,", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des Weltraums dem Geschick der Gottheit ganz entzogen.", "tokens": ["Des", "Welt\u00b7raums", "dem", "Ge\u00b7schick", "der", "Got\u00b7theit", "ganz", "ent\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So hat sich ", "tokens": ["So", "hat", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "So wies sich ", "tokens": ["So", "wies", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "So war auch ", "tokens": ["So", "war", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Als in der Rednerzunft, f\u00fcr ungemein zu preisen.", "tokens": ["Als", "in", "der", "Red\u00b7ner\u00b7zunft", ",", "f\u00fcr", "un\u00b7ge\u00b7mein", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "APPR", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dich, ", "tokens": ["Dich", ","], "token_info": ["word", "punct"], "pos": ["PPER", "$,"], "meter": "-", "measure": "single.down"}, "line.10": {"text": "Als er sein graues Haupt dem M\u00f6rder hingestreckt.", "tokens": ["Als", "er", "sein", "grau\u00b7es", "Haupt", "dem", "M\u00f6r\u00b7der", "hin\u00b7ge\u00b7streckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So ist ein ", "tokens": ["So", "ist", "ein"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "So hat sich ", "tokens": ["So", "hat", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "So hat ", "tokens": ["So", "hat"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "Nicht des Tyrannen Zorn, nicht Bann und Tod gescheut;", "tokens": ["Nicht", "des", "Ty\u00b7ran\u00b7nen", "Zorn", ",", "nicht", "Bann", "und", "Tod", "ge\u00b7scheut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "NN", "$,", "PTKNEG", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So haben andre mehr, die noch die Welt erhebet,", "tokens": ["So", "ha\u00b7ben", "and\u00b7re", "mehr", ",", "die", "noch", "die", "Welt", "er\u00b7he\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Tugend nachgejagt, der Weisheit nachgestrebet.", "tokens": ["Der", "Tu\u00b7gend", "nach\u00b7ge\u00b7jagt", ",", "der", "Weis\u00b7heit", "nach\u00b7ge\u00b7stre\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ihr Ruhm verschwindet nicht, so lange Sonn und Mond", "tokens": ["Ihr", "Ruhm", "ver\u00b7schwin\u00b7det", "nicht", ",", "so", "lan\u00b7ge", "Sonn", "und", "Mond"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKNEG", "$,", "ADV", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die Zeiten theilen wird, der Mensch auf Erden wohnt.", "tokens": ["Die", "Zei\u00b7ten", "thei\u00b7len", "wird", ",", "der", "Mensch", "auf", "Er\u00b7den", "wohnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VAFIN", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Das sind die Helden nun, auf die euch Pallas f\u00fchret,", "tokens": ["Das", "sind", "die", "Hel\u00b7den", "nun", ",", "auf", "die", "euch", "Pal\u00b7las", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$,", "APPR", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihr Freunde! wenn sie euch die muntre Scheitel zieret.", "tokens": ["Ihr", "Freun\u00b7de", "!", "wenn", "sie", "euch", "die", "mun\u00b7tre", "Schei\u00b7tel", "zie\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "KOUS", "PPER", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sie, als ", "tokens": ["Wie", "sie", ",", "als"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWAV", "PPER", "$,", "KOUS"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Nur von ", "tokens": ["Nur", "von"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "So reizt sie einen Geist, der von dem Himmel stammet,", "tokens": ["So", "reizt", "sie", "ei\u00b7nen", "Geist", ",", "der", "von", "dem", "Him\u00b7mel", "stam\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In dem die edle Glut der Weisheitliebe flammet,", "tokens": ["In", "dem", "die", "ed\u00b7le", "Glut", "der", "Weis\u00b7heit\u00b7lie\u00b7be", "flam\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der fast verge\u00dfnen Spur der Alten nachzugehn,", "tokens": ["Der", "fast", "ver\u00b7ge\u00df\u00b7nen", "Spur", "der", "Al\u00b7ten", "nach\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und sich, wie sie gethan, durch Tugend zu erh\u00f6hn:", "tokens": ["Und", "sich", ",", "wie", "sie", "ge\u00b7than", ",", "durch", "Tu\u00b7gend", "zu", "er\u00b7h\u00f6hn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$,", "PWAV", "PPER", "VVPP", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Durch Tugend, die sich zeigt durch ein vern\u00fcnftig Wissen,", "tokens": ["Durch", "Tu\u00b7gend", ",", "die", "sich", "zeigt", "durch", "ein", "ver\u00b7n\u00fcnf\u00b7tig", "Wis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "VVFIN", "APPR", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Gott und Menschen dient, und sich dem Wahn entrissen.", "tokens": ["Die", "Gott", "und", "Men\u00b7schen", "dient", ",", "und", "sich", "dem", "Wahn", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$,", "KON", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ihr Freunde, folgt ihr dann! ach folgt der F\u00fchrerinn!", "tokens": ["Ihr", "Freun\u00b7de", ",", "folgt", "ihr", "dann", "!", "ach", "folgt", "der", "F\u00fch\u00b7re\u00b7rinn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja, ja! ich kenne schon den ungemeinen Sinn,", "tokens": ["Ja", ",", "ja", "!", "ich", "ken\u00b7ne", "schon", "den", "un\u00b7ge\u00b7mei\u00b7nen", "Sinn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der eure Brust belebt. Ihr nehmt den Lehrertitel", "tokens": ["Der", "eu\u00b7re", "Brust", "be\u00b7lebt", ".", "Ihr", "nehmt", "den", "Leh\u00b7rer\u00b7ti\u00b7tel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl nicht aus Pralsucht an: ihr braucht ihn, als ein Mittel,", "tokens": ["Wohl", "nicht", "aus", "Pral\u00b7sucht", "an", ":", "ihr", "braucht", "ihn", ",", "als", "ein", "Mit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das andern zeigen soll, was ihr euch w\u00fcnscht zu seyn.", "tokens": ["Das", "an\u00b7dern", "zei\u00b7gen", "soll", ",", "was", "ihr", "euch", "w\u00fcnscht", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "$,", "PWS", "PPER", "PPER", "VVFIN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Grund ist schon gelegt, ihr kennet Holz und Stein,", "tokens": ["Der", "Grund", "ist", "schon", "ge\u00b7legt", ",", "ihr", "ken\u00b7net", "Holz", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Marmor und Metall, die ein Geb\u00e4ude zieren,", "tokens": ["Und", "Mar\u00b7mor", "und", "Me\u00b7tall", ",", "die", "ein", "Ge\u00b7b\u00e4u\u00b7de", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Minervens Tempelbau vollkommen aufzuf\u00fchren.", "tokens": ["Mi\u00b7ner\u00b7vens", "Tem\u00b7pel\u00b7bau", "voll\u00b7kom\u00b7men", "auf\u00b7zu\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "VVIZU", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Vollendet ihn begl\u00fcckt, vermehrt die Wissenschaft:", "tokens": ["Voll\u00b7en\u00b7det", "ihn", "be\u00b7gl\u00fcckt", ",", "ver\u00b7mehrt", "die", "Wis\u00b7sen\u00b7schaft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "$,", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Es fehlt euch nicht an Lust, es fehlt euch nicht an Kraft.", "tokens": ["Es", "fehlt", "euch", "nicht", "an", "Lust", ",", "es", "fehlt", "euch", "nicht", "an", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Begn\u00fcgt euch daran nicht, was ihr von mir geh\u00f6ret;", "tokens": ["Be\u00b7gn\u00fcgt", "euch", "da\u00b7ran", "nicht", ",", "was", "ihr", "von", "mir", "ge\u00b7h\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "PTKNEG", "$,", "PWS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Forscht selber flei\u00dfig nach, was ", "tokens": ["Forscht", "sel\u00b7ber", "flei\u00b7\u00dfig", "nach", ",", "was"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "ADJD", "PTKVZ", "$,", "PWS"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Was Holl- und Engelland, und Frankreich uns entdeckt,", "tokens": ["Was", "Holl", "und", "En\u00b7gel\u00b7land", ",", "und", "Fran\u00b7kreich", "uns", "ent\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "TRUNC", "KON", "NE", "$,", "KON", "NE", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und was f\u00fcr Flei\u00df und Witz in W\u00e4lschland selber steckt.", "tokens": ["Und", "was", "f\u00fcr", "Flei\u00df", "und", "Witz", "in", "W\u00e4l\u00b7schland", "sel\u00b7ber", "steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "KON", "NN", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Kunst ist nicht ersch\u00f6pft: wer kann sie ganz ergr\u00fcnden?", "tokens": ["Die", "Kunst", "ist", "nicht", "er\u00b7sch\u00f6pft", ":", "wer", "kann", "sie", "ganz", "er\u00b7gr\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$.", "PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wer eine Wahrheit weis, kann hundert andre finden.", "tokens": ["Wer", "ei\u00b7ne", "Wahr\u00b7heit", "weis", ",", "kann", "hun\u00b7dert", "and\u00b7re", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PTKVZ", "$,", "VMFIN", "CARD", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Wunder sind wir selbst, Natur und Welt so voll,", "tokens": ["Der", "Wun\u00b7der", "sind", "wir", "selbst", ",", "Na\u00b7tur", "und", "Welt", "so", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$,", "NN", "KON", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df niemand ihre Zahl so leicht ergr\u00fcnden soll.", "tokens": ["Da\u00df", "nie\u00b7mand", "ih\u00b7re", "Zahl", "so", "leicht", "er\u00b7gr\u00fcn\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Drum la\u00dft uns \u00e4msig seyn, und keine M\u00fche sparen!", "tokens": ["Drum", "la\u00dft", "uns", "\u00e4m\u00b7sig", "seyn", ",", "und", "kei\u00b7ne", "M\u00fc\u00b7he", "spa\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "VAINF", "$,", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Was man nicht heute lernt, das k\u00f6mmt doch mit den Jahren.", "tokens": ["Was", "man", "nicht", "heu\u00b7te", "lernt", ",", "das", "k\u00f6mmt", "doch", "mit", "den", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PTKNEG", "ADV", "VVFIN", "$,", "PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Doch dient auch, wie ihr k\u00f6nnt, der Welt durch euren Flei\u00df,", "tokens": ["Doch", "dient", "auch", ",", "wie", "ihr", "k\u00f6nnt", ",", "der", "Welt", "durch", "eu\u00b7ren", "Flei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lehrt andre, was ihr wi\u00dft, und nicht ein jeder weis.", "tokens": ["Lehrt", "and\u00b7re", ",", "was", "ihr", "wi\u00dft", ",", "und", "nicht", "ein", "je\u00b7der", "weis", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "KON", "PTKNEG", "ART", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir m\u00fcssen unser Pfand, das wir vom Himmel haben,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "un\u00b7ser", "Pfand", ",", "das", "wir", "vom", "Him\u00b7mel", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht in den lockern Sand des M\u00fc\u00dfigganges graben.", "tokens": ["Nicht", "in", "den", "lo\u00b7ckern", "Sand", "des", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ges", "gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bestreitet \u00fcberall das Vorurtheil der Welt,", "tokens": ["Be\u00b7strei\u00b7tet", "\u00fc\u00b7be\u00b7rall", "das", "Vor\u00b7urt\u00b7heil", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Philosophen nur f\u00fcr Grillenf\u00e4nger h\u00e4lt;", "tokens": ["Die", "Phi\u00b7lo\u00b7so\u00b7phen", "nur", "f\u00fcr", "Gril\u00b7len\u00b7f\u00e4n\u00b7ger", "h\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Und lasset k\u00fcnftighin in Worten, Schriften, Werken,", "tokens": ["Und", "las\u00b7set", "k\u00fcnf\u00b7tig\u00b7hin", "in", "Wor\u00b7ten", ",", "Schrif\u00b7ten", ",", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein philosophisch Thun und weises Wesen merken:", "tokens": ["Ein", "phi\u00b7lo\u00b7so\u00b7phisch", "Thun", "und", "wei\u00b7ses", "We\u00b7sen", "mer\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Denn wo nicht selbst die That von wahrer Weisheit spricht,", "tokens": ["Denn", "wo", "nicht", "selbst", "die", "That", "von", "wah\u00b7rer", "Weis\u00b7heit", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PTKNEG", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da glaubt man Hut und Ring und allen Titeln nicht.", "tokens": ["Da", "glaubt", "man", "Hut", "und", "Ring", "und", "al\u00b7len", "Ti\u00b7teln", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "KON", "NN", "KON", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So geht und tretet denn auf die geweihten Stuffen,", "tokens": ["So", "geht", "und", "tre\u00b7tet", "denn", "auf", "die", "ge\u00b7weih\u00b7ten", "Stuf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dahin euch Gl\u00fcck und Recht, ihr werthen Freunde! ruffen.", "tokens": ["Da\u00b7hin", "euch", "Gl\u00fcck", "und", "Recht", ",", "ihr", "wert\u00b7hen", "Freun\u00b7de", "!", "ruf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "PPER", "NN", "KON", "NN", "$,", "PPER", "VVFIN", "NN", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Empfanget nach Verdienst der Lorberzweige Schmuck.", "tokens": ["Emp\u00b7fan\u00b7get", "nach", "Ver\u00b7dienst", "der", "Lor\u00b7ber\u00b7zwei\u00b7ge", "Schmuck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer sie so w\u00fcrdig tr\u00e4gt, der tr\u00e4gt sie w\u00fcrdig gnug;", "tokens": ["Wer", "sie", "so", "w\u00fcr\u00b7dig", "tr\u00e4gt", ",", "der", "tr\u00e4gt", "sie", "w\u00fcr\u00b7dig", "gnug", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dem darf auch Momus nicht den bittern Vorwurf dr\u00e4uen,", "tokens": ["Dem", "darf", "auch", "Mo\u00b7mus", "nicht", "den", "bit\u00b7tern", "Vor\u00b7wurf", "dr\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "NE", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den andre sonst mit Recht bey neuen Titeln scheuen.", "tokens": ["Den", "and\u00b7re", "sonst", "mit", "Recht", "bey", "neu\u00b7en", "Ti\u00b7teln", "scheu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "APPR", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Allein, verzeihet mir, wenn euch die\u00df Blatt erkl\u00e4rt,", "tokens": ["Al\u00b7lein", ",", "ver\u00b7zei\u00b7het", "mir", ",", "wenn", "euch", "die\u00df", "Blatt", "er\u00b7kl\u00e4rt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was Pallas eurer Stirn f\u00fcr einen Kranz gew\u00e4hrt?", "tokens": ["Was", "Pal\u00b7las", "eu\u00b7rer", "Stirn", "f\u00fcr", "ei\u00b7nen", "Kranz", "ge\u00b7w\u00e4hrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PPOSAT", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und was es hei\u00dfen soll, wenn sie von ihren S\u00f6hnen", "tokens": ["Und", "was", "es", "hei\u00b7\u00dfen", "soll", ",", "wenn", "sie", "von", "ih\u00b7ren", "S\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Anstalt machen l\u00e4\u00dft, euch \u00f6ffentlich zu kr\u00f6nen?", "tokens": ["Die", "An\u00b7stalt", "ma\u00b7chen", "l\u00e4\u00dft", ",", "euch", "\u00f6f\u00b7fent\u00b7lich", "zu", "kr\u00f6\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie mancher kennt dabey nicht sie, nicht seine Pflicht,", "tokens": ["Wie", "man\u00b7cher", "kennt", "da\u00b7bey", "nicht", "sie", ",", "nicht", "sei\u00b7ne", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PAV", "PTKNEG", "PPER", "$,", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ja selbst den hohen Werth von dieser W\u00fcrde nicht;", "tokens": ["Ja", "selbst", "den", "ho\u00b7hen", "Werth", "von", "die\u00b7ser", "W\u00fcr\u00b7de", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und geht und eilt und l\u00e4uft, mit ungewaschnen H\u00e4nden,", "tokens": ["Und", "geht", "und", "eilt", "und", "l\u00e4uft", ",", "mit", "un\u00b7ge\u00b7waschnen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Minervens Heiligthum und G\u00f6tterhayn zu sch\u00e4nden.", "tokens": ["Mi\u00b7ner\u00b7vens", "Hei\u00b7lig\u00b7thum", "und", "G\u00f6t\u00b7ter\u00b7hayn", "zu", "sch\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Doch, wenn es ihm gelingt, so bleibt er, wer er war.", "tokens": ["Doch", ",", "wenn", "es", "ihm", "ge\u00b7lingt", ",", "so", "bleibt", "er", ",", "wer", "er", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Kein Werk, kein halbes Werk, kein einzig Wort so gar,", "tokens": ["Kein", "Werk", ",", "kein", "hal\u00b7bes", "Werk", ",", "kein", "ein\u00b7zig", "Wort", "so", "gar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "ADJA", "NN", "$,", "PIAT", "ADJD", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Entdeckt hernach von ihm, da\u00df er im Lehrerorden,", "tokens": ["Ent\u00b7deckt", "her\u00b7nach", "von", "ihm", ",", "da\u00df", "er", "im", "Leh\u00b7rer\u00b7or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "$,", "KOUS", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den er vergr\u00f6\u00dfert hat, ein t\u00fcchtig Glied geworden.", "tokens": ["Den", "er", "ver\u00b7gr\u00f6\u00b7\u00dfert", "hat", ",", "ein", "t\u00fcch\u00b7tig", "Glied", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAFIN", "$,", "ART", "ADJD", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ihr, Freunde! wi\u00dft es zwar, und habt es l\u00e4ngst bedacht,", "tokens": ["Ihr", ",", "Freun\u00b7de", "!", "wi\u00dft", "es", "zwar", ",", "und", "habt", "es", "l\u00e4ngst", "be\u00b7dacht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$.", "VVFIN", "PPER", "ADV", "$,", "KON", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was euren blauen Hut so ehrenw\u00fcrdig macht;", "tokens": ["Was", "eu\u00b7ren", "blau\u00b7en", "Hut", "so", "eh\u00b7ren\u00b7w\u00fcr\u00b7dig", "macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ja selber euch gescheut, mit allzuk\u00fchnen Spr\u00fcngen,", "tokens": ["Ja", "sel\u00b7ber", "euch", "ge\u00b7scheut", ",", "mit", "all\u00b7zu\u00b7k\u00fch\u00b7nen", "Spr\u00fcn\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "KON", "PPER", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Euch auf den hohen Sitz der Lehrenden zu schwingen.", "tokens": ["Euch", "auf", "den", "ho\u00b7hen", "Sitz", "der", "Leh\u00b7ren\u00b7den", "zu", "schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich weis es gar zu wohl. Doch h\u00f6rt mich die\u00dfmal an;", "tokens": ["Ich", "weis", "es", "gar", "zu", "wohl", ".", "Doch", "h\u00f6rt", "mich", "die\u00df\u00b7mal", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPER", "ADV", "APPR", "ADV", "$.", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Weil das, was ihr schon wi\u00dft, doch andern nutzen kann.", "tokens": ["Weil", "das", ",", "was", "ihr", "schon", "wi\u00dft", ",", "doch", "an\u00b7dern", "nut\u00b7zen", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,", "ADV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und wie? gefiel euch sonst mein treugesinntes Lehren,", "tokens": ["Und", "wie", "?", "ge\u00b7fiel", "euch", "sonst", "mein", "treu\u00b7ge\u00b7sinn\u00b7tes", "Leh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$.", "VVFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So sch\u00e4mt euch heute nicht den Schlu\u00df davon zu h\u00f6ren.", "tokens": ["So", "sch\u00e4mt", "euch", "heu\u00b7te", "nicht", "den", "Schlu\u00df", "da\u00b7von", "zu", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die Weisheit, der ihr hold, ja ganz ergeben seyd,", "tokens": ["Die", "Weis\u00b7heit", ",", "der", "ihr", "hold", ",", "ja", "ganz", "er\u00b7ge\u00b7ben", "seyd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "$,", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist nicht ein schn\u00f6des Spiel der Unbedachtsamkeit,", "tokens": ["Ist", "nicht", "ein", "schn\u00f6\u00b7des", "Spiel", "der", "Un\u00b7be\u00b7dacht\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist nicht ein Tockenwerk der unge\u00fcbten Jugend:", "tokens": ["Ist", "nicht", "ein", "To\u00b7cken\u00b7werk", "der", "un\u00b7ge\u00b7\u00fcb\u00b7ten", "Ju\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr Werk ist Wissenschaft, Gelehrsamkeit und Tugend.", "tokens": ["Ihr", "Werk", "ist", "Wis\u00b7sen\u00b7schaft", ",", "Ge\u00b7lehr\u00b7sam\u00b7keit", "und", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Minerva gleicht f\u00fcrwahr den frechen Dirnen nicht,", "tokens": ["Mi\u00b7ner\u00b7va", "gleicht", "f\u00fcr\u00b7wahr", "den", "fre\u00b7chen", "Dir\u00b7nen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKNEG", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Die den gemahlten Gips auf ihrem Angesicht", "tokens": ["Die", "den", "ge\u00b7mahl\u00b7ten", "Gips", "auf", "ih\u00b7rem", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit unversch\u00e4mter Stirn, den j\u00fcngsten Buhlern zeigen,", "tokens": ["Mit", "un\u00b7ver\u00b7sch\u00e4m\u00b7ter", "Stirn", ",", "den", "j\u00fcng\u00b7sten", "Buh\u00b7lern", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und jedem, der es w\u00fcnscht, ins geile Lager steigen.", "tokens": ["Und", "je\u00b7dem", ",", "der", "es", "w\u00fcnscht", ",", "ins", "gei\u00b7le", "La\u00b7ger", "stei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man haut kein pr\u00e4chtig Bild aus jedem Kieselstein:", "tokens": ["Man", "haut", "kein", "pr\u00e4ch\u00b7tig", "Bild", "aus", "je\u00b7dem", "Kie\u00b7sel\u00b7stein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "ADJD", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Kein niedertr\u00e4chtig Herz kann ihre Wohnung seyn.", "tokens": ["Kein", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "Herz", "kann", "ih\u00b7re", "Woh\u00b7nung", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Es mu\u00df ein edler Geist von ungemeinen Gaben,", "tokens": ["Es", "mu\u00df", "ein", "ed\u00b7ler", "Geist", "von", "un\u00b7ge\u00b7mei\u00b7nen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von seltnen Kr\u00e4ften seyn, der sie zur Freundinn haben,", "tokens": ["Von", "selt\u00b7nen", "Kr\u00e4f\u00b7ten", "seyn", ",", "der", "sie", "zur", "Freun\u00b7dinn", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAINF", "$,", "PRELS", "PPER", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ihr Herz gewinnen will. Wer nicht die Wahrheit liebt,", "tokens": ["Ihr", "Herz", "ge\u00b7win\u00b7nen", "will", ".", "Wer", "nicht", "die", "Wahr\u00b7heit", "liebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$.", "PWS", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Des P\u00f6bels Thorheit ha\u00dft, der Einfalt Abschied giebt,", "tokens": ["Des", "P\u00f6\u00b7bels", "Thor\u00b7heit", "ha\u00dft", ",", "der", "Ein\u00b7falt", "Ab\u00b7schied", "giebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Vernunft und Klugheit mehr, als Geld und Wollust achtet,", "tokens": ["Ver\u00b7nunft", "und", "Klug\u00b7heit", "mehr", ",", "als", "Geld", "und", "Wol\u00b7lust", "ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Dinge Grund erforscht, den Bau der Welt betrachtet,", "tokens": ["Der", "Din\u00b7ge", "Grund", "er\u00b7forscht", ",", "den", "Bau", "der", "Welt", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sich selber ausstudirt; und dann auf dieser Spur", "tokens": ["Sich", "sel\u00b7ber", "aus\u00b7stu\u00b7dirt", ";", "und", "dann", "auf", "die\u00b7ser", "Spur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADV", "VVPP", "$.", "KON", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den unumschr\u00e4nkten Geist, den Meister der Natur,", "tokens": ["Den", "un\u00b7um\u00b7schr\u00e4nk\u00b7ten", "Geist", ",", "den", "Meis\u00b7ter", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "In seinen Werken sucht, ergr\u00fcndet und entdecket;", "tokens": ["In", "sei\u00b7nen", "Wer\u00b7ken", "sucht", ",", "er\u00b7gr\u00fcn\u00b7det", "und", "ent\u00b7de\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wem nicht ein gro\u00dfes Herz in starken Br\u00fcsten stecket,", "tokens": ["Wem", "nicht", "ein", "gro\u00b7\u00dfes", "Herz", "in", "star\u00b7ken", "Br\u00fcs\u00b7ten", "ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So sich der Tugend weiht, die L\u00fcste niederschl\u00e4gt,", "tokens": ["So", "sich", "der", "Tu\u00b7gend", "weiht", ",", "die", "L\u00fcs\u00b7te", "nie\u00b7der\u00b7schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der Menschen Bestes sucht, zu allen Liebe tr\u00e4gt;", "tokens": ["Der", "Men\u00b7schen", "Bes\u00b7tes", "sucht", ",", "zu", "al\u00b7len", "Lie\u00b7be", "tr\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Vor keinem Unfall bebt, von keinem Misvergn\u00fcgen,", "tokens": ["Vor", "kei\u00b7nem", "Un\u00b7fall", "bebt", ",", "von", "kei\u00b7nem", "Mis\u00b7ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Verdru\u00df und Kummer weis, im Ungl\u00fcck nicht erliegen,", "tokens": ["Ver\u00b7dru\u00df", "und", "Kum\u00b7mer", "weis", ",", "im", "Un\u00b7gl\u00fcck", "nicht", "er\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$,", "APPRART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Nicht einmal wanken kann; wer nicht nach Ehre strebt,", "tokens": ["Nicht", "ein\u00b7mal", "wan\u00b7ken", "kann", ";", "wer", "nicht", "nach", "Eh\u00b7re", "strebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "VMFIN", "$.", "PWS", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die aus der Tugend k\u00f6mmt, kurz, wer nicht denkt und lebt,", "tokens": ["Die", "aus", "der", "Tu\u00b7gend", "k\u00f6mmt", ",", "kurz", ",", "wer", "nicht", "denkt", "und", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "ADJD", "$,", "PWS", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie weise M\u00e4nner thun; der irrt bey offnen Sinnen,", "tokens": ["Wie", "wei\u00b7se", "M\u00e4n\u00b7ner", "thun", ";", "der", "irrt", "bey", "off\u00b7nen", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$.", "ART", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und schm\u00e4uchelt sich umsonst die G\u00f6ttinn zu gewinnen.", "tokens": ["Und", "schm\u00e4u\u00b7chelt", "sich", "um\u00b7sonst", "die", "G\u00f6t\u00b7tinn", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "So, so war ", "tokens": ["So", ",", "so", "war"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADV", "$,", "ADV", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "So war auch ", "tokens": ["So", "war", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Der darinn nur gefehlt, da\u00df er die weiten Bogen", "tokens": ["Der", "da\u00b7rinn", "nur", "ge\u00b7fehlt", ",", "da\u00df", "er", "die", "wei\u00b7ten", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PAV", "ADV", "VVPP", "$,", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des Weltraums dem Geschick der Gottheit ganz entzogen.", "tokens": ["Des", "Welt\u00b7raums", "dem", "Ge\u00b7schick", "der", "Got\u00b7theit", "ganz", "ent\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So hat sich ", "tokens": ["So", "hat", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "So wies sich ", "tokens": ["So", "wies", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "So war auch ", "tokens": ["So", "war", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Als in der Rednerzunft, f\u00fcr ungemein zu preisen.", "tokens": ["Als", "in", "der", "Red\u00b7ner\u00b7zunft", ",", "f\u00fcr", "un\u00b7ge\u00b7mein", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "APPR", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dich, ", "tokens": ["Dich", ","], "token_info": ["word", "punct"], "pos": ["PPER", "$,"], "meter": "-", "measure": "single.down"}, "line.10": {"text": "Als er sein graues Haupt dem M\u00f6rder hingestreckt.", "tokens": ["Als", "er", "sein", "grau\u00b7es", "Haupt", "dem", "M\u00f6r\u00b7der", "hin\u00b7ge\u00b7streckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So ist ein ", "tokens": ["So", "ist", "ein"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "So hat sich ", "tokens": ["So", "hat", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "So hat ", "tokens": ["So", "hat"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "Nicht des Tyrannen Zorn, nicht Bann und Tod gescheut;", "tokens": ["Nicht", "des", "Ty\u00b7ran\u00b7nen", "Zorn", ",", "nicht", "Bann", "und", "Tod", "ge\u00b7scheut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "NN", "$,", "PTKNEG", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So haben andre mehr, die noch die Welt erhebet,", "tokens": ["So", "ha\u00b7ben", "and\u00b7re", "mehr", ",", "die", "noch", "die", "Welt", "er\u00b7he\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Tugend nachgejagt, der Weisheit nachgestrebet.", "tokens": ["Der", "Tu\u00b7gend", "nach\u00b7ge\u00b7jagt", ",", "der", "Weis\u00b7heit", "nach\u00b7ge\u00b7stre\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ihr Ruhm verschwindet nicht, so lange Sonn und Mond", "tokens": ["Ihr", "Ruhm", "ver\u00b7schwin\u00b7det", "nicht", ",", "so", "lan\u00b7ge", "Sonn", "und", "Mond"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKNEG", "$,", "ADV", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die Zeiten theilen wird, der Mensch auf Erden wohnt.", "tokens": ["Die", "Zei\u00b7ten", "thei\u00b7len", "wird", ",", "der", "Mensch", "auf", "Er\u00b7den", "wohnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VAFIN", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Das sind die Helden nun, auf die euch Pallas f\u00fchret,", "tokens": ["Das", "sind", "die", "Hel\u00b7den", "nun", ",", "auf", "die", "euch", "Pal\u00b7las", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$,", "APPR", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihr Freunde! wenn sie euch die muntre Scheitel zieret.", "tokens": ["Ihr", "Freun\u00b7de", "!", "wenn", "sie", "euch", "die", "mun\u00b7tre", "Schei\u00b7tel", "zie\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "KOUS", "PPER", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sie, als ", "tokens": ["Wie", "sie", ",", "als"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWAV", "PPER", "$,", "KOUS"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Nur von ", "tokens": ["Nur", "von"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "So reizt sie einen Geist, der von dem Himmel stammet,", "tokens": ["So", "reizt", "sie", "ei\u00b7nen", "Geist", ",", "der", "von", "dem", "Him\u00b7mel", "stam\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In dem die edle Glut der Weisheitliebe flammet,", "tokens": ["In", "dem", "die", "ed\u00b7le", "Glut", "der", "Weis\u00b7heit\u00b7lie\u00b7be", "flam\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der fast verge\u00dfnen Spur der Alten nachzugehn,", "tokens": ["Der", "fast", "ver\u00b7ge\u00df\u00b7nen", "Spur", "der", "Al\u00b7ten", "nach\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und sich, wie sie gethan, durch Tugend zu erh\u00f6hn:", "tokens": ["Und", "sich", ",", "wie", "sie", "ge\u00b7than", ",", "durch", "Tu\u00b7gend", "zu", "er\u00b7h\u00f6hn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$,", "PWAV", "PPER", "VVPP", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Durch Tugend, die sich zeigt durch ein vern\u00fcnftig Wissen,", "tokens": ["Durch", "Tu\u00b7gend", ",", "die", "sich", "zeigt", "durch", "ein", "ver\u00b7n\u00fcnf\u00b7tig", "Wis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "VVFIN", "APPR", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Gott und Menschen dient, und sich dem Wahn entrissen.", "tokens": ["Die", "Gott", "und", "Men\u00b7schen", "dient", ",", "und", "sich", "dem", "Wahn", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$,", "KON", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ihr Freunde, folgt ihr dann! ach folgt der F\u00fchrerinn!", "tokens": ["Ihr", "Freun\u00b7de", ",", "folgt", "ihr", "dann", "!", "ach", "folgt", "der", "F\u00fch\u00b7re\u00b7rinn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja, ja! ich kenne schon den ungemeinen Sinn,", "tokens": ["Ja", ",", "ja", "!", "ich", "ken\u00b7ne", "schon", "den", "un\u00b7ge\u00b7mei\u00b7nen", "Sinn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der eure Brust belebt. Ihr nehmt den Lehrertitel", "tokens": ["Der", "eu\u00b7re", "Brust", "be\u00b7lebt", ".", "Ihr", "nehmt", "den", "Leh\u00b7rer\u00b7ti\u00b7tel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl nicht aus Pralsucht an: ihr braucht ihn, als ein Mittel,", "tokens": ["Wohl", "nicht", "aus", "Pral\u00b7sucht", "an", ":", "ihr", "braucht", "ihn", ",", "als", "ein", "Mit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das andern zeigen soll, was ihr euch w\u00fcnscht zu seyn.", "tokens": ["Das", "an\u00b7dern", "zei\u00b7gen", "soll", ",", "was", "ihr", "euch", "w\u00fcnscht", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "$,", "PWS", "PPER", "PPER", "VVFIN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Grund ist schon gelegt, ihr kennet Holz und Stein,", "tokens": ["Der", "Grund", "ist", "schon", "ge\u00b7legt", ",", "ihr", "ken\u00b7net", "Holz", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Marmor und Metall, die ein Geb\u00e4ude zieren,", "tokens": ["Und", "Mar\u00b7mor", "und", "Me\u00b7tall", ",", "die", "ein", "Ge\u00b7b\u00e4u\u00b7de", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Minervens Tempelbau vollkommen aufzuf\u00fchren.", "tokens": ["Mi\u00b7ner\u00b7vens", "Tem\u00b7pel\u00b7bau", "voll\u00b7kom\u00b7men", "auf\u00b7zu\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "VVIZU", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Vollendet ihn begl\u00fcckt, vermehrt die Wissenschaft:", "tokens": ["Voll\u00b7en\u00b7det", "ihn", "be\u00b7gl\u00fcckt", ",", "ver\u00b7mehrt", "die", "Wis\u00b7sen\u00b7schaft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "$,", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Es fehlt euch nicht an Lust, es fehlt euch nicht an Kraft.", "tokens": ["Es", "fehlt", "euch", "nicht", "an", "Lust", ",", "es", "fehlt", "euch", "nicht", "an", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Begn\u00fcgt euch daran nicht, was ihr von mir geh\u00f6ret;", "tokens": ["Be\u00b7gn\u00fcgt", "euch", "da\u00b7ran", "nicht", ",", "was", "ihr", "von", "mir", "ge\u00b7h\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "PTKNEG", "$,", "PWS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Forscht selber flei\u00dfig nach, was ", "tokens": ["Forscht", "sel\u00b7ber", "flei\u00b7\u00dfig", "nach", ",", "was"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "ADJD", "PTKVZ", "$,", "PWS"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Was Holl- und Engelland, und Frankreich uns entdeckt,", "tokens": ["Was", "Holl", "und", "En\u00b7gel\u00b7land", ",", "und", "Fran\u00b7kreich", "uns", "ent\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "TRUNC", "KON", "NE", "$,", "KON", "NE", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und was f\u00fcr Flei\u00df und Witz in W\u00e4lschland selber steckt.", "tokens": ["Und", "was", "f\u00fcr", "Flei\u00df", "und", "Witz", "in", "W\u00e4l\u00b7schland", "sel\u00b7ber", "steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "KON", "NN", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Kunst ist nicht ersch\u00f6pft: wer kann sie ganz ergr\u00fcnden?", "tokens": ["Die", "Kunst", "ist", "nicht", "er\u00b7sch\u00f6pft", ":", "wer", "kann", "sie", "ganz", "er\u00b7gr\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$.", "PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wer eine Wahrheit weis, kann hundert andre finden.", "tokens": ["Wer", "ei\u00b7ne", "Wahr\u00b7heit", "weis", ",", "kann", "hun\u00b7dert", "and\u00b7re", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PTKVZ", "$,", "VMFIN", "CARD", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Wunder sind wir selbst, Natur und Welt so voll,", "tokens": ["Der", "Wun\u00b7der", "sind", "wir", "selbst", ",", "Na\u00b7tur", "und", "Welt", "so", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$,", "NN", "KON", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df niemand ihre Zahl so leicht ergr\u00fcnden soll.", "tokens": ["Da\u00df", "nie\u00b7mand", "ih\u00b7re", "Zahl", "so", "leicht", "er\u00b7gr\u00fcn\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Drum la\u00dft uns \u00e4msig seyn, und keine M\u00fche sparen!", "tokens": ["Drum", "la\u00dft", "uns", "\u00e4m\u00b7sig", "seyn", ",", "und", "kei\u00b7ne", "M\u00fc\u00b7he", "spa\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "VAINF", "$,", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Was man nicht heute lernt, das k\u00f6mmt doch mit den Jahren.", "tokens": ["Was", "man", "nicht", "heu\u00b7te", "lernt", ",", "das", "k\u00f6mmt", "doch", "mit", "den", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PTKNEG", "ADV", "VVFIN", "$,", "PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Doch dient auch, wie ihr k\u00f6nnt, der Welt durch euren Flei\u00df,", "tokens": ["Doch", "dient", "auch", ",", "wie", "ihr", "k\u00f6nnt", ",", "der", "Welt", "durch", "eu\u00b7ren", "Flei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lehrt andre, was ihr wi\u00dft, und nicht ein jeder weis.", "tokens": ["Lehrt", "and\u00b7re", ",", "was", "ihr", "wi\u00dft", ",", "und", "nicht", "ein", "je\u00b7der", "weis", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "KON", "PTKNEG", "ART", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir m\u00fcssen unser Pfand, das wir vom Himmel haben,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "un\u00b7ser", "Pfand", ",", "das", "wir", "vom", "Him\u00b7mel", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht in den lockern Sand des M\u00fc\u00dfigganges graben.", "tokens": ["Nicht", "in", "den", "lo\u00b7ckern", "Sand", "des", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ges", "gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bestreitet \u00fcberall das Vorurtheil der Welt,", "tokens": ["Be\u00b7strei\u00b7tet", "\u00fc\u00b7be\u00b7rall", "das", "Vor\u00b7urt\u00b7heil", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Philosophen nur f\u00fcr Grillenf\u00e4nger h\u00e4lt;", "tokens": ["Die", "Phi\u00b7lo\u00b7so\u00b7phen", "nur", "f\u00fcr", "Gril\u00b7len\u00b7f\u00e4n\u00b7ger", "h\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Und lasset k\u00fcnftighin in Worten, Schriften, Werken,", "tokens": ["Und", "las\u00b7set", "k\u00fcnf\u00b7tig\u00b7hin", "in", "Wor\u00b7ten", ",", "Schrif\u00b7ten", ",", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein philosophisch Thun und weises Wesen merken:", "tokens": ["Ein", "phi\u00b7lo\u00b7so\u00b7phisch", "Thun", "und", "wei\u00b7ses", "We\u00b7sen", "mer\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Denn wo nicht selbst die That von wahrer Weisheit spricht,", "tokens": ["Denn", "wo", "nicht", "selbst", "die", "That", "von", "wah\u00b7rer", "Weis\u00b7heit", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PTKNEG", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da glaubt man Hut und Ring und allen Titeln nicht.", "tokens": ["Da", "glaubt", "man", "Hut", "und", "Ring", "und", "al\u00b7len", "Ti\u00b7teln", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "KON", "NN", "KON", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}