{"textgrid.poem.24321": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "1L: (auf dem innern Deckel)", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "(auf dem innern Deckel)", "tokens": ["(", "auf", "dem", "in\u00b7nern", "De\u00b7ckel", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Madam! Ich hoffe sehr, da\u00df Sie mich \u00fcberleben", "tokens": ["Ma\u00b7dam", "!", "Ich", "hof\u00b7fe", "sehr", ",", "da\u00df", "Sie", "mich", "\u00fc\u00b7berl\u00b7e\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mir (wohl bald) einmal die letzte Ehre geben.", "tokens": ["Und", "mir", "(", "wohl", "bald", ")", "ein\u00b7mal", "die", "letz\u00b7te", "Eh\u00b7re", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "ADV", "ADV", "$(", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dort, hinterm Weizenfeld, das jetzt in \u00c4hren steht,", "tokens": ["Dort", ",", "hin\u00b7term", "Wei\u00b7zen\u00b7feld", ",", "das", "jetzt", "in", "\u00c4h\u00b7ren", "steht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Seh ich den Schauplatz unsres letzten T\u00eate-\u00e0-T\u00eate.", "tokens": ["Seh", "ich", "den", "Schau\u00b7platz", "uns\u00b7res", "letz\u00b7ten", "T\u00eate\u00b7\u00e0\u00b7T\u00eate", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Ich liege dann im Sarg; ein letzter Veilchenstrau\u00df", "tokens": ["Ich", "lie\u00b7ge", "dann", "im", "Sarg", ";", "ein", "letz\u00b7ter", "Veil\u00b7chen\u00b7strau\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Folgt mir aus Ihrer Hand, und dieses Spiel ist aus.", "tokens": ["Folgt", "mir", "aus", "Ih\u00b7rer", "Hand", ",", "und", "die\u00b7ses", "Spiel", "ist", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "KON", "PDAT", "NN", "VAFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie werden weinen. Ach, ich kenn Ihr gutes Herz,", "tokens": ["Sie", "wer\u00b7den", "wei\u00b7nen", ".", "Ach", ",", "ich", "kenn", "Ihr", "gu\u00b7tes", "Herz", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVINF", "$.", "ITJ", "$,", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Echt, wie Ihr Lieben, ist gewi\u00df Ihr Witwenschmerz,", "tokens": ["Echt", ",", "wie", "Ihr", "Lie\u00b7ben", ",", "ist", "ge\u00b7wi\u00df", "Ihr", "Wit\u00b7wensc\u00b7hmerz", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "ADJA", "$,", "VAFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und vielmals schreiten Sie zum schw\u00e4rzlichen Oval", "tokens": ["Und", "viel\u00b7mals", "schrei\u00b7ten", "Sie", "zum", "schw\u00e4rz\u00b7li\u00b7chen", "O\u00b7val"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Eibenb\u00e4ume in Graf Thr\u00fcmmels Schattental.", "tokens": ["Der", "Ei\u00b7ben\u00b7b\u00e4u\u00b7me", "in", "Graf", "Thr\u00fcm\u00b7mels", "Schat\u00b7ten\u00b7tal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "NN", "$."], "meter": "-+-+--++-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Dann aber, bitt ich sehr, Madam, solln Sie nicht weinen.", "tokens": ["Dann", "a\u00b7ber", ",", "bitt", "ich", "sehr", ",", "Ma\u00b7dam", ",", "solln", "Sie", "nicht", "wei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "VVFIN", "PPER", "ADV", "$,", "NN", "$,", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Sonne wird vergn\u00fcgt der goldenen Lilie scheinen,", "tokens": ["Die", "Son\u00b7ne", "wird", "ver\u00b7gn\u00fcgt", "der", "gol\u00b7de\u00b7nen", "Li\u00b7lie", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Die unsre T\u00e4nzerin in ihren H\u00e4nden h\u00e4lt,", "tokens": ["Die", "uns\u00b7re", "T\u00e4n\u00b7ze\u00b7rin", "in", "ih\u00b7ren", "H\u00e4n\u00b7den", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die unserm Schlummerplatz zur W\u00e4chtrin ward bestellt", "tokens": ["Die", "un\u00b7serm", "Schlum\u00b7mer\u00b7platz", "zur", "W\u00e4cht\u00b7rin", "ward", "be\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Durch eines Meisters Hand, der gern das Leben schm\u00fcckte", "tokens": ["Durch", "ei\u00b7nes", "Meis\u00b7ters", "Hand", ",", "der", "gern", "das", "Le\u00b7ben", "schm\u00fcck\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und dem sogar der Schmuck des Totenplatzes gl\u00fcckte.", "tokens": ["Und", "dem", "so\u00b7gar", "der", "Schmuck", "des", "To\u00b7ten\u00b7plat\u00b7zes", "gl\u00fcck\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wo sonst das Christenkreuz eckige Schatten legt,", "tokens": ["Wo", "sonst", "das", "Chris\u00b7ten\u00b7kreuz", "ec\u00b7ki\u00b7ge", "Schat\u00b7ten", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.19": {"text": "Hat eine Grazie er zum sch\u00f6nsten Tanz bewegt.", "tokens": ["Hat", "ei\u00b7ne", "Gra\u00b7zie", "er", "zum", "sch\u00f6ns\u00b7ten", "Tanz", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Selbst \u00fcber Gr\u00e4bern tanzt das Leben, stets am\u00f6n:", "tokens": ["Selbst", "\u00fc\u00b7ber", "Gr\u00e4\u00b7bern", "tanzt", "das", "Le\u00b7ben", ",", "stets", "a\u00b7m\u00f6n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein junges M\u00e4dchen ists, verliebt, gelenk und sch\u00f6n.", "tokens": ["Ein", "jun\u00b7ges", "M\u00e4d\u00b7chen", "ists", ",", "ver\u00b7liebt", ",", "ge\u00b7lenk", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "VVPP", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Betrachten Sie es wohl, und denken Sie dabei,", "tokens": ["Be\u00b7trach\u00b7ten", "Sie", "es", "wohl", ",", "und", "den\u00b7ken", "Sie", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "$,", "KON", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wie angenehm die Ruh nach langem Tanze sei", "tokens": ["Wie", "an\u00b7ge\u00b7nehm", "die", "Ruh", "nach", "lan\u00b7gem", "Tan\u00b7ze", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "F\u00fcr einen alten Mann, der manchen Pas gesprungen.", "tokens": ["F\u00fcr", "ei\u00b7nen", "al\u00b7ten", "Mann", ",", "der", "man\u00b7chen", "Pas", "ge\u00b7sprun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Gern, glauben Sies, Madam, lie\u00df er den Platz den Jungen.", "tokens": ["Gern", ",", "glau\u00b7ben", "Sies", ",", "Ma\u00b7dam", ",", "lie\u00df", "er", "den", "Platz", "den", "Jun\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PIS", "$,", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Nur da\u00df er Sie, mein Herz, verlassen mu\u00dfte, war", "tokens": ["Nur", "da\u00df", "er", "Sie", ",", "mein", "Herz", ",", "ver\u00b7las\u00b7sen", "mu\u00df\u00b7te", ",", "war"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "KOUS", "PPER", "PPER", "$,", "PPOSAT", "NN", "$,", "VVINF", "VMFIN", "$,", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ihm bitter weh ... Mein Gott, nun wein ich selber gar.", "tokens": ["Ihm", "bit\u00b7ter", "weh", "...", "Mein", "Gott", ",", "nun", "wein", "ich", "sel\u00b7ber", "gar", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKVZ", "$(", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ich liebe, liebe dich. Ich will nicht von dir gehn.", "tokens": ["Ich", "lie\u00b7be", ",", "lie\u00b7be", "dich", ".", "Ich", "will", "nicht", "von", "dir", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "PTKNEG", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und, wenn des Himmels Tore vor mir offen st\u00fcnden,", "tokens": ["Und", ",", "wenn", "des", "Him\u00b7mels", "To\u00b7re", "vor", "mir", "of\u00b7fen", "st\u00fcn\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "NE", "APPR", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ich will, will nicht zu Gott. In allen meinen S\u00fcnden,", "tokens": ["Ich", "will", ",", "will", "nicht", "zu", "Gott", ".", "In", "al\u00b7len", "mei\u00b7nen", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VMFIN", "PTKNEG", "APPR", "NN", "$.", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Krank, alt und schwach will ich an deiner Seite stehn.", "tokens": ["Krank", ",", "alt", "und", "schwach", "will", "ich", "an", "dei\u00b7ner", "Sei\u00b7te", "stehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "ADJD", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Grau wird es um mich her, doch hab ich dich, mein Licht.", "tokens": ["Grau", "wird", "es", "um", "mich", "her", ",", "doch", "hab", "ich", "dich", ",", "mein", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "PRF", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ich leide, ich bin m\u00fcd. Doch sterben will ich nicht.", "tokens": ["Ich", "lei\u00b7de", ",", "ich", "bin", "m\u00fcd", ".", "Doch", "ster\u00b7ben", "will", "ich", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "$.", "KON", "VVINF", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Nun, nun, nicht so, mein Herz. Was sein mu\u00df, das mu\u00df sein.", "tokens": ["Nun", ",", "nun", ",", "nicht", "so", ",", "mein", "Herz", ".", "Was", "sein", "mu\u00df", ",", "das", "mu\u00df", "sein", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "PTKNEG", "ADV", "$,", "PPOSAT", "NN", "$.", "PWS", "VAINF", "VMFIN", "$,", "PDS", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die T\u00e4nzerin winkt und l\u00e4dt zum letzten Tanz mich ein.", "tokens": ["Die", "T\u00e4n\u00b7ze\u00b7rin", "winkt", "und", "l\u00e4dt", "zum", "letz\u00b7ten", "Tanz", "mich", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ADJD", "APPRART", "ADJA", "NN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie m\u00fcssen mich, Madam, Sie m\u00fcssen mich ihr lassen", "tokens": ["Sie", "m\u00fcs\u00b7sen", "mich", ",", "Ma\u00b7dam", ",", "Sie", "m\u00fcs\u00b7sen", "mich", "ihr", "las\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "$,", "NN", "$,", "PPER", "VMFIN", "PPER", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und m\u00fcssen sich ein Herz zum letzten Schmerze fassen,", "tokens": ["Und", "m\u00fcs\u00b7sen", "sich", "ein", "Herz", "zum", "letz\u00b7ten", "Schmer\u00b7ze", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Ihnen von mir kommt, von mir, den nichts so qu\u00e4lt,", "tokens": ["Der", "Ih\u00b7nen", "von", "mir", "kommt", ",", "von", "mir", ",", "den", "nichts", "so", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVFIN", "$,", "APPR", "PPER", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als was er gegen Sie in Wirrheit hat gefehlt.", "tokens": ["Als", "was", "er", "ge\u00b7gen", "Sie", "in", "Wirr\u00b7heit", "hat", "ge\u00b7fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "PPER", "APPR", "PPER", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verzeih, verzeihe mir! Ich wei\u00df, ich habe dir", "tokens": ["Ver\u00b7zeih", ",", "ver\u00b7zei\u00b7he", "mir", "!", "Ich", "wei\u00df", ",", "ich", "ha\u00b7be", "dir"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Unendlich weh getan. Doch weher tat ich mir.", "tokens": ["Un\u00b7end\u00b7lich", "weh", "ge\u00b7tan", ".", "Doch", "we\u00b7her", "tat", "ich", "mir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVPP", "$.", "KON", "ADJD", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du stirbst vielleicht in Gott. Ich fahre gottlos hin,", "tokens": ["Du", "stirbst", "viel\u00b7leicht", "in", "Gott", ".", "Ich", "fah\u00b7re", "gott\u00b7los", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Weil ich ein Sohn der Qual und ohne Z\u00fcgel bin,", "tokens": ["Weil", "ich", "ein", "Sohn", "der", "Qual", "und", "oh\u00b7ne", "Z\u00fc\u00b7gel", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "KON", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein wildes Tier, vom Sporn des Teufels angehetzt,", "tokens": ["Ein", "wil\u00b7des", "Tier", ",", "vom", "Sporn", "des", "Teu\u00b7fels", "an\u00b7ge\u00b7hetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gequ\u00e4lt zu qu\u00e4len, \u2013 ach, wie ist mein Herz zerfetzt", "tokens": ["Ge\u00b7qu\u00e4lt", "zu", "qu\u00e4\u00b7len", ",", "\u2013", "ach", ",", "wie", "ist", "mein", "Herz", "zer\u00b7fetzt"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "PTKZU", "VVINF", "$,", "$(", "XY", "$,", "PWAV", "VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Von Wut und Gier und Angst. H\u00e4tt ich nicht dich gehabt,", "tokens": ["Von", "Wut", "und", "Gier", "und", "Angst", ".", "H\u00e4tt", "ich", "nicht", "dich", "ge\u00b7habt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$.", "VVFIN", "PPER", "PTKNEG", "PPER", "VAPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die immer wieder mich mit Licht und Trost begabt,", "tokens": ["Die", "im\u00b7mer", "wie\u00b7der", "mich", "mit", "Licht", "und", "Trost", "be\u00b7gabt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PPER", "APPR", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ich h\u00e4tte l\u00e4ngst mich selbst aus diesem Buch gestrichen,", "tokens": ["Ich", "h\u00e4t\u00b7te", "l\u00e4ngst", "mich", "selbst", "aus", "die\u00b7sem", "Buch", "ge\u00b7stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "ADV", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "In dem ich immer nur als Unheilsmaske stand,", "tokens": ["In", "dem", "ich", "im\u00b7mer", "nur", "als", "Un\u00b7heils\u00b7mas\u00b7ke", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Stand ich auch manchmal hoch. Erst als dein Herz ich fand,", "tokens": ["Stand", "ich", "auch", "manch\u00b7mal", "hoch", ".", "Erst", "als", "dein", "Herz", "ich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "$.", "ADV", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sind jener Nebel schwerste grau von mir gewichen.", "tokens": ["Sind", "je\u00b7ner", "Ne\u00b7bel", "schwers\u00b7te", "grau", "von", "mir", "ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "VVFIN", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich sch\u00e4me mich. Par Dieu! So schreibt kein Mann von Adel.", "tokens": ["Ich", "sch\u00e4\u00b7me", "mich", ".", "Par", "Di\u00b7eu", "!", "So", "schreibt", "kein", "Mann", "von", "A\u00b7del", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "NE", "NE", "$.", "ADV", "VVFIN", "PIAT", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gott, der Graf Thr\u00fcmmel schuf, verdient drum keinen Tadel,", "tokens": ["Gott", ",", "der", "Graf", "Thr\u00fcm\u00b7mel", "schuf", ",", "ver\u00b7dient", "drum", "kei\u00b7nen", "Ta\u00b7del", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "NN", "VVFIN", "$,", "VVFIN", "PAV", "PIAT", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und, was ich selbst mit mir, vielleicht verkehrt, begann,", "tokens": ["Und", ",", "was", "ich", "selbst", "mit", "mir", ",", "viel\u00b7leicht", "ver\u00b7kehrt", ",", "be\u00b7gann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "ADV", "APPR", "PPER", "$,", "ADV", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich tats auf meinen Kopf und als ein Edelmann.", "tokens": ["Ich", "tats", "auf", "mei\u00b7nen", "Kopf", "und", "als", "ein", "E\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der P\u00f6bel mag sich selbst ziehn an den langen Ohren,", "tokens": ["Der", "P\u00f6\u00b7bel", "mag", "sich", "selbst", "ziehn", "an", "den", "lan\u00b7gen", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "VVINF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich respektiere mich und bleibe wohlgeboren.", "tokens": ["Ich", "res\u00b7pek\u00b7tie\u00b7re", "mich", "und", "blei\u00b7be", "wohl\u00b7ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bereuen ist gemein. Tugend f\u00fcrs Publikum.", "tokens": ["Be\u00b7reu\u00b7en", "ist", "ge\u00b7mein", ".", "Tu\u00b7gend", "f\u00fcrs", "Pub\u00b7li\u00b7kum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$.", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Der Thr\u00fcmmel Wappenwort hei\u00dft stolz: Dreh dich nicht um!", "tokens": ["Der", "Thr\u00fcm\u00b7mel", "Wap\u00b7pen\u00b7wort", "hei\u00dft", "stolz", ":", "Dreh", "dich", "nicht", "um", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "$.", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth ist, wie ein jeder wei\u00df,", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "ist", ",", "wie", "ein", "je\u00b7der", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "PWAV", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sch\u00f6n, stolz und voller Witz, bei ihrer Augen Blitz", "tokens": ["Sch\u00f6n", ",", "stolz", "und", "vol\u00b7ler", "Witz", ",", "bei", "ih\u00b7rer", "Au\u00b7gen", "Blitz"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADJD", "KON", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird es den Pagen, wirds den Exzellenzen hei\u00df.", "tokens": ["Wird", "es", "den", "Pa\u00b7gen", ",", "wirds", "den", "Ex\u00b7zel\u00b7len\u00b7zen", "hei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Geruht sie mit Gef\u00fchl zu reden, schmilzt das Herz", "tokens": ["Ge\u00b7ruht", "sie", "mit", "Ge\u00b7f\u00fchl", "zu", "re\u00b7den", ",", "schmilzt", "das", "Herz"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Horchenden dahin, umnebelt wird der Sinn,", "tokens": ["Dem", "Hor\u00b7chen\u00b7den", "da\u00b7hin", ",", "um\u00b7ne\u00b7belt", "wird", "der", "Sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "$,", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und jedes Mannesknie sinkt schleunigst erdenw\u00e4rts.", "tokens": ["Und", "je\u00b7des", "Man\u00b7nes\u00b7knie", "sinkt", "schleu\u00b7nigst", "er\u00b7den\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth geruhte gestern nacht", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "ge\u00b7ruh\u00b7te", "ge\u00b7stern", "nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Huldreich zu mir zu sein. Nacht wars und wir allein.", "tokens": ["Huld\u00b7reich", "zu", "mir", "zu", "sein", ".", "Nacht", "wars", "und", "wir", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PTKZU", "VAINF", "$.", "NN", "VAFIN", "KON", "PPER", "ADV", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und gro\u00df ist ihre hocherhabne Busenpracht.", "tokens": ["Und", "gro\u00df", "ist", "ih\u00b7re", "ho\u00b7cher\u00b7hab\u00b7ne", "Bu\u00b7sen\u00b7pracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Sie trug aus schwerem Samt ein malvenfarbnes Kleid,", "tokens": ["Sie", "trug", "aus", "schwe\u00b7rem", "Samt", "ein", "mal\u00b7ven\u00b7farb\u00b7nes", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im Mondenlichte war der Schimmer wunderbar.", "tokens": ["Im", "Mon\u00b7den\u00b7lich\u00b7te", "war", "der", "Schim\u00b7mer", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Um Hals und Kn\u00f6chel wand sich k\u00f6niglich Geschmeid.", "tokens": ["Um", "Hals", "und", "Kn\u00f6\u00b7chel", "wand", "sich", "k\u00f6\u00b7nig\u00b7lich", "Ge\u00b7schmeid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "VVFIN", "PRF", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth nahm mich an ihre Hand", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "nahm", "mich", "an", "ih\u00b7re", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fchrte mich geschwind, als w\u00e4re ich ein Kind,", "tokens": ["Und", "f\u00fchr\u00b7te", "mich", "ge\u00b7schwind", ",", "als", "w\u00e4\u00b7re", "ich", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$,", "KOKOM", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zum Ende der Allee, wo eine Laube stand.", "tokens": ["Zum", "En\u00b7de", "der", "Al\u00b7lee", ",", "wo", "ei\u00b7ne", "Lau\u00b7be", "stand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Dort zeigte sie mir mehr, als ihres Busens Schnee.", "tokens": ["Dort", "zeig\u00b7te", "sie", "mir", "mehr", ",", "als", "ih\u00b7res", "Bu\u00b7sens", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich aber sprach: Pardon, wo ist nur mein Lorgnon?", "tokens": ["Ich", "a\u00b7ber", "sprach", ":", "Par\u00b7don", ",", "wo", "ist", "nur", "mein", "Lorg\u00b7non", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$.", "NN", "$,", "PWAV", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gestatten Sie, Madam, da\u00df ich es suchen geh.", "tokens": ["Ge\u00b7stat\u00b7ten", "Sie", ",", "Ma\u00b7dam", ",", "da\u00df", "ich", "es", "su\u00b7chen", "geh."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "abbreviation"], "pos": ["NN", "PPER", "$,", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth schlug wild mich ins Gesicht", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "schlug", "wild", "mich", "ins", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und spuckte in den Sand, dann ist sie fortgerannt,", "tokens": ["Und", "spuck\u00b7te", "in", "den", "Sand", ",", "dann", "ist", "sie", "fort\u00b7ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und heute sah ich sie, doch sie, sie sah mich nicht.", "tokens": ["Und", "heu\u00b7te", "sah", "ich", "sie", ",", "doch", "sie", ",", "sie", "sah", "mich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "$,", "KON", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Mich traf ihr Schlag, mich trifft Verachtung ganz mit Recht.", "tokens": ["Mich", "traf", "ihr", "Schlag", ",", "mich", "trifft", "Ver\u00b7ach\u00b7tung", "ganz", "mit", "Recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist man ein Kavalier, so habe man Manier", "tokens": ["Ist", "man", "ein", "Ka\u00b7va\u00b7lier", ",", "so", "ha\u00b7be", "man", "Ma\u00b7nier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ART", "NN", "$,", "ADV", "VAFIN", "PIS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch contre cour. Und ich betrug mich wirklich schlecht.", "tokens": ["Auch", "con\u00b7tre", "cour", ".", "Und", "ich", "be\u00b7trug", "mich", "wirk\u00b7lich", "schlecht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "$.", "KON", "PPER", "VVFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Madam, ich sag es frei:", "tokens": ["Ma\u00b7dam", ",", "ich", "sag", "es", "frei", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zufrieden sei ein jeder Mann,", "tokens": ["Zu\u00b7frie\u00b7den", "sei", "ein", "je\u00b7der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn er, und wers auch immer sei,", "tokens": ["Wenn", "er", ",", "und", "wers", "auch", "im\u00b7mer", "sei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KON", "PWS", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Au point d'amour was f\u00fchlen kann.", "tokens": ["Au", "po\u00b7int", "d'\u00b7a\u00b7mour", "was", "f\u00fch\u00b7len", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PIS", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Bald ist die Zeit der Kraft vorbei,", "tokens": ["Bald", "ist", "die", "Zeit", "der", "Kraft", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und dann", "tokens": ["Und", "dann"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Sieht jede Blume ihn mit Vorwurfsaugen an,", "tokens": ["Sieht", "je\u00b7de", "Blu\u00b7me", "ihn", "mit", "Vor\u00b7wurf\u00b7sau\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Herz ist ein Gef\u00e4\u00df voll eklem Sauerbrei", "tokens": ["Sein", "Herz", "ist", "ein", "Ge\u00b7f\u00e4\u00df", "voll", "ek\u00b7lem", "Sau\u00b7er\u00b7brei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Aus Reu und Mi\u00dfgunst, keuchend im Gespann", "tokens": ["Aus", "Reu", "und", "Mi\u00df\u00b7gunst", ",", "keu\u00b7chend", "im", "Ge\u00b7spann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NN", "$,", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Des Alters schleppt er die verpa\u00dften", "tokens": ["Des", "Al\u00b7ters", "schleppt", "er", "die", "ver\u00b7pa\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Gelegenheiten und wie ungeheure Lasten", "tokens": ["Ge\u00b7le\u00b7gen\u00b7hei\u00b7ten", "und", "wie", "un\u00b7ge\u00b7heu\u00b7re", "Las\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PWAV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Durch ein erinnerungsleeres Einerlei.", "tokens": ["Durch", "ein", "e\u00b7rin\u00b7ne\u00b7rungs\u00b7lee\u00b7res", "Ei\u00b7ner\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.13": {"text": "Wer aber nicht zu jenen Gottverha\u00dften", "tokens": ["Wer", "a\u00b7ber", "nicht", "zu", "je\u00b7nen", "Gott\u00b7ver\u00b7ha\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PTKNEG", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Geh\u00f6rt, in denen Wasser rann", "tokens": ["Ge\u00b7h\u00f6rt", ",", "in", "de\u00b7nen", "Was\u00b7ser", "rann"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "APPR", "PRELS", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Statt Blutes, wer sich Lust gewann,", "tokens": ["Statt", "Blu\u00b7tes", ",", "wer", "sich", "Lust", "ge\u00b7wann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PWS", "PRF", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Genie\u00dft im Lebenswinter noch einmal den Mai", "tokens": ["Ge\u00b7nie\u00dft", "im", "Le\u00b7bens\u00b7win\u00b7ter", "noch", "ein\u00b7mal", "den", "Mai"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "NN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Begl\u00fcckter Kraft, wie einen goldgefa\u00dften", "tokens": ["Be\u00b7gl\u00fcck\u00b7ter", "Kraft", ",", "wie", "ei\u00b7nen", "gold\u00b7ge\u00b7fa\u00df\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PWAV", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Demanten: als Erinnerung.", "tokens": ["De\u00b7man\u00b7ten", ":", "als", "E\u00b7rin\u00b7ne\u00b7rung", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "NN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.19": {"text": "So h\u00e4lt den Helden Lorbeer jung.", "tokens": ["So", "h\u00e4lt", "den", "Hel\u00b7den", "Lor\u00b7beer", "jung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Und erst der Tod schl\u00e4gt jenen Spiegelstein entzwei.", "tokens": ["Und", "erst", "der", "Tod", "schl\u00e4gt", "je\u00b7nen", "Spie\u00b7gel\u00b7stein", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "(unter eine Statue der Melancholie)", "tokens": ["(", "un\u00b7ter", "ei\u00b7ne", "Sta\u00b7tue", "der", "Me\u00b7lan\u00b7cho\u00b7lie", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Wagt euch nicht her, L\u00e4rm und gemeine Lust,", "tokens": ["Wagt", "euch", "nicht", "her", ",", "L\u00e4rm", "und", "ge\u00b7mei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Geklimper und Geschrei!", "tokens": ["Ge\u00b7klim\u00b7per", "und", "Ge\u00b7schrei", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hier tr\u00e4umt, umschleiert Angesicht und Brust,", "tokens": ["Hier", "tr\u00e4umt", ",", "um\u00b7schlei\u00b7ert", "An\u00b7ge\u00b7sicht", "und", "Brust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Melancholei.", "tokens": ["Me\u00b7lan\u00b7cho\u00b7lei", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Sie will das Leben nur durch Schleier sehn", "tokens": ["Sie", "will", "das", "Le\u00b7ben", "nur", "durch", "Schlei\u00b7er", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und weit von ihm entfernt;", "tokens": ["Und", "weit", "von", "ihm", "ent\u00b7fernt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Sie kennt die s\u00fc\u00dfe Ruh: in sich zu gehn", "tokens": ["Sie", "kennt", "die", "s\u00fc\u00b7\u00dfe", "Ruh", ":", "in", "sich", "zu", "gehn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$.", "APPR", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und hat der Wehmut gro\u00dfes Gl\u00fcck gelernt.", "tokens": ["Und", "hat", "der", "Weh\u00b7mut", "gro\u00b7\u00dfes", "Gl\u00fcck", "ge\u00b7lernt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ein Spiegel stand vor mir. Als ich darin mich sah:", "tokens": ["Ein", "Spie\u00b7gel", "stand", "vor", "mir", ".", "Als", "ich", "da\u00b7rin", "mich", "sah", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "$.", "KOUS", "PPER", "PAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie ward mir wunderlich, wie \u00e4ngstlich ward mir da.", "tokens": ["Wie", "ward", "mir", "wun\u00b7der\u00b7lich", ",", "wie", "\u00e4ngst\u00b7lich", "ward", "mir", "da", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Du, fragt ich mich, um Gott, Fremdling, wer bist denn du?", "tokens": ["Du", ",", "fragt", "ich", "mich", ",", "um", "Gott", ",", "Fremd\u00b7ling", ",", "wer", "bist", "denn", "du", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "PRF", "$,", "KOUI", "NN", "$,", "NN", "$,", "PWS", "VAFIN", "KON", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was siehst du mich so an? Was nickst du mir so zu?", "tokens": ["Was", "siehst", "du", "mich", "so", "an", "?", "Was", "nickst", "du", "mir", "so", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Jetzt h\u00e4ltst du an den Mund den Zeigefinger dir.", "tokens": ["Jetzt", "h\u00e4ltst", "du", "an", "den", "Mund", "den", "Zei\u00b7ge\u00b7fin\u00b7ger", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Still soll ich sein? Warum? Es ist ja niemand hier.", "tokens": ["Still", "soll", "ich", "sein", "?", "Wa\u00b7rum", "?", "Es", "ist", "ja", "nie\u00b7mand", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPER", "VAINF", "$.", "PWAV", "$.", "PPER", "VAFIN", "ADV", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wir zwei sind hier allein. Es schweigt die stumme Nacht,", "tokens": ["Wir", "zwei", "sind", "hier", "al\u00b7lein", ".", "Es", "schweigt", "die", "stum\u00b7me", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "VAFIN", "ADV", "ADV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "H\u00f6rt sie das Zwiegespr\u00e4ch der Zweie, die hier leise", "tokens": ["H\u00f6rt", "sie", "das", "Zwie\u00b7ge\u00b7spr\u00e4ch", "der", "Zwei\u00b7e", ",", "die", "hier", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "ART", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sich sagen, wie verrucht ihr Leben sie verbracht,", "tokens": ["Sich", "sa\u00b7gen", ",", "wie", "ver\u00b7rucht", "ihr", "Le\u00b7ben", "sie", "ver\u00b7bracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Zu lange t\u00f6richt, ach, und viel zu sp\u00e4te weise.", "tokens": ["Zu", "lan\u00b7ge", "t\u00f6\u00b7richt", ",", "ach", ",", "und", "viel", "zu", "sp\u00e4\u00b7te", "wei\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "$,", "ITJ", "$,", "KON", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der andre l\u00e4chelte. Wie tat dies L\u00e4cheln weh!", "tokens": ["Der", "and\u00b7re", "l\u00e4\u00b7chel\u00b7te", ".", "Wie", "tat", "dies", "L\u00e4\u00b7cheln", "weh", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "PWAV", "VVFIN", "PDS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich sah es schon einmal: so, da\u00df ichs immer seh.", "tokens": ["Ich", "sah", "es", "schon", "ein\u00b7mal", ":", "so", ",", "da\u00df", "ichs", "im\u00b7mer", "seh", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$.", "ADV", "$,", "KOUS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Es kam vom Galgen her, daran ein M\u00f6rder hing.", "tokens": ["Es", "kam", "vom", "Gal\u00b7gen", "her", ",", "da\u00b7ran", "ein", "M\u00f6r\u00b7der", "hing", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "PAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die Leiche l\u00e4chelte, da\u00df mir die Lust verging", "tokens": ["Die", "Lei\u00b7che", "l\u00e4\u00b7chel\u00b7te", ",", "da\u00df", "mir", "die", "Lust", "ver\u00b7ging"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Zu l\u00e4cheln wochenlang. Es war so grauenvoll,", "tokens": ["Zu", "l\u00e4\u00b7cheln", "wo\u00b7chen\u00b7lang", ".", "Es", "war", "so", "grau\u00b7en\u00b7voll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADJD", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da\u00df Angst im Herzen mir wie eine Kr\u00f6te schwoll.", "tokens": ["Da\u00df", "Angst", "im", "Her\u00b7zen", "mir", "wie", "ei\u00b7ne", "Kr\u00f6\u00b7te", "schwoll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "PPER", "KOKOM", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und nun erblickte ich dasselbe L\u00e4cheln mir", "tokens": ["Und", "nun", "er\u00b7blick\u00b7te", "ich", "das\u00b7sel\u00b7be", "L\u00e4\u00b7cheln", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PDAT", "NN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Im Spiegel vis-a-vis, bis sich der Mund zum Schreien", "tokens": ["Im", "Spie\u00b7gel", "vis\u00b7a\u00b7vis", ",", "bis", "sich", "der", "Mund", "zum", "Schrei\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NE", "$,", "KOUS", "PRF", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wild auseinanderri\u00df. Ich m\u00f6chte, schrie ich, dir,", "tokens": ["Wild", "aus\u00b7ein\u00b7an\u00b7der\u00b7ri\u00df", ".", "Ich", "m\u00f6ch\u00b7te", ",", "schrie", "ich", ",", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "PPER", "VMFIN", "$,", "VVFIN", "PPER", "$,", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Elendes Hohngesicht, in deine Larve speien.", "tokens": ["E\u00b7len\u00b7des", "Hohn\u00b7ge\u00b7sicht", ",", "in", "dei\u00b7ne", "Lar\u00b7ve", "spei\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.30": {"text": "Der andere schlo\u00df den Mund und starrte vor sich hin.", "tokens": ["Der", "an\u00b7de\u00b7re", "schlo\u00df", "den", "Mund", "und", "starr\u00b7te", "vor", "sich", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Trotz lag auf seiner Stirn, Wollust auf seinem Kinn.", "tokens": ["Trotz", "lag", "auf", "sei\u00b7ner", "Stirn", ",", "Wol\u00b7lust", "auf", "sei\u00b7nem", "Kinn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Er schien mir nicht bereit, der Reue Kreuz zu tragen", "tokens": ["Er", "schien", "mir", "nicht", "be\u00b7reit", ",", "der", "Reu\u00b7e", "Kreuz", "zu", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADJD", "$,", "ART", "NN", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und f\u00fcrderhin der Lust der Welt Valet zu sagen.", "tokens": ["Und", "f\u00fcr\u00b7der\u00b7hin", "der", "Lust", "der", "Welt", "Va\u00b7let", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Doch war in seinem Blick ein Grauen: bald ists aus:", "tokens": ["Doch", "war", "in", "sei\u00b7nem", "Blick", "ein", "Grau\u00b7en", ":", "bald", "ists", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "$.", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Es sitzt und nagt und pocht der Moderwurm im Haus.", "tokens": ["Es", "sitzt", "und", "nagt", "und", "pocht", "der", "Mo\u00b7der\u00b7wurm", "im", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Mein Spiegelkamerad verfiel und ward ein Greis.", "tokens": ["Mein", "Spie\u00b7gel\u00b7ka\u00b7me\u00b7rad", "ver\u00b7fiel", "und", "ward", "ein", "Greis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Sein Kinn sank auf die Brust, die Augen wurden bl\u00f6de.", "tokens": ["Sein", "Kinn", "sank", "auf", "die", "Brust", ",", "die", "Au\u00b7gen", "wur\u00b7den", "bl\u00f6\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "VAFIN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Ich schlug ins Spiegelglas. Es splitterte wie Eis.", "tokens": ["Ich", "schlug", "ins", "Spie\u00b7gel\u00b7glas", ".", "Es", "split\u00b7ter\u00b7te", "wie", "Eis", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$.", "PPER", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und mich umwinterte des Alters bange \u00d6de.", "tokens": ["Und", "mich", "um\u00b7win\u00b7ter\u00b7te", "des", "Al\u00b7ters", "ban\u00b7ge", "\u00d6\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Gern les ich den Horazius,", "tokens": ["Gern", "les", "ich", "den", "Ho\u00b7ra\u00b7zi\u00b7us", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "ART", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das war ein Kavalier.", "tokens": ["Das", "war", "ein", "Ka\u00b7va\u00b7lier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "An heutigen Karminibus", "tokens": ["An", "heu\u00b7ti\u00b7gen", "Kar\u00b7mi\u00b7ni\u00b7bus"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Find ich nicht viel Pl\u00e4sier.", "tokens": ["Find", "ich", "nicht", "viel", "Pl\u00e4\u00b7sier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PIAT", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Nach R\u00fcb\u00f6l riechen sie, das ranzt,", "tokens": ["Nach", "R\u00fc\u00b7b\u00f6l", "rie\u00b7chen", "sie", ",", "das", "ranzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$,", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wenn die deutsche Muse tanzt,", "tokens": ["Und", "wenn", "die", "deut\u00b7sche", "Mu\u00b7se", "tanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wackelt das Quartier.", "tokens": ["So", "wa\u00b7ckelt", "das", "Quar\u00b7tier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.15": {"line.1": {"text": "Das ist gewi\u00df, und wenn ichs nicht gest\u00fcnde,", "tokens": ["Das", "ist", "ge\u00b7wi\u00df", ",", "und", "wenn", "ichs", "nicht", "ge\u00b7st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$,", "KON", "KOUS", "PIS", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "W\u00e4rs gegen meines Blutes reinen Adel S\u00fcnde:", "tokens": ["W\u00e4rs", "ge\u00b7gen", "mei\u00b7nes", "Blu\u00b7tes", "rei\u00b7nen", "A\u00b7del", "S\u00fcn\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bin kein Heiliger, der sich f\u00fcr Gott verzehrt.", "tokens": ["Ich", "bin", "kein", "Hei\u00b7li\u00b7ger", ",", "der", "sich", "f\u00fcr", "Gott", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich habe ihn auf meine Art verehrt,", "tokens": ["Ich", "ha\u00b7be", "ihn", "auf", "mei\u00b7ne", "Art", "ver\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Als Gott der Liebe, der es selbst erfuhr,", "tokens": ["Als", "Gott", "der", "Lie\u00b7be", ",", "der", "es", "selbst", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df Zeugen Wonne ist, und der voll Gnaden", "tokens": ["Da\u00df", "Zeu\u00b7gen", "Won\u00b7ne", "ist", ",", "und", "der", "voll", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "NN", "VAFIN", "$,", "KON", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Darum jedwede kleine Kreatur", "tokens": ["Da\u00b7rum", "jed\u00b7we\u00b7de", "klei\u00b7ne", "Kre\u00b7a\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mit seiner Lust, zu zeugen, hat beladen.", "tokens": ["Mit", "sei\u00b7ner", "Lust", ",", "zu", "zeu\u00b7gen", ",", "hat", "be\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PTKZU", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mir scheint es gottlos, ohne Lust zu leben.", "tokens": ["Mir", "scheint", "es", "gott\u00b7los", ",", "oh\u00b7ne", "Lust", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUI", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Was so ein gro\u00dfer, guter Herr gegeben,", "tokens": ["Was", "so", "ein", "gro\u00b7\u00dfer", ",", "gu\u00b7ter", "Herr", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "$,", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wirft nur ein schlechter Diener ekel hin.", "tokens": ["Wirft", "nur", "ein", "schlech\u00b7ter", "Die\u00b7ner", "e\u00b7kel", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ich la\u00df mich gern von Blutes Wallen heben,", "tokens": ["Ich", "la\u00df", "mich", "gern", "von", "Blu\u00b7tes", "Wal\u00b7len", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Weil ich Gott treu und gern sein Diener bin.", "tokens": ["Weil", "ich", "Gott", "treu", "und", "gern", "sein", "Die\u00b7ner", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADJD", "KON", "ADV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Wer Gott auf andre Weise dient,", "tokens": ["Wer", "Gott", "auf", "and\u00b7re", "Wei\u00b7se", "dient", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist ganz in Trotz und schief geschient.", "tokens": ["Ist", "ganz", "in", "Trotz", "und", "schief", "ge\u00b7schient", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Pfl\u00fccke die Stunden!", "tokens": ["Pfl\u00fc\u00b7cke", "die", "Stun\u00b7den", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Zum Kranze gewunden", "tokens": ["Zum", "Kran\u00b7ze", "ge\u00b7wun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VAPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Hat sie die Macht,", "tokens": ["Hat", "sie", "die", "Macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Die dich erschuf.", "tokens": ["Die", "dich", "er\u00b7schuf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "Lust ist, o Sterblicher, Last nur den Toren,", "tokens": ["Lust", "ist", ",", "o", "Sterb\u00b7li\u00b7cher", ",", "Last", "nur", "den", "To\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "FM", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Die ihrer Sinne Kompa\u00df verloren,", "tokens": ["Die", "ih\u00b7rer", "Sin\u00b7ne", "Kom\u00b7pa\u00df", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Weisen ists wundervoll leichter Beruf.", "tokens": ["Wei\u00b7sen", "ists", "wun\u00b7der\u00b7voll", "leich\u00b7ter", "Be\u00b7ruf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Carpe diem, \u2013 und sei es bei Nacht.", "tokens": ["Car\u00b7pe", "diem", ",", "\u2013", "und", "sei", "es", "bei", "Nacht", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "$(", "KON", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.19": {"line.1": {"text": "Gestern nacht an meinem Bette", "tokens": ["Ge\u00b7stern", "nacht", "an", "mei\u00b7nem", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "APPR", "PPOSAT", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Stand das grinsende Skelette", "tokens": ["Stand", "das", "grin\u00b7sen\u00b7de", "Ske\u00b7let\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Jenes Mannes mit der Hippe", "tokens": ["Je\u00b7nes", "Man\u00b7nes", "mit", "der", "Hip\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Uhr.", "tokens": ["Und", "der", "Uhr", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "--+", "measure": "anapaest.init"}, "line.5": {"text": "Langsam sprach er ohne Lippe,", "tokens": ["Lang\u00b7sam", "sprach", "er", "oh\u00b7ne", "Lip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ohne Gaumen, ohne Zunge,", "tokens": ["Oh\u00b7ne", "Gau\u00b7men", ",", "oh\u00b7ne", "Zun\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ohne Wangen, ohne Lunge,", "tokens": ["Oh\u00b7ne", "Wan\u00b7gen", ",", "oh\u00b7ne", "Lun\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Knochen, Knochen, Knochen nur:", "tokens": ["Kno\u00b7chen", ",", "Kno\u00b7chen", ",", "Kno\u00b7chen", "nur", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Lieber Graf, ich bin zur Stelle,", "tokens": ["Lie\u00b7ber", "Graf", ",", "ich", "bin", "zur", "Stel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NE", "$,", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Da die Stunde zum Appelle", "tokens": ["Da", "die", "Stun\u00b7de", "zum", "Ap\u00b7pel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Vor dem Generalissimus naht.", "tokens": ["Vor", "dem", "Ge\u00b7ne\u00b7ra\u00b7lis\u00b7si\u00b7mus", "naht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Wenig braucht es Vorbereitung,", "tokens": ["We\u00b7nig", "braucht", "es", "Vor\u00b7be\u00b7rei\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Denn er sieht nicht viel auf Kleidung", "tokens": ["Denn", "er", "sieht", "nicht", "viel", "auf", "Klei\u00b7dung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Und er kennt nur einen Staat:", "tokens": ["Und", "er", "kennt", "nur", "ei\u00b7nen", "Staat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Tugend, die erg\u00f6tzlich helle,", "tokens": ["Tu\u00b7gend", ",", "die", "er\u00b7g\u00f6tz\u00b7lich", "hel\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Engelreine Lichtmontur.", "tokens": ["En\u00b7gel\u00b7rei\u00b7ne", "Licht\u00b7mon\u00b7tur", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Werter Herr, ich bin parat,", "tokens": ["Wer\u00b7ter", "Herr", ",", "ich", "bin", "pa\u00b7rat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VAFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagte ich, ein wenig leise,", "tokens": ["Sag\u00b7te", "ich", ",", "ein", "we\u00b7nig", "lei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "PIS", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend ich zur letzten Reise", "tokens": ["W\u00e4h\u00b7rend", "ich", "zur", "letz\u00b7ten", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ungern in den Schlafrock fuhr.", "tokens": ["Un\u00b7gern", "in", "den", "Schla\u00b7frock", "fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "H\u00f6flich st\u00fctzt er mich beim Gehen,", "tokens": ["H\u00f6f\u00b7lich", "st\u00fctzt", "er", "mich", "beim", "Ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seine d\u00fcrren Knochenzehen", "tokens": ["Sei\u00b7ne", "d\u00fcr\u00b7ren", "Kno\u00b7chen\u00b7ze\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Klapperten auf dem Parkett.", "tokens": ["Klap\u00b7per\u00b7ten", "auf", "dem", "Par\u00b7kett", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.22": {"line.1": {"text": "Manchmal blieb mein F\u00fchrer stehen,", "tokens": ["Manch\u00b7mal", "blieb", "mein", "F\u00fch\u00b7rer", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich ein Bildnis anzusehen,", "tokens": ["Sich", "ein", "Bild\u00b7nis", "an\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kennerierte,", "tokens": ["Ken\u00b7ne\u00b7rier\u00b7te", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Rezensierte:", "tokens": ["Re\u00b7zen\u00b7sier\u00b7te", ":"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "\u00bbhm, nicht \u00fcbel, hm, ganz nett.\u00ab", "tokens": ["\u00bb", "hm", ",", "nicht", "\u00fc\u00b7bel", ",", "hm", ",", "ganz", "nett", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "$,", "PTKNEG", "ADJD", "$,", "NE", "$,", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Gerne h\u00e4tt ich ihn gebeten,", "tokens": ["Ger\u00b7ne", "h\u00e4tt", "ich", "ihn", "ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In die Galerie zu treten,", "tokens": ["In", "die", "Ga\u00b7le\u00b7rie", "zu", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil dort Meisterwerke viel", "tokens": ["Weil", "dort", "Meis\u00b7ter\u00b7wer\u00b7ke", "viel"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Leuchtend zum Verweilen laden,", "tokens": ["Leuch\u00b7tend", "zum", "Ver\u00b7wei\u00b7len", "la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch es dr\u00e4ngten seine Gnaden", "tokens": ["Doch", "es", "dr\u00e4ng\u00b7ten", "sei\u00b7ne", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sehr bestimmt nach anderm Ziel.", "tokens": ["Sehr", "be\u00b7stimmt", "nach", "an\u00b7derm", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Schleppte mich zum Spiegelsaale,", "tokens": ["Schlepp\u00b7te", "mich", "zum", "Spie\u00b7gel\u00b7saa\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo wer wei\u00df wie viele Male", "tokens": ["Wo", "wer", "wei\u00df", "wie", "vie\u00b7le", "Ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PWS", "VVFIN", "KOKOM", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "(auf dem innern Deckel)", "tokens": ["(", "auf", "dem", "in\u00b7nern", "De\u00b7ckel", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Madam! Ich hoffe sehr, da\u00df Sie mich \u00fcberleben", "tokens": ["Ma\u00b7dam", "!", "Ich", "hof\u00b7fe", "sehr", ",", "da\u00df", "Sie", "mich", "\u00fc\u00b7berl\u00b7e\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mir (wohl bald) einmal die letzte Ehre geben.", "tokens": ["Und", "mir", "(", "wohl", "bald", ")", "ein\u00b7mal", "die", "letz\u00b7te", "Eh\u00b7re", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "ADV", "ADV", "$(", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dort, hinterm Weizenfeld, das jetzt in \u00c4hren steht,", "tokens": ["Dort", ",", "hin\u00b7term", "Wei\u00b7zen\u00b7feld", ",", "das", "jetzt", "in", "\u00c4h\u00b7ren", "steht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Seh ich den Schauplatz unsres letzten T\u00eate-\u00e0-T\u00eate.", "tokens": ["Seh", "ich", "den", "Schau\u00b7platz", "uns\u00b7res", "letz\u00b7ten", "T\u00eate\u00b7\u00e0\u00b7T\u00eate", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Ich liege dann im Sarg; ein letzter Veilchenstrau\u00df", "tokens": ["Ich", "lie\u00b7ge", "dann", "im", "Sarg", ";", "ein", "letz\u00b7ter", "Veil\u00b7chen\u00b7strau\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Folgt mir aus Ihrer Hand, und dieses Spiel ist aus.", "tokens": ["Folgt", "mir", "aus", "Ih\u00b7rer", "Hand", ",", "und", "die\u00b7ses", "Spiel", "ist", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "KON", "PDAT", "NN", "VAFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie werden weinen. Ach, ich kenn Ihr gutes Herz,", "tokens": ["Sie", "wer\u00b7den", "wei\u00b7nen", ".", "Ach", ",", "ich", "kenn", "Ihr", "gu\u00b7tes", "Herz", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVINF", "$.", "ITJ", "$,", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Echt, wie Ihr Lieben, ist gewi\u00df Ihr Witwenschmerz,", "tokens": ["Echt", ",", "wie", "Ihr", "Lie\u00b7ben", ",", "ist", "ge\u00b7wi\u00df", "Ihr", "Wit\u00b7wensc\u00b7hmerz", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "ADJA", "$,", "VAFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und vielmals schreiten Sie zum schw\u00e4rzlichen Oval", "tokens": ["Und", "viel\u00b7mals", "schrei\u00b7ten", "Sie", "zum", "schw\u00e4rz\u00b7li\u00b7chen", "O\u00b7val"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Eibenb\u00e4ume in Graf Thr\u00fcmmels Schattental.", "tokens": ["Der", "Ei\u00b7ben\u00b7b\u00e4u\u00b7me", "in", "Graf", "Thr\u00fcm\u00b7mels", "Schat\u00b7ten\u00b7tal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "NN", "$."], "meter": "-+-+--++-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Dann aber, bitt ich sehr, Madam, solln Sie nicht weinen.", "tokens": ["Dann", "a\u00b7ber", ",", "bitt", "ich", "sehr", ",", "Ma\u00b7dam", ",", "solln", "Sie", "nicht", "wei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "VVFIN", "PPER", "ADV", "$,", "NN", "$,", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Sonne wird vergn\u00fcgt der goldenen Lilie scheinen,", "tokens": ["Die", "Son\u00b7ne", "wird", "ver\u00b7gn\u00fcgt", "der", "gol\u00b7de\u00b7nen", "Li\u00b7lie", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Die unsre T\u00e4nzerin in ihren H\u00e4nden h\u00e4lt,", "tokens": ["Die", "uns\u00b7re", "T\u00e4n\u00b7ze\u00b7rin", "in", "ih\u00b7ren", "H\u00e4n\u00b7den", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die unserm Schlummerplatz zur W\u00e4chtrin ward bestellt", "tokens": ["Die", "un\u00b7serm", "Schlum\u00b7mer\u00b7platz", "zur", "W\u00e4cht\u00b7rin", "ward", "be\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Durch eines Meisters Hand, der gern das Leben schm\u00fcckte", "tokens": ["Durch", "ei\u00b7nes", "Meis\u00b7ters", "Hand", ",", "der", "gern", "das", "Le\u00b7ben", "schm\u00fcck\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und dem sogar der Schmuck des Totenplatzes gl\u00fcckte.", "tokens": ["Und", "dem", "so\u00b7gar", "der", "Schmuck", "des", "To\u00b7ten\u00b7plat\u00b7zes", "gl\u00fcck\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wo sonst das Christenkreuz eckige Schatten legt,", "tokens": ["Wo", "sonst", "das", "Chris\u00b7ten\u00b7kreuz", "ec\u00b7ki\u00b7ge", "Schat\u00b7ten", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.19": {"text": "Hat eine Grazie er zum sch\u00f6nsten Tanz bewegt.", "tokens": ["Hat", "ei\u00b7ne", "Gra\u00b7zie", "er", "zum", "sch\u00f6ns\u00b7ten", "Tanz", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Selbst \u00fcber Gr\u00e4bern tanzt das Leben, stets am\u00f6n:", "tokens": ["Selbst", "\u00fc\u00b7ber", "Gr\u00e4\u00b7bern", "tanzt", "das", "Le\u00b7ben", ",", "stets", "a\u00b7m\u00f6n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein junges M\u00e4dchen ists, verliebt, gelenk und sch\u00f6n.", "tokens": ["Ein", "jun\u00b7ges", "M\u00e4d\u00b7chen", "ists", ",", "ver\u00b7liebt", ",", "ge\u00b7lenk", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "VVPP", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Betrachten Sie es wohl, und denken Sie dabei,", "tokens": ["Be\u00b7trach\u00b7ten", "Sie", "es", "wohl", ",", "und", "den\u00b7ken", "Sie", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "$,", "KON", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wie angenehm die Ruh nach langem Tanze sei", "tokens": ["Wie", "an\u00b7ge\u00b7nehm", "die", "Ruh", "nach", "lan\u00b7gem", "Tan\u00b7ze", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "F\u00fcr einen alten Mann, der manchen Pas gesprungen.", "tokens": ["F\u00fcr", "ei\u00b7nen", "al\u00b7ten", "Mann", ",", "der", "man\u00b7chen", "Pas", "ge\u00b7sprun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Gern, glauben Sies, Madam, lie\u00df er den Platz den Jungen.", "tokens": ["Gern", ",", "glau\u00b7ben", "Sies", ",", "Ma\u00b7dam", ",", "lie\u00df", "er", "den", "Platz", "den", "Jun\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PIS", "$,", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Nur da\u00df er Sie, mein Herz, verlassen mu\u00dfte, war", "tokens": ["Nur", "da\u00df", "er", "Sie", ",", "mein", "Herz", ",", "ver\u00b7las\u00b7sen", "mu\u00df\u00b7te", ",", "war"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "KOUS", "PPER", "PPER", "$,", "PPOSAT", "NN", "$,", "VVINF", "VMFIN", "$,", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ihm bitter weh ... Mein Gott, nun wein ich selber gar.", "tokens": ["Ihm", "bit\u00b7ter", "weh", "...", "Mein", "Gott", ",", "nun", "wein", "ich", "sel\u00b7ber", "gar", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKVZ", "$(", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ich liebe, liebe dich. Ich will nicht von dir gehn.", "tokens": ["Ich", "lie\u00b7be", ",", "lie\u00b7be", "dich", ".", "Ich", "will", "nicht", "von", "dir", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "PTKNEG", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und, wenn des Himmels Tore vor mir offen st\u00fcnden,", "tokens": ["Und", ",", "wenn", "des", "Him\u00b7mels", "To\u00b7re", "vor", "mir", "of\u00b7fen", "st\u00fcn\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "NE", "APPR", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ich will, will nicht zu Gott. In allen meinen S\u00fcnden,", "tokens": ["Ich", "will", ",", "will", "nicht", "zu", "Gott", ".", "In", "al\u00b7len", "mei\u00b7nen", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VMFIN", "PTKNEG", "APPR", "NN", "$.", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Krank, alt und schwach will ich an deiner Seite stehn.", "tokens": ["Krank", ",", "alt", "und", "schwach", "will", "ich", "an", "dei\u00b7ner", "Sei\u00b7te", "stehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "ADJD", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Grau wird es um mich her, doch hab ich dich, mein Licht.", "tokens": ["Grau", "wird", "es", "um", "mich", "her", ",", "doch", "hab", "ich", "dich", ",", "mein", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "PRF", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ich leide, ich bin m\u00fcd. Doch sterben will ich nicht.", "tokens": ["Ich", "lei\u00b7de", ",", "ich", "bin", "m\u00fcd", ".", "Doch", "ster\u00b7ben", "will", "ich", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "$.", "KON", "VVINF", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Nun, nun, nicht so, mein Herz. Was sein mu\u00df, das mu\u00df sein.", "tokens": ["Nun", ",", "nun", ",", "nicht", "so", ",", "mein", "Herz", ".", "Was", "sein", "mu\u00df", ",", "das", "mu\u00df", "sein", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "PTKNEG", "ADV", "$,", "PPOSAT", "NN", "$.", "PWS", "VAINF", "VMFIN", "$,", "PDS", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die T\u00e4nzerin winkt und l\u00e4dt zum letzten Tanz mich ein.", "tokens": ["Die", "T\u00e4n\u00b7ze\u00b7rin", "winkt", "und", "l\u00e4dt", "zum", "letz\u00b7ten", "Tanz", "mich", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ADJD", "APPRART", "ADJA", "NN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie m\u00fcssen mich, Madam, Sie m\u00fcssen mich ihr lassen", "tokens": ["Sie", "m\u00fcs\u00b7sen", "mich", ",", "Ma\u00b7dam", ",", "Sie", "m\u00fcs\u00b7sen", "mich", "ihr", "las\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "$,", "NN", "$,", "PPER", "VMFIN", "PPER", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und m\u00fcssen sich ein Herz zum letzten Schmerze fassen,", "tokens": ["Und", "m\u00fcs\u00b7sen", "sich", "ein", "Herz", "zum", "letz\u00b7ten", "Schmer\u00b7ze", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Ihnen von mir kommt, von mir, den nichts so qu\u00e4lt,", "tokens": ["Der", "Ih\u00b7nen", "von", "mir", "kommt", ",", "von", "mir", ",", "den", "nichts", "so", "qu\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVFIN", "$,", "APPR", "PPER", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als was er gegen Sie in Wirrheit hat gefehlt.", "tokens": ["Als", "was", "er", "ge\u00b7gen", "Sie", "in", "Wirr\u00b7heit", "hat", "ge\u00b7fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "PPER", "APPR", "PPER", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verzeih, verzeihe mir! Ich wei\u00df, ich habe dir", "tokens": ["Ver\u00b7zeih", ",", "ver\u00b7zei\u00b7he", "mir", "!", "Ich", "wei\u00df", ",", "ich", "ha\u00b7be", "dir"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Unendlich weh getan. Doch weher tat ich mir.", "tokens": ["Un\u00b7end\u00b7lich", "weh", "ge\u00b7tan", ".", "Doch", "we\u00b7her", "tat", "ich", "mir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVPP", "$.", "KON", "ADJD", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du stirbst vielleicht in Gott. Ich fahre gottlos hin,", "tokens": ["Du", "stirbst", "viel\u00b7leicht", "in", "Gott", ".", "Ich", "fah\u00b7re", "gott\u00b7los", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Weil ich ein Sohn der Qual und ohne Z\u00fcgel bin,", "tokens": ["Weil", "ich", "ein", "Sohn", "der", "Qual", "und", "oh\u00b7ne", "Z\u00fc\u00b7gel", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "KON", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein wildes Tier, vom Sporn des Teufels angehetzt,", "tokens": ["Ein", "wil\u00b7des", "Tier", ",", "vom", "Sporn", "des", "Teu\u00b7fels", "an\u00b7ge\u00b7hetzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gequ\u00e4lt zu qu\u00e4len, \u2013 ach, wie ist mein Herz zerfetzt", "tokens": ["Ge\u00b7qu\u00e4lt", "zu", "qu\u00e4\u00b7len", ",", "\u2013", "ach", ",", "wie", "ist", "mein", "Herz", "zer\u00b7fetzt"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "PTKZU", "VVINF", "$,", "$(", "XY", "$,", "PWAV", "VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Von Wut und Gier und Angst. H\u00e4tt ich nicht dich gehabt,", "tokens": ["Von", "Wut", "und", "Gier", "und", "Angst", ".", "H\u00e4tt", "ich", "nicht", "dich", "ge\u00b7habt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$.", "VVFIN", "PPER", "PTKNEG", "PPER", "VAPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die immer wieder mich mit Licht und Trost begabt,", "tokens": ["Die", "im\u00b7mer", "wie\u00b7der", "mich", "mit", "Licht", "und", "Trost", "be\u00b7gabt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PPER", "APPR", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ich h\u00e4tte l\u00e4ngst mich selbst aus diesem Buch gestrichen,", "tokens": ["Ich", "h\u00e4t\u00b7te", "l\u00e4ngst", "mich", "selbst", "aus", "die\u00b7sem", "Buch", "ge\u00b7stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "ADV", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "In dem ich immer nur als Unheilsmaske stand,", "tokens": ["In", "dem", "ich", "im\u00b7mer", "nur", "als", "Un\u00b7heils\u00b7mas\u00b7ke", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Stand ich auch manchmal hoch. Erst als dein Herz ich fand,", "tokens": ["Stand", "ich", "auch", "manch\u00b7mal", "hoch", ".", "Erst", "als", "dein", "Herz", "ich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "$.", "ADV", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sind jener Nebel schwerste grau von mir gewichen.", "tokens": ["Sind", "je\u00b7ner", "Ne\u00b7bel", "schwers\u00b7te", "grau", "von", "mir", "ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "VVFIN", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Ich sch\u00e4me mich. Par Dieu! So schreibt kein Mann von Adel.", "tokens": ["Ich", "sch\u00e4\u00b7me", "mich", ".", "Par", "Di\u00b7eu", "!", "So", "schreibt", "kein", "Mann", "von", "A\u00b7del", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "NE", "NE", "$.", "ADV", "VVFIN", "PIAT", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gott, der Graf Thr\u00fcmmel schuf, verdient drum keinen Tadel,", "tokens": ["Gott", ",", "der", "Graf", "Thr\u00fcm\u00b7mel", "schuf", ",", "ver\u00b7dient", "drum", "kei\u00b7nen", "Ta\u00b7del", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "NN", "VVFIN", "$,", "VVFIN", "PAV", "PIAT", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und, was ich selbst mit mir, vielleicht verkehrt, begann,", "tokens": ["Und", ",", "was", "ich", "selbst", "mit", "mir", ",", "viel\u00b7leicht", "ver\u00b7kehrt", ",", "be\u00b7gann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "ADV", "APPR", "PPER", "$,", "ADV", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich tats auf meinen Kopf und als ein Edelmann.", "tokens": ["Ich", "tats", "auf", "mei\u00b7nen", "Kopf", "und", "als", "ein", "E\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der P\u00f6bel mag sich selbst ziehn an den langen Ohren,", "tokens": ["Der", "P\u00f6\u00b7bel", "mag", "sich", "selbst", "ziehn", "an", "den", "lan\u00b7gen", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "VVINF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich respektiere mich und bleibe wohlgeboren.", "tokens": ["Ich", "res\u00b7pek\u00b7tie\u00b7re", "mich", "und", "blei\u00b7be", "wohl\u00b7ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bereuen ist gemein. Tugend f\u00fcrs Publikum.", "tokens": ["Be\u00b7reu\u00b7en", "ist", "ge\u00b7mein", ".", "Tu\u00b7gend", "f\u00fcrs", "Pub\u00b7li\u00b7kum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$.", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Der Thr\u00fcmmel Wappenwort hei\u00dft stolz: Dreh dich nicht um!", "tokens": ["Der", "Thr\u00fcm\u00b7mel", "Wap\u00b7pen\u00b7wort", "hei\u00dft", "stolz", ":", "Dreh", "dich", "nicht", "um", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "$.", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}}, "stanza.28": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth ist, wie ein jeder wei\u00df,", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "ist", ",", "wie", "ein", "je\u00b7der", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "PWAV", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sch\u00f6n, stolz und voller Witz, bei ihrer Augen Blitz", "tokens": ["Sch\u00f6n", ",", "stolz", "und", "vol\u00b7ler", "Witz", ",", "bei", "ih\u00b7rer", "Au\u00b7gen", "Blitz"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADJD", "KON", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird es den Pagen, wirds den Exzellenzen hei\u00df.", "tokens": ["Wird", "es", "den", "Pa\u00b7gen", ",", "wirds", "den", "Ex\u00b7zel\u00b7len\u00b7zen", "hei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Geruht sie mit Gef\u00fchl zu reden, schmilzt das Herz", "tokens": ["Ge\u00b7ruht", "sie", "mit", "Ge\u00b7f\u00fchl", "zu", "re\u00b7den", ",", "schmilzt", "das", "Herz"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Horchenden dahin, umnebelt wird der Sinn,", "tokens": ["Dem", "Hor\u00b7chen\u00b7den", "da\u00b7hin", ",", "um\u00b7ne\u00b7belt", "wird", "der", "Sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "$,", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und jedes Mannesknie sinkt schleunigst erdenw\u00e4rts.", "tokens": ["Und", "je\u00b7des", "Man\u00b7nes\u00b7knie", "sinkt", "schleu\u00b7nigst", "er\u00b7den\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.30": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth geruhte gestern nacht", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "ge\u00b7ruh\u00b7te", "ge\u00b7stern", "nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Huldreich zu mir zu sein. Nacht wars und wir allein.", "tokens": ["Huld\u00b7reich", "zu", "mir", "zu", "sein", ".", "Nacht", "wars", "und", "wir", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PTKZU", "VAINF", "$.", "NN", "VAFIN", "KON", "PPER", "ADV", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und gro\u00df ist ihre hocherhabne Busenpracht.", "tokens": ["Und", "gro\u00df", "ist", "ih\u00b7re", "ho\u00b7cher\u00b7hab\u00b7ne", "Bu\u00b7sen\u00b7pracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Sie trug aus schwerem Samt ein malvenfarbnes Kleid,", "tokens": ["Sie", "trug", "aus", "schwe\u00b7rem", "Samt", "ein", "mal\u00b7ven\u00b7farb\u00b7nes", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im Mondenlichte war der Schimmer wunderbar.", "tokens": ["Im", "Mon\u00b7den\u00b7lich\u00b7te", "war", "der", "Schim\u00b7mer", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Um Hals und Kn\u00f6chel wand sich k\u00f6niglich Geschmeid.", "tokens": ["Um", "Hals", "und", "Kn\u00f6\u00b7chel", "wand", "sich", "k\u00f6\u00b7nig\u00b7lich", "Ge\u00b7schmeid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "VVFIN", "PRF", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth nahm mich an ihre Hand", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "nahm", "mich", "an", "ih\u00b7re", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und f\u00fchrte mich geschwind, als w\u00e4re ich ein Kind,", "tokens": ["Und", "f\u00fchr\u00b7te", "mich", "ge\u00b7schwind", ",", "als", "w\u00e4\u00b7re", "ich", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$,", "KOKOM", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zum Ende der Allee, wo eine Laube stand.", "tokens": ["Zum", "En\u00b7de", "der", "Al\u00b7lee", ",", "wo", "ei\u00b7ne", "Lau\u00b7be", "stand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Dort zeigte sie mir mehr, als ihres Busens Schnee.", "tokens": ["Dort", "zeig\u00b7te", "sie", "mir", "mehr", ",", "als", "ih\u00b7res", "Bu\u00b7sens", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich aber sprach: Pardon, wo ist nur mein Lorgnon?", "tokens": ["Ich", "a\u00b7ber", "sprach", ":", "Par\u00b7don", ",", "wo", "ist", "nur", "mein", "Lorg\u00b7non", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$.", "NN", "$,", "PWAV", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gestatten Sie, Madam, da\u00df ich es suchen geh.", "tokens": ["Ge\u00b7stat\u00b7ten", "Sie", ",", "Ma\u00b7dam", ",", "da\u00df", "ich", "es", "su\u00b7chen", "geh."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "abbreviation"], "pos": ["NN", "PPER", "$,", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Die Gr\u00e4fin Wackebarth schlug wild mich ins Gesicht", "tokens": ["Die", "Gr\u00e4\u00b7fin", "Wac\u00b7keb\u00b7arth", "schlug", "wild", "mich", "ins", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und spuckte in den Sand, dann ist sie fortgerannt,", "tokens": ["Und", "spuck\u00b7te", "in", "den", "Sand", ",", "dann", "ist", "sie", "fort\u00b7ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und heute sah ich sie, doch sie, sie sah mich nicht.", "tokens": ["Und", "heu\u00b7te", "sah", "ich", "sie", ",", "doch", "sie", ",", "sie", "sah", "mich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "$,", "KON", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Mich traf ihr Schlag, mich trifft Verachtung ganz mit Recht.", "tokens": ["Mich", "traf", "ihr", "Schlag", ",", "mich", "trifft", "Ver\u00b7ach\u00b7tung", "ganz", "mit", "Recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist man ein Kavalier, so habe man Manier", "tokens": ["Ist", "man", "ein", "Ka\u00b7va\u00b7lier", ",", "so", "ha\u00b7be", "man", "Ma\u00b7nier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ART", "NN", "$,", "ADV", "VAFIN", "PIS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch contre cour. Und ich betrug mich wirklich schlecht.", "tokens": ["Auch", "con\u00b7tre", "cour", ".", "Und", "ich", "be\u00b7trug", "mich", "wirk\u00b7lich", "schlecht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "$.", "KON", "PPER", "VVFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Madam, ich sag es frei:", "tokens": ["Ma\u00b7dam", ",", "ich", "sag", "es", "frei", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zufrieden sei ein jeder Mann,", "tokens": ["Zu\u00b7frie\u00b7den", "sei", "ein", "je\u00b7der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn er, und wers auch immer sei,", "tokens": ["Wenn", "er", ",", "und", "wers", "auch", "im\u00b7mer", "sei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KON", "PWS", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Au point d'amour was f\u00fchlen kann.", "tokens": ["Au", "po\u00b7int", "d'\u00b7a\u00b7mour", "was", "f\u00fch\u00b7len", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PIS", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Bald ist die Zeit der Kraft vorbei,", "tokens": ["Bald", "ist", "die", "Zeit", "der", "Kraft", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und dann", "tokens": ["Und", "dann"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Sieht jede Blume ihn mit Vorwurfsaugen an,", "tokens": ["Sieht", "je\u00b7de", "Blu\u00b7me", "ihn", "mit", "Vor\u00b7wurf\u00b7sau\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Herz ist ein Gef\u00e4\u00df voll eklem Sauerbrei", "tokens": ["Sein", "Herz", "ist", "ein", "Ge\u00b7f\u00e4\u00df", "voll", "ek\u00b7lem", "Sau\u00b7er\u00b7brei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Aus Reu und Mi\u00dfgunst, keuchend im Gespann", "tokens": ["Aus", "Reu", "und", "Mi\u00df\u00b7gunst", ",", "keu\u00b7chend", "im", "Ge\u00b7spann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NN", "$,", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Des Alters schleppt er die verpa\u00dften", "tokens": ["Des", "Al\u00b7ters", "schleppt", "er", "die", "ver\u00b7pa\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Gelegenheiten und wie ungeheure Lasten", "tokens": ["Ge\u00b7le\u00b7gen\u00b7hei\u00b7ten", "und", "wie", "un\u00b7ge\u00b7heu\u00b7re", "Las\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PWAV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Durch ein erinnerungsleeres Einerlei.", "tokens": ["Durch", "ein", "e\u00b7rin\u00b7ne\u00b7rungs\u00b7lee\u00b7res", "Ei\u00b7ner\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.13": {"text": "Wer aber nicht zu jenen Gottverha\u00dften", "tokens": ["Wer", "a\u00b7ber", "nicht", "zu", "je\u00b7nen", "Gott\u00b7ver\u00b7ha\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PTKNEG", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Geh\u00f6rt, in denen Wasser rann", "tokens": ["Ge\u00b7h\u00f6rt", ",", "in", "de\u00b7nen", "Was\u00b7ser", "rann"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "APPR", "PRELS", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Statt Blutes, wer sich Lust gewann,", "tokens": ["Statt", "Blu\u00b7tes", ",", "wer", "sich", "Lust", "ge\u00b7wann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PWS", "PRF", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Genie\u00dft im Lebenswinter noch einmal den Mai", "tokens": ["Ge\u00b7nie\u00dft", "im", "Le\u00b7bens\u00b7win\u00b7ter", "noch", "ein\u00b7mal", "den", "Mai"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "NN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Begl\u00fcckter Kraft, wie einen goldgefa\u00dften", "tokens": ["Be\u00b7gl\u00fcck\u00b7ter", "Kraft", ",", "wie", "ei\u00b7nen", "gold\u00b7ge\u00b7fa\u00df\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PWAV", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Demanten: als Erinnerung.", "tokens": ["De\u00b7man\u00b7ten", ":", "als", "E\u00b7rin\u00b7ne\u00b7rung", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "NN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.19": {"text": "So h\u00e4lt den Helden Lorbeer jung.", "tokens": ["So", "h\u00e4lt", "den", "Hel\u00b7den", "Lor\u00b7beer", "jung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Und erst der Tod schl\u00e4gt jenen Spiegelstein entzwei.", "tokens": ["Und", "erst", "der", "Tod", "schl\u00e4gt", "je\u00b7nen", "Spie\u00b7gel\u00b7stein", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "(unter eine Statue der Melancholie)", "tokens": ["(", "un\u00b7ter", "ei\u00b7ne", "Sta\u00b7tue", "der", "Me\u00b7lan\u00b7cho\u00b7lie", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Wagt euch nicht her, L\u00e4rm und gemeine Lust,", "tokens": ["Wagt", "euch", "nicht", "her", ",", "L\u00e4rm", "und", "ge\u00b7mei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Geklimper und Geschrei!", "tokens": ["Ge\u00b7klim\u00b7per", "und", "Ge\u00b7schrei", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hier tr\u00e4umt, umschleiert Angesicht und Brust,", "tokens": ["Hier", "tr\u00e4umt", ",", "um\u00b7schlei\u00b7ert", "An\u00b7ge\u00b7sicht", "und", "Brust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Melancholei.", "tokens": ["Me\u00b7lan\u00b7cho\u00b7lei", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Sie will das Leben nur durch Schleier sehn", "tokens": ["Sie", "will", "das", "Le\u00b7ben", "nur", "durch", "Schlei\u00b7er", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und weit von ihm entfernt;", "tokens": ["Und", "weit", "von", "ihm", "ent\u00b7fernt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Sie kennt die s\u00fc\u00dfe Ruh: in sich zu gehn", "tokens": ["Sie", "kennt", "die", "s\u00fc\u00b7\u00dfe", "Ruh", ":", "in", "sich", "zu", "gehn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$.", "APPR", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und hat der Wehmut gro\u00dfes Gl\u00fcck gelernt.", "tokens": ["Und", "hat", "der", "Weh\u00b7mut", "gro\u00b7\u00dfes", "Gl\u00fcck", "ge\u00b7lernt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ein Spiegel stand vor mir. Als ich darin mich sah:", "tokens": ["Ein", "Spie\u00b7gel", "stand", "vor", "mir", ".", "Als", "ich", "da\u00b7rin", "mich", "sah", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "$.", "KOUS", "PPER", "PAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie ward mir wunderlich, wie \u00e4ngstlich ward mir da.", "tokens": ["Wie", "ward", "mir", "wun\u00b7der\u00b7lich", ",", "wie", "\u00e4ngst\u00b7lich", "ward", "mir", "da", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Du, fragt ich mich, um Gott, Fremdling, wer bist denn du?", "tokens": ["Du", ",", "fragt", "ich", "mich", ",", "um", "Gott", ",", "Fremd\u00b7ling", ",", "wer", "bist", "denn", "du", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "PRF", "$,", "KOUI", "NN", "$,", "NN", "$,", "PWS", "VAFIN", "KON", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was siehst du mich so an? Was nickst du mir so zu?", "tokens": ["Was", "siehst", "du", "mich", "so", "an", "?", "Was", "nickst", "du", "mir", "so", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Jetzt h\u00e4ltst du an den Mund den Zeigefinger dir.", "tokens": ["Jetzt", "h\u00e4ltst", "du", "an", "den", "Mund", "den", "Zei\u00b7ge\u00b7fin\u00b7ger", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Still soll ich sein? Warum? Es ist ja niemand hier.", "tokens": ["Still", "soll", "ich", "sein", "?", "Wa\u00b7rum", "?", "Es", "ist", "ja", "nie\u00b7mand", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPER", "VAINF", "$.", "PWAV", "$.", "PPER", "VAFIN", "ADV", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wir zwei sind hier allein. Es schweigt die stumme Nacht,", "tokens": ["Wir", "zwei", "sind", "hier", "al\u00b7lein", ".", "Es", "schweigt", "die", "stum\u00b7me", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "VAFIN", "ADV", "ADV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "H\u00f6rt sie das Zwiegespr\u00e4ch der Zweie, die hier leise", "tokens": ["H\u00f6rt", "sie", "das", "Zwie\u00b7ge\u00b7spr\u00e4ch", "der", "Zwei\u00b7e", ",", "die", "hier", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "ART", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sich sagen, wie verrucht ihr Leben sie verbracht,", "tokens": ["Sich", "sa\u00b7gen", ",", "wie", "ver\u00b7rucht", "ihr", "Le\u00b7ben", "sie", "ver\u00b7bracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Zu lange t\u00f6richt, ach, und viel zu sp\u00e4te weise.", "tokens": ["Zu", "lan\u00b7ge", "t\u00f6\u00b7richt", ",", "ach", ",", "und", "viel", "zu", "sp\u00e4\u00b7te", "wei\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "$,", "ITJ", "$,", "KON", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der andre l\u00e4chelte. Wie tat dies L\u00e4cheln weh!", "tokens": ["Der", "and\u00b7re", "l\u00e4\u00b7chel\u00b7te", ".", "Wie", "tat", "dies", "L\u00e4\u00b7cheln", "weh", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "PWAV", "VVFIN", "PDS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich sah es schon einmal: so, da\u00df ichs immer seh.", "tokens": ["Ich", "sah", "es", "schon", "ein\u00b7mal", ":", "so", ",", "da\u00df", "ichs", "im\u00b7mer", "seh", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$.", "ADV", "$,", "KOUS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Es kam vom Galgen her, daran ein M\u00f6rder hing.", "tokens": ["Es", "kam", "vom", "Gal\u00b7gen", "her", ",", "da\u00b7ran", "ein", "M\u00f6r\u00b7der", "hing", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "PAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die Leiche l\u00e4chelte, da\u00df mir die Lust verging", "tokens": ["Die", "Lei\u00b7che", "l\u00e4\u00b7chel\u00b7te", ",", "da\u00df", "mir", "die", "Lust", "ver\u00b7ging"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Zu l\u00e4cheln wochenlang. Es war so grauenvoll,", "tokens": ["Zu", "l\u00e4\u00b7cheln", "wo\u00b7chen\u00b7lang", ".", "Es", "war", "so", "grau\u00b7en\u00b7voll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADJD", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da\u00df Angst im Herzen mir wie eine Kr\u00f6te schwoll.", "tokens": ["Da\u00df", "Angst", "im", "Her\u00b7zen", "mir", "wie", "ei\u00b7ne", "Kr\u00f6\u00b7te", "schwoll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "PPER", "KOKOM", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und nun erblickte ich dasselbe L\u00e4cheln mir", "tokens": ["Und", "nun", "er\u00b7blick\u00b7te", "ich", "das\u00b7sel\u00b7be", "L\u00e4\u00b7cheln", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PDAT", "NN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Im Spiegel vis-a-vis, bis sich der Mund zum Schreien", "tokens": ["Im", "Spie\u00b7gel", "vis\u00b7a\u00b7vis", ",", "bis", "sich", "der", "Mund", "zum", "Schrei\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NE", "$,", "KOUS", "PRF", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wild auseinanderri\u00df. Ich m\u00f6chte, schrie ich, dir,", "tokens": ["Wild", "aus\u00b7ein\u00b7an\u00b7der\u00b7ri\u00df", ".", "Ich", "m\u00f6ch\u00b7te", ",", "schrie", "ich", ",", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "PPER", "VMFIN", "$,", "VVFIN", "PPER", "$,", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Elendes Hohngesicht, in deine Larve speien.", "tokens": ["E\u00b7len\u00b7des", "Hohn\u00b7ge\u00b7sicht", ",", "in", "dei\u00b7ne", "Lar\u00b7ve", "spei\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.30": {"text": "Der andere schlo\u00df den Mund und starrte vor sich hin.", "tokens": ["Der", "an\u00b7de\u00b7re", "schlo\u00df", "den", "Mund", "und", "starr\u00b7te", "vor", "sich", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Trotz lag auf seiner Stirn, Wollust auf seinem Kinn.", "tokens": ["Trotz", "lag", "auf", "sei\u00b7ner", "Stirn", ",", "Wol\u00b7lust", "auf", "sei\u00b7nem", "Kinn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Er schien mir nicht bereit, der Reue Kreuz zu tragen", "tokens": ["Er", "schien", "mir", "nicht", "be\u00b7reit", ",", "der", "Reu\u00b7e", "Kreuz", "zu", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADJD", "$,", "ART", "NN", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und f\u00fcrderhin der Lust der Welt Valet zu sagen.", "tokens": ["Und", "f\u00fcr\u00b7der\u00b7hin", "der", "Lust", "der", "Welt", "Va\u00b7let", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Doch war in seinem Blick ein Grauen: bald ists aus:", "tokens": ["Doch", "war", "in", "sei\u00b7nem", "Blick", "ein", "Grau\u00b7en", ":", "bald", "ists", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "$.", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Es sitzt und nagt und pocht der Moderwurm im Haus.", "tokens": ["Es", "sitzt", "und", "nagt", "und", "pocht", "der", "Mo\u00b7der\u00b7wurm", "im", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Mein Spiegelkamerad verfiel und ward ein Greis.", "tokens": ["Mein", "Spie\u00b7gel\u00b7ka\u00b7me\u00b7rad", "ver\u00b7fiel", "und", "ward", "ein", "Greis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Sein Kinn sank auf die Brust, die Augen wurden bl\u00f6de.", "tokens": ["Sein", "Kinn", "sank", "auf", "die", "Brust", ",", "die", "Au\u00b7gen", "wur\u00b7den", "bl\u00f6\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "VAFIN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Ich schlug ins Spiegelglas. Es splitterte wie Eis.", "tokens": ["Ich", "schlug", "ins", "Spie\u00b7gel\u00b7glas", ".", "Es", "split\u00b7ter\u00b7te", "wie", "Eis", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$.", "PPER", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und mich umwinterte des Alters bange \u00d6de.", "tokens": ["Und", "mich", "um\u00b7win\u00b7ter\u00b7te", "des", "Al\u00b7ters", "ban\u00b7ge", "\u00d6\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Gern les ich den Horazius,", "tokens": ["Gern", "les", "ich", "den", "Ho\u00b7ra\u00b7zi\u00b7us", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "ART", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das war ein Kavalier.", "tokens": ["Das", "war", "ein", "Ka\u00b7va\u00b7lier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "An heutigen Karminibus", "tokens": ["An", "heu\u00b7ti\u00b7gen", "Kar\u00b7mi\u00b7ni\u00b7bus"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Find ich nicht viel Pl\u00e4sier.", "tokens": ["Find", "ich", "nicht", "viel", "Pl\u00e4\u00b7sier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "PIAT", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Nach R\u00fcb\u00f6l riechen sie, das ranzt,", "tokens": ["Nach", "R\u00fc\u00b7b\u00f6l", "rie\u00b7chen", "sie", ",", "das", "ranzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$,", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wenn die deutsche Muse tanzt,", "tokens": ["Und", "wenn", "die", "deut\u00b7sche", "Mu\u00b7se", "tanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wackelt das Quartier.", "tokens": ["So", "wa\u00b7ckelt", "das", "Quar\u00b7tier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.39": {"line.1": {"text": "Das ist gewi\u00df, und wenn ichs nicht gest\u00fcnde,", "tokens": ["Das", "ist", "ge\u00b7wi\u00df", ",", "und", "wenn", "ichs", "nicht", "ge\u00b7st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$,", "KON", "KOUS", "PIS", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "W\u00e4rs gegen meines Blutes reinen Adel S\u00fcnde:", "tokens": ["W\u00e4rs", "ge\u00b7gen", "mei\u00b7nes", "Blu\u00b7tes", "rei\u00b7nen", "A\u00b7del", "S\u00fcn\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bin kein Heiliger, der sich f\u00fcr Gott verzehrt.", "tokens": ["Ich", "bin", "kein", "Hei\u00b7li\u00b7ger", ",", "der", "sich", "f\u00fcr", "Gott", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich habe ihn auf meine Art verehrt,", "tokens": ["Ich", "ha\u00b7be", "ihn", "auf", "mei\u00b7ne", "Art", "ver\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Als Gott der Liebe, der es selbst erfuhr,", "tokens": ["Als", "Gott", "der", "Lie\u00b7be", ",", "der", "es", "selbst", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df Zeugen Wonne ist, und der voll Gnaden", "tokens": ["Da\u00df", "Zeu\u00b7gen", "Won\u00b7ne", "ist", ",", "und", "der", "voll", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "NN", "VAFIN", "$,", "KON", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Darum jedwede kleine Kreatur", "tokens": ["Da\u00b7rum", "jed\u00b7we\u00b7de", "klei\u00b7ne", "Kre\u00b7a\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mit seiner Lust, zu zeugen, hat beladen.", "tokens": ["Mit", "sei\u00b7ner", "Lust", ",", "zu", "zeu\u00b7gen", ",", "hat", "be\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PTKZU", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mir scheint es gottlos, ohne Lust zu leben.", "tokens": ["Mir", "scheint", "es", "gott\u00b7los", ",", "oh\u00b7ne", "Lust", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUI", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Was so ein gro\u00dfer, guter Herr gegeben,", "tokens": ["Was", "so", "ein", "gro\u00b7\u00dfer", ",", "gu\u00b7ter", "Herr", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "$,", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wirft nur ein schlechter Diener ekel hin.", "tokens": ["Wirft", "nur", "ein", "schlech\u00b7ter", "Die\u00b7ner", "e\u00b7kel", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ich la\u00df mich gern von Blutes Wallen heben,", "tokens": ["Ich", "la\u00df", "mich", "gern", "von", "Blu\u00b7tes", "Wal\u00b7len", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Weil ich Gott treu und gern sein Diener bin.", "tokens": ["Weil", "ich", "Gott", "treu", "und", "gern", "sein", "Die\u00b7ner", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADJD", "KON", "ADV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Wer Gott auf andre Weise dient,", "tokens": ["Wer", "Gott", "auf", "and\u00b7re", "Wei\u00b7se", "dient", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist ganz in Trotz und schief geschient.", "tokens": ["Ist", "ganz", "in", "Trotz", "und", "schief", "ge\u00b7schient", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Pfl\u00fccke die Stunden!", "tokens": ["Pfl\u00fc\u00b7cke", "die", "Stun\u00b7den", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Zum Kranze gewunden", "tokens": ["Zum", "Kran\u00b7ze", "ge\u00b7wun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VAPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Hat sie die Macht,", "tokens": ["Hat", "sie", "die", "Macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Die dich erschuf.", "tokens": ["Die", "dich", "er\u00b7schuf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.42": {"line.1": {"text": "Lust ist, o Sterblicher, Last nur den Toren,", "tokens": ["Lust", "ist", ",", "o", "Sterb\u00b7li\u00b7cher", ",", "Last", "nur", "den", "To\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "FM", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Die ihrer Sinne Kompa\u00df verloren,", "tokens": ["Die", "ih\u00b7rer", "Sin\u00b7ne", "Kom\u00b7pa\u00df", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Weisen ists wundervoll leichter Beruf.", "tokens": ["Wei\u00b7sen", "ists", "wun\u00b7der\u00b7voll", "leich\u00b7ter", "Be\u00b7ruf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Carpe diem, \u2013 und sei es bei Nacht.", "tokens": ["Car\u00b7pe", "diem", ",", "\u2013", "und", "sei", "es", "bei", "Nacht", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "$(", "KON", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.43": {"line.1": {"text": "Gestern nacht an meinem Bette", "tokens": ["Ge\u00b7stern", "nacht", "an", "mei\u00b7nem", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "APPR", "PPOSAT", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Stand das grinsende Skelette", "tokens": ["Stand", "das", "grin\u00b7sen\u00b7de", "Ske\u00b7let\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Jenes Mannes mit der Hippe", "tokens": ["Je\u00b7nes", "Man\u00b7nes", "mit", "der", "Hip\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Uhr.", "tokens": ["Und", "der", "Uhr", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "--+", "measure": "anapaest.init"}, "line.5": {"text": "Langsam sprach er ohne Lippe,", "tokens": ["Lang\u00b7sam", "sprach", "er", "oh\u00b7ne", "Lip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ohne Gaumen, ohne Zunge,", "tokens": ["Oh\u00b7ne", "Gau\u00b7men", ",", "oh\u00b7ne", "Zun\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ohne Wangen, ohne Lunge,", "tokens": ["Oh\u00b7ne", "Wan\u00b7gen", ",", "oh\u00b7ne", "Lun\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Knochen, Knochen, Knochen nur:", "tokens": ["Kno\u00b7chen", ",", "Kno\u00b7chen", ",", "Kno\u00b7chen", "nur", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Lieber Graf, ich bin zur Stelle,", "tokens": ["Lie\u00b7ber", "Graf", ",", "ich", "bin", "zur", "Stel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NE", "$,", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Da die Stunde zum Appelle", "tokens": ["Da", "die", "Stun\u00b7de", "zum", "Ap\u00b7pel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Vor dem Generalissimus naht.", "tokens": ["Vor", "dem", "Ge\u00b7ne\u00b7ra\u00b7lis\u00b7si\u00b7mus", "naht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Wenig braucht es Vorbereitung,", "tokens": ["We\u00b7nig", "braucht", "es", "Vor\u00b7be\u00b7rei\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Denn er sieht nicht viel auf Kleidung", "tokens": ["Denn", "er", "sieht", "nicht", "viel", "auf", "Klei\u00b7dung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Und er kennt nur einen Staat:", "tokens": ["Und", "er", "kennt", "nur", "ei\u00b7nen", "Staat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Tugend, die erg\u00f6tzlich helle,", "tokens": ["Tu\u00b7gend", ",", "die", "er\u00b7g\u00f6tz\u00b7lich", "hel\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Engelreine Lichtmontur.", "tokens": ["En\u00b7gel\u00b7rei\u00b7ne", "Licht\u00b7mon\u00b7tur", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Werter Herr, ich bin parat,", "tokens": ["Wer\u00b7ter", "Herr", ",", "ich", "bin", "pa\u00b7rat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VAFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagte ich, ein wenig leise,", "tokens": ["Sag\u00b7te", "ich", ",", "ein", "we\u00b7nig", "lei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "PIS", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend ich zur letzten Reise", "tokens": ["W\u00e4h\u00b7rend", "ich", "zur", "letz\u00b7ten", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ungern in den Schlafrock fuhr.", "tokens": ["Un\u00b7gern", "in", "den", "Schla\u00b7frock", "fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "H\u00f6flich st\u00fctzt er mich beim Gehen,", "tokens": ["H\u00f6f\u00b7lich", "st\u00fctzt", "er", "mich", "beim", "Ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seine d\u00fcrren Knochenzehen", "tokens": ["Sei\u00b7ne", "d\u00fcr\u00b7ren", "Kno\u00b7chen\u00b7ze\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Klapperten auf dem Parkett.", "tokens": ["Klap\u00b7per\u00b7ten", "auf", "dem", "Par\u00b7kett", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.46": {"line.1": {"text": "Manchmal blieb mein F\u00fchrer stehen,", "tokens": ["Manch\u00b7mal", "blieb", "mein", "F\u00fch\u00b7rer", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich ein Bildnis anzusehen,", "tokens": ["Sich", "ein", "Bild\u00b7nis", "an\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kennerierte,", "tokens": ["Ken\u00b7ne\u00b7rier\u00b7te", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Rezensierte:", "tokens": ["Re\u00b7zen\u00b7sier\u00b7te", ":"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "\u00bbhm, nicht \u00fcbel, hm, ganz nett.\u00ab", "tokens": ["\u00bb", "hm", ",", "nicht", "\u00fc\u00b7bel", ",", "hm", ",", "ganz", "nett", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "$,", "PTKNEG", "ADJD", "$,", "NE", "$,", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Gerne h\u00e4tt ich ihn gebeten,", "tokens": ["Ger\u00b7ne", "h\u00e4tt", "ich", "ihn", "ge\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In die Galerie zu treten,", "tokens": ["In", "die", "Ga\u00b7le\u00b7rie", "zu", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil dort Meisterwerke viel", "tokens": ["Weil", "dort", "Meis\u00b7ter\u00b7wer\u00b7ke", "viel"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Leuchtend zum Verweilen laden,", "tokens": ["Leuch\u00b7tend", "zum", "Ver\u00b7wei\u00b7len", "la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch es dr\u00e4ngten seine Gnaden", "tokens": ["Doch", "es", "dr\u00e4ng\u00b7ten", "sei\u00b7ne", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sehr bestimmt nach anderm Ziel.", "tokens": ["Sehr", "be\u00b7stimmt", "nach", "an\u00b7derm", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Schleppte mich zum Spiegelsaale,", "tokens": ["Schlepp\u00b7te", "mich", "zum", "Spie\u00b7gel\u00b7saa\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo wer wei\u00df wie viele Male", "tokens": ["Wo", "wer", "wei\u00df", "wie", "vie\u00b7le", "Ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PWS", "VVFIN", "KOKOM", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}