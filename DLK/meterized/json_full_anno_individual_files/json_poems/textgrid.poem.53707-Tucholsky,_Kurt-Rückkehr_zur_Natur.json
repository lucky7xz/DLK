{"textgrid.poem.53707": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "R\u00fcckkehr zur Natur", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man darf schon wieder Stiefel vor die T\u00fcre stellen \u2013", "tokens": ["Man", "darf", "schon", "wie\u00b7der", "Stie\u00b7fel", "vor", "die", "T\u00fc\u00b7re", "stel\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "sie werden nicht geklaut.", "tokens": ["sie", "wer\u00b7den", "nicht", "ge\u00b7klaut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man darf auch ruhig nach der Butter schellen", "tokens": ["Man", "darf", "auch", "ru\u00b7hig", "nach", "der", "But\u00b7ter", "schel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "ADJD", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "zu seiner Schale Haut.", "tokens": ["zu", "sei\u00b7ner", "Scha\u00b7le", "Haut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Man kann sich auch zum Trinkgeld schon bequemen.", "tokens": ["Man", "kann", "sich", "auch", "zum", "Trink\u00b7geld", "schon", "be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "APPRART", "NN", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nur wenig Kellner schie\u00dfen, wenn sies nehmen.", "tokens": ["Nur", "we\u00b7nig", "Kell\u00b7ner", "schie\u00b7\u00dfen", ",", "wenn", "sies", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Das ist ein Gl\u00fcck.", "tokens": ["Das", "ist", "ein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Wir kehren langsam zur Natur zur\u00fcck.", "tokens": ["Wir", "keh\u00b7ren", "lang\u00b7sam", "zur", "Na\u00b7tur", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Man darf schon wieder den Artikel schreiben", "tokens": ["Man", "darf", "schon", "wie\u00b7der", "den", "Ar\u00b7ti\u00b7kel", "schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "vor manches Substantiv.", "tokens": ["vor", "man\u00b7ches", "Subs\u00b7tan\u00b7tiv", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man braucht es nicht mehr so geballt zu treiben", "tokens": ["Man", "braucht", "es", "nicht", "mehr", "so", "ge\u00b7ballt", "zu", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "VVPP", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und krumm und schief.", "tokens": ["und", "krumm", "und", "schief", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Man mu\u00df auch nicht mehr langen nach Tagoren,", "tokens": ["Man", "mu\u00df", "auch", "nicht", "mehr", "lan\u00b7gen", "nach", "Ta\u00b7go\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "PTKNEG", "ADV", "ADJA", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "den haben wir im Werfelspiel verloren . . .", "tokens": ["den", "ha\u00b7ben", "wir", "im", "Wer\u00b7fel\u00b7spiel", "ver\u00b7lo\u00b7ren", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Das ist ein Gl\u00fcck.", "tokens": ["Das", "ist", "ein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Wir kehren langsam zur Natur zur\u00fcck.", "tokens": ["Wir", "keh\u00b7ren", "lang\u00b7sam", "zur", "Na\u00b7tur", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Man darf schon wieder feste kommandieren,", "tokens": ["Man", "darf", "schon", "wie\u00b7der", "fes\u00b7te", "kom\u00b7man\u00b7die\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wenn man Beamter ist.", "tokens": ["wenn", "man", "Be\u00b7am\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "VAFIN", "$."], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Untertan darf stramm stehn und parieren,", "tokens": ["Der", "Un\u00b7ter\u00b7tan", "darf", "stramm", "stehn", "und", "pa\u00b7rie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+--++-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "weil er ein Deutscher ist.", "tokens": ["weil", "er", "ein", "Deut\u00b7scher", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die neue Republik ist uns kein Jokus,", "tokens": ["Die", "neu\u00b7e", "Re\u00b7pub\u00b7lik", "ist", "uns", "kein", "Jo\u00b7kus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "und die Verfassung h\u00e4ngt auf jedem Lokus.", "tokens": ["und", "die", "Ver\u00b7fas\u00b7sung", "h\u00e4ngt", "auf", "je\u00b7dem", "Lo\u00b7kus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wir haben noch die alten B\u00fcrokraten,", "tokens": ["Wir", "ha\u00b7ben", "noch", "die", "al\u00b7ten", "B\u00fc\u00b7ro\u00b7kra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "die alten Richter und die Traditions-Soldaten . . .", "tokens": ["die", "al\u00b7ten", "Rich\u00b7ter", "und", "die", "Tra\u00b7di\u00b7ti\u00b7ons\u00b7Sol\u00b7da\u00b7ten", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Das ist ein Gl\u00fcck.", "tokens": ["Das", "ist", "ein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Wir kehren still zur Monarchie zur\u00fcck.", "tokens": ["Wir", "keh\u00b7ren", "still", "zur", "Mon\u00b7ar\u00b7chie", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Man darf schon wieder Stiefel vor die T\u00fcre stellen \u2013", "tokens": ["Man", "darf", "schon", "wie\u00b7der", "Stie\u00b7fel", "vor", "die", "T\u00fc\u00b7re", "stel\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "sie werden nicht geklaut.", "tokens": ["sie", "wer\u00b7den", "nicht", "ge\u00b7klaut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man darf auch ruhig nach der Butter schellen", "tokens": ["Man", "darf", "auch", "ru\u00b7hig", "nach", "der", "But\u00b7ter", "schel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "ADJD", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "zu seiner Schale Haut.", "tokens": ["zu", "sei\u00b7ner", "Scha\u00b7le", "Haut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Man kann sich auch zum Trinkgeld schon bequemen.", "tokens": ["Man", "kann", "sich", "auch", "zum", "Trink\u00b7geld", "schon", "be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "APPRART", "NN", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nur wenig Kellner schie\u00dfen, wenn sies nehmen.", "tokens": ["Nur", "we\u00b7nig", "Kell\u00b7ner", "schie\u00b7\u00dfen", ",", "wenn", "sies", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Das ist ein Gl\u00fcck.", "tokens": ["Das", "ist", "ein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Wir kehren langsam zur Natur zur\u00fcck.", "tokens": ["Wir", "keh\u00b7ren", "lang\u00b7sam", "zur", "Na\u00b7tur", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Man darf schon wieder den Artikel schreiben", "tokens": ["Man", "darf", "schon", "wie\u00b7der", "den", "Ar\u00b7ti\u00b7kel", "schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "vor manches Substantiv.", "tokens": ["vor", "man\u00b7ches", "Subs\u00b7tan\u00b7tiv", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man braucht es nicht mehr so geballt zu treiben", "tokens": ["Man", "braucht", "es", "nicht", "mehr", "so", "ge\u00b7ballt", "zu", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "VVPP", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und krumm und schief.", "tokens": ["und", "krumm", "und", "schief", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Man mu\u00df auch nicht mehr langen nach Tagoren,", "tokens": ["Man", "mu\u00df", "auch", "nicht", "mehr", "lan\u00b7gen", "nach", "Ta\u00b7go\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "PTKNEG", "ADV", "ADJA", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "den haben wir im Werfelspiel verloren . . .", "tokens": ["den", "ha\u00b7ben", "wir", "im", "Wer\u00b7fel\u00b7spiel", "ver\u00b7lo\u00b7ren", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Das ist ein Gl\u00fcck.", "tokens": ["Das", "ist", "ein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Wir kehren langsam zur Natur zur\u00fcck.", "tokens": ["Wir", "keh\u00b7ren", "lang\u00b7sam", "zur", "Na\u00b7tur", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Man darf schon wieder feste kommandieren,", "tokens": ["Man", "darf", "schon", "wie\u00b7der", "fes\u00b7te", "kom\u00b7man\u00b7die\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wenn man Beamter ist.", "tokens": ["wenn", "man", "Be\u00b7am\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "VAFIN", "$."], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Untertan darf stramm stehn und parieren,", "tokens": ["Der", "Un\u00b7ter\u00b7tan", "darf", "stramm", "stehn", "und", "pa\u00b7rie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+--++-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "weil er ein Deutscher ist.", "tokens": ["weil", "er", "ein", "Deut\u00b7scher", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die neue Republik ist uns kein Jokus,", "tokens": ["Die", "neu\u00b7e", "Re\u00b7pub\u00b7lik", "ist", "uns", "kein", "Jo\u00b7kus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "und die Verfassung h\u00e4ngt auf jedem Lokus.", "tokens": ["und", "die", "Ver\u00b7fas\u00b7sung", "h\u00e4ngt", "auf", "je\u00b7dem", "Lo\u00b7kus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wir haben noch die alten B\u00fcrokraten,", "tokens": ["Wir", "ha\u00b7ben", "noch", "die", "al\u00b7ten", "B\u00fc\u00b7ro\u00b7kra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "die alten Richter und die Traditions-Soldaten . . .", "tokens": ["die", "al\u00b7ten", "Rich\u00b7ter", "und", "die", "Tra\u00b7di\u00b7ti\u00b7ons\u00b7Sol\u00b7da\u00b7ten", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Das ist ein Gl\u00fcck.", "tokens": ["Das", "ist", "ein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Wir kehren still zur Monarchie zur\u00fcck.", "tokens": ["Wir", "keh\u00b7ren", "still", "zur", "Mon\u00b7ar\u00b7chie", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}