{"textgrid.poem.39065": {"metadata": {"author": {"name": "Prutz, Robert Eduard", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und m\u00f6gen wir auch noch so klar", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und m\u00f6gen wir auch noch so klar", "tokens": ["Und", "m\u00f6\u00b7gen", "wir", "auch", "noch", "so", "klar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von dem, was not tut, sagen,", "tokens": ["von", "dem", ",", "was", "not", "tut", ",", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "$,", "PWS", "NN", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und m\u00f6gen noch so offenbar", "tokens": ["und", "m\u00f6\u00b7gen", "noch", "so", "of\u00b7fen\u00b7bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der Freiheit Banner tragen:", "tokens": ["der", "Frei\u00b7heit", "Ban\u00b7ner", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ihr lacht uns doch ins Angesicht", "tokens": ["Ihr", "lacht", "uns", "doch", "ins", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und z\u00e4hlt uns zu den Tollen,", "tokens": ["und", "z\u00e4hlt", "uns", "zu", "den", "Tol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "ihr denkt, wir wissen selber nicht,", "tokens": ["ihr", "denkt", ",", "wir", "wis\u00b7sen", "sel\u00b7ber", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "nicht v\u00f6llig, was wir wollen.", "tokens": ["nicht", "v\u00f6l\u00b7lig", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "So merkt denn auf! Das Vaterland", "tokens": ["So", "merkt", "denn", "auf", "!", "Das", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "soll fest zusammenhalten,", "tokens": ["soll", "fest", "zu\u00b7sam\u00b7men\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "vom Rhein bis an den Ostseestrand", "tokens": ["vom", "Rhein", "bis", "an", "den", "Ost\u00b7see\u00b7strand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NE", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "selbst\u00e4ndig, unzerspalten;", "tokens": ["selb\u00b7st\u00e4n\u00b7dig", ",", "un\u00b7zer\u00b7spal\u00b7ten", ";"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "stets soll es vorw\u00e4rts, vorw\u00e4rts gehn,", "tokens": ["stets", "soll", "es", "vor\u00b7w\u00e4rts", ",", "vor\u00b7w\u00e4rts", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und ob die Donner rollen,", "tokens": ["und", "ob", "die", "Don\u00b7ner", "rol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "auf eignen F\u00fc\u00dfen soll es stehn \u2013", "tokens": ["auf", "eig\u00b7nen", "F\u00fc\u00b7\u00dfen", "soll", "es", "stehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wir wollen F\u00fcrsten, habet acht,", "tokens": ["Wir", "wol\u00b7len", "F\u00fcrs\u00b7ten", ",", "ha\u00b7bet", "acht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$,", "VAFIN", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die gern dem Volk vertrauen", "tokens": ["die", "gern", "dem", "Volk", "ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und die die S\u00e4ulen ihrer Macht", "tokens": ["und", "die", "die", "S\u00e4u\u00b7len", "ih\u00b7rer", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "nur auf dem Recht erbauen;", "tokens": ["nur", "auf", "dem", "Recht", "er\u00b7bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wir wollen F\u00fcrsten, die nicht gleich", "tokens": ["wir", "wol\u00b7len", "F\u00fcrs\u00b7ten", ",", "die", "nicht", "gleich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "PRELS", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "um ein paar Verse schmollen,", "tokens": ["um", "ein", "paar", "Ver\u00b7se", "schmol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "an Schmeichlern arm, an Liebe reich \u2013", "tokens": ["an", "Schmeich\u00b7lern", "arm", ",", "an", "Lie\u00b7be", "reich", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wir wollen V\u00f6lker, k\u00fchn und stark,", "tokens": ["Wir", "wol\u00b7len", "V\u00f6l\u00b7ker", ",", "k\u00fchn", "und", "stark", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von keinem Joch gebogen,", "tokens": ["von", "kei\u00b7nem", "Joch", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "gen\u00e4hrt von ihrer Vorzeit Mark,", "tokens": ["ge\u00b7n\u00e4hrt", "von", "ih\u00b7rer", "Vor\u00b7zeit", "Mark", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "zu Knechten nicht erzogen;", "tokens": ["zu", "Knech\u00b7ten", "nicht", "er\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wir wollen V\u00f6lker, die nicht blo\u00df", "tokens": ["wir", "wol\u00b7len", "V\u00f6l\u00b7ker", ",", "die", "nicht", "blo\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "PRELS", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "stets m\u00fcssen und stets sollen,", "tokens": ["stets", "m\u00fcs\u00b7sen", "und", "stets", "sol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "KON", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "durch Krieg ber\u00fchmt, durch Frieden gro\u00df \u2013", "tokens": ["durch", "Krieg", "be\u00b7r\u00fchmt", ",", "durch", "Frie\u00b7den", "gro\u00df", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wir wolln Gesetze, kurz und rund,", "tokens": ["Wir", "wolln", "Ge\u00b7set\u00b7ze", ",", "kurz", "und", "rund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die klar und deutlich sprechen", "tokens": ["die", "klar", "und", "deut\u00b7lich", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und die auch keines K\u00f6nigs Mund", "tokens": ["und", "die", "auch", "kei\u00b7nes", "K\u00f6\u00b7nigs", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "darf biegen oder brechen;", "tokens": ["darf", "bie\u00b7gen", "o\u00b7der", "bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wir wolln Gesetze, die dem Born", "tokens": ["wir", "wolln", "Ge\u00b7set\u00b7ze", ",", "die", "dem", "Born"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "des Lebens frisch entquollen,", "tokens": ["des", "Le\u00b7bens", "frisch", "ent\u00b7quol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "der B\u00f6sen Zaum, der Guten Sporn \u2013", "tokens": ["der", "B\u00f6\u00b7sen", "Zaum", ",", "der", "Gu\u00b7ten", "Sporn", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wir wolln Minister (merkt's, ihr Herrn!),", "tokens": ["Wir", "wolln", "Mi\u00b7nis\u00b7ter", "(", "merkt's", ",", "ihr", "Herrn", "!", ")", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "NN", "$(", "NE", "$,", "PPOSAT", "NN", "$.", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit oder ohne Ahnen,", "tokens": ["mit", "o\u00b7der", "oh\u00b7ne", "Ah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "wenn sie nur dem Jahrhundert gern", "tokens": ["wenn", "sie", "nur", "dem", "Jahr\u00b7hun\u00b7dert", "gern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "weit offne Stra\u00dfen bahnen!", "tokens": ["weit", "off\u00b7ne", "Stra\u00b7\u00dfen", "bah\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Doch wem des Volkes Liebe fehlt,", "tokens": ["Doch", "wem", "des", "Vol\u00b7kes", "Lie\u00b7be", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der soll vom Amt sich trollen,", "tokens": ["der", "soll", "vom", "Amt", "sich", "trol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VMFIN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "und ob er sechzehn Ahnen z\u00e4hlt \u2013", "tokens": ["und", "ob", "er", "sech\u00b7zehn", "Ah\u00b7nen", "z\u00e4hlt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wir wollen freie Wissenschaft,", "tokens": ["Wir", "wol\u00b7len", "frei\u00b7e", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zu lernen und zu lehren,", "tokens": ["zu", "ler\u00b7nen", "und", "zu", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und niemand soll des Denkers Kraft", "tokens": ["und", "nie\u00b7mand", "soll", "des", "Den\u00b7kers", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VMFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in ihrem Fluge wehren.", "tokens": ["in", "ih\u00b7rem", "Flu\u00b7ge", "weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wir wollen, da\u00df man nicht den Geist,", "tokens": ["Wir", "wol\u00b7len", ",", "da\u00df", "man", "nicht", "den", "Geist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PIS", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "den frischen, lebensvollen,", "tokens": ["den", "fri\u00b7schen", ",", "le\u00b7bens\u00b7vol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "nur Holz und Wasser tragen hei\u00dft \u2013", "tokens": ["nur", "Holz", "und", "Was\u00b7ser", "tra\u00b7gen", "hei\u00dft", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und dann mein ewig A und O,", "tokens": ["Und", "dann", "mein", "e\u00b7wig", "A", "und", "O", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ADJD", "NE", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ich es nicht vergesse!", "tokens": ["da\u00df", "ich", "es", "nicht", "ver\u00b7ges\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn ohne das wird niemand froh \u2013", "tokens": ["Denn", "oh\u00b7ne", "das", "wird", "nie\u00b7mand", "froh", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDS", "VAFIN", "PIS", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "das ist die freie Presse;", "tokens": ["das", "ist", "die", "frei\u00b7e", "Pres\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "da\u00df wir des Geistes Bl\u00fcte nicht", "tokens": ["da\u00df", "wir", "des", "Geis\u00b7tes", "Bl\u00fc\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bei der Zensur verzollen,", "tokens": ["bei", "der", "Zen\u00b7sur", "ver\u00b7zol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "das d\u00fcnkt uns Recht, das d\u00fcnkt uns Pflicht \u2013", "tokens": ["das", "d\u00fcnkt", "uns", "Recht", ",", "das", "d\u00fcnkt", "uns", "Pflicht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "$,", "PDS", "VVFIN", "PPER", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Zuletzt noch eins, das ist ein Ton,", "tokens": ["Zu\u00b7letzt", "noch", "eins", ",", "das", "ist", "ein", "Ton", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "bei dem die Herzen schlagen,", "tokens": ["bei", "dem", "die", "Her\u00b7zen", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "er hei\u00dft, er hei\u00dft \u2013 ihr kennt ihn schon,", "tokens": ["er", "hei\u00dft", ",", "er", "hei\u00dft", "\u2013", "ihr", "kennt", "ihn", "schon", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ich darf ihn doch nicht sagen.", "tokens": ["ich", "darf", "ihn", "doch", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wer wagt das Wort? Wer nennt es hier?", "tokens": ["Wer", "wagt", "das", "Wort", "?", "Wer", "nennt", "es", "hier", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcrwahr, ihr m\u00f6chtet grollen:", "tokens": ["F\u00fcr\u00b7wahr", ",", "ihr", "m\u00f6ch\u00b7tet", "grol\u00b7len", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Doch gebt nur das, so haben wir,", "tokens": ["Doch", "gebt", "nur", "das", ",", "so", "ha\u00b7ben", "wir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PDS", "$,", "ADV", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wir haben, was wir wollen.", "tokens": ["wir", "ha\u00b7ben", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und m\u00f6gen wir auch noch so klar", "tokens": ["Und", "m\u00f6\u00b7gen", "wir", "auch", "noch", "so", "klar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von dem, was not tut, sagen,", "tokens": ["von", "dem", ",", "was", "not", "tut", ",", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "$,", "PWS", "NN", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und m\u00f6gen noch so offenbar", "tokens": ["und", "m\u00f6\u00b7gen", "noch", "so", "of\u00b7fen\u00b7bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der Freiheit Banner tragen:", "tokens": ["der", "Frei\u00b7heit", "Ban\u00b7ner", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ihr lacht uns doch ins Angesicht", "tokens": ["Ihr", "lacht", "uns", "doch", "ins", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und z\u00e4hlt uns zu den Tollen,", "tokens": ["und", "z\u00e4hlt", "uns", "zu", "den", "Tol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "ihr denkt, wir wissen selber nicht,", "tokens": ["ihr", "denkt", ",", "wir", "wis\u00b7sen", "sel\u00b7ber", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "nicht v\u00f6llig, was wir wollen.", "tokens": ["nicht", "v\u00f6l\u00b7lig", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "So merkt denn auf! Das Vaterland", "tokens": ["So", "merkt", "denn", "auf", "!", "Das", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "soll fest zusammenhalten,", "tokens": ["soll", "fest", "zu\u00b7sam\u00b7men\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "vom Rhein bis an den Ostseestrand", "tokens": ["vom", "Rhein", "bis", "an", "den", "Ost\u00b7see\u00b7strand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NE", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "selbst\u00e4ndig, unzerspalten;", "tokens": ["selb\u00b7st\u00e4n\u00b7dig", ",", "un\u00b7zer\u00b7spal\u00b7ten", ";"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "stets soll es vorw\u00e4rts, vorw\u00e4rts gehn,", "tokens": ["stets", "soll", "es", "vor\u00b7w\u00e4rts", ",", "vor\u00b7w\u00e4rts", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und ob die Donner rollen,", "tokens": ["und", "ob", "die", "Don\u00b7ner", "rol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "auf eignen F\u00fc\u00dfen soll es stehn \u2013", "tokens": ["auf", "eig\u00b7nen", "F\u00fc\u00b7\u00dfen", "soll", "es", "stehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wir wollen F\u00fcrsten, habet acht,", "tokens": ["Wir", "wol\u00b7len", "F\u00fcrs\u00b7ten", ",", "ha\u00b7bet", "acht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$,", "VAFIN", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die gern dem Volk vertrauen", "tokens": ["die", "gern", "dem", "Volk", "ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und die die S\u00e4ulen ihrer Macht", "tokens": ["und", "die", "die", "S\u00e4u\u00b7len", "ih\u00b7rer", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "nur auf dem Recht erbauen;", "tokens": ["nur", "auf", "dem", "Recht", "er\u00b7bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wir wollen F\u00fcrsten, die nicht gleich", "tokens": ["wir", "wol\u00b7len", "F\u00fcrs\u00b7ten", ",", "die", "nicht", "gleich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "PRELS", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "um ein paar Verse schmollen,", "tokens": ["um", "ein", "paar", "Ver\u00b7se", "schmol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "an Schmeichlern arm, an Liebe reich \u2013", "tokens": ["an", "Schmeich\u00b7lern", "arm", ",", "an", "Lie\u00b7be", "reich", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wir wollen V\u00f6lker, k\u00fchn und stark,", "tokens": ["Wir", "wol\u00b7len", "V\u00f6l\u00b7ker", ",", "k\u00fchn", "und", "stark", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von keinem Joch gebogen,", "tokens": ["von", "kei\u00b7nem", "Joch", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "gen\u00e4hrt von ihrer Vorzeit Mark,", "tokens": ["ge\u00b7n\u00e4hrt", "von", "ih\u00b7rer", "Vor\u00b7zeit", "Mark", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "zu Knechten nicht erzogen;", "tokens": ["zu", "Knech\u00b7ten", "nicht", "er\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wir wollen V\u00f6lker, die nicht blo\u00df", "tokens": ["wir", "wol\u00b7len", "V\u00f6l\u00b7ker", ",", "die", "nicht", "blo\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "PRELS", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "stets m\u00fcssen und stets sollen,", "tokens": ["stets", "m\u00fcs\u00b7sen", "und", "stets", "sol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "KON", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "durch Krieg ber\u00fchmt, durch Frieden gro\u00df \u2013", "tokens": ["durch", "Krieg", "be\u00b7r\u00fchmt", ",", "durch", "Frie\u00b7den", "gro\u00df", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Wir wolln Gesetze, kurz und rund,", "tokens": ["Wir", "wolln", "Ge\u00b7set\u00b7ze", ",", "kurz", "und", "rund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die klar und deutlich sprechen", "tokens": ["die", "klar", "und", "deut\u00b7lich", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und die auch keines K\u00f6nigs Mund", "tokens": ["und", "die", "auch", "kei\u00b7nes", "K\u00f6\u00b7nigs", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "darf biegen oder brechen;", "tokens": ["darf", "bie\u00b7gen", "o\u00b7der", "bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wir wolln Gesetze, die dem Born", "tokens": ["wir", "wolln", "Ge\u00b7set\u00b7ze", ",", "die", "dem", "Born"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "des Lebens frisch entquollen,", "tokens": ["des", "Le\u00b7bens", "frisch", "ent\u00b7quol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "der B\u00f6sen Zaum, der Guten Sporn \u2013", "tokens": ["der", "B\u00f6\u00b7sen", "Zaum", ",", "der", "Gu\u00b7ten", "Sporn", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wir wolln Minister (merkt's, ihr Herrn!),", "tokens": ["Wir", "wolln", "Mi\u00b7nis\u00b7ter", "(", "merkt's", ",", "ihr", "Herrn", "!", ")", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "NN", "$(", "NE", "$,", "PPOSAT", "NN", "$.", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit oder ohne Ahnen,", "tokens": ["mit", "o\u00b7der", "oh\u00b7ne", "Ah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "wenn sie nur dem Jahrhundert gern", "tokens": ["wenn", "sie", "nur", "dem", "Jahr\u00b7hun\u00b7dert", "gern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "weit offne Stra\u00dfen bahnen!", "tokens": ["weit", "off\u00b7ne", "Stra\u00b7\u00dfen", "bah\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Doch wem des Volkes Liebe fehlt,", "tokens": ["Doch", "wem", "des", "Vol\u00b7kes", "Lie\u00b7be", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der soll vom Amt sich trollen,", "tokens": ["der", "soll", "vom", "Amt", "sich", "trol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VMFIN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "und ob er sechzehn Ahnen z\u00e4hlt \u2013", "tokens": ["und", "ob", "er", "sech\u00b7zehn", "Ah\u00b7nen", "z\u00e4hlt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Wir wollen freie Wissenschaft,", "tokens": ["Wir", "wol\u00b7len", "frei\u00b7e", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zu lernen und zu lehren,", "tokens": ["zu", "ler\u00b7nen", "und", "zu", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und niemand soll des Denkers Kraft", "tokens": ["und", "nie\u00b7mand", "soll", "des", "Den\u00b7kers", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VMFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in ihrem Fluge wehren.", "tokens": ["in", "ih\u00b7rem", "Flu\u00b7ge", "weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wir wollen, da\u00df man nicht den Geist,", "tokens": ["Wir", "wol\u00b7len", ",", "da\u00df", "man", "nicht", "den", "Geist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PIS", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "den frischen, lebensvollen,", "tokens": ["den", "fri\u00b7schen", ",", "le\u00b7bens\u00b7vol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "nur Holz und Wasser tragen hei\u00dft \u2013", "tokens": ["nur", "Holz", "und", "Was\u00b7ser", "tra\u00b7gen", "hei\u00dft", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Und dann mein ewig A und O,", "tokens": ["Und", "dann", "mein", "e\u00b7wig", "A", "und", "O", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ADJD", "NE", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ich es nicht vergesse!", "tokens": ["da\u00df", "ich", "es", "nicht", "ver\u00b7ges\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn ohne das wird niemand froh \u2013", "tokens": ["Denn", "oh\u00b7ne", "das", "wird", "nie\u00b7mand", "froh", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDS", "VAFIN", "PIS", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "das ist die freie Presse;", "tokens": ["das", "ist", "die", "frei\u00b7e", "Pres\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "da\u00df wir des Geistes Bl\u00fcte nicht", "tokens": ["da\u00df", "wir", "des", "Geis\u00b7tes", "Bl\u00fc\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bei der Zensur verzollen,", "tokens": ["bei", "der", "Zen\u00b7sur", "ver\u00b7zol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "das d\u00fcnkt uns Recht, das d\u00fcnkt uns Pflicht \u2013", "tokens": ["das", "d\u00fcnkt", "uns", "Recht", ",", "das", "d\u00fcnkt", "uns", "Pflicht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "$,", "PDS", "VVFIN", "PPER", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "das ist es, was wir wollen.", "tokens": ["das", "ist", "es", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Zuletzt noch eins, das ist ein Ton,", "tokens": ["Zu\u00b7letzt", "noch", "eins", ",", "das", "ist", "ein", "Ton", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "bei dem die Herzen schlagen,", "tokens": ["bei", "dem", "die", "Her\u00b7zen", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "er hei\u00dft, er hei\u00dft \u2013 ihr kennt ihn schon,", "tokens": ["er", "hei\u00dft", ",", "er", "hei\u00dft", "\u2013", "ihr", "kennt", "ihn", "schon", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ich darf ihn doch nicht sagen.", "tokens": ["ich", "darf", "ihn", "doch", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wer wagt das Wort? Wer nennt es hier?", "tokens": ["Wer", "wagt", "das", "Wort", "?", "Wer", "nennt", "es", "hier", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcrwahr, ihr m\u00f6chtet grollen:", "tokens": ["F\u00fcr\u00b7wahr", ",", "ihr", "m\u00f6ch\u00b7tet", "grol\u00b7len", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Doch gebt nur das, so haben wir,", "tokens": ["Doch", "gebt", "nur", "das", ",", "so", "ha\u00b7ben", "wir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PDS", "$,", "ADV", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wir haben, was wir wollen.", "tokens": ["wir", "ha\u00b7ben", ",", "was", "wir", "wol\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}