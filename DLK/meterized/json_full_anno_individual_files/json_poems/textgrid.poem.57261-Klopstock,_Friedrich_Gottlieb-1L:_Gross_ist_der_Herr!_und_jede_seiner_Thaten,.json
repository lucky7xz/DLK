{"textgrid.poem.57261": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gross ist der Herr! und jede seiner Thaten,", "genre": "verse", "period": "N.A.", "pub_year": 1764, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gross ist der Herr! und jede seiner Thaten,", "tokens": ["Gross", "ist", "der", "Herr", "!", "und", "je\u00b7de", "sei\u00b7ner", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$.", "KON", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die wir kennen, ist gross!", "tokens": ["Die", "wir", "ken\u00b7nen", ",", "ist", "gross", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ozean der Welten, Sterne sind Tropfen des Ozeans!", "tokens": ["O\u00b7ze\u00b7an", "der", "Wel\u00b7ten", ",", "Ster\u00b7ne", "sind", "Trop\u00b7fen", "des", "O\u00b7ze\u00b7ans", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "NN", "VAFIN", "NN", "ART", "NN", "$."], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Wir kennen dich nicht!", "tokens": ["Wir", "ken\u00b7nen", "dich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Wo beginn ich, und ach! wo end' ich", "tokens": ["Wo", "be\u00b7ginn", "ich", ",", "und", "ach", "!", "wo", "end'", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KON", "XY", "$.", "PWAV", "VVFIN", "PPER"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Des Ewigen Preis?", "tokens": ["Des", "E\u00b7wi\u00b7gen", "Preis", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Welcher Donner giebt mir Stimme?", "tokens": ["Wel\u00b7cher", "Don\u00b7ner", "giebt", "mir", "Stim\u00b7me", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gedanken welcher Engel?", "tokens": ["Ge\u00b7dan\u00b7ken", "wel\u00b7cher", "En\u00b7gel", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PWAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wer leitet mich hinauf", "tokens": ["Wer", "lei\u00b7tet", "mich", "hin\u00b7auf"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zu den ewigen H\u00fcgeln?", "tokens": ["Zu", "den", "e\u00b7wi\u00b7gen", "H\u00fc\u00b7geln", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ich versink', ich versinke, geh unter", "tokens": ["Ich", "ver\u00b7sink'", ",", "ich", "ver\u00b7sin\u00b7ke", ",", "geh", "un\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "VVFIN", "APPR"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "In deiner Welten Ozean!", "tokens": ["In", "dei\u00b7ner", "Wel\u00b7ten", "O\u00b7ze\u00b7an", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie sch\u00f6n, und wie hehr war diese Sternennacht,", "tokens": ["Wie", "sch\u00f6n", ",", "und", "wie", "hehr", "war", "die\u00b7se", "Ster\u00b7nen\u00b7nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "KON", "PWAV", "ADJD", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Eh ich des grossen Gedankens Flug,", "tokens": ["Eh", "ich", "des", "gros\u00b7sen", "Ge\u00b7dan\u00b7kens", "Flug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Eh ich es wagte, mich zu fragen:", "tokens": ["Eh", "ich", "es", "wag\u00b7te", ",", "mich", "zu", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Welche Thaten th\u00e4te dort oben der Herliche?", "tokens": ["Wel\u00b7che", "Tha\u00b7ten", "th\u00e4\u00b7te", "dort", "o\u00b7ben", "der", "Her\u00b7li\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+--+--+--", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Mich, den Thoren! den Staub!", "tokens": ["Mich", ",", "den", "Tho\u00b7ren", "!", "den", "Staub", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ich f\u00fcrchtet', als ich zu fragen begann,", "tokens": ["Ich", "f\u00fcrch\u00b7tet'", ",", "als", "ich", "zu", "fra\u00b7gen", "be\u00b7gann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dass kommen w\u00fcrde, was gekommen ist.", "tokens": ["Dass", "kom\u00b7men", "w\u00fcr\u00b7de", ",", "was", "ge\u00b7kom\u00b7men", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VAFIN", "$,", "PRELS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich unterliege dem grossen Gedanken!", "tokens": ["Ich", "un\u00b7ter\u00b7lie\u00b7ge", "dem", "gros\u00b7sen", "Ge\u00b7dan\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Weniger k\u00fchn, hast, o Pilot,", "tokens": ["We\u00b7ni\u00b7ger", "k\u00fchn", ",", "hast", ",", "o", "Pi\u00b7lot", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VAFIN", "$,", "FM", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Du gleiches Schicksal.", "tokens": ["Du", "glei\u00b7ches", "Schick\u00b7sal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Tr\u00fcb' an dem fernen Olymp", "tokens": ["Tr\u00fcb'", "an", "dem", "fer\u00b7nen", "O\u00b7lymp"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Sammeln sich Sturmwolken.", "tokens": ["Sam\u00b7meln", "sich", "Sturm\u00b7wol\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PRF", "NN", "$."], "meter": "+--+--", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Jetzo ruht noch das Meer f\u00fcrchterlich still.", "tokens": ["Jet\u00b7zo", "ruht", "noch", "das", "Meer", "f\u00fcrch\u00b7ter\u00b7lich", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+--++--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Doch der Pilot weiss,", "tokens": ["Doch", "der", "Pi\u00b7lot", "weiss", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Welcher Sturm dort herdroht!", "tokens": ["Wel\u00b7cher", "Sturm", "dort", "her\u00b7droht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "ADV", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Und die eherne Brust bebt ihm,", "tokens": ["Und", "die", "e\u00b7her\u00b7ne", "Brust", "bebt", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "--+--+--", "measure": "anapaest.di.plus"}}, "stanza.8": {"line.1": {"text": "Er st\u00fcrzt an dem Maste", "tokens": ["Er", "st\u00fcrzt", "an", "dem", "Mas\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Bleich die Segel herab.", "tokens": ["Bleich", "die", "Se\u00b7gel", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "ADV", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ach! nun kr\u00e4uselt sich", "tokens": ["Ach", "!", "nun", "kr\u00e4u\u00b7selt", "sich"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "PRF"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Das Meer, und der Sturm ist da!", "tokens": ["Das", "Meer", ",", "und", "der", "Sturm", "ist", "da", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Donnernder rauscht der Ozean als du, schwarzer Olymp!", "tokens": ["Don\u00b7nern\u00b7der", "rauscht", "der", "O\u00b7ze\u00b7an", "als", "du", ",", "schwar\u00b7zer", "O\u00b7lymp", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "KOUS", "PPER", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Krachend st\u00fcrzet der Mast!", "tokens": ["Kra\u00b7chend", "st\u00fcr\u00b7zet", "der", "Mast", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Lautheulend zuckt der Sturm!", "tokens": ["Lau\u00b7theu\u00b7lend", "zuckt", "der", "Sturm", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Singt Todtengesang!", "tokens": ["Singt", "Tod\u00b7ten\u00b7ge\u00b7sang", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.10": {"line.1": {"text": "Der Pilot kennet ihn. Immer steigender hebst, Woge, du dich!", "tokens": ["Der", "Pi\u00b7lot", "ken\u00b7net", "ihn", ".", "Im\u00b7mer", "stei\u00b7gen\u00b7der", "hebst", ",", "Wo\u00b7ge", ",", "du", "dich", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "ADV", "ADJD", "VVFIN", "$,", "NN", "$,", "PPER", "PRF", "$."], "meter": "-+-+--+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Ach die letzte, letzte bist du! Das Schif geht unter!", "tokens": ["Ach", "die", "letz\u00b7te", ",", "letz\u00b7te", "bist", "du", "!", "Das", "Schif", "geht", "un\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ART", "ADJA", "$,", "ADJA", "VAFIN", "PPER", "$.", "ART", "NN", "VVFIN", "APPR", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und den Todtengesang heult dumpf fort", "tokens": ["Und", "den", "Tod\u00b7ten\u00b7ge\u00b7sang", "heult", "dumpf", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "PTKVZ"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Auf dem grossen, immer offenem Grabe der Sturm!", "tokens": ["Auf", "dem", "gros\u00b7sen", ",", "im\u00b7mer", "of\u00b7fe\u00b7nem", "Gra\u00b7be", "der", "Sturm", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "ADV", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Gross ist der Herr! und jede seiner Thaten,", "tokens": ["Gross", "ist", "der", "Herr", "!", "und", "je\u00b7de", "sei\u00b7ner", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$.", "KON", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die wir kennen, ist gross!", "tokens": ["Die", "wir", "ken\u00b7nen", ",", "ist", "gross", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ozean der Welten, Sterne sind Tropfen des Ozeans!", "tokens": ["O\u00b7ze\u00b7an", "der", "Wel\u00b7ten", ",", "Ster\u00b7ne", "sind", "Trop\u00b7fen", "des", "O\u00b7ze\u00b7ans", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "NN", "VAFIN", "NN", "ART", "NN", "$."], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Wir kennen dich nicht!", "tokens": ["Wir", "ken\u00b7nen", "dich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.12": {"line.1": {"text": "Wo beginn ich, und ach! wo end' ich", "tokens": ["Wo", "be\u00b7ginn", "ich", ",", "und", "ach", "!", "wo", "end'", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KON", "XY", "$.", "PWAV", "VVFIN", "PPER"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Des Ewigen Preis?", "tokens": ["Des", "E\u00b7wi\u00b7gen", "Preis", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Welcher Donner giebt mir Stimme?", "tokens": ["Wel\u00b7cher", "Don\u00b7ner", "giebt", "mir", "Stim\u00b7me", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gedanken welcher Engel?", "tokens": ["Ge\u00b7dan\u00b7ken", "wel\u00b7cher", "En\u00b7gel", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PWAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wer leitet mich hinauf", "tokens": ["Wer", "lei\u00b7tet", "mich", "hin\u00b7auf"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zu den ewigen H\u00fcgeln?", "tokens": ["Zu", "den", "e\u00b7wi\u00b7gen", "H\u00fc\u00b7geln", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ich versink', ich versinke, geh unter", "tokens": ["Ich", "ver\u00b7sink'", ",", "ich", "ver\u00b7sin\u00b7ke", ",", "geh", "un\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "VVFIN", "APPR"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "In deiner Welten Ozean!", "tokens": ["In", "dei\u00b7ner", "Wel\u00b7ten", "O\u00b7ze\u00b7an", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie sch\u00f6n, und wie hehr war diese Sternennacht,", "tokens": ["Wie", "sch\u00f6n", ",", "und", "wie", "hehr", "war", "die\u00b7se", "Ster\u00b7nen\u00b7nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "KON", "PWAV", "ADJD", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Eh ich des grossen Gedankens Flug,", "tokens": ["Eh", "ich", "des", "gros\u00b7sen", "Ge\u00b7dan\u00b7kens", "Flug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Eh ich es wagte, mich zu fragen:", "tokens": ["Eh", "ich", "es", "wag\u00b7te", ",", "mich", "zu", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Welche Thaten th\u00e4te dort oben der Herliche?", "tokens": ["Wel\u00b7che", "Tha\u00b7ten", "th\u00e4\u00b7te", "dort", "o\u00b7ben", "der", "Her\u00b7li\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+--+--+--", "measure": "trochaic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Mich, den Thoren! den Staub!", "tokens": ["Mich", ",", "den", "Tho\u00b7ren", "!", "den", "Staub", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ich f\u00fcrchtet', als ich zu fragen begann,", "tokens": ["Ich", "f\u00fcrch\u00b7tet'", ",", "als", "ich", "zu", "fra\u00b7gen", "be\u00b7gann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dass kommen w\u00fcrde, was gekommen ist.", "tokens": ["Dass", "kom\u00b7men", "w\u00fcr\u00b7de", ",", "was", "ge\u00b7kom\u00b7men", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VAFIN", "$,", "PRELS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich unterliege dem grossen Gedanken!", "tokens": ["Ich", "un\u00b7ter\u00b7lie\u00b7ge", "dem", "gros\u00b7sen", "Ge\u00b7dan\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Weniger k\u00fchn, hast, o Pilot,", "tokens": ["We\u00b7ni\u00b7ger", "k\u00fchn", ",", "hast", ",", "o", "Pi\u00b7lot", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "VAFIN", "$,", "FM", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Du gleiches Schicksal.", "tokens": ["Du", "glei\u00b7ches", "Schick\u00b7sal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Tr\u00fcb' an dem fernen Olymp", "tokens": ["Tr\u00fcb'", "an", "dem", "fer\u00b7nen", "O\u00b7lymp"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Sammeln sich Sturmwolken.", "tokens": ["Sam\u00b7meln", "sich", "Sturm\u00b7wol\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PRF", "NN", "$."], "meter": "+--+--", "measure": "dactylic.di.plus"}}, "stanza.17": {"line.1": {"text": "Jetzo ruht noch das Meer f\u00fcrchterlich still.", "tokens": ["Jet\u00b7zo", "ruht", "noch", "das", "Meer", "f\u00fcrch\u00b7ter\u00b7lich", "still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+--++--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Doch der Pilot weiss,", "tokens": ["Doch", "der", "Pi\u00b7lot", "weiss", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Welcher Sturm dort herdroht!", "tokens": ["Wel\u00b7cher", "Sturm", "dort", "her\u00b7droht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "ADV", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Und die eherne Brust bebt ihm,", "tokens": ["Und", "die", "e\u00b7her\u00b7ne", "Brust", "bebt", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "--+--+--", "measure": "anapaest.di.plus"}}, "stanza.18": {"line.1": {"text": "Er st\u00fcrzt an dem Maste", "tokens": ["Er", "st\u00fcrzt", "an", "dem", "Mas\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Bleich die Segel herab.", "tokens": ["Bleich", "die", "Se\u00b7gel", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "ADV", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ach! nun kr\u00e4uselt sich", "tokens": ["Ach", "!", "nun", "kr\u00e4u\u00b7selt", "sich"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "PRF"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Das Meer, und der Sturm ist da!", "tokens": ["Das", "Meer", ",", "und", "der", "Sturm", "ist", "da", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Donnernder rauscht der Ozean als du, schwarzer Olymp!", "tokens": ["Don\u00b7nern\u00b7der", "rauscht", "der", "O\u00b7ze\u00b7an", "als", "du", ",", "schwar\u00b7zer", "O\u00b7lymp", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "KOUS", "PPER", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Krachend st\u00fcrzet der Mast!", "tokens": ["Kra\u00b7chend", "st\u00fcr\u00b7zet", "der", "Mast", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Lautheulend zuckt der Sturm!", "tokens": ["Lau\u00b7theu\u00b7lend", "zuckt", "der", "Sturm", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Singt Todtengesang!", "tokens": ["Singt", "Tod\u00b7ten\u00b7ge\u00b7sang", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.20": {"line.1": {"text": "Der Pilot kennet ihn. Immer steigender hebst, Woge, du dich!", "tokens": ["Der", "Pi\u00b7lot", "ken\u00b7net", "ihn", ".", "Im\u00b7mer", "stei\u00b7gen\u00b7der", "hebst", ",", "Wo\u00b7ge", ",", "du", "dich", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "ADV", "ADJD", "VVFIN", "$,", "NN", "$,", "PPER", "PRF", "$."], "meter": "-+-+--+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Ach die letzte, letzte bist du! Das Schif geht unter!", "tokens": ["Ach", "die", "letz\u00b7te", ",", "letz\u00b7te", "bist", "du", "!", "Das", "Schif", "geht", "un\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ART", "ADJA", "$,", "ADJA", "VAFIN", "PPER", "$.", "ART", "NN", "VVFIN", "APPR", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und den Todtengesang heult dumpf fort", "tokens": ["Und", "den", "Tod\u00b7ten\u00b7ge\u00b7sang", "heult", "dumpf", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "PTKVZ"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Auf dem grossen, immer offenem Grabe der Sturm!", "tokens": ["Auf", "dem", "gros\u00b7sen", ",", "im\u00b7mer", "of\u00b7fe\u00b7nem", "Gra\u00b7be", "der", "Sturm", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "ADV", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}}}}}