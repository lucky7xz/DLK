{"dta.poem.13394": {"metadata": {"author": {"name": "Suppius, Christoph Eusebius", "birth": "N.A.", "death": "N.A."}, "title": "Die Kutsch-Pferde.  \n   \n  Die  \n  \u00fcber den ohnweit Hannover im Brach-  \n mond 1748 geschehenen ungl\u00fccklichen  \n Fall  \n  Sr. Freyherrl. Excellenz  \n Des Herrn Geheimden Raths  \n und Gro\u00dfvogts,  \n  B aron von  M \u00fcnchhausen,  \n als ihres mildesten Herrn und besten  \n Versorgers,  \n \u00e4usserst darnieder geschlagenen  \n  Pferde.  \n Aus der Sprache der Houyhnhmns \u00fcbersetzet  \n von  \n  Gulliver dem J\u00fcngern.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1749", "urn": "urn:nbn:de:kobv:b4-20594-7", "language": ["de:0.99"], "booktitle": "Suppius, Christoph Eusebius: Oden und Lieder. Gotha, 1749."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn Reue kann Vergebung finden,", "tokens": ["Wenn", "Reu\u00b7e", "kann", "Ver\u00b7ge\u00b7bung", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dafern auf nimmer Wiederthun,", "tokens": ["Da\u00b7fern", "auf", "nim\u00b7mer", "Wie\u00b7der\u00b7thun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach Abla\u00df der begangnen S\u00fcnden,", "tokens": ["Nach", "Ab\u00b7la\u00df", "der", "be\u00b7gang\u00b7nen", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein edelm\u00fcthig Herz kann ruhn;", "tokens": ["Ein", "e\u00b7del\u00b7m\u00fct\u00b7hig", "Herz", "kann", "ruhn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So kommen wir, die frechen Hengste,", "tokens": ["So", "kom\u00b7men", "wir", ",", "die", "fre\u00b7chen", "Hengs\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und wiehern nach Barmherzigkeit,", "tokens": ["Und", "wie\u00b7hern", "nach", "Barm\u00b7her\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Uns qv\u00e4len Millionen Aengste,", "tokens": ["Uns", "qv\u00e4\u00b7len", "Mil\u00b7lion\u00b7en", "A\u00b7engs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Was wir begangen, ist uns leid!", "tokens": ["Was", "wir", "be\u00b7gan\u00b7gen", ",", "ist", "uns", "leid", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wir, h\u00f6chst bedr\u00e4ngte Gegenst\u00e4nde", "tokens": ["Wir", ",", "h\u00f6chst", "be\u00b7dr\u00e4ng\u00b7te", "Ge\u00b7gen\u00b7st\u00e4n\u00b7de"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Donner, Blitz und manchem Fluch,", "tokens": ["Von", "Don\u00b7ner", ",", "Blitz", "und", "man\u00b7chem", "Fluch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind, durch der Speiser milde H\u00e4nde,", "tokens": ["Sind", ",", "durch", "der", "Spei\u00b7ser", "mil\u00b7de", "H\u00e4n\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Streichen itzt beschenkt genug;", "tokens": ["Mit", "Strei\u00b7chen", "itzt", "be\u00b7schenkt", "ge\u00b7nug", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sagen uns in ihrer Sprache,", "tokens": ["Sie", "sa\u00b7gen", "uns", "in", "ih\u00b7rer", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Pferde dennoch auch verstehn,", "tokens": ["Die", "Pfer\u00b7de", "den\u00b7noch", "auch", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir h\u00e4tten aus geheimer Rache", "tokens": ["Wir", "h\u00e4t\u00b7ten", "aus", "ge\u00b7hei\u00b7mer", "Ra\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit Dir gesuchet durch zu gehn.", "tokens": ["Mit", "Dir", "ge\u00b7su\u00b7chet", "durch", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch, Herr! die\u00df ist zu mild gesprochen,", "tokens": ["Doch", ",", "Herr", "!", "die\u00df", "ist", "zu", "mild", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$.", "PDS", "VAFIN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und heisset uns was angeklebt,", "tokens": ["Und", "heis\u00b7set", "uns", "was", "an\u00b7ge\u00b7klebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir haben nie so was verbrochen,", "tokens": ["Wir", "ha\u00b7ben", "nie", "so", "was", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So wahr das Pferd am Himmel lebt!", "tokens": ["So", "wahr", "das", "Pferd", "am", "Him\u00b7mel", "lebt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das ist am theuresten geschworen;", "tokens": ["Das", "ist", "am", "theu\u00b7res\u00b7ten", "ge\u00b7schwo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wo h\u00e4tten wir doch hin gewollt?", "tokens": ["Wo", "h\u00e4t\u00b7ten", "wir", "doch", "hin", "ge\u00b7wollt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "VMPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wer hat die Krippen gern verlohren,", "tokens": ["Wer", "hat", "die", "Krip\u00b7pen", "gern", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wo t\u00e4glich fetter Hafer rollt?", "tokens": ["Wo", "t\u00e4g\u00b7lich", "fet\u00b7ter", "Ha\u00b7fer", "rollt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Du bist bey alle dem so g\u00fctig,", "tokens": ["Du", "bist", "bey", "al\u00b7le", "dem", "so", "g\u00fc\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIS", "ART", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und immer ein so lieber Wirth,", "tokens": ["Und", "im\u00b7mer", "ein", "so", "lie\u00b7ber", "Wirth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df noch kein Thier sich \u00fcberm\u00fcthig", "tokens": ["Da\u00df", "noch", "kein", "Thier", "sich", "\u00fc\u00b7ber\u00b7m\u00fct\u00b7hig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIAT", "NN", "PRF", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In deinen Diensten aufgef\u00fchrt;", "tokens": ["In", "dei\u00b7nen", "Diens\u00b7ten", "auf\u00b7ge\u00b7f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie sollten wir uns so vergessen,", "tokens": ["Wie", "soll\u00b7ten", "wir", "uns", "so", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn wir Dich \u00fcbel heim gebracht!", "tokens": ["Wenn", "wir", "Dich", "\u00fc\u00b7bel", "heim", "ge\u00b7bracht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O dieses w\u00e4re zu vermessen,", "tokens": ["O", "die\u00b7ses", "w\u00e4\u00b7re", "zu", "ver\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDS", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und ziemlich schlecht von uns gedacht.", "tokens": ["Und", "ziem\u00b7lich", "schlecht", "von", "uns", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nein! Pferde wissen auch zu leben!", "tokens": ["Nein", "!", "Pfer\u00b7de", "wis\u00b7sen", "auch", "zu", "le\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So unvern\u00fcnftig sind wir nicht!", "tokens": ["So", "un\u00b7ver\u00b7n\u00fcnf\u00b7tig", "sind", "wir", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein folgsam r\u00fchmliches Bestreben", "tokens": ["Ein", "folg\u00b7sam", "r\u00fchm\u00b7li\u00b7ches", "Be\u00b7stre\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist bey uns die h\u00f6chste Pflicht;", "tokens": ["Das", "ist", "bey", "uns", "die", "h\u00f6chs\u00b7te", "Pflicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Es hat sich zwar in Eselsk\u00f6pfen", "tokens": ["Es", "hat", "sich", "zwar", "in", "E\u00b7sels\u00b7k\u00f6p\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Uebermuth oft stolz gezeigt,", "tokens": ["Der", "Ue\u00b7ber\u00b7muth", "oft", "stolz", "ge\u00b7zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Auch sagt man, unter den Gesch\u00f6pfen", "tokens": ["Auch", "sagt", "man", ",", "un\u00b7ter", "den", "Ge\u00b7sch\u00f6p\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sind Pferde sehr dazu geneigt.", "tokens": ["Sind", "Pfer\u00b7de", "sehr", "da\u00b7zu", "ge\u00b7neigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch solches sind nur L\u00e4sterungen,", "tokens": ["Doch", "sol\u00b7ches", "sind", "nur", "L\u00e4s\u00b7te\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von manchem schlechten Karrengaul,", "tokens": ["Von", "man\u00b7chem", "schlech\u00b7ten", "Kar\u00b7ren\u00b7gaul", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was sich nie aus dem Staub geschwungen,", "tokens": ["Was", "sich", "nie", "aus", "dem", "Staub", "ge\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Hat \u00fcber uns das gr\u00f6\u00dfste Maul;", "tokens": ["Hat", "\u00fc\u00b7ber", "uns", "das", "gr\u00f6\u00df\u00b7ste", "Maul", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bucephalus zeigt auch in Mienen,", "tokens": ["Bu\u00b7ce\u00b7pha\u00b7lus", "zeigt", "auch", "in", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Da\u00df er den Alexander tr\u00e4gt;", "tokens": ["Da\u00df", "er", "den", "A\u00b7lex\u00b7an\u00b7der", "tr\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wer hat, wenn wir zu muthig schienen,", "tokens": ["Wer", "hat", ",", "wenn", "wir", "zu", "mut\u00b7hig", "schie\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "KOUS", "PPER", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Uns sonst, als Du, dazu bewegt?", "tokens": ["Uns", "sonst", ",", "als", "Du", ",", "da\u00b7zu", "be\u00b7wegt", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "KOUS", "PPER", "$,", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "O Gn\u00e4diger! Du wirst verg\u00f6nnen,", "tokens": ["O", "Gn\u00e4\u00b7di\u00b7ger", "!", "Du", "wirst", "ver\u00b7g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PPER", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Wahrheit ewig treu zu seyn;", "tokens": ["Der", "Wahr\u00b7heit", "e\u00b7wig", "treu", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nie werden wir es l\u00e4ugnen k\u00f6nnen,", "tokens": ["Nie", "wer\u00b7den", "wir", "es", "l\u00e4ug\u00b7nen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir bilden uns auf Dich was ein,", "tokens": ["Wir", "bil\u00b7den", "uns", "auf", "Dich", "was", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur ausgenommen, was in St\u00e4llen", "tokens": ["Nur", "aus\u00b7ge\u00b7nom\u00b7men", ",", "was", "in", "St\u00e4l\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVPP", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Des Gottes dieser Lande zehrt:", "tokens": ["Des", "Got\u00b7tes", "die\u00b7ser", "Lan\u00b7de", "zehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Jedoch in allen andern F\u00e4llen", "tokens": ["Je\u00b7doch", "in", "al\u00b7len", "an\u00b7dern", "F\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sind wir zwiefacher Ehren werth.", "tokens": ["Sind", "wir", "zwie\u00b7fac\u00b7her", "Eh\u00b7ren", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Kein andrer L\u00e4ufer oder Springer", "tokens": ["Kein", "an\u00b7drer", "L\u00e4u\u00b7fer", "o\u00b7der", "Sprin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Versuch und nehm es mit uns auf!", "tokens": ["Ver\u00b7such", "und", "nehm", "es", "mit", "uns", "auf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was wollten doch die armen J\u00fcnger,", "tokens": ["Was", "woll\u00b7ten", "doch", "die", "ar\u00b7men", "J\u00fcn\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Versuchten sie doch einen Lauf.", "tokens": ["Ver\u00b7such\u00b7ten", "sie", "doch", "ei\u00b7nen", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man kann sich sicher drauf verlassen,", "tokens": ["Man", "kann", "sich", "si\u00b7cher", "drauf", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADJD", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was es mit Dir zu sagen hat;", "tokens": ["Was", "es", "mit", "Dir", "zu", "sa\u00b7gen", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo man uns sieht, auf allen Strassen,", "tokens": ["Wo", "man", "uns", "sieht", ",", "auf", "al\u00b7len", "Stras\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da spricht man sich von Dir nicht satt.", "tokens": ["Da", "spricht", "man", "sich", "von", "Dir", "nicht", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "APPR", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "J\u00fcngst ziehn wir Dich nach jener Gegend,", "tokens": ["J\u00fcngst", "ziehn", "wir", "Dich", "nach", "je\u00b7ner", "Ge\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die nur zu Zeiten so belebt,", "tokens": ["Die", "nur", "zu", "Zei\u00b7ten", "so", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn sie der Landesvater segent,", "tokens": ["Wenn", "sie", "der", "Lan\u00b7des\u00b7va\u00b7ter", "se\u00b7gent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "Der sich, ach! weit dahin erhebt,", "tokens": ["Der", "sich", ",", "ach", "!", "weit", "da\u00b7hin", "er\u00b7hebt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "$,", "ITJ", "$.", "ADJD", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du bist uns sonsten zwar tagt\u00e4glich", "tokens": ["Du", "bist", "uns", "sons\u00b7ten", "zwar", "tag\u00b7t\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die allerangenehmste Last,", "tokens": ["Die", "al\u00b7ler\u00b7an\u00b7ge\u00b7nehms\u00b7te", "Last", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch die\u00dfmahl war es uns ohnm\u00f6glich,", "tokens": ["Doch", "die\u00df\u00b7mahl", "war", "es", "uns", "ohn\u00b7m\u00f6g\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "F\u00fcr Wohllust kollerten wir fast.", "tokens": ["F\u00fcr", "Wohl\u00b7lust", "kol\u00b7ler\u00b7ten", "wir", "fast", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.10": {"line.1": {"text": "O was f\u00fcr Leute! welche Menge", "tokens": ["O", "was", "f\u00fcr", "Leu\u00b7te", "!", "wel\u00b7che", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "PWS", "APPR", "NN", "$.", "PWAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zog nicht des Landes Herrgott her!", "tokens": ["Zog", "nicht", "des", "Lan\u00b7des", "Herr\u00b7gott", "her", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vor allem murmelnden Gedr\u00e4nge", "tokens": ["Vor", "al\u00b7lem", "mur\u00b7meln\u00b7den", "Ge\u00b7dr\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War uns sogar der Durchzug schwer,", "tokens": ["War", "uns", "so\u00b7gar", "der", "Durch\u00b7zug", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Jetzt schreckt sie unser Schnauben wenig,", "tokens": ["Jetzt", "schreckt", "sie", "un\u00b7ser", "Schnau\u00b7ben", "we\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn sie erf\u00fcllt nur eine Lust,", "tokens": ["Denn", "sie", "er\u00b7f\u00fcllt", "nur", "ei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kaum siehet sie den grossen K\u00f6nig,", "tokens": ["Kaum", "sie\u00b7het", "sie", "den", "gros\u00b7sen", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So ist ihr Preis Georg August.", "tokens": ["So", "ist", "ihr", "Preis", "Ge\u00b7org", "Au\u00b7gust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Zwar wiehern wir: Weicht aus, ihr Leute!", "tokens": ["Zwar", "wie\u00b7hern", "wir", ":", "Weicht", "aus", ",", "ihr", "Leu\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NN", "PTKVZ", "$,", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Jhr Herrn, zur\u00fcck! doch ist kein Platz;", "tokens": ["Ihr", "Herrn", ",", "zu\u00b7r\u00fcck", "!", "doch", "ist", "kein", "Platz", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PTKVZ", "$.", "ADV", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir schielen trotzig von der Seite,", "tokens": ["Wir", "schie\u00b7len", "trot\u00b7zig", "von", "der", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Versuchen manchen k\u00fchnen Satz;", "tokens": ["Ver\u00b7su\u00b7chen", "man\u00b7chen", "k\u00fch\u00b7nen", "Satz", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Damit mu\u00df es denn noch gelingen,", "tokens": ["Da\u00b7mit", "mu\u00df", "es", "denn", "noch", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Da\u00df man uns eine Bahne macht,", "tokens": ["Da\u00df", "man", "uns", "ei\u00b7ne", "Bah\u00b7ne", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bis an den Vorhof durchzudringen,", "tokens": ["Bis", "an", "den", "Vor\u00b7hof", "durch\u00b7zu\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wohin wir Dich schon oft gebracht.", "tokens": ["Wo\u00b7hin", "wir", "Dich", "schon", "oft", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Auf beyden Seiten stehn wie W\u00e4nde", "tokens": ["Auf", "bey\u00b7den", "Sei\u00b7ten", "stehn", "wie", "W\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVINF", "KOKOM", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Menschen ganz bis an das Thor,", "tokens": ["Die", "Men\u00b7schen", "ganz", "bis", "an", "das", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Theils heben segnend ihre H\u00e4nde,", "tokens": ["Theils", "he\u00b7ben", "seg\u00b7nend", "ih\u00b7re", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Theils strecken sie den Hals empor,", "tokens": ["Theils", "stre\u00b7cken", "sie", "den", "Hals", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Volk, und Leute von Verstande,", "tokens": ["Das", "Volk", ",", "und", "Leu\u00b7te", "von", "Ver\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die sagten, als sie Dich gesehn:", "tokens": ["Die", "sag\u00b7ten", ",", "als", "sie", "Dich", "ge\u00b7sehn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es ist der Joseph hier im Lande!", "tokens": ["Es", "ist", "der", "Jo\u00b7se\u00b7ph", "hier", "im", "Lan\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ein Herr \u2012 \u2012! es mu\u00df ihm wohl ergehn!", "tokens": ["Ein", "Herr", "\u2012", "\u2012", "!", "es", "mu\u00df", "ihm", "wohl", "er\u00b7gehn", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "$(", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Er hilft Bedr\u00e4ngten, sch\u00fctzt die Waysen,", "tokens": ["Er", "hilft", "Be\u00b7dr\u00e4ng\u00b7ten", ",", "sch\u00fctzt", "die", "Way\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Wittwen Sachen sind im Werth,", "tokens": ["Der", "Witt\u00b7wen", "Sa\u00b7chen", "sind", "im", "Werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Landvolk ruft: Er ist zu preisen,", "tokens": ["Das", "Land\u00b7volk", "ruft", ":", "Er", "ist", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn h\u00e4tt er wohl das Land beschwert?", "tokens": ["Wenn", "h\u00e4tt", "er", "wohl", "das", "Land", "be\u00b7schwert", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir h\u00f6rten mehr, von allen Leuten,", "tokens": ["Wir", "h\u00f6r\u00b7ten", "mehr", ",", "von", "al\u00b7len", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es war kein schmeichlerischer Ton,", "tokens": ["Es", "war", "kein", "schmeich\u00b7le\u00b7ri\u00b7scher", "Ton", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Von dem Saturn, von g\u00fcldnen Zeiten,", "tokens": ["Von", "dem", "Sa\u00b7turn", ",", "von", "g\u00fcld\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zwar, was versteht ein Pferd davon?", "tokens": ["Zwar", ",", "was", "ver\u00b7steht", "ein", "Pferd", "da\u00b7von", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie r\u00fchmten hochgelahrte M\u00e4nner", "tokens": ["Wie", "r\u00fchm\u00b7ten", "hoch\u00b7ge\u00b7lahr\u00b7te", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dich, nach verehrter Gegenwart,", "tokens": ["Dich", ",", "nach", "ver\u00b7ehr\u00b7ter", "Ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ganz heimlich als den feinsten Kenner", "tokens": ["Ganz", "heim\u00b7lich", "als", "den", "feins\u00b7ten", "Ken\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Creaturen ihrer Art!", "tokens": ["Von", "Crea\u00b7tu\u00b7ren", "ih\u00b7rer", "Art", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du liessest Wissenschaften rufen,", "tokens": ["Du", "lies\u00b7sest", "Wis\u00b7sen\u00b7schaf\u00b7ten", "ru\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es s\u00e4he sich der Flei\u00df belohnt;", "tokens": ["Es", "s\u00e4\u00b7he", "sich", "der", "Flei\u00df", "be\u00b7lohnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie beydes denn auf Ehrenstufen", "tokens": ["Wie", "bey\u00b7des", "denn", "auf", "Eh\u00b7ren\u00b7stu\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Jm weissen Ro\u00df von Deutschland wohnt.", "tokens": ["Jm", "weis\u00b7sen", "Ro\u00df", "von", "Deutschland", "wohnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wie will ein Pferd doch alles merken,", "tokens": ["Wie", "will", "ein", "Pferd", "doch", "al\u00b7les", "mer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir haben nie den Kopf beschwert;", "tokens": ["Wir", "ha\u00b7ben", "nie", "den", "Kopf", "be\u00b7schwert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist so gro\u00df in Thun und Werken,", "tokens": ["Du", "bist", "so", "gro\u00df", "in", "Thun", "und", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df man sein rechtes Wunder h\u00f6rt;", "tokens": ["Da\u00df", "man", "sein", "rech\u00b7tes", "Wun\u00b7der", "h\u00f6rt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Soll das nicht unser Herz ergetzen?", "tokens": ["Soll", "das", "nicht", "un\u00b7ser", "Herz", "er\u00b7get\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Macht es nicht w\u00e4hlig und geschwind", "tokens": ["Macht", "es", "nicht", "w\u00e4h\u00b7lig", "und", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "ADJD", "KON", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Die wir uns so schon gl\u00fccklich sch\u00e4tzen,", "tokens": ["Die", "wir", "uns", "so", "schon", "gl\u00fcck\u00b7lich", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df wir an deiner Krippe sind.", "tokens": ["Da\u00df", "wir", "an", "dei\u00b7ner", "Krip\u00b7pe", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Hier\u00fcber w\u00fchlten wir in Steinen", "tokens": ["Hier\u00b7\u00fc\u00b7ber", "w\u00fchl\u00b7ten", "wir", "in", "Stei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und waren an Gedanken reich,", "tokens": ["Und", "wa\u00b7ren", "an", "Ge\u00b7dan\u00b7ken", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun mochtest du zur\u00fcck erscheinen,", "tokens": ["Nun", "moch\u00b7test", "du", "zu\u00b7r\u00fcck", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gnug, wir bekamen einen Streich;", "tokens": ["Gnug", ",", "wir", "be\u00b7ka\u00b7men", "ei\u00b7nen", "Streich", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Schrecken kommt oft ungelegen,", "tokens": ["Das", "Schre\u00b7cken", "kommt", "oft", "un\u00b7ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Pferd hat seinen Eigensinn;", "tokens": ["Ein", "Pferd", "hat", "sei\u00b7nen", "Ei\u00b7gen\u00b7sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Du warest wirklich bald zugegen,", "tokens": ["Du", "wa\u00b7rest", "wirk\u00b7lich", "bald", "zu\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da gieng es nach Hannover hin.", "tokens": ["Da", "gieng", "es", "nach", "Han\u00b7no\u00b7ver", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.17": {"line.1": {"text": "Nun dachten wir durch schnelle Dienste", "tokens": ["Nun", "dach\u00b7ten", "wir", "durch", "schnel\u00b7le", "Diens\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nur deiner Gnade werth zu seyn,", "tokens": ["Nur", "dei\u00b7ner", "Gna\u00b7de", "werth", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gebrauchten folglich alle K\u00fcnste,", "tokens": ["Ge\u00b7brauch\u00b7ten", "folg\u00b7lich", "al\u00b7le", "K\u00fcns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja rannten endlich qver feldein;", "tokens": ["Ja", "rann\u00b7ten", "end\u00b7lich", "qver", "feld\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir dachten so, wie Pferde denken,", "tokens": ["Wir", "dach\u00b7ten", "so", ",", "wie", "Pfer\u00b7de", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist ein Herr! der hat zu thun!", "tokens": ["Das", "ist", "ein", "Herr", "!", "der", "hat", "zu", "thun", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "ART", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und liessen uns nicht weiter lenken", "tokens": ["Und", "lies\u00b7sen", "uns", "nicht", "wei\u00b7ter", "len\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von selbst wohl wissend, wo zu ruhn.", "tokens": ["Von", "selbst", "wohl", "wis\u00b7send", ",", "wo", "zu", "ruhn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "VVPP", "$,", "PWAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "O lieber Herr! wenn unsre Klauen", "tokens": ["O", "lie\u00b7ber", "Herr", "!", "wenn", "uns\u00b7re", "Klau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "ADV", "NN", "$.", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Uns die\u00dfmahl doch den Dienst versagt,", "tokens": ["Uns", "die\u00df\u00b7mahl", "doch", "den", "Dienst", "ver\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bevor dein minderes Vertrauen", "tokens": ["Be\u00b7vor", "dein", "min\u00b7de\u00b7res", "Ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu uns den Ungl\u00fccks-Sprung gewagt!", "tokens": ["Zu", "uns", "den", "Un\u00b7gl\u00fccks\u00b7Sprung", "ge\u00b7wagt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was hilft die Warnungs-Stimme Pferden;", "tokens": ["Was", "hilft", "die", "War\u00b7nungs\u00b7Stim\u00b7me", "Pfer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df Eilen \u00f6fters sch\u00e4dlich ist,", "tokens": ["Da\u00df", "Ei\u00b7len", "\u00f6f\u00b7ters", "sch\u00e4d\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es kann nicht mehr ge\u00e4ndert werden,", "tokens": ["Es", "kann", "nicht", "mehr", "ge\u00b7\u00e4n\u00b7dert", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So lange du nicht besser bist.", "tokens": ["So", "lan\u00b7ge", "du", "nicht", "bes\u00b7ser", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PTKNEG", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Nun sind wir wider unsern Willen", "tokens": ["Nun", "sind", "wir", "wi\u00b7der", "un\u00b7sern", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An deinem grossen Unfall schuld.", "tokens": ["An", "dei\u00b7nem", "gros\u00b7sen", "Un\u00b7fall", "schuld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Unmuth l\u00e4sset sich nicht stillen,", "tokens": ["Der", "Un\u00b7muth", "l\u00e4s\u00b7set", "sich", "nicht", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er treibt uns bis zur Ungeduld!", "tokens": ["Er", "treibt", "uns", "bis", "zur", "Un\u00b7ge\u00b7duld", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der beste Herr, den wir verehren,", "tokens": ["Der", "bes\u00b7te", "Herr", ",", "den", "wir", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist unter der Centauren Hand,", "tokens": ["Ist", "un\u00b7ter", "der", "Cen\u00b7tau\u00b7ren", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was m\u00fcssen wir vor Fl\u00fcche h\u00f6ren!", "tokens": ["Was", "m\u00fcs\u00b7sen", "wir", "vor", "Fl\u00fc\u00b7che", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ach! uns verw\u00fcnschen Stadt und Land.", "tokens": ["Ach", "!", "uns", "ver\u00b7w\u00fcn\u00b7schen", "Stadt", "und", "Land", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Doch Herr! vergieb es deinen Hengsten!", "tokens": ["Doch", "Herr", "!", "ver\u00b7gieb", "es", "dei\u00b7nen", "Hengs\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du ahndest sonst so leichte nicht.", "tokens": ["Du", "ahn\u00b7dest", "sonst", "so", "leich\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJA", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir sind bestraft! wir stehn in Aengsten,", "tokens": ["Wir", "sind", "be\u00b7straft", "!", "wir", "stehn", "in", "A\u00b7engs\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "PPER", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und wer erblickt dein Angesicht?", "tokens": ["Und", "wer", "er\u00b7blickt", "dein", "An\u00b7ge\u00b7sicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Geschwindigkeit wird unter Rossen", "tokens": ["Ge\u00b7schwin\u00b7dig\u00b7keit", "wird", "un\u00b7ter", "Ros\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ja sonst der Tugend beygez\u00e4hlt,", "tokens": ["Ja", "sonst", "der", "Tu\u00b7gend", "bey\u00b7ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Woran es oftmals denen Grossen", "tokens": ["Wo\u00b7ran", "es", "oft\u00b7mals", "de\u00b7nen", "Gros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "PDS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von unsrer Nation gefehlt.", "tokens": ["Von", "uns\u00b7rer", "Na\u00b7tion", "ge\u00b7fehlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Du wirst ja jenes Eyland kennen,", "tokens": ["Du", "wirst", "ja", "je\u00b7nes", "Ey\u00b7land", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Gott herrscht hier und dort zugleich,", "tokens": ["Ein", "Gott", "herrscht", "hier", "und", "dort", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da macht noch itzt manch Pferd durch Rennen", "tokens": ["Da", "macht", "noch", "itzt", "manch", "Pferd", "durch", "Ren\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PIAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Oft seinen Herrn wer wei\u00df wie reich;", "tokens": ["Oft", "sei\u00b7nen", "Herrn", "wer", "wei\u00df", "wie", "reich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PWS", "VVFIN", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Pferde-Tageb\u00fccher melden", "tokens": ["Die", "Pfer\u00b7de\u00b7Ta\u00b7ge\u00b7b\u00fc\u00b7cher", "mel\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von einer grossen Tiber-Stadt,", "tokens": ["Von", "ei\u00b7ner", "gros\u00b7sen", "Ti\u00b7ber\u00b7Stadt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df man von schnellen Pferde-Helden", "tokens": ["Da\u00df", "man", "von", "schnel\u00b7len", "Pfer\u00b7de\u00b7Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Daselbst auch Ueberwinder hat.", "tokens": ["Da\u00b7selbst", "auch", "Ue\u00b7ber\u00b7win\u00b7der", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Es steht in unsern Zeit-Geschichten", "tokens": ["Es", "steht", "in", "un\u00b7sern", "Zeit\u00b7Ge\u00b7schich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von einer alten alten Zeit,", "tokens": ["Von", "ei\u00b7ner", "al\u00b7ten", "al\u00b7ten", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Pferde-Rennen gab zu dichten", "tokens": ["Das", "Pfer\u00b7de\u00b7Ren\u00b7nen", "gab", "zu", "dich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vier Jahr einmahl Gelegenheit,", "tokens": ["Vier", "Jahr", "ein\u00b7mahl", "Ge\u00b7le\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Griechen nennten solches Spiele,", "tokens": ["Die", "Grie\u00b7chen", "nenn\u00b7ten", "sol\u00b7ches", "Spie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und sassen stets sehr ernsthaft da,", "tokens": ["Und", "sas\u00b7sen", "stets", "sehr", "ernst\u00b7haft", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch starb so mancher Gaul am Ziele", "tokens": ["Doch", "starb", "so", "man\u00b7cher", "Gaul", "am", "Zie\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als Helden vor die Helena.", "tokens": ["Als", "Hel\u00b7den", "vor", "die", "He\u00b7le\u00b7na", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Die Pferde waren Ueberwinder", "tokens": ["Die", "Pfer\u00b7de", "wa\u00b7ren", "Ue\u00b7ber\u00b7win\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und doch bekam ein Mann den Prei\u00df,", "tokens": ["Und", "doch", "be\u00b7kam", "ein", "Mann", "den", "Prei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr sie war Hafer viel ges\u00fcnder", "tokens": ["F\u00fcr", "sie", "war", "Ha\u00b7fer", "viel", "ge\u00b7s\u00fcn\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VAFIN", "NN", "PIAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als oft f\u00fcr ihn das gr\u00fcne Rei\u00df,", "tokens": ["Als", "oft", "f\u00fcr", "ihn", "das", "gr\u00fc\u00b7ne", "Rei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn wenn die Renner doppelt frassen,", "tokens": ["Denn", "wenn", "die", "Ren\u00b7ner", "dop\u00b7pelt", "fras\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ward ihnen neuer Muth gebracht;", "tokens": ["Ward", "ih\u00b7nen", "neu\u00b7er", "Muth", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch kann der Mensch sich \u00f6fters fassen,", "tokens": ["Doch", "kann", "der", "Mensch", "sich", "\u00f6f\u00b7ters", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem nur ein Zufall Ehre macht?", "tokens": ["Dem", "nur", "ein", "Zu\u00b7fall", "Eh\u00b7re", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Zur Zeit, als selbsten noch die G\u00f6tter", "tokens": ["Zur", "Zeit", ",", "als", "selbs\u00b7ten", "noch", "die", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Staats-Karossen angespannt,", "tokens": ["Die", "Staats\u00b7Ka\u00b7ros\u00b7sen", "an\u00b7ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist auch Neptun als wie ein Wetter", "tokens": ["Ist", "auch", "Nep\u00b7tun", "als", "wie", "ein", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "NN", "KOUS", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Einmahl vor Jlium gerannt;", "tokens": ["Ein\u00b7mahl", "vor", "Jlium", "ge\u00b7rannt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Homer, der uns an vielen Stellen", "tokens": ["Ho\u00b7mer", ",", "der", "uns", "an", "vie\u00b7len", "Stel\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN"], "meter": "+-+----+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "So sch\u00f6n geschildert, zeigt es ja;", "tokens": ["So", "sch\u00f6n", "ge\u00b7schil\u00b7dert", ",", "zeigt", "es", "ja", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Er f\u00e4hret ab, rollt \u00fcber Wellen,", "tokens": ["Er", "f\u00e4h\u00b7ret", "ab", ",", "rollt", "\u00fc\u00b7ber", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weit ist der Weg, nun ist er da.", "tokens": ["Weit", "ist", "der", "Weg", ",", "nun", "ist", "er", "da", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Was alle Zeiten von uns r\u00fchmen,", "tokens": ["Was", "al\u00b7le", "Zei\u00b7ten", "von", "uns", "r\u00fch\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was Pferden Preis und Ehre bringt,", "tokens": ["Was", "Pfer\u00b7den", "Preis", "und", "Eh\u00b7re", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das soll allein uns nicht geziemen,", "tokens": ["Das", "soll", "al\u00b7lein", "uns", "nicht", "ge\u00b7zie\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die allemahl dein Ruhm verj\u00fcngt?", "tokens": ["Die", "al\u00b7le\u00b7mahl", "dein", "Ruhm", "ver\u00b7j\u00fcngt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bey welchem wir die Ohren spitzen,", "tokens": ["Bey", "wel\u00b7chem", "wir", "die", "Oh\u00b7ren", "spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die K\u00f6pfe recht vern\u00fcnftig drehn,", "tokens": ["Die", "K\u00f6p\u00b7fe", "recht", "ver\u00b7n\u00fcnf\u00b7tig", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Auch sonst Gelassenheit besitzen,", "tokens": ["Auch", "sonst", "Ge\u00b7las\u00b7sen\u00b7heit", "be\u00b7sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df wir auf einen Tonlaut stehn!", "tokens": ["Da\u00df", "wir", "auf", "ei\u00b7nen", "Ton\u00b7laut", "stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Die Neueren und auch die Alten", "tokens": ["Die", "Neu\u00b7e\u00b7ren", "und", "auch", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erkannten diesen unsern Werth;", "tokens": ["Er\u00b7kann\u00b7ten", "die\u00b7sen", "un\u00b7sern", "Werth", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was jener Ritter hochgehalten,", "tokens": ["Was", "je\u00b7ner", "Rit\u00b7ter", "hoch\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War Rossinant, hernach das Schwerd,", "tokens": ["War", "Ros\u00b7si\u00b7nant", ",", "her\u00b7nach", "das", "Schwerd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kann eine Tugend auch verj\u00e4hren,", "tokens": ["Kann", "ei\u00b7ne", "Tu\u00b7gend", "auch", "ver\u00b7j\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und achtet man sie nicht mehr hoch:", "tokens": ["Und", "ach\u00b7tet", "man", "sie", "nicht", "mehr", "hoch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So seyd ihr gl\u00fccklich, faule M\u00e4hren,", "tokens": ["So", "seyd", "ihr", "gl\u00fcck\u00b7lich", ",", "fau\u00b7le", "M\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bey Peitsche, Hexel, Karn und Joch!", "tokens": ["Bey", "Peit\u00b7sche", ",", "He\u00b7xel", ",", "Karn", "und", "Joch", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Herr! Deinen Zorn von uns zu lenken,", "tokens": ["Herr", "!", "Dei\u00b7nen", "Zorn", "von", "uns", "zu", "len\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPOSAT", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat die\u00df die Nothwehr beygebracht,", "tokens": ["Hat", "die\u00df", "die", "Noth\u00b7wehr", "bey\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu zeigen, da\u00df wir nicht so denken,", "tokens": ["Zu", "zei\u00b7gen", ",", "da\u00df", "wir", "nicht", "so", "den\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als man uns zum Verbrechen macht;", "tokens": ["Als", "man", "uns", "zum", "Ver\u00b7bre\u00b7chen", "macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df wir es vielleicht verdienen,", "tokens": ["Und", "da\u00df", "wir", "es", "viel\u00b7leicht", "ver\u00b7die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Wenn man uns dir recht h\u00e4\u00dflich malt;", "tokens": ["Wenn", "man", "uns", "dir", "recht", "h\u00e4\u00df\u00b7lich", "malt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verleumdung ist dir nie erschienen,", "tokens": ["Ver\u00b7leum\u00b7dung", "ist", "dir", "nie", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Du hast sie allzeit schlecht bezahlt.", "tokens": ["Du", "hast", "sie", "all\u00b7zeit", "schlecht", "be\u00b7zahlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Wenn wir indessen was beklagen,", "tokens": ["Wenn", "wir", "in\u00b7des\u00b7sen", "was", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So ist es, Herr! Dein Ungemach!", "tokens": ["So", "ist", "es", ",", "Herr", "!", "Dein", "Un\u00b7ge\u00b7mach", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir stehn, wie vor den Kopf geschlagen,", "tokens": ["Wir", "stehn", ",", "wie", "vor", "den", "Kopf", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Stall ert\u00f6nt von lauter Ach!", "tokens": ["Dein", "Stall", "er\u00b7t\u00f6nt", "von", "lau\u00b7ter", "Ach", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Uns lasse dich bald wieder blicken", "tokens": ["Uns", "las\u00b7se", "dich", "bald", "wie\u00b7der", "bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein grosser Geist der Heilungskunst,", "tokens": ["Ein", "gros\u00b7ser", "Geist", "der", "Hei\u00b7lungs\u00b7kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So ziehen wir mit ganzem R\u00fccken", "tokens": ["So", "zie\u00b7hen", "wir", "mit", "gan\u00b7zem", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hinfort an deiner Gnad und Gunst.", "tokens": ["Hin\u00b7fort", "an", "dei\u00b7ner", "Gnad", "und", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Nur dieses noch heischt Flehn und Bitten,", "tokens": ["Nur", "die\u00b7ses", "noch", "heischt", "Flehn", "und", "Bit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADV", "ADJD", "VVINF", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vergi\u00df hinfort der Missethat!", "tokens": ["Ver\u00b7gi\u00df", "hin\u00b7fort", "der", "Mis\u00b7se\u00b7that", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den aus der Art geschlagnen Tritten,", "tokens": ["Den", "aus", "der", "Art", "ge\u00b7schlag\u00b7nen", "Trit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die schon dein Zug verbessert hat;", "tokens": ["Die", "schon", "dein", "Zug", "ver\u00b7bes\u00b7sert", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dir unsre Noth selbst vorzutragen,", "tokens": ["Dir", "uns\u00b7re", "Noth", "selbst", "vor\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00e4llt unsrer Mundart viel zu schwer,", "tokens": ["F\u00e4llt", "uns\u00b7rer", "Mund\u00b7art", "viel", "zu", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch, was wir hier mit Ehrfurcht sagen,", "tokens": ["Doch", ",", "was", "wir", "hier", "mit", "Ehr\u00b7furcht", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Verdeutschet uns ein Gulliver.", "tokens": ["Ver\u00b7deut\u00b7schet", "uns", "ein", "Gul\u00b7li\u00b7ver", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}