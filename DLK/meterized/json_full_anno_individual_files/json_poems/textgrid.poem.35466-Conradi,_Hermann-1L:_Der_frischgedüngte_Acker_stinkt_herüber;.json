{"textgrid.poem.35466": {"metadata": {"author": {"name": "Conradi, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der frischged\u00fcngte Acker stinkt her\u00fcber;", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der frischged\u00fcngte Acker stinkt her\u00fcber;", "tokens": ["Der", "frischge\u00b7d\u00fcng\u00b7te", "A\u00b7cker", "stinkt", "her\u00b7\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-++-+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Braunrotes Land nickt \u00fcber die Stackete,", "tokens": ["Braun\u00b7ro\u00b7tes", "Land", "nickt", "\u00fc\u00b7ber", "die", "Sta\u00b7cke\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die letzten Astern k\u00fcmmern auf dem Beete \u2013", "tokens": ["Die", "letz\u00b7ten", "As\u00b7tern", "k\u00fcm\u00b7mern", "auf", "dem", "Bee\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und t\u00e4glich wird der Himmel tr\u00fcb und tr\u00fcber.", "tokens": ["Und", "t\u00e4g\u00b7lich", "wird", "der", "Him\u00b7mel", "tr\u00fcb", "und", "tr\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Aus der Spelunke jagte mich das Fieber", "tokens": ["Aus", "der", "Spe\u00b7lun\u00b7ke", "jag\u00b7te", "mich", "das", "Fie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und warf auf meine Backen grelle R\u00f6te.", "tokens": ["Und", "warf", "auf", "mei\u00b7ne", "Ba\u00b7cken", "grel\u00b7le", "R\u00f6\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.4": {"text": "Wie sie heut wieder br\u00fcnstig k\u00fc\u00dfte, flehte:", "tokens": ["Wie", "sie", "heut", "wie\u00b7der", "br\u00fcns\u00b7tig", "k\u00fc\u00df\u00b7te", ",", "fleh\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich m\u00f6chte wiederkommen! Viel, viel lieber", "tokens": ["Ich", "m\u00f6ch\u00b7te", "wie\u00b7der\u00b7kom\u00b7men", "!", "Viel", ",", "viel", "lie\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "ADV", "$,", "ADV", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sei ihr die Nacht! ... Denn, w\u00e4r' der Tag zu R\u00fcste,", "tokens": ["Sei", "ihr", "die", "Nacht", "!", "...", "Denn", ",", "w\u00e4r'", "der", "Tag", "zu", "R\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$.", "$(", "KON", "$,", "VAFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dann spr\u00e4ngen hei\u00dfer all die s\u00fc\u00dfen L\u00fcste", "tokens": ["Dann", "spr\u00e4n\u00b7gen", "hei\u00b7\u00dfer", "all", "die", "s\u00fc\u00b7\u00dfen", "L\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und s\u00fc\u00dfer sei das Indenarmenliegen! ...", "tokens": ["Und", "s\u00fc\u00b7\u00dfer", "sei", "das", "In\u00b7de\u00b7nar\u00b7men\u00b7lie\u00b7gen", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}}, "stanza.4": {"line.1": {"text": "Der frischged\u00fcngte Acker stinkt emp\u00f6rend, \u2013", "tokens": ["Der", "frischge\u00b7d\u00fcng\u00b7te", "A\u00b7cker", "stinkt", "em\u00b7p\u00f6\u00b7rend", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "$,", "$("], "meter": "-++-+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Doch ist sein Stunk nicht grade unbelehrend:", "tokens": ["Doch", "ist", "sein", "Stunk", "nicht", "gra\u00b7de", "un\u00b7be\u00b7leh\u00b7rend", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Der frischged\u00fcngte Acker stinkt her\u00fcber;", "tokens": ["Der", "frischge\u00b7d\u00fcng\u00b7te", "A\u00b7cker", "stinkt", "her\u00b7\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-++-+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Braunrotes Land nickt \u00fcber die Stackete,", "tokens": ["Braun\u00b7ro\u00b7tes", "Land", "nickt", "\u00fc\u00b7ber", "die", "Sta\u00b7cke\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die letzten Astern k\u00fcmmern auf dem Beete \u2013", "tokens": ["Die", "letz\u00b7ten", "As\u00b7tern", "k\u00fcm\u00b7mern", "auf", "dem", "Bee\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und t\u00e4glich wird der Himmel tr\u00fcb und tr\u00fcber.", "tokens": ["Und", "t\u00e4g\u00b7lich", "wird", "der", "Him\u00b7mel", "tr\u00fcb", "und", "tr\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Aus der Spelunke jagte mich das Fieber", "tokens": ["Aus", "der", "Spe\u00b7lun\u00b7ke", "jag\u00b7te", "mich", "das", "Fie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und warf auf meine Backen grelle R\u00f6te.", "tokens": ["Und", "warf", "auf", "mei\u00b7ne", "Ba\u00b7cken", "grel\u00b7le", "R\u00f6\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.4": {"text": "Wie sie heut wieder br\u00fcnstig k\u00fc\u00dfte, flehte:", "tokens": ["Wie", "sie", "heut", "wie\u00b7der", "br\u00fcns\u00b7tig", "k\u00fc\u00df\u00b7te", ",", "fleh\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich m\u00f6chte wiederkommen! Viel, viel lieber", "tokens": ["Ich", "m\u00f6ch\u00b7te", "wie\u00b7der\u00b7kom\u00b7men", "!", "Viel", ",", "viel", "lie\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "ADV", "$,", "ADV", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Sei ihr die Nacht! ... Denn, w\u00e4r' der Tag zu R\u00fcste,", "tokens": ["Sei", "ihr", "die", "Nacht", "!", "...", "Denn", ",", "w\u00e4r'", "der", "Tag", "zu", "R\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$.", "$(", "KON", "$,", "VAFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dann spr\u00e4ngen hei\u00dfer all die s\u00fc\u00dfen L\u00fcste", "tokens": ["Dann", "spr\u00e4n\u00b7gen", "hei\u00b7\u00dfer", "all", "die", "s\u00fc\u00b7\u00dfen", "L\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und s\u00fc\u00dfer sei das Indenarmenliegen! ...", "tokens": ["Und", "s\u00fc\u00b7\u00dfer", "sei", "das", "In\u00b7de\u00b7nar\u00b7men\u00b7lie\u00b7gen", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}}, "stanza.8": {"line.1": {"text": "Der frischged\u00fcngte Acker stinkt emp\u00f6rend, \u2013", "tokens": ["Der", "frischge\u00b7d\u00fcng\u00b7te", "A\u00b7cker", "stinkt", "em\u00b7p\u00f6\u00b7rend", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "$,", "$("], "meter": "-++-+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Doch ist sein Stunk nicht grade unbelehrend:", "tokens": ["Doch", "ist", "sein", "Stunk", "nicht", "gra\u00b7de", "un\u00b7be\u00b7leh\u00b7rend", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}