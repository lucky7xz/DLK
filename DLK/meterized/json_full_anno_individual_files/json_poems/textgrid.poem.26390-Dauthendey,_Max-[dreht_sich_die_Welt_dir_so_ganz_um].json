{"textgrid.poem.26390": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[dreht sich die Welt dir so ganz um]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dreht sich die Welt dir so ganz um,", "tokens": ["Dreht", "sich", "die", "Welt", "dir", "so", "ganz", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Siehst du auch gute Dinge krumm.", "tokens": ["Siehst", "du", "auch", "gu\u00b7te", "Din\u00b7ge", "krumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Bei meiner Stadt steht n\u00e4mlich Wald,", "tokens": ["Bei", "mei\u00b7ner", "Stadt", "steht", "n\u00e4m\u00b7lich", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ist schon mythologisch alt;", "tokens": ["Der", "ist", "schon", "my\u00b7tho\u00b7lo\u00b7gisch", "alt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wildschweine hausen hinter Eichen,", "tokens": ["Wild\u00b7schwei\u00b7ne", "hau\u00b7sen", "hin\u00b7ter", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wo Borsten sie an Rinden streichen.", "tokens": ["Wo", "Bors\u00b7ten", "sie", "an", "Rin\u00b7den", "strei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Es rauchen Meiler still verstohlen,", "tokens": ["Es", "rau\u00b7chen", "Mei\u00b7ler", "still", "ver\u00b7stoh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zum B\u00fcgeln macht man dort die Kohlen.", "tokens": ["Zum", "B\u00fc\u00b7geln", "macht", "man", "dort", "die", "Koh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Still ist es, wie in jedem Wald,", "tokens": ["Still", "ist", "es", ",", "wie", "in", "je\u00b7dem", "Wald", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PWAV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und eingeschlafen ist man bald.", "tokens": ["Und", "ein\u00b7ge\u00b7schla\u00b7fen", "ist", "man", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sehr fr\u00fch ist dann die Morgenstund',", "tokens": ["Sehr", "fr\u00fch", "ist", "dann", "die", "Mor\u00b7gen\u00b7stund'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn V\u00f6gel halten schwer den Mund.", "tokens": ["Denn", "V\u00f6\u00b7gel", "hal\u00b7ten", "schwer", "den", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sie ziehen ihre T\u00f6ne lang,", "tokens": ["Sie", "zie\u00b7hen", "ih\u00b7re", "T\u00f6\u00b7ne", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann ist der Wald voll Vogelsang.", "tokens": ["Dann", "ist", "der", "Wald", "voll", "Vo\u00b7gel\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Zum Wald kam ich im Sommer hin,", "tokens": ["Zum", "Wald", "kam", "ich", "im", "Som\u00b7mer", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch abf\u00e4rbend schien mir sein Gr\u00fcn,", "tokens": ["Doch", "ab\u00b7f\u00e4r\u00b7bend", "schien", "mir", "sein", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.9": {"line.1": {"text": "Leichengr\u00fcn spielten meine H\u00e4nde,", "tokens": ["Lei\u00b7chen\u00b7gr\u00fcn", "spiel\u00b7ten", "mei\u00b7ne", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und ringsum nahm der Wald kein Ende.", "tokens": ["Und", "ring\u00b7sum", "nahm", "der", "Wald", "kein", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die Wege waren regenglatt,", "tokens": ["Die", "We\u00b7ge", "wa\u00b7ren", "re\u00b7gen\u00b7glatt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn Sonne fand nur drau\u00dfen statt;", "tokens": ["Denn", "Son\u00b7ne", "fand", "nur", "drau\u00b7\u00dfen", "statt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Regenschnecken, schwarz wie Grauen,", "tokens": ["Die", "Re\u00b7gen\u00b7schne\u00b7cken", ",", "schwarz", "wie", "Grau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Krochen wie Finger, abgehauen;", "tokens": ["Kro\u00b7chen", "wie", "Fin\u00b7ger", ",", "ab\u00b7ge\u00b7hau\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KOKOM", "NN", "$,", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Stinkpilze sa\u00dfen da verlegen", "tokens": ["Stink\u00b7pil\u00b7ze", "sa\u00b7\u00dfen", "da", "ver\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und konnten sich wie Dreck nicht regen;", "tokens": ["Und", "konn\u00b7ten", "sich", "wie", "Dreck", "nicht", "re\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "KOKOM", "NE", "PTKNEG", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Mit einem Wort, mir war's nicht wohl", "tokens": ["Mit", "ei\u00b7nem", "Wort", ",", "mir", "wa\u00b7r's", "nicht", "wohl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und mir war nicht, wie mir's sein soll.", "tokens": ["Und", "mir", "war", "nicht", ",", "wie", "mir's", "sein", "soll", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "$,", "PWAV", "PIS", "VAINF", "VMFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "Und ist solch' Tag dann endlich aus,", "tokens": ["Und", "ist", "solch'", "Tag", "dann", "end\u00b7lich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann schl\u00e4ft man in dem Waldwirtshaus.", "tokens": ["Dann", "schl\u00e4ft", "man", "in", "dem", "Wald\u00b7wirts\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und dort ich's Mohrle treffen t\u00e4t,", "tokens": ["Und", "dort", "ich's", "Mohr\u00b7le", "tref\u00b7fen", "t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nacht war's, und sie kam an mein Bett.", "tokens": ["Nacht", "wa\u00b7r's", ",", "und", "sie", "kam", "an", "mein", "Bett", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Ich mu\u00dfte tiefen Atem holen,", "tokens": ["Ich", "mu\u00df\u00b7te", "tie\u00b7fen", "A\u00b7tem", "ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00fcrde wieder was gestohlen.", "tokens": ["Als", "w\u00fcr\u00b7de", "wie\u00b7der", "was", "ge\u00b7stoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Sie tat an meinem Bette stehn,", "tokens": ["Sie", "tat", "an", "mei\u00b7nem", "Bet\u00b7te", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bat, sie sollt' nicht n\u00e4her gehn.", "tokens": ["Ich", "bat", ",", "sie", "sollt'", "nicht", "n\u00e4\u00b7her", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ich sprach: \u00bbIch bin noch seelenkrank,", "tokens": ["Ich", "sprach", ":", "\u00bb", "Ich", "bin", "noch", "see\u00b7len\u00b7krank", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh fort und f\u00fcrcht meinen Gestank.", "tokens": ["Geh", "fort", "und", "f\u00fcrcht", "mei\u00b7nen", "Ge\u00b7stank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.19": {"line.1": {"text": "Vorl\u00e4ufig hass' ich jedes Lieben,", "tokens": ["Vor\u00b7l\u00e4u\u00b7fig", "hass'", "ich", "je\u00b7des", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PIAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vergib, da\u00df du mir treu geblieben.\u00ab", "tokens": ["Ver\u00b7gib", ",", "da\u00df", "du", "mir", "treu", "ge\u00b7blie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Sie war der Mutter still entwichen,", "tokens": ["Sie", "war", "der", "Mut\u00b7ter", "still", "ent\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Hemd verkl\u00e4rt hereingeschlichen,", "tokens": ["Im", "Hemd", "ver\u00b7kl\u00e4rt", "her\u00b7ein\u00b7ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Sie kam wie Zigarettenduft", "tokens": ["Sie", "kam", "wie", "Zi\u00b7ga\u00b7ret\u00b7ten\u00b7duft"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meine Seelenzimmerluft,", "tokens": ["In", "mei\u00b7ne", "See\u00b7len\u00b7zim\u00b7mer\u00b7luft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "War f\u00fcr die Nase Rosenholz", "tokens": ["War", "f\u00fcr", "die", "Na\u00b7se", "Ro\u00b7sen\u00b7holz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fcr das Herz ein Armbrustbolz,", "tokens": ["Und", "f\u00fcr", "das", "Herz", "ein", "Arm\u00b7brust\u00b7bolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "War wie das Rote in dem Blut", "tokens": ["War", "wie", "das", "Ro\u00b7te", "in", "dem", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wie ein Blutk\u00f6rperlein gut.", "tokens": ["Und", "wie", "ein", "Blut\u00b7k\u00f6r\u00b7per\u00b7lein", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Doch trug sie in dem Aug' die Nacht,", "tokens": ["Doch", "trug", "sie", "in", "dem", "Aug'", "die", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die mir K\u00f6nigin tot gemacht,", "tokens": ["Die", "mir", "K\u00f6\u00b7ni\u00b7gin", "tot", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "ADJD", "VVPP", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.25": {"line.1": {"text": "Wie Flecken, die nicht weitergehn", "tokens": ["Wie", "Fle\u00b7cken", ",", "die", "nicht", "wei\u00b7ter\u00b7gehn"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "PRELS", "PTKNEG", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und jeder W\u00e4sche widerstehn.", "tokens": ["Und", "je\u00b7der", "W\u00e4\u00b7sche", "wi\u00b7der\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Sie zitterte auf nackten Zehen,", "tokens": ["Sie", "zit\u00b7ter\u00b7te", "auf", "nack\u00b7ten", "Ze\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Tat wie ein Streichholz leis ausgehen,", "tokens": ["Tat", "wie", "ein", "Streich\u00b7holz", "leis", "aus\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.27": {"line.1": {"text": "Sprang fr\u00fch wild in den Wald hinaus", "tokens": ["Sprang", "fr\u00fch", "wild", "in", "den", "Wald", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "ADJD", "APPR", "ART", "NN", "APZR"], "meter": "-+++-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und kam des abends erst nach Haus.", "tokens": ["Und", "kam", "des", "a\u00b7bends", "erst", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Trat ihre roten Schuhe schief,", "tokens": ["Trat", "ih\u00b7re", "ro\u00b7ten", "Schu\u00b7he", "schief", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als sie im Wald nach Schweinen lief;", "tokens": ["Als", "sie", "im", "Wald", "nach", "Schwei\u00b7nen", "lief", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Hat sich im Wald ganz hart gesessen,", "tokens": ["Hat", "sich", "im", "Wald", "ganz", "hart", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "APPRART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00fcnschend, ein Wildschwein m\u00f6g' sie fressen,", "tokens": ["W\u00fcn\u00b7schend", ",", "ein", "Wild\u00b7schwein", "m\u00f6g'", "sie", "fres\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.30": {"line.1": {"text": "W\u00fcnschend, ein Pilz m\u00f6g' sie vergiften,", "tokens": ["W\u00fcn\u00b7schend", ",", "ein", "Pilz", "m\u00f6g'", "sie", "ver\u00b7gif\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Oder sonst was den Tod ihr stiften.", "tokens": ["O\u00b7der", "sonst", "was", "den", "Tod", "ihr", "stif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PWS", "ART", "NN", "PPOSAT", "ADJA", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.31": {"line.1": {"text": "Die Schweine lie\u00dfen sie in Ruh',", "tokens": ["Die", "Schwei\u00b7ne", "lie\u00b7\u00dfen", "sie", "in", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Pilze sahen ihr nur zur,", "tokens": ["Die", "Pil\u00b7ze", "sa\u00b7hen", "ihr", "nur", "zur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPRART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.32": {"line.1": {"text": "B\u00e4ume standen wie Wand an Wand,", "tokens": ["B\u00e4u\u00b7me", "stan\u00b7den", "wie", "Wand", "an", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "NN", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Da\u00df sie mit Einsicht stille stand.", "tokens": ["Da\u00df", "sie", "mit", "Ein\u00b7sicht", "stil\u00b7le", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Sie kam zu einem Weiher hin,", "tokens": ["Sie", "kam", "zu", "ei\u00b7nem", "Wei\u00b7her", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und auf dem Kopf sah sie sich drin,", "tokens": ["Und", "auf", "dem", "Kopf", "sah", "sie", "sich", "drin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Sie weinte auf ihr Spiegelbild,", "tokens": ["Sie", "wein\u00b7te", "auf", "ihr", "Spie\u00b7gel\u00b7bild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das machte sie mit sich so mild.", "tokens": ["Das", "mach\u00b7te", "sie", "mit", "sich", "so", "mild", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Sie sprach: \u00bbBin ich wo zu Besuch,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Bin", "ich", "wo", "zu", "Be\u00b7such", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VAFIN", "PPER", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Heimlich ich oft in B\u00fcchern such'", "tokens": ["Heim\u00b7lich", "ich", "oft", "in", "B\u00fc\u00b7chern", "such'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "ADV", "APPR", "NN", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.36": {"line.1": {"text": "Ein Ammenlied, man sang's als Kind,", "tokens": ["Ein", "Am\u00b7men\u00b7lied", ",", "man", "sang's", "als", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIS", "PIS", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und von dem Lied ich's End' nie find'.", "tokens": ["Und", "von", "dem", "Lied", "ich's", "End'", "nie", "find'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Wie dieses Lied macht mir jetzt Not", "tokens": ["Wie", "die\u00b7ses", "Lied", "macht", "mir", "jetzt", "Not"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PDAT", "NN", "VVFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Lieb', ich find' nicht ihren Tod.", "tokens": ["Die", "Lieb'", ",", "ich", "find'", "nicht", "ih\u00b7ren", "Tod", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Ich brauch' ins Wasser nicht zu tunken,", "tokens": ["Ich", "brauch'", "ins", "Was\u00b7ser", "nicht", "zu", "tun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich f\u00fchle mich schon halb ertrunken,", "tokens": ["Ich", "f\u00fch\u00b7le", "mich", "schon", "halb", "er\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Heimkehre ich erst recht jetzt heiter,", "tokens": ["Heim\u00b7keh\u00b7re", "ich", "erst", "recht", "jetzt", "hei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Leb' noch mit einer H\u00e4lfte weiter.", "tokens": ["Leb'", "noch", "mit", "ei\u00b7ner", "H\u00e4lf\u00b7te", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Sie nahm ihr T\u00fcchlein aus der Taschen,", "tokens": ["Sie", "nahm", "ihr", "T\u00fcch\u00b7lein", "aus", "der", "Ta\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat die Pupillen rein gewaschen.", "tokens": ["Hat", "die", "Pu\u00b7pil\u00b7len", "rein", "ge\u00b7wa\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Bla\u00df sah das ganze Mohrle aus,", "tokens": ["Bla\u00df", "sah", "das", "gan\u00b7ze", "Mohr\u00b7le", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und es erkannt' sie kaum das Haus.", "tokens": ["Und", "es", "er\u00b7kannt'", "sie", "kaum", "das", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Die Haust\u00fcr stand vor Staunen offen,", "tokens": ["Die", "Haus\u00b7t\u00fcr", "stand", "vor", "Stau\u00b7nen", "of\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort hat den Balzer sie getroffen.", "tokens": ["Dort", "hat", "den", "Bal\u00b7zer", "sie", "ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Bist du gestorben,\u00ab fragte er,", "tokens": ["Bist", "du", "ge\u00b7stor\u00b7ben", ",", "\u00ab", "frag\u00b7te", "er", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "$(", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbbla\u00df bist du wie das wei\u00dfe Meer?\u00ab", "tokens": ["\u00bb", "bla\u00df", "bist", "du", "wie", "das", "wei\u00b7\u00dfe", "Meer", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "KOKOM", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "\u00bbich bin nicht tot und nicht begraben,", "tokens": ["\u00bb", "ich", "bin", "nicht", "tot", "und", "nicht", "be\u00b7gra\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKNEG", "ADJD", "KON", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wildschwein nicht mal wollt' mich haben,", "tokens": ["Das", "Wild\u00b7schwein", "nicht", "mal", "wollt'", "mich", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Ich f\u00fchle mich nur ausgerottet,", "tokens": ["Ich", "f\u00fch\u00b7le", "mich", "nur", "aus\u00b7ge\u00b7rot\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df es jeder Beschreibung spottet.\u00ab", "tokens": ["Da\u00df", "es", "je\u00b7der", "Be\u00b7schrei\u00b7bung", "spot\u00b7tet", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.46": {"line.1": {"text": "Da seufzte Balzer: \u00bbDu wei\u00dft dies:", "tokens": ["Da", "seufz\u00b7te", "Bal\u00b7zer", ":", "\u00bb", "Du", "wei\u00dft", "dies", ":"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$.", "$(", "PPER", "VVFIN", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Frau K\u00f6nigin mich kalt entlie\u00df,", "tokens": ["Frau", "K\u00f6\u00b7ni\u00b7gin", "mich", "kalt", "ent\u00b7lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Heut hat sie Einen kr\u00f6nen lassen,", "tokens": ["Heut", "hat", "sie", "Ei\u00b7nen", "kr\u00f6\u00b7nen", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bin enttront und tu mich hassen.", "tokens": ["Ich", "bin", "ent\u00b7tront", "und", "tu", "mich", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Dachte, da\u00df man stets Liebe spielt,", "tokens": ["Dach\u00b7te", ",", "da\u00df", "man", "stets", "Lie\u00b7be", "spielt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIS", "ADV", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Doch macht's die K\u00f6niginnen wild,", "tokens": ["Doch", "macht's", "die", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "wild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Und schwarze Mohrle werden wei\u00df,", "tokens": ["Und", "schwar\u00b7ze", "Mohr\u00b7le", "wer\u00b7den", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil ich sie wie der Tod anbei\u00df!", "tokens": ["Weil", "ich", "sie", "wie", "der", "Tod", "an\u00b7bei\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Verpf\u00e4ndet f\u00fchl' ich meine Glieder,", "tokens": ["Ver\u00b7pf\u00e4n\u00b7det", "f\u00fchl'", "ich", "mei\u00b7ne", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich lege mich verschlafen nieder,", "tokens": ["Ich", "le\u00b7ge", "mich", "ver\u00b7schla\u00b7fen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "F\u00fchle mich, wie Kamele gehn,", "tokens": ["F\u00fch\u00b7le", "mich", ",", "wie", "Ka\u00b7me\u00b7le", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "NN", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Vorl\u00e4ufig tu ich W\u00fcsten sehn.", "tokens": ["Vor\u00b7l\u00e4u\u00b7fig", "tu", "ich", "W\u00fcs\u00b7ten", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Doch einst komm' ich an deine Br\u00fcste,", "tokens": ["Doch", "einst", "komm'", "ich", "an", "dei\u00b7ne", "Br\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Fata Morgana in der W\u00fcste,", "tokens": ["Fa\u00b7ta", "Mor\u00b7ga\u00b7na", "in", "der", "W\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.53": {"line.1": {"text": "Du wei\u00dft, unl\u00f6schbar ist mein Durst.", "tokens": ["Du", "wei\u00dft", ",", "un\u00b7l\u00f6schbar", "ist", "mein", "Durst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bin hoffentlich dir dann nicht Wurst?\u00ab", "tokens": ["Bin", "hof\u00b7fent\u00b7lich", "dir", "dann", "nicht", "Wurst", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ADV", "PTKNEG", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.54": {"line.1": {"text": "\u00bbtopp\u00ab, rief das Mohrle, \u00bbangenommen,", "tokens": ["\u00bb", "topp", "\u00ab", ",", "rief", "das", "Mohr\u00b7le", ",", "\u00bb", "an\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$(", "$,", "VVFIN", "ART", "NN", "$,", "$(", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kannst gehen und kannst wiederkommen,", "tokens": ["Kannst", "ge\u00b7hen", "und", "kannst", "wie\u00b7der\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Kamel, dein Mohrle wird dich tr\u00e4nken,", "tokens": ["Ka\u00b7mel", ",", "dein", "Mohr\u00b7le", "wird", "dich", "tr\u00e4n\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dir in Oasen Palmschnaps schenken.", "tokens": ["Dir", "in", "O\u00b7a\u00b7sen", "Palm\u00b7schnaps", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Denn sieh, ich sprach niemals im Fieber,", "tokens": ["Denn", "sieh", ",", "ich", "sprach", "nie\u00b7mals", "im", "Fie\u00b7ber", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$,", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Liebe geht nicht nur so vor\u00fcber,", "tokens": ["Lie\u00b7be", "geht", "nicht", "nur", "so", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.57": {"line.1": {"text": "Du kannst verachten mich und schlagen,", "tokens": ["Du", "kannst", "ver\u00b7ach\u00b7ten", "mich", "und", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "PPER", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kannst kopfstehn selbst auf meinem Magen,", "tokens": ["Kannst", "kopf\u00b7stehn", "selbst", "auf", "mei\u00b7nem", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Kannst alle Schaltjahr wiederkommen,", "tokens": ["Kannst", "al\u00b7le", "Schalt\u00b7jahr", "wie\u00b7der\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wirst wie der Sonntag angenommen.", "tokens": ["Wirst", "wie", "der", "Sonn\u00b7tag", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Statt da\u00df ich mit dem Tode tausch',", "tokens": ["Statt", "da\u00df", "ich", "mit", "dem", "To\u00b7de", "tausch'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "W\u00fcnsch' ich mir oft noch deinen Rausch,", "tokens": ["W\u00fcn\u00b7sch'", "ich", "mir", "oft", "noch", "dei\u00b7nen", "Rausch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.60": {"line.1": {"text": "Wollen mit Seufzern nichts verderben,", "tokens": ["Wol\u00b7len", "mit", "Seuf\u00b7zern", "nichts", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PIS", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Helden sollen berauscht nur sterben.\u00ab", "tokens": ["Hel\u00b7den", "sol\u00b7len", "be\u00b7rauscht", "nur", "ster\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VMFIN", "VVFIN", "ADV", "VVINF", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.61": {"line.1": {"text": "Dreht sich die Welt dir so ganz um,", "tokens": ["Dreht", "sich", "die", "Welt", "dir", "so", "ganz", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Siehst du auch gute Dinge krumm.", "tokens": ["Siehst", "du", "auch", "gu\u00b7te", "Din\u00b7ge", "krumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Bei meiner Stadt steht n\u00e4mlich Wald,", "tokens": ["Bei", "mei\u00b7ner", "Stadt", "steht", "n\u00e4m\u00b7lich", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ist schon mythologisch alt;", "tokens": ["Der", "ist", "schon", "my\u00b7tho\u00b7lo\u00b7gisch", "alt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Wildschweine hausen hinter Eichen,", "tokens": ["Wild\u00b7schwei\u00b7ne", "hau\u00b7sen", "hin\u00b7ter", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wo Borsten sie an Rinden streichen.", "tokens": ["Wo", "Bors\u00b7ten", "sie", "an", "Rin\u00b7den", "strei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Es rauchen Meiler still verstohlen,", "tokens": ["Es", "rau\u00b7chen", "Mei\u00b7ler", "still", "ver\u00b7stoh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zum B\u00fcgeln macht man dort die Kohlen.", "tokens": ["Zum", "B\u00fc\u00b7geln", "macht", "man", "dort", "die", "Koh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Still ist es, wie in jedem Wald,", "tokens": ["Still", "ist", "es", ",", "wie", "in", "je\u00b7dem", "Wald", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PWAV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und eingeschlafen ist man bald.", "tokens": ["Und", "ein\u00b7ge\u00b7schla\u00b7fen", "ist", "man", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Sehr fr\u00fch ist dann die Morgenstund',", "tokens": ["Sehr", "fr\u00fch", "ist", "dann", "die", "Mor\u00b7gen\u00b7stund'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn V\u00f6gel halten schwer den Mund.", "tokens": ["Denn", "V\u00f6\u00b7gel", "hal\u00b7ten", "schwer", "den", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Sie ziehen ihre T\u00f6ne lang,", "tokens": ["Sie", "zie\u00b7hen", "ih\u00b7re", "T\u00f6\u00b7ne", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann ist der Wald voll Vogelsang.", "tokens": ["Dann", "ist", "der", "Wald", "voll", "Vo\u00b7gel\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Zum Wald kam ich im Sommer hin,", "tokens": ["Zum", "Wald", "kam", "ich", "im", "Som\u00b7mer", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch abf\u00e4rbend schien mir sein Gr\u00fcn,", "tokens": ["Doch", "ab\u00b7f\u00e4r\u00b7bend", "schien", "mir", "sein", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.69": {"line.1": {"text": "Leichengr\u00fcn spielten meine H\u00e4nde,", "tokens": ["Lei\u00b7chen\u00b7gr\u00fcn", "spiel\u00b7ten", "mei\u00b7ne", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und ringsum nahm der Wald kein Ende.", "tokens": ["Und", "ring\u00b7sum", "nahm", "der", "Wald", "kein", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Die Wege waren regenglatt,", "tokens": ["Die", "We\u00b7ge", "wa\u00b7ren", "re\u00b7gen\u00b7glatt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn Sonne fand nur drau\u00dfen statt;", "tokens": ["Denn", "Son\u00b7ne", "fand", "nur", "drau\u00b7\u00dfen", "statt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Die Regenschnecken, schwarz wie Grauen,", "tokens": ["Die", "Re\u00b7gen\u00b7schne\u00b7cken", ",", "schwarz", "wie", "Grau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Krochen wie Finger, abgehauen;", "tokens": ["Kro\u00b7chen", "wie", "Fin\u00b7ger", ",", "ab\u00b7ge\u00b7hau\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KOKOM", "NN", "$,", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.72": {"line.1": {"text": "Stinkpilze sa\u00dfen da verlegen", "tokens": ["Stink\u00b7pil\u00b7ze", "sa\u00b7\u00dfen", "da", "ver\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und konnten sich wie Dreck nicht regen;", "tokens": ["Und", "konn\u00b7ten", "sich", "wie", "Dreck", "nicht", "re\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "KOKOM", "NE", "PTKNEG", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Mit einem Wort, mir war's nicht wohl", "tokens": ["Mit", "ei\u00b7nem", "Wort", ",", "mir", "wa\u00b7r's", "nicht", "wohl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und mir war nicht, wie mir's sein soll.", "tokens": ["Und", "mir", "war", "nicht", ",", "wie", "mir's", "sein", "soll", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "$,", "PWAV", "PIS", "VAINF", "VMFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.74": {"line.1": {"text": "Und ist solch' Tag dann endlich aus,", "tokens": ["Und", "ist", "solch'", "Tag", "dann", "end\u00b7lich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann schl\u00e4ft man in dem Waldwirtshaus.", "tokens": ["Dann", "schl\u00e4ft", "man", "in", "dem", "Wald\u00b7wirts\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Und dort ich's Mohrle treffen t\u00e4t,", "tokens": ["Und", "dort", "ich's", "Mohr\u00b7le", "tref\u00b7fen", "t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nacht war's, und sie kam an mein Bett.", "tokens": ["Nacht", "wa\u00b7r's", ",", "und", "sie", "kam", "an", "mein", "Bett", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.76": {"line.1": {"text": "Ich mu\u00dfte tiefen Atem holen,", "tokens": ["Ich", "mu\u00df\u00b7te", "tie\u00b7fen", "A\u00b7tem", "ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00fcrde wieder was gestohlen.", "tokens": ["Als", "w\u00fcr\u00b7de", "wie\u00b7der", "was", "ge\u00b7stoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Sie tat an meinem Bette stehn,", "tokens": ["Sie", "tat", "an", "mei\u00b7nem", "Bet\u00b7te", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bat, sie sollt' nicht n\u00e4her gehn.", "tokens": ["Ich", "bat", ",", "sie", "sollt'", "nicht", "n\u00e4\u00b7her", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Ich sprach: \u00bbIch bin noch seelenkrank,", "tokens": ["Ich", "sprach", ":", "\u00bb", "Ich", "bin", "noch", "see\u00b7len\u00b7krank", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh fort und f\u00fcrcht meinen Gestank.", "tokens": ["Geh", "fort", "und", "f\u00fcrcht", "mei\u00b7nen", "Ge\u00b7stank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.79": {"line.1": {"text": "Vorl\u00e4ufig hass' ich jedes Lieben,", "tokens": ["Vor\u00b7l\u00e4u\u00b7fig", "hass'", "ich", "je\u00b7des", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PIAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vergib, da\u00df du mir treu geblieben.\u00ab", "tokens": ["Ver\u00b7gib", ",", "da\u00df", "du", "mir", "treu", "ge\u00b7blie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Sie war der Mutter still entwichen,", "tokens": ["Sie", "war", "der", "Mut\u00b7ter", "still", "ent\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Hemd verkl\u00e4rt hereingeschlichen,", "tokens": ["Im", "Hemd", "ver\u00b7kl\u00e4rt", "her\u00b7ein\u00b7ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "Sie kam wie Zigarettenduft", "tokens": ["Sie", "kam", "wie", "Zi\u00b7ga\u00b7ret\u00b7ten\u00b7duft"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meine Seelenzimmerluft,", "tokens": ["In", "mei\u00b7ne", "See\u00b7len\u00b7zim\u00b7mer\u00b7luft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "War f\u00fcr die Nase Rosenholz", "tokens": ["War", "f\u00fcr", "die", "Na\u00b7se", "Ro\u00b7sen\u00b7holz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fcr das Herz ein Armbrustbolz,", "tokens": ["Und", "f\u00fcr", "das", "Herz", "ein", "Arm\u00b7brust\u00b7bolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "War wie das Rote in dem Blut", "tokens": ["War", "wie", "das", "Ro\u00b7te", "in", "dem", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wie ein Blutk\u00f6rperlein gut.", "tokens": ["Und", "wie", "ein", "Blut\u00b7k\u00f6r\u00b7per\u00b7lein", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Doch trug sie in dem Aug' die Nacht,", "tokens": ["Doch", "trug", "sie", "in", "dem", "Aug'", "die", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die mir K\u00f6nigin tot gemacht,", "tokens": ["Die", "mir", "K\u00f6\u00b7ni\u00b7gin", "tot", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "ADJD", "VVPP", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.85": {"line.1": {"text": "Wie Flecken, die nicht weitergehn", "tokens": ["Wie", "Fle\u00b7cken", ",", "die", "nicht", "wei\u00b7ter\u00b7gehn"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "PRELS", "PTKNEG", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und jeder W\u00e4sche widerstehn.", "tokens": ["Und", "je\u00b7der", "W\u00e4\u00b7sche", "wi\u00b7der\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.86": {"line.1": {"text": "Sie zitterte auf nackten Zehen,", "tokens": ["Sie", "zit\u00b7ter\u00b7te", "auf", "nack\u00b7ten", "Ze\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Tat wie ein Streichholz leis ausgehen,", "tokens": ["Tat", "wie", "ein", "Streich\u00b7holz", "leis", "aus\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.87": {"line.1": {"text": "Sprang fr\u00fch wild in den Wald hinaus", "tokens": ["Sprang", "fr\u00fch", "wild", "in", "den", "Wald", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "ADJD", "APPR", "ART", "NN", "APZR"], "meter": "-+++-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und kam des abends erst nach Haus.", "tokens": ["Und", "kam", "des", "a\u00b7bends", "erst", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Trat ihre roten Schuhe schief,", "tokens": ["Trat", "ih\u00b7re", "ro\u00b7ten", "Schu\u00b7he", "schief", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als sie im Wald nach Schweinen lief;", "tokens": ["Als", "sie", "im", "Wald", "nach", "Schwei\u00b7nen", "lief", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.89": {"line.1": {"text": "Hat sich im Wald ganz hart gesessen,", "tokens": ["Hat", "sich", "im", "Wald", "ganz", "hart", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "APPRART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00fcnschend, ein Wildschwein m\u00f6g' sie fressen,", "tokens": ["W\u00fcn\u00b7schend", ",", "ein", "Wild\u00b7schwein", "m\u00f6g'", "sie", "fres\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.90": {"line.1": {"text": "W\u00fcnschend, ein Pilz m\u00f6g' sie vergiften,", "tokens": ["W\u00fcn\u00b7schend", ",", "ein", "Pilz", "m\u00f6g'", "sie", "ver\u00b7gif\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Oder sonst was den Tod ihr stiften.", "tokens": ["O\u00b7der", "sonst", "was", "den", "Tod", "ihr", "stif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PWS", "ART", "NN", "PPOSAT", "ADJA", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.91": {"line.1": {"text": "Die Schweine lie\u00dfen sie in Ruh',", "tokens": ["Die", "Schwei\u00b7ne", "lie\u00b7\u00dfen", "sie", "in", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Pilze sahen ihr nur zur,", "tokens": ["Die", "Pil\u00b7ze", "sa\u00b7hen", "ihr", "nur", "zur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPRART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.92": {"line.1": {"text": "B\u00e4ume standen wie Wand an Wand,", "tokens": ["B\u00e4u\u00b7me", "stan\u00b7den", "wie", "Wand", "an", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "NN", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Da\u00df sie mit Einsicht stille stand.", "tokens": ["Da\u00df", "sie", "mit", "Ein\u00b7sicht", "stil\u00b7le", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.93": {"line.1": {"text": "Sie kam zu einem Weiher hin,", "tokens": ["Sie", "kam", "zu", "ei\u00b7nem", "Wei\u00b7her", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und auf dem Kopf sah sie sich drin,", "tokens": ["Und", "auf", "dem", "Kopf", "sah", "sie", "sich", "drin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.94": {"line.1": {"text": "Sie weinte auf ihr Spiegelbild,", "tokens": ["Sie", "wein\u00b7te", "auf", "ihr", "Spie\u00b7gel\u00b7bild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das machte sie mit sich so mild.", "tokens": ["Das", "mach\u00b7te", "sie", "mit", "sich", "so", "mild", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.95": {"line.1": {"text": "Sie sprach: \u00bbBin ich wo zu Besuch,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Bin", "ich", "wo", "zu", "Be\u00b7such", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VAFIN", "PPER", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Heimlich ich oft in B\u00fcchern such'", "tokens": ["Heim\u00b7lich", "ich", "oft", "in", "B\u00fc\u00b7chern", "such'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "ADV", "APPR", "NN", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.96": {"line.1": {"text": "Ein Ammenlied, man sang's als Kind,", "tokens": ["Ein", "Am\u00b7men\u00b7lied", ",", "man", "sang's", "als", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIS", "PIS", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und von dem Lied ich's End' nie find'.", "tokens": ["Und", "von", "dem", "Lied", "ich's", "End'", "nie", "find'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.97": {"line.1": {"text": "Wie dieses Lied macht mir jetzt Not", "tokens": ["Wie", "die\u00b7ses", "Lied", "macht", "mir", "jetzt", "Not"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PDAT", "NN", "VVFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Lieb', ich find' nicht ihren Tod.", "tokens": ["Die", "Lieb'", ",", "ich", "find'", "nicht", "ih\u00b7ren", "Tod", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Ich brauch' ins Wasser nicht zu tunken,", "tokens": ["Ich", "brauch'", "ins", "Was\u00b7ser", "nicht", "zu", "tun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich f\u00fchle mich schon halb ertrunken,", "tokens": ["Ich", "f\u00fch\u00b7le", "mich", "schon", "halb", "er\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.99": {"line.1": {"text": "Heimkehre ich erst recht jetzt heiter,", "tokens": ["Heim\u00b7keh\u00b7re", "ich", "erst", "recht", "jetzt", "hei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Leb' noch mit einer H\u00e4lfte weiter.", "tokens": ["Leb'", "noch", "mit", "ei\u00b7ner", "H\u00e4lf\u00b7te", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.100": {"line.1": {"text": "Sie nahm ihr T\u00fcchlein aus der Taschen,", "tokens": ["Sie", "nahm", "ihr", "T\u00fcch\u00b7lein", "aus", "der", "Ta\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat die Pupillen rein gewaschen.", "tokens": ["Hat", "die", "Pu\u00b7pil\u00b7len", "rein", "ge\u00b7wa\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.101": {"line.1": {"text": "Bla\u00df sah das ganze Mohrle aus,", "tokens": ["Bla\u00df", "sah", "das", "gan\u00b7ze", "Mohr\u00b7le", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und es erkannt' sie kaum das Haus.", "tokens": ["Und", "es", "er\u00b7kannt'", "sie", "kaum", "das", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.102": {"line.1": {"text": "Die Haust\u00fcr stand vor Staunen offen,", "tokens": ["Die", "Haus\u00b7t\u00fcr", "stand", "vor", "Stau\u00b7nen", "of\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort hat den Balzer sie getroffen.", "tokens": ["Dort", "hat", "den", "Bal\u00b7zer", "sie", "ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.103": {"line.1": {"text": "Bist du gestorben,\u00ab fragte er,", "tokens": ["Bist", "du", "ge\u00b7stor\u00b7ben", ",", "\u00ab", "frag\u00b7te", "er", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "$(", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbbla\u00df bist du wie das wei\u00dfe Meer?\u00ab", "tokens": ["\u00bb", "bla\u00df", "bist", "du", "wie", "das", "wei\u00b7\u00dfe", "Meer", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "KOKOM", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.104": {"line.1": {"text": "\u00bbich bin nicht tot und nicht begraben,", "tokens": ["\u00bb", "ich", "bin", "nicht", "tot", "und", "nicht", "be\u00b7gra\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKNEG", "ADJD", "KON", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wildschwein nicht mal wollt' mich haben,", "tokens": ["Das", "Wild\u00b7schwein", "nicht", "mal", "wollt'", "mich", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.105": {"line.1": {"text": "Ich f\u00fchle mich nur ausgerottet,", "tokens": ["Ich", "f\u00fch\u00b7le", "mich", "nur", "aus\u00b7ge\u00b7rot\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df es jeder Beschreibung spottet.\u00ab", "tokens": ["Da\u00df", "es", "je\u00b7der", "Be\u00b7schrei\u00b7bung", "spot\u00b7tet", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.106": {"line.1": {"text": "Da seufzte Balzer: \u00bbDu wei\u00dft dies:", "tokens": ["Da", "seufz\u00b7te", "Bal\u00b7zer", ":", "\u00bb", "Du", "wei\u00dft", "dies", ":"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$.", "$(", "PPER", "VVFIN", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Frau K\u00f6nigin mich kalt entlie\u00df,", "tokens": ["Frau", "K\u00f6\u00b7ni\u00b7gin", "mich", "kalt", "ent\u00b7lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.107": {"line.1": {"text": "Heut hat sie Einen kr\u00f6nen lassen,", "tokens": ["Heut", "hat", "sie", "Ei\u00b7nen", "kr\u00f6\u00b7nen", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bin enttront und tu mich hassen.", "tokens": ["Ich", "bin", "ent\u00b7tront", "und", "tu", "mich", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.108": {"line.1": {"text": "Dachte, da\u00df man stets Liebe spielt,", "tokens": ["Dach\u00b7te", ",", "da\u00df", "man", "stets", "Lie\u00b7be", "spielt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIS", "ADV", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Doch macht's die K\u00f6niginnen wild,", "tokens": ["Doch", "macht's", "die", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "wild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.109": {"line.1": {"text": "Und schwarze Mohrle werden wei\u00df,", "tokens": ["Und", "schwar\u00b7ze", "Mohr\u00b7le", "wer\u00b7den", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil ich sie wie der Tod anbei\u00df!", "tokens": ["Weil", "ich", "sie", "wie", "der", "Tod", "an\u00b7bei\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.110": {"line.1": {"text": "Verpf\u00e4ndet f\u00fchl' ich meine Glieder,", "tokens": ["Ver\u00b7pf\u00e4n\u00b7det", "f\u00fchl'", "ich", "mei\u00b7ne", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich lege mich verschlafen nieder,", "tokens": ["Ich", "le\u00b7ge", "mich", "ver\u00b7schla\u00b7fen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.111": {"line.1": {"text": "F\u00fchle mich, wie Kamele gehn,", "tokens": ["F\u00fch\u00b7le", "mich", ",", "wie", "Ka\u00b7me\u00b7le", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "NN", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Vorl\u00e4ufig tu ich W\u00fcsten sehn.", "tokens": ["Vor\u00b7l\u00e4u\u00b7fig", "tu", "ich", "W\u00fcs\u00b7ten", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.112": {"line.1": {"text": "Doch einst komm' ich an deine Br\u00fcste,", "tokens": ["Doch", "einst", "komm'", "ich", "an", "dei\u00b7ne", "Br\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Fata Morgana in der W\u00fcste,", "tokens": ["Fa\u00b7ta", "Mor\u00b7ga\u00b7na", "in", "der", "W\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.113": {"line.1": {"text": "Du wei\u00dft, unl\u00f6schbar ist mein Durst.", "tokens": ["Du", "wei\u00dft", ",", "un\u00b7l\u00f6schbar", "ist", "mein", "Durst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bin hoffentlich dir dann nicht Wurst?\u00ab", "tokens": ["Bin", "hof\u00b7fent\u00b7lich", "dir", "dann", "nicht", "Wurst", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ADV", "PTKNEG", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.114": {"line.1": {"text": "\u00bbtopp\u00ab, rief das Mohrle, \u00bbangenommen,", "tokens": ["\u00bb", "topp", "\u00ab", ",", "rief", "das", "Mohr\u00b7le", ",", "\u00bb", "an\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$(", "$,", "VVFIN", "ART", "NN", "$,", "$(", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kannst gehen und kannst wiederkommen,", "tokens": ["Kannst", "ge\u00b7hen", "und", "kannst", "wie\u00b7der\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.115": {"line.1": {"text": "Kamel, dein Mohrle wird dich tr\u00e4nken,", "tokens": ["Ka\u00b7mel", ",", "dein", "Mohr\u00b7le", "wird", "dich", "tr\u00e4n\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dir in Oasen Palmschnaps schenken.", "tokens": ["Dir", "in", "O\u00b7a\u00b7sen", "Palm\u00b7schnaps", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.116": {"line.1": {"text": "Denn sieh, ich sprach niemals im Fieber,", "tokens": ["Denn", "sieh", ",", "ich", "sprach", "nie\u00b7mals", "im", "Fie\u00b7ber", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$,", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Liebe geht nicht nur so vor\u00fcber,", "tokens": ["Lie\u00b7be", "geht", "nicht", "nur", "so", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ADV", "ADV", "PTKVZ", "$,"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.117": {"line.1": {"text": "Du kannst verachten mich und schlagen,", "tokens": ["Du", "kannst", "ver\u00b7ach\u00b7ten", "mich", "und", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "PPER", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kannst kopfstehn selbst auf meinem Magen,", "tokens": ["Kannst", "kopf\u00b7stehn", "selbst", "auf", "mei\u00b7nem", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.118": {"line.1": {"text": "Kannst alle Schaltjahr wiederkommen,", "tokens": ["Kannst", "al\u00b7le", "Schalt\u00b7jahr", "wie\u00b7der\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wirst wie der Sonntag angenommen.", "tokens": ["Wirst", "wie", "der", "Sonn\u00b7tag", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.119": {"line.1": {"text": "Statt da\u00df ich mit dem Tode tausch',", "tokens": ["Statt", "da\u00df", "ich", "mit", "dem", "To\u00b7de", "tausch'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "W\u00fcnsch' ich mir oft noch deinen Rausch,", "tokens": ["W\u00fcn\u00b7sch'", "ich", "mir", "oft", "noch", "dei\u00b7nen", "Rausch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.120": {"line.1": {"text": "Wollen mit Seufzern nichts verderben,", "tokens": ["Wol\u00b7len", "mit", "Seuf\u00b7zern", "nichts", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PIS", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Helden sollen berauscht nur sterben.\u00ab", "tokens": ["Hel\u00b7den", "sol\u00b7len", "be\u00b7rauscht", "nur", "ster\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VMFIN", "VVFIN", "ADV", "VVINF", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}}}}