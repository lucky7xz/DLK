{"textgrid.poem.42503": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Fahne der Vergessenheit,", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Fahne der Vergessenheit,", "tokens": ["Die", "Fah\u00b7ne", "der", "Ver\u00b7ges\u00b7sen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie mu\u00dfte lange wehen:", "tokens": ["Sie", "mu\u00df\u00b7te", "lan\u00b7ge", "we\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf meinen Wegen traf ich die,", "tokens": ["Auf", "mei\u00b7nen", "We\u00b7gen", "traf", "ich", "die", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die lang ich nicht gesehen.", "tokens": ["Die", "lang", "ich", "nicht", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Woher, wohin, wie ging es dir,", "tokens": ["Wo\u00b7her", ",", "wo\u00b7hin", ",", "wie", "ging", "es", "dir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "$,", "PWAV", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du hast so schmale Wangen.", "tokens": ["Du", "hast", "so", "schma\u00b7le", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Zeit du hast, komm mit. Bald hat", "tokens": ["Wenn", "Zeit", "du", "hast", ",", "komm", "mit", ".", "Bald", "hat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "NN", "PPER", "VAFIN", "$,", "VVFIN", "PTKVZ", "$.", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie mir am Arm gehangen.", "tokens": ["Sie", "mir", "am", "Arm", "ge\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "An einem Flusse schritten wir,", "tokens": ["An", "ei\u00b7nem", "Flus\u00b7se", "schrit\u00b7ten", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und in den alten Garten", "tokens": ["Und", "in", "den", "al\u00b7ten", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sind wir getreten, wo wir einst", "tokens": ["Sind", "wir", "ge\u00b7tre\u00b7ten", ",", "wo", "wir", "einst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "PWAV", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sehns\u00fcchtig auf uns harrten.", "tokens": ["Sehn\u00b7s\u00fcch\u00b7tig", "auf", "uns", "harr\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wir sprachen viel, wir lachten auch,", "tokens": ["Wir", "spra\u00b7chen", "viel", ",", "wir", "lach\u00b7ten", "auch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erz\u00e4hlten uns Geschichten.", "tokens": ["Er\u00b7z\u00e4hl\u00b7ten", "uns", "Ge\u00b7schich\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie anders damals. Heute wars", "tokens": ["Wie", "an\u00b7ders", "da\u00b7mals", ".", "Heu\u00b7te", "wars"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "$.", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein m\u00fchelos Verzichten.", "tokens": ["Ein", "m\u00fc\u00b7he\u00b7los", "Ver\u00b7zich\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wir kehrten in die Stadt zur\u00fcck,", "tokens": ["Wir", "kehr\u00b7ten", "in", "die", "Stadt", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von neuem ri\u00df der Faden.", "tokens": ["Von", "neu\u00b7em", "ri\u00df", "der", "Fa\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch eh wir schieden, blieb ich stehn", "tokens": ["Doch", "eh", "wir", "schie\u00b7den", ",", "blieb", "ich", "stehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor einem Blumenladen.", "tokens": ["Vor", "ei\u00b7nem", "Blu\u00b7men\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die sch\u00f6nste Rose w\u00e4hlt ich aus,", "tokens": ["Die", "sch\u00f6ns\u00b7te", "Ro\u00b7se", "w\u00e4hlt", "ich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr sie die letzte Spende,", "tokens": ["F\u00fcr", "sie", "die", "letz\u00b7te", "Spen\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und k\u00fc\u00dfte ihr zum letzten Mal", "tokens": ["Und", "k\u00fc\u00df\u00b7te", "ihr", "zum", "letz\u00b7ten", "Mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dankbar die lieben H\u00e4nde.", "tokens": ["Dank\u00b7bar", "die", "lie\u00b7ben", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.7": {"line.1": {"text": "Zwei Stra\u00dfenbahnen kreuzten sich,", "tokens": ["Zwei", "Stra\u00b7\u00dfen\u00b7bah\u00b7nen", "kreuz\u00b7ten", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als wir das Haus verlassen.", "tokens": ["Als", "wir", "das", "Haus", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir stiegen ein \u2013 in Nord und S\u00fcd", "tokens": ["Wir", "stie\u00b7gen", "ein", "\u2013", "in", "Nord", "und", "S\u00fcd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "$(", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verschlangen uns die Gassen.", "tokens": ["Ver\u00b7schlan\u00b7gen", "uns", "die", "Gas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Die Fahne der Vergessenheit,", "tokens": ["Die", "Fah\u00b7ne", "der", "Ver\u00b7ges\u00b7sen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie mu\u00dfte lange wehen:", "tokens": ["Sie", "mu\u00df\u00b7te", "lan\u00b7ge", "we\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf meinen Wegen traf ich die,", "tokens": ["Auf", "mei\u00b7nen", "We\u00b7gen", "traf", "ich", "die", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die lang ich nicht gesehen.", "tokens": ["Die", "lang", "ich", "nicht", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Woher, wohin, wie ging es dir,", "tokens": ["Wo\u00b7her", ",", "wo\u00b7hin", ",", "wie", "ging", "es", "dir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "$,", "PWAV", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du hast so schmale Wangen.", "tokens": ["Du", "hast", "so", "schma\u00b7le", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Zeit du hast, komm mit. Bald hat", "tokens": ["Wenn", "Zeit", "du", "hast", ",", "komm", "mit", ".", "Bald", "hat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "NN", "PPER", "VAFIN", "$,", "VVFIN", "PTKVZ", "$.", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie mir am Arm gehangen.", "tokens": ["Sie", "mir", "am", "Arm", "ge\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "An einem Flusse schritten wir,", "tokens": ["An", "ei\u00b7nem", "Flus\u00b7se", "schrit\u00b7ten", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und in den alten Garten", "tokens": ["Und", "in", "den", "al\u00b7ten", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sind wir getreten, wo wir einst", "tokens": ["Sind", "wir", "ge\u00b7tre\u00b7ten", ",", "wo", "wir", "einst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "PWAV", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sehns\u00fcchtig auf uns harrten.", "tokens": ["Sehn\u00b7s\u00fcch\u00b7tig", "auf", "uns", "harr\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wir sprachen viel, wir lachten auch,", "tokens": ["Wir", "spra\u00b7chen", "viel", ",", "wir", "lach\u00b7ten", "auch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erz\u00e4hlten uns Geschichten.", "tokens": ["Er\u00b7z\u00e4hl\u00b7ten", "uns", "Ge\u00b7schich\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie anders damals. Heute wars", "tokens": ["Wie", "an\u00b7ders", "da\u00b7mals", ".", "Heu\u00b7te", "wars"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "$.", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein m\u00fchelos Verzichten.", "tokens": ["Ein", "m\u00fc\u00b7he\u00b7los", "Ver\u00b7zich\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wir kehrten in die Stadt zur\u00fcck,", "tokens": ["Wir", "kehr\u00b7ten", "in", "die", "Stadt", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von neuem ri\u00df der Faden.", "tokens": ["Von", "neu\u00b7em", "ri\u00df", "der", "Fa\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch eh wir schieden, blieb ich stehn", "tokens": ["Doch", "eh", "wir", "schie\u00b7den", ",", "blieb", "ich", "stehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor einem Blumenladen.", "tokens": ["Vor", "ei\u00b7nem", "Blu\u00b7men\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Die sch\u00f6nste Rose w\u00e4hlt ich aus,", "tokens": ["Die", "sch\u00f6ns\u00b7te", "Ro\u00b7se", "w\u00e4hlt", "ich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr sie die letzte Spende,", "tokens": ["F\u00fcr", "sie", "die", "letz\u00b7te", "Spen\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und k\u00fc\u00dfte ihr zum letzten Mal", "tokens": ["Und", "k\u00fc\u00df\u00b7te", "ihr", "zum", "letz\u00b7ten", "Mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dankbar die lieben H\u00e4nde.", "tokens": ["Dank\u00b7bar", "die", "lie\u00b7ben", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.14": {"line.1": {"text": "Zwei Stra\u00dfenbahnen kreuzten sich,", "tokens": ["Zwei", "Stra\u00b7\u00dfen\u00b7bah\u00b7nen", "kreuz\u00b7ten", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als wir das Haus verlassen.", "tokens": ["Als", "wir", "das", "Haus", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir stiegen ein \u2013 in Nord und S\u00fcd", "tokens": ["Wir", "stie\u00b7gen", "ein", "\u2013", "in", "Nord", "und", "S\u00fcd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "$(", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verschlangen uns die Gassen.", "tokens": ["Ver\u00b7schlan\u00b7gen", "uns", "die", "Gas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}