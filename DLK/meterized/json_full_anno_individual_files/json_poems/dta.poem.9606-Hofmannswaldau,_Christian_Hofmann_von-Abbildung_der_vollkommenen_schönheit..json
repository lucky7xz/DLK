{"dta.poem.9606": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Abbildung der vollkommenen sch\u00f6nheit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Holdseliges geschlecht/ h\u00f6r an/ ich will dichs lehren/", "tokens": ["Hold\u00b7se\u00b7li\u00b7ges", "ge\u00b7schlecht", "/", "h\u00f6r", "an", "/", "ich", "will", "dichs", "leh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$(", "VVFIN", "PTKVZ", "$(", "PPER", "VMFIN", "PIS", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Wie es gestalt mu\u00df seyn/ was man vor sch\u00f6n soll ehren.", "tokens": ["Wie", "es", "ge\u00b7stalt", "mu\u00df", "seyn", "/", "was", "man", "vor", "sch\u00f6n", "soll", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "VMFIN", "VAINF", "$(", "PWS", "PIS", "APPR", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Li\u00df diese zeilen durch/ so wird dir seyn bekant/", "tokens": ["Li\u00df", "die\u00b7se", "zei\u00b7len", "durch", "/", "so", "wird", "dir", "seyn", "be\u00b7kant", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VVFIN", "APPR", "$(", "ADV", "VAFIN", "PPER", "PPOSAT", "ADJD", "$("], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Wodurch die Helena so trefflich sch\u00f6n genant.", "tokens": ["Wo\u00b7durch", "die", "He\u00b7le\u00b7na", "so", "treff\u00b7lich", "sch\u00f6n", "ge\u00b7nant", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NE", "ADV", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der leib mu\u00df seine pracht erst von den farben haben/", "tokens": ["Der", "leib", "mu\u00df", "sei\u00b7ne", "pracht", "erst", "von", "den", "far\u00b7ben", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von diesen m\u00fcssen drey sich gleichen schwartzen raben/", "tokens": ["Von", "die\u00b7sen", "m\u00fcs\u00b7sen", "drey", "sich", "glei\u00b7chen", "schwart\u00b7zen", "ra\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "CARD", "PRF", "ADJA", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drey m\u00fcssen wie der schnee so wei\u00df seyn anzusehn/", "tokens": ["Drey", "m\u00fcs\u00b7sen", "wie", "der", "schnee", "so", "wei\u00df", "seyn", "an\u00b7zu\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "KOKOM", "ART", "NN", "ADV", "ADJD", "VAINF", "VVIZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Drey die an r\u00f6the selbst den purpur \u00fcbergehn.", "tokens": ["Drey", "die", "an", "r\u00f6\u00b7the", "selbst", "den", "pur\u00b7pur", "\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ART", "APPR", "VVFIN", "ADV", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Drey andre m\u00fcssen ruhm durch ihre k\u00fcrtz\u2019 erlangen/", "tokens": ["Drey", "and\u00b7re", "m\u00fcs\u00b7sen", "ruhm", "durch", "ih\u00b7re", "k\u00fcrtz'", "er\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "PIS", "VMFIN", "NN", "APPR", "PPOSAT", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Hingegen andre drey mit sch\u00f6ner l\u00e4nge prangen;", "tokens": ["Hin\u00b7ge\u00b7gen", "and\u00b7re", "drey", "mit", "sch\u00f6\u00b7ner", "l\u00e4n\u00b7ge", "pran\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "CARD", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.11": {"text": "Drey m\u00fcssen seyn was dick/ doch wolgebildt dabey/", "tokens": ["Drey", "m\u00fcs\u00b7sen", "seyn", "was", "dick", "/", "doch", "wol\u00b7ge\u00b7bildt", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "VAINF", "PWS", "ADJD", "$(", "ADV", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Darneben m\u00fcssen schmal und schlanck seyn andre drey.", "tokens": ["Dar\u00b7ne\u00b7ben", "m\u00fcs\u00b7sen", "schmal", "und", "schlanck", "seyn", "and\u00b7re", "drey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ADV", "KON", "VVFIN", "PPOSAT", "ADJA", "CARD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die weite mu\u00df man auch an eben so viel r\u00fchmen/", "tokens": ["Die", "wei\u00b7te", "mu\u00df", "man", "auch", "an", "e\u00b7ben", "so", "viel", "r\u00fch\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "PIS", "ADV", "APPR", "ADV", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und andern gleicher zahl will eng zu seyn geziemen.", "tokens": ["Und", "an\u00b7dern", "glei\u00b7cher", "zahl", "will", "eng", "zu", "seyn", "ge\u00b7zie\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "VMFIN", "ADJD", "PTKZU", "VAINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wenn man zu diesen f\u00fcgt drey/ welche zierlich klein/", "tokens": ["Wenn", "man", "zu", "die\u00b7sen", "f\u00fcgt", "drey", "/", "wel\u00b7che", "zier\u00b7lich", "klein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PDAT", "VVFIN", "CARD", "$(", "PRELS", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So kan die sch\u00f6nheit selbst nicht vollenkommner seyn.", "tokens": ["So", "kan", "die", "sch\u00f6n\u00b7heit", "selbst", "nicht", "vol\u00b7len\u00b7komm\u00b7ner", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die augen preiset man/ die schwartzen kohlen gleichen/", "tokens": ["Die", "au\u00b7gen", "prei\u00b7set", "man", "/", "die", "schwart\u00b7zen", "koh\u00b7len", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "$(", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "An strahlen aber doch der sonnen selbst nicht weichen;", "tokens": ["An", "strah\u00b7len", "a\u00b7ber", "doch", "der", "son\u00b7nen", "selbst", "nicht", "wei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "ADV", "ART", "ADJA", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und umb dieselbe mu\u00df ein schwartzer bogen gehn/", "tokens": ["Und", "umb", "die\u00b7sel\u00b7be", "mu\u00df", "ein", "schwart\u00b7zer", "bo\u00b7gen", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Dadurch di\u00df sternen-paar kan \u00fcberschattet stehn.", "tokens": ["Da\u00b7durch", "di\u00df", "ster\u00b7nen\u00b7paar", "kan", "\u00fc\u00b7bersc\u00b7hat\u00b7tet", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PDS", "NN", "VMFIN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zum dritten mu\u00df der pusch/ der jene h\u00f6le decket/", "tokens": ["Zum", "drit\u00b7ten", "mu\u00df", "der", "pusch", "/", "der", "je\u00b7ne", "h\u00f6\u00b7le", "de\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VMFIN", "ART", "ADJD", "$(", "ART", "PDAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "In welcher Venus selbst das ziel der brunst verstecket/", "tokens": ["In", "wel\u00b7cher", "Ve\u00b7nus", "selbst", "das", "ziel", "der", "brunst", "ver\u00b7ste\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Gantz eingeh\u00fcllet seyn in schwartze dunckelheit/", "tokens": ["Gantz", "ein\u00b7ge\u00b7h\u00fcl\u00b7let", "seyn", "in", "schwart\u00b7ze", "dun\u00b7ckel\u00b7heit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAINF", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Weil Amor solch ein kind/ das sich im dunckeln freut.", "tokens": ["Weil", "A\u00b7mor", "solch", "ein", "kind", "/", "das", "sich", "im", "dun\u00b7ckeln", "freut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PIAT", "ART", "NN", "$(", "PRELS", "PRF", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die haare m\u00fcssen seyn so wei\u00df/ als reine seide/", "tokens": ["Die", "haa\u00b7re", "m\u00fcs\u00b7sen", "seyn", "so", "wei\u00df", "/", "als", "rei\u00b7ne", "sei\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "ADV", "VVFIN", "$(", "KOUS", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der alabaster-hal\u00df/ wie nie ber\u00fchrte kreide/", "tokens": ["Der", "a\u00b7la\u00b7bas\u00b7ter\u00b7ha\u00b7l\u00df", "/", "wie", "nie", "be\u00b7r\u00fchr\u00b7te", "krei\u00b7de", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOKOM", "ADV", "VVFIN", "VVFIN", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Die z\u00e4hne m\u00fc\u00dfen stehn/ wie blanckes helffenbein/", "tokens": ["Die", "z\u00e4h\u00b7ne", "m\u00fc\u00b7\u00dfen", "stehn", "/", "wie", "blan\u00b7ckes", "helf\u00b7fen\u00b7bein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$(", "KOKOM", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wenn sie von tadel gantz entfernet sollen seyn.", "tokens": ["Wenn", "sie", "von", "ta\u00b7del", "gantz", "ent\u00b7fer\u00b7net", "sol\u00b7len", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "ADV", "VVFIN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Er mu\u00df weit \u00fcbergehn die brennenden rubinen/", "tokens": ["Er", "mu\u00df", "weit", "\u00fc\u00b7ber\u00b7gehn", "die", "bren\u00b7nen\u00b7den", "ru\u00b7bi\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Soll sonst der lippen saum den rechten prei\u00df verdienen.", "tokens": ["Soll", "sonst", "der", "lip\u00b7pen", "saum", "den", "rech\u00b7ten", "prei\u00df", "ver\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die wangen/ die nicht roth/ sind nicht vollkommen sch\u00f6n/", "tokens": ["Die", "wan\u00b7gen", "/", "die", "nicht", "roth", "/", "sind", "nicht", "voll\u00b7kom\u00b7men", "sch\u00f6n", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PTKNEG", "ADJD", "$(", "VAFIN", "PTKNEG", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und auff den br\u00fcsten selbst mu\u00df roth am gipffel stehn.", "tokens": ["Und", "auff", "den", "br\u00fcs\u00b7ten", "selbst", "mu\u00df", "roth", "am", "gipf\u00b7fel", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "ADV", "VMFIN", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die z\u00e4hne m\u00fc\u00dfen kurtz nur seyn in ihren reihen/", "tokens": ["Die", "z\u00e4h\u00b7ne", "m\u00fc\u00b7\u00dfen", "kurtz", "nur", "seyn", "in", "ih\u00b7ren", "rei\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "ADV", "VAINF", "APPR", "PPOSAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Derselben ma\u00dfe sich die f\u00fcsse gleichsals weihen.", "tokens": ["Der\u00b7sel\u00b7ben", "ma\u00b7\u00dfe", "sich", "die", "f\u00fcs\u00b7se", "gleic\u00b7hsals", "wei\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Di\u00df einz\u2019ge giebet auch den ohren ihren prei\u00df/", "tokens": ["Di\u00df", "einz'\u00b7ge", "gie\u00b7bet", "auch", "den", "oh\u00b7ren", "ih\u00b7ren", "prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Da\u00df man/ wie andre theil/ sie sch\u00f6n zu nennen wei\u00df.", "tokens": ["Da\u00df", "man", "/", "wie", "and\u00b7re", "theil", "/", "sie", "sch\u00f6n", "zu", "nen\u00b7nen", "wei\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$(", "KOKOM", "ADJA", "NN", "$(", "PPER", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Es mu\u00df ein sch\u00f6ner leib sich nach den g\u2019raden sichten/", "tokens": ["Es", "mu\u00df", "ein", "sch\u00f6\u00b7ner", "leib", "sich", "nach", "den", "g'\u00b7ra\u00b7den", "sich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Die wie die s\u00e4ulen stehn/ in seiner l\u00e4nge richten.", "tokens": ["Die", "wie", "die", "s\u00e4u\u00b7len", "stehn", "/", "in", "sei\u00b7ner", "l\u00e4n\u00b7ge", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "NN", "VVINF", "$(", "APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Die h\u00e4nde/ die mit lust der liebe z\u00fcgel f\u00fchrn/", "tokens": ["Die", "h\u00e4n\u00b7de", "/", "die", "mit", "lust", "der", "lie\u00b7be", "z\u00fc\u00b7gel", "f\u00fchrn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "ART", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Mu\u00df/ wenn sie zierlich sind/ gew\u00fcnschte l\u00e4nge ziern.", "tokens": ["Mu\u00df", "/", "wenn", "sie", "zier\u00b7lich", "sind", "/", "ge\u00b7w\u00fcnschte", "l\u00e4n\u00b7ge", "zi\u00b7ern", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$(", "KOUS", "PPER", "ADJD", "VAFIN", "$(", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.41": {"text": "Und soll dem Venus-sohn die liebes-jagt gel\u00fccken/", "tokens": ["Und", "soll", "dem", "Ve\u00b7nus\u00b7sohn", "die", "lie\u00b7bes\u00b7jagt", "ge\u00b7l\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Mu\u00df er aus langem haar ihm netz und sehnen stricken.", "tokens": ["Mu\u00df", "er", "aus", "lan\u00b7gem", "haar", "ihm", "netz", "und", "seh\u00b7nen", "stri\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ADJA", "NN", "PPER", "NE", "KON", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Denn soll in sclaverey die freyheit seyn gebracht/", "tokens": ["Denn", "soll", "in", "scla\u00b7ve\u00b7rey", "die", "frey\u00b7heit", "seyn", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "NN", "ART", "NN", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "So m\u00fcssen fe\u00dfeln seyn aus langem haar gemacht.", "tokens": ["So", "m\u00fcs\u00b7sen", "fe\u00b7\u00df\u00b7eln", "seyn", "aus", "lan\u00b7gem", "haar", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.45": {"text": "Es ist ein solcher leib vor andren hoch zu preisen/", "tokens": ["Es", "ist", "ein", "sol\u00b7cher", "leib", "vor", "an\u00b7dren", "hoch", "zu", "prei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "APPR", "PIS", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "An dem die h\u00fcfften sich in rechter dicke weisen.", "tokens": ["An", "dem", "die", "h\u00fcff\u00b7ten", "sich", "in", "rech\u00b7ter", "di\u00b7cke", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "PRF", "APPR", "ADJA", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Auch das/ was die natur zum sitz-platz au\u00dfersehn/", "tokens": ["Auch", "das", "/", "was", "die", "na\u00b7tur", "zum", "sitz\u00b7platz", "au\u00b7\u00dfer\u00b7sehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "PWS", "ART", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Ist dadurch/ wenn es dick und ausgef\u00fcllet/ sch\u00f6n.", "tokens": ["Ist", "da\u00b7durch", "/", "wenn", "es", "dick", "und", "aus\u00b7ge\u00b7f\u00fcl\u00b7let", "/", "sch\u00f6n", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PAV", "$(", "KOUS", "PPER", "ADJD", "KON", "VVFIN", "$(", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Und drittens mu\u00df der ort/ der unsre sinnen raubet/", "tokens": ["Und", "drit\u00b7tens", "mu\u00df", "der", "ort", "/", "der", "uns\u00b7re", "sin\u00b7nen", "rau\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Wenn er mit sch\u00f6ner kr\u00e4u\u00df\u2019 als ein gep\u00fcsch belaubet/", "tokens": ["Wenn", "er", "mit", "sch\u00f6\u00b7ner", "kr\u00e4u\u00df'", "als", "ein", "ge\u00b7p\u00fcsch", "be\u00b7lau\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "KOKOM", "ART", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Seyn einem h\u00fcgel gleich von bergen eingeh\u00fcllt/", "tokens": ["Seyn", "ei\u00b7nem", "h\u00fc\u00b7gel", "gleich", "von", "ber\u00b7gen", "ein\u00b7ge\u00b7h\u00fcllt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ART", "NN", "ADV", "APPR", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "So da\u00df er eine hand mit seiner dicke f\u00fcllt.", "tokens": ["So", "da\u00df", "er", "ei\u00b7ne", "hand", "mit", "sei\u00b7ner", "di\u00b7cke", "f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Die finger/ welche schmal und zierlich sich erstrecken/", "tokens": ["Die", "fin\u00b7ger", "/", "wel\u00b7che", "schmal", "und", "zier\u00b7lich", "sich", "er\u00b7stre\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "PRELS", "ADJD", "KON", "ADJD", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Die k\u00f6nnen/ was sonst halb erstorben/ aufferwecken/", "tokens": ["Die", "k\u00f6n\u00b7nen", "/", "was", "sonst", "halb", "ers\u00b7tor\u00b7ben", "/", "auf\u00b7fer\u00b7we\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VMFIN", "$(", "PWS", "ADV", "ADJD", "VVPP", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Und arme dieser art sind das gew\u00fcnschte band/", "tokens": ["Und", "ar\u00b7me", "die\u00b7ser", "art", "sind", "das", "ge\u00b7w\u00fcnschte", "band", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "PDAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.56": {"text": "Wodurch man an das joch der liebe wird gespan\u0303t.", "tokens": ["Wo\u00b7durch", "man", "an", "das", "joch", "der", "lie\u00b7be", "wird", "ge\u00b7spa\u00f1t", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "ART", "NN", "ART", "ADJA", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Auch mu\u00df ein sch\u00f6nes kind seyn schmal un\u0303 schlanck von beinen/", "tokens": ["Auch", "mu\u00df", "ein", "sch\u00f6\u00b7nes", "kind", "seyn", "schmal", "u\u00f1", "schlanck", "von", "bei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "PPOSAT", "ADJD", "KON", "VVFIN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Da\u00df/ wenn die flammen sich im mittel-punct vereinen/", "tokens": ["Da\u00df", "/", "wenn", "die", "flam\u00b7men", "sich", "im", "mit\u00b7tel\u00b7punct", "ver\u00b7ei\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "KOUS", "ART", "VVFIN", "PRF", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Gantz umb das oberste das unterste sich schwenckt/", "tokens": ["Gantz", "umb", "das", "o\u00b7bers\u00b7te", "das", "un\u00b7ters\u00b7te", "sich", "schwenckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "ART", "ADJA", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Gleichwie Adonis ward von Venus eingeschr\u00e4nckt.", "tokens": ["Gleich\u00b7wie", "A\u00b7do\u00b7nis", "ward", "von", "Ve\u00b7nus", "ein\u00b7ge\u00b7schr\u00e4nckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Der weite lob kan man au\u00df dreyen st\u00fccken lernen:", "tokens": ["Der", "wei\u00b7te", "lob", "kan", "man", "au\u00df", "drey\u00b7en", "st\u00fc\u00b7cken", "ler\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PIS", "APPR", "CARD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "An augenbraunen/ die von ander sich entfernen/", "tokens": ["An", "au\u00b7gen\u00b7brau\u00b7nen", "/", "die", "von", "an\u00b7der", "sich", "ent\u00b7fer\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "ART", "APPR", "ADJD", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "An lenden/ die nicht gar zu nah beysammen stehn/", "tokens": ["An", "len\u00b7den", "/", "die", "nicht", "gar", "zu", "nah", "bey\u00b7sam\u00b7men", "stehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "PRELS", "PTKNEG", "ADV", "PTKA", "ADJD", "VVINF", "VVINF", "$("], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.64": {"text": "Vornehmlich wenn man will in Amors irrgang gehn.", "tokens": ["Vor\u00b7nehm\u00b7lich", "wenn", "man", "will", "in", "A\u00b7mors", "irr\u00b7gang", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "VMFIN", "APPR", "NE", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Auch m\u00fc\u00dfen weit entfernt sich zeigen jene h\u00fcgel", "tokens": ["Auch", "m\u00fc\u00b7\u00dfen", "weit", "ent\u00b7fernt", "sich", "zei\u00b7gen", "je\u00b7ne", "h\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADJD", "ADJD", "PRF", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Der schwanen-gleichen brust/ da\u00df mit verh\u00e4ngtem z\u00fcgel", "tokens": ["Der", "schwa\u00b7nen\u00b7glei\u00b7chen", "brust", "/", "da\u00df", "mit", "ver\u00b7h\u00e4ng\u00b7tem", "z\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Die brunst/ wenn sie genug mit k\u00fc\u00dfen hat gespielt/", "tokens": ["Die", "brunst", "/", "wenn", "sie", "ge\u00b7nug", "mit", "k\u00fc\u00b7\u00dfen", "hat", "ge\u00b7spielt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOUS", "PPER", "ADV", "APPR", "VVINF", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Durch dieses thal kan gehn/ wo sie wird abgek\u00fchlt.", "tokens": ["Durch", "die\u00b7ses", "thal", "kan", "gehn", "/", "wo", "sie", "wird", "ab\u00b7ge\u00b7k\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "VVINF", "$(", "PWAV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Drey enge m\u00fc\u00dfen sich bey jenen dreyen weisen:", "tokens": ["Drey", "en\u00b7ge", "m\u00fc\u00b7\u00dfen", "sich", "bey", "je\u00b7nen", "drey\u00b7en", "wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "VMFIN", "PRF", "APPR", "PDAT", "CARD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Ein rosengleicher mund mu\u00df enge seyn zu preisen;", "tokens": ["Ein", "ro\u00b7sen\u00b7glei\u00b7cher", "mund", "mu\u00df", "en\u00b7ge", "seyn", "zu", "prei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADJA", "VAINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Die seiten m\u00fc\u00dfen eng und dicht zusammen seyn/", "tokens": ["Die", "sei\u00b7ten", "m\u00fc\u00b7\u00dfen", "eng", "und", "dicht", "zu\u00b7sam\u00b7men", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "KON", "ADJD", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Da\u00df eine ehle sie bey nah kan schlie\u00dfen ein.", "tokens": ["Da\u00df", "ei\u00b7ne", "eh\u00b7le", "sie", "bey", "nah", "kan", "schlie\u00b7\u00dfen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "PPER", "APPR", "ADJD", "VMFIN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Vor allen aber mu\u00df die grufft/ da Venus lachet/", "tokens": ["Vor", "al\u00b7len", "a\u00b7ber", "mu\u00df", "die", "grufft", "/", "da", "Ve\u00b7nus", "la\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "VMFIN", "ART", "NN", "$(", "KOUS", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Wo das/ was st\u00e4hlern schien/ wie wachs wird weich gemachet/", "tokens": ["Wo", "das", "/", "was", "st\u00e4h\u00b7lern", "schien", "/", "wie", "wachs", "wird", "weich", "ge\u00b7ma\u00b7chet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "$(", "PWS", "VVFIN", "VVFIN", "$(", "PWAV", "PIS", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Gantz enge seyn/ damit wenn unsre brunst entsteht/", "tokens": ["Gantz", "en\u00b7ge", "seyn", "/", "da\u00b7mit", "wenn", "uns\u00b7re", "brunst", "ent\u00b7steht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "VAINF", "$(", "PAV", "KOUS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Sie ein und wieder au\u00df mit mehrerm kitzel geht.", "tokens": ["Sie", "ein", "und", "wie\u00b7der", "au\u00df", "mit", "meh\u00b7rerm", "kit\u00b7zel", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "KON", "ADV", "APPR", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Und letzlich m\u00fc\u00dfen drey seyn zierlich klein zu nennen:", "tokens": ["Und", "letz\u00b7lich", "m\u00fc\u00b7\u00dfen", "drey", "seyn", "zier\u00b7lich", "klein", "zu", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "CARD", "PPOSAT", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Die nase mu\u00df man erst de\u00dfwegen loben k\u00f6nnen:", "tokens": ["Die", "na\u00b7se", "mu\u00df", "man", "erst", "de\u00df\u00b7we\u00b7gen", "lo\u00b7ben", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIS", "ADV", "PAV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Die br\u00fcste gleiches falls/ die eine hand spannt ein;", "tokens": ["Die", "br\u00fcs\u00b7te", "glei\u00b7ches", "falls", "/", "die", "ei\u00b7ne", "hand", "spannt", "ein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$(", "ART", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Die gipffel m\u00fc\u00dfen drauff gleich kleinen erdbeern seyn.", "tokens": ["Die", "gipf\u00b7fel", "m\u00fc\u00b7\u00dfen", "drauff", "gleich", "klei\u00b7nen", "erd\u00b7beern", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PAV", "ADV", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Wann dann der leib gebildt in solchem sch\u00f6nen wesen/", "tokens": ["Wann", "dann", "der", "leib", "ge\u00b7bildt", "in", "sol\u00b7chem", "sch\u00f6\u00b7nen", "we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVPP", "APPR", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "So hat zum wohnplatz ihn die liebe selbst erlesen/", "tokens": ["So", "hat", "zum", "wohn\u00b7platz", "ihn", "die", "lie\u00b7be", "selbst", "er\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "PPER", "ART", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Und wann an diesem auch bald di\u00df bald jenes fehlt/", "tokens": ["Und", "wann", "an", "die\u00b7sem", "auch", "bald", "di\u00df", "bald", "je\u00b7nes", "fehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "PDAT", "ADV", "ADV", "PDS", "ADV", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "So hat Cupido schon ein anders auserwehlt;", "tokens": ["So", "hat", "Cu\u00b7pi\u00b7do", "schon", "ein", "an\u00b7ders", "au\u00b7ser\u00b7wehlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "ADV", "ART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Dann wann die sch\u00f6nheit gleich nicht v\u00f6llig ist zu finden/", "tokens": ["Dann", "wann", "die", "sch\u00f6n\u00b7heit", "gleich", "nicht", "v\u00f6l\u00b7lig", "ist", "zu", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "ART", "NN", "ADV", "PTKNEG", "ADJD", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "So kan die freundlichkeit doch alles \u00fcberwinden:", "tokens": ["So", "kan", "die", "freund\u00b7lich\u00b7keit", "doch", "al\u00b7les", "\u00fc\u00b7berw\u00b7in\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Der nun die sch\u00f6nheit nicht auff allen gliedern schwebt/", "tokens": ["Der", "nun", "die", "sch\u00f6n\u00b7heit", "nicht", "auff", "al\u00b7len", "glie\u00b7dern", "schwebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "PTKNEG", "APPR", "PIS", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Der rath\u2019 ich/ da\u00df sie sich durch freundlichkeit erhebt.", "tokens": ["Der", "ra\u00b7th'", "ich", "/", "da\u00df", "sie", "sich", "durch", "freund\u00b7lich\u00b7keit", "er\u00b7hebt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.89": {"text": "Hie seht ihr/ sch\u00f6nstes volck/ wodurch ihr sch\u00f6n zu nennen/", "tokens": ["Hie", "seht", "ihr", "/", "sch\u00f6ns\u00b7tes", "volck", "/", "wo\u00b7durch", "ihr", "sch\u00f6n", "zu", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "ADJA", "NN", "$(", "PWAV", "PPER", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Werdt ihr ins k\u00fcnfftige mir besser nachricht g\u00f6nnen/", "tokens": ["Werdt", "ihr", "ins", "k\u00fcnff\u00b7ti\u00b7ge", "mir", "bes\u00b7ser", "nach\u00b7richt", "g\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "ADJA", "PPER", "ADJD", "VVPP", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Soll meine feder euch zum dienst seyn angewand/", "tokens": ["Soll", "mei\u00b7ne", "fe\u00b7der", "euch", "zum", "dienst", "seyn", "an\u00b7ge\u00b7wand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "APPRART", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Wenn ihr dieselbe f\u00fchrt mit eurer sch\u00f6nen hand.", "tokens": ["Wenn", "ihr", "die\u00b7sel\u00b7be", "f\u00fchrt", "mit", "eu\u00b7rer", "sch\u00f6\u00b7nen", "hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}