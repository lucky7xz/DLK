{"textgrid.poem.48594": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "4. Auf eines guten Freundes Geburtstag", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Liebe hat die Pierinnen", "tokens": ["Lie\u00b7be", "hat", "die", "Pie\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "erst auf meine Seite bracht,", "tokens": ["erst", "auf", "mei\u00b7ne", "Sei\u00b7te", "bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liebe hat mich lieb gemacht", "tokens": ["Lie\u00b7be", "hat", "mich", "lieb", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "bei den deutschen Kastalinnen,", "tokens": ["bei", "den", "deut\u00b7schen", "Kas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Liebe kan mit leichter Sachen", "tokens": ["Lie\u00b7be", "kan", "mit", "leich\u00b7ter", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "uns zu G\u00f6tter Freunde machen.", "tokens": ["uns", "zu", "G\u00f6t\u00b7ter", "Freun\u00b7de", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "ward ich anfangs dir verm\u00e4hlt!", "tokens": ["ward", "ich", "an\u00b7fangs", "dir", "ver\u00b7m\u00e4hlt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie, sie hat uns so umpf\u00e4hlt,", "tokens": ["Sie", ",", "sie", "hat", "uns", "so", "ump\u00b7f\u00e4hlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df uns nichts vonsammen triebe.", "tokens": ["da\u00df", "uns", "nichts", "von\u00b7sam\u00b7men", "trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was sich treu und standhaft nennet,", "tokens": ["Was", "sich", "treu", "und", "stand\u00b7haft", "nen\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wird durchaus durch nichts getrennet.", "tokens": ["wird", "durc\u00b7haus", "durch", "nichts", "ge\u00b7tren\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PIS", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Nun, du bist mir zwar genommen", "tokens": ["Nun", ",", "du", "bist", "mir", "zwar", "ge\u00b7nom\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "durch das Tun, so Alles nimmt;", "tokens": ["durch", "das", "Tun", ",", "so", "Al\u00b7les", "nimmt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "doch so lang' ein Auge glimmt,", "tokens": ["doch", "so", "lang'", "ein", "Au\u00b7ge", "glimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "solst du mir wol nicht entkommen.", "tokens": ["solst", "du", "mir", "wol", "nicht", "ent\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Musen, ihr und du, o Liebe,", "tokens": ["Mu\u00b7sen", ",", "ihr", "und", "du", ",", "o", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "KON", "PPER", "$,", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "fraget nichts nach jenem Diebe.", "tokens": ["fra\u00b7get", "nichts", "nach", "je\u00b7nem", "Die\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Weil ich athme, weil ich lebe,", "tokens": ["Weil", "ich", "ath\u00b7me", ",", "weil", "ich", "le\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "will ich schreiben, was ich kan,", "tokens": ["will", "ich", "schrei\u00b7ben", ",", "was", "ich", "kan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nur da\u00df dich der Bleckezahn", "tokens": ["nur", "da\u00df", "dich", "der", "Ble\u00b7cke\u00b7zahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tod ins Leben wieder gebe.", "tokens": ["Tod", "ins", "Le\u00b7ben", "wie\u00b7der", "ge\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wem sich Lieb' und Musen geben,", "tokens": ["Wem", "sich", "Lieb'", "und", "Mu\u00b7sen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der mu\u00df auch gestorben leben.", "tokens": ["der", "mu\u00df", "auch", "ge\u00b7stor\u00b7ben", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVPP", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach da\u00df nun doch Einer k\u00e4me,", "tokens": ["Ach", "da\u00df", "nun", "doch", "Ei\u00b7ner", "k\u00e4\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "ADV", "ADV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der mich so, wie ", "tokens": ["der", "mich", "so", ",", "wie"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "PPER", "ADV", "$,", "PWAV"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Her, wo ist ein solcher Freund,", "tokens": ["Her", ",", "wo", "ist", "ein", "sol\u00b7cher", "Freund", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VAFIN", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dem ich mich, wie ihm, bequeme?", "tokens": ["dem", "ich", "mich", ",", "wie", "ihm", ",", "be\u00b7que\u00b7me", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PRF", "$,", "PWAV", "PPER", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Liebe macht aus Fremden Br\u00fcder,", "tokens": ["Lie\u00b7be", "macht", "aus", "Frem\u00b7den", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ha\u00df aus Br\u00fcdern Fremde wieder.", "tokens": ["Ha\u00df", "aus", "Br\u00fc\u00b7dern", "Frem\u00b7de", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Bruder, meine mich mit Treuen,", "tokens": ["Bru\u00b7der", ",", "mei\u00b7ne", "mich", "mit", "Treu\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so du treu es meinen kanst!", "tokens": ["so", "du", "treu", "es", "mei\u00b7nen", "kanst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJD", "PPER", "VVFIN", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zoilus sein falscher Wanst", "tokens": ["Zoi\u00b7lus", "sein", "fal\u00b7scher", "Wanst"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPOSAT", "ADJA", "NN"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "berste, wie er will, von neuen!", "tokens": ["bers\u00b7te", ",", "wie", "er", "will", ",", "von", "neu\u00b7en", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "APPR", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ehrlich, treulich, standhaft Lieben", "tokens": ["Ehr\u00b7lich", ",", "treu\u00b7lich", ",", "stand\u00b7haft", "Lie\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ist f\u00fcr Neide stets doch blieben.", "tokens": ["ist", "f\u00fcr", "Nei\u00b7de", "stets", "doch", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Deiner Tugend weise Gaben", "tokens": ["Dei\u00b7ner", "Tu\u00b7gend", "wei\u00b7se", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "locken, Lieber, mich zu dir.", "tokens": ["lo\u00b7cken", ",", "Lie\u00b7ber", ",", "mich", "zu", "dir", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVINF", "$,", "ADJD", "$,", "PRF", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun so komm! Da solst an mir,", "tokens": ["Nun", "so", "komm", "!", "Da", "solst", "an", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$.", "ADV", "VMFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was die Liebe w\u00fcndschet, haben.", "tokens": ["was", "die", "Lie\u00b7be", "w\u00fcnd\u00b7schet", ",", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ein Herz ein Herze krieget,", "tokens": ["Wenn", "ein", "Herz", "ein", "Her\u00b7ze", "krie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das ihm gleicht, so ists vergn\u00fcget.", "tokens": ["das", "ihm", "gleicht", ",", "so", "ists", "ver\u00b7gn\u00fc\u00b7get", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sonst hab' ich auch \u00fcber Hoffen", "tokens": ["Sonst", "hab'", "ich", "auch", "\u00fc\u00b7ber", "Hof\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Einen, der sich mir und dir,", "tokens": ["Ei\u00b7nen", ",", "der", "sich", "mir", "und", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PRF", "PPER", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der sich ", "tokens": ["der", "sich"], "token_info": ["word", "word"], "pos": ["ART", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "durch die G\u00f6tter angetroffen.", "tokens": ["durch", "die", "G\u00f6t\u00b7ter", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach wie selten kan erreichen", "tokens": ["Ach", "wie", "sel\u00b7ten", "kan", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ADJD", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ein treu Herze seinesgleichen!", "tokens": ["ein", "treu", "Her\u00b7ze", "sei\u00b7nes\u00b7glei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Er mein Leben, du mein Leben,", "tokens": ["Er", "mein", "Le\u00b7ben", ",", "du", "mein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "euer beider Leben ich,", "tokens": ["eu\u00b7er", "bei\u00b7der", "Le\u00b7ben", "ich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ich durch euch und ihr durch mich,", "tokens": ["ich", "durch", "euch", "und", "ihr", "durch", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "KON", "PPER", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wollen bis ans Blaue schweben.", "tokens": ["wol\u00b7len", "bis", "ans", "Blau\u00b7e", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unser' Namen schwingt die Liebe", "tokens": ["Un\u00b7ser'", "Na\u00b7men", "schwingt", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcber Nebel durch das Tr\u00fcbe.", "tokens": ["\u00fc\u00b7ber", "Ne\u00b7bel", "durch", "das", "Tr\u00fc\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Komme, so du ihn zu sehen", "tokens": ["Kom\u00b7me", ",", "so", "du", "ihn", "zu", "se\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "PPER", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lust und ein Verlangen hast!", "tokens": ["Lust", "und", "ein", "Ver\u00b7lan\u00b7gen", "hast", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch er mu\u00df sein unser Gast,", "tokens": ["Doch", "er", "mu\u00df", "sein", "un\u00b7ser", "Gast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn die L\u00f6sung soll geschehen.", "tokens": ["wenn", "die", "L\u00f6\u00b7sung", "soll", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Besser ist nicht treuen Flammen,", "tokens": ["Bes\u00b7ser", "ist", "nicht", "treu\u00b7en", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "als im Fall' sie sind beisammen.", "tokens": ["als", "im", "Fall'", "sie", "sind", "bei\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Liebe hat mich erst geliebet,", "tokens": ["Lie\u00b7be", "hat", "mich", "erst", "ge\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebe hat mich wert gemacht,", "tokens": ["Lie\u00b7be", "hat", "mich", "wert", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liebe hat mir wieder bracht", "tokens": ["Lie\u00b7be", "hat", "mir", "wie\u00b7der", "bracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was der Tod mir abgediebet.", "tokens": ["was", "der", "Tod", "mir", "ab\u00b7ge\u00b7die\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "In der Liebe will ich bleiben,", "tokens": ["In", "der", "Lie\u00b7be", "will", "ich", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "bis er mich auch ab wird leiben.", "tokens": ["bis", "er", "mich", "auch", "ab", "wird", "lei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKVZ", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Liebe hat die Pierinnen", "tokens": ["Lie\u00b7be", "hat", "die", "Pie\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "erst auf meine Seite bracht,", "tokens": ["erst", "auf", "mei\u00b7ne", "Sei\u00b7te", "bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liebe hat mich lieb gemacht", "tokens": ["Lie\u00b7be", "hat", "mich", "lieb", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "bei den deutschen Kastalinnen,", "tokens": ["bei", "den", "deut\u00b7schen", "Kas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Liebe kan mit leichter Sachen", "tokens": ["Lie\u00b7be", "kan", "mit", "leich\u00b7ter", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "uns zu G\u00f6tter Freunde machen.", "tokens": ["uns", "zu", "G\u00f6t\u00b7ter", "Freun\u00b7de", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "ward ich anfangs dir verm\u00e4hlt!", "tokens": ["ward", "ich", "an\u00b7fangs", "dir", "ver\u00b7m\u00e4hlt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie, sie hat uns so umpf\u00e4hlt,", "tokens": ["Sie", ",", "sie", "hat", "uns", "so", "ump\u00b7f\u00e4hlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df uns nichts vonsammen triebe.", "tokens": ["da\u00df", "uns", "nichts", "von\u00b7sam\u00b7men", "trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was sich treu und standhaft nennet,", "tokens": ["Was", "sich", "treu", "und", "stand\u00b7haft", "nen\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wird durchaus durch nichts getrennet.", "tokens": ["wird", "durc\u00b7haus", "durch", "nichts", "ge\u00b7tren\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PIS", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Nun, du bist mir zwar genommen", "tokens": ["Nun", ",", "du", "bist", "mir", "zwar", "ge\u00b7nom\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "durch das Tun, so Alles nimmt;", "tokens": ["durch", "das", "Tun", ",", "so", "Al\u00b7les", "nimmt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "doch so lang' ein Auge glimmt,", "tokens": ["doch", "so", "lang'", "ein", "Au\u00b7ge", "glimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "solst du mir wol nicht entkommen.", "tokens": ["solst", "du", "mir", "wol", "nicht", "ent\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Musen, ihr und du, o Liebe,", "tokens": ["Mu\u00b7sen", ",", "ihr", "und", "du", ",", "o", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "KON", "PPER", "$,", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "fraget nichts nach jenem Diebe.", "tokens": ["fra\u00b7get", "nichts", "nach", "je\u00b7nem", "Die\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Weil ich athme, weil ich lebe,", "tokens": ["Weil", "ich", "ath\u00b7me", ",", "weil", "ich", "le\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "will ich schreiben, was ich kan,", "tokens": ["will", "ich", "schrei\u00b7ben", ",", "was", "ich", "kan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nur da\u00df dich der Bleckezahn", "tokens": ["nur", "da\u00df", "dich", "der", "Ble\u00b7cke\u00b7zahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Tod ins Leben wieder gebe.", "tokens": ["Tod", "ins", "Le\u00b7ben", "wie\u00b7der", "ge\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wem sich Lieb' und Musen geben,", "tokens": ["Wem", "sich", "Lieb'", "und", "Mu\u00b7sen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der mu\u00df auch gestorben leben.", "tokens": ["der", "mu\u00df", "auch", "ge\u00b7stor\u00b7ben", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVPP", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ach da\u00df nun doch Einer k\u00e4me,", "tokens": ["Ach", "da\u00df", "nun", "doch", "Ei\u00b7ner", "k\u00e4\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "ADV", "ADV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der mich so, wie ", "tokens": ["der", "mich", "so", ",", "wie"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "PPER", "ADV", "$,", "PWAV"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Her, wo ist ein solcher Freund,", "tokens": ["Her", ",", "wo", "ist", "ein", "sol\u00b7cher", "Freund", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VAFIN", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dem ich mich, wie ihm, bequeme?", "tokens": ["dem", "ich", "mich", ",", "wie", "ihm", ",", "be\u00b7que\u00b7me", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PRF", "$,", "PWAV", "PPER", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Liebe macht aus Fremden Br\u00fcder,", "tokens": ["Lie\u00b7be", "macht", "aus", "Frem\u00b7den", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ha\u00df aus Br\u00fcdern Fremde wieder.", "tokens": ["Ha\u00df", "aus", "Br\u00fc\u00b7dern", "Frem\u00b7de", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Bruder, meine mich mit Treuen,", "tokens": ["Bru\u00b7der", ",", "mei\u00b7ne", "mich", "mit", "Treu\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so du treu es meinen kanst!", "tokens": ["so", "du", "treu", "es", "mei\u00b7nen", "kanst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJD", "PPER", "VVFIN", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zoilus sein falscher Wanst", "tokens": ["Zoi\u00b7lus", "sein", "fal\u00b7scher", "Wanst"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPOSAT", "ADJA", "NN"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "berste, wie er will, von neuen!", "tokens": ["bers\u00b7te", ",", "wie", "er", "will", ",", "von", "neu\u00b7en", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "APPR", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ehrlich, treulich, standhaft Lieben", "tokens": ["Ehr\u00b7lich", ",", "treu\u00b7lich", ",", "stand\u00b7haft", "Lie\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ist f\u00fcr Neide stets doch blieben.", "tokens": ["ist", "f\u00fcr", "Nei\u00b7de", "stets", "doch", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Deiner Tugend weise Gaben", "tokens": ["Dei\u00b7ner", "Tu\u00b7gend", "wei\u00b7se", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "locken, Lieber, mich zu dir.", "tokens": ["lo\u00b7cken", ",", "Lie\u00b7ber", ",", "mich", "zu", "dir", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVINF", "$,", "ADJD", "$,", "PRF", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun so komm! Da solst an mir,", "tokens": ["Nun", "so", "komm", "!", "Da", "solst", "an", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$.", "ADV", "VMFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was die Liebe w\u00fcndschet, haben.", "tokens": ["was", "die", "Lie\u00b7be", "w\u00fcnd\u00b7schet", ",", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ein Herz ein Herze krieget,", "tokens": ["Wenn", "ein", "Herz", "ein", "Her\u00b7ze", "krie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das ihm gleicht, so ists vergn\u00fcget.", "tokens": ["das", "ihm", "gleicht", ",", "so", "ists", "ver\u00b7gn\u00fc\u00b7get", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Sonst hab' ich auch \u00fcber Hoffen", "tokens": ["Sonst", "hab'", "ich", "auch", "\u00fc\u00b7ber", "Hof\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Einen, der sich mir und dir,", "tokens": ["Ei\u00b7nen", ",", "der", "sich", "mir", "und", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PRF", "PPER", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der sich ", "tokens": ["der", "sich"], "token_info": ["word", "word"], "pos": ["ART", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "durch die G\u00f6tter angetroffen.", "tokens": ["durch", "die", "G\u00f6t\u00b7ter", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach wie selten kan erreichen", "tokens": ["Ach", "wie", "sel\u00b7ten", "kan", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ADJD", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ein treu Herze seinesgleichen!", "tokens": ["ein", "treu", "Her\u00b7ze", "sei\u00b7nes\u00b7glei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Er mein Leben, du mein Leben,", "tokens": ["Er", "mein", "Le\u00b7ben", ",", "du", "mein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "euer beider Leben ich,", "tokens": ["eu\u00b7er", "bei\u00b7der", "Le\u00b7ben", "ich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ich durch euch und ihr durch mich,", "tokens": ["ich", "durch", "euch", "und", "ihr", "durch", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "KON", "PPER", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wollen bis ans Blaue schweben.", "tokens": ["wol\u00b7len", "bis", "ans", "Blau\u00b7e", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unser' Namen schwingt die Liebe", "tokens": ["Un\u00b7ser'", "Na\u00b7men", "schwingt", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcber Nebel durch das Tr\u00fcbe.", "tokens": ["\u00fc\u00b7ber", "Ne\u00b7bel", "durch", "das", "Tr\u00fc\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Komme, so du ihn zu sehen", "tokens": ["Kom\u00b7me", ",", "so", "du", "ihn", "zu", "se\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "PPER", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lust und ein Verlangen hast!", "tokens": ["Lust", "und", "ein", "Ver\u00b7lan\u00b7gen", "hast", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch er mu\u00df sein unser Gast,", "tokens": ["Doch", "er", "mu\u00df", "sein", "un\u00b7ser", "Gast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn die L\u00f6sung soll geschehen.", "tokens": ["wenn", "die", "L\u00f6\u00b7sung", "soll", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Besser ist nicht treuen Flammen,", "tokens": ["Bes\u00b7ser", "ist", "nicht", "treu\u00b7en", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "als im Fall' sie sind beisammen.", "tokens": ["als", "im", "Fall'", "sie", "sind", "bei\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Liebe hat mich erst geliebet,", "tokens": ["Lie\u00b7be", "hat", "mich", "erst", "ge\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebe hat mich wert gemacht,", "tokens": ["Lie\u00b7be", "hat", "mich", "wert", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liebe hat mir wieder bracht", "tokens": ["Lie\u00b7be", "hat", "mir", "wie\u00b7der", "bracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was der Tod mir abgediebet.", "tokens": ["was", "der", "Tod", "mir", "ab\u00b7ge\u00b7die\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "In der Liebe will ich bleiben,", "tokens": ["In", "der", "Lie\u00b7be", "will", "ich", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "bis er mich auch ab wird leiben.", "tokens": ["bis", "er", "mich", "auch", "ab", "wird", "lei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKVZ", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}