{"textgrid.poem.57748": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Ein Wiegenlied", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie sangen ihm von Avalun,", "tokens": ["Sie", "san\u00b7gen", "ihm", "von", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gelb war sein Haar,", "tokens": ["Gelb", "war", "sein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "In Avalun, da sollst du ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "sollst", "du", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00dcber das Jahr;", "tokens": ["\u00dc\u00b7ber", "das", "Jahr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Avalun, das sch\u00f6ne Land,", "tokens": ["A\u00b7val\u00b7un", ",", "das", "sch\u00f6\u00b7ne", "Land", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ganz und gar von Zuckerkand,", "tokens": ["Ganz", "und", "gar", "von", "Zu\u00b7cker\u00b7kand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Der J\u00fcngling rief: O Avalun,", "tokens": ["Der", "J\u00fcng\u00b7ling", "rief", ":", "O", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blond ist mein Haar,", "tokens": ["Blond", "ist", "mein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "In Avalun, da will ich ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "will", "ich", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Heute \u00fcbers Jahr;", "tokens": ["Heu\u00b7te", "\u00fc\u00b7bers", "Jahr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Avalun ist nicht mehr fern,", "tokens": ["A\u00b7val\u00b7un", "ist", "nicht", "mehr", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun, du roter Stern,", "tokens": ["A\u00b7val\u00b7un", ",", "du", "ro\u00b7ter", "Stern", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Es sprach der Mann: O Avalun,", "tokens": ["Es", "sprach", "der", "Mann", ":", "O", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fahl wird mein Haar,", "tokens": ["Fahl", "wird", "mein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "In Avalun, da will ich ruh'n,", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "will", "ich", "ruh'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich reit' schon drei\u00dfig Jahr;", "tokens": ["Ich", "reit'", "schon", "drei\u00b7\u00dfig", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Avalun ist nicht mehr weit,", "tokens": ["A\u00b7val\u00b7un", "ist", "nicht", "mehr", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun, o Seligkeit,", "tokens": ["A\u00b7val\u00b7un", ",", "o", "Se\u00b7lig\u00b7keit", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Es seufzt der Greis: O Avalun,", "tokens": ["Es", "seufzt", "der", "Greis", ":", "O", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Grau ist mein Haar,", "tokens": ["Grau", "ist", "mein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "In Avalun, da will ich ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "will", "ich", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun bin ich siebzig Jahr';", "tokens": ["Nun", "bin", "ich", "sieb\u00b7zig", "Jahr'", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Avalun, bald bin ich da,", "tokens": ["A\u00b7val\u00b7un", ",", "bald", "bin", "ich", "da", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun, ich seh' es ja,", "tokens": ["A\u00b7val\u00b7un", ",", "ich", "seh'", "es", "ja", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Sie fuhren ihn nach Avalun,", "tokens": ["Sie", "fuh\u00b7ren", "ihn", "nach", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wei\u00df war sein Haar,", "tokens": ["Wei\u00df", "war", "sein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "In Avalun, da sollst du ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "sollst", "du", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jahr \u00fcber Jahr;", "tokens": ["Jahr", "\u00fc\u00b7ber", "Jahr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Avalun, das ist der Tod,", "tokens": ["A\u00b7val\u00b7un", ",", "das", "ist", "der", "Tod", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun ist Nimmernot,", "tokens": ["A\u00b7val\u00b7un", "ist", "Nim\u00b7mer\u00b7not", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Sie sangen ihm von Avalun,", "tokens": ["Sie", "san\u00b7gen", "ihm", "von", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gelb war sein Haar,", "tokens": ["Gelb", "war", "sein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "In Avalun, da sollst du ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "sollst", "du", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00dcber das Jahr;", "tokens": ["\u00dc\u00b7ber", "das", "Jahr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Avalun, das sch\u00f6ne Land,", "tokens": ["A\u00b7val\u00b7un", ",", "das", "sch\u00f6\u00b7ne", "Land", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ganz und gar von Zuckerkand,", "tokens": ["Ganz", "und", "gar", "von", "Zu\u00b7cker\u00b7kand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Der J\u00fcngling rief: O Avalun,", "tokens": ["Der", "J\u00fcng\u00b7ling", "rief", ":", "O", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blond ist mein Haar,", "tokens": ["Blond", "ist", "mein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "In Avalun, da will ich ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "will", "ich", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Heute \u00fcbers Jahr;", "tokens": ["Heu\u00b7te", "\u00fc\u00b7bers", "Jahr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Avalun ist nicht mehr fern,", "tokens": ["A\u00b7val\u00b7un", "ist", "nicht", "mehr", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun, du roter Stern,", "tokens": ["A\u00b7val\u00b7un", ",", "du", "ro\u00b7ter", "Stern", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Es sprach der Mann: O Avalun,", "tokens": ["Es", "sprach", "der", "Mann", ":", "O", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fahl wird mein Haar,", "tokens": ["Fahl", "wird", "mein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "In Avalun, da will ich ruh'n,", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "will", "ich", "ruh'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich reit' schon drei\u00dfig Jahr;", "tokens": ["Ich", "reit'", "schon", "drei\u00b7\u00dfig", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Avalun ist nicht mehr weit,", "tokens": ["A\u00b7val\u00b7un", "ist", "nicht", "mehr", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun, o Seligkeit,", "tokens": ["A\u00b7val\u00b7un", ",", "o", "Se\u00b7lig\u00b7keit", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Es seufzt der Greis: O Avalun,", "tokens": ["Es", "seufzt", "der", "Greis", ":", "O", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Grau ist mein Haar,", "tokens": ["Grau", "ist", "mein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "In Avalun, da will ich ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "will", "ich", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun bin ich siebzig Jahr';", "tokens": ["Nun", "bin", "ich", "sieb\u00b7zig", "Jahr'", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Avalun, bald bin ich da,", "tokens": ["A\u00b7val\u00b7un", ",", "bald", "bin", "ich", "da", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun, ich seh' es ja,", "tokens": ["A\u00b7val\u00b7un", ",", "ich", "seh'", "es", "ja", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Sie fuhren ihn nach Avalun,", "tokens": ["Sie", "fuh\u00b7ren", "ihn", "nach", "A\u00b7val\u00b7un", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wei\u00df war sein Haar,", "tokens": ["Wei\u00df", "war", "sein", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "In Avalun, da sollst du ruh'n", "tokens": ["In", "A\u00b7val\u00b7un", ",", "da", "sollst", "du", "ruh'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KOUS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jahr \u00fcber Jahr;", "tokens": ["Jahr", "\u00fc\u00b7ber", "Jahr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Avalun, das ist der Tod,", "tokens": ["A\u00b7val\u00b7un", ",", "das", "ist", "der", "Tod", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Avalun ist Nimmernot,", "tokens": ["A\u00b7val\u00b7un", "ist", "Nim\u00b7mer\u00b7not", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "O Avalun.", "tokens": ["O", "A\u00b7val\u00b7un", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}