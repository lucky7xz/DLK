{"textgrid.poem.48572": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "4. Auf eine Hochzeit zu Dresden", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kleiner Gott der gro\u00dfen Glut,", "tokens": ["Klei\u00b7ner", "Gott", "der", "gro\u00b7\u00dfen", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die uns Herz und Seelen zwinget,", "tokens": ["die", "uns", "Herz", "und", "See\u00b7len", "zwin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die durch Mark und Seele dringet", "tokens": ["die", "durch", "Mark", "und", "See\u00b7le", "drin\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und versenget Sin und Mut,", "tokens": ["und", "ver\u00b7sen\u00b7get", "Sin", "und", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "KON", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "sieh die zwei Verliebten an,", "tokens": ["sieh", "die", "zwei", "Ver\u00b7lieb\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "CARD", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "schau an diese Frau und Man!", "tokens": ["schau", "an", "die\u00b7se", "Frau", "und", "Man", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PDAT", "NN", "KON", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Sieh sie an, das hei\u00dfe Paar,", "tokens": ["Sieh", "sie", "an", ",", "das", "hei\u00b7\u00dfe", "Paar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "das vor diesem deine St\u00e4rke", "tokens": ["das", "vor", "die\u00b7sem", "dei\u00b7ne", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "PDAT", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "auch befunden in dem Werke!", "tokens": ["auch", "be\u00b7fun\u00b7den", "in", "dem", "Wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das sonst auch verfreiet war,", "tokens": ["Das", "sonst", "auch", "ver\u00b7frei\u00b7et", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "spricht dich, wie es vor getan,", "tokens": ["spricht", "dich", ",", "wie", "es", "vor", "ge\u00b7tan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "PPER", "APPR", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wiederum zu dienen an.", "tokens": ["wie\u00b7de\u00b7rum", "zu", "die\u00b7nen", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Sag mir, was dein Dienst doch sei!", "tokens": ["Sag", "mir", ",", "was", "dein", "Dienst", "doch", "sei", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Es ist ein verkehrt Verlangen,", "tokens": ["Es", "ist", "ein", "ver\u00b7kehrt", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "VVPP", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da, ie mehr wir sind gefangen,", "tokens": ["da", ",", "ie", "mehr", "wir", "sind", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "ie mehr achten wir uns frei,", "tokens": ["ie", "mehr", "ach\u00b7ten", "wir", "uns", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und, ie mehr wir frei ausgehn,", "tokens": ["und", ",", "ie", "mehr", "wir", "frei", "aus\u00b7gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "ADV", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen wir in Diensten stehn.", "tokens": ["wol\u00b7len", "wir", "in", "Diens\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie ein s\u00fc\u00dfes Regiment", "tokens": ["Wie", "ein", "s\u00fc\u00b7\u00dfes", "Re\u00b7gi\u00b7ment"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "mu\u00df es doch sein um das deine!", "tokens": ["mu\u00df", "es", "doch", "sein", "um", "das", "dei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPOSAT", "APPR", "PRELS", "PPOSAT", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Das beweist mit klarem Scheine", "tokens": ["Das", "be\u00b7weist", "mit", "kla\u00b7rem", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "di\u00df, so abermalig brennt,", "tokens": ["di\u00df", ",", "so", "a\u00b7ber\u00b7ma\u00b7lig", "brennt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "dieses herzverliebte Paar", "tokens": ["die\u00b7ses", "herz\u00b7ver\u00b7lieb\u00b7te", "Paar"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und macht's durch sich selbsten klar.", "tokens": ["und", "macht's", "durch", "sich", "selbs\u00b7ten", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PRF", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Was uns sonsten nur erfreut,", "tokens": ["Was", "uns", "sons\u00b7ten", "nur", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "es sei was es sei auf Erden,", "tokens": ["es", "sei", "was", "es", "sei", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PWS", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "das mag nicht verglichen werden", "tokens": ["das", "mag", "nicht", "ver\u00b7gli\u00b7chen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PTKNEG", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mit der g\u00fcldnen Ledigkeit.", "tokens": ["mit", "der", "g\u00fcld\u00b7nen", "Le\u00b7dig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Es sei was es auch nur sei,", "tokens": ["Es", "sei", "was", "es", "auch", "nur", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PWS", "PPER", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "das ist froh, wenn es ist frei.", "tokens": ["das", "ist", "froh", ",", "wenn", "es", "ist", "frei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "VAFIN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Wenn die sch\u00f6ne Nachtigal", "tokens": ["Wenn", "die", "sch\u00f6\u00b7ne", "Nach\u00b7ti\u00b7gal"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "einmal aus der Wacht entsprungen,", "tokens": ["ein\u00b7mal", "aus", "der", "Wacht", "ent\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "hat man ihr auch vorgesungen", "tokens": ["hat", "man", "ihr", "auch", "vor\u00b7ge\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einen solchen s\u00fc\u00dfen Schall,", "tokens": ["ei\u00b7nen", "sol\u00b7chen", "s\u00fc\u00b7\u00dfen", "Schall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df sie wieder fl\u00f6g' herein", "tokens": ["da\u00df", "sie", "wie\u00b7der", "fl\u00f6g'", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und sich lie\u00dfe sperren ein?", "tokens": ["und", "sich", "lie\u00b7\u00dfe", "sper\u00b7ren", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Was uns einmal hat ergetzt,", "tokens": ["Was", "uns", "ein\u00b7mal", "hat", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "das verlockt uns das Gem\u00fcte", "tokens": ["das", "ver\u00b7lockt", "uns", "das", "Ge\u00b7m\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "immerdar durch seine G\u00fcte.", "tokens": ["im\u00b7mer\u00b7dar", "durch", "sei\u00b7ne", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was uns einmal hat verletzt,", "tokens": ["Was", "uns", "ein\u00b7mal", "hat", "ver\u00b7letzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "das fliehn und verh\u00fcten wir,", "tokens": ["das", "fliehn", "und", "ver\u00b7h\u00fc\u00b7ten", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "KON", "VVFIN", "PPER", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "wie wir k\u00f6nnen, f\u00fcr und f\u00fcr.", "tokens": ["wie", "wir", "k\u00f6n\u00b7nen", ",", "f\u00fcr", "und", "f\u00fcr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "$,", "APPR", "KON", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "W\u00e4re das Verehlichtsein", "tokens": ["W\u00e4\u00b7re", "das", "Ver\u00b7eh\u00b7lich\u00b7tsein"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "nichts als immer neue Plagen", "tokens": ["nichts", "als", "im\u00b7mer", "neu\u00b7e", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "KOKOM", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und, wie schlechte Leute sagen,", "tokens": ["und", ",", "wie", "schlech\u00b7te", "Leu\u00b7te", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADJA", "NN", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "eine liebe lange Pein,", "tokens": ["ei\u00b7ne", "lie\u00b7be", "lan\u00b7ge", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "was h\u00e4tt' euch denn angebracht,", "tokens": ["was", "h\u00e4tt'", "euch", "denn", "an\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df ihr wieder dran gedacht?", "tokens": ["da\u00df", "ihr", "wie\u00b7der", "dran", "ge\u00b7dacht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Ihr versichert uns durch euch,", "tokens": ["Ihr", "ver\u00b7si\u00b7chert", "uns", "durch", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df wir dem nun Glauben geben,", "tokens": ["da\u00df", "wir", "dem", "nun", "Glau\u00b7ben", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Liebe m\u00fcsse sein ein Leben,", "tokens": ["Lie\u00b7be", "m\u00fcs\u00b7se", "sein", "ein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPOSAT", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dem auch keins auf Erden gleich,", "tokens": ["dem", "auch", "keins", "auf", "Er\u00b7den", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "APPR", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df der, so sich ihr ergiebt,", "tokens": ["da\u00df", "der", ",", "so", "sich", "ihr", "er\u00b7giebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "ADV", "PRF", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Freiheit mehr als Dienste liebt.", "tokens": ["Frei\u00b7heit", "mehr", "als", "Diens\u00b7te", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "KOKOM", "PDS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Wol euch, die ihr dienstbar seid,", "tokens": ["Wol", "euch", ",", "die", "ihr", "dienst\u00b7bar", "seid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die ihr euch so wol verbunden!", "tokens": ["die", "ihr", "euch", "so", "wol", "ver\u00b7bun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr habt euer Gl\u00fccke funden", "tokens": ["Ihr", "habt", "eu\u00b7er", "Gl\u00fc\u00b7cke", "fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der freien Dienstbarkeit.", "tokens": ["in", "der", "frei\u00b7en", "Dienst\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihr seid, Liebe, ihr seid blos,", "tokens": ["Ihr", "seid", ",", "Lie\u00b7be", ",", "ihr", "seid", "blos", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "PPER", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mitten in dem Dienen los.", "tokens": ["mit\u00b7ten", "in", "dem", "Die\u00b7nen", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Wir, die wir noch m\u00fc\u00dfig stehn,", "tokens": ["Wir", ",", "die", "wir", "noch", "m\u00fc\u00b7\u00dfig", "stehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die wir dem gelobten Knaben", "tokens": ["die", "wir", "dem", "ge\u00b7lob\u00b7ten", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "uns noch nicht vermietet haben", "tokens": ["uns", "noch", "nicht", "ver\u00b7mie\u00b7tet", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "PTKNEG", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und in w\u00fcster Irre gehn,", "tokens": ["und", "in", "w\u00fcs\u00b7ter", "Ir\u00b7re", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "w\u00fcndschen euch Heil und Gewinst,", "tokens": ["w\u00fcnd\u00b7schen", "euch", "Heil", "und", "Ge\u00b7winst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "uns auch balde solchen Dienst.", "tokens": ["uns", "auch", "bal\u00b7de", "sol\u00b7chen", "Dienst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Kleiner Gott der gro\u00dfen Glut,", "tokens": ["Klei\u00b7ner", "Gott", "der", "gro\u00b7\u00dfen", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die uns Herz und Seelen zwinget,", "tokens": ["die", "uns", "Herz", "und", "See\u00b7len", "zwin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die durch Mark und Seele dringet", "tokens": ["die", "durch", "Mark", "und", "See\u00b7le", "drin\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und versenget Sin und Mut,", "tokens": ["und", "ver\u00b7sen\u00b7get", "Sin", "und", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "KON", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "sieh die zwei Verliebten an,", "tokens": ["sieh", "die", "zwei", "Ver\u00b7lieb\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "CARD", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "schau an diese Frau und Man!", "tokens": ["schau", "an", "die\u00b7se", "Frau", "und", "Man", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PDAT", "NN", "KON", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Sieh sie an, das hei\u00dfe Paar,", "tokens": ["Sieh", "sie", "an", ",", "das", "hei\u00b7\u00dfe", "Paar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "das vor diesem deine St\u00e4rke", "tokens": ["das", "vor", "die\u00b7sem", "dei\u00b7ne", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "PDAT", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "auch befunden in dem Werke!", "tokens": ["auch", "be\u00b7fun\u00b7den", "in", "dem", "Wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das sonst auch verfreiet war,", "tokens": ["Das", "sonst", "auch", "ver\u00b7frei\u00b7et", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "spricht dich, wie es vor getan,", "tokens": ["spricht", "dich", ",", "wie", "es", "vor", "ge\u00b7tan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "PPER", "APPR", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wiederum zu dienen an.", "tokens": ["wie\u00b7de\u00b7rum", "zu", "die\u00b7nen", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Sag mir, was dein Dienst doch sei!", "tokens": ["Sag", "mir", ",", "was", "dein", "Dienst", "doch", "sei", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Es ist ein verkehrt Verlangen,", "tokens": ["Es", "ist", "ein", "ver\u00b7kehrt", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "VVPP", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da, ie mehr wir sind gefangen,", "tokens": ["da", ",", "ie", "mehr", "wir", "sind", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "ie mehr achten wir uns frei,", "tokens": ["ie", "mehr", "ach\u00b7ten", "wir", "uns", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und, ie mehr wir frei ausgehn,", "tokens": ["und", ",", "ie", "mehr", "wir", "frei", "aus\u00b7gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "ADV", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "wollen wir in Diensten stehn.", "tokens": ["wol\u00b7len", "wir", "in", "Diens\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Wie ein s\u00fc\u00dfes Regiment", "tokens": ["Wie", "ein", "s\u00fc\u00b7\u00dfes", "Re\u00b7gi\u00b7ment"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "mu\u00df es doch sein um das deine!", "tokens": ["mu\u00df", "es", "doch", "sein", "um", "das", "dei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPOSAT", "APPR", "PRELS", "PPOSAT", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Das beweist mit klarem Scheine", "tokens": ["Das", "be\u00b7weist", "mit", "kla\u00b7rem", "Schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "di\u00df, so abermalig brennt,", "tokens": ["di\u00df", ",", "so", "a\u00b7ber\u00b7ma\u00b7lig", "brennt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "dieses herzverliebte Paar", "tokens": ["die\u00b7ses", "herz\u00b7ver\u00b7lieb\u00b7te", "Paar"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und macht's durch sich selbsten klar.", "tokens": ["und", "macht's", "durch", "sich", "selbs\u00b7ten", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PRF", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Was uns sonsten nur erfreut,", "tokens": ["Was", "uns", "sons\u00b7ten", "nur", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "es sei was es sei auf Erden,", "tokens": ["es", "sei", "was", "es", "sei", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PWS", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "das mag nicht verglichen werden", "tokens": ["das", "mag", "nicht", "ver\u00b7gli\u00b7chen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PTKNEG", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mit der g\u00fcldnen Ledigkeit.", "tokens": ["mit", "der", "g\u00fcld\u00b7nen", "Le\u00b7dig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Es sei was es auch nur sei,", "tokens": ["Es", "sei", "was", "es", "auch", "nur", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PWS", "PPER", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "das ist froh, wenn es ist frei.", "tokens": ["das", "ist", "froh", ",", "wenn", "es", "ist", "frei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "VAFIN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.17": {"line.1": {"text": "Wenn die sch\u00f6ne Nachtigal", "tokens": ["Wenn", "die", "sch\u00f6\u00b7ne", "Nach\u00b7ti\u00b7gal"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "einmal aus der Wacht entsprungen,", "tokens": ["ein\u00b7mal", "aus", "der", "Wacht", "ent\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "hat man ihr auch vorgesungen", "tokens": ["hat", "man", "ihr", "auch", "vor\u00b7ge\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einen solchen s\u00fc\u00dfen Schall,", "tokens": ["ei\u00b7nen", "sol\u00b7chen", "s\u00fc\u00b7\u00dfen", "Schall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df sie wieder fl\u00f6g' herein", "tokens": ["da\u00df", "sie", "wie\u00b7der", "fl\u00f6g'", "her\u00b7ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und sich lie\u00dfe sperren ein?", "tokens": ["und", "sich", "lie\u00b7\u00dfe", "sper\u00b7ren", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Was uns einmal hat ergetzt,", "tokens": ["Was", "uns", "ein\u00b7mal", "hat", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "das verlockt uns das Gem\u00fcte", "tokens": ["das", "ver\u00b7lockt", "uns", "das", "Ge\u00b7m\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "immerdar durch seine G\u00fcte.", "tokens": ["im\u00b7mer\u00b7dar", "durch", "sei\u00b7ne", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was uns einmal hat verletzt,", "tokens": ["Was", "uns", "ein\u00b7mal", "hat", "ver\u00b7letzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "das fliehn und verh\u00fcten wir,", "tokens": ["das", "fliehn", "und", "ver\u00b7h\u00fc\u00b7ten", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "KON", "VVFIN", "PPER", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "wie wir k\u00f6nnen, f\u00fcr und f\u00fcr.", "tokens": ["wie", "wir", "k\u00f6n\u00b7nen", ",", "f\u00fcr", "und", "f\u00fcr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VMFIN", "$,", "APPR", "KON", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "W\u00e4re das Verehlichtsein", "tokens": ["W\u00e4\u00b7re", "das", "Ver\u00b7eh\u00b7lich\u00b7tsein"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "nichts als immer neue Plagen", "tokens": ["nichts", "als", "im\u00b7mer", "neu\u00b7e", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "KOKOM", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und, wie schlechte Leute sagen,", "tokens": ["und", ",", "wie", "schlech\u00b7te", "Leu\u00b7te", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADJA", "NN", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "eine liebe lange Pein,", "tokens": ["ei\u00b7ne", "lie\u00b7be", "lan\u00b7ge", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "was h\u00e4tt' euch denn angebracht,", "tokens": ["was", "h\u00e4tt'", "euch", "denn", "an\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df ihr wieder dran gedacht?", "tokens": ["da\u00df", "ihr", "wie\u00b7der", "dran", "ge\u00b7dacht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Ihr versichert uns durch euch,", "tokens": ["Ihr", "ver\u00b7si\u00b7chert", "uns", "durch", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df wir dem nun Glauben geben,", "tokens": ["da\u00df", "wir", "dem", "nun", "Glau\u00b7ben", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Liebe m\u00fcsse sein ein Leben,", "tokens": ["Lie\u00b7be", "m\u00fcs\u00b7se", "sein", "ein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPOSAT", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dem auch keins auf Erden gleich,", "tokens": ["dem", "auch", "keins", "auf", "Er\u00b7den", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "APPR", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df der, so sich ihr ergiebt,", "tokens": ["da\u00df", "der", ",", "so", "sich", "ihr", "er\u00b7giebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "ADV", "PRF", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Freiheit mehr als Dienste liebt.", "tokens": ["Frei\u00b7heit", "mehr", "als", "Diens\u00b7te", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "KOKOM", "PDS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Wol euch, die ihr dienstbar seid,", "tokens": ["Wol", "euch", ",", "die", "ihr", "dienst\u00b7bar", "seid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die ihr euch so wol verbunden!", "tokens": ["die", "ihr", "euch", "so", "wol", "ver\u00b7bun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr habt euer Gl\u00fccke funden", "tokens": ["Ihr", "habt", "eu\u00b7er", "Gl\u00fc\u00b7cke", "fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der freien Dienstbarkeit.", "tokens": ["in", "der", "frei\u00b7en", "Dienst\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihr seid, Liebe, ihr seid blos,", "tokens": ["Ihr", "seid", ",", "Lie\u00b7be", ",", "ihr", "seid", "blos", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "PPER", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mitten in dem Dienen los.", "tokens": ["mit\u00b7ten", "in", "dem", "Die\u00b7nen", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Wir, die wir noch m\u00fc\u00dfig stehn,", "tokens": ["Wir", ",", "die", "wir", "noch", "m\u00fc\u00b7\u00dfig", "stehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die wir dem gelobten Knaben", "tokens": ["die", "wir", "dem", "ge\u00b7lob\u00b7ten", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "uns noch nicht vermietet haben", "tokens": ["uns", "noch", "nicht", "ver\u00b7mie\u00b7tet", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "PTKNEG", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und in w\u00fcster Irre gehn,", "tokens": ["und", "in", "w\u00fcs\u00b7ter", "Ir\u00b7re", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "w\u00fcndschen euch Heil und Gewinst,", "tokens": ["w\u00fcnd\u00b7schen", "euch", "Heil", "und", "Ge\u00b7winst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "uns auch balde solchen Dienst.", "tokens": ["uns", "auch", "bal\u00b7de", "sol\u00b7chen", "Dienst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}