{"textgrid.poem.46287": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Gartenbulschaft oder krantlieb", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich war in einem sch\u00f6nen garten,", "tokens": ["Ich", "war", "in", "ei\u00b7nem", "sch\u00f6\u00b7nen", "gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da der Braunellen ich must warten;", "tokens": ["da", "der", "Brau\u00b7nel\u00b7len", "ich", "must", "war\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "alsbald sie kam und sah mich an,", "tokens": ["als\u00b7bald", "sie", "kam", "und", "sah", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "empfanden wir das ", "tokens": ["emp\u00b7fan\u00b7den", "wir", "das"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "\u00bbach, was empfind ich in dem herzen!\u00ab", "tokens": ["\u00bb", "ach", ",", "was", "emp\u00b7find", "ich", "in", "dem", "her\u00b7zen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "PWS", "VVFIN", "PPER", "APPR", "ART", "VVINF", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "sprach sie; ich antwort: \u00bbla\u00df uns scherzen!", "tokens": ["sprach", "sie", ";", "ich", "ant\u00b7wort", ":", "\u00bb", "la\u00df", "uns", "scher\u00b7zen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "NN", "$.", "$(", "VVIMP", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "la\u00df uns mit ma\u00df und ohn ", "tokens": ["la\u00df", "uns", "mit", "ma\u00df", "und", "ohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "NN", "KON", "APPR"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.8": {"text": "la\u00df uns das ", "tokens": ["la\u00df", "uns", "das"], "token_info": ["word", "word", "word"], "pos": ["VVIMP", "PPER", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.9": {"text": "das so s\u00fc\u00df, under deinen schurz.\u00ab", "tokens": ["das", "so", "s\u00fc\u00df", ",", "un\u00b7der", "dei\u00b7nen", "schurz", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "ADV", "ADJD", "$,", "KON", "PPOSAT", "ADJD", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "\u00bbja, ", "tokens": ["\u00bb", "ja", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "PTKANT", "$,"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "sprach sie, \u00bbmir allzeit wol zuschlagen:", "tokens": ["sprach", "sie", ",", "\u00bb", "mir", "all\u00b7zeit", "wol", "zu\u00b7schla\u00b7gen", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.12": {"text": "dieweil sie gut f\u00fcr die, die bleich,", "tokens": ["die\u00b7weil", "sie", "gut", "f\u00fcr", "die", ",", "die", "bleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ART", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "so steck es tief in das ", "tokens": ["so", "steck", "es", "tief", "in", "das"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "wan es kein ", "tokens": ["wan", "es", "kein"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "PIAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "auch lieb und s\u00fc\u00df ist die ", "tokens": ["auch", "lieb", "und", "s\u00fc\u00df", "ist", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAFIN", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "mit ", "tokens": ["mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.17": {"text": "Dan seine tugend stets passieret.", "tokens": ["Dan", "sei\u00b7ne", "tu\u00b7gend", "stets", "pas\u00b7sie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "so bald es k\u00fctzelnd tief ber\u00fchret", "tokens": ["so", "bald", "es", "k\u00fct\u00b7zelnd", "tief", "be\u00b7r\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "ADJD", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "die zarte ", "tokens": ["die", "zar\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.20": {"text": "so wird es gleichsam ", "tokens": ["so", "wird", "es", "gleich\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "\u00bbes ist gnug, la\u00df nun ab zu scherzen,", "tokens": ["\u00bb", "es", "ist", "gnug", ",", "la\u00df", "nun", "ab", "zu", "scher\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "$,", "VVIMP", "ADV", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "bis wir einander wider herzen,", "tokens": ["bis", "wir", "ein\u00b7an\u00b7der", "wi\u00b7der", "her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "mein ", "tokens": ["mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}}, "stanza.2": {"line.1": {"text": "Ich war in einem sch\u00f6nen garten,", "tokens": ["Ich", "war", "in", "ei\u00b7nem", "sch\u00f6\u00b7nen", "gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da der Braunellen ich must warten;", "tokens": ["da", "der", "Brau\u00b7nel\u00b7len", "ich", "must", "war\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "alsbald sie kam und sah mich an,", "tokens": ["als\u00b7bald", "sie", "kam", "und", "sah", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "empfanden wir das ", "tokens": ["emp\u00b7fan\u00b7den", "wir", "das"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "\u00bbach, was empfind ich in dem herzen!\u00ab", "tokens": ["\u00bb", "ach", ",", "was", "emp\u00b7find", "ich", "in", "dem", "her\u00b7zen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "PWS", "VVFIN", "PPER", "APPR", "ART", "VVINF", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "sprach sie; ich antwort: \u00bbla\u00df uns scherzen!", "tokens": ["sprach", "sie", ";", "ich", "ant\u00b7wort", ":", "\u00bb", "la\u00df", "uns", "scher\u00b7zen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "NN", "$.", "$(", "VVIMP", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "la\u00df uns mit ma\u00df und ohn ", "tokens": ["la\u00df", "uns", "mit", "ma\u00df", "und", "ohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "NN", "KON", "APPR"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.8": {"text": "la\u00df uns das ", "tokens": ["la\u00df", "uns", "das"], "token_info": ["word", "word", "word"], "pos": ["VVIMP", "PPER", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.9": {"text": "das so s\u00fc\u00df, under deinen schurz.\u00ab", "tokens": ["das", "so", "s\u00fc\u00df", ",", "un\u00b7der", "dei\u00b7nen", "schurz", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "ADV", "ADJD", "$,", "KON", "PPOSAT", "ADJD", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "\u00bbja, ", "tokens": ["\u00bb", "ja", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "PTKANT", "$,"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "sprach sie, \u00bbmir allzeit wol zuschlagen:", "tokens": ["sprach", "sie", ",", "\u00bb", "mir", "all\u00b7zeit", "wol", "zu\u00b7schla\u00b7gen", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.12": {"text": "dieweil sie gut f\u00fcr die, die bleich,", "tokens": ["die\u00b7weil", "sie", "gut", "f\u00fcr", "die", ",", "die", "bleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ART", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "so steck es tief in das ", "tokens": ["so", "steck", "es", "tief", "in", "das"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "wan es kein ", "tokens": ["wan", "es", "kein"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "PIAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "auch lieb und s\u00fc\u00df ist die ", "tokens": ["auch", "lieb", "und", "s\u00fc\u00df", "ist", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAFIN", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "mit ", "tokens": ["mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.17": {"text": "Dan seine tugend stets passieret.", "tokens": ["Dan", "sei\u00b7ne", "tu\u00b7gend", "stets", "pas\u00b7sie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "so bald es k\u00fctzelnd tief ber\u00fchret", "tokens": ["so", "bald", "es", "k\u00fct\u00b7zelnd", "tief", "be\u00b7r\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "ADJD", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "die zarte ", "tokens": ["die", "zar\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.20": {"text": "so wird es gleichsam ", "tokens": ["so", "wird", "es", "gleich\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "\u00bbes ist gnug, la\u00df nun ab zu scherzen,", "tokens": ["\u00bb", "es", "ist", "gnug", ",", "la\u00df", "nun", "ab", "zu", "scher\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "$,", "VVIMP", "ADV", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "bis wir einander wider herzen,", "tokens": ["bis", "wir", "ein\u00b7an\u00b7der", "wi\u00b7der", "her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "mein ", "tokens": ["mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}}}}}