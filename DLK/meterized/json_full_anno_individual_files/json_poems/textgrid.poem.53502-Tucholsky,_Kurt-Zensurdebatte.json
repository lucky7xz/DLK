{"textgrid.poem.53502": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Zensurdebatte", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Reichstag haben sie \u00fcber Zensur gesprochen", "tokens": ["Im", "Reichs\u00b7tag", "ha\u00b7ben", "sie", "\u00fc\u00b7ber", "Zen\u00b7sur", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "APPR", "NN", "VVPP"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "und alle Mi\u00dfgriffe derselben f\u00fcrchterlich gerochen.", "tokens": ["und", "al\u00b7le", "Mi\u00df\u00b7grif\u00b7fe", "der\u00b7sel\u00b7ben", "f\u00fcrch\u00b7ter\u00b7lich", "ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PDAT", "ADJD", "VVPP", "$."], "meter": "-+-++--+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.2": {"line.1": {"text": "Herr Gothein hat es ausf\u00fchrlich in den Saal hineingeredet,", "tokens": ["Herr", "Got\u00b7hein", "hat", "es", "aus\u00b7f\u00fchr\u00b7lich", "in", "den", "Saal", "hin\u00b7ein\u00b7ge\u00b7re\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "gro\u00df sei das Debet derselben, aber klein ihr Kredit.", "tokens": ["gro\u00df", "sei", "das", "De\u00b7bet", "der\u00b7sel\u00b7ben", ",", "a\u00b7ber", "klein", "ihr", "Kre\u00b7dit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "PDAT", "$,", "ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Und auch Herr M\u00fcller-Meiningen hat sich dahin ausgelassen:", "tokens": ["Und", "auch", "Herr", "M\u00fcl\u00b7ler\u00b7Mei\u00b7nin\u00b7gen", "hat", "sich", "da\u00b7hin", "aus\u00b7ge\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "NE", "VAFIN", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "neben England m\u00fcsse man dieselbe am meisten hassen.", "tokens": ["ne\u00b7ben", "En\u00b7gland", "m\u00fcs\u00b7se", "man", "die\u00b7sel\u00b7be", "am", "meis\u00b7ten", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VMFIN", "PIS", "PDAT", "APPRART", "PIS", "VVINF", "$."], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}}, "stanza.4": {"line.1": {"text": "Dann haben sich aber die Vertreter der Regierung erhoben", "tokens": ["Dann", "ha\u00b7ben", "sich", "a\u00b7ber", "die", "Ver\u00b7tre\u00b7ter", "der", "Re\u00b7gie\u00b7rung", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "ADV", "ART", "NN", "ART", "NN", "VVPP"], "meter": "-+--+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "und sagten: man m\u00fcsse dieselbe ertragen, aber nicht loben.", "tokens": ["und", "sag\u00b7ten", ":", "man", "m\u00fcs\u00b7se", "die\u00b7sel\u00b7be", "er\u00b7tra\u00b7gen", ",", "a\u00b7ber", "nicht", "lo\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PIS", "VMFIN", "PDAT", "VVINF", "$,", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+--+-+--+-", "measure": "amphibrach.tetra.plus"}}, "stanza.5": {"line.1": {"text": "Und wenn die Offiziersburschen mit den Dienstm\u00e4dchen gingen,", "tokens": ["Und", "wenn", "die", "Of\u00b7fi\u00b7ziers\u00b7bur\u00b7schen", "mit", "den", "Dienst\u00b7m\u00e4d\u00b7chen", "gin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-++-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "so sei das geheim; \u00fcber Truppenbewegungen d\u00fcrfe man nichts bringen.", "tokens": ["so", "sei", "das", "ge\u00b7heim", ";", "\u00fc\u00b7ber", "Trup\u00b7pen\u00b7be\u00b7we\u00b7gun\u00b7gen", "d\u00fcr\u00b7fe", "man", "nichts", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJD", "$.", "APPR", "NN", "VMFIN", "PIS", "PIS", "VVINF", "$."], "meter": "-+--+--+--++-+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Und auch Herr von Tirpitz geh\u00f6re wie die Papierverteilung zu denjenigen Sachen,", "tokens": ["Und", "auch", "Herr", "von", "Tir\u00b7pitz", "ge\u00b7h\u00f6\u00b7re", "wie", "die", "Pa\u00b7pier\u00b7ver\u00b7tei\u00b7lung", "zu", "den\u00b7je\u00b7ni\u00b7gen", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "APPR", "NE", "VVFIN", "KOKOM", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "--+-+--+-+--+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "deren diskrete Geheimhaltung vor den Feinden uns viele Sorgen machen.", "tokens": ["de\u00b7ren", "dis\u00b7kre\u00b7te", "Ge\u00b7heim\u00b7hal\u00b7tung", "vor", "den", "Fein\u00b7den", "uns", "vie\u00b7le", "Sor\u00b7gen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "APPR", "ART", "NN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+--++-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.7": {"line.1": {"text": "Und so wurde noch allerhand hin-, beziehungsweise herverhandelt.", "tokens": ["Und", "so", "wur\u00b7de", "noch", "al\u00b7ler\u00b7hand", "hin", ",", "be\u00b7zie\u00b7hungs\u00b7wei\u00b7se", "her\u00b7ver\u00b7han\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "PIAT", "TRUNC", "$,", "ADJD", "VVPP", "$."], "meter": "+-+-++-+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Es steht aber nicht zu bef\u00fcrchten, da\u00df sich in n\u00e4chster Zeit etwas wandelt.", "tokens": ["Es", "steht", "a\u00b7ber", "nicht", "zu", "be\u00b7f\u00fcrch\u00b7ten", ",", "da\u00df", "sich", "in", "n\u00e4chs\u00b7ter", "Zeit", "et\u00b7was", "wan\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,", "KOUS", "PRF", "APPR", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+--+--+--+-+-+--+-", "measure": "amphibrach.tetra.plus"}}, "stanza.8": {"line.1": {"text": "Und wie in alten Schultagen f\u00fchl ich beklommen:", "tokens": ["Und", "wie", "in", "al\u00b7ten", "Schul\u00b7ta\u00b7gen", "f\u00fchl", "ich", "be\u00b7klom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "ADJA", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wir haben eine miserable Zensur bekommen!", "tokens": ["Wir", "ha\u00b7ben", "ei\u00b7ne", "mi\u00b7se\u00b7rab\u00b7le", "Zen\u00b7sur", "be\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Im Reichstag haben sie \u00fcber Zensur gesprochen", "tokens": ["Im", "Reichs\u00b7tag", "ha\u00b7ben", "sie", "\u00fc\u00b7ber", "Zen\u00b7sur", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "APPR", "NN", "VVPP"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "und alle Mi\u00dfgriffe derselben f\u00fcrchterlich gerochen.", "tokens": ["und", "al\u00b7le", "Mi\u00df\u00b7grif\u00b7fe", "der\u00b7sel\u00b7ben", "f\u00fcrch\u00b7ter\u00b7lich", "ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PDAT", "ADJD", "VVPP", "$."], "meter": "-+-++--+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.10": {"line.1": {"text": "Herr Gothein hat es ausf\u00fchrlich in den Saal hineingeredet,", "tokens": ["Herr", "Got\u00b7hein", "hat", "es", "aus\u00b7f\u00fchr\u00b7lich", "in", "den", "Saal", "hin\u00b7ein\u00b7ge\u00b7re\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "gro\u00df sei das Debet derselben, aber klein ihr Kredit.", "tokens": ["gro\u00df", "sei", "das", "De\u00b7bet", "der\u00b7sel\u00b7ben", ",", "a\u00b7ber", "klein", "ihr", "Kre\u00b7dit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "PDAT", "$,", "ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Und auch Herr M\u00fcller-Meiningen hat sich dahin ausgelassen:", "tokens": ["Und", "auch", "Herr", "M\u00fcl\u00b7ler\u00b7Mei\u00b7nin\u00b7gen", "hat", "sich", "da\u00b7hin", "aus\u00b7ge\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "NE", "VAFIN", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "neben England m\u00fcsse man dieselbe am meisten hassen.", "tokens": ["ne\u00b7ben", "En\u00b7gland", "m\u00fcs\u00b7se", "man", "die\u00b7sel\u00b7be", "am", "meis\u00b7ten", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VMFIN", "PIS", "PDAT", "APPRART", "PIS", "VVINF", "$."], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}}, "stanza.12": {"line.1": {"text": "Dann haben sich aber die Vertreter der Regierung erhoben", "tokens": ["Dann", "ha\u00b7ben", "sich", "a\u00b7ber", "die", "Ver\u00b7tre\u00b7ter", "der", "Re\u00b7gie\u00b7rung", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "ADV", "ART", "NN", "ART", "NN", "VVPP"], "meter": "-+--+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "und sagten: man m\u00fcsse dieselbe ertragen, aber nicht loben.", "tokens": ["und", "sag\u00b7ten", ":", "man", "m\u00fcs\u00b7se", "die\u00b7sel\u00b7be", "er\u00b7tra\u00b7gen", ",", "a\u00b7ber", "nicht", "lo\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PIS", "VMFIN", "PDAT", "VVINF", "$,", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+--+-+--+-", "measure": "amphibrach.tetra.plus"}}, "stanza.13": {"line.1": {"text": "Und wenn die Offiziersburschen mit den Dienstm\u00e4dchen gingen,", "tokens": ["Und", "wenn", "die", "Of\u00b7fi\u00b7ziers\u00b7bur\u00b7schen", "mit", "den", "Dienst\u00b7m\u00e4d\u00b7chen", "gin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-++-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "so sei das geheim; \u00fcber Truppenbewegungen d\u00fcrfe man nichts bringen.", "tokens": ["so", "sei", "das", "ge\u00b7heim", ";", "\u00fc\u00b7ber", "Trup\u00b7pen\u00b7be\u00b7we\u00b7gun\u00b7gen", "d\u00fcr\u00b7fe", "man", "nichts", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJD", "$.", "APPR", "NN", "VMFIN", "PIS", "PIS", "VVINF", "$."], "meter": "-+--+--+--++-+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.14": {"line.1": {"text": "Und auch Herr von Tirpitz geh\u00f6re wie die Papierverteilung zu denjenigen Sachen,", "tokens": ["Und", "auch", "Herr", "von", "Tir\u00b7pitz", "ge\u00b7h\u00f6\u00b7re", "wie", "die", "Pa\u00b7pier\u00b7ver\u00b7tei\u00b7lung", "zu", "den\u00b7je\u00b7ni\u00b7gen", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "APPR", "NE", "VVFIN", "KOKOM", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "--+-+--+-+--+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "deren diskrete Geheimhaltung vor den Feinden uns viele Sorgen machen.", "tokens": ["de\u00b7ren", "dis\u00b7kre\u00b7te", "Ge\u00b7heim\u00b7hal\u00b7tung", "vor", "den", "Fein\u00b7den", "uns", "vie\u00b7le", "Sor\u00b7gen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "APPR", "ART", "NN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+--++-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.15": {"line.1": {"text": "Und so wurde noch allerhand hin-, beziehungsweise herverhandelt.", "tokens": ["Und", "so", "wur\u00b7de", "noch", "al\u00b7ler\u00b7hand", "hin", ",", "be\u00b7zie\u00b7hungs\u00b7wei\u00b7se", "her\u00b7ver\u00b7han\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "PIAT", "TRUNC", "$,", "ADJD", "VVPP", "$."], "meter": "+-+-++-+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Es steht aber nicht zu bef\u00fcrchten, da\u00df sich in n\u00e4chster Zeit etwas wandelt.", "tokens": ["Es", "steht", "a\u00b7ber", "nicht", "zu", "be\u00b7f\u00fcrch\u00b7ten", ",", "da\u00df", "sich", "in", "n\u00e4chs\u00b7ter", "Zeit", "et\u00b7was", "wan\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,", "KOUS", "PRF", "APPR", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+--+--+--+-+-+--+-", "measure": "amphibrach.tetra.plus"}}, "stanza.16": {"line.1": {"text": "Und wie in alten Schultagen f\u00fchl ich beklommen:", "tokens": ["Und", "wie", "in", "al\u00b7ten", "Schul\u00b7ta\u00b7gen", "f\u00fchl", "ich", "be\u00b7klom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "ADJA", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wir haben eine miserable Zensur bekommen!", "tokens": ["Wir", "ha\u00b7ben", "ei\u00b7ne", "mi\u00b7se\u00b7rab\u00b7le", "Zen\u00b7sur", "be\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}}}}