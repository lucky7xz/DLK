{"textgrid.poem.37551": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Das brave Lenchen", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf einem Schlosse fern im Holz", "tokens": ["Auf", "ei\u00b7nem", "Schlos\u00b7se", "fern", "im", "Holz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wohnt eine Frau gar reich und stolz.", "tokens": ["wohnt", "ei\u00b7ne", "Frau", "gar", "reich", "und", "stolz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "In einem H\u00fcttchen arm und klein", "tokens": ["In", "ei\u00b7nem", "H\u00fctt\u00b7chen", "arm", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wohnt Lenchen und ihr M\u00fctterlein.", "tokens": ["wohnt", "Len\u00b7chen", "und", "ihr", "M\u00fct\u00b7ter\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das M\u00fctterlein ist schwach und krank", "tokens": ["Das", "M\u00fct\u00b7ter\u00b7lein", "ist", "schwach", "und", "krank"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und ohne Geld und Speis und Trank.", "tokens": ["und", "oh\u00b7ne", "Geld", "und", "Speis", "und", "Trank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da denkt das Lenchen: \u00bbAch, ich lauf", "tokens": ["Da", "denkt", "das", "Len\u00b7chen", ":", "\u00bb", "Ach", ",", "ich", "lauf"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ITJ", "$,", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "um Hilfe nach dem Schlo\u00df hinauf!\u00ab", "tokens": ["um", "Hil\u00b7fe", "nach", "dem", "Schlo\u00df", "hin\u00b7auf", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es nimmt sich nichts wie einen Schnitt", "tokens": ["Es", "nimmt", "sich", "nichts", "wie", "ei\u00b7nen", "Schnitt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PIS", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vom allerletzten Brote mit.", "tokens": ["vom", "al\u00b7ler\u00b7letz\u00b7ten", "Bro\u00b7te", "mit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie es kommt bis an den Steg,", "tokens": ["Und", "wie", "es", "kommt", "bis", "an", "den", "Steg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sitzt da ein armer Hund am Weg.", "tokens": ["sitzt", "da", "ein", "ar\u00b7mer", "Hund", "am", "Weg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbach!\u00ab \u2013 ruft der Hund \u2013 \u00bbmein Herr ist tot;", "tokens": ["\u00bb", "ach", "!", "\u00ab", "\u2013", "ruft", "der", "Hund", "\u2013", "\u00bb", "mein", "Herr", "ist", "tot", ";"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "h\u00e4tt' ich doch nur ein St\u00fcckchen Brot!\u00ab", "tokens": ["h\u00e4tt'", "ich", "doch", "nur", "ein", "St\u00fcck\u00b7chen", "Brot", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbhier!\u00ab \u2013 spricht das Lenchen \u2013 \u00bbhast du was!\u00ab", "tokens": ["\u00bb", "hier", "!", "\u00ab", "\u2013", "spricht", "das", "Len\u00b7chen", "\u2013", "\u00bb", "hast", "du", "was", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "VAFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zieht's Brot hervor und gibt ihm das.", "tokens": ["zieht's", "Brot", "her\u00b7vor", "und", "gibt", "ihm", "das", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie es weiter fortgerannt,", "tokens": ["Und", "wie", "es", "wei\u00b7ter", "fort\u00b7ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "liegt da ein Fisch auf trocknem Sand.", "tokens": ["liegt", "da", "ein", "Fisch", "auf", "trock\u00b7nem", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbach!\u00ab \u2013 ruft der Fisch und zappelt sehr \u2013", "tokens": ["\u00bb", "ach", "!", "\u00ab", "\u2013", "ruft", "der", "Fisch", "und", "zap\u00b7pelt", "sehr", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "$(", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwenn ich doch nur im Wasser w\u00e4r!\u00ab", "tokens": ["\u00bb", "wenn", "ich", "doch", "nur", "im", "Was\u00b7ser", "w\u00e4r", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADV", "APPRART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Gleich b\u00fcckt das Lenchen sich danach", "tokens": ["Gleich", "b\u00fcckt", "das", "Len\u00b7chen", "sich", "da\u00b7nach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und tr\u00e4gt ihn wieder in den Bach.", "tokens": ["und", "tr\u00e4gt", "ihn", "wie\u00b7der", "in", "den", "Bach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann ist es weiter fortgerannt,", "tokens": ["Dann", "ist", "es", "wei\u00b7ter", "fort\u00b7ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bis es die Frau im Schlosse fand. \u2013", "tokens": ["bis", "es", "die", "Frau", "im", "Schlos\u00b7se", "fand", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbach, liebe Frau, erbarmt euch mein,", "tokens": ["\u00bb", "ach", ",", "lie\u00b7be", "Frau", ",", "er\u00b7barmt", "euch", "mein", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ich hab ein krankes M\u00fctterlein!\u00ab", "tokens": ["ich", "hab", "ein", "kran\u00b7kes", "M\u00fct\u00b7ter\u00b7lein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbfort!\u00ab \u2013 schreit die Frau \u2013 \u00bbnichts gibt es hier!\u00ab", "tokens": ["\u00bb", "fort", "!", "\u00ab", "\u2013", "schreit", "die", "Frau", "\u2013", "\u00bb", "nichts", "gibt", "es", "hier", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKVZ", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "PIS", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und jagt das Lenchen vor die T\u00fcr.", "tokens": ["und", "jagt", "das", "Len\u00b7chen", "vor", "die", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Das Lenchen sieht vor Tr\u00e4nen kaum", "tokens": ["Das", "Len\u00b7chen", "sieht", "vor", "Tr\u00e4\u00b7nen", "kaum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und setzt sich stumm an einen Baum.", "tokens": ["und", "setzt", "sich", "stumm", "an", "ei\u00b7nen", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und horch, im hohlen Baum erklingt", "tokens": ["Und", "horch", ",", "im", "hoh\u00b7len", "Baum", "er\u00b7klingt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$,", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein feines Stimmlein, welches singt:", "tokens": ["ein", "fei\u00b7nes", "Stimm\u00b7lein", ",", "wel\u00b7ches", "singt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbmach auf, mach auf, ich bitt gar sch\u00f6n,", "tokens": ["\u00bb", "mach", "auf", ",", "mach", "auf", ",", "ich", "bitt", "gar", "sch\u00f6n", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "m\u00f6cht gern die liebe Sonne sehn!\u00ab", "tokens": ["m\u00f6cht", "gern", "die", "lie\u00b7be", "Son\u00b7ne", "sehn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Im Baum da ist ein L\u00f6chlein rund,", "tokens": ["Im", "Baum", "da", "ist", "ein", "L\u00f6c\u00b7hlein", "rund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ist zugesteckt mit einem Spund.", "tokens": ["ist", "zu\u00b7ge\u00b7steckt", "mit", "ei\u00b7nem", "Spund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Den zieht das Lenchen aus und spricht:", "tokens": ["Den", "zieht", "das", "Len\u00b7chen", "aus", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbso komm ans Licht, du armer Wicht!\u00ab", "tokens": ["\u00bb", "so", "komm", "ans", "Licht", ",", "du", "ar\u00b7mer", "Wicht", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPRART", "NN", "$,", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh da, und eine Schlange schmiegt", "tokens": ["Sieh", "da", ",", "und", "ei\u00b7ne", "Schlan\u00b7ge", "schmiegt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$,", "KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sich aus dem Baum hervor und kriecht", "tokens": ["sich", "aus", "dem", "Baum", "her\u00b7vor", "und", "kriecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "NN", "PTKVZ", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und schlingt und schl\u00e4ngelt mit Gezisch", "tokens": ["und", "schlingt", "und", "schl\u00e4n\u00b7gelt", "mit", "Ge\u00b7zisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sich in das dichte Waldgeb\u00fcsch,", "tokens": ["sich", "in", "das", "dich\u00b7te", "Wald\u00b7ge\u00b7b\u00fcsch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und raschelt da herum und kam", "tokens": ["und", "ra\u00b7schelt", "da", "he\u00b7rum", "und", "kam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und bracht ein Bl\u00fcmlein wundersam.", "tokens": ["und", "bracht", "ein", "Bl\u00fcm\u00b7lein", "wun\u00b7der\u00b7sam", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "O Krankentrost, du Bl\u00fcmlein rot,", "tokens": ["O", "Kran\u00b7kent\u00b7rost", ",", "du", "Bl\u00fcm\u00b7lein", "rot", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herztulipan, hilf aus der Not!", "tokens": ["Herz\u00b7tu\u00b7li\u00b7pan", ",", "hilf", "aus", "der", "Not", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Das Lenchen nimmt das Bl\u00fcmlein an", "tokens": ["Das", "Len\u00b7chen", "nimmt", "das", "Bl\u00fcm\u00b7lein", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und eilt nach Haus so schnell es kann.", "tokens": ["und", "eilt", "nach", "Haus", "so", "schnell", "es", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADV", "ADJD", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und wie es kommt bis \u00fcber'n Steg,", "tokens": ["Und", "wie", "es", "kommt", "bis", "\u00fc\u00b7ber'n", "Steg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "tritt ihm ein R\u00e4uber in den Weg.", "tokens": ["tritt", "ihm", "ein", "R\u00e4u\u00b7ber", "in", "den", "Weg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem armen Lenchen stockt das Blut,", "tokens": ["Dem", "ar\u00b7men", "Len\u00b7chen", "stockt", "das", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "l\u00e4\u00dft's Bl\u00fcmlein fallen in die Flut.", "tokens": ["l\u00e4\u00dft's", "Bl\u00fcm\u00b7lein", "fal\u00b7len", "in", "die", "Flut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Da kommt der Hund und jagt zum Gl\u00fcck", "tokens": ["Da", "kommt", "der", "Hund", "und", "jagt", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den R\u00e4uber in den Wald zur\u00fcck.", "tokens": ["Den", "R\u00e4u\u00b7ber", "in", "den", "Wald", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und unser Fisch ist auch nicht faul;", "tokens": ["Und", "un\u00b7ser", "Fisch", "ist", "auch", "nicht", "faul", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "er tr\u00e4gt die Blume in dem Maul.", "tokens": ["er", "tr\u00e4gt", "die", "Blu\u00b7me", "in", "dem", "Maul", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Jetzt l\u00e4uft das Lenchen schnell hinein", "tokens": ["Jetzt", "l\u00e4uft", "das", "Len\u00b7chen", "schnell", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zum lieben kranken M\u00fctterlein,", "tokens": ["zum", "lie\u00b7ben", "kran\u00b7ken", "M\u00fct\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "legt's Bl\u00fcmlein ihr auf Herz und Mund,", "tokens": ["legt's", "Bl\u00fcm\u00b7lein", "ihr", "auf", "Herz", "und", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPOSAT", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "macht's M\u00fctterlein sogleich gesund;", "tokens": ["macht's", "M\u00fct\u00b7ter\u00b7lein", "sog\u00b7leich", "ge\u00b7sund", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "heilt auch noch sonst viel kranke Leut", "tokens": ["heilt", "auch", "noch", "sonst", "viel", "kran\u00b7ke", "Leut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "PIAT", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "und ist aus aller Not befreit.", "tokens": ["und", "ist", "aus", "al\u00b7ler", "Not", "be\u00b7freit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Der R\u00e4uber aber hat bei Nacht", "tokens": ["Der", "R\u00e4u\u00b7ber", "a\u00b7ber", "hat", "bei", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Frau im Schlosse totgemacht.", "tokens": ["Die", "Frau", "im", "Schlos\u00b7se", "tot\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Auf einem Schlosse fern im Holz", "tokens": ["Auf", "ei\u00b7nem", "Schlos\u00b7se", "fern", "im", "Holz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wohnt eine Frau gar reich und stolz.", "tokens": ["wohnt", "ei\u00b7ne", "Frau", "gar", "reich", "und", "stolz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "In einem H\u00fcttchen arm und klein", "tokens": ["In", "ei\u00b7nem", "H\u00fctt\u00b7chen", "arm", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wohnt Lenchen und ihr M\u00fctterlein.", "tokens": ["wohnt", "Len\u00b7chen", "und", "ihr", "M\u00fct\u00b7ter\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das M\u00fctterlein ist schwach und krank", "tokens": ["Das", "M\u00fct\u00b7ter\u00b7lein", "ist", "schwach", "und", "krank"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und ohne Geld und Speis und Trank.", "tokens": ["und", "oh\u00b7ne", "Geld", "und", "Speis", "und", "Trank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Da denkt das Lenchen: \u00bbAch, ich lauf", "tokens": ["Da", "denkt", "das", "Len\u00b7chen", ":", "\u00bb", "Ach", ",", "ich", "lauf"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ITJ", "$,", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "um Hilfe nach dem Schlo\u00df hinauf!\u00ab", "tokens": ["um", "Hil\u00b7fe", "nach", "dem", "Schlo\u00df", "hin\u00b7auf", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Es nimmt sich nichts wie einen Schnitt", "tokens": ["Es", "nimmt", "sich", "nichts", "wie", "ei\u00b7nen", "Schnitt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PIS", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vom allerletzten Brote mit.", "tokens": ["vom", "al\u00b7ler\u00b7letz\u00b7ten", "Bro\u00b7te", "mit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie es kommt bis an den Steg,", "tokens": ["Und", "wie", "es", "kommt", "bis", "an", "den", "Steg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sitzt da ein armer Hund am Weg.", "tokens": ["sitzt", "da", "ein", "ar\u00b7mer", "Hund", "am", "Weg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbach!\u00ab \u2013 ruft der Hund \u2013 \u00bbmein Herr ist tot;", "tokens": ["\u00bb", "ach", "!", "\u00ab", "\u2013", "ruft", "der", "Hund", "\u2013", "\u00bb", "mein", "Herr", "ist", "tot", ";"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "h\u00e4tt' ich doch nur ein St\u00fcckchen Brot!\u00ab", "tokens": ["h\u00e4tt'", "ich", "doch", "nur", "ein", "St\u00fcck\u00b7chen", "Brot", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "\u00bbhier!\u00ab \u2013 spricht das Lenchen \u2013 \u00bbhast du was!\u00ab", "tokens": ["\u00bb", "hier", "!", "\u00ab", "\u2013", "spricht", "das", "Len\u00b7chen", "\u2013", "\u00bb", "hast", "du", "was", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "VAFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zieht's Brot hervor und gibt ihm das.", "tokens": ["zieht's", "Brot", "her\u00b7vor", "und", "gibt", "ihm", "das", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie es weiter fortgerannt,", "tokens": ["Und", "wie", "es", "wei\u00b7ter", "fort\u00b7ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "liegt da ein Fisch auf trocknem Sand.", "tokens": ["liegt", "da", "ein", "Fisch", "auf", "trock\u00b7nem", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbach!\u00ab \u2013 ruft der Fisch und zappelt sehr \u2013", "tokens": ["\u00bb", "ach", "!", "\u00ab", "\u2013", "ruft", "der", "Fisch", "und", "zap\u00b7pelt", "sehr", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "$(", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwenn ich doch nur im Wasser w\u00e4r!\u00ab", "tokens": ["\u00bb", "wenn", "ich", "doch", "nur", "im", "Was\u00b7ser", "w\u00e4r", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADV", "APPRART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Gleich b\u00fcckt das Lenchen sich danach", "tokens": ["Gleich", "b\u00fcckt", "das", "Len\u00b7chen", "sich", "da\u00b7nach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und tr\u00e4gt ihn wieder in den Bach.", "tokens": ["und", "tr\u00e4gt", "ihn", "wie\u00b7der", "in", "den", "Bach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann ist es weiter fortgerannt,", "tokens": ["Dann", "ist", "es", "wei\u00b7ter", "fort\u00b7ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bis es die Frau im Schlosse fand. \u2013", "tokens": ["bis", "es", "die", "Frau", "im", "Schlos\u00b7se", "fand", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "\u00bbach, liebe Frau, erbarmt euch mein,", "tokens": ["\u00bb", "ach", ",", "lie\u00b7be", "Frau", ",", "er\u00b7barmt", "euch", "mein", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ich hab ein krankes M\u00fctterlein!\u00ab", "tokens": ["ich", "hab", "ein", "kran\u00b7kes", "M\u00fct\u00b7ter\u00b7lein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "\u00bbfort!\u00ab \u2013 schreit die Frau \u2013 \u00bbnichts gibt es hier!\u00ab", "tokens": ["\u00bb", "fort", "!", "\u00ab", "\u2013", "schreit", "die", "Frau", "\u2013", "\u00bb", "nichts", "gibt", "es", "hier", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKVZ", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "PIS", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und jagt das Lenchen vor die T\u00fcr.", "tokens": ["und", "jagt", "das", "Len\u00b7chen", "vor", "die", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Das Lenchen sieht vor Tr\u00e4nen kaum", "tokens": ["Das", "Len\u00b7chen", "sieht", "vor", "Tr\u00e4\u00b7nen", "kaum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und setzt sich stumm an einen Baum.", "tokens": ["und", "setzt", "sich", "stumm", "an", "ei\u00b7nen", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und horch, im hohlen Baum erklingt", "tokens": ["Und", "horch", ",", "im", "hoh\u00b7len", "Baum", "er\u00b7klingt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$,", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein feines Stimmlein, welches singt:", "tokens": ["ein", "fei\u00b7nes", "Stimm\u00b7lein", ",", "wel\u00b7ches", "singt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbmach auf, mach auf, ich bitt gar sch\u00f6n,", "tokens": ["\u00bb", "mach", "auf", ",", "mach", "auf", ",", "ich", "bitt", "gar", "sch\u00f6n", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "m\u00f6cht gern die liebe Sonne sehn!\u00ab", "tokens": ["m\u00f6cht", "gern", "die", "lie\u00b7be", "Son\u00b7ne", "sehn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Im Baum da ist ein L\u00f6chlein rund,", "tokens": ["Im", "Baum", "da", "ist", "ein", "L\u00f6c\u00b7hlein", "rund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ist zugesteckt mit einem Spund.", "tokens": ["ist", "zu\u00b7ge\u00b7steckt", "mit", "ei\u00b7nem", "Spund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Den zieht das Lenchen aus und spricht:", "tokens": ["Den", "zieht", "das", "Len\u00b7chen", "aus", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbso komm ans Licht, du armer Wicht!\u00ab", "tokens": ["\u00bb", "so", "komm", "ans", "Licht", ",", "du", "ar\u00b7mer", "Wicht", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPRART", "NN", "$,", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh da, und eine Schlange schmiegt", "tokens": ["Sieh", "da", ",", "und", "ei\u00b7ne", "Schlan\u00b7ge", "schmiegt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$,", "KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sich aus dem Baum hervor und kriecht", "tokens": ["sich", "aus", "dem", "Baum", "her\u00b7vor", "und", "kriecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "NN", "PTKVZ", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und schlingt und schl\u00e4ngelt mit Gezisch", "tokens": ["und", "schlingt", "und", "schl\u00e4n\u00b7gelt", "mit", "Ge\u00b7zisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sich in das dichte Waldgeb\u00fcsch,", "tokens": ["sich", "in", "das", "dich\u00b7te", "Wald\u00b7ge\u00b7b\u00fcsch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und raschelt da herum und kam", "tokens": ["und", "ra\u00b7schelt", "da", "he\u00b7rum", "und", "kam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und bracht ein Bl\u00fcmlein wundersam.", "tokens": ["und", "bracht", "ein", "Bl\u00fcm\u00b7lein", "wun\u00b7der\u00b7sam", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "O Krankentrost, du Bl\u00fcmlein rot,", "tokens": ["O", "Kran\u00b7kent\u00b7rost", ",", "du", "Bl\u00fcm\u00b7lein", "rot", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herztulipan, hilf aus der Not!", "tokens": ["Herz\u00b7tu\u00b7li\u00b7pan", ",", "hilf", "aus", "der", "Not", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Das Lenchen nimmt das Bl\u00fcmlein an", "tokens": ["Das", "Len\u00b7chen", "nimmt", "das", "Bl\u00fcm\u00b7lein", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und eilt nach Haus so schnell es kann.", "tokens": ["und", "eilt", "nach", "Haus", "so", "schnell", "es", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADV", "ADJD", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Und wie es kommt bis \u00fcber'n Steg,", "tokens": ["Und", "wie", "es", "kommt", "bis", "\u00fc\u00b7ber'n", "Steg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "tritt ihm ein R\u00e4uber in den Weg.", "tokens": ["tritt", "ihm", "ein", "R\u00e4u\u00b7ber", "in", "den", "Weg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem armen Lenchen stockt das Blut,", "tokens": ["Dem", "ar\u00b7men", "Len\u00b7chen", "stockt", "das", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "l\u00e4\u00dft's Bl\u00fcmlein fallen in die Flut.", "tokens": ["l\u00e4\u00dft's", "Bl\u00fcm\u00b7lein", "fal\u00b7len", "in", "die", "Flut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Da kommt der Hund und jagt zum Gl\u00fcck", "tokens": ["Da", "kommt", "der", "Hund", "und", "jagt", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den R\u00e4uber in den Wald zur\u00fcck.", "tokens": ["Den", "R\u00e4u\u00b7ber", "in", "den", "Wald", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Und unser Fisch ist auch nicht faul;", "tokens": ["Und", "un\u00b7ser", "Fisch", "ist", "auch", "nicht", "faul", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "er tr\u00e4gt die Blume in dem Maul.", "tokens": ["er", "tr\u00e4gt", "die", "Blu\u00b7me", "in", "dem", "Maul", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Jetzt l\u00e4uft das Lenchen schnell hinein", "tokens": ["Jetzt", "l\u00e4uft", "das", "Len\u00b7chen", "schnell", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zum lieben kranken M\u00fctterlein,", "tokens": ["zum", "lie\u00b7ben", "kran\u00b7ken", "M\u00fct\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "legt's Bl\u00fcmlein ihr auf Herz und Mund,", "tokens": ["legt's", "Bl\u00fcm\u00b7lein", "ihr", "auf", "Herz", "und", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPOSAT", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "macht's M\u00fctterlein sogleich gesund;", "tokens": ["macht's", "M\u00fct\u00b7ter\u00b7lein", "sog\u00b7leich", "ge\u00b7sund", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "heilt auch noch sonst viel kranke Leut", "tokens": ["heilt", "auch", "noch", "sonst", "viel", "kran\u00b7ke", "Leut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "PIAT", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "und ist aus aller Not befreit.", "tokens": ["und", "ist", "aus", "al\u00b7ler", "Not", "be\u00b7freit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Der R\u00e4uber aber hat bei Nacht", "tokens": ["Der", "R\u00e4u\u00b7ber", "a\u00b7ber", "hat", "bei", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Frau im Schlosse totgemacht.", "tokens": ["Die", "Frau", "im", "Schlos\u00b7se", "tot\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}