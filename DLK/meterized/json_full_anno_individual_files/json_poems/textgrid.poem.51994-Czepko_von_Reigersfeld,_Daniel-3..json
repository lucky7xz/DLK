{"textgrid.poem.51994": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "3.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin dir wol nicht gram, da\u00df du die L\u00f6cher siehst,", "tokens": ["Ich", "bin", "dir", "wol", "nicht", "gram", ",", "da\u00df", "du", "die", "L\u00f6\u00b7cher", "siehst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auff denen Eurus l\u00e4st verfaulte Winde streichen,", "tokens": ["Auff", "de\u00b7nen", "Eu\u00b7rus", "l\u00e4st", "ver\u00b7faul\u00b7te", "Win\u00b7de", "strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NE", "VVFIN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Wann der Calfactor dir die Ruthe pflegt zu reichen,", "tokens": ["Wann", "der", "Cal\u00b7fac\u00b7tor", "dir", "die", "Ru\u00b7the", "pflegt", "zu", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die deine Wonn und Lust und Cron und Zepter ist.", "tokens": ["Die", "dei\u00b7ne", "Wonn", "und", "Lust", "und", "Cron", "und", "Zep\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Du magst die Lection aus der lateinschen Kunst,", "tokens": ["Du", "magst", "die", "Lec\u00b7ti\u00b7on", "aus", "der", "la\u00b7tein\u00b7schen", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Sch\u00fclern auff der Banck mit gr\u00fcnen Bircken schlagen,", "tokens": ["Den", "Sch\u00fc\u00b7lern", "auff", "der", "Banck", "mit", "gr\u00fc\u00b7nen", "Bir\u00b7cken", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und durch die Classes sie ihr Cujus partis fragen:", "tokens": ["Und", "durch", "die", "Clas\u00b7ses", "sie", "ihr", "Cu\u00b7jus", "par\u00b7tis", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "PPOSAT", "FM", "FM", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo du was weiters thust, so ist dein Thun umbsonst.", "tokens": ["Wo", "du", "was", "wei\u00b7ters", "thust", ",", "so", "ist", "dein", "Thun", "um\u00b7bsonst", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PWS", "PIS", "VVFIN", "$,", "ADV", "VAFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Man sagt, da\u00df Aleph dir und Gimmel sey bekannt,", "tokens": ["Man", "sagt", ",", "da\u00df", "A\u00b7leph", "dir", "und", "Gim\u00b7mel", "sey", "be\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "NE", "PPER", "KON", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df du viel Grecken solst von dem Homerus wi\u00dfen,", "tokens": ["Da\u00df", "du", "viel", "Gre\u00b7cken", "solst", "von", "dem", "Ho\u00b7me\u00b7rus", "wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VMFIN", "APPR", "ART", "NE", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Verse lauffen dir auff ihren eignen F\u00fc\u00dfen,", "tokens": ["Die", "Ver\u00b7se", "lauf\u00b7fen", "dir", "auff", "ih\u00b7ren", "eig\u00b7nen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und haben be\u00dfre Wort als Lehren und Verstand.", "tokens": ["Und", "ha\u00b7ben", "be\u00df\u00b7re", "Wort", "als", "Leh\u00b7ren", "und", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJA", "NN", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Kein Priester kan zuerst auff seiner Cantzel stehn,", "tokens": ["Kein", "Pries\u00b7ter", "kan", "zu\u00b7erst", "auff", "sei\u00b7ner", "Cant\u00b7zel", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Gl\u00f6ckner stirbt, kein Herr hat etwas unterfangen,", "tokens": ["Kein", "Gl\u00f6ck\u00b7ner", "stirbt", ",", "kein", "Herr", "hat", "et\u00b7was", "un\u00b7ter\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn es des Doctors Magd selbst \u00fcbel ist gegangen,", "tokens": ["Wenn", "es", "des", "Doc\u00b7tors", "Magd", "selbst", "\u00fc\u00b7bel", "ist", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So mu\u00df mit Versen dir dein Weib zum Drucker gehn.", "tokens": ["So", "mu\u00df", "mit", "Ver\u00b7sen", "dir", "dein", "Weib", "zum", "Dru\u00b7cker", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "PPER", "PPOSAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Was dein Latein betrifft, so g\u00f6nn ich gleichfalls dir,", "tokens": ["Was", "dein", "La\u00b7tein", "be\u00b7tr\u00b7ifft", ",", "so", "g\u00f6nn", "ich", "gleich\u00b7falls", "dir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PPER", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Da\u00df du die phrases kanst in deine Scripta bringen,", "tokens": ["Da\u00df", "du", "die", "phra\u00b7ses", "kanst", "in", "dei\u00b7ne", "Scrip\u00b7ta", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die dorte Plautus w\u00e4scht, hier Flaccus wei\u00df zu singen,", "tokens": ["Die", "dor\u00b7te", "Plau\u00b7tus", "w\u00e4scht", ",", "hier", "Flac\u00b7cus", "wei\u00df", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ADV", "NE", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was der R\u00f6msche Marckt den Kr\u00e4mern leget f\u00fcr.", "tokens": ["Und", "was", "der", "R\u00f6m\u00b7sche", "Marckt", "den", "Kr\u00e4\u00b7mern", "le\u00b7get", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Nur dieses bitt ich dich, la\u00df deine Sichel nicht", "tokens": ["Nur", "die\u00b7ses", "bitt", "ich", "dich", ",", "la\u00df", "dei\u00b7ne", "Si\u00b7chel", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "PRF", "$,", "VVIMP", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Andrer Erndte gehn: nicht Andern Grund begrasen,", "tokens": ["In", "A\u00b7ndrer", "Ernd\u00b7te", "gehn", ":", "nicht", "An\u00b7dern", "Grund", "be\u00b7gra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$.", "PTKNEG", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich kenne deinen Witz: und was mit krummer Nasen", "tokens": ["Ich", "ken\u00b7ne", "dei\u00b7nen", "Witz", ":", "und", "was", "mit", "krum\u00b7mer", "Na\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Herr Magister thut, ist auch der Knaben Pflicht.", "tokens": ["Der", "Herr", "Ma\u00b7gis\u00b7ter", "thut", ",", "ist", "auch", "der", "Kna\u00b7ben", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Denn wo auch di\u00df die Hand aus deinem Barthe streicht,", "tokens": ["Denn", "wo", "auch", "di\u00df", "die", "Hand", "aus", "dei\u00b7nem", "Bar\u00b7the", "streicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PDS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und du dich unterstehst mich seitwerts anzustechen,", "tokens": ["Und", "du", "dich", "un\u00b7ter\u00b7stehst", "mich", "seit\u00b7werts", "an\u00b7zu\u00b7ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "VVFIN", "PPER", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So la\u00df mich unverklagt, wenn ich mich werde r\u00e4chen:", "tokens": ["So", "la\u00df", "mich", "un\u00b7ver\u00b7klagt", ",", "wenn", "ich", "mich", "wer\u00b7de", "r\u00e4\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJD", "$,", "KOUS", "PPER", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nein: Eule glaub es nicht, da\u00df dir der Reiger weicht.", "tokens": ["Nein", ":", "Eu\u00b7le", "glaub", "es", "nicht", ",", "da\u00df", "dir", "der", "Rei\u00b7ger", "weicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NE", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ich bin dir wol nicht gram, da\u00df du die L\u00f6cher siehst,", "tokens": ["Ich", "bin", "dir", "wol", "nicht", "gram", ",", "da\u00df", "du", "die", "L\u00f6\u00b7cher", "siehst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auff denen Eurus l\u00e4st verfaulte Winde streichen,", "tokens": ["Auff", "de\u00b7nen", "Eu\u00b7rus", "l\u00e4st", "ver\u00b7faul\u00b7te", "Win\u00b7de", "strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NE", "VVFIN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Wann der Calfactor dir die Ruthe pflegt zu reichen,", "tokens": ["Wann", "der", "Cal\u00b7fac\u00b7tor", "dir", "die", "Ru\u00b7the", "pflegt", "zu", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die deine Wonn und Lust und Cron und Zepter ist.", "tokens": ["Die", "dei\u00b7ne", "Wonn", "und", "Lust", "und", "Cron", "und", "Zep\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Du magst die Lection aus der lateinschen Kunst,", "tokens": ["Du", "magst", "die", "Lec\u00b7ti\u00b7on", "aus", "der", "la\u00b7tein\u00b7schen", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Sch\u00fclern auff der Banck mit gr\u00fcnen Bircken schlagen,", "tokens": ["Den", "Sch\u00fc\u00b7lern", "auff", "der", "Banck", "mit", "gr\u00fc\u00b7nen", "Bir\u00b7cken", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und durch die Classes sie ihr Cujus partis fragen:", "tokens": ["Und", "durch", "die", "Clas\u00b7ses", "sie", "ihr", "Cu\u00b7jus", "par\u00b7tis", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "PPOSAT", "FM", "FM", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo du was weiters thust, so ist dein Thun umbsonst.", "tokens": ["Wo", "du", "was", "wei\u00b7ters", "thust", ",", "so", "ist", "dein", "Thun", "um\u00b7bsonst", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PWS", "PIS", "VVFIN", "$,", "ADV", "VAFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Man sagt, da\u00df Aleph dir und Gimmel sey bekannt,", "tokens": ["Man", "sagt", ",", "da\u00df", "A\u00b7leph", "dir", "und", "Gim\u00b7mel", "sey", "be\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "NE", "PPER", "KON", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df du viel Grecken solst von dem Homerus wi\u00dfen,", "tokens": ["Da\u00df", "du", "viel", "Gre\u00b7cken", "solst", "von", "dem", "Ho\u00b7me\u00b7rus", "wi\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VMFIN", "APPR", "ART", "NE", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Verse lauffen dir auff ihren eignen F\u00fc\u00dfen,", "tokens": ["Die", "Ver\u00b7se", "lauf\u00b7fen", "dir", "auff", "ih\u00b7ren", "eig\u00b7nen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und haben be\u00dfre Wort als Lehren und Verstand.", "tokens": ["Und", "ha\u00b7ben", "be\u00df\u00b7re", "Wort", "als", "Leh\u00b7ren", "und", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJA", "NN", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Kein Priester kan zuerst auff seiner Cantzel stehn,", "tokens": ["Kein", "Pries\u00b7ter", "kan", "zu\u00b7erst", "auff", "sei\u00b7ner", "Cant\u00b7zel", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Gl\u00f6ckner stirbt, kein Herr hat etwas unterfangen,", "tokens": ["Kein", "Gl\u00f6ck\u00b7ner", "stirbt", ",", "kein", "Herr", "hat", "et\u00b7was", "un\u00b7ter\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn es des Doctors Magd selbst \u00fcbel ist gegangen,", "tokens": ["Wenn", "es", "des", "Doc\u00b7tors", "Magd", "selbst", "\u00fc\u00b7bel", "ist", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So mu\u00df mit Versen dir dein Weib zum Drucker gehn.", "tokens": ["So", "mu\u00df", "mit", "Ver\u00b7sen", "dir", "dein", "Weib", "zum", "Dru\u00b7cker", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "PPER", "PPOSAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Was dein Latein betrifft, so g\u00f6nn ich gleichfalls dir,", "tokens": ["Was", "dein", "La\u00b7tein", "be\u00b7tr\u00b7ifft", ",", "so", "g\u00f6nn", "ich", "gleich\u00b7falls", "dir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PPER", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Da\u00df du die phrases kanst in deine Scripta bringen,", "tokens": ["Da\u00df", "du", "die", "phra\u00b7ses", "kanst", "in", "dei\u00b7ne", "Scrip\u00b7ta", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die dorte Plautus w\u00e4scht, hier Flaccus wei\u00df zu singen,", "tokens": ["Die", "dor\u00b7te", "Plau\u00b7tus", "w\u00e4scht", ",", "hier", "Flac\u00b7cus", "wei\u00df", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ADV", "NE", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was der R\u00f6msche Marckt den Kr\u00e4mern leget f\u00fcr.", "tokens": ["Und", "was", "der", "R\u00f6m\u00b7sche", "Marckt", "den", "Kr\u00e4\u00b7mern", "le\u00b7get", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Nur dieses bitt ich dich, la\u00df deine Sichel nicht", "tokens": ["Nur", "die\u00b7ses", "bitt", "ich", "dich", ",", "la\u00df", "dei\u00b7ne", "Si\u00b7chel", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "PRF", "$,", "VVIMP", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Andrer Erndte gehn: nicht Andern Grund begrasen,", "tokens": ["In", "A\u00b7ndrer", "Ernd\u00b7te", "gehn", ":", "nicht", "An\u00b7dern", "Grund", "be\u00b7gra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$.", "PTKNEG", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich kenne deinen Witz: und was mit krummer Nasen", "tokens": ["Ich", "ken\u00b7ne", "dei\u00b7nen", "Witz", ":", "und", "was", "mit", "krum\u00b7mer", "Na\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Herr Magister thut, ist auch der Knaben Pflicht.", "tokens": ["Der", "Herr", "Ma\u00b7gis\u00b7ter", "thut", ",", "ist", "auch", "der", "Kna\u00b7ben", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Denn wo auch di\u00df die Hand aus deinem Barthe streicht,", "tokens": ["Denn", "wo", "auch", "di\u00df", "die", "Hand", "aus", "dei\u00b7nem", "Bar\u00b7the", "streicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "PDS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und du dich unterstehst mich seitwerts anzustechen,", "tokens": ["Und", "du", "dich", "un\u00b7ter\u00b7stehst", "mich", "seit\u00b7werts", "an\u00b7zu\u00b7ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "VVFIN", "PPER", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So la\u00df mich unverklagt, wenn ich mich werde r\u00e4chen:", "tokens": ["So", "la\u00df", "mich", "un\u00b7ver\u00b7klagt", ",", "wenn", "ich", "mich", "wer\u00b7de", "r\u00e4\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJD", "$,", "KOUS", "PPER", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nein: Eule glaub es nicht, da\u00df dir der Reiger weicht.", "tokens": ["Nein", ":", "Eu\u00b7le", "glaub", "es", "nicht", ",", "da\u00df", "dir", "der", "Rei\u00b7ger", "weicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NE", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}