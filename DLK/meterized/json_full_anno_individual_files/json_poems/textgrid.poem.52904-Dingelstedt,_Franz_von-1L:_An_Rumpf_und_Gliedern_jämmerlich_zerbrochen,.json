{"textgrid.poem.52904": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: An Rumpf und Gliedern j\u00e4mmerlich zerbrochen,", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "An Rumpf und Gliedern j\u00e4mmerlich zerbrochen,", "tokens": ["An", "Rumpf", "und", "Glie\u00b7dern", "j\u00e4m\u00b7mer\u00b7lich", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gebannt in eine Form aus Sand und Lehm,", "tokens": ["Ge\u00b7bannt", "in", "ei\u00b7ne", "Form", "aus", "Sand", "und", "Lehm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hernach in Flammen, die fanatisch kochen,", "tokens": ["Her\u00b7nach", "in", "Flam\u00b7men", ",", "die", "fa\u00b7na\u00b7tisch", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gegossen nach erk\u00fcnsteltem System,", "tokens": ["Ge\u00b7gos\u00b7sen", "nach", "er\u00b7k\u00fcns\u00b7tel\u00b7tem", "Sys\u00b7tem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "So liegst Du, lichtlos, starr und unbequem", "tokens": ["So", "liegst", "Du", ",", "licht\u00b7los", ",", "starr", "und", "un\u00b7be\u00b7quem"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In Deiner Gruft, Bavaria, viele Wochen,", "tokens": ["In", "Dei\u00b7ner", "Gruft", ",", "Ba\u00b7va\u00b7ria", ",", "vie\u00b7le", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NE", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bis da\u00df der Meister, wann es ihm genehm,", "tokens": ["Bis", "da\u00df", "der", "Meis\u00b7ter", ",", "wann", "es", "ihm", "ge\u00b7nehm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "$,", "PWAV", "PPER", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sein \u00bbfertig\u00ab seufzend \u00fcber Dich gesprochen.", "tokens": ["Sein", "\u00bb", "fer\u00b7tig", "\u00ab", "seuf\u00b7zend", "\u00fc\u00b7ber", "Dich", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "ADJD", "$(", "VVPP", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und dann, ein Monument f\u00fcr das Jahrhundert,", "tokens": ["Und", "dann", ",", "ein", "Mo\u00b7nu\u00b7ment", "f\u00fcr", "das", "Jahr\u00b7hun\u00b7dert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "--+-+----+-", "measure": "anapaest.init"}, "line.2": {"text": "Von au\u00dfen gl\u00e4nzend' Erz, von innen hohl,", "tokens": ["Von", "au\u00b7\u00dfen", "gl\u00e4n\u00b7zend'", "Erz", ",", "von", "in\u00b7nen", "hohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "APPR", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Stehst Du erhaben da und all-bewundert.", "tokens": ["Stehst", "Du", "er\u00b7ha\u00b7ben", "da", "und", "all\u00b7be\u00b7wun\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Nur schad: Eins fehlt dem riesigen Symbol,", "tokens": ["Nur", "schad", ":", "Eins", "fehlt", "dem", "rie\u00b7si\u00b7gen", "Sym\u00b7bol", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df K\u00f6nig Ludwig noch den Hammer hebe", "tokens": ["Da\u00df", "K\u00f6\u00b7nig", "Lud\u00b7wig", "noch", "den", "Ham\u00b7mer", "he\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "NE", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und mit dem letzten Schlag Dir sage: LEBE!", "tokens": ["Und", "mit", "dem", "letz\u00b7ten", "Schlag", "Dir", "sa\u00b7ge", ":", "Le\u00b7BE", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$.", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.5": {"line.1": {"text": "An Rumpf und Gliedern j\u00e4mmerlich zerbrochen,", "tokens": ["An", "Rumpf", "und", "Glie\u00b7dern", "j\u00e4m\u00b7mer\u00b7lich", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gebannt in eine Form aus Sand und Lehm,", "tokens": ["Ge\u00b7bannt", "in", "ei\u00b7ne", "Form", "aus", "Sand", "und", "Lehm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hernach in Flammen, die fanatisch kochen,", "tokens": ["Her\u00b7nach", "in", "Flam\u00b7men", ",", "die", "fa\u00b7na\u00b7tisch", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gegossen nach erk\u00fcnsteltem System,", "tokens": ["Ge\u00b7gos\u00b7sen", "nach", "er\u00b7k\u00fcns\u00b7tel\u00b7tem", "Sys\u00b7tem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "So liegst Du, lichtlos, starr und unbequem", "tokens": ["So", "liegst", "Du", ",", "licht\u00b7los", ",", "starr", "und", "un\u00b7be\u00b7quem"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In Deiner Gruft, Bavaria, viele Wochen,", "tokens": ["In", "Dei\u00b7ner", "Gruft", ",", "Ba\u00b7va\u00b7ria", ",", "vie\u00b7le", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NE", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bis da\u00df der Meister, wann es ihm genehm,", "tokens": ["Bis", "da\u00df", "der", "Meis\u00b7ter", ",", "wann", "es", "ihm", "ge\u00b7nehm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "$,", "PWAV", "PPER", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sein \u00bbfertig\u00ab seufzend \u00fcber Dich gesprochen.", "tokens": ["Sein", "\u00bb", "fer\u00b7tig", "\u00ab", "seuf\u00b7zend", "\u00fc\u00b7ber", "Dich", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "ADJD", "$(", "VVPP", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und dann, ein Monument f\u00fcr das Jahrhundert,", "tokens": ["Und", "dann", ",", "ein", "Mo\u00b7nu\u00b7ment", "f\u00fcr", "das", "Jahr\u00b7hun\u00b7dert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "--+-+----+-", "measure": "anapaest.init"}, "line.2": {"text": "Von au\u00dfen gl\u00e4nzend' Erz, von innen hohl,", "tokens": ["Von", "au\u00b7\u00dfen", "gl\u00e4n\u00b7zend'", "Erz", ",", "von", "in\u00b7nen", "hohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "APPR", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Stehst Du erhaben da und all-bewundert.", "tokens": ["Stehst", "Du", "er\u00b7ha\u00b7ben", "da", "und", "all\u00b7be\u00b7wun\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Nur schad: Eins fehlt dem riesigen Symbol,", "tokens": ["Nur", "schad", ":", "Eins", "fehlt", "dem", "rie\u00b7si\u00b7gen", "Sym\u00b7bol", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df K\u00f6nig Ludwig noch den Hammer hebe", "tokens": ["Da\u00df", "K\u00f6\u00b7nig", "Lud\u00b7wig", "noch", "den", "Ham\u00b7mer", "he\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "NE", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und mit dem letzten Schlag Dir sage: LEBE!", "tokens": ["Und", "mit", "dem", "letz\u00b7ten", "Schlag", "Dir", "sa\u00b7ge", ":", "Le\u00b7BE", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$.", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}