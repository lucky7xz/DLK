{"textgrid.poem.35290": {"metadata": {"author": {"name": "Dranmor, (Schmid, Ludwig Ferdinand)", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbentartet ist die junge Brut,", "tokens": ["\u00bb", "ent\u00b7ar\u00b7tet", "ist", "die", "jun\u00b7ge", "Brut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u2013 Gott verzeihe mir die S\u00fcnde \u2013", "tokens": ["Und", "\u2013", "Gott", "ver\u00b7zei\u00b7he", "mir", "die", "S\u00fcn\u00b7de", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich habe sehr gewicht'ge Gr\u00fcnde", "tokens": ["Ich", "ha\u00b7be", "sehr", "ge\u00b7wicht'\u00b7ge", "Gr\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und manchen Anla\u00df, mehr als gut,", "tokens": ["Und", "man\u00b7chen", "An\u00b7la\u00df", ",", "mehr", "als", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit meinem eignen Fleisch zu hadern;", "tokens": ["Mit", "mei\u00b7nem", "eig\u00b7nen", "Fleisch", "zu", "ha\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn Wasser, anstatt hei\u00dfes Blut,", "tokens": ["Denn", "Was\u00b7ser", ",", "an\u00b7statt", "hei\u00b7\u00dfes", "Blut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KOUI", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Rinnt meinen S\u00f6hnen durch die Adern,", "tokens": ["Rinnt", "mei\u00b7nen", "S\u00f6h\u00b7nen", "durch", "die", "A\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Seitdem ich, auf der Mutter Bitte,", "tokens": ["Seit\u00b7dem", "ich", ",", "auf", "der", "Mut\u00b7ter", "Bit\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Den Rechtsverdrehern sie gebracht,", "tokens": ["Den", "Rechts\u00b7ver\u00b7dre\u00b7hern", "sie", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zu Advokaten sie gemacht", "tokens": ["Zu", "Ad\u00b7vo\u00b7ka\u00b7ten", "sie", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Dort in Sanct-Paul, nach heut'ger Sitte.", "tokens": ["Dort", "in", "Sanc\u00b7tPaul", ",", "nach", "heut'\u00b7ger", "Sit\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "APPR", "ADJA", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Jetzt sind sie modisch angekleidet", "tokens": ["Jetzt", "sind", "sie", "mo\u00b7disch", "an\u00b7ge\u00b7klei\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mit engen Hosen und Krawatten;", "tokens": ["Mit", "en\u00b7gen", "Ho\u00b7sen", "und", "Kra\u00b7wat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch wilde Hengste abzumatten", "tokens": ["Doch", "wil\u00b7de", "Hengs\u00b7te", "ab\u00b7zu\u00b7mat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVIZU"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ist ihnen lange schon verleidet;", "tokens": ["Ist", "ih\u00b7nen", "lan\u00b7ge", "schon", "ver\u00b7lei\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Statt dessen wird von Politik,", "tokens": ["Statt", "des\u00b7sen", "wird", "von", "Po\u00b7li\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Von Menschenrechten viel gesprochen,", "tokens": ["Von", "Men\u00b7schen\u00b7rech\u00b7ten", "viel", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Und von Theater und Musik.", "tokens": ["Und", "von", "The\u00b7a\u00b7ter", "und", "Mu\u00b7sik", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Was soll's? Die Keckheit ist gebrochen \u2013", "tokens": ["Was", "soll's", "?", "Die", "Keck\u00b7heit", "ist", "ge\u00b7bro\u00b7chen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$.", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Verrostet sind der Alten Messer;", "tokens": ["Ver\u00b7ros\u00b7tet", "sind", "der", "Al\u00b7ten", "Mes\u00b7ser", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Es gilt ihr Wort nur dann und wann,", "tokens": ["Es", "gilt", "ihr", "Wort", "nur", "dann", "und", "wann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "KON", "PWAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Denn Kinder wissen alles besser.", "tokens": ["Denn", "Kin\u00b7der", "wis\u00b7sen", "al\u00b7les", "bes\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Habt Ihr's verstanden, junger Mann?", "tokens": ["Habt", "Ih\u00b7r's", "ver\u00b7stan\u00b7den", ",", "jun\u00b7ger", "Mann", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.24": {"text": "Vielleicht geh\u00f6rt Ihr auch zu jenen", "tokens": ["Viel\u00b7leicht", "ge\u00b7h\u00f6rt", "Ihr", "auch", "zu", "je\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PDAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Spa\u00dfv\u00f6geln, die mit schlaffen Sehnen", "tokens": ["Spa\u00df\u00b7v\u00f6\u00b7geln", ",", "die", "mit", "schlaf\u00b7fen", "Seh\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Her\u00fcberfliegen, uns zu mahnen", "tokens": ["Her\u00b7\u00fc\u00b7berf\u00b7lie\u00b7gen", ",", "uns", "zu", "mah\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "An Fortschritt und an Eisenbahnen", "tokens": ["An", "Fort\u00b7schritt", "und", "an", "Ei\u00b7sen\u00b7bah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und andre solche Narrenspossen?", "tokens": ["Und", "and\u00b7re", "sol\u00b7che", "Nar\u00b7rens\u00b7pos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Gleichviel! La\u00dft die gelehrten Leute,", "tokens": ["Gleich\u00b7viel", "!", "La\u00dft", "die", "ge\u00b7lehr\u00b7ten", "Leu\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVIMP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und wenn Ihr wollt, erz\u00e4hl' ich heute", "tokens": ["Und", "wenn", "Ihr", "wollt", ",", "er\u00b7z\u00e4hl'", "ich", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VMFIN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Von einem Freund und Zeitgenossen;", "tokens": ["Von", "ei\u00b7nem", "Freund", "und", "Zeit\u00b7ge\u00b7nos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Garcia hie\u00df er als der Sohn", "tokens": ["Gar\u00b7cia", "hie\u00df", "er", "als", "der", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "KOUS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.33": {"text": "Ehrbarer Eltern (wohlgeraten", "tokens": ["Ehr\u00b7ba\u00b7rer", "El\u00b7tern", "(", "wohl\u00b7ge\u00b7ra\u00b7ten"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJA", "NN", "$(", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.34": {"text": "War dieser Sprosse \u2013 mir zum Hohn!)", "tokens": ["War", "die\u00b7ser", "Spros\u00b7se", "\u2013", "mir", "zum", "Hohn", "!", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$(", "PPER", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Und Januario von dem Paten.", "tokens": ["Und", "Ja\u00b7nu\u00b7a\u00b7rio", "von", "dem", "Pa\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.36": {"text": "Garcia! \u2013 Ha, Ihr sollt erfahren,", "tokens": ["Gar\u00b7cia", "!", "\u2013", "Ha", ",", "Ihr", "sollt", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "ITJ", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.37": {"text": "Wie der gewu\u00dft, sein Recht zu wahren,", "tokens": ["Wie", "der", "ge\u00b7wu\u00dft", ",", "sein", "Recht", "zu", "wah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "VVPP", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Was der auf diesem Grund und Boden", "tokens": ["Was", "der", "auf", "die\u00b7sem", "Grund", "und", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "APPR", "PDAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Gethan, um Unkraut auszuroden,", "tokens": ["Ge\u00b7than", ",", "um", "Un\u00b7kraut", "aus\u00b7zu\u00b7ro\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUI", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Was der geschworen und gelitten!", "tokens": ["Was", "der", "ge\u00b7schwo\u00b7ren", "und", "ge\u00b7lit\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Schon gestern hatt' ich's auf der Zunge,", "tokens": ["Schon", "ge\u00b7stern", "hatt'", "ich's", "auf", "der", "Zun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Als wir die kleine Strecke ritten", "tokens": ["Als", "wir", "die", "klei\u00b7ne", "Stre\u00b7cke", "rit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Von Sorocaba nach It\u00f9;", "tokens": ["Von", "So\u00b7ro\u00b7ca\u00b7ba", "nach", "It\u00f9", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.44": {"text": "Staub aber lag auf meiner Zunge", "tokens": ["Staub", "a\u00b7ber", "lag", "auf", "mei\u00b7ner", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Und klebte mir die Lippen zu.\u00ab", "tokens": ["Und", "kleb\u00b7te", "mir", "die", "Lip\u00b7pen", "zu", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nach solchen Eingangsworten flo\u00df", "tokens": ["Nach", "sol\u00b7chen", "Ein\u00b7gangs\u00b7wor\u00b7ten", "flo\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Rede von des Alten Munde.", "tokens": ["Die", "Re\u00b7de", "von", "des", "Al\u00b7ten", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir lagen schweigend in der Runde,", "tokens": ["Wir", "la\u00b7gen", "schwei\u00b7gend", "in", "der", "Run\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wenn uns mancher Wink verdro\u00df,", "tokens": ["Und", "wenn", "uns", "man\u00b7cher", "Wink", "ver\u00b7dro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir mu\u00dften dies und jenes h\u00f6ren,", "tokens": ["Wir", "mu\u00df\u00b7ten", "dies", "und", "je\u00b7nes", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PDS", "KON", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es wagte keiner ihn zu st\u00f6ren.", "tokens": ["Es", "wag\u00b7te", "kei\u00b7ner", "ihn", "zu", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Fazendeiro", "tokens": ["Ein", "Fa\u00b7zen\u00b7dei\u00b7ro"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "In harter Arbeit, hei\u00dfem Schaffen,", "tokens": ["In", "har\u00b7ter", "Ar\u00b7beit", ",", "hei\u00b7\u00dfem", "Schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Der seine blankgeputzten Waffen", "tokens": ["Der", "sei\u00b7ne", "blank\u00b7ge\u00b7putz\u00b7ten", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zuweilen grimmig angeschaut,", "tokens": ["Zu\u00b7wei\u00b7len", "grim\u00b7mig", "an\u00b7ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ein halber Gaucho, rauh und z\u00e4he. \u2013 \u2013", "tokens": ["Ein", "hal\u00b7ber", "Gau\u00b7cho", ",", "rauh", "und", "z\u00e4\u00b7he", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "KON", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wir ruhten aus am Lagerfeuer;", "tokens": ["Wir", "ruh\u00b7ten", "aus", "am", "La\u00b7ger\u00b7feu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die Pferde grasten in der N\u00e4he,", "tokens": ["Die", "Pfer\u00b7de", "gras\u00b7ten", "in", "der", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und da\u00df Garcias Abenteuer", "tokens": ["Und", "da\u00df", "Gar\u00b7ci\u00b7as", "A\u00b7bent\u00b7eu\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Uns, deren Herzen nicht gest\u00e4hlt,", "tokens": ["Uns", ",", "de\u00b7ren", "Her\u00b7zen", "nicht", "ge\u00b7st\u00e4hlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Den Schlaf verscheuchten, glaube jeder,", "tokens": ["Den", "Schlaf", "ver\u00b7scheuch\u00b7ten", ",", "glau\u00b7be", "je\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Der lesen mag, was meine Feder", "tokens": ["Der", "le\u00b7sen", "mag", ",", "was", "mei\u00b7ne", "Fe\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "VVINF", "VMFIN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Mit leichten Strichen nacherz\u00e4hlt.", "tokens": ["Mit", "leich\u00b7ten", "Stri\u00b7chen", "na\u00b7ch\u00b7er\u00b7z\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.19": {"text": "Denn ich bekenne meine Schw\u00e4che,", "tokens": ["Denn", "ich", "be\u00b7ken\u00b7ne", "mei\u00b7ne", "Schw\u00e4\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die Scene schildern kann ich nicht.", "tokens": ["Die", "Sce\u00b7ne", "schil\u00b7dern", "kann", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Vollmond go\u00df sein Silberlicht", "tokens": ["Der", "Voll\u00b7mond", "go\u00df", "sein", "Sil\u00b7ber\u00b7licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf eine waldumkr\u00e4nzte Fl\u00e4che,", "tokens": ["Auf", "ei\u00b7ne", "wald\u00b7um\u00b7kr\u00e4nz\u00b7te", "Fl\u00e4\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hier Gr\u00e4ser, von Demanten funkelnd,", "tokens": ["Hier", "Gr\u00e4\u00b7ser", ",", "von", "De\u00b7man\u00b7ten", "fun\u00b7kelnd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Felsbl\u00f6cke dort auf Blumenmatten,", "tokens": ["Fels\u00b7bl\u00f6\u00b7cke", "dort", "auf", "Blu\u00b7men\u00b7mat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit ihren langgestreckten Schatten", "tokens": ["Mit", "ih\u00b7ren", "lang\u00b7ge\u00b7streck\u00b7ten", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das wunderbare Bild verdunkelnd.", "tokens": ["Das", "wun\u00b7der\u00b7ba\u00b7re", "Bild", "ver\u00b7dun\u00b7kelnd", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des Alten Stimme, bald erschallend", "tokens": ["Des", "Al\u00b7ten", "Stim\u00b7me", ",", "bald", "er\u00b7schal\u00b7lend"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie Sturmestoben, bald verhallend", "tokens": ["Wie", "Stur\u00b7me\u00b7sto\u00b7ben", ",", "bald", "ver\u00b7hal\u00b7lend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWAV", "NN", "$,", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wie Todesseufzer, dumpf und hohl \u2013", "tokens": ["Wie", "To\u00b7des\u00b7seuf\u00b7zer", ",", "dumpf", "und", "hohl", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das alles l\u00e4\u00dft sich nicht beschreiben;", "tokens": ["Das", "al\u00b7les", "l\u00e4\u00dft", "sich", "nicht", "be\u00b7schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Mir aber wird die Scene wohl", "tokens": ["Mir", "a\u00b7ber", "wird", "die", "Sce\u00b7ne", "wohl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Auf immer im Ged\u00e4chtnis bleiben!", "tokens": ["Auf", "im\u00b7mer", "im", "Ge\u00b7d\u00e4cht\u00b7nis", "blei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbentartet ist die junge Brut,", "tokens": ["\u00bb", "ent\u00b7ar\u00b7tet", "ist", "die", "jun\u00b7ge", "Brut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u2013 Gott verzeihe mir die S\u00fcnde \u2013", "tokens": ["Und", "\u2013", "Gott", "ver\u00b7zei\u00b7he", "mir", "die", "S\u00fcn\u00b7de", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich habe sehr gewicht'ge Gr\u00fcnde", "tokens": ["Ich", "ha\u00b7be", "sehr", "ge\u00b7wicht'\u00b7ge", "Gr\u00fcn\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und manchen Anla\u00df, mehr als gut,", "tokens": ["Und", "man\u00b7chen", "An\u00b7la\u00df", ",", "mehr", "als", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit meinem eignen Fleisch zu hadern;", "tokens": ["Mit", "mei\u00b7nem", "eig\u00b7nen", "Fleisch", "zu", "ha\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn Wasser, anstatt hei\u00dfes Blut,", "tokens": ["Denn", "Was\u00b7ser", ",", "an\u00b7statt", "hei\u00b7\u00dfes", "Blut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KOUI", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Rinnt meinen S\u00f6hnen durch die Adern,", "tokens": ["Rinnt", "mei\u00b7nen", "S\u00f6h\u00b7nen", "durch", "die", "A\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Seitdem ich, auf der Mutter Bitte,", "tokens": ["Seit\u00b7dem", "ich", ",", "auf", "der", "Mut\u00b7ter", "Bit\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Den Rechtsverdrehern sie gebracht,", "tokens": ["Den", "Rechts\u00b7ver\u00b7dre\u00b7hern", "sie", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zu Advokaten sie gemacht", "tokens": ["Zu", "Ad\u00b7vo\u00b7ka\u00b7ten", "sie", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Dort in Sanct-Paul, nach heut'ger Sitte.", "tokens": ["Dort", "in", "Sanc\u00b7tPaul", ",", "nach", "heut'\u00b7ger", "Sit\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "APPR", "ADJA", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Jetzt sind sie modisch angekleidet", "tokens": ["Jetzt", "sind", "sie", "mo\u00b7disch", "an\u00b7ge\u00b7klei\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mit engen Hosen und Krawatten;", "tokens": ["Mit", "en\u00b7gen", "Ho\u00b7sen", "und", "Kra\u00b7wat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch wilde Hengste abzumatten", "tokens": ["Doch", "wil\u00b7de", "Hengs\u00b7te", "ab\u00b7zu\u00b7mat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVIZU"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ist ihnen lange schon verleidet;", "tokens": ["Ist", "ih\u00b7nen", "lan\u00b7ge", "schon", "ver\u00b7lei\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Statt dessen wird von Politik,", "tokens": ["Statt", "des\u00b7sen", "wird", "von", "Po\u00b7li\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Von Menschenrechten viel gesprochen,", "tokens": ["Von", "Men\u00b7schen\u00b7rech\u00b7ten", "viel", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Und von Theater und Musik.", "tokens": ["Und", "von", "The\u00b7a\u00b7ter", "und", "Mu\u00b7sik", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Was soll's? Die Keckheit ist gebrochen \u2013", "tokens": ["Was", "soll's", "?", "Die", "Keck\u00b7heit", "ist", "ge\u00b7bro\u00b7chen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$.", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Verrostet sind der Alten Messer;", "tokens": ["Ver\u00b7ros\u00b7tet", "sind", "der", "Al\u00b7ten", "Mes\u00b7ser", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Es gilt ihr Wort nur dann und wann,", "tokens": ["Es", "gilt", "ihr", "Wort", "nur", "dann", "und", "wann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "KON", "PWAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Denn Kinder wissen alles besser.", "tokens": ["Denn", "Kin\u00b7der", "wis\u00b7sen", "al\u00b7les", "bes\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Habt Ihr's verstanden, junger Mann?", "tokens": ["Habt", "Ih\u00b7r's", "ver\u00b7stan\u00b7den", ",", "jun\u00b7ger", "Mann", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.24": {"text": "Vielleicht geh\u00f6rt Ihr auch zu jenen", "tokens": ["Viel\u00b7leicht", "ge\u00b7h\u00f6rt", "Ihr", "auch", "zu", "je\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PDAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Spa\u00dfv\u00f6geln, die mit schlaffen Sehnen", "tokens": ["Spa\u00df\u00b7v\u00f6\u00b7geln", ",", "die", "mit", "schlaf\u00b7fen", "Seh\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Her\u00fcberfliegen, uns zu mahnen", "tokens": ["Her\u00b7\u00fc\u00b7berf\u00b7lie\u00b7gen", ",", "uns", "zu", "mah\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "An Fortschritt und an Eisenbahnen", "tokens": ["An", "Fort\u00b7schritt", "und", "an", "Ei\u00b7sen\u00b7bah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und andre solche Narrenspossen?", "tokens": ["Und", "and\u00b7re", "sol\u00b7che", "Nar\u00b7rens\u00b7pos\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Gleichviel! La\u00dft die gelehrten Leute,", "tokens": ["Gleich\u00b7viel", "!", "La\u00dft", "die", "ge\u00b7lehr\u00b7ten", "Leu\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVIMP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und wenn Ihr wollt, erz\u00e4hl' ich heute", "tokens": ["Und", "wenn", "Ihr", "wollt", ",", "er\u00b7z\u00e4hl'", "ich", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VMFIN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Von einem Freund und Zeitgenossen;", "tokens": ["Von", "ei\u00b7nem", "Freund", "und", "Zeit\u00b7ge\u00b7nos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Garcia hie\u00df er als der Sohn", "tokens": ["Gar\u00b7cia", "hie\u00df", "er", "als", "der", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "KOUS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.33": {"text": "Ehrbarer Eltern (wohlgeraten", "tokens": ["Ehr\u00b7ba\u00b7rer", "El\u00b7tern", "(", "wohl\u00b7ge\u00b7ra\u00b7ten"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJA", "NN", "$(", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.34": {"text": "War dieser Sprosse \u2013 mir zum Hohn!)", "tokens": ["War", "die\u00b7ser", "Spros\u00b7se", "\u2013", "mir", "zum", "Hohn", "!", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$(", "PPER", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Und Januario von dem Paten.", "tokens": ["Und", "Ja\u00b7nu\u00b7a\u00b7rio", "von", "dem", "Pa\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.36": {"text": "Garcia! \u2013 Ha, Ihr sollt erfahren,", "tokens": ["Gar\u00b7cia", "!", "\u2013", "Ha", ",", "Ihr", "sollt", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "ITJ", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.37": {"text": "Wie der gewu\u00dft, sein Recht zu wahren,", "tokens": ["Wie", "der", "ge\u00b7wu\u00dft", ",", "sein", "Recht", "zu", "wah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "VVPP", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Was der auf diesem Grund und Boden", "tokens": ["Was", "der", "auf", "die\u00b7sem", "Grund", "und", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "APPR", "PDAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Gethan, um Unkraut auszuroden,", "tokens": ["Ge\u00b7than", ",", "um", "Un\u00b7kraut", "aus\u00b7zu\u00b7ro\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUI", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Was der geschworen und gelitten!", "tokens": ["Was", "der", "ge\u00b7schwo\u00b7ren", "und", "ge\u00b7lit\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Schon gestern hatt' ich's auf der Zunge,", "tokens": ["Schon", "ge\u00b7stern", "hatt'", "ich's", "auf", "der", "Zun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Als wir die kleine Strecke ritten", "tokens": ["Als", "wir", "die", "klei\u00b7ne", "Stre\u00b7cke", "rit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Von Sorocaba nach It\u00f9;", "tokens": ["Von", "So\u00b7ro\u00b7ca\u00b7ba", "nach", "It\u00f9", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.44": {"text": "Staub aber lag auf meiner Zunge", "tokens": ["Staub", "a\u00b7ber", "lag", "auf", "mei\u00b7ner", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Und klebte mir die Lippen zu.\u00ab", "tokens": ["Und", "kleb\u00b7te", "mir", "die", "Lip\u00b7pen", "zu", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nach solchen Eingangsworten flo\u00df", "tokens": ["Nach", "sol\u00b7chen", "Ein\u00b7gangs\u00b7wor\u00b7ten", "flo\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Rede von des Alten Munde.", "tokens": ["Die", "Re\u00b7de", "von", "des", "Al\u00b7ten", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir lagen schweigend in der Runde,", "tokens": ["Wir", "la\u00b7gen", "schwei\u00b7gend", "in", "der", "Run\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wenn uns mancher Wink verdro\u00df,", "tokens": ["Und", "wenn", "uns", "man\u00b7cher", "Wink", "ver\u00b7dro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir mu\u00dften dies und jenes h\u00f6ren,", "tokens": ["Wir", "mu\u00df\u00b7ten", "dies", "und", "je\u00b7nes", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PDS", "KON", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es wagte keiner ihn zu st\u00f6ren.", "tokens": ["Es", "wag\u00b7te", "kei\u00b7ner", "ihn", "zu", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Fazendeiro", "tokens": ["Ein", "Fa\u00b7zen\u00b7dei\u00b7ro"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "In harter Arbeit, hei\u00dfem Schaffen,", "tokens": ["In", "har\u00b7ter", "Ar\u00b7beit", ",", "hei\u00b7\u00dfem", "Schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Der seine blankgeputzten Waffen", "tokens": ["Der", "sei\u00b7ne", "blank\u00b7ge\u00b7putz\u00b7ten", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zuweilen grimmig angeschaut,", "tokens": ["Zu\u00b7wei\u00b7len", "grim\u00b7mig", "an\u00b7ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ein halber Gaucho, rauh und z\u00e4he. \u2013 \u2013", "tokens": ["Ein", "hal\u00b7ber", "Gau\u00b7cho", ",", "rauh", "und", "z\u00e4\u00b7he", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "KON", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wir ruhten aus am Lagerfeuer;", "tokens": ["Wir", "ruh\u00b7ten", "aus", "am", "La\u00b7ger\u00b7feu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die Pferde grasten in der N\u00e4he,", "tokens": ["Die", "Pfer\u00b7de", "gras\u00b7ten", "in", "der", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und da\u00df Garcias Abenteuer", "tokens": ["Und", "da\u00df", "Gar\u00b7ci\u00b7as", "A\u00b7bent\u00b7eu\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Uns, deren Herzen nicht gest\u00e4hlt,", "tokens": ["Uns", ",", "de\u00b7ren", "Her\u00b7zen", "nicht", "ge\u00b7st\u00e4hlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Den Schlaf verscheuchten, glaube jeder,", "tokens": ["Den", "Schlaf", "ver\u00b7scheuch\u00b7ten", ",", "glau\u00b7be", "je\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Der lesen mag, was meine Feder", "tokens": ["Der", "le\u00b7sen", "mag", ",", "was", "mei\u00b7ne", "Fe\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "VVINF", "VMFIN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Mit leichten Strichen nacherz\u00e4hlt.", "tokens": ["Mit", "leich\u00b7ten", "Stri\u00b7chen", "na\u00b7ch\u00b7er\u00b7z\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.19": {"text": "Denn ich bekenne meine Schw\u00e4che,", "tokens": ["Denn", "ich", "be\u00b7ken\u00b7ne", "mei\u00b7ne", "Schw\u00e4\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die Scene schildern kann ich nicht.", "tokens": ["Die", "Sce\u00b7ne", "schil\u00b7dern", "kann", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Vollmond go\u00df sein Silberlicht", "tokens": ["Der", "Voll\u00b7mond", "go\u00df", "sein", "Sil\u00b7ber\u00b7licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf eine waldumkr\u00e4nzte Fl\u00e4che,", "tokens": ["Auf", "ei\u00b7ne", "wald\u00b7um\u00b7kr\u00e4nz\u00b7te", "Fl\u00e4\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hier Gr\u00e4ser, von Demanten funkelnd,", "tokens": ["Hier", "Gr\u00e4\u00b7ser", ",", "von", "De\u00b7man\u00b7ten", "fun\u00b7kelnd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Felsbl\u00f6cke dort auf Blumenmatten,", "tokens": ["Fels\u00b7bl\u00f6\u00b7cke", "dort", "auf", "Blu\u00b7men\u00b7mat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit ihren langgestreckten Schatten", "tokens": ["Mit", "ih\u00b7ren", "lang\u00b7ge\u00b7streck\u00b7ten", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das wunderbare Bild verdunkelnd.", "tokens": ["Das", "wun\u00b7der\u00b7ba\u00b7re", "Bild", "ver\u00b7dun\u00b7kelnd", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Des Alten Stimme, bald erschallend", "tokens": ["Des", "Al\u00b7ten", "Stim\u00b7me", ",", "bald", "er\u00b7schal\u00b7lend"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie Sturmestoben, bald verhallend", "tokens": ["Wie", "Stur\u00b7me\u00b7sto\u00b7ben", ",", "bald", "ver\u00b7hal\u00b7lend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWAV", "NN", "$,", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wie Todesseufzer, dumpf und hohl \u2013", "tokens": ["Wie", "To\u00b7des\u00b7seuf\u00b7zer", ",", "dumpf", "und", "hohl", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das alles l\u00e4\u00dft sich nicht beschreiben;", "tokens": ["Das", "al\u00b7les", "l\u00e4\u00dft", "sich", "nicht", "be\u00b7schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Mir aber wird die Scene wohl", "tokens": ["Mir", "a\u00b7ber", "wird", "die", "Sce\u00b7ne", "wohl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Auf immer im Ged\u00e4chtnis bleiben!", "tokens": ["Auf", "im\u00b7mer", "im", "Ge\u00b7d\u00e4cht\u00b7nis", "blei\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}