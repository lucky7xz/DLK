{"textgrid.poem.55574": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "An Johann Heinrich Merck", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schicke dir hier in altem Kleid", "tokens": ["Schi\u00b7cke", "dir", "hier", "in", "al\u00b7tem", "Kleid"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ein neues Kindlein wohl bereit,", "tokens": ["Ein", "neu\u00b7es", "Kin\u00b7dlein", "wohl", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ist's nichts weiters auf der Bahn,", "tokens": ["Und", "ist's", "nichts", "wei\u00b7ters", "auf", "der", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat's immer alte Hosen an.", "tokens": ["Hat's", "im\u00b7mer", "al\u00b7te", "Ho\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir Neuen sind ja solche Hasen,", "tokens": ["Wir", "Neu\u00b7en", "sind", "ja", "sol\u00b7che", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sehn immer nach den alten Nasen,", "tokens": ["Sehn", "im\u00b7mer", "nach", "den", "al\u00b7ten", "Na\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und hast ja auch, wie's jeder schaut,", "tokens": ["Und", "hast", "ja", "auch", ",", "wie's", "je\u00b7der", "schaut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dir Neuen ein altes Haus gebaut.", "tokens": ["Dir", "Neu\u00b7en", "ein", "al\u00b7tes", "Haus", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Darum, wie's steht sodann geschrieben", "tokens": ["Da\u00b7rum", ",", "wie's", "steht", "so\u00b7dann", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "$,", "PWAV", "VVFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Im Evangelium da dr\u00fcben,", "tokens": ["Im", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "da", "dr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "$,"], "meter": "-----+-+-", "measure": "unknown.measure.di"}, "line.11": {"text": "Da\u00df sich der neu Most so erweist,", "tokens": ["Da\u00df", "sich", "der", "neu", "Most", "so", "er\u00b7weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJD", "NN", "ADV", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.12": {"text": "Da\u00df er die alten Schl\u00e4uch zerrei\u00dft. \u2013", "tokens": ["Da\u00df", "er", "die", "al\u00b7ten", "Schl\u00e4uch", "zer\u00b7rei\u00dft", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ist fast das Gegenteil so wahr,", "tokens": ["Ist", "fast", "das", "Ge\u00b7gen\u00b7teil", "so", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Das Alt' die jungen Schl\u00e4uch rei\u00dft gar.", "tokens": ["Das", "Alt'", "die", "jun\u00b7gen", "Schl\u00e4uch", "rei\u00dft", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und k\u00f6nnen wir nicht tragen mehr", "tokens": ["Und", "k\u00f6n\u00b7nen", "wir", "nicht", "tra\u00b7gen", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Krebs, Panzerhemd, Helm, Schwert und Speer", "tokens": ["Krebs", ",", "Pan\u00b7zer\u00b7hemd", ",", "Helm", ",", "Schwert", "und", "Speer"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und erliegen darunter tot", "tokens": ["Und", "er\u00b7lie\u00b7gen", "da\u00b7run\u00b7ter", "tot"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PAV", "ADJD"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Wie Ameis unterm Schollenkot,", "tokens": ["Wie", "Am\u00b7eis", "un\u00b7term", "Schol\u00b7len\u00b7kot", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So ist doch immer unser Mut", "tokens": ["So", "ist", "doch", "im\u00b7mer", "un\u00b7ser", "Mut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wahrhaftig wahr und bieder gut.", "tokens": ["Wahr\u00b7haf\u00b7tig", "wahr", "und", "bie\u00b7der", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Und allen Perr\u00fcckeurs und Fratzen", "tokens": ["Und", "al\u00b7len", "Per\u00b7r\u00fc\u00b7ck\u00b7eurs", "und", "Frat\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Und allen literar'schen Katzen", "tokens": ["Und", "al\u00b7len", "li\u00b7tera\u00b7r'\u00b7schen", "Kat\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Und R\u00e4ten, Schreibern, M\u00e4dels, Kindern", "tokens": ["Und", "R\u00e4\u00b7ten", ",", "Schrei\u00b7bern", ",", "M\u00e4\u00b7dels", ",", "Kin\u00b7dern"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und wissenschaftlich sch\u00f6nen S\u00fcndern", "tokens": ["Und", "wis\u00b7sen\u00b7schaft\u00b7lich", "sch\u00f6\u00b7nen", "S\u00fcn\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Sei Trotz und Hohn gesprochen hier", "tokens": ["Sei", "Trotz", "und", "Hohn", "ge\u00b7spro\u00b7chen", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "NN", "VVPP", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Und Ha\u00df und \u00c4rger f\u00fcr und f\u00fcr.", "tokens": ["Und", "Ha\u00df", "und", "\u00c4r\u00b7ger", "f\u00fcr", "und", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPR", "KON", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Weisen wir so diesen Philistern,", "tokens": ["Wei\u00b7sen", "wir", "so", "die\u00b7sen", "Phi\u00b7lis\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PDAT", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.28": {"text": "Kritikastern und ihren Geschwistern", "tokens": ["Kri\u00b7ti\u00b7kas\u00b7tern", "und", "ih\u00b7ren", "Ge\u00b7schwis\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "PPOSAT", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.29": {"text": "Wohl ein jeder aus seinem Haus", "tokens": ["Wohl", "ein", "je\u00b7der", "aus", "sei\u00b7nem", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "PIS", "APPR", "PPOSAT", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.30": {"text": "Seinen Arsch zum Fenster hinaus.", "tokens": ["Sei\u00b7nen", "Arsch", "zum", "Fens\u00b7ter", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Schicke dir hier in altem Kleid", "tokens": ["Schi\u00b7cke", "dir", "hier", "in", "al\u00b7tem", "Kleid"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ein neues Kindlein wohl bereit,", "tokens": ["Ein", "neu\u00b7es", "Kin\u00b7dlein", "wohl", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ist's nichts weiters auf der Bahn,", "tokens": ["Und", "ist's", "nichts", "wei\u00b7ters", "auf", "der", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat's immer alte Hosen an.", "tokens": ["Hat's", "im\u00b7mer", "al\u00b7te", "Ho\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir Neuen sind ja solche Hasen,", "tokens": ["Wir", "Neu\u00b7en", "sind", "ja", "sol\u00b7che", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sehn immer nach den alten Nasen,", "tokens": ["Sehn", "im\u00b7mer", "nach", "den", "al\u00b7ten", "Na\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und hast ja auch, wie's jeder schaut,", "tokens": ["Und", "hast", "ja", "auch", ",", "wie's", "je\u00b7der", "schaut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dir Neuen ein altes Haus gebaut.", "tokens": ["Dir", "Neu\u00b7en", "ein", "al\u00b7tes", "Haus", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Darum, wie's steht sodann geschrieben", "tokens": ["Da\u00b7rum", ",", "wie's", "steht", "so\u00b7dann", "ge\u00b7schrie\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "$,", "PWAV", "VVFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Im Evangelium da dr\u00fcben,", "tokens": ["Im", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "da", "dr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "$,"], "meter": "-----+-+-", "measure": "unknown.measure.di"}, "line.11": {"text": "Da\u00df sich der neu Most so erweist,", "tokens": ["Da\u00df", "sich", "der", "neu", "Most", "so", "er\u00b7weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJD", "NN", "ADV", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.12": {"text": "Da\u00df er die alten Schl\u00e4uch zerrei\u00dft. \u2013", "tokens": ["Da\u00df", "er", "die", "al\u00b7ten", "Schl\u00e4uch", "zer\u00b7rei\u00dft", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ist fast das Gegenteil so wahr,", "tokens": ["Ist", "fast", "das", "Ge\u00b7gen\u00b7teil", "so", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Das Alt' die jungen Schl\u00e4uch rei\u00dft gar.", "tokens": ["Das", "Alt'", "die", "jun\u00b7gen", "Schl\u00e4uch", "rei\u00dft", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und k\u00f6nnen wir nicht tragen mehr", "tokens": ["Und", "k\u00f6n\u00b7nen", "wir", "nicht", "tra\u00b7gen", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Krebs, Panzerhemd, Helm, Schwert und Speer", "tokens": ["Krebs", ",", "Pan\u00b7zer\u00b7hemd", ",", "Helm", ",", "Schwert", "und", "Speer"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und erliegen darunter tot", "tokens": ["Und", "er\u00b7lie\u00b7gen", "da\u00b7run\u00b7ter", "tot"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PAV", "ADJD"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Wie Ameis unterm Schollenkot,", "tokens": ["Wie", "Am\u00b7eis", "un\u00b7term", "Schol\u00b7len\u00b7kot", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So ist doch immer unser Mut", "tokens": ["So", "ist", "doch", "im\u00b7mer", "un\u00b7ser", "Mut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wahrhaftig wahr und bieder gut.", "tokens": ["Wahr\u00b7haf\u00b7tig", "wahr", "und", "bie\u00b7der", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Und allen Perr\u00fcckeurs und Fratzen", "tokens": ["Und", "al\u00b7len", "Per\u00b7r\u00fc\u00b7ck\u00b7eurs", "und", "Frat\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Und allen literar'schen Katzen", "tokens": ["Und", "al\u00b7len", "li\u00b7tera\u00b7r'\u00b7schen", "Kat\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Und R\u00e4ten, Schreibern, M\u00e4dels, Kindern", "tokens": ["Und", "R\u00e4\u00b7ten", ",", "Schrei\u00b7bern", ",", "M\u00e4\u00b7dels", ",", "Kin\u00b7dern"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und wissenschaftlich sch\u00f6nen S\u00fcndern", "tokens": ["Und", "wis\u00b7sen\u00b7schaft\u00b7lich", "sch\u00f6\u00b7nen", "S\u00fcn\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Sei Trotz und Hohn gesprochen hier", "tokens": ["Sei", "Trotz", "und", "Hohn", "ge\u00b7spro\u00b7chen", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "NN", "VVPP", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Und Ha\u00df und \u00c4rger f\u00fcr und f\u00fcr.", "tokens": ["Und", "Ha\u00df", "und", "\u00c4r\u00b7ger", "f\u00fcr", "und", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPR", "KON", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Weisen wir so diesen Philistern,", "tokens": ["Wei\u00b7sen", "wir", "so", "die\u00b7sen", "Phi\u00b7lis\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PDAT", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.28": {"text": "Kritikastern und ihren Geschwistern", "tokens": ["Kri\u00b7ti\u00b7kas\u00b7tern", "und", "ih\u00b7ren", "Ge\u00b7schwis\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "PPOSAT", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.29": {"text": "Wohl ein jeder aus seinem Haus", "tokens": ["Wohl", "ein", "je\u00b7der", "aus", "sei\u00b7nem", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "PIS", "APPR", "PPOSAT", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.30": {"text": "Seinen Arsch zum Fenster hinaus.", "tokens": ["Sei\u00b7nen", "Arsch", "zum", "Fens\u00b7ter", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}}}}