{"textgrid.poem.54035": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Immer", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zum Beispiel Sie, Herr Fairbanks, sind doch eine Nummer!", "tokens": ["Zum", "Bei\u00b7spiel", "Sie", ",", "Herr", "Fair\u00b7banks", ",", "sind", "doch", "ei\u00b7ne", "Num\u00b7mer", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "$,", "NN", "NE", "$,", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie haben Ihren eigenen Ozean", "tokens": ["Sie", "ha\u00b7ben", "Ih\u00b7ren", "ei\u00b7ge\u00b7nen", "O\u00b7ze\u00b7an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "und soviel Geld! und Gl\u00fcck . . . und niemals Kummer . . .", "tokens": ["und", "so\u00b7viel", "Geld", "!", "und", "Gl\u00fcck", ".", ".", ".", "und", "nie\u00b7mals", "Kum\u00b7mer", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "$.", "KON", "NN", "$.", "$.", "$.", "KON", "ADV", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und eine Frau so s\u00fc\u00df wie Marzipan.", "tokens": ["und", "ei\u00b7ne", "Frau", "so", "s\u00fc\u00df", "wie", "Mar\u00b7zi\u00b7pan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADJD", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch manchmal, denk ich, nachts, wenn alles schweigt,", "tokens": ["Doch", "manch\u00b7mal", ",", "denk", "ich", ",", "nachts", ",", "wenn", "al\u00b7les", "schweigt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VVFIN", "PPER", "$,", "ADV", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "ob Ihnen da die Traurigkeit nicht einen geigt:", "tokens": ["ob", "Ih\u00b7nen", "da", "die", "Trau\u00b7rig\u00b7keit", "nicht", "ei\u00b7nen", "geigt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "PTKNEG", "ART", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u00bbja, immer Gl\u00fcck . . . das ist es eben . . .", "tokens": ["\u00bb", "ja", ",", "im\u00b7mer", "Gl\u00fcck", ".", ".", ".", "das", "ist", "es", "e\u00b7ben", ".", ".", "."], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "ADV", "NN", "$.", "$.", "$.", "PDS", "VAFIN", "PPER", "ADV", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den ganzen Tag?", "tokens": ["Den", "gan\u00b7zen", "Tag", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Das ganze Jahr?", "tokens": ["Das", "gan\u00b7ze", "Jahr", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Das ganze Leben \u2013?\u00ab", "tokens": ["Das", "gan\u00b7ze", "Le\u00b7ben", "\u2013", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Zum Beispiel Sie, Herr Ehemann, sind zu beneiden:", "tokens": ["Zum", "Bei\u00b7spiel", "Sie", ",", "Herr", "E\u00b7he\u00b7mann", ",", "sind", "zu", "be\u00b7nei\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "$,", "NN", "NN", "$,", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie haben eine Sch\u00f6nheitsk\u00f6nigin zur Frau.", "tokens": ["Sie", "ha\u00b7ben", "ei\u00b7ne", "Sch\u00f6n\u00b7heits\u00b7k\u00f6\u00b7ni\u00b7gin", "zur", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vor Ihnen darf die Venus aus der Wanne steigen . . .", "tokens": ["Vor", "Ih\u00b7nen", "darf", "die", "Ve\u00b7nus", "aus", "der", "Wan\u00b7ne", "stei\u00b7gen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPER", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wir sehn ihr Bild \u2013 Sie kennen sie genau.", "tokens": ["wir", "sehn", "ihr", "Bild", "\u2013", "Sie", "ken\u00b7nen", "sie", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$(", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn so verteilt die Gaben das Geschick.", "tokens": ["Denn", "so", "ver\u00b7teilt", "die", "Ga\u00b7ben", "das", "Ge\u00b7schick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nach Jahren ist da was in Ihrem Blick . . .", "tokens": ["Nach", "Jah\u00b7ren", "ist", "da", "was", "in", "Ih\u00b7rem", "Blick", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "NN", "VAFIN", "ADV", "PWS", "APPR", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So summsen Fliegen, die am Sirup kleben . . .", "tokens": ["So", "summ\u00b7sen", "Flie\u00b7gen", ",", "die", "am", "Si\u00b7rup", "kle\u00b7ben", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Den ganzen Tag?", "tokens": ["Den", "gan\u00b7zen", "Tag", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Das ganze Jahr?", "tokens": ["Das", "gan\u00b7ze", "Jahr", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Das ganze Leben \u2013?", "tokens": ["Das", "gan\u00b7ze", "Le\u00b7ben", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Mensch, sei nicht neidisch!", "tokens": ["Mensch", ",", "sei", "nicht", "nei\u00b7disch", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Gl\u00fcck hat seinen Schimmer . . .", "tokens": ["Gl\u00fcck", "hat", "sei\u00b7nen", "Schim\u00b7mer", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stehst du im Tal, vergi\u00df nicht vor den H\u00f6hn:", "tokens": ["Stehst", "du", "im", "Tal", ",", "ver\u00b7gi\u00df", "nicht", "vor", "den", "H\u00f6hn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "VVIMP", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das, was man einmal tut, ist sch\u00f6n. Doch was man immer", "tokens": ["Das", ",", "was", "man", "ein\u00b7mal", "tut", ",", "ist", "sch\u00f6n", ".", "Doch", "was", "man", "im\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,", "VAFIN", "ADJD", "$.", "KON", "PWS", "PIS", "ADV"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}, "line.5": {"text": "zu tun gen\u00f6tigt ist, ist weniger sch\u00f6n.", "tokens": ["zu", "tun", "ge\u00b7n\u00f6\u00b7tigt", "ist", ",", "ist", "we\u00b7ni\u00b7ger", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVPP", "VAFIN", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Brathuhn ist gut. Was aber t\u00e4tst du tun,", "tokens": ["Bra\u00b7thuhn", "ist", "gut", ".", "Was", "a\u00b7ber", "t\u00e4tst", "du", "tun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PWS", "ADV", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "gibt man dir jeden Tag gebratenes Huhn?", "tokens": ["gibt", "man", "dir", "je\u00b7den", "Tag", "ge\u00b7bra\u00b7te\u00b7nes", "Huhn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Na, siehst du. Sowas sch\u00e4tzt du auch daneben . . .", "tokens": ["Na", ",", "siehst", "du", ".", "So\u00b7was", "sch\u00e4tzt", "du", "auch", "da\u00b7ne\u00b7ben", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "$.", "PIS", "VVFIN", "PPER", "ADV", "PAV", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sei helle!", "tokens": ["Sei", "hel\u00b7le", "!"], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "ADJA", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Lebe du dein eigenes Leben.", "tokens": ["Le\u00b7be", "du", "dein", "ei\u00b7ge\u00b7nes", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Zum Beispiel Sie, Herr Fairbanks, sind doch eine Nummer!", "tokens": ["Zum", "Bei\u00b7spiel", "Sie", ",", "Herr", "Fair\u00b7banks", ",", "sind", "doch", "ei\u00b7ne", "Num\u00b7mer", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "$,", "NN", "NE", "$,", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie haben Ihren eigenen Ozean", "tokens": ["Sie", "ha\u00b7ben", "Ih\u00b7ren", "ei\u00b7ge\u00b7nen", "O\u00b7ze\u00b7an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "und soviel Geld! und Gl\u00fcck . . . und niemals Kummer . . .", "tokens": ["und", "so\u00b7viel", "Geld", "!", "und", "Gl\u00fcck", ".", ".", ".", "und", "nie\u00b7mals", "Kum\u00b7mer", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "$.", "KON", "NN", "$.", "$.", "$.", "KON", "ADV", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und eine Frau so s\u00fc\u00df wie Marzipan.", "tokens": ["und", "ei\u00b7ne", "Frau", "so", "s\u00fc\u00df", "wie", "Mar\u00b7zi\u00b7pan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADJD", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch manchmal, denk ich, nachts, wenn alles schweigt,", "tokens": ["Doch", "manch\u00b7mal", ",", "denk", "ich", ",", "nachts", ",", "wenn", "al\u00b7les", "schweigt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VVFIN", "PPER", "$,", "ADV", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "ob Ihnen da die Traurigkeit nicht einen geigt:", "tokens": ["ob", "Ih\u00b7nen", "da", "die", "Trau\u00b7rig\u00b7keit", "nicht", "ei\u00b7nen", "geigt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "PTKNEG", "ART", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u00bbja, immer Gl\u00fcck . . . das ist es eben . . .", "tokens": ["\u00bb", "ja", ",", "im\u00b7mer", "Gl\u00fcck", ".", ".", ".", "das", "ist", "es", "e\u00b7ben", ".", ".", "."], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "ADV", "NN", "$.", "$.", "$.", "PDS", "VAFIN", "PPER", "ADV", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den ganzen Tag?", "tokens": ["Den", "gan\u00b7zen", "Tag", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Das ganze Jahr?", "tokens": ["Das", "gan\u00b7ze", "Jahr", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Das ganze Leben \u2013?\u00ab", "tokens": ["Das", "gan\u00b7ze", "Le\u00b7ben", "\u2013", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Zum Beispiel Sie, Herr Ehemann, sind zu beneiden:", "tokens": ["Zum", "Bei\u00b7spiel", "Sie", ",", "Herr", "E\u00b7he\u00b7mann", ",", "sind", "zu", "be\u00b7nei\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "$,", "NN", "NN", "$,", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie haben eine Sch\u00f6nheitsk\u00f6nigin zur Frau.", "tokens": ["Sie", "ha\u00b7ben", "ei\u00b7ne", "Sch\u00f6n\u00b7heits\u00b7k\u00f6\u00b7ni\u00b7gin", "zur", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vor Ihnen darf die Venus aus der Wanne steigen . . .", "tokens": ["Vor", "Ih\u00b7nen", "darf", "die", "Ve\u00b7nus", "aus", "der", "Wan\u00b7ne", "stei\u00b7gen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPER", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "wir sehn ihr Bild \u2013 Sie kennen sie genau.", "tokens": ["wir", "sehn", "ihr", "Bild", "\u2013", "Sie", "ken\u00b7nen", "sie", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$(", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn so verteilt die Gaben das Geschick.", "tokens": ["Denn", "so", "ver\u00b7teilt", "die", "Ga\u00b7ben", "das", "Ge\u00b7schick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nach Jahren ist da was in Ihrem Blick . . .", "tokens": ["Nach", "Jah\u00b7ren", "ist", "da", "was", "in", "Ih\u00b7rem", "Blick", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "NN", "VAFIN", "ADV", "PWS", "APPR", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So summsen Fliegen, die am Sirup kleben . . .", "tokens": ["So", "summ\u00b7sen", "Flie\u00b7gen", ",", "die", "am", "Si\u00b7rup", "kle\u00b7ben", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Den ganzen Tag?", "tokens": ["Den", "gan\u00b7zen", "Tag", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Das ganze Jahr?", "tokens": ["Das", "gan\u00b7ze", "Jahr", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Das ganze Leben \u2013?", "tokens": ["Das", "gan\u00b7ze", "Le\u00b7ben", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Mensch, sei nicht neidisch!", "tokens": ["Mensch", ",", "sei", "nicht", "nei\u00b7disch", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Gl\u00fcck hat seinen Schimmer . . .", "tokens": ["Gl\u00fcck", "hat", "sei\u00b7nen", "Schim\u00b7mer", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stehst du im Tal, vergi\u00df nicht vor den H\u00f6hn:", "tokens": ["Stehst", "du", "im", "Tal", ",", "ver\u00b7gi\u00df", "nicht", "vor", "den", "H\u00f6hn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "VVIMP", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das, was man einmal tut, ist sch\u00f6n. Doch was man immer", "tokens": ["Das", ",", "was", "man", "ein\u00b7mal", "tut", ",", "ist", "sch\u00f6n", ".", "Doch", "was", "man", "im\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,", "VAFIN", "ADJD", "$.", "KON", "PWS", "PIS", "ADV"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}, "line.5": {"text": "zu tun gen\u00f6tigt ist, ist weniger sch\u00f6n.", "tokens": ["zu", "tun", "ge\u00b7n\u00f6\u00b7tigt", "ist", ",", "ist", "we\u00b7ni\u00b7ger", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVPP", "VAFIN", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Brathuhn ist gut. Was aber t\u00e4tst du tun,", "tokens": ["Bra\u00b7thuhn", "ist", "gut", ".", "Was", "a\u00b7ber", "t\u00e4tst", "du", "tun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "$.", "PWS", "ADV", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "gibt man dir jeden Tag gebratenes Huhn?", "tokens": ["gibt", "man", "dir", "je\u00b7den", "Tag", "ge\u00b7bra\u00b7te\u00b7nes", "Huhn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Na, siehst du. Sowas sch\u00e4tzt du auch daneben . . .", "tokens": ["Na", ",", "siehst", "du", ".", "So\u00b7was", "sch\u00e4tzt", "du", "auch", "da\u00b7ne\u00b7ben", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "$.", "PIS", "VVFIN", "PPER", "ADV", "PAV", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sei helle!", "tokens": ["Sei", "hel\u00b7le", "!"], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "ADJA", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Lebe du dein eigenes Leben.", "tokens": ["Le\u00b7be", "du", "dein", "ei\u00b7ge\u00b7nes", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}}}}}