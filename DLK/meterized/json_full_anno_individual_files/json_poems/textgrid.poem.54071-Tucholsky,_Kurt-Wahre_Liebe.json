{"textgrid.poem.54071": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Wahre Liebe", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn ich so m\u00fcd nach Hause komm,", "tokens": ["Wenn", "ich", "so", "m\u00fcd", "nach", "Hau\u00b7se", "komm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zerredet und zerschrieben:", "tokens": ["zer\u00b7re\u00b7det", "und", "zer\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "dann sitzt du da, so lieb und fromm.", "tokens": ["dann", "sitzt", "du", "da", ",", "so", "lieb", "und", "fromm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man mu\u00df, man mu\u00df dich lieben!", "tokens": ["Man", "mu\u00df", ",", "man", "mu\u00df", "dich", "lie\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,", "PIS", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Nacht gleich einem Feste ist.", "tokens": ["Die", "Nacht", "gleich", "ei\u00b7nem", "Fes\u00b7te", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich wei\u00df, da\u00df du die Beste bist.", "tokens": ["Ich", "wei\u00df", ",", "da\u00df", "du", "die", "Bes\u00b7te", "bist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und warum ist das? N\u00e4mlich:", "tokens": ["Und", "wa\u00b7rum", "ist", "das", "?", "N\u00e4m\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "PDS", "$.", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Du bist so himmlisch d\u00e4mlich.", "tokens": ["Du", "bist", "so", "himm\u00b7lisch", "d\u00e4m\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Du hast es gut.", "tokens": ["Du", "hast", "es", "gut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Du ahnst es nicht,", "tokens": ["Du", "ahnst", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "was Stalin j\u00fcngst gesprochen;", "tokens": ["was", "Sta\u00b7lin", "j\u00fcngst", "ge\u00b7spro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "wei\u00dft nichts vom leipziger Reichsgericht", "tokens": ["wei\u00dft", "nichts", "vom", "leip\u00b7zi\u00b7ger", "Reichs\u00b7ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPRART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "und nichts von Kunstepochen.", "tokens": ["und", "nichts", "von", "Kuns\u00b7te\u00b7po\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Du h\u00e4ltst einen Puff f\u00fcr ein Hotel", "tokens": ["Du", "h\u00e4ltst", "ei\u00b7nen", "Puff", "f\u00fcr", "ein", "Ho\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "und Bronnen f\u00fcr einen lauteren Quell . . .", "tokens": ["und", "Bron\u00b7nen", "f\u00fcr", "ei\u00b7nen", "lau\u00b7te\u00b7ren", "Quell", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "NN", "APPR", "ART", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ich liebe dich. Weil . . . n\u00e4mlich . . .", "tokens": ["Ich", "lie\u00b7be", "dich", ".", "Weil", ".", ".", ".", "n\u00e4m\u00b7lich", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "KOUS", "$.", "$.", "$.", "ADV", "$.", "$.", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Du bist so himmlisch d\u00e4mlich!", "tokens": ["Du", "bist", "so", "himm\u00b7lisch", "d\u00e4m\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Mein blondes Gl\u00fcck! Von Zeit zu Zeit", "tokens": ["Mein", "blon\u00b7des", "Gl\u00fcck", "!", "Von", "Zeit", "zu", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "tu ich ein bi\u00dfchen fremd gehn.", "tokens": ["tu", "ich", "ein", "bi\u00df\u00b7chen", "fremd", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "PIS", "ADJD", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Die andern Frauen sind so gescheit", "tokens": ["Die", "an\u00b7dern", "Frau\u00b7en", "sind", "so", "ge\u00b7scheit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und lassen das noch im Hemd sehn.", "tokens": ["und", "las\u00b7sen", "das", "noch", "im", "Hemd", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dann kehr ich reuig zu dir zur\u00fcck", "tokens": ["Dann", "kehr", "ich", "reu\u00b7ig", "zu", "dir", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "und genie\u00dfe tief atmend das reine Gl\u00fcck . . .", "tokens": ["und", "ge\u00b7nie\u00b7\u00dfe", "tief", "at\u00b7mend", "das", "rei\u00b7ne", "Gl\u00fcck", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJD", "VVPP", "ART", "ADJA", "NN", "$.", "$.", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Dumm liebt zweimal.", "tokens": ["Dumm", "liebt", "zwei\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.8": {"text": "N\u00e4mlich:", "tokens": ["N\u00e4m\u00b7lich", ":"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Du bist so himmlisch d\u00e4mlich \u2013!", "tokens": ["Du", "bist", "so", "himm\u00b7lisch", "d\u00e4m\u00b7lich", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wenn ich so m\u00fcd nach Hause komm,", "tokens": ["Wenn", "ich", "so", "m\u00fcd", "nach", "Hau\u00b7se", "komm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zerredet und zerschrieben:", "tokens": ["zer\u00b7re\u00b7det", "und", "zer\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "dann sitzt du da, so lieb und fromm.", "tokens": ["dann", "sitzt", "du", "da", ",", "so", "lieb", "und", "fromm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man mu\u00df, man mu\u00df dich lieben!", "tokens": ["Man", "mu\u00df", ",", "man", "mu\u00df", "dich", "lie\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,", "PIS", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Nacht gleich einem Feste ist.", "tokens": ["Die", "Nacht", "gleich", "ei\u00b7nem", "Fes\u00b7te", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich wei\u00df, da\u00df du die Beste bist.", "tokens": ["Ich", "wei\u00df", ",", "da\u00df", "du", "die", "Bes\u00b7te", "bist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und warum ist das? N\u00e4mlich:", "tokens": ["Und", "wa\u00b7rum", "ist", "das", "?", "N\u00e4m\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "PDS", "$.", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Du bist so himmlisch d\u00e4mlich.", "tokens": ["Du", "bist", "so", "himm\u00b7lisch", "d\u00e4m\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Du hast es gut.", "tokens": ["Du", "hast", "es", "gut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Du ahnst es nicht,", "tokens": ["Du", "ahnst", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "was Stalin j\u00fcngst gesprochen;", "tokens": ["was", "Sta\u00b7lin", "j\u00fcngst", "ge\u00b7spro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "wei\u00dft nichts vom leipziger Reichsgericht", "tokens": ["wei\u00dft", "nichts", "vom", "leip\u00b7zi\u00b7ger", "Reichs\u00b7ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPRART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "und nichts von Kunstepochen.", "tokens": ["und", "nichts", "von", "Kuns\u00b7te\u00b7po\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Du h\u00e4ltst einen Puff f\u00fcr ein Hotel", "tokens": ["Du", "h\u00e4ltst", "ei\u00b7nen", "Puff", "f\u00fcr", "ein", "Ho\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "und Bronnen f\u00fcr einen lauteren Quell . . .", "tokens": ["und", "Bron\u00b7nen", "f\u00fcr", "ei\u00b7nen", "lau\u00b7te\u00b7ren", "Quell", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "NN", "APPR", "ART", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ich liebe dich. Weil . . . n\u00e4mlich . . .", "tokens": ["Ich", "lie\u00b7be", "dich", ".", "Weil", ".", ".", ".", "n\u00e4m\u00b7lich", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "KOUS", "$.", "$.", "$.", "ADV", "$.", "$.", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Du bist so himmlisch d\u00e4mlich!", "tokens": ["Du", "bist", "so", "himm\u00b7lisch", "d\u00e4m\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Mein blondes Gl\u00fcck! Von Zeit zu Zeit", "tokens": ["Mein", "blon\u00b7des", "Gl\u00fcck", "!", "Von", "Zeit", "zu", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "tu ich ein bi\u00dfchen fremd gehn.", "tokens": ["tu", "ich", "ein", "bi\u00df\u00b7chen", "fremd", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "PIS", "ADJD", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Die andern Frauen sind so gescheit", "tokens": ["Die", "an\u00b7dern", "Frau\u00b7en", "sind", "so", "ge\u00b7scheit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und lassen das noch im Hemd sehn.", "tokens": ["und", "las\u00b7sen", "das", "noch", "im", "Hemd", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dann kehr ich reuig zu dir zur\u00fcck", "tokens": ["Dann", "kehr", "ich", "reu\u00b7ig", "zu", "dir", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "und genie\u00dfe tief atmend das reine Gl\u00fcck . . .", "tokens": ["und", "ge\u00b7nie\u00b7\u00dfe", "tief", "at\u00b7mend", "das", "rei\u00b7ne", "Gl\u00fcck", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJD", "VVPP", "ART", "ADJA", "NN", "$.", "$.", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Dumm liebt zweimal.", "tokens": ["Dumm", "liebt", "zwei\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.8": {"text": "N\u00e4mlich:", "tokens": ["N\u00e4m\u00b7lich", ":"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Du bist so himmlisch d\u00e4mlich \u2013!", "tokens": ["Du", "bist", "so", "himm\u00b7lisch", "d\u00e4m\u00b7lich", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}