{"textgrid.poem.57315": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Iduna Hensler gr\u00fcsset, mein Stollberg, dich,", "genre": "verse", "period": "N.A.", "pub_year": 1781, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Iduna Hensler gr\u00fcsset, mein Stollberg, dich,", "tokens": ["I\u00b7du\u00b7na", "Hens\u00b7ler", "gr\u00fcs\u00b7set", ",", "mein", "Stoll\u00b7berg", ",", "dich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PPER", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Und sagt dir leichthinspielendes Ganges, hoch", "tokens": ["Und", "sagt", "dir", "leich\u00b7thin\u00b7spie\u00b7len\u00b7des", "Gan\u00b7ges", ",", "hoch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJA", "NN", "$,", "ADJD"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Den Kopf, die M\u00e4hn' im Fluge: Dass sie,", "tokens": ["Den", "Kopf", ",", "die", "M\u00e4hn'", "im", "Flu\u00b7ge", ":", "Dass", "sie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$.", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey der entscheuchenden Kerze Schimmer,", "tokens": ["Bey", "der", "ent\u00b7scheu\u00b7chen\u00b7den", "Ker\u00b7ze", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "In diesem stets noch starrenden Winter, (Ach", "tokens": ["In", "die\u00b7sem", "stets", "noch", "star\u00b7ren\u00b7den", "Win\u00b7ter", ",", "(", "Ach"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["APPR", "PDAT", "ADV", "ADV", "ADJA", "NN", "$,", "$(", "ITJ"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zum erstenmale wagt' ich, die m\u00fcrrischen", "tokens": ["Zum", "ers\u00b7ten\u00b7ma\u00b7le", "wagt'", "ich", ",", "die", "m\u00fcr\u00b7ri\u00b7schen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "$,", "ART", "ADJA"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ostwinde meidend, nicht, der Eisbahn", "tokens": ["Ost\u00b7win\u00b7de", "mei\u00b7dend", ",", "nicht", ",", "der", "Eis\u00b7bahn"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "$,", "PTKNEG", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "T\u00f6nende Fl\u00fcgel mir anzulegen!)", "tokens": ["T\u00f6\u00b7nen\u00b7de", "Fl\u00fc\u00b7gel", "mir", "an\u00b7zu\u00b7le\u00b7gen", "!", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "PPER", "VVIZU", "$.", "$("], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Durch mich zum Aufsitz stehen gelernt; durch mich", "tokens": ["Durch", "mich", "zum", "Auf\u00b7sitz", "ste\u00b7hen", "ge\u00b7lernt", ";", "durch", "mich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "APPRART", "NN", "VVFIN", "VVPP", "$.", "APPR", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Gelernet kurzen Zephyrgalopp, verlernt,", "tokens": ["Ge\u00b7ler\u00b7net", "kur\u00b7zen", "Ze\u00b7phyr\u00b7ga\u00b7lopp", ",", "ver\u00b7lernt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch nicht zu sehr! den allzu frohen,", "tokens": ["Doch", "nicht", "zu", "sehr", "!", "den", "all\u00b7zu", "fro\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PTKA", "ADV", "$.", "ART", "PTKA", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Launigen Schwung in die L\u00e4ng' und Breite!", "tokens": ["Lau\u00b7ni\u00b7gen", "Schwung", "in", "die", "L\u00e4ng'", "und", "Brei\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Hat sie, von mir auch so durch den Fluss zu fliehn", "tokens": ["Hat", "sie", ",", "von", "mir", "auch", "so", "durch", "den", "Fluss", "zu", "fliehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "APPR", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Gelehrt, dass spritzend Wasser den Blick mir traf,", "tokens": ["Ge\u00b7lehrt", ",", "dass", "sprit\u00b7zend", "Was\u00b7ser", "den", "Blick", "mir", "traf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "ADJD", "NN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Von selbst nicht in dem See einst halbe", "tokens": ["Von", "selbst", "nicht", "in", "dem", "See", "einst", "hal\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PTKNEG", "APPR", "ART", "NN", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kreise gemacht, mit des Rehes Ansprung?", "tokens": ["Krei\u00b7se", "ge\u00b7macht", ",", "mit", "des", "Re\u00b7hes", "An\u00b7sprung", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Sie sagt dir ferner, wiehert es obenein:", "tokens": ["Sie", "sagt", "dir", "fer\u00b7ner", ",", "wie\u00b7hert", "es", "o\u00b7be\u00b7nein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mit goldner Buckel sey, dir zu Ehren! ihr", "tokens": ["Mit", "gold\u00b7ner", "Bu\u00b7ckel", "sey", ",", "dir", "zu", "Eh\u00b7ren", "!", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "$,", "PPER", "APPR", "NN", "$.", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Zaum geschm\u00fcckt. Was Buckel? sie sey", "tokens": ["Der", "Zaum", "ge\u00b7schm\u00fcckt", ".", "Was", "Bu\u00b7ckel", "?", "sie", "sey"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PWS", "NN", "$.", "PPER", "VAFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Sch\u00f6ner, als deine Olympione!", "tokens": ["Sch\u00f6\u00b7ner", ",", "als", "dei\u00b7ne", "O\u00b7lym\u00b7pi\u00b7o\u00b7ne", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "Das wirst du neiden, wenn ich im Lenze dir,", "tokens": ["Das", "wirst", "du", "nei\u00b7den", ",", "wenn", "ich", "im", "Len\u00b7ze", "dir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NN", "PPER", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und Bernstorff, nach dem langen Geharr im Busch,", "tokens": ["Und", "Bern\u00b7storff", ",", "nach", "dem", "lan\u00b7gen", "Ge\u00b7harr", "im", "Busch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "APPR", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So bald des Gleises W\u00f6lkchen herwallt,", "tokens": ["So", "bald", "des", "Glei\u00b7ses", "W\u00f6lk\u00b7chen", "her\u00b7wallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Schnell aus dem Schatten entgegen fliege.", "tokens": ["Schnell", "aus", "dem", "Schat\u00b7ten", "ent\u00b7ge\u00b7gen", "flie\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Iduna Hensler gr\u00fcsset, mein Stollberg, dich,", "tokens": ["I\u00b7du\u00b7na", "Hens\u00b7ler", "gr\u00fcs\u00b7set", ",", "mein", "Stoll\u00b7berg", ",", "dich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PPER", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Und sagt dir leichthinspielendes Ganges, hoch", "tokens": ["Und", "sagt", "dir", "leich\u00b7thin\u00b7spie\u00b7len\u00b7des", "Gan\u00b7ges", ",", "hoch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJA", "NN", "$,", "ADJD"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Den Kopf, die M\u00e4hn' im Fluge: Dass sie,", "tokens": ["Den", "Kopf", ",", "die", "M\u00e4hn'", "im", "Flu\u00b7ge", ":", "Dass", "sie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$.", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey der entscheuchenden Kerze Schimmer,", "tokens": ["Bey", "der", "ent\u00b7scheu\u00b7chen\u00b7den", "Ker\u00b7ze", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "In diesem stets noch starrenden Winter, (Ach", "tokens": ["In", "die\u00b7sem", "stets", "noch", "star\u00b7ren\u00b7den", "Win\u00b7ter", ",", "(", "Ach"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["APPR", "PDAT", "ADV", "ADV", "ADJA", "NN", "$,", "$(", "ITJ"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zum erstenmale wagt' ich, die m\u00fcrrischen", "tokens": ["Zum", "ers\u00b7ten\u00b7ma\u00b7le", "wagt'", "ich", ",", "die", "m\u00fcr\u00b7ri\u00b7schen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "$,", "ART", "ADJA"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ostwinde meidend, nicht, der Eisbahn", "tokens": ["Ost\u00b7win\u00b7de", "mei\u00b7dend", ",", "nicht", ",", "der", "Eis\u00b7bahn"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "$,", "PTKNEG", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "T\u00f6nende Fl\u00fcgel mir anzulegen!)", "tokens": ["T\u00f6\u00b7nen\u00b7de", "Fl\u00fc\u00b7gel", "mir", "an\u00b7zu\u00b7le\u00b7gen", "!", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "PPER", "VVIZU", "$.", "$("], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "Durch mich zum Aufsitz stehen gelernt; durch mich", "tokens": ["Durch", "mich", "zum", "Auf\u00b7sitz", "ste\u00b7hen", "ge\u00b7lernt", ";", "durch", "mich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "APPRART", "NN", "VVFIN", "VVPP", "$.", "APPR", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Gelernet kurzen Zephyrgalopp, verlernt,", "tokens": ["Ge\u00b7ler\u00b7net", "kur\u00b7zen", "Ze\u00b7phyr\u00b7ga\u00b7lopp", ",", "ver\u00b7lernt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch nicht zu sehr! den allzu frohen,", "tokens": ["Doch", "nicht", "zu", "sehr", "!", "den", "all\u00b7zu", "fro\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PTKA", "ADV", "$.", "ART", "PTKA", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Launigen Schwung in die L\u00e4ng' und Breite!", "tokens": ["Lau\u00b7ni\u00b7gen", "Schwung", "in", "die", "L\u00e4ng'", "und", "Brei\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.10": {"line.1": {"text": "Hat sie, von mir auch so durch den Fluss zu fliehn", "tokens": ["Hat", "sie", ",", "von", "mir", "auch", "so", "durch", "den", "Fluss", "zu", "fliehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "APPR", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Gelehrt, dass spritzend Wasser den Blick mir traf,", "tokens": ["Ge\u00b7lehrt", ",", "dass", "sprit\u00b7zend", "Was\u00b7ser", "den", "Blick", "mir", "traf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "ADJD", "NN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Von selbst nicht in dem See einst halbe", "tokens": ["Von", "selbst", "nicht", "in", "dem", "See", "einst", "hal\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PTKNEG", "APPR", "ART", "NN", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kreise gemacht, mit des Rehes Ansprung?", "tokens": ["Krei\u00b7se", "ge\u00b7macht", ",", "mit", "des", "Re\u00b7hes", "An\u00b7sprung", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.11": {"line.1": {"text": "Sie sagt dir ferner, wiehert es obenein:", "tokens": ["Sie", "sagt", "dir", "fer\u00b7ner", ",", "wie\u00b7hert", "es", "o\u00b7be\u00b7nein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mit goldner Buckel sey, dir zu Ehren! ihr", "tokens": ["Mit", "gold\u00b7ner", "Bu\u00b7ckel", "sey", ",", "dir", "zu", "Eh\u00b7ren", "!", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "$,", "PPER", "APPR", "NN", "$.", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Zaum geschm\u00fcckt. Was Buckel? sie sey", "tokens": ["Der", "Zaum", "ge\u00b7schm\u00fcckt", ".", "Was", "Bu\u00b7ckel", "?", "sie", "sey"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PWS", "NN", "$.", "PPER", "VAFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Sch\u00f6ner, als deine Olympione!", "tokens": ["Sch\u00f6\u00b7ner", ",", "als", "dei\u00b7ne", "O\u00b7lym\u00b7pi\u00b7o\u00b7ne", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.12": {"line.1": {"text": "Das wirst du neiden, wenn ich im Lenze dir,", "tokens": ["Das", "wirst", "du", "nei\u00b7den", ",", "wenn", "ich", "im", "Len\u00b7ze", "dir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NN", "PPER", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und Bernstorff, nach dem langen Geharr im Busch,", "tokens": ["Und", "Bern\u00b7storff", ",", "nach", "dem", "lan\u00b7gen", "Ge\u00b7harr", "im", "Busch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "APPR", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So bald des Gleises W\u00f6lkchen herwallt,", "tokens": ["So", "bald", "des", "Glei\u00b7ses", "W\u00f6lk\u00b7chen", "her\u00b7wallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Schnell aus dem Schatten entgegen fliege.", "tokens": ["Schnell", "aus", "dem", "Schat\u00b7ten", "ent\u00b7ge\u00b7gen", "flie\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}}}}