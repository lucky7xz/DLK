{"textgrid.poem.52822": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich habe oft in Beck's Naturgeschichte", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe oft in Beck's Naturgeschichte", "tokens": ["Ich", "ha\u00b7be", "oft", "in", "Beck's", "Na\u00b7tur\u00b7ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gelesen von des L\u00f6wenthieres Art,", "tokens": ["Ge\u00b7le\u00b7sen", "von", "des", "L\u00f6\u00b7wen\u00b7thie\u00b7res", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich habe oft in Pfeffel's Sinngedichte", "tokens": ["Ich", "ha\u00b7be", "oft", "in", "Pfef\u00b7fel's", "Sinn\u00b7ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bewundert seine Geistesgegenwart,", "tokens": ["Be\u00b7wun\u00b7dert", "sei\u00b7ne", "Geis\u00b7tes\u00b7ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nicht minder seine Gro\u00dfmuth, seine M\u00e4hnen,", "tokens": ["Nicht", "min\u00b7der", "sei\u00b7ne", "Gro\u00df\u00b7muth", ",", "sei\u00b7ne", "M\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Selbst seines Br\u00fcllens wirkungsreiches Dr\u00f6hnen.", "tokens": ["Selbst", "sei\u00b7nes", "Br\u00fcl\u00b7lens", "wir\u00b7kungs\u00b7rei\u00b7ches", "Dr\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "In solchem Bilde tritt mir vor die Seele", "tokens": ["In", "sol\u00b7chem", "Bil\u00b7de", "tritt", "mir", "vor", "die", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dein Geist, o C\u00e4sar, Mann der schnellen That,", "tokens": ["Dein", "Geist", ",", "o", "C\u00e4\u00b7sar", ",", "Mann", "der", "schnel\u00b7len", "That", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "FM", "NE", "$,", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein L\u00f6we bist du, welcher an der Kehle", "tokens": ["Ein", "L\u00f6\u00b7we", "bist", "du", ",", "wel\u00b7cher", "an", "der", "Keh\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NE", "VAFIN", "PPER", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das schlimme Messer der Beschr\u00e4nktheit hat,", "tokens": ["Das", "schlim\u00b7me", "Mes\u00b7ser", "der", "Be\u00b7schr\u00e4nk\u00b7theit", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn Brutus sowie Cassius, engverschworen,", "tokens": ["Denn", "Bru\u00b7tus", "so\u00b7wie", "Cas\u00b7sius", ",", "eng\u00b7ver\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NE", "KON", "NE", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So hoch ich sonst sie sch\u00e4tze, waren Thoren.", "tokens": ["So", "hoch", "ich", "sonst", "sie", "sch\u00e4t\u00b7ze", ",", "wa\u00b7ren", "Tho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich frage Jeden, der sich nur ein wenig", "tokens": ["Ich", "fra\u00b7ge", "Je\u00b7den", ",", "der", "sich", "nur", "ein", "we\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "$,", "PRELS", "PRF", "ADV", "ART", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Leben umgeschaut, der je gewirkt", "tokens": ["Im", "Le\u00b7ben", "um\u00b7ge\u00b7schaut", ",", "der", "je", "ge\u00b7wirkt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$,", "PRELS", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fcr die Verfassung, ohne seinem K\u00f6nig", "tokens": ["F\u00fcr", "die", "Ver\u00b7fas\u00b7sung", ",", "oh\u00b7ne", "sei\u00b7nem", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KOUI", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu nah' zu treten, der nicht ganz vert\u00fcrkt,", "tokens": ["Zu", "nah'", "zu", "tre\u00b7ten", ",", "der", "nicht", "ganz", "ver\u00b7t\u00fcrkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "PTKZU", "VVINF", "$,", "PRELS", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich frage ihn, ob nicht die Leidenschaften", "tokens": ["Ich", "fra\u00b7ge", "ihn", ",", "ob", "nicht", "die", "Lei\u00b7den\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Des P\u00f6bels ihm sein Ideal entrafften?", "tokens": ["Des", "P\u00f6\u00b7bels", "ihm", "sein", "I\u00b7deal", "en\u00b7traff\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "So war's zu deiner Zeit in Rom, o C\u00e4sar,", "tokens": ["So", "wa\u00b7r's", "zu", "dei\u00b7ner", "Zeit", "in", "Rom", ",", "o", "C\u00e4\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "APPR", "NE", "$,", "FM", "NE", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Die Anarchie war schon zu weit gedieh'n;", "tokens": ["Die", "An\u00b7ar\u00b7chie", "war", "schon", "zu", "weit", "ge\u00b7dieh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist's da nicht besser, wenn ein Reichsverwesar,", "tokens": ["Ist's", "da", "nicht", "bes\u00b7ser", ",", "wenn", "ein", "Reichs\u00b7ver\u00b7we\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "ADJD", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Karren wei\u00df dem Unflath zu entzieh'n?", "tokens": ["Den", "Kar\u00b7ren", "wei\u00df", "dem", "Un\u00b7flath", "zu", "ent\u00b7zieh'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Besonders wenn mit L\u00f6wengeist und St\u00e4rke", "tokens": ["Be\u00b7son\u00b7ders", "wenn", "mit", "L\u00f6\u00b7wen\u00b7geist", "und", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Er Vorschub leistet dem erhab'nen Werke!", "tokens": ["Er", "Vor\u00b7schub", "leis\u00b7tet", "dem", "er\u00b7hab'\u00b7nen", "Wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Pompejus, Cato, Cicero und Solche,", "tokens": ["Pom\u00b7pe\u00b7jus", ",", "Ca\u00b7to", ",", "Ci\u00b7ce\u00b7ro", "und", "Sol\u00b7che", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der freien Staatsverfassung zugethan,", "tokens": ["Der", "frei\u00b7en", "Staats\u00b7ver\u00b7fas\u00b7sung", "zu\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Catilina einst und seine Strolche", "tokens": ["Die", "Ca\u00b7ti\u00b7li\u00b7na", "einst", "und", "sei\u00b7ne", "Strol\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "ADV", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schon angenagt mit gift'gem W\u00fchlerzahn,", "tokens": ["Schon", "an\u00b7ge\u00b7nagt", "mit", "gift'\u00b7gem", "W\u00fc\u00b7hler\u00b7zahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Hochgestirne waren jetzt erloschen,", "tokens": ["Die", "Hoch\u00b7ges\u00b7tir\u00b7ne", "wa\u00b7ren", "jetzt", "er\u00b7lo\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "War da nicht Alles leeres Stroh gedroschen?", "tokens": ["War", "da", "nicht", "Al\u00b7les", "lee\u00b7res", "Stroh", "ge\u00b7dro\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Wie mu\u00df der Denker sich noch heute gr\u00e4men,", "tokens": ["Wie", "mu\u00df", "der", "Den\u00b7ker", "sich", "noch", "heu\u00b7te", "gr\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn er f\u00fcr Menschenwohl empfindlich ist,", "tokens": ["Wenn", "er", "f\u00fcr", "Men\u00b7schen\u00b7wohl", "emp\u00b7find\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df du, o C\u00e4sar, g\u00f6ttlich von Benehmen,", "tokens": ["Da\u00df", "du", ",", "o", "C\u00e4\u00b7sar", ",", "g\u00f6tt\u00b7lich", "von", "Be\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "FM", "NE", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem Vorurtheile unterlegen bist;", "tokens": ["Dem", "Vor\u00b7urt\u00b7hei\u00b7le", "un\u00b7ter\u00b7le\u00b7gen", "bist", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Schon kr\u00e4chzen rings des Knechtsinns feile M\u00f6wen,", "tokens": ["Schon", "kr\u00e4ch\u00b7zen", "rings", "des", "Knech\u00b7tsinns", "fei\u00b7le", "M\u00f6\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und die dir folgten, waren keine L\u00f6wen!", "tokens": ["Und", "die", "dir", "folg\u00b7ten", ",", "wa\u00b7ren", "kei\u00b7ne", "L\u00f6\u00b7wen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVFIN", "$,", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Entschuldiget, des C\u00e4sars gro\u00dfe Manen,", "tokens": ["Ent\u00b7schul\u00b7di\u00b7get", ",", "des", "C\u00e4\u00b7sars", "gro\u00b7\u00dfe", "Ma\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich so frei war, Euch dies Lied zu weih'n.", "tokens": ["Da\u00df", "ich", "so", "frei", "war", ",", "Euch", "dies", "Lied", "zu", "weih'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "PPER", "PDS", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein schlichter B\u00fcrger, dessen schlichte Ahnen", "tokens": ["Ein", "schlich\u00b7ter", "B\u00fcr\u00b7ger", ",", "des\u00b7sen", "schlich\u00b7te", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In Weltgeschichte nie sich mischten ein \u2013", "tokens": ["In", "Welt\u00b7ge\u00b7schich\u00b7te", "nie", "sich", "mischten", "ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PRF", "VVFIN", "ART", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Doch konnt' ich nicht umhin, euch anzusingen,", "tokens": ["Doch", "konnt'", "ich", "nicht", "um\u00b7hin", ",", "euch", "an\u00b7zu\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In einer Zeit voll Schw\u00e4ch- und Finsterlingen!", "tokens": ["In", "ei\u00b7ner", "Zeit", "voll", "Schw\u00e4ch", "und", "Fins\u00b7ter\u00b7lin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ich habe oft in Beck's Naturgeschichte", "tokens": ["Ich", "ha\u00b7be", "oft", "in", "Beck's", "Na\u00b7tur\u00b7ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gelesen von des L\u00f6wenthieres Art,", "tokens": ["Ge\u00b7le\u00b7sen", "von", "des", "L\u00f6\u00b7wen\u00b7thie\u00b7res", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich habe oft in Pfeffel's Sinngedichte", "tokens": ["Ich", "ha\u00b7be", "oft", "in", "Pfef\u00b7fel's", "Sinn\u00b7ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bewundert seine Geistesgegenwart,", "tokens": ["Be\u00b7wun\u00b7dert", "sei\u00b7ne", "Geis\u00b7tes\u00b7ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nicht minder seine Gro\u00dfmuth, seine M\u00e4hnen,", "tokens": ["Nicht", "min\u00b7der", "sei\u00b7ne", "Gro\u00df\u00b7muth", ",", "sei\u00b7ne", "M\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Selbst seines Br\u00fcllens wirkungsreiches Dr\u00f6hnen.", "tokens": ["Selbst", "sei\u00b7nes", "Br\u00fcl\u00b7lens", "wir\u00b7kungs\u00b7rei\u00b7ches", "Dr\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "In solchem Bilde tritt mir vor die Seele", "tokens": ["In", "sol\u00b7chem", "Bil\u00b7de", "tritt", "mir", "vor", "die", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dein Geist, o C\u00e4sar, Mann der schnellen That,", "tokens": ["Dein", "Geist", ",", "o", "C\u00e4\u00b7sar", ",", "Mann", "der", "schnel\u00b7len", "That", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "FM", "NE", "$,", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein L\u00f6we bist du, welcher an der Kehle", "tokens": ["Ein", "L\u00f6\u00b7we", "bist", "du", ",", "wel\u00b7cher", "an", "der", "Keh\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NE", "VAFIN", "PPER", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das schlimme Messer der Beschr\u00e4nktheit hat,", "tokens": ["Das", "schlim\u00b7me", "Mes\u00b7ser", "der", "Be\u00b7schr\u00e4nk\u00b7theit", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn Brutus sowie Cassius, engverschworen,", "tokens": ["Denn", "Bru\u00b7tus", "so\u00b7wie", "Cas\u00b7sius", ",", "eng\u00b7ver\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NE", "KON", "NE", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So hoch ich sonst sie sch\u00e4tze, waren Thoren.", "tokens": ["So", "hoch", "ich", "sonst", "sie", "sch\u00e4t\u00b7ze", ",", "wa\u00b7ren", "Tho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Ich frage Jeden, der sich nur ein wenig", "tokens": ["Ich", "fra\u00b7ge", "Je\u00b7den", ",", "der", "sich", "nur", "ein", "we\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "$,", "PRELS", "PRF", "ADV", "ART", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Leben umgeschaut, der je gewirkt", "tokens": ["Im", "Le\u00b7ben", "um\u00b7ge\u00b7schaut", ",", "der", "je", "ge\u00b7wirkt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$,", "PRELS", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fcr die Verfassung, ohne seinem K\u00f6nig", "tokens": ["F\u00fcr", "die", "Ver\u00b7fas\u00b7sung", ",", "oh\u00b7ne", "sei\u00b7nem", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KOUI", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu nah' zu treten, der nicht ganz vert\u00fcrkt,", "tokens": ["Zu", "nah'", "zu", "tre\u00b7ten", ",", "der", "nicht", "ganz", "ver\u00b7t\u00fcrkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "PTKZU", "VVINF", "$,", "PRELS", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich frage ihn, ob nicht die Leidenschaften", "tokens": ["Ich", "fra\u00b7ge", "ihn", ",", "ob", "nicht", "die", "Lei\u00b7den\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Des P\u00f6bels ihm sein Ideal entrafften?", "tokens": ["Des", "P\u00f6\u00b7bels", "ihm", "sein", "I\u00b7deal", "en\u00b7traff\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "So war's zu deiner Zeit in Rom, o C\u00e4sar,", "tokens": ["So", "wa\u00b7r's", "zu", "dei\u00b7ner", "Zeit", "in", "Rom", ",", "o", "C\u00e4\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "APPR", "NE", "$,", "FM", "NE", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Die Anarchie war schon zu weit gedieh'n;", "tokens": ["Die", "An\u00b7ar\u00b7chie", "war", "schon", "zu", "weit", "ge\u00b7dieh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist's da nicht besser, wenn ein Reichsverwesar,", "tokens": ["Ist's", "da", "nicht", "bes\u00b7ser", ",", "wenn", "ein", "Reichs\u00b7ver\u00b7we\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "ADJD", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Karren wei\u00df dem Unflath zu entzieh'n?", "tokens": ["Den", "Kar\u00b7ren", "wei\u00df", "dem", "Un\u00b7flath", "zu", "ent\u00b7zieh'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Besonders wenn mit L\u00f6wengeist und St\u00e4rke", "tokens": ["Be\u00b7son\u00b7ders", "wenn", "mit", "L\u00f6\u00b7wen\u00b7geist", "und", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Er Vorschub leistet dem erhab'nen Werke!", "tokens": ["Er", "Vor\u00b7schub", "leis\u00b7tet", "dem", "er\u00b7hab'\u00b7nen", "Wer\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Pompejus, Cato, Cicero und Solche,", "tokens": ["Pom\u00b7pe\u00b7jus", ",", "Ca\u00b7to", ",", "Ci\u00b7ce\u00b7ro", "und", "Sol\u00b7che", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der freien Staatsverfassung zugethan,", "tokens": ["Der", "frei\u00b7en", "Staats\u00b7ver\u00b7fas\u00b7sung", "zu\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Catilina einst und seine Strolche", "tokens": ["Die", "Ca\u00b7ti\u00b7li\u00b7na", "einst", "und", "sei\u00b7ne", "Strol\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "ADV", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schon angenagt mit gift'gem W\u00fchlerzahn,", "tokens": ["Schon", "an\u00b7ge\u00b7nagt", "mit", "gift'\u00b7gem", "W\u00fc\u00b7hler\u00b7zahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Hochgestirne waren jetzt erloschen,", "tokens": ["Die", "Hoch\u00b7ges\u00b7tir\u00b7ne", "wa\u00b7ren", "jetzt", "er\u00b7lo\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "War da nicht Alles leeres Stroh gedroschen?", "tokens": ["War", "da", "nicht", "Al\u00b7les", "lee\u00b7res", "Stroh", "ge\u00b7dro\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Wie mu\u00df der Denker sich noch heute gr\u00e4men,", "tokens": ["Wie", "mu\u00df", "der", "Den\u00b7ker", "sich", "noch", "heu\u00b7te", "gr\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn er f\u00fcr Menschenwohl empfindlich ist,", "tokens": ["Wenn", "er", "f\u00fcr", "Men\u00b7schen\u00b7wohl", "emp\u00b7find\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df du, o C\u00e4sar, g\u00f6ttlich von Benehmen,", "tokens": ["Da\u00df", "du", ",", "o", "C\u00e4\u00b7sar", ",", "g\u00f6tt\u00b7lich", "von", "Be\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "FM", "NE", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem Vorurtheile unterlegen bist;", "tokens": ["Dem", "Vor\u00b7urt\u00b7hei\u00b7le", "un\u00b7ter\u00b7le\u00b7gen", "bist", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Schon kr\u00e4chzen rings des Knechtsinns feile M\u00f6wen,", "tokens": ["Schon", "kr\u00e4ch\u00b7zen", "rings", "des", "Knech\u00b7tsinns", "fei\u00b7le", "M\u00f6\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und die dir folgten, waren keine L\u00f6wen!", "tokens": ["Und", "die", "dir", "folg\u00b7ten", ",", "wa\u00b7ren", "kei\u00b7ne", "L\u00f6\u00b7wen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVFIN", "$,", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Entschuldiget, des C\u00e4sars gro\u00dfe Manen,", "tokens": ["Ent\u00b7schul\u00b7di\u00b7get", ",", "des", "C\u00e4\u00b7sars", "gro\u00b7\u00dfe", "Ma\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich so frei war, Euch dies Lied zu weih'n.", "tokens": ["Da\u00df", "ich", "so", "frei", "war", ",", "Euch", "dies", "Lied", "zu", "weih'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "PPER", "PDS", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein schlichter B\u00fcrger, dessen schlichte Ahnen", "tokens": ["Ein", "schlich\u00b7ter", "B\u00fcr\u00b7ger", ",", "des\u00b7sen", "schlich\u00b7te", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In Weltgeschichte nie sich mischten ein \u2013", "tokens": ["In", "Welt\u00b7ge\u00b7schich\u00b7te", "nie", "sich", "mischten", "ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PRF", "VVFIN", "ART", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Doch konnt' ich nicht umhin, euch anzusingen,", "tokens": ["Doch", "konnt'", "ich", "nicht", "um\u00b7hin", ",", "euch", "an\u00b7zu\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In einer Zeit voll Schw\u00e4ch- und Finsterlingen!", "tokens": ["In", "ei\u00b7ner", "Zeit", "voll", "Schw\u00e4ch", "und", "Fins\u00b7ter\u00b7lin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}