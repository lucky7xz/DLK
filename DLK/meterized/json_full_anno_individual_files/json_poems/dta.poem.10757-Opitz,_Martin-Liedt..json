{"dta.poem.10757": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Liedt.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Mein feines Lieb ist fern von mir/", "tokens": ["Mein", "fei\u00b7nes", "Lieb", "ist", "fern", "von", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hat mit jhr sehr kurtze frewdt/", "tokens": ["Ich", "hat", "mit", "jhr", "sehr", "kurt\u00b7ze", "frewdt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sehr kurtze frewdt hat ich mit jhr/", "tokens": ["Sehr", "kurt\u00b7ze", "frewdt", "hat", "ich", "mit", "jhr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "PPER", "APPR", "PPOSAT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das macht mir desto gr\u00f6sser leidt/", "tokens": ["Das", "macht", "mir", "des\u00b7to", "gr\u00f6s\u00b7ser", "leidt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Tag bring ich mit seusstzen zu/", "tokens": ["Mein", "Tag", "bring", "ich", "mit", "seusst\u00b7zen", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "VVINF", "PTKZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mitlauter Vnruh meine Ruh:", "tokens": ["Mit\u00b7lau\u00b7ter", "Vn\u00b7ruh", "mei\u00b7ne", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Hertz hat sie genommen mit/", "tokens": ["Mein", "Hertz", "hat", "sie", "ge\u00b7nom\u00b7men", "mit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Es halff kein Klag/ es halff kein Bitt.", "tokens": ["Es", "halff", "kein", "Klag", "/", "es", "halff", "kein", "Bitt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$(", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ihr seuftzen/ ach jhr seuftzen mein/", "tokens": ["Ihr", "seuft\u00b7zen", "/", "ach", "jhr", "seuft\u00b7zen", "mein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$(", "XY", "PPER", "VVFIN", "PPOSAT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die jhr so he\u00fcffig eilt von mir/", "tokens": ["Die", "jhr", "so", "he\u00b7\u00fcf\u00b7fig", "eilt", "von", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVFIN", "APPR", "PPER", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Fahrt hin zu meinem Liebelein/", "tokens": ["Fahrt", "hin", "zu", "mei\u00b7nem", "Lie\u00b7be\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fahrt hin/ vnd sagt der Edlen Zier/", "tokens": ["Fahrt", "hin", "/", "vnd", "sagt", "der", "Ed\u00b7len", "Zier", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$(", "KON", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df jhr getrewer Diener sich", "tokens": ["Da\u00df", "jhr", "ge\u00b7tre\u00b7wer", "Die\u00b7ner", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "NN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vmb sie bek\u00fcmmer inniglich/", "tokens": ["Vmb", "sie", "be\u00b7k\u00fcm\u00b7mer", "in\u00b7nig\u00b7lich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ohn vnderla\u00df insolchem schmertz", "tokens": ["Ohn", "vn\u00b7der\u00b7la\u00df", "in\u00b7sol\u00b7chem", "schmertz"], "token_info": ["word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gedencket an jhr Keusches Hertz.", "tokens": ["Ge\u00b7den\u00b7cket", "an", "jhr", "Keu\u00b7sches", "Hertz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Gleich wie ein Turtelteubelein/", "tokens": ["Gleich", "wie", "ein", "Tur\u00b7tel\u00b7teu\u00b7be\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sein Gesellen hat verlohrn;", "tokens": ["Das", "sein", "Ge\u00b7sel\u00b7len", "hat", "ver\u00b7lohrn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sitz ich trawrig vnd allein/", "tokens": ["So", "sitz", "ich", "traw\u00b7rig", "vnd", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJD", "KON", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das schwinde scheiden thut mir zorn/", "tokens": ["Das", "schwin\u00b7de", "schei\u00b7den", "thut", "mir", "zorn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VVFIN", "PPER", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach scheiden/ ach zum letzten mahl", "tokens": ["Ach", "schei\u00b7den", "/", "ach", "zum", "letz\u00b7ten", "mahl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "VVFIN", "$(", "XY", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da fing erst an die rechte Qual/", "tokens": ["Da", "fing", "erst", "an", "die", "rech\u00b7te", "Qual", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zum letzten mahl da sie fort ruckt/", "tokens": ["Zum", "letz\u00b7ten", "mahl", "da", "sie", "fort", "ruckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "KOUS", "PPER", "PTKVZ", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mein Hertz ich in jhr Lefftzen truckt.", "tokens": ["Mein", "Hertz", "ich", "in", "jhr", "Lefft\u00b7zen", "truckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich hab euch jwar so lang erwehrt/", "tokens": ["Ich", "hab", "euch", "jwar", "so", "lang", "er\u00b7wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df mich kein Jungfraw fangen solt/", "tokens": ["Da\u00df", "mich", "kein", "Jung\u00b7fraw", "fan\u00b7gen", "solt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun seh ich wohl/ euch ist beschert/", "tokens": ["Nun", "seh", "ich", "wohl", "/", "euch", "ist", "be\u00b7schert", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich euch muste werden holdt/", "tokens": ["Da\u00df", "ich", "euch", "mus\u00b7te", "wer\u00b7den", "holdt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VMFIN", "VAINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr ward die jenig/ jhr allein/", "tokens": ["Ihr", "ward", "die", "je\u00b7nig", "/", "jhr", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "$(", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr seyt es vnd jhr solt es sein/", "tokens": ["Ihr", "seyt", "es", "vnd", "jhr", "solt", "es", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "KON", "PPER", "VMFIN", "PPER", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die mich durch jhre lieblichkeit", "tokens": ["Die", "mich", "durch", "jhre", "lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Vnd Tugent also hat verleit.", "tokens": ["Vnd", "Tu\u00b7gent", "al\u00b7so", "hat", "ver\u00b7leit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach liebstes Lieb/ kehrt wieder vmb/", "tokens": ["Ach", "liebs\u00b7tes", "Lieb", "/", "kehrt", "wie\u00b7der", "vmb", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$(", "VVFIN", "ADV", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kehrt vmb/ ach liebstes Liebelein/", "tokens": ["Kehrt", "vmb", "/", "ach", "liebs\u00b7tes", "Lie\u00b7be\u00b7lein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "$(", "XY", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eh dann ich gantz vnd gar vmbkumb/", "tokens": ["Eh", "dann", "ich", "gantz", "vnd", "gar", "vmb\u00b7kumb", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPER", "ADV", "KON", "ADV", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd geb mir nur ein Zeichen klein/", "tokens": ["Vnd", "geb", "mir", "nur", "ein", "Zei\u00b7chen", "klein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kan es nit mit dem Leibe sein/", "tokens": ["Kan", "es", "nit", "mit", "dem", "Lei\u00b7be", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "VAINF", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "So last es doch ein Schreiben sein/", "tokens": ["So", "last", "es", "doch", "ein", "Schrei\u00b7ben", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hab ich so vil genad bey euch/", "tokens": ["Hab", "ich", "so", "vil", "ge\u00b7nad", "bey", "euch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PIAT", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So frag ich nach keim K\u00f6nigreich.", "tokens": ["So", "frag", "ich", "nach", "keim", "K\u00f6\u00b7nig\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}