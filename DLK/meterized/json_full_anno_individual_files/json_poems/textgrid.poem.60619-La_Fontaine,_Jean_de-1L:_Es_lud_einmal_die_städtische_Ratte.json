{"textgrid.poem.60619": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es lud einmal die st\u00e4dtische Ratte", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es lud einmal die st\u00e4dtische Ratte", "tokens": ["Es", "lud", "ein\u00b7mal", "die", "st\u00e4d\u00b7ti\u00b7sche", "Rat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Ratte aus dem Felde ein", "tokens": ["Die", "Rat\u00b7te", "aus", "dem", "Fel\u00b7de", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu einem Braten, den sie hatte.", "tokens": ["Zu", "ei\u00b7nem", "Bra\u00b7ten", ",", "den", "sie", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fettammern waren's, zart und fein.", "tokens": ["Fet\u00b7tam\u00b7mern", "wa\u00b7ren's", ",", "zart", "und", "fein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Auf einem Perserteppich prangte", "tokens": ["Auf", "ei\u00b7nem", "Per\u00b7ser\u00b7tep\u00b7pich", "prang\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Tafel, \u00fcberreich gedeckt.", "tokens": ["Die", "Ta\u00b7fel", ",", "\u00fc\u00b7berr\u00b7eich", "ge\u00b7deckt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was ihren Appetit anlangte \u2013", "tokens": ["Was", "ih\u00b7ren", "Ap\u00b7pe\u00b7tit", "an\u00b7lang\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gewi\u00df hat's beiden wohlgeschmeckt.", "tokens": ["Ge\u00b7wi\u00df", "hat's", "bei\u00b7den", "wohl\u00b7ge\u00b7schmeckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein Festmahl war es, ohne Frage,", "tokens": ["Ein", "Fest\u00b7mahl", "war", "es", ",", "oh\u00b7ne", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nichts fehlte, was das Herz begehrt,", "tokens": ["Nichts", "fehl\u00b7te", ",", "was", "das", "Herz", "be\u00b7gehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch pl\u00f6tzlich wurde das Gelage", "tokens": ["Doch", "pl\u00f6tz\u00b7lich", "wur\u00b7de", "das", "Ge\u00b7la\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im besten Zuge j\u00e4h gest\u00f6rt.", "tokens": ["Im", "bes\u00b7ten", "Zu\u00b7ge", "j\u00e4h", "ge\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein L\u00e4rm von drau\u00dfen, welch ein Schrecken!", "tokens": ["Ein", "L\u00e4rm", "von", "drau\u00b7\u00dfen", ",", "welch", "ein", "Schre\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "$,", "PWAT", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es poltert an des Saales T\u00fcr.", "tokens": ["Es", "pol\u00b7tert", "an", "des", "Saa\u00b7les", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Stadtratte lief, sich zu verstecken,", "tokens": ["Stadt\u00b7rat\u00b7te", "lief", ",", "sich", "zu", "ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihre Freundin folgte ihr.", "tokens": ["Und", "ih\u00b7re", "Freun\u00b7din", "folg\u00b7te", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der L\u00e4rm erlosch. Als erste wagte", "tokens": ["Der", "L\u00e4rm", "er\u00b7losch", ".", "Als", "ers\u00b7te", "wag\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "$.", "KOUS", "ADJA", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich keck hervor die aus der Stadt,", "tokens": ["Sich", "keck", "her\u00b7vor", "die", "aus", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKVZ", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die tr\u00f6stlich zu der B\u00e4urin sagte:", "tokens": ["Die", "tr\u00f6st\u00b7lich", "zu", "der", "B\u00e4u\u00b7rin", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbkomm her und esse dich nun satt.\u00ab", "tokens": ["\u00bb", "komm", "her", "und", "es\u00b7se", "dich", "nun", "satt", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Da sprach die andre: \u00bbMeine Beste,", "tokens": ["Da", "sprach", "die", "and\u00b7re", ":", "\u00bb", "Mei\u00b7ne", "Bes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$.", "$(", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Komm morgen hin zu mir hinaus.", "tokens": ["Komm", "mor\u00b7gen", "hin", "zu", "mir", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Recht \u00fcppig zwar sind deine Feste,", "tokens": ["Recht", "\u00fcp\u00b7pig", "zwar", "sind", "dei\u00b7ne", "Fes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch sieh, ich mache mir nichts draus.", "tokens": ["Doch", "sieh", ",", "ich", "ma\u00b7che", "mir", "nichts", "draus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Bei mir wird alles glatt sich f\u00fcgen,", "tokens": ["Bei", "mir", "wird", "al\u00b7les", "glatt", "sich", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIS", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist einfach auch mein l\u00e4ndlich Brot.", "tokens": ["Ist", "ein\u00b7fach", "auch", "mein", "l\u00e4nd\u00b7lich", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Leb wohl!\u00ab \u2013 Wie arm ist ein Vergn\u00fcgen,", "tokens": ["Leb", "wohl", "!", "\u00ab", "\u2013", "Wie", "arm", "ist", "ein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "$(", "$(", "PWAV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das immer eine Angst bedroht!", "tokens": ["Das", "im\u00b7mer", "ei\u00b7ne", "Angst", "be\u00b7droht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es lud einmal die st\u00e4dtische Ratte", "tokens": ["Es", "lud", "ein\u00b7mal", "die", "st\u00e4d\u00b7ti\u00b7sche", "Rat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Ratte aus dem Felde ein", "tokens": ["Die", "Rat\u00b7te", "aus", "dem", "Fel\u00b7de", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu einem Braten, den sie hatte.", "tokens": ["Zu", "ei\u00b7nem", "Bra\u00b7ten", ",", "den", "sie", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fettammern waren's, zart und fein.", "tokens": ["Fet\u00b7tam\u00b7mern", "wa\u00b7ren's", ",", "zart", "und", "fein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Auf einem Perserteppich prangte", "tokens": ["Auf", "ei\u00b7nem", "Per\u00b7ser\u00b7tep\u00b7pich", "prang\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Tafel, \u00fcberreich gedeckt.", "tokens": ["Die", "Ta\u00b7fel", ",", "\u00fc\u00b7berr\u00b7eich", "ge\u00b7deckt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was ihren Appetit anlangte \u2013", "tokens": ["Was", "ih\u00b7ren", "Ap\u00b7pe\u00b7tit", "an\u00b7lang\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gewi\u00df hat's beiden wohlgeschmeckt.", "tokens": ["Ge\u00b7wi\u00df", "hat's", "bei\u00b7den", "wohl\u00b7ge\u00b7schmeckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ein Festmahl war es, ohne Frage,", "tokens": ["Ein", "Fest\u00b7mahl", "war", "es", ",", "oh\u00b7ne", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nichts fehlte, was das Herz begehrt,", "tokens": ["Nichts", "fehl\u00b7te", ",", "was", "das", "Herz", "be\u00b7gehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch pl\u00f6tzlich wurde das Gelage", "tokens": ["Doch", "pl\u00f6tz\u00b7lich", "wur\u00b7de", "das", "Ge\u00b7la\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im besten Zuge j\u00e4h gest\u00f6rt.", "tokens": ["Im", "bes\u00b7ten", "Zu\u00b7ge", "j\u00e4h", "ge\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ein L\u00e4rm von drau\u00dfen, welch ein Schrecken!", "tokens": ["Ein", "L\u00e4rm", "von", "drau\u00b7\u00dfen", ",", "welch", "ein", "Schre\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "$,", "PWAT", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es poltert an des Saales T\u00fcr.", "tokens": ["Es", "pol\u00b7tert", "an", "des", "Saa\u00b7les", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Stadtratte lief, sich zu verstecken,", "tokens": ["Stadt\u00b7rat\u00b7te", "lief", ",", "sich", "zu", "ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihre Freundin folgte ihr.", "tokens": ["Und", "ih\u00b7re", "Freun\u00b7din", "folg\u00b7te", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der L\u00e4rm erlosch. Als erste wagte", "tokens": ["Der", "L\u00e4rm", "er\u00b7losch", ".", "Als", "ers\u00b7te", "wag\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "$.", "KOUS", "ADJA", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich keck hervor die aus der Stadt,", "tokens": ["Sich", "keck", "her\u00b7vor", "die", "aus", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKVZ", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die tr\u00f6stlich zu der B\u00e4urin sagte:", "tokens": ["Die", "tr\u00f6st\u00b7lich", "zu", "der", "B\u00e4u\u00b7rin", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbkomm her und esse dich nun satt.\u00ab", "tokens": ["\u00bb", "komm", "her", "und", "es\u00b7se", "dich", "nun", "satt", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Da sprach die andre: \u00bbMeine Beste,", "tokens": ["Da", "sprach", "die", "and\u00b7re", ":", "\u00bb", "Mei\u00b7ne", "Bes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$.", "$(", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Komm morgen hin zu mir hinaus.", "tokens": ["Komm", "mor\u00b7gen", "hin", "zu", "mir", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Recht \u00fcppig zwar sind deine Feste,", "tokens": ["Recht", "\u00fcp\u00b7pig", "zwar", "sind", "dei\u00b7ne", "Fes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch sieh, ich mache mir nichts draus.", "tokens": ["Doch", "sieh", ",", "ich", "ma\u00b7che", "mir", "nichts", "draus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Bei mir wird alles glatt sich f\u00fcgen,", "tokens": ["Bei", "mir", "wird", "al\u00b7les", "glatt", "sich", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIS", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist einfach auch mein l\u00e4ndlich Brot.", "tokens": ["Ist", "ein\u00b7fach", "auch", "mein", "l\u00e4nd\u00b7lich", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Leb wohl!\u00ab \u2013 Wie arm ist ein Vergn\u00fcgen,", "tokens": ["Leb", "wohl", "!", "\u00ab", "\u2013", "Wie", "arm", "ist", "ein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "$(", "$(", "PWAV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das immer eine Angst bedroht!", "tokens": ["Das", "im\u00b7mer", "ei\u00b7ne", "Angst", "be\u00b7droht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}