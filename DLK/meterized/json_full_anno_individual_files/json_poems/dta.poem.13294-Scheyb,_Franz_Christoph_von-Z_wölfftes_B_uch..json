{"dta.poem.13294": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "Z w\u00f6lfftes  B uch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20535-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Alte ", "tokens": ["Der", "Al\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "150Und wies, da\u00df er sich Ehr und Ansehn geben kann,", "tokens": ["wies", ",", "da\u00df", "er", "sich", "Ehr", "und", "An\u00b7sehn", "ge\u00b7ben", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PRF", "NN", "KON", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Dann alles wurde still. Er, ohne zu verziehen", "tokens": ["Dann", "al\u00b7les", "wur\u00b7de", "still", ".", "Er", ",", "oh\u00b7ne", "zu", "ver\u00b7zie\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIS", "VAFIN", "ADJD", "$.", "PPER", "$,", "KOUI", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Fieng mit den Worten an: \u201eNun hat man uns verliehen,", "tokens": ["Fi\u00b7eng", "mit", "den", "Wor\u00b7ten", "an", ":", "\u201e", "Nun", "hat", "man", "uns", "ver\u00b7lie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$.", "$(", "ADV", "VAFIN", "PIS", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "\u201ewas keine von dem Krei\u00df sich eingebildet hat;", "tokens": ["\u201e", "was", "kei\u00b7ne", "von", "dem", "Krei\u00df", "sich", "ein\u00b7ge\u00b7bil\u00b7det", "hat", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PIAT", "APPR", "ART", "NN", "PRF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201edas ist: ", "tokens": ["\u201e", "das", "ist", ":"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "155\u201dBegl\u00fcckte Gegenwart! fast alles ward ermessen,", "tokens": ["\"", "Be\u00b7gl\u00fcck\u00b7te", "Ge\u00b7gen\u00b7wart", "!", "fast", "al\u00b7les", "ward", "er\u00b7mes\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$.", "ADV", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eso gar weswegen wir beysammen seynd gesessen.", "tokens": ["\u201e", "so", "gar", "wes\u00b7we\u00b7gen", "wir", "bey\u00b7sam\u00b7men", "seynd", "ge\u00b7ses\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "VVFIN", "PPER", "VVPP", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201ewas geben also wir noch mehr Erwegung Statt,", "tokens": ["\u201e", "was", "ge\u00b7ben", "al\u00b7so", "wir", "noch", "mehr", "Er\u00b7we\u00b7gung", "Statt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "PPER", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201eda sie den Tugend-Streit schon selbst entschieden hat?", "tokens": ["\u201e", "da", "sie", "den", "Tu\u00b7gen\u00b7dStreit", "schon", "selbst", "ent\u00b7schie\u00b7den", "hat", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201ejedoch damit wir uns mit einem Schlu\u00df vergn\u00fcgen,", "tokens": ["\u201e", "je\u00b7doch", "da\u00b7mit", "wir", "uns", "mit", "ei\u00b7nem", "Schlu\u00df", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "160\u201dSo fahr du, Wahrheit! fort; sprich! wem geb\u00fchrt zu siegen?", "tokens": ["\"", "So", "fahr", "du", ",", "Wahr\u00b7heit", "!", "fort", ";", "sprich", "!", "wem", "ge\u00b7b\u00fchrt", "zu", "sie\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "NN", "$.", "PTKVZ", "$.", "ADJD", "$.", "PWS", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}