{"dta.poem.20537": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "Drittes Buch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20536-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein Lispeln, welches sanfft durch alle Reihen", "tokens": ["Ein", "Lis\u00b7peln", ",", "wel\u00b7ches", "sanfft", "durch", "al\u00b7le", "Rei\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "schlich,", "tokens": ["schlich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Lie\u00df, als ob man sich schon um einen Schlu\u00df", "tokens": ["Lie\u00df", ",", "als", "ob", "man", "sich", "schon", "um", "ei\u00b7nen", "Schlu\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOKOM", "KOUS", "PIS", "PRF", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "verglich:", "tokens": ["ver\u00b7glich", ":"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Doch weil Gleichgiltigkeit aus vielen Augen blickte,", "tokens": ["Doch", "weil", "Gleich\u00b7gil\u00b7tig\u00b7keit", "aus", "vie\u00b7len", "Au\u00b7gen", "blick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So sah man, da\u00df der Prei\u00df des Rangs noch keiner gl\u00fcckte;", "tokens": ["So", "sah", "man", ",", "da\u00df", "der", "Prei\u00df", "des", "Rangs", "noch", "kei\u00b7ner", "gl\u00fcck\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KOUS", "ART", "NN", "ART", "NN", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Noch weniger da schon ein angenehmer Mund", "tokens": ["Noch", "we\u00b7ni\u00b7ger", "da", "schon", "ein", "an\u00b7ge\u00b7neh\u00b7mer", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Voll Herrlichkeit und Pracht, zu sprechen fertig stund.", "tokens": ["Voll", "Herr\u00b7lich\u00b7keit", "und", "Pracht", ",", "zu", "spre\u00b7chen", "fer\u00b7tig", "stund", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$,", "PTKZU", "VVINF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mehr als ein Meisterst\u00fcck erhabner, grosser Sinnen", "tokens": ["Mehr", "als", "ein", "Meis\u00b7ter\u00b7st\u00fcck", "er\u00b7hab\u00b7ner", ",", "gros\u00b7ser", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "KOKOM", "ART", "NN", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wies diese durch die Wei\u00df ihr Reden zu beginnen.", "tokens": ["Wies", "die\u00b7se", "durch", "die", "Wei\u00df", "ihr", "Re\u00b7den", "zu", "be\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "APPR", "ART", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eich suche weder Rang, noch Friese\u201e, fieng sie an,", "tokens": ["\u201e", "ich", "su\u00b7che", "we\u00b7der", "Rang", ",", "noch", "Frie\u00b7se", "\u201e", ",", "fi\u00b7eng", "sie", "an", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "KON", "NN", "$,", "ADV", "NN", "$(", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "10\u201dDas ist nicht, was mein Hertz in Regung bringen kann:", "tokens": ["\"", "Das", "ist", "nicht", ",", "was", "mein", "Hertz", "in", "Re\u00b7gung", "brin\u00b7gen", "kann", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PTKNEG", "$,", "PRELS", "PPOSAT", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201eich will auch eurem Amt die Ehre nicht versagen;", "tokens": ["\u201e", "ich", "will", "auch", "eu\u00b7rem", "Amt", "die", "Eh\u00b7re", "nicht", "ver\u00b7sa\u00b7gen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PPOSAT", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eich nehme mir nicht vor, dem Rath was vorzutragen,", "tokens": ["\u201e", "ich", "neh\u00b7me", "mir", "nicht", "vor", ",", "dem", "Rath", "was", "vor\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "ART", "NN", "PIS", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201edamit ich dieses Steins Besitz vor euch gewinn;", "tokens": ["\u201e", "da\u00b7mit", "ich", "die\u00b7ses", "Steins", "Be\u00b7sitz", "vor", "euch", "ge\u00b7winn", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PDAT", "NN", "NN", "APPR", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201enein: ich er\u00f6ffne nicht deswegen meinen Sinn.", "tokens": ["\u201e", "nein", ":", "ich", "er\u00b7\u00f6ff\u00b7ne", "nicht", "des\u00b7we\u00b7gen", "mei\u00b7nen", "Sinn", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$.", "PPER", "VVFIN", "PTKNEG", "PAV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Sie griff nach ihrem Schild, und wies ihn gantz erhoben:", "tokens": ["Sie", "griff", "nach", "ih\u00b7rem", "Schild", ",", "und", "wies", "ihn", "gantz", "er\u00b7ho\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eseht\u201e, fuhr sie fort, den Kopf, den L\u00f6wen-Kopf hieroben!", "tokens": ["\u201e", "seht", "\u201e", ",", "fuhr", "sie", "fort", ",", "den", "Kopf", ",", "den", "L\u00f6\u00b7wen\u00b7Kopf", "hier\u00b7o\u00b7ben", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$(", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eist etwas in der Welt, vor dem der L\u00f6w erschrickt?", "tokens": ["\u201e", "ist", "et\u00b7was", "in", "der", "Welt", ",", "vor", "dem", "der", "L\u00f6w", "er\u00b7schrickt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "APPR", "ART", "NN", "$,", "APPR", "ART", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(es war sein Ebenbild in diesem Schild gestickt)", "tokens": ["(", "es", "war", "sein", "E\u00b7ben\u00b7bild", "in", "die\u00b7sem", "Schild", "ge\u00b7stickt", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201esein Hertz ist mein Gem\u00fcth, es scheuet kein Bedrohen;", "tokens": ["\u201e", "sein", "Hertz", "ist", "mein", "Ge\u00b7m\u00fcth", ",", "es", "scheu\u00b7et", "kein", "Be\u00b7dro\u00b7hen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "20\u201dIch blieb in Waffen stehn, wo man den Feind geflohen.", "tokens": ["\"", "Ich", "blieb", "in", "Waf\u00b7fen", "stehn", ",", "wo", "man", "den", "Feind", "ge\u00b7flo\u00b7hen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "NN", "VVINF", "$,", "PWAV", "PIS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201edas ist des L\u00f6wens Geist: nichts hemmet seinen Muth;", "tokens": ["\u201e", "das", "ist", "des", "L\u00f6\u00b7wens", "Geist", ":", "nichts", "hem\u00b7met", "sei\u00b7nen", "Muth", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "NN", "$.", "PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eer ist sich allzeit gleich; er schl\u00e4ft nicht, wann er ruht;", "tokens": ["\u201e", "er", "ist", "sich", "all\u00b7zeit", "gleich", ";", "er", "schl\u00e4ft", "nicht", ",", "wann", "er", "ruht", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PRF", "ADV", "ADV", "$.", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201edringt gleich die Finsterni\u00df in dessen Augenlieder,", "tokens": ["\u201e", "dringt", "gleich", "die", "Fins\u00b7ter\u00b7ni\u00df", "in", "des\u00b7sen", "Au\u00b7gen\u00b7lie\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "APPR", "PRELAT", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "\u201eso wirfft er doch den Blitz des Blickes hin und wieder:", "tokens": ["\u201e", "so", "wirfft", "er", "doch", "den", "Blitz", "des", "Bli\u00b7ckes", "hin", "und", "wie\u00b7der", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "25\u201dEr ligt mit Wachtsamkeit; sein Auge schlie\u00dft sich nicht,", "tokens": ["\"", "Er", "ligt", "mit", "Wacht\u00b7sam\u00b7keit", ";", "sein", "Au\u00b7ge", "schlie\u00dft", "sich", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "NN", "$.", "PPOSAT", "NN", "VVFIN", "PRF", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201ees gibt ihm stets von dem, auf was es sieht, Bericht.", "tokens": ["\u201e", "es", "gibt", "ihm", "stets", "von", "dem", ",", "auf", "was", "es", "sieht", ",", "Be\u00b7richt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "\u201eso findt er auch im Schlaf die Mittel sich zu retten,", "tokens": ["\u201e", "so", "findt", "er", "auch", "im", "Schlaf", "die", "Mit\u00b7tel", "sich", "zu", "ret\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201emithin tr\u00e4gt er niemahls die Last der Schwermuths-Ketten.", "tokens": ["\u201e", "mi\u00b7thin", "tr\u00e4gt", "er", "nie\u00b7mahls", "die", "Last", "der", "Schwer\u00b7muths\u00b7Ket\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "\u201eer ist sich selbst zum Schutz, zur Brustwehr; auch allein", "tokens": ["\u201e", "er", "ist", "sich", "selbst", "zum", "Schutz", ",", "zur", "Brust\u00b7wehr", ";", "auch", "al\u00b7lein"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "PRF", "ADV", "APPRART", "NN", "$,", "APPRART", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "30\u201dWann ihn ein Feind umringt, kan er noch sicher seyn.", "tokens": ["\"", "Wann", "ihn", "ein", "Feind", "um\u00b7ringt", ",", "kan", "er", "noch", "si\u00b7cher", "seyn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "VVPP", "$,", "VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.17": {"text": "\u201ewill aber er den Streit, die Schlacht, das K\u00e4mpfen meiden;", "tokens": ["\u201e", "will", "a\u00b7ber", "er", "den", "Streit", ",", "die", "Schlacht", ",", "das", "K\u00e4mp\u00b7fen", "mei\u00b7den", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "ADV", "PPER", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201eso pflegt er nicht mit Furcht vom Waffen-Platz zu scheiden:", "tokens": ["\u201e", "so", "pflegt", "er", "nicht", "mit", "Furcht", "vom", "Waf\u00b7fen\u00b7Platz", "zu", "schei\u00b7den", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201eer rei\u00dft sich der Gefahr nicht niedertr\u00e4chtig lo\u00df;", "tokens": ["\u201e", "er", "rei\u00dft", "sich", "der", "Ge\u00b7fahr", "nicht", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "lo\u00df", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "ART", "NN", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "\u201esein Hertz ist viel zu starck; die Starckmuth viel zu gro\u00df;", "tokens": ["\u201e", "sein", "Hertz", "ist", "viel", "zu", "starck", ";", "die", "Starck\u00b7muth", "viel", "zu", "gro\u00df", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$.", "ART", "NN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "35\u201dDie Gro\u00dfmuth viel zu klug: er geht nur diese Weege;", "tokens": ["\"", "Die", "Gro\u00df\u00b7muth", "viel", "zu", "klug", ":", "er", "geht", "nur", "die\u00b7se", "Wee\u00b7ge", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "PTKA", "ADJD", "$.", "PPER", "VVFIN", "ADV", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "\u201enur diese machen ihn zum unternehmen rege.", "tokens": ["\u201e", "nur", "die\u00b7se", "ma\u00b7chen", "ihn", "zum", "un\u00b7ter\u00b7neh\u00b7men", "re\u00b7ge", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PDS", "VVFIN", "PPER", "APPRART", "ADJA", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "\u201eder Eigenschaften Werth ist der, so mich erhebt;", "tokens": ["\u201e", "der", "Ei\u00b7gen\u00b7schaf\u00b7ten", "Werth", "ist", "der", ",", "so", "mich", "er\u00b7hebt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "ART", "$,", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201edurch eines L\u00f6wens Hertz wird meine Brust belebt.", "tokens": ["\u201e", "durch", "ei\u00b7nes", "L\u00f6\u00b7wens", "Hertz", "wird", "mei\u00b7ne", "Brust", "be\u00b7lebt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ees hei\u00dft nicht Eigenlieb, aus was mein Ruhm entspringet;", "tokens": ["\u201e", "es", "hei\u00dft", "nicht", "Ei\u00b7gen\u00b7lieb", ",", "aus", "was", "mein", "Ruhm", "ent\u00b7sprin\u00b7get", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "NN", "$,", "APPR", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "40\u201dDie Gr\u00f6sse meines Geists ist, die mir Ehre bringet.", "tokens": ["\"", "Die", "Gr\u00f6s\u00b7se", "mei\u00b7nes", "Geists", "ist", ",", "die", "mir", "Eh\u00b7re", "brin\u00b7get", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "PPOSAT", "NN", "VAFIN", "$,", "PRELS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201emich qu\u00e4let kein Verdru\u00df, kein Eigensinn, kein Wahn;", "tokens": ["\u201e", "mich", "qu\u00e4\u00b7let", "kein", "Ver\u00b7dru\u00df", ",", "kein", "Ei\u00b7gen\u00b7sinn", ",", "kein", "Wahn", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201enichts ist, was meinem Muth die Gleichheit nehmen kann.", "tokens": ["\u201e", "nichts", "ist", ",", "was", "mei\u00b7nem", "Muth", "die", "Gleich\u00b7heit", "neh\u00b7men", "kann", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201espricht jemand von dem Lob Verwundrungs-werther Seelen,", "tokens": ["\u201e", "spricht", "je\u00b7mand", "von", "dem", "Lob", "Ver\u00b7wun\u00b7drungs\u00b7wer\u00b7ther", "See\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eso pflegt man ihnen mich, die ", "tokens": ["\u201e", "so", "pflegt", "man", "ih\u00b7nen", "mich", ",", "die"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["$(", "ADV", "VVFIN", "PIS", "PPER", "PPER", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "45\u201dWer in dem Gl\u00fccke Muth, in Widrigkeiten Gram;", "tokens": ["\"", "Wer", "in", "dem", "Gl\u00fc\u00b7cke", "Muth", ",", "in", "Wid\u00b7rig\u00b7kei\u00b7ten", "Gram", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "APPR", "ART", "NN", "NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ewer nach der Sachen Lauf, Zorn, Traurigkeit und Scham", "tokens": ["\u201e", "wer", "nach", "der", "Sa\u00b7chen", "Lauf", ",", "Zorn", ",", "Trau\u00b7rig\u00b7keit", "und", "Scham"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "PWS", "APPR", "ART", "NN", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.11": {"text": "\u201efreud", "tokens": ["\u201e", "freud"], "token_info": ["punct", "word"], "pos": ["$(", "VVFIN"], "meter": "+", "measure": "single.up"}, "line.12": {"text": "\u201edem ist kein grosser Geist, nur schwache Menschheit eigen:", "tokens": ["\u201e", "dem", "ist", "kein", "gros\u00b7ser", "Geist", ",", "nur", "schwa\u00b7che", "Menschheit", "ei\u00b7gen", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PIAT", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "\u201eder aber hier und dort der Sinnen Gleichheit weist;", "tokens": ["\u201e", "der", "a\u00b7ber", "hier", "und", "dort", "der", "Sin\u00b7nen", "Gleich\u00b7heit", "weist", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "ADV", "KON", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "50\u201dDesselben Brust belebt ein grosser Helden-Geist.", "tokens": ["\"", "Des\u00b7sel\u00b7ben", "Brust", "be\u00b7lebt", "ein", "gros\u00b7ser", "Hel\u00b7den\u00b7Geist", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201edergleichen Trefflichkeit ist, welche mich begeistert:", "tokens": ["\u201e", "derg\u00b7lei\u00b7chen", "Treff\u00b7lich\u00b7keit", "ist", ",", "wel\u00b7che", "mich", "be\u00b7geis\u00b7tert", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201eich habe Freund\u2019 und Feind\u2019, und mich dadurch bemeistert.", "tokens": ["\u201e", "ich", "ha\u00b7be", "Freund'", "und", "Feind'", ",", "und", "mich", "da\u00b7durch", "be\u00b7meis\u00b7tert", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "NN", "KON", "NN", "$,", "KON", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201ewas man vortrefflich, gro\u00df und edel nennt, ist mein;", "tokens": ["\u201e", "was", "man", "vor\u00b7treff\u00b7lich", ",", "gro\u00df", "und", "e\u00b7del", "nennt", ",", "ist", "mein", ";"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "PIS", "ADJD", "$,", "ADJD", "KON", "ADJD", "VVFIN", "$,", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201ewer kann von euch so viel, als ich, sein eigen seyn?", "tokens": ["\u201e", "wer", "kann", "von", "euch", "so", "viel", ",", "als", "ich", ",", "sein", "ei\u00b7gen", "seyn", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "APPR", "PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "$,", "PPOSAT", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "\u201ewie viele sehen sich in Pracht und Hoheit schimmern,", "tokens": ["\u201e", "wie", "vie\u00b7le", "se\u00b7hen", "sich", "in", "Pracht", "und", "Ho\u00b7heit", "schim\u00b7mern", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201edie Ruhm und Ehr, und Gl\u00fcck, und Wohl, und Heil verschlim\u0303ern?", "tokens": ["\u201e", "die", "Ruhm", "und", "Ehr", ",", "und", "Gl\u00fcck", ",", "und", "Wohl", ",", "und", "Heil", "ver\u00b7schlim\u0303ern", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "KON", "NN", "$,", "KON", "NN", "$,", "KON", "ADV", "$,", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eich kenne des Gem\u00fcths Begier und Selbst-Betrug,", "tokens": ["\u201e", "ich", "ken\u00b7ne", "des", "Ge\u00b7m\u00fcths", "Be\u00b7gier", "und", "Selbst\u00b7Be\u00b7trug", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eauch der Verwirrungen fast nie vermerckten Zug.", "tokens": ["\u201e", "auch", "der", "Ver\u00b7wir\u00b7run\u00b7gen", "fast", "nie", "ver\u00b7merck\u00b7ten", "Zug", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "+--++--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "\u201epracht, Schicksal, Wissenschaft, Freud, Ansehn, Ehr und G\u00fcter", "tokens": ["\u201e", "pracht", ",", "Schick\u00b7sal", ",", "Wis\u00b7sen\u00b7schaft", ",", "Freud", ",", "An\u00b7sehn", ",", "Ehr", "und", "G\u00fc\u00b7ter"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "60\u201dVerf\u00fchren durch den Werth und Unwerth die Gem\u00fcther:", "tokens": ["\"", "Ver\u00b7f\u00fch\u00b7ren", "durch", "den", "Werth", "und", "Un\u00b7werth", "die", "Ge\u00b7m\u00fc\u00b7ther", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "APPR", "ART", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201edie\u00df herrscht nicht \u00fcber mich; nichts ist, was mir besiehlt,", "tokens": ["\u201e", "die\u00df", "herrscht", "nicht", "\u00fc\u00b7ber", "mich", ";", "nichts", "ist", ",", "was", "mir", "be\u00b7siehlt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PTKNEG", "APPR", "PPER", "$.", "PIS", "VAFIN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eob es, wanns m\u00f6glich w\u00e4r, mich schon gefesselt hielt.", "tokens": ["\u201e", "ob", "es", ",", "wanns", "m\u00f6g\u00b7lich", "w\u00e4r", ",", "mich", "schon", "ge\u00b7fes\u00b7selt", "hielt", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "$,", "PWAV", "ADJD", "VAFIN", "$,", "PPER", "ADV", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201emich schw\u00e4chet keine Macht; Gewalt hat kein Geseze,", "tokens": ["\u201e", "mich", "schw\u00e4\u00b7chet", "kei\u00b7ne", "Macht", ";", "Ge\u00b7walt", "hat", "kein", "Ge\u00b7se\u00b7ze", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "$.", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201eso meines Sinns Bestand, und freyen Muth verleze.", "tokens": ["\u201e", "so", "mei\u00b7nes", "Sinns", "Be\u00b7stand", ",", "und", "frey\u00b7en", "Muth", "ver\u00b7le\u00b7ze", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPOSAT", "NN", "NN", "$,", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "65\u201dWann meiner Faust die Krafft, indem sie k\u00e4mpft, gebricht,", "tokens": ["\"", "Wann", "mei\u00b7ner", "Faust", "die", "Krafft", ",", "in\u00b7dem", "sie", "k\u00e4mpft", ",", "ge\u00b7bricht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PWAV", "PPOSAT", "NN", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eso fehlt doch meinem Geist der Schild der Gro\u00dfmuth nicht.", "tokens": ["\u201e", "so", "fehlt", "doch", "mei\u00b7nem", "Geist", "der", "Schild", "der", "Gro\u00df\u00b7muth", "nicht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADV", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201eje weniger ich mich von meinem Stand entferne,", "tokens": ["\u201e", "je", "we\u00b7ni\u00b7ger", "ich", "mich", "von", "mei\u00b7nem", "Stand", "ent\u00b7fer\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eje mehr ich den Gebrauch der falschen Ehre lerne.", "tokens": ["\u201e", "je", "mehr", "ich", "den", "Ge\u00b7brauch", "der", "fal\u00b7schen", "Eh\u00b7re", "ler\u00b7ne", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "PPER", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "\u201emit solchen W\u00fcrckungen hatt\u2019 ich den hohen Sinn", "tokens": ["\u201e", "mit", "sol\u00b7chen", "W\u00fcr\u00b7ckun\u00b7gen", "hatt'", "ich", "den", "ho\u00b7hen", "Sinn"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PIAT", "NN", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "70\u201dDie Herzens-Regungen der Grossen K\u00f6niginn", "tokens": ["\"", "Die", "Her\u00b7zens\u00b7Re\u00b7gun\u00b7gen", "der", "Gros\u00b7sen", "K\u00f6\u00b7ni\u00b7ginn"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "\u201ebegeistert und belebt; so wu\u00dft\u2019 ich ihr zum streiten", "tokens": ["\u201e", "be\u00b7geis\u00b7tert", "und", "be\u00b7lebt", ";", "so", "wu\u00dft'", "ich", "ihr", "zum", "strei\u00b7ten"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVPP", "KON", "VVPP", "$.", "ADV", "VVFIN", "PPER", "PPER", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eden Arm, das Herz, den Muth, die Waffen zu bereiten.", "tokens": ["\u201e", "den", "Arm", ",", "das", "Herz", ",", "den", "Muth", ",", "die", "Waf\u00b7fen", "zu", "be\u00b7rei\u00b7ten", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eso folgte Sieg auf Sieg; so th\u00f6nte Schlag auf Schlag,", "tokens": ["\u201e", "so", "folg\u00b7te", "Sieg", "auf", "Sieg", ";", "so", "th\u00f6n\u00b7te", "Schlag", "auf", "Schlag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "APPR", "NN", "$.", "ADV", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201evon welchem mehr der Feind, als ich erzehlen mag.", "tokens": ["\u201e", "von", "wel\u00b7chem", "mehr", "der", "Feind", ",", "als", "ich", "er\u00b7zeh\u00b7len", "mag."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "abbreviation"], "pos": ["$(", "APPR", "PRELS", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "75\u201dSo wu\u00dfte sie das Schwert zur Gegenwehr zu sch\u00e4rffen,", "tokens": ["\"", "So", "wu\u00df\u00b7te", "sie", "das", "Schwert", "zur", "Ge\u00b7gen\u00b7wehr", "zu", "sch\u00e4rf\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eso lehrt\u2019 ich sie zum Thron den Grund-Ri\u00df zu entwerffen.", "tokens": ["\u201e", "so", "lehrt'", "ich", "sie", "zum", "Thron", "den", "Grun\u00b7dRi\u00df", "zu", "ent\u00b7werf\u00b7fen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "\u201enun f\u00e4hrt sie gl\u00fccklich fort: was klein, veracht sie nicht,", "tokens": ["\u201e", "nun", "f\u00e4hrt", "sie", "gl\u00fcck\u00b7lich", "fort", ":", "was", "klein", ",", "ver\u00b7acht", "sie", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "PWS", "ADJD", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201edem Grossen stellt sie sich mit Gro\u00dfmuth vors Gesicht.", "tokens": ["\u201e", "dem", "Gros\u00b7sen", "stellt", "sie", "sich", "mit", "Gro\u00df\u00b7muth", "vors", "Ge\u00b7sicht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "PRF", "APPR", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ees sey die Macht des Gl\u00fccks gesezt, vermehrt, vermindert,", "tokens": ["\u201e", "es", "sey", "die", "Macht", "des", "Gl\u00fccks", "ge\u00b7sezt", ",", "ver\u00b7mehrt", ",", "ver\u00b7min\u00b7dert", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "80\u201dSo wird ihr Helden-Geist an keinem Werck verhindert.", "tokens": ["\"", "So", "wird", "ihr", "Hel\u00b7den\u00b7Geist", "an", "kei\u00b7nem", "Werck", "ver\u00b7hin\u00b7dert", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Geb\u00e4rden, Aug und Sprach erwiesen in der That", "tokens": ["Ge\u00b7b\u00e4r\u00b7den", ",", "Aug", "und", "Sprach", "er\u00b7wie\u00b7sen", "in", "der", "That"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df diese Rednerinn ein solches Amt vertrat,", "tokens": ["Da\u00df", "die\u00b7se", "Red\u00b7ne\u00b7rinn", "ein", "sol\u00b7ches", "Amt", "ver\u00b7trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wodurch ", "tokens": ["Wo\u00b7durch"], "token_info": ["word"], "pos": ["PWAV"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Und andrer Tugenden sich zu gebrauchen wisse.", "tokens": ["Und", "an\u00b7drer", "Tu\u00b7gen\u00b7den", "sich", "zu", "ge\u00b7brau\u00b7chen", "wis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PRF", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "\u201eich bin die F\u00fchrerin\u201e, so fuhr sie weiter fort,", "tokens": ["\u201e", "ich", "bin", "die", "F\u00fch\u00b7re\u00b7rin", "\u201e", ",", "so", "fuhr", "sie", "wei\u00b7ter", "fort", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$(", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eman findet ohne mich sie fast an keinem Ort.", "tokens": ["\u201e", "man", "fin\u00b7det", "oh\u00b7ne", "mich", "sie", "fast", "an", "kei\u00b7nem", "Ort", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "APPR", "PPER", "PPER", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eich lasse niemahls zu, da\u00df schwache Leidenschafften", "tokens": ["\u201e", "ich", "las\u00b7se", "nie\u00b7mahls", "zu", ",", "da\u00df", "schwa\u00b7che", "Lei\u00b7den\u00b7schaff\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ADV", "PTKVZ", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ean ihren Regungen, an ihrer Neigung hafften.", "tokens": ["\u201e", "an", "ih\u00b7ren", "Re\u00b7gun\u00b7gen", ",", "an", "ih\u00b7rer", "Nei\u00b7gung", "haff\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "\u201egeschicke, Rach und Ha\u00df, Gl\u00fcck, Freundschafft, Liebe, Neid,", "tokens": ["\u201e", "ge\u00b7schi\u00b7cke", ",", "Rach", "und", "Ha\u00df", ",", "Gl\u00fcck", ",", "Freund\u00b7schafft", ",", "Lie\u00b7be", ",", "Neid", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "90\u201dLust, Ungl\u00fcck, Zorn, Gefahr, Freud, Unfall, Ehre, Leid,", "tokens": ["\"", "Lust", ",", "Un\u00b7gl\u00fcck", ",", "Zorn", ",", "Ge\u00b7fahr", ",", "Freud", ",", "Un\u00b7fall", ",", "Eh\u00b7re", ",", "Leid", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eja was ein Menschen-Herz mag r\u00fchren und beklemmen,", "tokens": ["\u201e", "ja", "was", "ein", "Men\u00b7schen\u00b7Herz", "mag", "r\u00fch\u00b7ren", "und", "be\u00b7klem\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PWS", "ART", "NN", "VMFIN", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201ekan ihre Gleichheit nicht, nicht ihre Gro\u00dfmuth hemmen.", "tokens": ["\u201e", "kan", "ih\u00b7re", "Gleich\u00b7heit", "nicht", ",", "nicht", "ih\u00b7re", "Gro\u00df\u00b7muth", "hem\u00b7men", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPOSAT", "NN", "PTKNEG", "$,", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201ejhr Geist ist viel zu fest, da\u00df er sich biegen lie\u00df;", "tokens": ["\u201e", "jhr", "Geist", "ist", "viel", "zu", "fest", ",", "da\u00df", "er", "sich", "bie\u00b7gen", "lie\u00df", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$,", "KOUS", "PPER", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ezu starck, da\u00df die Gewalt ihn aus der Tugend ri\u00df.", "tokens": ["\u201e", "zu", "starck", ",", "da\u00df", "die", "Ge\u00b7walt", "ihn", "aus", "der", "Tu\u00b7gend", "ri\u00df", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKA", "ADJD", "$,", "KOUS", "ART", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "95\u201dEr\u00f6ffnet eine Flutt den Schwall, sie zu verschlingen,", "tokens": ["\"", "Er\u00b7\u00f6ff\u00b7net", "ei\u00b7ne", "Flutt", "den", "Schwall", ",", "sie", "zu", "ver\u00b7schlin\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ART", "NN", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eso wei\u00df sie sich beherzt aus der Gefahr zu schwingen.", "tokens": ["\u201e", "so", "wei\u00df", "sie", "sich", "be\u00b7herzt", "aus", "der", "Ge\u00b7fahr", "zu", "schwin\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PRF", "ADJD", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201ewas immer ich erw\u00e4hn\u2019, ist aller Welt bewu\u00dft;", "tokens": ["\u201e", "was", "im\u00b7mer", "ich", "er\u00b7w\u00e4hn'", ",", "ist", "al\u00b7ler", "Welt", "be\u00b7wu\u00dft", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eein Gro\u00dfmuths-volles Herz bewohnet ihre Brust.", "tokens": ["\u201e", "ein", "Gro\u00df\u00b7muths\u00b7vol\u00b7les", "Herz", "be\u00b7woh\u00b7net", "ih\u00b7re", "Brust", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ewer prangt mit solchem Ruhm? wer ist in diesen Reihen?", "tokens": ["\u201e", "wer", "prangt", "mit", "sol\u00b7chem", "Ruhm", "?", "wer", "ist", "in", "die\u00b7sen", "Rei\u00b7hen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "APPR", "PIAT", "NN", "$.", "PWS", "VAFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "100\u201dWer kan mit gleichem Sinn erz\u00fcrnen und verzeihen?", "tokens": ["\"", "Wer", "kan", "mit", "glei\u00b7chem", "Sinn", "er\u00b7z\u00fcr\u00b7nen", "und", "ver\u00b7zei\u00b7hen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201edie Rache ligt besiegt, wann sie den Feind erlegt;", "tokens": ["\u201e", "die", "Ra\u00b7che", "ligt", "be\u00b7siegt", ",", "wann", "sie", "den", "Feind", "er\u00b7legt", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "VVPP", "$,", "PWAV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201ejhr Herz wird durch den Sieg zu keinem Stolz erregt.", "tokens": ["\u201e", "jhr", "Herz", "wird", "durch", "den", "Sieg", "zu", "kei\u00b7nem", "Stolz", "er\u00b7regt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201edie Rechte f\u00fchren sie zum streiten bey den H\u00e4nden;", "tokens": ["\u201e", "die", "Rech\u00b7te", "f\u00fch\u00b7ren", "sie", "zum", "strei\u00b7ten", "bey", "den", "H\u00e4n\u00b7den", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "APPRART", "ADJA", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "\u201ewo Wuth und Rache sicht, pflegt sie den Fahn zu wenden.", "tokens": ["\u201e", "wo", "Wuth", "und", "Ra\u00b7che", "sicht", ",", "pflegt", "sie", "den", "Fahn", "zu", "wen\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "NN", "KON", "NN", "VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "105\u201dEs schreckt sie keine Macht, kein Bliz, kein Donner-Knall;", "tokens": ["\"", "Es", "schreckt", "sie", "kei\u00b7ne", "Macht", ",", "kein", "Bliz", ",", "kein", "Don\u00b7ner\u00b7Knall", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "\u201eder ihr geweihte Plaz bleibt ihr in jedem Fall.", "tokens": ["\u201e", "der", "ihr", "ge\u00b7weih\u00b7te", "Plaz", "bleibt", "ihr", "in", "je\u00b7dem", "Fall", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "\u201ejhr Thun und Lassen ist so lebhafft und begeistert,", "tokens": ["\u201e", "jhr", "Thun", "und", "Las\u00b7sen", "ist", "so", "leb\u00b7hafft", "und", "be\u00b7geis\u00b7tert", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "KON", "NN", "VAFIN", "ADV", "ADJD", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eda\u00df sie den Trieb des Geists, so viel sie will, bemeistert.", "tokens": ["\u201e", "da\u00df", "sie", "den", "Trieb", "des", "Geists", ",", "so", "viel", "sie", "will", ",", "be\u00b7meis\u00b7tert", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "ART", "NN", "$,", "ADV", "ADV", "PPER", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ejhr wi\u00dft, wie viel sie will? so viel nur, als sie kann;", "tokens": ["\u201e", "jhr", "wi\u00dft", ",", "wie", "viel", "sie", "will", "?", "so", "viel", "nur", ",", "als", "sie", "kann", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PWAV", "PIS", "PPER", "VMFIN", "$.", "ADV", "ADV", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "110\u201dSie f\u00e4ngt, wann sie nicht kann, niemahl zu wollen an:", "tokens": ["\"", "Sie", "f\u00e4ngt", ",", "wann", "sie", "nicht", "kann", ",", "nie\u00b7mahl", "zu", "wol\u00b7len", "an", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PWAV", "PPER", "PTKNEG", "VMFIN", "$,", "ADV", "PTKZU", "VMINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201edoch kann sie, was sie will: sie folget ihrem Willen,", "tokens": ["\u201e", "doch", "kann", "sie", ",", "was", "sie", "will", ":", "sie", "fol\u00b7get", "ih\u00b7rem", "Wil\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eweil er nichts anders will, als was geb\u00fchrt, erf\u00fcllen.", "tokens": ["\u201e", "weil", "er", "nichts", "an\u00b7ders", "will", ",", "als", "was", "ge\u00b7b\u00fchrt", ",", "er\u00b7f\u00fcl\u00b7len", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PIS", "ADV", "VMFIN", "$,", "KOUS", "PIS", "VVPP", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "\u201eerkennt ihr nun die Macht, die Tugend und die Krafft,", "tokens": ["\u201e", "er\u00b7kennt", "ihr", "nun", "die", "Macht", ",", "die", "Tu\u00b7gend", "und", "die", "Krafft", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201ewodurch ", "tokens": ["\u201e", "wo\u00b7durch"], "token_info": ["punct", "word"], "pos": ["$(", "PWAV"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "115\u201dDas ist, warum sie gro\u00df und m\u00e4chtig ward befunden,", "tokens": ["\"", "Das", "ist", ",", "wa\u00b7rum", "sie", "gro\u00df", "und", "m\u00e4ch\u00b7tig", "ward", "be\u00b7fun\u00b7den", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "$,", "PWAV", "PPER", "ADJD", "KON", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eals Zepter, Kron und Thron in den Gefahren stunden.", "tokens": ["\u201e", "als", "Zep\u00b7ter", ",", "Kron", "und", "Thron", "in", "den", "Ge\u00b7fah\u00b7ren", "stun\u00b7den", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "$,", "NN", "KON", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201edas ist, warum sie dort am allergr\u00f6sten war,", "tokens": ["\u201e", "das", "ist", ",", "wa\u00b7rum", "sie", "dort", "am", "al\u00b7ler\u00b7gr\u00f6s\u00b7ten", "war", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "$,", "PWAV", "PPER", "ADV", "APPRART", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eals ihrer Feinde Stolz das gr\u00f6ste Leid gebahr.", "tokens": ["\u201e", "als", "ih\u00b7rer", "Fein\u00b7de", "Stolz", "das", "gr\u00f6s\u00b7te", "Leid", "ge\u00b7bahr", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPOSAT", "NN", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201esagt! \u00fcbertraff sie nicht sich selbst an ihrer Gr\u00f6sse,", "tokens": ["\u201e", "sagt", "!", "\u00fc\u00b7bert\u00b7raff", "sie", "nicht", "sich", "selbst", "an", "ih\u00b7rer", "Gr\u00f6s\u00b7se", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "VVFIN", "PPER", "PTKNEG", "PRF", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "120\u201dDa sie sich unbewehrt, in Hilff- und Waffen-Bl\u00f6sse", "tokens": ["\"", "Da", "sie", "sich", "un\u00b7be\u00b7wehrt", ",", "in", "Hilff", "und", "Waf\u00b7fen\u00b7B\u00b7l\u00f6s\u00b7se"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "PRF", "ADJD", "$,", "APPR", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201edes Anfalls nicht entsezt; mit heiterm Auge sah,", "tokens": ["\u201e", "des", "An\u00b7falls", "nicht", "ent\u00b7sezt", ";", "mit", "hei\u00b7term", "Au\u00b7ge", "sah", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "PTKNEG", "VVPP", "$.", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ewas vor Gewalt dem Heil des Vaterlands geschah?", "tokens": ["\u201e", "was", "vor", "Ge\u00b7walt", "dem", "Heil", "des", "Va\u00b7ter\u00b7lands", "ge\u00b7schah", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "APPR", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201edie L\u00e4nder lagen zwar gefesselt und gebunden,", "tokens": ["\u201e", "die", "L\u00e4n\u00b7der", "la\u00b7gen", "zwar", "ge\u00b7fes\u00b7selt", "und", "ge\u00b7bun\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201enur ihr verla\u00dfnes Hertz verblieb un\u00fcberwunden.", "tokens": ["\u201e", "nur", "ihr", "ver\u00b7la\u00df\u00b7nes", "Hertz", "ver\u00b7blieb", "un\u00b7\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "125\u201dSo w\u00e4chst und gr\u00fcnt, und steigt, und bl\u00fcht die Aloe;", "tokens": ["\"", "So", "w\u00e4chst", "und", "gr\u00fcnt", ",", "und", "steigt", ",", "und", "bl\u00fcht", "die", "A\u00b7loe", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "KON", "VVFIN", "$,", "KON", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "\u201eso th\u00fcrmet sie den Schmuck der Blumen in die H\u00f6h;", "tokens": ["\u201e", "so", "th\u00fcr\u00b7met", "sie", "den", "Schmuck", "der", "Blu\u00b7men", "in", "die", "H\u00f6h", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201eje mehr die Bitterkeit und W\u00e4rme sie durchdringet,", "tokens": ["\u201e", "je", "mehr", "die", "Bit\u00b7ter\u00b7keit", "und", "W\u00e4r\u00b7me", "sie", "durch\u00b7drin\u00b7get", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.16": {"text": "\u201eje pr\u00e4chtiger sie sich aus ihren Stauden schwinget.", "tokens": ["\u201e", "je", "pr\u00e4ch\u00b7ti\u00b7ger", "sie", "sich", "aus", "ih\u00b7ren", "Stau\u00b7den", "schwin\u00b7get", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "\u201enun ist der Feinde Schwert und Wuth, und Stolz gez\u00e4hmt,", "tokens": ["\u201e", "nun", "ist", "der", "Fein\u00b7de", "Schwert", "und", "Wuth", ",", "und", "Stolz", "ge\u00b7z\u00e4hmt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "NE", "KON", "NN", "$,", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "130\u201dDa sie mit Sieg und Recht derselben Ruhm besch\u00e4mt.", "tokens": ["\"", "Da", "sie", "mit", "Sieg", "und", "Recht", "der\u00b7sel\u00b7ben", "Ruhm", "be\u00b7sch\u00e4mt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "APPR", "NN", "KON", "NN", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ewann jemand es der Welt, der Nachwelt soll beschreiben,", "tokens": ["\u201e", "wann", "je\u00b7mand", "es", "der", "Welt", ",", "der", "Nach\u00b7welt", "soll", "be\u00b7schrei\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "PPER", "ART", "NN", "$,", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ewurd es zur Folge nicht, zum Wunder nur verbleiben.", "tokens": ["\u201e", "wurd", "es", "zur", "Fol\u00b7ge", "nicht", ",", "zum", "Wun\u00b7der", "nur", "ver\u00b7blei\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "APPRART", "NN", "PTKNEG", "$,", "APPRART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201ejhr selber nennet sie der Helden Seltenheit;", "tokens": ["\u201e", "jhr", "sel\u00b7ber", "nen\u00b7net", "sie", "der", "Hel\u00b7den", "Sel\u00b7ten\u00b7heit", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "VVFIN", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eein wahres Meisterst\u00fcck der Unerschrockenheit:", "tokens": ["\u201e", "ein", "wah\u00b7res", "Meis\u00b7ter\u00b7st\u00fcck", "der", "Un\u00b7er\u00b7schro\u00b7cken\u00b7heit", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "135\u201dIch hab es selbst gesehn, als man sie wollt berauben,", "tokens": ["\"", "Ich", "hab", "es", "selbst", "ge\u00b7sehn", ",", "als", "man", "sie", "wollt", "be\u00b7rau\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,", "KOUS", "PIS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201ewie starck sie sich erwies, sonst wurd\u2019 ich es nicht glauben.", "tokens": ["\u201e", "wie", "starck", "sie", "sich", "er\u00b7wies", ",", "sonst", "wurd'", "ich", "es", "nicht", "glau\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "PPER", "PRF", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201eich lernte selbst von ihr der eignen Tugend Werth,", "tokens": ["\u201e", "ich", "lern\u00b7te", "selbst", "von", "ihr", "der", "eig\u00b7nen", "Tu\u00b7gend", "Werth", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201eund sahe, da\u00df der Feind an ihr denselben ehrt.", "tokens": ["\u201e", "und", "sa\u00b7he", ",", "da\u00df", "der", "Feind", "an", "ihr", "den\u00b7sel\u00b7ben", "ehrt", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "$,", "KOUS", "ART", "NN", "APPR", "PPER", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eich stunde selbst in Angst, und wu\u00dfte nichts zu hoffen,", "tokens": ["\u201e", "ich", "stun\u00b7de", "selbst", "in", "Angst", ",", "und", "wu\u00df\u00b7te", "nichts", "zu", "hof\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,", "KON", "VVFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "140\u201dMithin war ich von ihr an Gro\u00dfmuth \u00fcbertroffen.", "tokens": ["\"", "Mi\u00b7thin", "war", "ich", "von", "ihr", "an", "Gro\u00df\u00b7muth", "\u00fc\u00b7ber\u00b7trof\u00b7fen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "APPR", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "\u201eso hat sie mir, ich ihr, best\u00e4ndig nachgeschwebt,", "tokens": ["\u201e", "so", "hat", "sie", "mir", ",", "ich", "ihr", ",", "be\u00b7st\u00e4n\u00b7dig", "nach\u00b7ge\u00b7schwebt", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PPER", "$,", "PPER", "PPER", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eso ward ihr Geist von mir, mein Herz von ihr belebt.", "tokens": ["\u201e", "so", "ward", "ihr", "Geist", "von", "mir", ",", "mein", "Herz", "von", "ihr", "be\u00b7lebt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPOSAT", "NN", "APPR", "PPER", "$,", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ewas vor Abwechslungen und unverhoffte F\u00e4lle", "tokens": ["\u201e", "was", "vor", "Ab\u00b7wechs\u00b7lun\u00b7gen", "und", "un\u00b7ver\u00b7hoff\u00b7te", "F\u00e4l\u00b7le"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWS", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "\u201eseynd nicht des Wanckelmuths Grund, Ursach, Trieb und Quelle?", "tokens": ["\u201e", "seynd", "nicht", "des", "Wan\u00b7ckel\u00b7muths", "Grund", ",", "Ur\u00b7sach", ",", "Trieb", "und", "Quel\u00b7le", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PTKNEG", "ART", "NN", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "145\u201dBald schrecket die Gefahr; bald droht der Feinde Schwert:", "tokens": ["\"", "Bald", "schre\u00b7cket", "die", "Ge\u00b7fahr", ";", "bald", "droht", "der", "Fein\u00b7de", "Schwert", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201edort soll man tapfer seyn; hier Muth-voll und bewehrt.", "tokens": ["\u201e", "dort", "soll", "man", "tap\u00b7fer", "seyn", ";", "hier", "Muth\u00b7voll", "und", "be\u00b7wehrt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PIS", "ADJD", "VAINF", "$.", "ADV", "NN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201enicht alle Tugenden seynd jederzeit vonn\u00f6then;", "tokens": ["\u201e", "nicht", "al\u00b7le", "Tu\u00b7gen\u00b7den", "seynd", "je\u00b7der\u00b7zeit", "von\u00b7n\u00f6\u00b7then", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "PIAT", "NN", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201ebald diese jenes Amt, bald jene das vertreten.", "tokens": ["\u201e", "bald", "die\u00b7se", "je\u00b7nes", "Amt", ",", "bald", "je\u00b7ne", "das", "ver\u00b7tre\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PDAT", "PDAT", "NN", "$,", "ADV", "PDAT", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201emir aber ist Gefahr und Drohung einerley:", "tokens": ["\u201e", "mir", "a\u00b7ber", "ist", "Ge\u00b7fahr", "und", "Dro\u00b7hung", "ei\u00b7ner\u00b7ley", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "VAFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "150\u201dEins: ob ich in der Schlacht; in Staats-Gesch\u00e4fften sey.", "tokens": ["\"", "Eins", ":", "ob", "ich", "in", "der", "Schlacht", ";", "in", "Staats\u00b7Ge\u00b7sch\u00e4ff\u00b7ten", "sey", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$.", "KOUS", "PPER", "APPR", "ART", "NN", "$.", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eund sagt! was ist im Lauf der Zeiten vorgekommen,", "tokens": ["\u201e", "und", "sagt", "!", "was", "ist", "im", "Lauf", "der", "Zei\u00b7ten", "vor\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "$.", "PWS", "VAFIN", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201ewo nicht die Gro\u00dfmuth sich des Wercks hat angenommen?", "tokens": ["\u201e", "wo", "nicht", "die", "Gro\u00df\u00b7muth", "sich", "des", "Wercks", "hat", "an\u00b7ge\u00b7nom\u00b7men", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PTKNEG", "ART", "NN", "PRF", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "\u201eentschliesset, was ihr wollt, des Frieses Ehren-Stein", "tokens": ["\u201e", "ent\u00b7schlies\u00b7set", ",", "was", "ihr", "wollt", ",", "des", "Frie\u00b7ses", "Eh\u00b7ren\u00b7Stein"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "PWS", "PPER", "VMFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201ek\u00f6nnt nur durch meinen Prei\u00df und Nahmen pr\u00e4chtig seyn.", "tokens": ["\u201e", "k\u00f6nnt", "nur", "durch", "mei\u00b7nen", "Prei\u00df", "und", "Nah\u00b7men", "pr\u00e4ch\u00b7tig", "seyn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "155\u201dSo w\u00fc\u00dft ich nicht wer sonst denselben Platz bewohne,", "tokens": ["\"", "So", "w\u00fc\u00dft", "ich", "nicht", "wer", "sonst", "den\u00b7sel\u00b7ben", "Platz", "be\u00b7woh\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKNEG", "PWS", "ADV", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201edie Krone gibt dem Schmuck den Werth, nicht er der Krone?", "tokens": ["\u201e", "die", "Kro\u00b7ne", "gibt", "dem", "Schmuck", "den", "Werth", ",", "nicht", "er", "der", "Kro\u00b7ne", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$,", "PTKNEG", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Indem die Gro\u00dfmuth so von ihren Thaten sprach,", "tokens": ["In\u00b7dem", "die", "Gro\u00df\u00b7muth", "so", "von", "ih\u00b7ren", "Tha\u00b7ten", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gieng meine Wi\u00dfbegier fast allen Blicken nach;", "tokens": ["Gieng", "mei\u00b7ne", "Wi\u00df\u00b7be\u00b7gier", "fast", "al\u00b7len", "Bli\u00b7cken", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich wurde nimmer satt dieselben zu betrachten,", "tokens": ["Ich", "wur\u00b7de", "nim\u00b7mer", "satt", "die\u00b7sel\u00b7ben", "zu", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "160Weil sie mein Auge stets in mehr Erg\u00f6zung brachten.", "tokens": ["sie", "mein", "Au\u00b7ge", "stets", "in", "mehr", "Er\u00b7g\u00f6\u00b7zung", "brach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Die schwieg. Nun merckten wir, da\u00df seitw\u00e4rts eine Frau", "tokens": ["Die", "schwieg", ".", "Nun", "merck\u00b7ten", "wir", ",", "da\u00df", "seit\u00b7w\u00e4rts", "ei\u00b7ne", "Frau"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von reizender Gestalt auf ihre N\u00e4chste schau;", "tokens": ["Von", "rei\u00b7zen\u00b7der", "Ge\u00b7stalt", "auf", "ih\u00b7re", "N\u00e4chs\u00b7te", "schau", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie, wann sie Rath verlang, ob sie sich melden solte,", "tokens": ["Wie", ",", "wann", "sie", "Rath", "ver\u00b7lang", ",", "ob", "sie", "sich", "mel\u00b7den", "sol\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "PPER", "NN", "VVFIN", "$,", "KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sonst aber ihren Sinn noch nicht er\u00f6ffnen wolte.", "tokens": ["Sonst", "a\u00b7ber", "ih\u00b7ren", "Sinn", "noch", "nicht", "er\u00b7\u00f6ff\u00b7nen", "wol\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "165Ein freundliches Gesicht, in dessen Augen-Paar", "tokens": ["freund\u00b7li\u00b7ches", "Ge\u00b7sicht", ",", "in", "des\u00b7sen", "Au\u00b7gen\u00b7Paar"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "APPR", "PRELAT", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.10": {"text": "Fried, Unschuld, Sittsamkeit und Ruhe kenntlich war;", "tokens": ["Fried", ",", "Un\u00b7schuld", ",", "Sitt\u00b7sam\u00b7keit", "und", "Ru\u00b7he", "kennt\u00b7lich", "war", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Man las in ihrer Ernst- und Demuths-vollen Miene,", "tokens": ["Man", "las", "in", "ih\u00b7rer", "Ernst", "und", "De\u00b7muths\u00b7vol\u00b7len", "Mie\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPOSAT", "TRUNC", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df ihr in diesem Streit noch nichts erwiesen schiene.", "tokens": ["Da\u00df", "ihr", "in", "die\u00b7sem", "Streit", "noch", "nichts", "er\u00b7wie\u00b7sen", "schie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "ADV", "PIS", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sie trat zwar w\u00fcrcklich auf, doch redte sie noch nicht,", "tokens": ["Sie", "trat", "zwar", "w\u00fcrck\u00b7lich", "auf", ",", "doch", "red\u00b7te", "sie", "noch", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "170Ein angenehmes Roth durchbrach ihr Angesicht.", "tokens": ["an\u00b7ge\u00b7neh\u00b7mes", "Roth", "durch\u00b7brach", "ihr", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.15": {"text": "Es sprach ihr jemand zu; da\u00df sie sich endlich wagte,", "tokens": ["Es", "sprach", "ihr", "je\u00b7mand", "zu", ";", "da\u00df", "sie", "sich", "end\u00b7lich", "wag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PTKVZ", "$.", "KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und mit Bedachtsamkeit die frommen Worte sagte:", "tokens": ["Und", "mit", "Be\u00b7dacht\u00b7sam\u00b7keit", "die", "from\u00b7men", "Wor\u00b7te", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "\u201eman streitet um den Rang, Freundinnen! viel zu sehr:", "tokens": ["\u201e", "man", "strei\u00b7tet", "um", "den", "Rang", ",", "Freun\u00b7din\u00b7nen", "!", "viel", "zu", "sehr", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "APPR", "ART", "NN", "$,", "NN", "$.", "ADV", "PTKA", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201egl\u00fcck, Wohlfahrt, Rath und Hilff komt nur von oben her.", "tokens": ["\u201e", "gl\u00fcck", ",", "Wohl\u00b7fahrt", ",", "Rath", "und", "Hilff", "komt", "nur", "von", "o\u00b7ben", "her", "."], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "$,", "NN", "KON", "NN", "VVFIN", "ADV", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "175\u201dDoch es sey fern von mir, euch etwas abzusprechen;", "tokens": ["\"", "Doch", "es", "sey", "fern", "von", "mir", ",", "euch", "et\u00b7was", "ab\u00b7zu\u00b7spre\u00b7chen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "VAFIN", "ADJD", "APPR", "PPER", "$,", "PPER", "PIS", "VVIZU", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "\u201efern, euern Amts-Verdienst und Tugend-Werth zu schw\u00e4chen.", "tokens": ["\u201e", "fern", ",", "eu\u00b7ern", "Amts\u00b7Ver\u00b7dienst", "und", "Tu\u00b7gen\u00b7dWerth", "zu", "schw\u00e4\u00b7chen", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPOSAT", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Hier ward sie still, wie wann sie noch Bedencken trug;", "tokens": ["Hier", "ward", "sie", "still", ",", "wie", "wann", "sie", "noch", "Be\u00b7den\u00b7cken", "trug", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKVZ", "$,", "PWAV", "PWAV", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil sie ganz zweifelhaft die Augen nieder schlug.", "tokens": ["Weil", "sie", "ganz", "zwei\u00b7fel\u00b7haft", "die", "Au\u00b7gen", "nie\u00b7der", "schlug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch fuhr sie wieder fort: \u201eUnd wie kan ich mich r\u00fchmen,", "tokens": ["Doch", "fuhr", "sie", "wie\u00b7der", "fort", ":", "\u201e", "Und", "wie", "kan", "ich", "mich", "r\u00fch\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$(", "KON", "PWAV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "180\u201dDa\u00df mir vielleicht der Platz des Frieses soll geziemen?", "tokens": ["\"", "Da\u00df", "mir", "viel\u00b7leicht", "der", "Platz", "des", "Frie\u00b7ses", "soll", "ge\u00b7zie\u00b7men", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201enein: die\u00df ist nicht mein Ziel; dann ich verlange nicht,", "tokens": ["\u201e", "nein", ":", "die\u00df", "ist", "nicht", "mein", "Ziel", ";", "dann", "ich", "ver\u00b7lan\u00b7ge", "nicht", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$.", "PDS", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$.", "ADV", "PPER", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eda\u00df man zu meinem Ruhm ein Ehren-Werck erricht.", "tokens": ["\u201e", "da\u00df", "man", "zu", "mei\u00b7nem", "Ruhm", "ein", "Eh\u00b7ren\u00b7\u00b7Werck", "er\u00b7richt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "APPR", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eentschlie\u00dft ihr einen Bau, so bauet GOtt zu Ehren,", "tokens": ["\u201e", "ent\u00b7schlie\u00dft", "ihr", "ei\u00b7nen", "Bau", ",", "so", "bau\u00b7et", "Gott", "zu", "Eh\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eer ists, dem Gl\u00fcck und Sieg, und Kron und Thron geh\u00f6ren.", "tokens": ["\u201e", "er", "ists", ",", "dem", "Gl\u00fcck", "und", "Sieg", ",", "und", "Kron", "und", "Thron", "ge\u00b7h\u00f6\u00b7ren", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "ART", "NN", "KON", "NN", "$,", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "185\u201dErz\u00e4hl' ich meinen Dienst, so such' ich keinen Ruhm;", "tokens": ["\"", "Er\u00b7z\u00e4hl'", "ich", "mei\u00b7nen", "Dienst", ",", "so", "such'", "ich", "kei\u00b7nen", "Ruhm", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201eich schm\u00fcckte nur mein Haupt mit fremdem Eigenthum.", "tokens": ["\u201e", "ich", "schm\u00fcck\u00b7te", "nur", "mein", "Haupt", "mit", "frem\u00b7dem", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eso will ich zwar, was ich gewircket habe, zeigen;", "tokens": ["\u201e", "so", "will", "ich", "zwar", ",", "was", "ich", "ge\u00b7wir\u00b7cket", "ha\u00b7be", ",", "zei\u00b7gen", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "ADV", "$,", "PWS", "PPER", "VVPP", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201ejedoch nur, nicht den Schutz des Himmels zu verschweigen.", "tokens": ["\u201e", "je\u00b7doch", "nur", ",", "nicht", "den", "Schutz", "des", "Him\u00b7mels", "zu", "ver\u00b7schwei\u00b7gen", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "PTKNEG", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "\u201ein den Bedr\u00e4ngnissen, in dem verla\u00dfnen Stand,", "tokens": ["\u201e", "in", "den", "Be\u00b7dr\u00e4ng\u00b7nis\u00b7sen", ",", "in", "dem", "ver\u00b7la\u00df\u00b7nen", "Stand", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+---+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "190\u201dIn dem Theresia von Anfang sich befand;", "tokens": ["\"", "In", "dem", "The\u00b7re\u00b7sia", "von", "An\u00b7fang", "sich", "be\u00b7fand", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NE", "APPR", "NN", "PRF", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "\u201ewer wollt\u2019 es dazumahl, uns Rath zu geben, wagen?", "tokens": ["\u201e", "wer", "wollt'", "es", "da\u00b7zu\u00b7mahl", ",", "uns", "Rath", "zu", "ge\u00b7ben", ",", "wa\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "ADV", "$,", "PPER", "NN", "PTKZU", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ewar nicht der Feind schon da, den Abzug anzusagen?", "tokens": ["\u201e", "war", "nicht", "der", "Feind", "schon", "da", ",", "den", "Ab\u00b7zug", "an\u00b7zu\u00b7sa\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PTKNEG", "ART", "NN", "ADV", "ADV", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eich sahe nah und fern desselben Krieges-Schaar,", "tokens": ["\u201e", "ich", "sa\u00b7he", "nah", "und", "fern", "des\u00b7sel\u00b7ben", "Krie\u00b7ge\u00b7sSchaar", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201edie mehr mit Feur und Schwert, als Recht bewaffnet war:", "tokens": ["\u201e", "die", "mehr", "mit", "Feur", "und", "Schwert", ",", "als", "Recht", "be\u00b7waff\u00b7net", "war", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "APPR", "NN", "KON", "NN", "$,", "KOUS", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "195\u201dDa lief ich unverweilt vor allen andern Dingen,", "tokens": ["\"", "Da", "lief", "ich", "un\u00b7ver\u00b7weilt", "vor", "al\u00b7len", "an\u00b7dern", "Din\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADJD", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201euns bey dem Himmel Hilff und Beystand aufzubringen:", "tokens": ["\u201e", "uns", "bey", "dem", "Him\u00b7mel", "Hilff", "und", "Beys\u00b7tand", "auf\u00b7zu\u00b7brin\u00b7gen", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "APPR", "ART", "NN", "NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201edann, wo wir hingesehn, sagt an! was fanden wir?", "tokens": ["\u201e", "dann", ",", "wo", "wir", "hin\u00b7ge\u00b7sehn", ",", "sagt", "an", "!", "was", "fan\u00b7den", "wir", "?"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PWAV", "PPER", "VVINF", "$,", "VVFIN", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ewar nicht der Untergang des Hauses vor der Th\u00fcr?", "tokens": ["\u201e", "war", "nicht", "der", "Un\u00b7ter\u00b7gang", "des", "Hau\u00b7ses", "vor", "der", "Th\u00fcr", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PTKNEG", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201ewas halff es, tapfer seyn, nichts f\u00fcrchten, nirgends weichen,", "tokens": ["\u201e", "was", "halff", "es", ",", "tap\u00b7fer", "seyn", ",", "nichts", "f\u00fcrch\u00b7ten", ",", "nir\u00b7gends", "wei\u00b7chen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$,", "ADJD", "VAINF", "$,", "PIS", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "200\u201dWann weder Heil dadurch noch Rettung zu erreichen?", "tokens": ["\"", "Wann", "we\u00b7der", "Heil", "da\u00b7durch", "noch", "Ret\u00b7tung", "zu", "er\u00b7rei\u00b7chen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "KON", "NN", "PAV", "ADV", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201edie K\u00f6niginn ergriff und lobte meinen Schlu\u00df,", "tokens": ["\u201e", "die", "K\u00f6\u00b7ni\u00b7ginn", "er\u00b7griff", "und", "lob\u00b7te", "mei\u00b7nen", "Schlu\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eder, sprach sie, sonsten nichts, ist was uns helffen mu\u00df.", "tokens": ["\u201e", "der", ",", "sprach", "sie", ",", "sons\u00b7ten", "nichts", ",", "ist", "was", "uns", "helf\u00b7fen", "mu\u00df", "."], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PIS", "$,", "VAFIN", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201eje mehr mich Furcht und Angst, und Schmerz, und Unmuth qu\u00e4lte,", "tokens": ["\u201e", "je", "mehr", "mich", "Furcht", "und", "Angst", ",", "und", "Schmerz", ",", "und", "Un\u00b7muth", "qu\u00e4l\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "PPER", "NN", "KON", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "VVFIN", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.16": {"text": "\u201eje mehr ich in Vertraun es GOtt um Hilff erz\u00e4hlte.", "tokens": ["\u201e", "je", "mehr", "ich", "in", "Ver\u00b7traun", "es", "Gott", "um", "Hilff", "er\u00b7z\u00e4hl\u00b7te", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "PPER", "APPR", "NN", "PPER", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "\u201eder Schiffmann, welcher Gl\u00fcck und Heil auf Wellen baut,", "tokens": ["\u201e", "der", "Schiff\u00b7mann", ",", "wel\u00b7cher", "Gl\u00fcck", "und", "Heil", "auf", "Wel\u00b7len", "baut", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PWAT", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201esein Leben, Hab und Gut dem falschen Wind vertraut,", "tokens": ["\u201e", "sein", "Le\u00b7ben", ",", "Hab", "und", "Gut", "dem", "fal\u00b7schen", "Wind", "ver\u00b7traut", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ewas dient ihm zum Geleit, damit er sicher schiffe?", "tokens": ["\u201e", "was", "dient", "ihm", "zum", "Ge\u00b7leit", ",", "da\u00b7mit", "er", "si\u00b7cher", "schif\u00b7fe", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "APPRART", "NN", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201enicht wahr, da\u00df er den Pol, die Nadel immer pr\u00fcffe?", "tokens": ["\u201e", "nicht", "wahr", ",", "da\u00df", "er", "den", "Pol", ",", "die", "Na\u00b7del", "im\u00b7mer", "pr\u00fcf\u00b7fe", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "ART", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201edie zeigen ihm den Weeg, den er mit seinem Kahn", "tokens": ["\u201e", "die", "zei\u00b7gen", "ihm", "den", "Weeg", ",", "den", "er", "mit", "sei\u00b7nem", "Kahn"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PDS", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "210\u201dZu suchen sich gewagt, zugleich die Mittel an,", "tokens": ["\"", "Zu", "su\u00b7chen", "sich", "ge\u00b7wagt", ",", "zu\u00b7gleich", "die", "Mit\u00b7tel", "an", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VVINF", "PRF", "VVPP", "$,", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201egefahren, Strandungen und Klippen zu vermeiden,", "tokens": ["\u201e", "ge\u00b7fah\u00b7ren", ",", "Stran\u00b7dun\u00b7gen", "und", "Klip\u00b7pen", "zu", "ver\u00b7mei\u00b7den", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "$,", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "\u201eso wei\u00df er unbesorgt die Wellen durchzuschneiden.", "tokens": ["\u201e", "so", "wei\u00df", "er", "un\u00b7be\u00b7sorgt", "die", "Wel\u00b7len", "durch\u00b7zu\u00b7schnei\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201everachtet er den Pol; verliehrt er den Magnet;", "tokens": ["\u201e", "ver\u00b7ach\u00b7tet", "er", "den", "Pol", ";", "ver\u00b7liehrt", "er", "den", "Mag\u00b7net", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "\u201ekein Wunder ist es dann, wann er zu Grunde geht.", "tokens": ["\u201e", "kein", "Wun\u00b7der", "ist", "es", "dann", ",", "wann", "er", "zu", "Grun\u00b7de", "geht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "VAFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "\u201euns ist bewu\u00dft, da\u00df auch ", "tokens": ["\u201e", "uns", "ist", "be\u00b7wu\u00dft", ",", "da\u00df", "auch"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "$,", "KOUS", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u201ebekannt, was \u00fcber sie vor St\u00fcrme seynd gekommen:", "tokens": ["\u201e", "be\u00b7kannt", ",", "was", "\u00fc\u00b7ber", "sie", "vor", "St\u00fcr\u00b7me", "seynd", "ge\u00b7kom\u00b7men", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PRELS", "APPR", "PPER", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201esie schiffte durch den Schaum der f\u00fcrchterlichsten Flutt;", "tokens": ["\u201e", "sie", "schiff\u00b7te", "durch", "den", "Schaum", "der", "f\u00fcrch\u00b7ter\u00b7lichs\u00b7ten", "Flutt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eauf wem, als nur auf mir, hat ihre Fart beruht?", "tokens": ["\u201e", "auf", "wem", ",", "als", "nur", "auf", "mir", ",", "hat", "ih\u00b7re", "Fart", "be\u00b7ruht", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIS", "$,", "KOUS", "ADV", "APPR", "PPER", "$,", "VAFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "\u201edie Winde drangen sich das Schiff herum zu schlagen,", "tokens": ["\u201e", "die", "Win\u00b7de", "dran\u00b7gen", "sich", "das", "Schiff", "he\u00b7rum", "zu", "schla\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PRF", "ART", "NN", "APZR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "220\u201dSie sch\u00e4rfften die Gewalt, es auf den Strand zu jagen;", "tokens": ["\"", "Sie", "sch\u00e4rff\u00b7ten", "die", "Ge\u00b7walt", ",", "es", "auf", "den", "Strand", "zu", "ja\u00b7gen", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "$,", "PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201edie Wellen welzten sich von allen Seiten her,", "tokens": ["\u201e", "die", "Wel\u00b7len", "welz\u00b7ten", "sich", "von", "al\u00b7len", "Sei\u00b7ten", "her", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PRF", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201esie rollten Flutt auf Flutt, erz\u00fcrnten selbst das Meer;", "tokens": ["\u201e", "sie", "roll\u00b7ten", "Flutt", "auf", "Flutt", ",", "er\u00b7z\u00fcrn\u00b7ten", "selbst", "das", "Meer", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "APPR", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201ekein Ungest\u00fcm verga\u00df sich wieder sie zu b\u00e4umen;", "tokens": ["\u201e", "kein", "Un\u00b7ge\u00b7st\u00fcm", "ver\u00b7ga\u00df", "sich", "wie\u00b7der", "sie", "zu", "b\u00e4u\u00b7men", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "VVFIN", "PRF", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201edie W\u00e4sser funckelten f\u00fcr Grimmen-vollem Sch\u00e4umen.", "tokens": ["\u201e", "die", "W\u00e4s\u00b7ser", "fun\u00b7ckel\u00b7ten", "f\u00fcr", "Grim\u00b7men\u00b7vol\u00b7lem", "Sch\u00e4u\u00b7men", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "225\u201dSo gar der Wolcken Grau wies Rach und Zorn daran,", "tokens": ["\"", "So", "gar", "der", "Wol\u00b7cken", "Grau", "wies", "Rach", "und", "Zorn", "da\u00b7ran", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "NN", "VVFIN", "NN", "KON", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201everh\u00fcllte Lufft und Meer, und den best\u00fcrmten Kahn;", "tokens": ["\u201e", "ver\u00b7h\u00fcll\u00b7te", "Lufft", "und", "Meer", ",", "und", "den", "be\u00b7st\u00fcrm\u00b7ten", "Kahn", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "KON", "NN", "$,", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201eder Schrecken h\u00e4uffte sich; der Hoffnungs-Ancker krachte,", "tokens": ["\u201e", "der", "Schre\u00b7cken", "h\u00e4uff\u00b7te", "sich", ";", "der", "Hoff\u00b7nungs\u00b7An\u00b7cker", "krach\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PRF", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eindem die schwartze Luft den Keilen Weege machte,", "tokens": ["\u201e", "in\u00b7dem", "die", "schwart\u00b7ze", "Luft", "den", "Kei\u00b7len", "Wee\u00b7ge", "mach\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "ADJA", "NN", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ewodurch des Donners Macht, Bliz, Feur und Hagel scho\u00df,", "tokens": ["\u201e", "wo\u00b7durch", "des", "Don\u00b7ners", "Macht", ",", "Bliz", ",", "Feur", "und", "Ha\u00b7gel", "scho\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ART", "NN", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "230\u201dDas Hoffnungs-blosse Schiff in Gr\u00e4\u00dflichkeit verschlo\u00df.", "tokens": ["\"", "Das", "Hoff\u00b7nungs\u00b7\u00b7blos\u00b7se", "Schiff", "in", "Gr\u00e4\u00df\u00b7lich\u00b7keit", "ver\u00b7schlo\u00df", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201emich greifft ein Schauer an; Mund, Herz und Stim\u0303e zittern,", "tokens": ["\u201e", "mich", "greifft", "ein", "Schau\u00b7er", "an", ";", "Mund", ",", "Herz", "und", "Stim\u0303e", "zit\u00b7tern", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$.", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+--++-++-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "\u201ewann ich des schw\u00e4chsten Schlags von diesen Ungewittern", "tokens": ["\u201e", "wann", "ich", "des", "schw\u00e4chs\u00b7ten", "Schlags", "von", "die\u00b7sen", "Un\u00b7ge\u00b7wit\u00b7tern"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PPER", "ART", "ADJA", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201emich noch erinnere: wie das erbo\u00dfte Feur", "tokens": ["\u201e", "mich", "noch", "e\u00b7rin\u00b7ne\u00b7re", ":", "wie", "das", "er\u00b7bo\u00df\u00b7te", "Feur"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADV", "VVFIN", "$.", "PWAV", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.20": {"text": "\u201edes Hochmuths sich emp\u00f6rt: mit was vor Abentheur", "tokens": ["\u201e", "des", "Hoch\u00b7muths", "sich", "em\u00b7p\u00f6rt", ":", "mit", "was", "vor", "A\u00b7bent\u00b7heur"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "PRF", "ADJD", "$.", "APPR", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "235\u201dDas wallende Geb\u00fcrg den Rachen aufgeblehet,", "tokens": ["\"", "Das", "wal\u00b7len\u00b7de", "Ge\u00b7b\u00fcrg", "den", "Ra\u00b7chen", "auf\u00b7ge\u00b7ble\u00b7het", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "\u201eund um desselben Schlund das Schiff herum gedrehet.", "tokens": ["\u201e", "und", "um", "des\u00b7sel\u00b7ben", "Schlund", "das", "Schiff", "he\u00b7rum", "ge\u00b7dre\u00b7het", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "APPR", "PDAT", "NN", "ART", "NN", "APZR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "\u201eerz\u00e4hlt mir, Wertheste! wie sich ", "tokens": ["\u201e", "er\u00b7z\u00e4hlt", "mir", ",", "Wert\u00b7hes\u00b7te", "!", "wie", "sich"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "$,", "NN", "$.", "PWAV", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "\u201ein der Gefahr erwies! wer war zum Helffen da?", "tokens": ["\u201e", "in", "der", "Ge\u00b7fahr", "er\u00b7wies", "!", "wer", "war", "zum", "Helf\u00b7fen", "da", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "VVFIN", "$.", "PWS", "VAFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "\u201ewas halff die k\u00fchne Faust, Standhafftigkeit der Sinnen,", "tokens": ["\u201e", "was", "halff", "die", "k\u00fch\u00b7ne", "Faust", ",", "Stand\u00b7haff\u00b7tig\u00b7keit", "der", "Sin\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ART", "ADJA", "NN", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "240\u201dEin unerschrockner Geist, die Winde zu gewinnen?", "tokens": ["\"", "Ein", "un\u00b7er\u00b7schrock\u00b7ner", "Geist", ",", "die", "Win\u00b7de", "zu", "ge\u00b7win\u00b7nen", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "\u201edas Meer trozt jede Macht. Die Nadel und der Pol,", "tokens": ["\u201e", "das", "Meer", "trozt", "je\u00b7de", "Macht", ".", "Die", "Na\u00b7del", "und", "der", "Pol", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PIAT", "NN", "$.", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "\u201ean diesen hieng das Schiff, Gl\u00fcck, Rettung, Heil und Wohl.", "tokens": ["\u201e", "an", "die\u00b7sen", "hieng", "das", "Schiff", ",", "Gl\u00fcck", ",", "Ret\u00b7tung", ",", "Heil", "und", "Wohl", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "VVFIN", "ART", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "\u201edas Auge GOttes war der Pol, auf den wir schauten;", "tokens": ["\u201e", "das", "Au\u00b7ge", "Got\u00b7tes", "war", "der", "Pol", ",", "auf", "den", "wir", "schau\u00b7ten", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201enach dessen Blick und Winck wir uns dem Meer vertrauten;", "tokens": ["\u201e", "nach", "des\u00b7sen", "Blick", "und", "Win\u00b7ck", "wir", "uns", "dem", "Meer", "ver\u00b7trau\u00b7ten", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PRELAT", "NN", "KON", "NN", "PPER", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "245\u201dDas Herz der K\u00f6niginn war Nadel und Compa\u00df,", "tokens": ["\"", "Das", "Herz", "der", "K\u00f6\u00b7ni\u00b7ginn", "war", "Na\u00b7del", "und", "Com\u00b7pa\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eden weder Flutt, noch Wind, noch Jrrlicht von der Stra\u00df,", "tokens": ["\u201e", "den", "we\u00b7der", "Flutt", ",", "noch", "Wind", ",", "noch", "Jrr\u00b7licht", "von", "der", "Stra\u00df", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "KON", "NN", "$,", "ADV", "NN", "$,", "ADV", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201evom Pol entferneten: mich traff das Ruder f\u00fchren:", "tokens": ["\u201e", "vom", "Pol", "ent\u00b7fer\u00b7ne\u00b7ten", ":", "mich", "traff", "das", "Ru\u00b7der", "f\u00fch\u00b7ren", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eso konnten wir uns nicht in diesem Sturm verliehren.", "tokens": ["\u201e", "so", "konn\u00b7ten", "wir", "uns", "nicht", "in", "die\u00b7sem", "Sturm", "ver\u00b7lieh\u00b7ren", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "PRF", "PTKNEG", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eja, was am pl\u00f6zlichsten sonst zu erschrecken pflegt,", "tokens": ["\u201e", "ja", ",", "was", "am", "pl\u00f6z\u00b7lichs\u00b7ten", "sonst", "zu", "er\u00b7schre\u00b7cken", "pflegt", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "PRELS", "APPRART", "ADJA", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.8": {"text": "250\u201dWar, was in unserm Sinn oft neuen Muth erregt.", "tokens": ["\"", "War", ",", "was", "in", "un\u00b7serm", "Sinn", "oft", "neu\u00b7en", "Muth", "er\u00b7regt", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201eje mehr der Bliz das Grau der blassen Luft zerrizte,", "tokens": ["\u201e", "je", "mehr", "der", "Bliz", "das", "Grau", "der", "blas\u00b7sen", "Luft", "zer\u00b7riz\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201eje mehr in unsrer Brust sich Trost und Hoffnung st\u00fczte.", "tokens": ["\u201e", "je", "mehr", "in", "uns\u00b7rer", "Brust", "sich", "Trost", "und", "Hoff\u00b7nung", "st\u00fcz\u00b7te", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "APPR", "PPOSAT", "NN", "PRF", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201edie Finsterni\u00df nahm uns der Augen Zuversicht,", "tokens": ["\u201e", "die", "Fins\u00b7ter\u00b7ni\u00df", "nahm", "uns", "der", "Au\u00b7gen", "Zu\u00b7ver\u00b7sicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eder Bliz hingegen gab uns wieder Schein und Licht,", "tokens": ["\u201e", "der", "Bliz", "hin\u00b7ge\u00b7gen", "gab", "uns", "wie\u00b7der", "Schein", "und", "Licht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "VVFIN", "PPER", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "255\u201dDa\u00df wir den Lauf des Sturms, das Wetter konnten sehen,", "tokens": ["\"", "Da\u00df", "wir", "den", "Lauf", "des", "Sturms", ",", "das", "Wet\u00b7ter", "konn\u00b7ten", "se\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eund folglich der Gefahr des Untergangs entgehen.", "tokens": ["\u201e", "und", "folg\u00b7lich", "der", "Ge\u00b7fahr", "des", "Un\u00b7ter\u00b7gangs", "ent\u00b7ge\u00b7hen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "\u201enun ruff\u2019 ich billich auf: Wer halff bey dieser Fart?", "tokens": ["\u201e", "nun", "ruff'", "ich", "bil\u00b7lich", "auf", ":", "Wer", "halff", "bey", "die\u00b7ser", "Fart", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "PWS", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eda ihr noch selber nicht zum Beystand einig wart?", "tokens": ["\u201e", "da", "ihr", "noch", "sel\u00b7ber", "nicht", "zum", "Beys\u00b7tand", "ei\u00b7nig", "wart", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADV", "PTKNEG", "APPRART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ewie taugte dazumahl ein menschliches Verm\u00f6gen?", "tokens": ["\u201e", "wie", "taug\u00b7te", "da\u00b7zu\u00b7mahl", "ein", "menschli\u00b7ches", "Ver\u00b7m\u00f6\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "260\u201dDrum suchten wir die Macht des Himmels zu bewegen:", "tokens": ["\"", "Drum", "such\u00b7ten", "wir", "die", "Macht", "des", "Him\u00b7mels", "zu", "be\u00b7we\u00b7gen", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201ezu solchem End hab ichs, die ", "tokens": ["\u201e", "zu", "sol\u00b7chem", "End", "hab", "ichs", ",", "die"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["$(", "APPR", "PIAT", "NN", "VAFIN", "PIS", "$,", "PRELS"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "\u201eund so verschwand der Greul der Schrecken-vollen Nacht.", "tokens": ["\u201e", "und", "so", "ver\u00b7schwand", "der", "Greul", "der", "Schre\u00b7cken\u00b7vol\u00b7len", "Nacht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201egOtt gab uns Hilff und Schuz; durch ihn seynd wir gerettet,", "tokens": ["\u201e", "gOtt", "gab", "uns", "Hilff", "und", "Schuz", ";", "durch", "ihn", "seynd", "wir", "ge\u00b7ret\u00b7tet", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "NN", "KON", "NN", "$.", "APPR", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "\u201ejhn haben wir allein um Beystand angebetet.", "tokens": ["\u201e", "jhn", "ha\u00b7ben", "wir", "al\u00b7lein", "um", "Beys\u00b7tand", "an\u00b7ge\u00b7be\u00b7tet", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201eweil schon der Feinde Gifft der Freunde Blut durchschlich.", "tokens": ["\u201e", "weil", "schon", "der", "Fein\u00b7de", "Gifft", "der", "Freun\u00b7de", "Blut", "durch\u00b7schlich", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "NN", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201enur was uns GOtt verlieh, gieng, trozte die Gefahren,", "tokens": ["\u201e", "nur", "was", "uns", "Gott", "ver\u00b7lieh", ",", "gieng", ",", "troz\u00b7te", "die", "Ge\u00b7fah\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PWS", "PPER", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eund wiedersezte sich den Herrsucht-vollen Schaaren.", "tokens": ["\u201e", "und", "wie\u00b7der\u00b7sez\u00b7te", "sich", "den", "Herr\u00b7sucht\u00b7vol\u00b7len", "Schaa\u00b7ren", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PRF", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201edas hat die ", "tokens": ["\u201e", "das", "hat", "die"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.22": {"line.1": {"text": "Die Unerschrockenheit gab \u00f6ffters solche Zeichen,", "tokens": ["Die", "Un\u00b7er\u00b7schro\u00b7cken\u00b7heit", "gab", "\u00f6ff\u00b7ters", "sol\u00b7che", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df sich die Fr\u00f6mmigkeit mit ihr nicht sollt vergleichen.", "tokens": ["Da\u00df", "sich", "die", "Fr\u00f6m\u00b7mig\u00b7keit", "mit", "ihr", "nicht", "sollt", "ver\u00b7glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPR", "PPER", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Hier aber stund sie auf, und sprach: \u201eWer wei\u00df es nicht,", "tokens": ["Hier", "a\u00b7ber", "stund", "sie", "auf", ",", "und", "sprach", ":", "\u201e", "Wer", "wei\u00df", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "$.", "$(", "PWS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eda\u00df Fr\u00f6mmigkeit von nichts, als von der Andacht spricht?", "tokens": ["\u201e", "da\u00df", "Fr\u00f6m\u00b7mig\u00b7keit", "von", "nichts", ",", "als", "von", "der", "An\u00b7dacht", "spricht", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "APPR", "PIS", "$,", "KOUS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eallein, hast du dadurch so viel, als ich, erwiesen?", "tokens": ["\u201e", "al\u00b7lein", ",", "hast", "du", "da\u00b7durch", "so", "viel", ",", "als", "ich", ",", "er\u00b7wie\u00b7sen", "?"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$,", "VAFIN", "PPER", "PAV", "ADV", "ADV", "$,", "KOUS", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201edein Vortrag ist mein Werck: h\u00e4tt euch der Sturm erschreckt;", "tokens": ["\u201e", "dein", "Vor\u00b7trag", "ist", "mein", "Werck", ":", "h\u00e4tt", "euch", "der", "Sturm", "er\u00b7schreckt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$.", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201ewo w\u00e4r die Fr\u00f6mmigkeit mit ihrem Schiff gesteckt?", "tokens": ["\u201e", "wo", "w\u00e4r", "die", "Fr\u00f6m\u00b7mig\u00b7keit", "mit", "ih\u00b7rem", "Schiff", "ge\u00b7steckt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201estumm, blind, unm\u00e4chtig, taub, erstarrt h\u00e4ttst du geschworen,", "tokens": ["\u201e", "stumm", ",", "blind", ",", "un\u00b7m\u00e4ch\u00b7tig", ",", "taub", ",", "er\u00b7starrt", "h\u00e4ttst", "du", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "VVPP", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Die Fr\u00f6mmigkeit vernahm den Einwurff; schwieg dazu,", "tokens": ["Die", "Fr\u00f6m\u00b7mig\u00b7keit", "ver\u00b7nahm", "den", "Ein\u00b7wurff", ";", "schwieg", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$.", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wies in dem Gesicht Gelassenheit und Ruh:", "tokens": ["Und", "wies", "in", "dem", "Ge\u00b7sicht", "Ge\u00b7las\u00b7sen\u00b7heit", "und", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch endlich sprach sie dies: \u201eWas? Freundinn? willst du streiten?", "tokens": ["Doch", "end\u00b7lich", "sprach", "sie", "dies", ":", "\u201e", "Was", "?", "Freun\u00b7dinn", "?", "willst", "du", "strei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PDS", "$.", "$(", "PWS", "$.", "NN", "$.", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ewie? oder selber gar den Sieg mir zubereiten?", "tokens": ["\u201e", "wie", "?", "o\u00b7der", "sel\u00b7ber", "gar", "den", "Sieg", "mir", "zu\u00b7be\u00b7rei\u00b7ten", "?"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$.", "KON", "ADV", "ADV", "ART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eals du? wer hat es mehr zum Kriegen aufgehezt?", "tokens": ["\u201e", "als", "du", "?", "wer", "hat", "es", "mehr", "zum", "Krie\u00b7gen", "auf\u00b7ge\u00b7hezt", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "$.", "PWS", "VAFIN", "PPER", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201edu triebst es in die Wuth: es hat gepocht, gefochten;", "tokens": ["\u201e", "du", "triebst", "es", "in", "die", "Wuth", ":", "es", "hat", "ge\u00b7pocht", ",", "ge\u00b7foch\u00b7ten", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "PPER", "VAFIN", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eund dannoch sieht man es mit wenig Laub umflochten.", "tokens": ["\u201e", "und", "dan\u00b7noch", "sieht", "man", "es", "mit", "we\u00b7nig", "Laub", "um\u00b7floch\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "VVFIN", "PIS", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Darauf ward eingewendt: \u201eDie Furcht ist dein Geleit;", "tokens": ["Da\u00b7rauf", "ward", "ein\u00b7ge\u00b7wendt", ":", "\u201e", "Die", "Furcht", "ist", "dein", "Ge\u00b7leit", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "VVPP", "$.", "$(", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201esie schl\u00e4gt der Krieger Muth durch ihr Entfliehen nieder;", "tokens": ["\u201e", "sie", "schl\u00e4gt", "der", "Krie\u00b7ger", "Muth", "durch", "ihr", "Ent\u00b7flie\u00b7hen", "nie\u00b7der", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201esie st\u00f6rt der Schaaren Feur, und schw\u00e4cht die Macht der Glieder.", "tokens": ["\u201e", "sie", "st\u00f6rt", "der", "Schaa\u00b7ren", "Feur", ",", "und", "schw\u00e4cht", "die", "Macht", "der", "Glie\u00b7der", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "NN", "$,", "KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201ewas\u201e, sprach die Fr\u00f6mmigkeit, was ist dein Helden-Muth?", "tokens": ["\u201e", "was", "\u201e", ",", "sprach", "die", "Fr\u00f6m\u00b7mig\u00b7keit", ",", "was", "ist", "dein", "Hel\u00b7den\u00b7Muth", "?"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "$(", "$,", "VVFIN", "ART", "NN", "$,", "PWS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eerz\u00e4hl, auf was dein Rath, Verdienst und Werck beruht!", "tokens": ["\u201e", "er\u00b7z\u00e4hl", ",", "auf", "was", "dein", "Rath", ",", "Ver\u00b7dienst", "und", "Werck", "be\u00b7ruht", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "APPR", "PRELS", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201esagst du? so bist du nicht mit uns im Sturm gewesen?", "tokens": ["\u201e", "sagst", "du", "?", "so", "bist", "du", "nicht", "mit", "uns", "im", "Sturm", "ge\u00b7we\u00b7sen", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$.", "ADV", "VAFIN", "PPER", "PTKNEG", "APPR", "PPER", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eund dannoch haben wir die gr\u00f6\u00dfte Wuth besiegt:", "tokens": ["\u201e", "und", "dan\u00b7noch", "ha\u00b7ben", "wir", "die", "gr\u00f6\u00df\u00b7te", "Wuth", "be\u00b7siegt", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ewie der Bewei\u00df dem Krei\u00df und dir vor Augen ligt:", "tokens": ["\u201e", "wie", "der", "Be\u00b7wei\u00df", "dem", "Krei\u00df", "und", "dir", "vor", "Au\u00b7gen", "ligt", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ART", "NN", "ART", "NN", "KON", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.16": {"text": "\u201ewarst aber du sowohl als ich im Sturm vorhanden;", "tokens": ["\u201e", "warst", "a\u00b7ber", "du", "so\u00b7wohl", "als", "ich", "im", "Sturm", "vor\u00b7han\u00b7den", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "NE", "KON", "KOUS", "PPER", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201eallein was nuzt die Frag und dieser eitle Streit?", "tokens": ["\u201e", "al\u00b7lein", "was", "nuzt", "die", "Frag", "und", "die\u00b7ser", "eit\u00b7le", "Streit", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PWS", "VVFIN", "ART", "NN", "KON", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201ehier ist die Fr\u00f6mmigkeit; dort Unerschrockenheit.", "tokens": ["\u201e", "hier", "ist", "die", "Fr\u00f6m\u00b7mig\u00b7keit", ";", "dort", "Un\u00b7er\u00b7schro\u00b7cken\u00b7heit", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "$.", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Sie schwieg und sezte sich mit stillem L\u00e4cheln nieder,", "tokens": ["Sie", "schwieg", "und", "sez\u00b7te", "sich", "mit", "stil\u00b7lem", "L\u00e4\u00b7cheln", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da jene sich erwies, als br\u00e4chte sie darwieder", "tokens": ["Da", "je\u00b7ne", "sich", "er\u00b7wies", ",", "als", "br\u00e4ch\u00b7te", "sie", "dar\u00b7wie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PRF", "VVFIN", "$,", "KOKOM", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein es stellte sich schon jemand an den Plaz,", "tokens": ["Al\u00b7lein", "es", "stell\u00b7te", "sich", "schon", "je\u00b7mand", "an", "den", "Plaz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PRF", "ADV", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und unterbrach den Streit. So war man zwar zu frieden;", "tokens": ["Und", "un\u00b7ter\u00b7brach", "den", "Streit", ".", "So", "war", "man", "zwar", "zu", "frie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$.", "ADV", "VAFIN", "PIS", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch wegen dem Geb\u00e4u so viel als nichts entschieden.", "tokens": ["Doch", "we\u00b7gen", "dem", "Ge\u00b7b\u00e4u", "so", "viel", "als", "nichts", "ent\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "ADV", "KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Ein herrliches Gesicht, so bald es sich erh\u00f6ht,\n310Erweckte bey dem Krei\u00df durch seine Majest\u00e4t", "tokens": ["Ein", "herr\u00b7li\u00b7ches", "Ge\u00b7sicht", ",", "so", "bald", "es", "sich", "er\u00b7h\u00f6ht", ",", "310\u00b7Er\u00b7weck\u00b7te", "bey", "dem", "Krei\u00df", "durch", "sei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "number_compound", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADV", "PPER", "PRF", "VVPP", "$,", "VVFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Aufmercksamkeit und Acht. Es war der F\u00fcrsten Zierde,", "tokens": ["Auf\u00b7merck\u00b7sam\u00b7keit", "und", "Acht", ".", "Es", "war", "der", "F\u00fcrs\u00b7ten", "Zier\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "CARD", "$.", "PPER", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ja selbst die ", "tokens": ["Ja", "selbst", "die"], "token_info": ["word", "word", "word"], "pos": ["PTKANT", "ADV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Zum reden fertig stund, nachdem sie einen Schild,", "tokens": ["Zum", "re\u00b7den", "fer\u00b7tig", "stund", ",", "nach\u00b7dem", "sie", "ei\u00b7nen", "Schild", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVINF", "ADJD", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Den sie zu mehrer Pracht und Hoheit vor sich hielt,", "tokens": ["Den", "sie", "zu", "meh\u00b7rer", "Pracht", "und", "Ho\u00b7heit", "vor", "sich", "hielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIAT", "NN", "KON", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eist bi\u00df auf diese Zeit allein dahin gegangen,", "tokens": ["\u201e", "ist", "bi\u00df", "auf", "die\u00b7se", "Zeit", "al\u00b7lein", "da\u00b7hin", "ge\u00b7gan\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "APPR", "PDAT", "NN", "ADV", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eda\u00df ich die ", "tokens": ["\u201e", "da\u00df", "ich", "die"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "ART"], "meter": "++-", "measure": "unknown.measure.di"}, "line.8": {"text": "\u201edie meine Majest\u00e4t mir eigenthumlich macht,", "tokens": ["\u201e", "die", "mei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t", "mir", "ei\u00b7gen\u00b7thum\u00b7lich", "macht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PPOSAT", "NN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201edem Vaterland zum Heil und ihr zum Nachruhm ziere;", "tokens": ["\u201e", "dem", "Va\u00b7ter\u00b7land", "zum", "Heil", "und", "ihr", "zum", "Nach\u00b7ruhm", "zie\u00b7re", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPRART", "NN", "KON", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ees ist bekannt, wie sich des Adlers Aug erquickt,", "tokens": ["\u201e", "es", "ist", "be\u00b7kannt", ",", "wie", "sich", "des", "Ad\u00b7lers", "Aug", "er\u00b7quickt", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "$,", "PWAV", "PRF", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201ewann er der Sonne Licht und sch\u00e4rfsten Glanz erblickt.", "tokens": ["\u201e", "wann", "er", "der", "Son\u00b7ne", "Licht", "und", "sch\u00e4rfs\u00b7ten", "Glanz", "er\u00b7blickt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Kaum h\u00f6rten wir das Wort, so wandte sie das Auge", "tokens": ["Kaum", "h\u00f6r\u00b7ten", "wir", "das", "Wort", ",", "so", "wand\u00b7te", "sie", "das", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Nach ihrem Schild, und sprach: \u201eHier sehet, was er tauge!", "tokens": ["Nach", "ih\u00b7rem", "Schild", ",", "und", "sprach", ":", "\u201e", "Hier", "se\u00b7het", ",", "was", "er", "tau\u00b7ge", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "$.", "$(", "ADV", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wie Pfeilen-schnell und stolz er durch die Wolcken fliegt.", "tokens": ["Wie", "Pfei\u00b7len\u00b7schnell", "und", "stolz", "er", "durch", "die", "Wol\u00b7cken", "fliegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "ADJD", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ejemehr der Sonne Strahl ihm in das Antliz blizet,", "tokens": ["\u201e", "je\u00b7mehr", "der", "Son\u00b7ne", "Strahl", "ihm", "in", "das", "Ant\u00b7liz", "bli\u00b7zet", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "War ferner ihr Gespr\u00e4ch, \u201ejemehr er sich erhizet;", "tokens": ["War", "fer\u00b7ner", "ihr", "Ge\u00b7spr\u00e4ch", ",", "\u201e", "je\u00b7mehr", "er", "sich", "er\u00b7hi\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$,", "$(", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201eer schie\u00dft und wirfft den Blick um alle Seiten her,", "tokens": ["\u201e", "er", "schie\u00dft", "und", "wirfft", "den", "Blick", "um", "al\u00b7le", "Sei\u00b7ten", "her", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201eer sieht die Sonne sich durch alle Kreise schwingen,", "tokens": ["\u201e", "er", "sieht", "die", "Son\u00b7ne", "sich", "durch", "al\u00b7le", "Krei\u00b7se", "schwin\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "PRF", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201eund auf der hohen Bahn der Sterne Licht verdringen:", "tokens": ["\u201e", "und", "auf", "der", "ho\u00b7hen", "Bahn", "der", "Ster\u00b7ne", "Licht", "ver\u00b7drin\u00b7gen", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "APPR", "ART", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "\u201eer sch\u00e4zt und achtet sich als seines gleichens Haupt;", "tokens": ["\u201e", "er", "sch\u00e4zt", "und", "ach\u00b7tet", "sich", "als", "sei\u00b7nes", "glei\u00b7chens", "Haupt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "KON", "VVFIN", "PRF", "KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "\u201evermeint, er w\u00e4r der Ehr und Majest\u00e4t beraubt,", "tokens": ["\u201e", "ver\u00b7meint", ",", "er", "w\u00e4r", "der", "Ehr", "und", "Ma\u00b7jes\u00b7t\u00e4t", "be\u00b7raubt", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "$,", "PPER", "VAFIN", "ART", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "\u201eund er nicht so, wie sie, den Himmel \u00fcberfl\u00f6ge.", "tokens": ["\u201e", "und", "er", "nicht", "so", ",", "wie", "sie", ",", "den", "Him\u00b7mel", "\u00fc\u00b7berf\u00b7l\u00f6\u00b7ge", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "PTKNEG", "ADV", "$,", "PWAV", "PPER", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "\u201eer st\u00fcrzt sich in die Luft, verl\u00e4\u00dft der Erde Rund;", "tokens": ["\u201e", "er", "st\u00fcrzt", "sich", "in", "die", "Luft", ",", "ver\u00b7l\u00e4\u00dft", "der", "Er\u00b7de", "Rund", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u201eund macht der Sonne selbst sein hohes Wesen kund.", "tokens": ["\u201e", "und", "macht", "der", "Son\u00b7ne", "selbst", "sein", "ho\u00b7hes", "We\u00b7sen", "kund", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "ART", "NN", "ADV", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "\u201esie strahlt ihm ins Gesicht, er trozt mit seinen Augen,", "tokens": ["\u201e", "sie", "strahlt", "ihm", "ins", "Ge\u00b7sicht", ",", "er", "trozt", "mit", "sei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPRART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "\u201eer sch\u00e4rfft den k\u00fchnen Blick, und achtet keinen Keil,", "tokens": ["\u201e", "er", "sch\u00e4rfft", "den", "k\u00fch\u00b7nen", "Blick", ",", "und", "ach\u00b7tet", "kei\u00b7nen", "Keil", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "\u201eschwingt selber sich so schnell als ein gescho\u00dfner Pfeil:", "tokens": ["\u201e", "schwingt", "sel\u00b7ber", "sich", "so", "schnell", "als", "ein", "ge\u00b7scho\u00df\u00b7ner", "Pfeil", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PRF", "ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "\u201edurch sein gro\u00dfm\u00fcthiges und unerschrocknes Fl\u00fcgen", "tokens": ["\u201e", "durch", "sein", "gro\u00df\u00b7m\u00fct\u00b7hi\u00b7ges", "und", "un\u00b7er\u00b7schrock\u00b7nes", "Fl\u00fc\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "KON", "ADJA", "NN"], "meter": "---++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "\u201emu\u00df, was ihm wiedersteht, den Klauen unterligen.", "tokens": ["\u201e", "mu\u00df", ",", "was", "ihm", "wie\u00b7ders\u00b7teht", ",", "den", "Klau\u00b7en", "un\u00b7ter\u00b7li\u00b7gen", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "\u201eer bricht sie, wafnet sich damit: das ist der Bliz,", "tokens": ["\u201e", "er", "bricht", "sie", ",", "waf\u00b7net", "sich", "da\u00b7mit", ":", "das", "ist", "der", "Bliz", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "VVFIN", "PRF", "PAV", "$.", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "\u201emit dem er auf den Feind, der ihn erz\u00fcrnet, wettert,", "tokens": ["\u201e", "mit", "dem", "er", "auf", "den", "Feind", ",", "der", "ihn", "er\u00b7z\u00fcr\u00b7net", ",", "wet\u00b7tert", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "APPR", "PRELS", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "\u201edesselben Hochmuth trozt; Wuth, Rach und Macht zerschmettert.", "tokens": ["\u201e", "des\u00b7sel\u00b7ben", "Hoch\u00b7muth", "trozt", ";", "Wuth", ",", "Rach", "und", "Macht", "zer\u00b7schmet\u00b7tert", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDAT", "NN", "VVFIN", "$.", "NN", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "\u201eso sch\u00fczt der Adler sich; so schwingt er sich empor;", "tokens": ["\u201e", "so", "sch\u00fczt", "der", "Ad\u00b7ler", "sich", ";", "so", "schwingt", "er", "sich", "em\u00b7por", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "PRF", "$.", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "350\u201dSo geht ihm kein Geschlecht der Welt an Hoheit vor.", "tokens": ["\"", "So", "geht", "ihm", "kein", "Ge\u00b7schlecht", "der", "Welt", "an", "Ho\u00b7heit", "vor", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PIAT", "NN", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eso wird der Sterne Reich vom Adler \u00fcberflogen,", "tokens": ["\u201e", "so", "wird", "der", "Ster\u00b7ne", "Reich", "vom", "Ad\u00b7ler", "\u00fc\u00b7berf\u00b7lo\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eund dessentwegen er als K\u00f6nig vorgezogen.", "tokens": ["\u201e", "und", "des\u00b7sent\u00b7we\u00b7gen", "er", "als", "K\u00f6\u00b7nig", "vor\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PAV", "PPER", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "\u201eaus diesem Flug erhellt, was ich erkl\u00e4ren will:", "tokens": ["\u201e", "aus", "die\u00b7sem", "Flug", "er\u00b7hellt", ",", "was", "ich", "er\u00b7kl\u00e4\u00b7ren", "will", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "NN", "VVFIN", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eob nicht ", "tokens": ["\u201e", "ob", "nicht"], "token_info": ["punct", "word", "word"], "pos": ["$(", "KOUS", "PTKNEG"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "\u201edes Adlers Aug\u2019 und Muth in ihren Thaten gleiche.", "tokens": ["\u201e", "des", "Ad\u00b7lers", "Aug'", "und", "Muth", "in", "ih\u00b7ren", "Tha\u00b7ten", "glei\u00b7che", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ejhr sehet, wie beherzt sie nach des Adlers Art", "tokens": ["\u201e", "jhr", "se\u00b7het", ",", "wie", "be\u00b7herzt", "sie", "nach", "des", "Ad\u00b7lers", "Art"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201ein der Standhafftigkeit der Gegenwehr verharrt.", "tokens": ["\u201e", "in", "der", "Stand\u00b7haff\u00b7tig\u00b7keit", "der", "Ge\u00b7gen\u00b7wehr", "ver\u00b7harrt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "\u201ehat sie der Sonne nicht schon Strahlen abgebrochen,", "tokens": ["\u201e", "hat", "sie", "der", "Son\u00b7ne", "nicht", "schon", "Strah\u00b7len", "ab\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NN", "PTKNEG", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "\u201esteigt nun die Majest\u00e4t mit solcher Pracht empor;", "tokens": ["\u201e", "steigt", "nun", "die", "Ma\u00b7jes\u00b7t\u00e4t", "mit", "sol\u00b7cher", "Pracht", "em\u00b7por", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eso kommt der Marmel-Stein mir allzu wenig vor,", "tokens": ["\u201e", "so", "kommt", "der", "Mar\u00b7mel\u00b7Stein", "mir", "all\u00b7zu", "we\u00b7nig", "vor", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "PPER", "PTKA", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eda\u00df ich um dessen Rang, Besiz und Ehre streite:", "tokens": ["\u201e", "da\u00df", "ich", "um", "des\u00b7sen", "Rang", ",", "Be\u00b7siz", "und", "Eh\u00b7re", "strei\u00b7te", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "APPR", "PRELAT", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eweil ich mir nichts dadurch zu gr\u00f6sserm Ansehn weihte.", "tokens": ["\u201e", "weil", "ich", "mir", "nichts", "da\u00b7durch", "zu", "gr\u00f6s\u00b7serm", "An\u00b7sehn", "weih\u00b7te", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPER", "PIS", "PAV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eund nichts den Ruhm, womit ", "tokens": ["\u201e", "und", "nichts", "den", "Ruhm", ",", "wo\u00b7mit"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word"], "pos": ["$(", "KON", "PIS", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "\u201eso f\u00e4llt mir auch nicht ein dem Friese nachzustreben,", "tokens": ["\u201e", "so", "f\u00e4llt", "mir", "auch", "nicht", "ein", "dem", "Frie\u00b7se", "nach\u00b7zu\u00b7stre\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ART", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201ees kann der Majest\u00e4t kein h\u00f6hers Wesen geben:", "tokens": ["\u201e", "es", "kann", "der", "Ma\u00b7jes\u00b7t\u00e4t", "kein", "h\u00f6\u00b7hers", "We\u00b7sen", "ge\u00b7ben", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ART", "NN", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201e", "tokens": ["\u201e"], "token_info": ["punct"], "pos": ["$("]}, "line.9": {"text": "\u201ehingegen pfleg\u2019 ich auch ihr Haupt empor zu schwingen,", "tokens": ["\u201e", "hin\u00b7ge\u00b7gen", "pfleg'", "ich", "auch", "ihr", "Haupt", "em\u00b7por", "zu", "schwin\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "\u201ewie ich davon gar leicht k\u00f6nnt tausend Proben bringen;", "tokens": ["\u201e", "wie", "ich", "da\u00b7von", "gar", "leicht", "k\u00f6nnt", "tau\u00b7send", "Pro\u00b7ben", "brin\u00b7gen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "PAV", "ADV", "ADJD", "VVFIN", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eallein ich trage nichts als einen Umstand vor:", "tokens": ["\u201e", "al\u00b7lein", "ich", "tra\u00b7ge", "nichts", "als", "ei\u00b7nen", "Um\u00b7stand", "vor", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPER", "VVFIN", "PIS", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201evon diesem stammt ihr Heil, Gl\u00fcck, Ansehn, Ruhm und Flor.", "tokens": ["\u201e", "von", "die\u00b7sem", "stammt", "ihr", "Heil", ",", "Gl\u00fcck", ",", "An\u00b7sehn", ",", "Ruhm", "und", "Flor", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "VVFIN", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201esonst h\u00e4tt es ihr vielleicht noch mehr an Hilff gefehlet.", "tokens": ["\u201e", "sonst", "h\u00e4tt", "es", "ihr", "viel\u00b7leicht", "noch", "mehr", "an", "Hilff", "ge\u00b7feh\u00b7let", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PPER", "ADV", "ADV", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eich wies ihr den Entwurff des aufgedrungnen Kriegs,", "tokens": ["\u201e", "ich", "wies", "ihr", "den", "Ent\u00b7wurff", "des", "auf\u00b7ge\u00b7drung\u00b7nen", "Kriegs", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201eden Weeg zur Gegenwehr, die M\u00f6glichkeit des Siegs.", "tokens": ["\u201e", "den", "Weeg", "zur", "Ge\u00b7gen\u00b7wehr", ",", "die", "M\u00f6g\u00b7lich\u00b7keit", "des", "Siegs", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201eerinnert euch der Zeit, des Orts und jener Thaten,", "tokens": ["\u201e", "e\u00b7rin\u00b7nert", "euch", "der", "Zeit", ",", "des", "Orts", "und", "je\u00b7ner", "Tha\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "NN", "KON", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201ebetrachtet nur den Pomp der ersten K\u00f6nigs-Pracht,", "tokens": ["\u201e", "be\u00b7trach\u00b7tet", "nur", "den", "Pomp", "der", "ers\u00b7ten", "K\u00f6\u00b7nigs\u00b7Pracht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201emit der sie sich so werth und Welt-beliebt gemacht;", "tokens": ["\u201e", "mit", "der", "sie", "sich", "so", "werth", "und", "Welt\u00b7be\u00b7liebt", "ge\u00b7macht", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PRELS", "PPER", "PRF", "ADV", "ADJD", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201eals auf dem K\u00f6nigs-Berg sie gleich dem gr\u00f6sten Helden", "tokens": ["\u201e", "als", "auf", "dem", "K\u00f6\u00b7nigs\u00b7Berg", "sie", "gleich", "dem", "gr\u00f6s\u00b7ten", "Hel\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "APPR", "ART", "NN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "\u201egewafnet angezeigt, was einst von ihr zu melden;", "tokens": ["\u201e", "ge\u00b7waf\u00b7net", "an\u00b7ge\u00b7zeigt", ",", "was", "einst", "von", "ihr", "zu", "mel\u00b7den", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVPP", "$,", "PRELS", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "\u201eder von derselben Stund und von demselben Wall", "tokens": ["\u201e", "der", "von", "der\u00b7sel\u00b7ben", "Stund", "und", "von", "dem\u00b7sel\u00b7ben", "Wall"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "APPR", "PDAT", "NN", "KON", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "\u201efast durch die gantze Welt sich pl\u00f6zlich ausgebreitet;", "tokens": ["\u201e", "fast", "durch", "die", "gant\u00b7ze", "Welt", "sich", "pl\u00f6z\u00b7lich", "aus\u00b7ge\u00b7brei\u00b7tet", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "ART", "ADJA", "NN", "PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "\u201edas hat die Majest\u00e4t, ich, meine Macht bereitet.", "tokens": ["\u201e", "das", "hat", "die", "Ma\u00b7jes\u00b7t\u00e4t", ",", "ich", ",", "mei\u00b7ne", "Macht", "be\u00b7rei\u00b7tet", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "$,", "PPER", "$,", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u201edie Folg\u2019 ist euch bekannt; hie\u00df es nicht: Leib und Blut", "tokens": ["\u201e", "die", "Fol\u00b7g'", "ist", "euch", "be\u00b7kannt", ";", "hie\u00df", "es", "nicht", ":", "Leib", "und", "Blut"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VAFIN", "PPER", "ADJD", "$.", "VVFIN", "PPER", "PTKNEG", "$.", "NN", "KON", "NN"], "meter": "-+-+--++--+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "\u201esey dieser Frau geschenckt? man wolle sie besch\u00fctzen,", "tokens": ["\u201e", "sey", "die\u00b7ser", "Frau", "ge\u00b7schenckt", "?", "man", "wol\u00b7le", "sie", "be\u00b7sch\u00fct\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PDAT", "NN", "VVPP", "$.", "PIS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "\u201eund eh der Feinde Faust mit eignem Blut bespritzen", "tokens": ["\u201e", "und", "eh", "der", "Fein\u00b7de", "Faust", "mit", "eig\u00b7nem", "Blut", "be\u00b7sprit\u00b7zen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "KOUS", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "\u201eals leiden, da\u00df man ihr nur einen Stein der Kron", "tokens": ["\u201e", "als", "lei\u00b7den", ",", "da\u00df", "man", "ihr", "nur", "ei\u00b7nen", "Stein", "der", "Kron"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "VVINF", "$,", "KOUS", "PIS", "PPER", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "\u201everr\u00fccket sehen soll; war dieses nicht der Thon?", "tokens": ["\u201e", "ver\u00b7r\u00fc\u00b7cket", "se\u00b7hen", "soll", ";", "war", "die\u00b7ses", "nicht", "der", "Thon", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "VVINF", "VMFIN", "$.", "VAFIN", "PDS", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "\u201eworauf der Helden F\u00fcrst, ja dessen gantzer Orden", "tokens": ["\u201e", "wo\u00b7rauf", "der", "Hel\u00b7den", "F\u00fcrst", ",", "ja", "des\u00b7sen", "gant\u00b7zer", "Or\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "ART", "NN", "NN", "$,", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "\u201emit ihr sich schlagen soll? Sie sa\u00df in Majest\u00e4t,", "tokens": ["\u201e", "mit", "ihr", "sich", "schla\u00b7gen", "soll", "?", "Sie", "sa\u00df", "in", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPER", "PRF", "VVINF", "VMFIN", "$.", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "\u201edas Reichs-Schwert in der Hand, auf einem Pferd erh\u00f6ht;", "tokens": ["\u201e", "das", "Reichs\u00b7Schwert", "in", "der", "Hand", ",", "auf", "ei\u00b7nem", "Pferd", "er\u00b7h\u00f6ht", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "\u201ewie wann von jedem Theil der Welt Gefahr erschiene,", "tokens": ["\u201e", "wie", "wann", "von", "je\u00b7dem", "Theil", "der", "Welt", "Ge\u00b7fahr", "er\u00b7schie\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWAV", "APPR", "PIAT", "NN", "ART", "NN", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "\u201eich r\u00fchme kein Ger\u00fccht; man hatte wohl gesp\u00fchrt,", "tokens": ["\u201e", "ich", "r\u00fch\u00b7me", "kein", "Ge\u00b7r\u00fccht", ";", "man", "hat\u00b7te", "wohl", "ge\u00b7sp\u00fchrt", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "$.", "PIS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "\u201eda\u00df wahrer Helden-Muth allda den Degen f\u00fchrt.", "tokens": ["\u201e", "da\u00df", "wah\u00b7rer", "Hel\u00b7den\u00b7Muth", "all\u00b7da", "den", "De\u00b7gen", "f\u00fchrt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADJA", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "\u201esie ritte so behertzt und hieb so schwere Streiche,", "tokens": ["\u201e", "sie", "rit\u00b7te", "so", "be\u00b7hertzt", "und", "hieb", "so", "schwe\u00b7re", "Strei\u00b7che", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ADJD", "KON", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "\u201eda\u00df ihr Geth\u00f6n und Klang durch viele Konigreiche", "tokens": ["\u201e", "da\u00df", "ihr", "Ge\u00b7th\u00f6n", "und", "Klang", "durch", "vie\u00b7le", "Ko\u00b7ni\u00b7grei\u00b7che"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPOSAT", "NN", "KON", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "\u201eauf der man Heil und Ehr, und Sieg erfechten kann.", "tokens": ["\u201e", "auf", "der", "man", "Heil", "und", "Ehr", ",", "und", "Sieg", "er\u00b7fech\u00b7ten", "kann", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PRELS", "PIS", "NN", "KON", "NN", "$,", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "\u201ejhr Majest\u00e4tisches, niemahls gepflognes Reiten", "tokens": ["\u201e", "jhr", "Ma\u00b7jes\u00b7t\u00e4\u00b7ti\u00b7sches", ",", "nie\u00b7mahls", "ge\u00b7pflog\u00b7nes", "Rei\u00b7ten"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "$,", "ADV", "ADJA", "NN"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.39": {"text": "\u201efieng dorten an, dem Volck ihr Siegen vorzudeuten.", "tokens": ["\u201e", "fi\u00b7eng", "dor\u00b7ten", "an", ",", "dem", "Volck", "ihr", "Sie\u00b7gen", "vor\u00b7zu\u00b7deu\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PTKVZ", "$,", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.40": {"text": "\u201ewer sahe dort nicht vor, wie sie das Vaterland", "tokens": ["\u201e", "wer", "sa\u00b7he", "dort", "nicht", "vor", ",", "wie", "sie", "das", "Va\u00b7ter\u00b7land"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWS", "VVFIN", "ADV", "PTKNEG", "PTKVZ", "$,", "PWAV", "PPER", "ART", "NN"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.41": {"text": "\u201ejm Heil befestigen, im Gl\u00fcck beherrschen werde?", "tokens": ["\u201e", "jm", "Heil", "be\u00b7fes\u00b7ti\u00b7gen", ",", "im", "Gl\u00fcck", "be\u00b7herr\u00b7schen", "wer\u00b7de", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "NN", "VVINF", "$,", "APPRART", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "\u201eda\u00df es geschehen sey, bekennt der Krei\u00df der Erde.", "tokens": ["\u201e", "da\u00df", "es", "ge\u00b7sche\u00b7hen", "sey", ",", "be\u00b7kennt", "der", "Krei\u00df", "der", "Er\u00b7de", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VVPP", "VAFIN", "$,", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "\u201ewir wissen was der Feind vor Mienen springen lie\u00df,", "tokens": ["\u201e", "wir", "wis\u00b7sen", "was", "der", "Feind", "vor", "Mie\u00b7nen", "sprin\u00b7gen", "lie\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PWS", "ART", "NN", "APPR", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "\u201ewie sie das Vaterland der Wuth des Gl\u00fccks entri\u00df.", "tokens": ["\u201e", "wie", "sie", "das", "Va\u00b7ter\u00b7land", "der", "Wuth", "des", "Gl\u00fccks", "ent\u00b7ri\u00df", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "\u201ewo man zum ersten Mahl derselben Hoheit priese!", "tokens": ["\u201e", "wo", "man", "zum", "ers\u00b7ten", "Mahl", "der\u00b7sel\u00b7ben", "Ho\u00b7heit", "prie\u00b7se", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "APPRART", "ADJA", "NN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "\u201eschrie nicht das frohe Volck: Begl\u00fccktes K\u00f6nigreich!", "tokens": ["\u201e", "schrie", "nicht", "das", "fro\u00b7he", "Volck", ":", "Be\u00b7gl\u00fcck\u00b7tes", "K\u00f6\u00b7nig\u00b7reich", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "\u201eder F\u00fcrstinn Ankunfft ist der Morgenr\u00f6the gleich!", "tokens": ["\u201e", "der", "F\u00fcrs\u00b7tinn", "An\u00b7kunfft", "ist", "der", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", "gleich", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "\u201ewie? rieff man da: ", "tokens": ["\u201e", "wie", "?", "rieff", "man", "da", ":"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$.", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.49": {"text": "\u201eauf Br\u00fcder zum Gewehr! wann ihr nach Wohlfart strebt!", "tokens": ["\u201e", "auf", "Br\u00fc\u00b7der", "zum", "Ge\u00b7wehr", "!", "wann", "ihr", "nach", "Wohl\u00b7fart", "strebt", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "APPRART", "NN", "$.", "PWAV", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "\u201ewir wollen durch den Stahl, der unsern Muth belebt,", "tokens": ["\u201e", "wir", "wol\u00b7len", "durch", "den", "Stahl", ",", "der", "un\u00b7sern", "Muth", "be\u00b7lebt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "\u201eder Feinde Troz zu Troz als K\u00f6nig sie behaupten;", "tokens": ["\u201e", "der", "Fein\u00b7de", "Troz", "zu", "Troz", "als", "K\u00f6\u00b7nig", "sie", "be\u00b7haup\u00b7ten", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "APPR", "NE", "KOUS", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "\u201ewann wir uns auch dadurch von Gut und Blut beraubten.", "tokens": ["\u201e", "wann", "wir", "uns", "auch", "da\u00b7durch", "von", "Gut", "und", "Blut", "be\u00b7raub\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "PRF", "ADV", "PAV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}