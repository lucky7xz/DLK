{"dta.poem.10842": {"metadata": {"author": {"name": "Ebeling, Johann Justus", "birth": "N.A.", "death": "N.A."}, "title": "Das  \n wundernsw\u00fcrdige Verh\u00e4ltnis  \n der Theile des menschlichen K\u00f6rpers,  \n welches sie gegen einander  \n haben.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1747", "urn": "urn:nbn:de:kobv:b4-200905198774", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df unser K\u00f6rper sey des Sch\u00f6pfers\nMeisterst\u00fck", "tokens": ["Da\u00df", "un\u00b7ser", "K\u00f6r\u00b7per", "sey", "des", "Sch\u00f6p\u00b7fers", "Meis\u00b7ter\u00b7st\u00fck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Draus seine Weisheit strahlt, lehrt", "tokens": ["Draus", "sei\u00b7ne", "Weis\u00b7heit", "strahlt", ",", "lehrt"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PAV", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Ordnung, Lage, Gr\u00f6\u00df von", "tokens": ["Die", "Ord\u00b7nung", ",", "La\u00b7ge", ",", "Gr\u00f6\u00df", "von"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "$,", "NN", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die an dem Leibe ist. Wenn wir", "tokens": ["Die", "an", "dem", "Lei\u00b7be", "ist", ".", "Wenn", "wir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VAFIN", "$.", "KOUS", "PPER"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wie herrlich im Gesicht, die Theile sind gefa\u00dft,", "tokens": ["Wie", "herr\u00b7lich", "im", "Ge\u00b7sicht", ",", "die", "Thei\u00b7le", "sind", "ge\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "APPRART", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nach der Proportion so weislich abgepa\u00dft;", "tokens": ["Nach", "der", "Pro\u00b7por\u00b7ti\u00b7on", "so", "weis\u00b7lich", "ab\u00b7ge\u00b7pa\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Wie sich der Kopf und Leib nach L\u00e4ng und Breit", "tokens": ["Wie", "sich", "der", "Kopf", "und", "Leib", "nach", "L\u00e4ng", "und", "Breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "ART", "NN", "KON", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "So merkt man sichtbarlich des Sch\u00f6pfers weises", "tokens": ["So", "merkt", "man", "sicht\u00b7bar\u00b7lich", "des", "Sch\u00f6p\u00b7fers", "wei\u00b7ses"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "ART", "NN", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Das bei der Bildung wacht; Sieht man wie wir", "tokens": ["Das", "bei", "der", "Bil\u00b7dung", "wacht", ";", "Sieht", "man", "wie", "wir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$.", "VVFIN", "PIS", "KOKOM", "PPER"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und wie des Leibes Bau so richtig aufgef\u00fchrt,", "tokens": ["Und", "wie", "des", "Lei\u00b7bes", "Bau", "so", "rich\u00b7tig", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie Regelm\u00e4\u00dfig sich ein Glied zum andern schik-", "tokens": ["Wie", "Re\u00b7gel\u00b7m\u00e4\u00b7\u00dfig", "sich", "ein", "Glied", "zum", "an\u00b7dern", "schi\u00b7k"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PRF", "ART", "NN", "APPRART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So ist des Meisters Bild auch darin abgedr\u00fck-", "tokens": ["So", "ist", "des", "Meis\u00b7ters", "Bild", "auch", "da\u00b7rin", "ab\u00b7ge\u00b7dr\u00fc\u00b7k"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "ADV", "PAV", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Es scheint als wenn der Mensch, wenn man ihm", "tokens": ["Es", "scheint", "als", "wenn", "der", "Mensch", ",", "wenn", "man", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "KOUS", "ART", "NN", "$,", "KOUS", "PIS", "PPER"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.14": {"text": "Nach einen Zirkelschlag und Masstab sey gemacht;", "tokens": ["Nach", "ei\u00b7nen", "Zir\u00b7kel\u00b7schlag", "und", "Mass\u00b7tab", "sey", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dies lehrt uns da\u00df ein ", "tokens": ["Dies", "lehrt", "uns", "da\u00df", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "KOUS", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.16": {"text": "Man seh den Leib nur an; aus allen kan man ken-", "tokens": ["Man", "seh", "den", "Leib", "nur", "an", ";", "aus", "al\u00b7len", "kan", "man", "ken"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$.", "APPR", "PIS", "VMFIN", "PIS", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Da\u00df uns ein weiser HErr zum Sch\u00f6nheits Bild", "tokens": ["Da\u00df", "uns", "ein", "wei\u00b7ser", "Herr", "zum", "Sch\u00f6n\u00b7heits", "Bild"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPRART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Jhr Zweifler! die ihr dies nicht wollet eingestehn;", "tokens": ["Ihr", "Zweif\u00b7ler", "!", "die", "ihr", "dies", "nicht", "wol\u00b7let", "ein\u00b7ge\u00b7stehn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PRELS", "PPER", "PDS", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sagt: Ob ein Ohngefehr so Kunstreich uns gef\u00fc-", "tokens": ["Sagt", ":", "Ob", "ein", "Ohn\u00b7ge\u00b7fehr", "so", "Kuns\u00b7treich", "uns", "ge\u00b7f\u00fc"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "KOUS", "ART", "NN", "ADV", "ADJD", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Das Haupt und Leib und Fu\u00df nach dem Verh\u00e4lt-", "tokens": ["Das", "Haupt", "und", "Leib", "und", "Fu\u00df", "nach", "dem", "Ver\u00b7h\u00e4l\u00b7t"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "KON", "NN", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Wenn ihr euch dieses k\u00fchn zu sagen noch getraut;", "tokens": ["Wenn", "ihr", "euch", "die\u00b7ses", "k\u00fchn", "zu", "sa\u00b7gen", "noch", "ge\u00b7traut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PDAT", "ADJD", "PTKZU", "VVINF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "So glaubet ihr auch leicht, ein Haus das sch\u00f6n ge-", "tokens": ["So", "glau\u00b7bet", "ihr", "auch", "leicht", ",", "ein", "Haus", "das", "sch\u00f6n", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "$,", "ART", "NN", "ART", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "K\u00f6rpers ausgemessen, bemerken, da\u00df einjeder sechs-\nmahl l\u00e4nger sey, als er breit ist, zehnmahl so lang\nals er auf seiner Brust dik ist, viermahl so lang, als\nseine Hand bis an den Ellenbogen reichet. Eben so\nlang, als er mit seinem beiden Armen abspannen kan.\nEin jeder Mensch ist sechsmahl so lang als sein Fu\u00df\nist, vier und zwanzigmahl so lang, als seine ausge-\nstrekte platte Hand, zwei und siebenzigmahl so lang,\nals sein Daumen breit ist, sechs und neunzigmahl so lang\nals sein Finger breit ist u. s. w. Es kommen also mehr\nals hundert tausend Verh\u00e4ltnisse des einen Gliedes\nan den K\u00f6rper gegen das andre heraus, wenn man\nsie alle ausrechnen wolte. Und diese sind bey allen ge-\nsund gebohrnen Menschen richtig, und treffen durch-\ngehends sehr genaue ein.", "tokens": ["K\u00f6r\u00b7pers", "aus\u00b7ge\u00b7mes\u00b7sen", ",", "be\u00b7mer\u00b7ken", ",", "da\u00df", "ein\u00b7je\u00b7der", "sechs", "mahl", "l\u00e4n\u00b7ger", "sey", ",", "als", "er", "breit", "ist", ",", "zehn\u00b7mahl", "so", "lang", "als", "er", "auf", "sei\u00b7ner", "Brust", "dik", "ist", ",", "vier\u00b7mahl", "so", "lang", ",", "als", "sei\u00b7ne", "Hand", "bis", "an", "den", "El\u00b7len\u00b7bo\u00b7gen", "rei\u00b7chet", ".", "E\u00b7ben", "so", "lang", ",", "als", "er", "mit", "sei\u00b7nem", "bei\u00b7den", "Ar\u00b7men", "ab\u00b7span\u00b7nen", "kan", ".", "Ein", "je\u00b7der", "Mensch", "ist", "sechs\u00b7mahl", "so", "lang", "als", "sein", "Fu\u00df", "ist", ",", "vier", "und", "zwan\u00b7zig\u00b7mahl", "so", "lang", ",", "als", "sei\u00b7ne", "aus\u00b7ge", "strek\u00b7te", "plat\u00b7te", "Hand", ",", "zwei", "und", "sie\u00b7ben\u00b7zig\u00b7mahl", "so", "lang", ",", "als", "sein", "Dau\u00b7men", "breit", "ist", ",", "sechs", "und", "neun\u00b7zig\u00b7mahl", "so", "lang", "als", "sein", "Fin\u00b7ger", "breit", "ist", "u.", "s.", "w.", "Es", "kom\u00b7men", "al\u00b7so", "mehr", "als", "hun\u00b7dert", "tau\u00b7send", "Ver\u00b7h\u00e4lt\u00b7nis\u00b7se", "des", "ei\u00b7nen", "Glie\u00b7des", "an", "den", "K\u00f6r\u00b7per", "ge\u00b7gen", "das", "and\u00b7re", "he\u00b7raus", ",", "wenn", "man", "sie", "al\u00b7le", "aus\u00b7rech\u00b7nen", "wol\u00b7te", ".", "Und", "die\u00b7se", "sind", "bey", "al\u00b7len", "ge", "sund", "ge\u00b7bohr\u00b7nen", "Men\u00b7schen", "rich\u00b7tig", ",", "und", "tref\u00b7fen", "durch", "ge\u00b7hends", "sehr", "ge\u00b7nau\u00b7e", "ein", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation", "abbreviation", "abbreviation", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "VVINF", "$,", "KOUS", "ART", "TRUNC", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "ADV", "ADV", "ADJD", "KOKOM", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "VAFIN", "$,", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVFIN", "$.", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "PIAT", "NN", "VVINF", "VMFIN", "$.", "ART", "PIAT", "NN", "VAFIN", "ADV", "ADV", "ADJD", "KOKOM", "PPOSAT", "NN", "VAFIN", "$,", "CARD", "KON", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPOSAT", "TRUNC", "VVFIN", "ADJA", "NN", "$,", "CARD", "KON", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "ADJD", "VAFIN", "$,", "CARD", "KON", "ADV", "ADV", "ADJD", "KOKOM", "PPOSAT", "NN", "ADJD", "VAFIN", "APPR", "VVIMP", "NN", "PPER", "VVFIN", "ADV", "PIAT", "KOKOM", "CARD", "CARD", "NN", "ART", "ART", "NN", "APPR", "ART", "NN", "APPR", "ART", "ADJA", "PTKVZ", "$,", "KOUS", "PIS", "PPER", "PIS", "VVINF", "VMFIN", "$.", "KON", "PDS", "VAFIN", "APPR", "PIAT", "TRUNC", "KON", "ADJA", "NN", "ADJD", "$,", "KON", "VVINF", "TRUNC", "NN", "ADV", "ADJA", "PTKVZ", "$."], "meter": "+-+-+------+-+-+-+--+-+--+-+-+-+--+--+-+-+-+-+-+-+-+--+-+-+-+-+-+--+-+-+-+--+--+-+-+-+-+-+-+-+-+-+--+--+-+--+-+-+-+-+-+--+-+--+-+-+-+-+--+-+-+-+-+-+-+--+--+---+--+-+-----+---+-+-+-+--+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.24": {"text": "Sey von sich selbst gemacht. Habt ihr das je gese-", "tokens": ["Sey", "von", "sich", "selbst", "ge\u00b7macht", ".", "Habt", "ihr", "das", "je", "ge\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PRF", "ADV", "VVPP", "$.", "VAFIN", "PPER", "PDS", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Kan aus der Unordnung von selbst die Ordnung ge-", "tokens": ["Kan", "aus", "der", "Un\u00b7ord\u00b7nung", "von", "selbst", "die", "Ord\u00b7nung", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "APPR", "ADV", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Jhr Thoren sch\u00e4met euch, ihr wollet weise seyn,", "tokens": ["Ihr", "Tho\u00b7ren", "sch\u00e4\u00b7met", "euch", ",", "ihr", "wol\u00b7let", "wei\u00b7se", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,", "PPER", "VMFIN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie reimt sich dieser Schlus mit euch? sehr unge-", "tokens": ["Wie", "reimt", "sich", "die\u00b7ser", "Schlus", "mit", "euch", "?", "sehr", "un\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "VVFIN", "PRF", "PDAT", "NN", "APPR", "PPER", "$.", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Jhr meint ein weiser mu\u00df was sonderbahr erfinden;", "tokens": ["Ihr", "meint", "ein", "wei\u00b7ser", "mu\u00df", "was", "son\u00b7der\u00b7bahr", "er\u00b7fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "VMFIN", "PWS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Drum wollet ihr ein Nichts, und Etwas auch ver-", "tokens": ["Drum", "wol\u00b7let", "ihr", "ein", "Nichts", ",", "und", "Et\u00b7was", "auch", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PPER", "ART", "PIS", "$,", "KON", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}