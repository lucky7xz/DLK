{"textgrid.poem.41273": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Seltsamer Zorn des Cleons", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des Cleons spanisch Rohr, der R\u00e4cher seiner Ehre,", "tokens": ["Des", "Cleons", "spa\u00b7nisch", "Rohr", ",", "der", "R\u00e4\u00b7cher", "sei\u00b7ner", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-++-+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Gab einem L\u00e4sterer empfindlich Unterricht.", "tokens": ["Gab", "ei\u00b7nem", "L\u00e4s\u00b7te\u00b7rer", "emp\u00b7find\u00b7lich", "Un\u00b7ter\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sinnlich demonstrirt die Lehre,", "tokens": ["Wie", "sinn\u00b7lich", "de\u00b7mons\u00b7trirt", "die", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Die fast des Sch\u00fclers R\u00fcckgrad bricht!", "tokens": ["Die", "fast", "des", "Sch\u00fc\u00b7lers", "R\u00fcck\u00b7grad", "bricht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wol zehnmal schrie der B\u00f6sewicht:", "tokens": ["Wol", "zehn\u00b7mal", "schrie", "der", "B\u00f6\u00b7se\u00b7wicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Herr, hab' ich Sie verleumd't; so sterb' ich auf der Stelle!", "tokens": ["Herr", ",", "hab'", "ich", "Sie", "ver\u00b7leumd't", ";", "so", "sterb'", "ich", "auf", "der", "Stel\u00b7le", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "PPER", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch Cleon gerbet fort und spricht:", "tokens": ["Doch", "Cle\u00b7on", "ger\u00b7bet", "fort", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wei\u00df ich schon, du sauberer Geselle;", "tokens": ["Das", "wei\u00df", "ich", "schon", ",", "du", "sau\u00b7be\u00b7rer", "Ge\u00b7sel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Doch lobtest du mich gestern nicht?", "tokens": ["Doch", "lob\u00b7test", "du", "mich", "ge\u00b7stern", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "PTKNEG", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Des Cleons spanisch Rohr, der R\u00e4cher seiner Ehre,", "tokens": ["Des", "Cleons", "spa\u00b7nisch", "Rohr", ",", "der", "R\u00e4\u00b7cher", "sei\u00b7ner", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-++-+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Gab einem L\u00e4sterer empfindlich Unterricht.", "tokens": ["Gab", "ei\u00b7nem", "L\u00e4s\u00b7te\u00b7rer", "emp\u00b7find\u00b7lich", "Un\u00b7ter\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sinnlich demonstrirt die Lehre,", "tokens": ["Wie", "sinn\u00b7lich", "de\u00b7mons\u00b7trirt", "die", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Die fast des Sch\u00fclers R\u00fcckgrad bricht!", "tokens": ["Die", "fast", "des", "Sch\u00fc\u00b7lers", "R\u00fcck\u00b7grad", "bricht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wol zehnmal schrie der B\u00f6sewicht:", "tokens": ["Wol", "zehn\u00b7mal", "schrie", "der", "B\u00f6\u00b7se\u00b7wicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Herr, hab' ich Sie verleumd't; so sterb' ich auf der Stelle!", "tokens": ["Herr", ",", "hab'", "ich", "Sie", "ver\u00b7leumd't", ";", "so", "sterb'", "ich", "auf", "der", "Stel\u00b7le", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "PPER", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch Cleon gerbet fort und spricht:", "tokens": ["Doch", "Cle\u00b7on", "ger\u00b7bet", "fort", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wei\u00df ich schon, du sauberer Geselle;", "tokens": ["Das", "wei\u00df", "ich", "schon", ",", "du", "sau\u00b7be\u00b7rer", "Ge\u00b7sel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Doch lobtest du mich gestern nicht?", "tokens": ["Doch", "lob\u00b7test", "du", "mich", "ge\u00b7stern", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "PTKNEG", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}