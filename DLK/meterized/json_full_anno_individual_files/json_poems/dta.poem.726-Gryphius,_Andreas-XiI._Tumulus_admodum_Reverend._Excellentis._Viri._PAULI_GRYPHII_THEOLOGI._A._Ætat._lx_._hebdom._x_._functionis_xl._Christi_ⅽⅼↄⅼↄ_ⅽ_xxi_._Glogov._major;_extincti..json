{"dta.poem.726": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XiI.  Tumulus admodum Reverend. Excellentis. Viri.  \n PAULI GRYPHII THEOLOGI.  \n A. \u00c6tat.  lx . hebdom.  x . functionis  xl. Christi  \n \u217d\u217c\u2184\u217c\u2184 \u217d  xxi . Glogov. major; extincti.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Der Christum frey bekand/ vnd seine stim\u0303 erhoben ", "tokens": ["Der", "Chris\u00b7tum", "frey", "be\u00b7kand", "/", "vnd", "sei\u00b7ne", "stim\u0303", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$(", "KON", "PPOSAT", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gleich einer ", "tokens": ["Gleich", "ei\u00b7ner"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Eh als die blutt Trompett au\u00df seines grimmes Zelt", "tokens": ["Eh", "als", "die", "blutt", "Trom\u00b7pett", "au\u00df", "sei\u00b7nes", "grim\u00b7mes", "Zelt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "ADJD", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Erschall\u2019 eh\u2019 als sein grimm so scharff anfing zu toben.", "tokens": ["Er\u00b7schall'", "eh'", "als", "sein", "grimm", "so", "scharff", "an\u00b7fing", "zu", "to\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOKOM", "PPOSAT", "ADJD", "ADV", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Hier ruht sein m\u00fcder Leib gantz sicher/ bi\u00df von oben", "tokens": ["Hier", "ruht", "sein", "m\u00fc\u00b7der", "Leib", "gantz", "si\u00b7cher", "/", "bi\u00df", "von", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "$(", "ADV", "APPR", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Printz einbrechen wird/ dem jeder vorgestelt ", "tokens": ["Der", "Printz", "ein\u00b7bre\u00b7chen", "wird", "/", "dem", "je\u00b7der", "vor\u00b7ge\u00b7stelt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VAFIN", "$(", "ART", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Sol werden/ den der Tod in seinen armen h\u00e4lt/", "tokens": ["Sol", "wer\u00b7den", "/", "den", "der", "Tod", "in", "sei\u00b7nen", "ar\u00b7men", "h\u00e4lt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "$(", "ART", "ART", "NN", "APPR", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Seel ist schon bey den die Gott dort ewig loben.", "tokens": ["Die", "Seel", "ist", "schon", "bey", "den", "die", "Gott", "dort", "e\u00b7wig", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ART", "ART", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Sie wartet auf die Cron/ mit der jhr trewer fleis/", "tokens": ["Sie", "war\u00b7tet", "auf", "die", "Cron", "/", "mit", "der", "jhr", "tre\u00b7wer", "fleis", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "APPR", "PRELS", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Jhr lehren/ jhre m\u00fch\u2019 jhr k\u00e4mpfen/ angst vnd schweis/", "tokens": ["Ihr", "leh\u00b7ren", "/", "jhre", "m\u00fch'", "jhr", "k\u00e4mp\u00b7fen", "/", "angst", "vnd", "schweis", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$(", "PPOSAT", "VMFIN", "PPER", "VVINF", "$(", "VVPP", "KON", "ADJD", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Jhr eyfer welcher nie der frechen laster schonet:", "tokens": ["Ihr", "ey\u00b7fer", "wel\u00b7cher", "nie", "der", "fre\u00b7chen", "las\u00b7ter", "scho\u00b7net", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRELS", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Jhr wissen/ da\u00df sie nur zu Gottes Ehr anwandt. ", "tokens": ["Ihr", "wis\u00b7sen", "/", "da\u00df", "sie", "nur", "zu", "Got\u00b7tes", "Ehr", "an\u00b7wandt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$(", "KOUS", "PPER", "ADV", "APPR", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jhr leiden/ das sie dem/ der vor sie lied verbandt", "tokens": ["Ihr", "lei\u00b7den", "/", "das", "sie", "dem", "/", "der", "vor", "sie", "lied", "ver\u00b7bandt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVINF", "$(", "PRELS", "PPER", "ART", "$(", "ART", "APPR", "PPER", "VVFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd keinen lohn gesucht/ wird \u00fcber lohn/ belohnet.", "tokens": ["Vnd", "kei\u00b7nen", "lohn", "ge\u00b7sucht", "/", "wird", "\u00fc\u00b7ber", "lohn", "/", "be\u00b7loh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$(", "VAFIN", "APPR", "NN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}