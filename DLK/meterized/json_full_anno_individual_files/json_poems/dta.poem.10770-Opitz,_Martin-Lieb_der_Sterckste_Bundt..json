{"dta.poem.10770": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Lieb der Sterckste Bundt.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "La\u00df B\u00fcndnu\u00df B\u00fcndnu\u00df sein/ die grossen Herrn behagen/", "tokens": ["La\u00df", "B\u00fcnd\u00b7nu\u00df", "B\u00fcnd\u00b7nu\u00df", "sein", "/", "die", "gros\u00b7sen", "Herrn", "be\u00b7ha\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "NN", "VAINF", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da Land vnd Land wird eins/ sich friedlich zu betragen/", "tokens": ["Da", "Land", "vnd", "Land", "wird", "eins", "/", "sich", "fried\u00b7lich", "zu", "be\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VAFIN", "PIS", "$(", "PRF", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd da man Gut vnd Blut zusamen setzen wil/", "tokens": ["Vnd", "da", "man", "Gut", "vnd", "Blut", "zu\u00b7sa\u00b7men", "set\u00b7zen", "wil", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADJD", "KON", "NN", "VVINF", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo etwan einer k\u00e4m/ dem Vehd vnd Krieg gefiel.", "tokens": ["Wo", "et\u00b7wan", "ei\u00b7ner", "k\u00e4m", "/", "dem", "Vehd", "vnd", "Krieg", "ge\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "$(", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es ist ein zweifflich ding/ vff B\u00fcndnu\u00df sich verlassen/", "tokens": ["Es", "ist", "ein", "zweif\u00b7flich", "ding", "/", "vff", "B\u00fcnd\u00b7nu\u00df", "sich", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$(", "APPR", "NN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dieselbe brechen offt/ gantz vnverhoffter massen/", "tokens": ["Die\u00b7sel\u00b7be", "bre\u00b7chen", "offt", "/", "gantz", "vn\u00b7ver\u00b7hoff\u00b7ter", "mas\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "ADV", "$(", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wen findstu der da halt/ was er dir hat geschworn?", "tokens": ["Wen", "finds\u00b7tu", "der", "da", "halt", "/", "was", "er", "dir", "hat", "ge\u00b7schworn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADV", "VVFIN", "$(", "PWS", "PPER", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du suchst jhn dann bey denn/ die vor vns warn geborn.", "tokens": ["Du", "suchst", "jhn", "dann", "bey", "denn", "/", "die", "vor", "vns", "warn", "ge\u00b7born", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "KON", "$(", "ART", "APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Bi\u00dfweilen drennt die Forcht was einmal ist verglichen/", "tokens": ["Bi\u00df\u00b7wei\u00b7len", "drennt", "die", "Forcht", "was", "ein\u00b7mal", "ist", "ver\u00b7gli\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PWS", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bi\u00dfweilen macht das Gelt/ durch B\u00fcndnu\u00df einen strichen/", "tokens": ["Bi\u00df\u00b7wei\u00b7len", "macht", "das", "Gelt", "/", "durch", "B\u00fcnd\u00b7nu\u00df", "ei\u00b7nen", "stri\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "APPR", "NN", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Bi\u00dfweilen vngl\u00fcck auch dieselbe schneid entzwey/", "tokens": ["Bi\u00df\u00b7wei\u00b7len", "vn\u00b7gl\u00fcck", "auch", "die\u00b7sel\u00b7be", "schneid", "ent\u00b7zwey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PDAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So bald Gefahr sich regt/ seind B\u00fcndnu\u00df wie ein Ey.", "tokens": ["So", "bald", "Ge\u00b7fahr", "sich", "regt", "/", "seind", "B\u00fcnd\u00b7nu\u00df", "wie", "ein", "Ey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "PRF", "VVFIN", "$(", "VAFIN", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das ist ein vester Bund/ da sich die Lieb gesellet/", "tokens": ["Das", "ist", "ein", "ves\u00b7ter", "Bund", "/", "da", "sich", "die", "Lieb", "ge\u00b7sel\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "KOUS", "PRF", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da sich die Liebe selbst f\u00fcr einen Zeugen stellet/", "tokens": ["Da", "sich", "die", "Lie\u00b7be", "selbst", "f\u00fcr", "ei\u00b7nen", "Zeu\u00b7gen", "stel\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da Lieb ist selbst der Eyd/ da\u00df Pitschafft vnd die Hand/", "tokens": ["Da", "Lieb", "ist", "selbst", "der", "Eyd", "/", "da\u00df", "Pit\u00b7schafft", "vnd", "die", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "ADV", "ART", "NN", "$(", "KOUS", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Vnderh\u00e4ndler selbst/ der Bott vnd Abgesandt.", "tokens": ["Der", "Vn\u00b7der\u00b7h\u00e4nd\u00b7ler", "selbst", "/", "der", "Bott", "vnd", "Ab\u00b7ge\u00b7sandt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "In diesem fall hat nichts das b\u00f6se Gl\u00fcck zu hoffen/", "tokens": ["In", "die\u00b7sem", "fall", "hat", "nichts", "das", "b\u00f6\u00b7se", "Gl\u00fcck", "zu", "hof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PIS", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Hie hat das Gl\u00fcck gar offt die H\u00f6rner abgeloffen/", "tokens": ["Hie", "hat", "das", "Gl\u00fcck", "gar", "offt", "die", "H\u00f6r\u00b7ner", "ab\u00b7ge\u00b7lof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Je mehr dasselbig w\u00fcth/ je stercker wird die Trew/", "tokens": ["Je", "mehr", "das\u00b7sel\u00b7big", "w\u00fcth", "/", "je", "ster\u00b7cker", "wird", "die", "Trew", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVFIN", "$(", "ADV", "ADJD", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Durch vngerahte Tag wird nur die Liebe new:", "tokens": ["Durch", "vn\u00b7ge\u00b7rah\u00b7te", "Tag", "wird", "nur", "die", "Lie\u00b7be", "new", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Gleich wie die rawe K\u00e4lt/ so durch vnd durch thut schneiden/", "tokens": ["Gleich", "wie", "die", "ra\u00b7we", "K\u00e4lt", "/", "so", "durch", "vnd", "durch", "thut", "schnei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$(", "ADV", "APPR", "KON", "APPR", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Mag zwey in einem Bett durch sein gewaltnicht scheiden/", "tokens": ["Mag", "zwey", "in", "ei\u00b7nem", "Bett", "durch", "sein", "ge\u00b7walt\u00b7nicht", "schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "CARD", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Je mehr die Winters zeit die zarte Leiber druckt/", "tokens": ["Je", "mehr", "die", "Win\u00b7ters", "zeit", "die", "zar\u00b7te", "Lei\u00b7ber", "druckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Je mehr vnd mehr als dann die Lieb zur Liebe ruckt.", "tokens": ["Je", "mehr", "vnd", "mehr", "als", "dann", "die", "Lieb", "zur", "Lie\u00b7be", "ruckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "PIS", "KOKOM", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ein Jungfraw sa\u00df allein/ vnd sang von Liebs gedancken/", "tokens": ["Ein", "Jung\u00b7fraw", "sa\u00df", "al\u00b7lein", "/", "vnd", "sang", "von", "Liebs", "ge\u00b7dan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "KON", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Sie sprach von dir/ mein Hertz/ begehrich nicht zu wancken/", "tokens": ["Sie", "sprach", "von", "dir", "/", "mein", "Hertz", "/", "be\u00b7ge\u00b7hrich", "nicht", "zu", "wan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$(", "PPOSAT", "NN", "$(", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Vnd mu\u00df ich mit dir gehn/ durch Fewer/ Schnee vnd Kelt/", "tokens": ["Vnd", "mu\u00df", "ich", "mit", "dir", "gehn", "/", "durch", "Fe\u00b7wer", "/", "Schnee", "vnd", "Kelt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$(", "APPR", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Vnd durch das wilde Meer/ wie Zornig es sich stelt.", "tokens": ["Vnd", "durch", "das", "wil\u00b7de", "Meer", "/", "wie", "Zor\u00b7nig", "es", "sich", "stelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$(", "KOKOM", "NN", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ich dacht in meinem Sinn/ ob es solt m\u00fcglich scheinen/", "tokens": ["Ich", "dacht", "in", "mei\u00b7nem", "Sinn", "/", "ob", "es", "solt", "m\u00fcg\u00b7lich", "schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$(", "KOUS", "PPER", "VMFIN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ich fragt die Braut darumb/ Sie that es nicht verneinen/", "tokens": ["Ich", "fragt", "die", "Braut", "da\u00b7rumb", "/", "Sie", "that", "es", "nicht", "ver\u00b7nei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PAV", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Sie sprach/ die Kelt ist warm/ Sie sprach die Hitz ist k\u00fchl/", "tokens": ["Sie", "sprach", "/", "die", "Kelt", "ist", "warm", "/", "Sie", "sprach", "die", "Hitz", "ist", "k\u00fchl", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "VAFIN", "ADJD", "$(", "PPER", "VVFIN", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Wann ich die Liebe nur in meinem Hertzen f\u00fchl.", "tokens": ["Wann", "ich", "die", "Lie\u00b7be", "nur", "in", "mei\u00b7nem", "Hert\u00b7zen", "f\u00fchl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ich fragt den Br\u00e4utigam/ er solt sein Meinung sagen/", "tokens": ["Ich", "fragt", "den", "Br\u00e4u\u00b7ti\u00b7gam", "/", "er", "solt", "sein", "Mei\u00b7nung", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NE", "$(", "PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Er antwort mir geschwind/ ich solt mich selber fragen?", "tokens": ["Er", "ant\u00b7wort", "mir", "ge\u00b7schwind", "/", "ich", "solt", "mich", "sel\u00b7ber", "fra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$(", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ich schweig vnd gieng davon/ dacht vnter Wegs bey mir/", "tokens": ["Ich", "schweig", "vnd", "gieng", "da\u00b7von", "/", "dacht", "vn\u00b7ter", "Wegs", "bey", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PAV", "$(", "VVFIN", "APPR", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wie nun Herr Br\u00e4utigam/ wer sagt die sachen dir?", "tokens": ["Wie", "nun", "Herr", "Br\u00e4u\u00b7ti\u00b7gam", "/", "wer", "sagt", "die", "sa\u00b7chen", "dir", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "NE", "$(", "PWS", "VVFIN", "ART", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}