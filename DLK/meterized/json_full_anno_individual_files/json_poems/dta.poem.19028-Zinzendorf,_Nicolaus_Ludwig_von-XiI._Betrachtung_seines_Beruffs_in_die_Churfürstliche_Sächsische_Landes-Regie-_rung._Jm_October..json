{"dta.poem.19028": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "XiI.  Betrachtung seines Beruffs in die  \n Churf\u00fcrstliche S\u00e4chsische Landes-Regie-  \n rung.   Jm October.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Du grosser HErr der Welt! es ist dir unverborgen,", "tokens": ["Du", "gros\u00b7ser", "Herr", "der", "Welt", "!", "es", "ist", "dir", "un\u00b7ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "$.", "PPER", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie sehr mich diese Welt mit ihrem Dienst erschreckt:", "tokens": ["Wie", "sehr", "mich", "die\u00b7se", "Welt", "mit", "ih\u00b7rem", "Dienst", "er\u00b7schreckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich w\u00e4re gar zu gern zu deinem Dienst erweckt:", "tokens": ["Ich", "w\u00e4\u00b7re", "gar", "zu", "gern", "zu", "dei\u00b7nem", "Dienst", "er\u00b7weckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKA", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Abend w\u00e4hrt mir lang: Ich seufze nach dem Morgen.", "tokens": ["Der", "A\u00b7bend", "w\u00e4hrt", "mir", "lang", ":", "Ich", "seuf\u00b7ze", "nach", "dem", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es ist nicht mehr die Zeit, die wohl vor diesem war:", "tokens": ["Es", "ist", "nicht", "mehr", "die", "Zeit", ",", "die", "wohl", "vor", "die\u00b7sem", "war", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "PDAT", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir qv\u00e4len uns umsonst, wir nutzen ihr kein Haar.", "tokens": ["Wir", "qv\u00e4\u00b7len", "uns", "um\u00b7sonst", ",", "wir", "nut\u00b7zen", "ihr", "kein", "Haar", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ach w\u00e4re noch der Tag, da man mit Staupen-Schl\u00e4gen,", "tokens": ["Ach", "w\u00e4\u00b7re", "noch", "der", "Tag", ",", "da", "man", "mit", "Stau\u00b7pen\u00b7Schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VAFIN", "ADV", "ART", "NN", "$,", "KOUS", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit St\u00f6ck- und Pfl\u00f6cken sich an deinen Gliedern rieb,", "tokens": ["Mit", "St\u00f6\u00b7ck", "und", "Pfl\u00f6\u00b7cken", "sich", "an", "dei\u00b7nen", "Glie\u00b7dern", "rieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und sie den Schafen gleich aufs Mord-Ger\u00fcste trieb;", "tokens": ["Und", "sie", "den", "Scha\u00b7fen", "gleich", "aufs", "Mord\u00b7Ge\u00b7r\u00fcs\u00b7te", "trieb", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00fcrde sich mein Gram mit leichter M\u00fche legen.", "tokens": ["So", "w\u00fcr\u00b7de", "sich", "mein", "Gram", "mit", "leich\u00b7ter", "M\u00fc\u00b7he", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn HErr das weissest du, ich k\u00fcsse Rad und Pfahl", "tokens": ["Denn", "Herr", "das", "weis\u00b7sest", "du", ",", "ich", "k\u00fcs\u00b7se", "Rad", "und", "Pfahl"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "PDS", "VVFIN", "PPER", "$,", "PPER", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Um deinetwillen gern; Ich jauchzte bey der Qvaal;", "tokens": ["Um", "dei\u00b7net\u00b7wil\u00b7len", "gern", ";", "Ich", "jauchz\u00b7te", "bey", "der", "Qvaal", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich scheue keine Schmach; mich ehrt die Narren-Kappen,", "tokens": ["Ich", "scheu\u00b7e", "kei\u00b7ne", "Schmach", ";", "mich", "ehrt", "die", "Nar\u00b7ren\u00b7Kap\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Darein manch eitler Hof dein Volck so gern verh\u00fcllt,", "tokens": ["Da\u00b7rein", "manch", "eit\u00b7ler", "Hof", "dein", "Volck", "so", "gern", "ver\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "ADJA", "NN", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Hof, dem Zions Ach mit Lust die Ohren f\u00fcllt,", "tokens": ["Ein", "Hof", ",", "dem", "Zi\u00b7ons", "Ach", "mit", "Lust", "die", "Oh\u00b7ren", "f\u00fcllt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NE", "NN", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Hof, wo kluge Leut\u2019 am hellen Tage tappen;", "tokens": ["Ein", "Hof", ",", "wo", "klu\u00b7ge", "Leut'", "am", "hel\u00b7len", "Ta\u00b7ge", "tap\u00b7pen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da hie\u00df ich gern ein Thor, ein Schw\u00e4rmer, ein Phantast,", "tokens": ["Da", "hie\u00df", "ich", "gern", "ein", "Thor", ",", "ein", "Schw\u00e4r\u00b7mer", ",", "ein", "Phan\u00b7tast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mir w\u00e4r der Erden-Zorn nur eine kleine Last.", "tokens": ["Mir", "w\u00e4r", "der", "Er\u00b7den\u00b7Zorn", "nur", "ei\u00b7ne", "klei\u00b7ne", "Last", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Allein, du alter Freund, dem Millionen Tage", "tokens": ["Al\u00b7lein", ",", "du", "al\u00b7ter", "Freund", ",", "dem", "Mil\u00b7lion\u00b7en", "Ta\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "ADJA", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie sechzig Stunden sind, der keinen Wechsel kennt,", "tokens": ["Wie", "sech\u00b7zig", "Stun\u00b7den", "sind", ",", "der", "kei\u00b7nen", "Wech\u00b7sel", "kennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "CARD", "NN", "VAFIN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sich mit allem Recht von heut und gestern nennt,", "tokens": ["Und", "sich", "mit", "al\u00b7lem", "Recht", "von", "heut", "und", "ge\u00b7stern", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIS", "NN", "APPR", "ADV", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Legst du die alte Welt mit dieser auf die Wage;", "tokens": ["Legst", "du", "die", "al\u00b7te", "Welt", "mit", "die\u00b7ser", "auf", "die", "Wa\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "PDAT", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So muste Jonathan vor seinem Vater fliehn,", "tokens": ["So", "mus\u00b7te", "Jo\u00b7na\u00b7than", "vor", "sei\u00b7nem", "Va\u00b7ter", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch kont\u2019 er seinen Freund des Vaters Wuth entziehn;", "tokens": ["Doch", "kont'", "er", "sei\u00b7nen", "Freund", "des", "Va\u00b7ters", "Wuth", "ent\u00b7ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPOSAT", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der Rath Ahitophels war kaum zur Narrheit worden,", "tokens": ["Der", "Rath", "A\u00b7hi\u00b7to\u00b7phels", "war", "kaum", "zur", "Nar\u00b7rheit", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VAFIN", "ADV", "APPRART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als des Husai Mund vor Davids Leben stritt.", "tokens": ["Als", "des", "Hu\u00b7sai", "Mund", "vor", "Da\u00b7vids", "Le\u00b7ben", "stritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Zog Ahab in den Streit, fuhr Josaphat zwar mit;", "tokens": ["Zog", "A\u00b7hab", "in", "den", "Streit", ",", "fuhr", "Jo\u00b7sa\u00b7phat", "zwar", "mit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "$,", "VVFIN", "NE", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein er bl\u00f6ssete den gantzen Baals-Orden,", "tokens": ["Al\u00b7lein", "er", "bl\u00f6s\u00b7se\u00b7te", "den", "gant\u00b7zen", "Baals\u00b7Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und der Prophete sprach: Ich schone Josaphat,", "tokens": ["Und", "der", "Pro\u00b7phe\u00b7te", "sprach", ":", "Ich", "scho\u00b7ne", "Jo\u00b7sa\u00b7phat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sonst bliebt ihr K\u00f6nige gewi\u00dflich ohne Rath.", "tokens": ["Sonst", "bliebt", "ihr", "K\u00f6\u00b7ni\u00b7ge", "ge\u00b7wi\u00df\u00b7lich", "oh\u00b7ne", "Rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der Nehemias war des Arthasasta Schencke,", "tokens": ["Der", "Ne\u00b7he\u00b7mi\u00b7as", "war", "des", "Ar\u00b7tha\u00b7sas\u00b7ta", "Schen\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein wohlgeplagter Mann; Allein er machte doch", "tokens": ["Ein", "wohl\u00b7ge\u00b7plag\u00b7ter", "Mann", ";", "Al\u00b7lein", "er", "mach\u00b7te", "doch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ADV", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sein v\u00e4terliches Hau\u00df von dem betr\u00fcbten Joch", "tokens": ["Sein", "v\u00e4\u00b7ter\u00b7li\u00b7ches", "Hau\u00df", "von", "dem", "be\u00b7tr\u00fcb\u00b7ten", "Joch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit einem Worte lo\u00df. Ich seufze, wenn ich dencke", "tokens": ["Mit", "ei\u00b7nem", "Wor\u00b7te", "lo\u00df", ".", "Ich", "seuf\u00b7ze", ",", "wenn", "ich", "den\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Mardachai Fu\u00df vor saure Schritte that;", "tokens": ["Was", "Mar\u00b7dac\u00b7hai", "Fu\u00df", "vor", "sau\u00b7re", "Schrit\u00b7te", "that", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Der aber doch dadurch sein Volck erl\u00f6set hat.", "tokens": ["Der", "a\u00b7ber", "doch", "da\u00b7durch", "sein", "Volck", "er\u00b7l\u00f6\u00b7set", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PAV", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Es mu\u00df auch Daniel das Hof-Get\u00fcmmel dulden;", "tokens": ["Es", "mu\u00df", "auch", "Da\u00b7ni\u00b7el", "das", "Hof\u00b7Ge\u00b7t\u00fcm\u00b7mel", "dul\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NE", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Allein wie betet nicht, wie \u00fcberwindet er!", "tokens": ["Al\u00b7lein", "wie", "be\u00b7tet", "nicht", ",", "wie", "\u00fc\u00b7berw\u00b7in\u00b7det", "er", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "VVFIN", "PTKNEG", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie wird es Misael und seinen Freunden schwer;", "tokens": ["Wie", "wird", "es", "Mi\u00b7sael", "und", "sei\u00b7nen", "Freun\u00b7den", "schwer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "NE", "KON", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Allein sie bleiben selbst im Ofen ohne Schulden,", "tokens": ["Al\u00b7lein", "sie", "blei\u00b7ben", "selbst", "im", "O\u00b7fen", "oh\u00b7ne", "Schul\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Leuen Rachen wird ein Maul-Korb angeleget;", "tokens": ["Der", "Leu\u00b7en", "Ra\u00b7chen", "wird", "ein", "Maul\u00b7Korb", "an\u00b7ge\u00b7le\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und von der Flamme brennt, wer Holtz zum Feuer tr\u00e4get;", "tokens": ["Und", "von", "der", "Flam\u00b7me", "brennt", ",", "wer", "Holtz", "zum", "Feu\u00b7er", "tr\u00e4\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "PWS", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die M\u00e4nner Juda sind bey ihrer Weise blieben,", "tokens": ["Die", "M\u00e4n\u00b7ner", "Ju\u00b7da", "sind", "bey", "ih\u00b7rer", "Wei\u00b7se", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VAFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "War gleich der gantze Hof ein ander Thun gewohnt,", "tokens": ["War", "gleich", "der", "gant\u00b7ze", "Hof", "ein", "an\u00b7der", "Thun", "ge\u00b7wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wurden dennoch sie mit Hof-Manier verschont;", "tokens": ["So", "wur\u00b7den", "den\u00b7noch", "sie", "mit", "Hof\u00b7Ma\u00b7nier", "ver\u00b7schont", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie hat der Eine nicht den K\u00f6nig eingetrieben,", "tokens": ["Wie", "hat", "der", "Ei\u00b7ne", "nicht", "den", "K\u00f6\u00b7nig", "ein\u00b7ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "PTKNEG", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als er das G\u00f6tzen-Volck der L\u00fcgen angeklagt,", "tokens": ["Als", "er", "das", "G\u00f6t\u00b7zen\u00b7Volck", "der", "L\u00fc\u00b7gen", "an\u00b7ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und einer, als er ihm der Wahrheit Lobspruch sagt.", "tokens": ["Und", "ei\u00b7ner", ",", "als", "er", "ihm", "der", "Wahr\u00b7heit", "Lob\u00b7spruch", "sagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Johannes muste zwar mit seinem Haupt bezahlen;", "tokens": ["Jo\u00b7han\u00b7nes", "mus\u00b7te", "zwar", "mit", "sei\u00b7nem", "Haupt", "be\u00b7zah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch h\u00f6rt\u2019 Jhn erst der F\u00fcrst, und folgte manchesmahl.", "tokens": ["Doch", "h\u00f6rt'", "Jhn", "erst", "der", "F\u00fcrst", ",", "und", "folg\u00b7te", "man\u00b7ches\u00b7mahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach w\u00fcste ich gewi\u00df ich k\u00e4m\u2019 in jener Z\u00e4hl:", "tokens": ["Ach", "w\u00fcs\u00b7te", "ich", "ge\u00b7wi\u00df", "ich", "k\u00e4m'", "in", "je\u00b7ner", "Z\u00e4hl", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "ADV", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So m\u00f6chte immerhin die Welt mit Feuer strahlen,", "tokens": ["So", "m\u00f6ch\u00b7te", "im\u00b7mer\u00b7hin", "die", "Welt", "mit", "Feu\u00b7er", "strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die schwersten Ubungen auf meine Scheidel speyn;", "tokens": ["Die", "schwers\u00b7ten", "U\u00b7bun\u00b7gen", "auf", "mei\u00b7ne", "Schei\u00b7del", "speyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Es solte Leue-Grimm mir gantz ertr\u00e4glich seyn.", "tokens": ["Es", "sol\u00b7te", "Leu\u00b7e\u00b7Grimm", "mir", "gantz", "er\u00b7tr\u00e4g\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Da ist mein offnes Hertz, du kennest mich von innen", "tokens": ["Da", "ist", "mein", "off\u00b7nes", "Hertz", ",", "du", "ken\u00b7nest", "mich", "von", "in\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PPER", "VVFIN", "PRF", "APPR", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Herr! wallt ein Tropfen Bluts durch meiner Adern-Bach,", "tokens": ["Herr", "!", "wallt", "ein", "Trop\u00b7fen", "Bluts", "durch", "mei\u00b7ner", "A\u00b7dern\u00b7Bach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der dir nicht eigen ist, den treffe deine Rach:", "tokens": ["Der", "dir", "nicht", "ei\u00b7gen", "ist", ",", "den", "tref\u00b7fe", "dei\u00b7ne", "Rach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "ADJD", "VAFIN", "$,", "ART", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein gantzes Hertz ist dein, die gantz Krafft der Sinnen,", "tokens": ["Mein", "gant\u00b7zes", "Hertz", "ist", "dein", ",", "die", "gantz", "Krafft", "der", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPOSAT", "$,", "PRELS", "ADV", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und der erl\u00f6ste Geist ist dir zum Opffer recht,", "tokens": ["Und", "der", "er\u00b7l\u00f6s\u00b7te", "Geist", "ist", "dir", "zum", "Opf\u00b7fer", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "PPER", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Mensch mit Leib und Seel ist ewiglich dein Knecht.", "tokens": ["Der", "Mensch", "mit", "Leib", "und", "Seel", "ist", "e\u00b7wig\u00b7lich", "dein", "Knecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}