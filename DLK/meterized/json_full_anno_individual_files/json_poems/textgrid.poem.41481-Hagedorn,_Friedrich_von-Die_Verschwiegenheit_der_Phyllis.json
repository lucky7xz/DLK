{"textgrid.poem.41481": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Die Verschwiegenheit der Phyllis", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nein, nein, man f\u00e4ngt mich nicht so bald!", "tokens": ["Nein", ",", "nein", ",", "man", "f\u00e4ngt", "mich", "nicht", "so", "bald", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sage keinem was ich denke.", "tokens": ["Ich", "sa\u00b7ge", "kei\u00b7nem", "was", "ich", "den\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich kenne schon der Sch\u00e4fer R\u00e4nke,", "tokens": ["Ich", "ken\u00b7ne", "schon", "der", "Sch\u00e4\u00b7fer", "R\u00e4n\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und bin nun sechszehn Sommer alt.", "tokens": ["Und", "bin", "nun", "sechs\u00b7zehn", "Som\u00b7mer", "alt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und h\u00f6re meine Schwester sagen:", "tokens": ["Und", "h\u00f6\u00b7re", "mei\u00b7ne", "Schwes\u00b7ter", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Man m\u00fcsse kein Gest\u00e4ndni\u00df wagen.", "tokens": ["Man", "m\u00fcs\u00b7se", "kein", "Ge\u00b7st\u00e4nd\u00b7ni\u00df", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Mein Sch\u00e4fer kennet mich noch nicht.", "tokens": ["Mein", "Sch\u00e4\u00b7fer", "ken\u00b7net", "mich", "noch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie w\u00e4r' es, wenn ich mich verriethe?", "tokens": ["Wie", "w\u00e4r'", "es", ",", "wenn", "ich", "mich", "ver\u00b7rie\u00b7the", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O liebt' ich ihn, so w\u00e4r' es G\u00fcte:", "tokens": ["O", "liebt'", "ich", "ihn", ",", "so", "w\u00e4r'", "es", "G\u00fc\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPER", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und liebt' er mich, so ist es Pflicht.", "tokens": ["Und", "liebt'", "er", "mich", ",", "so", "ist", "es", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Sch\u00e4ferinnen selbst bekennen,", "tokens": ["Die", "Sch\u00e4\u00b7fe\u00b7rin\u00b7nen", "selbst", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich sei schon liebenswerth zu nennen.", "tokens": ["Ich", "sei", "schon", "lie\u00b7bens\u00b7werth", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Er stahl so manchen Ku\u00df allhier.", "tokens": ["Er", "stahl", "so", "man\u00b7chen", "Ku\u00df", "all\u00b7hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wei\u00df allein die Zahl von allen:", "tokens": ["Ich", "wei\u00df", "al\u00b7lein", "die", "Zahl", "von", "al\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihm aber ist sie halb entfallen;", "tokens": ["Ihm", "a\u00b7ber", "ist", "sie", "halb", "ent\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und dies Geheimni\u00df merk' ich mir.", "tokens": ["Und", "dies", "Ge\u00b7heim\u00b7ni\u00df", "merk'", "ich", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch sollt' er nicht von meinen K\u00fcssen", "tokens": ["Doch", "sollt'", "er", "nicht", "von", "mei\u00b7nen", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nach allem Recht die Anzahl wissen?", "tokens": ["Nach", "al\u00b7lem", "Recht", "die", "An\u00b7zahl", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Er nenn' es immer G\u00fctigkeit,", "tokens": ["Er", "nenn'", "es", "im\u00b7mer", "G\u00fc\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich bei seinen Heerden weide.", "tokens": ["Da\u00df", "ich", "bei", "sei\u00b7nen", "Heer\u00b7den", "wei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich nenn' es eine Fr\u00fchlingsfreude,", "tokens": ["Ich", "nenn'", "es", "ei\u00b7ne", "Fr\u00fch\u00b7lings\u00b7freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und die ist keine Seltenheit.", "tokens": ["Und", "die", "ist", "kei\u00b7ne", "Sel\u00b7ten\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja, hie\u00df ich's mehr als ein Vergn\u00fcgen,", "tokens": ["Ja", ",", "hie\u00df", "ich's", "mehr", "als", "ein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PIS", "PIS", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So sag' ich's nicht und bin verschwiegen.", "tokens": ["So", "sag'", "ich's", "nicht", "und", "bin", "ver\u00b7schwie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKNEG", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich hab' ihm j\u00fcngst ein gr\u00fcnes Band", "tokens": ["Ich", "hab'", "ihm", "j\u00fcngst", "ein", "gr\u00fc\u00b7nes", "Band"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um Hut und Stab und Arm gebunden.", "tokens": ["Um", "Hut", "und", "Stab", "und", "Arm", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie sehr er diese Gunst empfunden,", "tokens": ["Wie", "sehr", "er", "die\u00b7se", "Gunst", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist mir nicht g\u00e4nzlich unbekannt.", "tokens": ["Ist", "mir", "nicht", "g\u00e4nz\u00b7lich", "un\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er aber hat es nicht erfahren,", "tokens": ["Er", "a\u00b7ber", "hat", "es", "nicht", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Warum ich bat, es zu bewahren.", "tokens": ["Wa\u00b7rum", "ich", "bat", ",", "es", "zu", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Um etwas, Liebe, bitt' ich dich:", "tokens": ["Um", "et\u00b7was", ",", "Lie\u00b7be", ",", "bitt'", "ich", "dich", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df ihn nicht diesen Busch beschreiten.", "tokens": ["La\u00df", "ihn", "nicht", "die\u00b7sen", "Busch", "be\u00b7schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du m\u00f6chtest ihn vielleicht begleiten:", "tokens": ["Du", "m\u00f6ch\u00b7test", "ihn", "viel\u00b7leicht", "be\u00b7glei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, wahrlich! dann verrieth ich mich.", "tokens": ["Und", ",", "wahr\u00b7lich", "!", "dann", "ver\u00b7rieth", "ich", "mich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "$.", "ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch hast du das dir vorgenommen:", "tokens": ["Doch", "hast", "du", "das", "dir", "vor\u00b7ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So la\u00df ihn ja nicht heute kommen.", "tokens": ["So", "la\u00df", "ihn", "ja", "nicht", "heu\u00b7te", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Nein, nein, man f\u00e4ngt mich nicht so bald!", "tokens": ["Nein", ",", "nein", ",", "man", "f\u00e4ngt", "mich", "nicht", "so", "bald", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sage keinem was ich denke.", "tokens": ["Ich", "sa\u00b7ge", "kei\u00b7nem", "was", "ich", "den\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich kenne schon der Sch\u00e4fer R\u00e4nke,", "tokens": ["Ich", "ken\u00b7ne", "schon", "der", "Sch\u00e4\u00b7fer", "R\u00e4n\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und bin nun sechszehn Sommer alt.", "tokens": ["Und", "bin", "nun", "sechs\u00b7zehn", "Som\u00b7mer", "alt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und h\u00f6re meine Schwester sagen:", "tokens": ["Und", "h\u00f6\u00b7re", "mei\u00b7ne", "Schwes\u00b7ter", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Man m\u00fcsse kein Gest\u00e4ndni\u00df wagen.", "tokens": ["Man", "m\u00fcs\u00b7se", "kein", "Ge\u00b7st\u00e4nd\u00b7ni\u00df", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Mein Sch\u00e4fer kennet mich noch nicht.", "tokens": ["Mein", "Sch\u00e4\u00b7fer", "ken\u00b7net", "mich", "noch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie w\u00e4r' es, wenn ich mich verriethe?", "tokens": ["Wie", "w\u00e4r'", "es", ",", "wenn", "ich", "mich", "ver\u00b7rie\u00b7the", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O liebt' ich ihn, so w\u00e4r' es G\u00fcte:", "tokens": ["O", "liebt'", "ich", "ihn", ",", "so", "w\u00e4r'", "es", "G\u00fc\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPER", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und liebt' er mich, so ist es Pflicht.", "tokens": ["Und", "liebt'", "er", "mich", ",", "so", "ist", "es", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Sch\u00e4ferinnen selbst bekennen,", "tokens": ["Die", "Sch\u00e4\u00b7fe\u00b7rin\u00b7nen", "selbst", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich sei schon liebenswerth zu nennen.", "tokens": ["Ich", "sei", "schon", "lie\u00b7bens\u00b7werth", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Er stahl so manchen Ku\u00df allhier.", "tokens": ["Er", "stahl", "so", "man\u00b7chen", "Ku\u00df", "all\u00b7hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wei\u00df allein die Zahl von allen:", "tokens": ["Ich", "wei\u00df", "al\u00b7lein", "die", "Zahl", "von", "al\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihm aber ist sie halb entfallen;", "tokens": ["Ihm", "a\u00b7ber", "ist", "sie", "halb", "ent\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und dies Geheimni\u00df merk' ich mir.", "tokens": ["Und", "dies", "Ge\u00b7heim\u00b7ni\u00df", "merk'", "ich", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch sollt' er nicht von meinen K\u00fcssen", "tokens": ["Doch", "sollt'", "er", "nicht", "von", "mei\u00b7nen", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nach allem Recht die Anzahl wissen?", "tokens": ["Nach", "al\u00b7lem", "Recht", "die", "An\u00b7zahl", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Er nenn' es immer G\u00fctigkeit,", "tokens": ["Er", "nenn'", "es", "im\u00b7mer", "G\u00fc\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich bei seinen Heerden weide.", "tokens": ["Da\u00df", "ich", "bei", "sei\u00b7nen", "Heer\u00b7den", "wei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich nenn' es eine Fr\u00fchlingsfreude,", "tokens": ["Ich", "nenn'", "es", "ei\u00b7ne", "Fr\u00fch\u00b7lings\u00b7freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und die ist keine Seltenheit.", "tokens": ["Und", "die", "ist", "kei\u00b7ne", "Sel\u00b7ten\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja, hie\u00df ich's mehr als ein Vergn\u00fcgen,", "tokens": ["Ja", ",", "hie\u00df", "ich's", "mehr", "als", "ein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PIS", "PIS", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So sag' ich's nicht und bin verschwiegen.", "tokens": ["So", "sag'", "ich's", "nicht", "und", "bin", "ver\u00b7schwie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKNEG", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich hab' ihm j\u00fcngst ein gr\u00fcnes Band", "tokens": ["Ich", "hab'", "ihm", "j\u00fcngst", "ein", "gr\u00fc\u00b7nes", "Band"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um Hut und Stab und Arm gebunden.", "tokens": ["Um", "Hut", "und", "Stab", "und", "Arm", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie sehr er diese Gunst empfunden,", "tokens": ["Wie", "sehr", "er", "die\u00b7se", "Gunst", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist mir nicht g\u00e4nzlich unbekannt.", "tokens": ["Ist", "mir", "nicht", "g\u00e4nz\u00b7lich", "un\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er aber hat es nicht erfahren,", "tokens": ["Er", "a\u00b7ber", "hat", "es", "nicht", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Warum ich bat, es zu bewahren.", "tokens": ["Wa\u00b7rum", "ich", "bat", ",", "es", "zu", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Um etwas, Liebe, bitt' ich dich:", "tokens": ["Um", "et\u00b7was", ",", "Lie\u00b7be", ",", "bitt'", "ich", "dich", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df ihn nicht diesen Busch beschreiten.", "tokens": ["La\u00df", "ihn", "nicht", "die\u00b7sen", "Busch", "be\u00b7schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du m\u00f6chtest ihn vielleicht begleiten:", "tokens": ["Du", "m\u00f6ch\u00b7test", "ihn", "viel\u00b7leicht", "be\u00b7glei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, wahrlich! dann verrieth ich mich.", "tokens": ["Und", ",", "wahr\u00b7lich", "!", "dann", "ver\u00b7rieth", "ich", "mich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "$.", "ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch hast du das dir vorgenommen:", "tokens": ["Doch", "hast", "du", "das", "dir", "vor\u00b7ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So la\u00df ihn ja nicht heute kommen.", "tokens": ["So", "la\u00df", "ihn", "ja", "nicht", "heu\u00b7te", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}