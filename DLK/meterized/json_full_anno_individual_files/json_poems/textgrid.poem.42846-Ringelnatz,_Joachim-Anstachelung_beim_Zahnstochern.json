{"textgrid.poem.42846": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Anstachelung beim Zahnstochern", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich biete euch Troglodyten die Spitze.", "tokens": ["Ich", "bie\u00b7te", "euch", "Tro\u00b7glo\u00b7dy\u00b7ten", "die", "Spit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "ART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Heraus mit euch! Wer sich in L\u00f6cher", "tokens": ["He\u00b7raus", "mit", "euch", "!", "Wer", "sich", "in", "L\u00f6\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "$.", "PWS", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Verkr\u00fcmelt, ist feig. Ich besitze", "tokens": ["Ver\u00b7kr\u00fc\u00b7melt", ",", "ist", "feig", ".", "Ich", "be\u00b7sit\u00b7ze"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VAFIN", "ADJD", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Pfeile genug in meinem K\u00f6cher.", "tokens": ["Der", "Pfei\u00b7le", "ge\u00b7nug", "in", "mei\u00b7nem", "K\u00f6\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Mit dem Pfeil, dem Bogen", "tokens": ["Mit", "dem", "Pfeil", ",", "dem", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Durch Gebirg und Tal", "tokens": ["Durch", "Ge\u00b7birg", "und", "Tal"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Kommt Odysseus gezogen", "tokens": ["Kommt", "O\u00b7dys\u00b7seus", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "NE", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und s\u00e4ubert den Augiasstall.", "tokens": ["Und", "s\u00e4u\u00b7bert", "den", "Au\u00b7gi\u00b7as\u00b7stall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Nein, ich schie\u00dfe euch freche", "tokens": ["Nein", ",", "ich", "schie\u00b7\u00dfe", "euch", "fre\u00b7che"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADJA"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Brut nicht. Ich steche!", "tokens": ["Brut", "nicht", ".", "Ich", "ste\u00b7che", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$.", "PPER", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Ihr macht mich krank", "tokens": ["Ihr", "macht", "mich", "krank"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Mit eurem Gestank.", "tokens": ["Mit", "eu\u00b7rem", "Ge\u00b7stank", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Ihr fre\u00dft an mir, anstatt", "tokens": ["Ihr", "fre\u00dft", "an", "mir", ",", "an\u00b7statt"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "KOUI"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mich zu n\u00e4hren. Ich bin noch nicht satt.", "tokens": ["Mich", "zu", "n\u00e4h\u00b7ren", ".", "Ich", "bin", "noch", "nicht", "satt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Heraus aus dem Loch!", "tokens": ["He\u00b7raus", "aus", "dem", "Loch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Ich h\u00fclle in Spucke euch", "tokens": ["Ich", "h\u00fcl\u00b7le", "in", "Spu\u00b7cke", "euch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PPER"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und schlucke euch \u2013", "tokens": ["Und", "schlu\u00b7cke", "euch", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Pieks-quieks \u2013 doch.", "tokens": ["Pieks\u00b7quieks", "\u2013", "doch", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "ADV", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Oder schnipse euch aufs Geratewohl", "tokens": ["O\u00b7der", "schnip\u00b7se", "euch", "aufs", "Ge\u00b7ra\u00b7te\u00b7wohl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "In ein unbekanntes Hilfdirselber. \u2013", "tokens": ["In", "ein", "un\u00b7be\u00b7kann\u00b7tes", "Hilf\u00b7dir\u00b7sel\u00b7ber", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ach mein Backenzahn ist schrecklich hohl", "tokens": ["Ach", "mein", "Ba\u00b7cken\u00b7zahn", "ist", "schreck\u00b7lich", "hohl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "PPOSAT", "NN", "VAFIN", "ADJD", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und wird t\u00e4glich br\u00f6ckliger und gelber.", "tokens": ["Und", "wird", "t\u00e4g\u00b7lich", "br\u00f6ck\u00b7li\u00b7ger", "und", "gel\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Keine Hand vors Gesicht.", "tokens": ["Kei\u00b7ne", "Hand", "vors", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Komm, Zahnst\u00f6cherchen,", "tokens": ["Komm", ",", "Zahn\u00b7st\u00f6\u00b7cher\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Piek die Peiniger", "tokens": ["Piek", "die", "Pei\u00b7ni\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Aus den L\u00f6cherchen!", "tokens": ["Aus", "den", "L\u00f6\u00b7cher\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.5": {"text": "Sch\u00e4me dich nicht,", "tokens": ["Sch\u00e4\u00b7me", "dich", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Denn du bist ein kluger Reiniger.", "tokens": ["Denn", "du", "bist", "ein", "klu\u00b7ger", "Rei\u00b7ni\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Immer wacker gespie\u00dft!", "tokens": ["Im\u00b7mer", "wa\u00b7cker", "ge\u00b7spie\u00dft", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wenn auch mal Blut flie\u00dft.", "tokens": ["Wenn", "auch", "mal", "Blut", "flie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Ich bin nicht bang.", "tokens": ["Ich", "bin", "nicht", "bang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Gesegnete Mahlzeit beim letzten Gang.", "tokens": ["Ge\u00b7se\u00b7gne\u00b7te", "Mahl\u00b7zeit", "beim", "letz\u00b7ten", "Gang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Ich biete euch Troglodyten die Spitze.", "tokens": ["Ich", "bie\u00b7te", "euch", "Tro\u00b7glo\u00b7dy\u00b7ten", "die", "Spit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "ART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Heraus mit euch! Wer sich in L\u00f6cher", "tokens": ["He\u00b7raus", "mit", "euch", "!", "Wer", "sich", "in", "L\u00f6\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "$.", "PWS", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Verkr\u00fcmelt, ist feig. Ich besitze", "tokens": ["Ver\u00b7kr\u00fc\u00b7melt", ",", "ist", "feig", ".", "Ich", "be\u00b7sit\u00b7ze"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VAFIN", "ADJD", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Pfeile genug in meinem K\u00f6cher.", "tokens": ["Der", "Pfei\u00b7le", "ge\u00b7nug", "in", "mei\u00b7nem", "K\u00f6\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Mit dem Pfeil, dem Bogen", "tokens": ["Mit", "dem", "Pfeil", ",", "dem", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Durch Gebirg und Tal", "tokens": ["Durch", "Ge\u00b7birg", "und", "Tal"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Kommt Odysseus gezogen", "tokens": ["Kommt", "O\u00b7dys\u00b7seus", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "NE", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und s\u00e4ubert den Augiasstall.", "tokens": ["Und", "s\u00e4u\u00b7bert", "den", "Au\u00b7gi\u00b7as\u00b7stall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.12": {"line.1": {"text": "Nein, ich schie\u00dfe euch freche", "tokens": ["Nein", ",", "ich", "schie\u00b7\u00dfe", "euch", "fre\u00b7che"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADJA"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Brut nicht. Ich steche!", "tokens": ["Brut", "nicht", ".", "Ich", "ste\u00b7che", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$.", "PPER", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.13": {"line.1": {"text": "Ihr macht mich krank", "tokens": ["Ihr", "macht", "mich", "krank"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Mit eurem Gestank.", "tokens": ["Mit", "eu\u00b7rem", "Ge\u00b7stank", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Ihr fre\u00dft an mir, anstatt", "tokens": ["Ihr", "fre\u00dft", "an", "mir", ",", "an\u00b7statt"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "KOUI"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mich zu n\u00e4hren. Ich bin noch nicht satt.", "tokens": ["Mich", "zu", "n\u00e4h\u00b7ren", ".", "Ich", "bin", "noch", "nicht", "satt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$.", "PPER", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Heraus aus dem Loch!", "tokens": ["He\u00b7raus", "aus", "dem", "Loch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Ich h\u00fclle in Spucke euch", "tokens": ["Ich", "h\u00fcl\u00b7le", "in", "Spu\u00b7cke", "euch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PPER"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und schlucke euch \u2013", "tokens": ["Und", "schlu\u00b7cke", "euch", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Pieks-quieks \u2013 doch.", "tokens": ["Pieks\u00b7quieks", "\u2013", "doch", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "ADV", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.15": {"line.1": {"text": "Oder schnipse euch aufs Geratewohl", "tokens": ["O\u00b7der", "schnip\u00b7se", "euch", "aufs", "Ge\u00b7ra\u00b7te\u00b7wohl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+----+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "In ein unbekanntes Hilfdirselber. \u2013", "tokens": ["In", "ein", "un\u00b7be\u00b7kann\u00b7tes", "Hilf\u00b7dir\u00b7sel\u00b7ber", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ach mein Backenzahn ist schrecklich hohl", "tokens": ["Ach", "mein", "Ba\u00b7cken\u00b7zahn", "ist", "schreck\u00b7lich", "hohl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "PPOSAT", "NN", "VAFIN", "ADJD", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und wird t\u00e4glich br\u00f6ckliger und gelber.", "tokens": ["Und", "wird", "t\u00e4g\u00b7lich", "br\u00f6ck\u00b7li\u00b7ger", "und", "gel\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Keine Hand vors Gesicht.", "tokens": ["Kei\u00b7ne", "Hand", "vors", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Komm, Zahnst\u00f6cherchen,", "tokens": ["Komm", ",", "Zahn\u00b7st\u00f6\u00b7cher\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Piek die Peiniger", "tokens": ["Piek", "die", "Pei\u00b7ni\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Aus den L\u00f6cherchen!", "tokens": ["Aus", "den", "L\u00f6\u00b7cher\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.5": {"text": "Sch\u00e4me dich nicht,", "tokens": ["Sch\u00e4\u00b7me", "dich", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Denn du bist ein kluger Reiniger.", "tokens": ["Denn", "du", "bist", "ein", "klu\u00b7ger", "Rei\u00b7ni\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Immer wacker gespie\u00dft!", "tokens": ["Im\u00b7mer", "wa\u00b7cker", "ge\u00b7spie\u00dft", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wenn auch mal Blut flie\u00dft.", "tokens": ["Wenn", "auch", "mal", "Blut", "flie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Ich bin nicht bang.", "tokens": ["Ich", "bin", "nicht", "bang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "Gesegnete Mahlzeit beim letzten Gang.", "tokens": ["Ge\u00b7se\u00b7gne\u00b7te", "Mahl\u00b7zeit", "beim", "letz\u00b7ten", "Gang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}