{"textgrid.poem.52058": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "18.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was wolt ihr eure S\u00f6hn in frembde L\u00e4nder schicken,", "tokens": ["Was", "wolt", "ihr", "eu\u00b7re", "S\u00f6hn", "in", "fremb\u00b7de", "L\u00e4n\u00b7der", "schi\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Leib und Sinn mit Tracht und Sprachen auszuschm\u00fccken:", "tokens": ["Den", "Leib", "und", "Sinn", "mit", "Tracht", "und", "Spra\u00b7chen", "aus\u00b7zu\u00b7schm\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr M\u00fctter thut es nicht, der Bauer ingemein,", "tokens": ["Ihr", "M\u00fct\u00b7ter", "thut", "es", "nicht", ",", "der", "Bau\u00b7er", "in\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn er den Mist besieht, redt wol und gut Lad ein.", "tokens": ["Wenn", "er", "den", "Mist", "be\u00b7sieht", ",", "redt", "wol", "und", "gut", "Lad", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "KON", "ADJD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Spansch, wenn er klagt, da\u00df man wil nach Rebeldern fragen:", "tokens": ["Spansch", ",", "wenn", "er", "klagt", ",", "da\u00df", "man", "wil", "nach", "Re\u00b7bel\u00b7dern", "fra\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "VVFIN", "$,", "KOUS", "PIS", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Welsch, wann mit Gabeln sich die Cavaliere tragen.", "tokens": ["Welsch", ",", "wann", "mit", "Ga\u00b7beln", "sich", "die", "Ca\u00b7va\u00b7lie\u00b7re", "tra\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "APPR", "NN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und wann er sa\u00fcisch frist, giebt er frantz\u00f6sisch zu:", "tokens": ["Und", "wann", "er", "sa\u00fc\u00b7isch", "frist", ",", "giebt", "er", "frant\u00b7z\u00f6\u00b7sisch", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADJD", "VVFIN", "$,", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die Deutsche Sprache bleibt vor dieser Schaar zu Ruh.", "tokens": ["Die", "Deut\u00b7sche", "Spra\u00b7che", "bleibt", "vor", "die\u00b7ser", "Schaar", "zu", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PDAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Man h\u00f6rt nichts als Don Hans, als Signor Merta ruffen,", "tokens": ["Man", "h\u00f6rt", "nichts", "als", "Don", "Hans", ",", "als", "Sig\u00b7nor", "Mer\u00b7ta", "ruf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "KOKOM", "NE", "NE", "$,", "KOUS", "NE", "NE", "VVFIN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wann Balger Dominus l\u00e4st Mons. Bartheln ruffen.", "tokens": ["Wann", "Bal\u00b7ger", "Do\u00b7mi\u00b7nus", "l\u00e4st", "Mons", ".", "Bar\u00b7theln", "ruf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "NE", "VVFIN", "NE", "$.", "NN", "VVINF", "$."], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Das sind die Sprachen blo\u00df: Wer sich l\u00e4st weiter ein,", "tokens": ["Das", "sind", "die", "Spra\u00b7chen", "blo\u00df", ":", "Wer", "sich", "l\u00e4st", "wei\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$.", "PWS", "PRF", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der mu\u00df gestehn, da\u00df sie sehr scharff gelehret seyn.", "tokens": ["Der", "mu\u00df", "ge\u00b7stehn", ",", "da\u00df", "sie", "sehr", "scharff", "ge\u00b7leh\u00b7ret", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VVINF", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Man h\u00f6rt die Sch\u00f6ppen ja (es sind sehr hohe Sachen)", "tokens": ["Man", "h\u00f6rt", "die", "Sch\u00f6p\u00b7pen", "ja", "(", "es", "sind", "sehr", "ho\u00b7he", "Sa\u00b7chen", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "$(", "PPER", "VAFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom Ent, und vom non Ent im Kretscham Schl\u00fc\u00dfe machen:", "tokens": ["Vom", "Ent", ",", "und", "vom", "non", "Ent", "im", "Kretsc\u00b7ham", "Schl\u00fc\u00b7\u00dfe", "ma\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KON", "APPRART", "ADJA", "NN", "APPRART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein Dorff ist, wo man nicht die schweren Fragen r\u00fchrt,", "tokens": ["Kein", "Dorff", "ist", ",", "wo", "man", "nicht", "die", "schwe\u00b7ren", "Fra\u00b7gen", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$,", "PWAV", "PIS", "PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und endlich in den Stock ein ander dr\u00fcber f\u00fchrt.", "tokens": ["Und", "end\u00b7lich", "in", "den", "Stock", "ein", "an\u00b7der", "dr\u00fc\u00b7ber", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ART", "ADJD", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Zwar Schaaff und K\u00fch und Pferd, und Hoff und Haus u. Leben,", "tokens": ["Zwar", "Schaaff", "und", "K\u00fch", "und", "Pferd", ",", "und", "Hoff", "und", "Haus", "u.", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "KON", "NN", "$,", "KON", "VVFIN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Mu\u00df vor das Lehr Geld er den scharffen Schulherrn geben:", "tokens": ["Mu\u00df", "vor", "das", "Lehr", "Geld", "er", "den", "scharf\u00b7fen", "Schul\u00b7herrn", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "NN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr M\u00fctter eure S\u00f6hn, indem ihr kratzt und schabt,", "tokens": ["Ihr", "M\u00fct\u00b7ter", "eu\u00b7re", "S\u00f6hn", ",", "in\u00b7dem", "ihr", "kratzt", "und", "schabt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verlehnen auch ihr Gut und alles was ihr habt.", "tokens": ["Ver\u00b7leh\u00b7nen", "auch", "ihr", "Gut", "und", "al\u00b7les", "was", "ihr", "habt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "KON", "PIS", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Das ist der Unterscheid: Die Bauern hinterm pfl\u00fcgen", "tokens": ["Das", "ist", "der", "Un\u00b7ter\u00b7scheid", ":", "Die", "Bau\u00b7ern", "hin\u00b7term", "pfl\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Begreiffen ihre Kunst und Wi\u00dfenschafft im Kriegen:", "tokens": ["Be\u00b7greif\u00b7fen", "ih\u00b7re", "Kunst", "und", "Wi\u00b7\u00dfen\u00b7schafft", "im", "Krie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel Bauern Kinder sehn in Finstern Zimmern an,", "tokens": ["Viel", "Bau\u00b7ern", "Kin\u00b7der", "sehn", "in", "Fins\u00b7tern", "Zim\u00b7mern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "APPR", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Draus kaum der Zehnde das, was hier ein Bader kan.", "tokens": ["Draus", "kaum", "der", "Zehn\u00b7de", "das", ",", "was", "hier", "ein", "Ba\u00b7der", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ART", "NN", "PDS", "$,", "PRELS", "ADV", "ART", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Was wolt ihr eure S\u00f6hn in frembde L\u00e4nder schicken,", "tokens": ["Was", "wolt", "ihr", "eu\u00b7re", "S\u00f6hn", "in", "fremb\u00b7de", "L\u00e4n\u00b7der", "schi\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Leib und Sinn mit Tracht und Sprachen auszuschm\u00fccken:", "tokens": ["Den", "Leib", "und", "Sinn", "mit", "Tracht", "und", "Spra\u00b7chen", "aus\u00b7zu\u00b7schm\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr M\u00fctter thut es nicht, der Bauer ingemein,", "tokens": ["Ihr", "M\u00fct\u00b7ter", "thut", "es", "nicht", ",", "der", "Bau\u00b7er", "in\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn er den Mist besieht, redt wol und gut Lad ein.", "tokens": ["Wenn", "er", "den", "Mist", "be\u00b7sieht", ",", "redt", "wol", "und", "gut", "Lad", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "ADV", "KON", "ADJD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Spansch, wenn er klagt, da\u00df man wil nach Rebeldern fragen:", "tokens": ["Spansch", ",", "wenn", "er", "klagt", ",", "da\u00df", "man", "wil", "nach", "Re\u00b7bel\u00b7dern", "fra\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "VVFIN", "$,", "KOUS", "PIS", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Welsch, wann mit Gabeln sich die Cavaliere tragen.", "tokens": ["Welsch", ",", "wann", "mit", "Ga\u00b7beln", "sich", "die", "Ca\u00b7va\u00b7lie\u00b7re", "tra\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "APPR", "NN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und wann er sa\u00fcisch frist, giebt er frantz\u00f6sisch zu:", "tokens": ["Und", "wann", "er", "sa\u00fc\u00b7isch", "frist", ",", "giebt", "er", "frant\u00b7z\u00f6\u00b7sisch", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADJD", "VVFIN", "$,", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die Deutsche Sprache bleibt vor dieser Schaar zu Ruh.", "tokens": ["Die", "Deut\u00b7sche", "Spra\u00b7che", "bleibt", "vor", "die\u00b7ser", "Schaar", "zu", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PDAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Man h\u00f6rt nichts als Don Hans, als Signor Merta ruffen,", "tokens": ["Man", "h\u00f6rt", "nichts", "als", "Don", "Hans", ",", "als", "Sig\u00b7nor", "Mer\u00b7ta", "ruf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "KOKOM", "NE", "NE", "$,", "KOUS", "NE", "NE", "VVFIN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wann Balger Dominus l\u00e4st Mons. Bartheln ruffen.", "tokens": ["Wann", "Bal\u00b7ger", "Do\u00b7mi\u00b7nus", "l\u00e4st", "Mons", ".", "Bar\u00b7theln", "ruf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "NE", "VVFIN", "NE", "$.", "NN", "VVINF", "$."], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Das sind die Sprachen blo\u00df: Wer sich l\u00e4st weiter ein,", "tokens": ["Das", "sind", "die", "Spra\u00b7chen", "blo\u00df", ":", "Wer", "sich", "l\u00e4st", "wei\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$.", "PWS", "PRF", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der mu\u00df gestehn, da\u00df sie sehr scharff gelehret seyn.", "tokens": ["Der", "mu\u00df", "ge\u00b7stehn", ",", "da\u00df", "sie", "sehr", "scharff", "ge\u00b7leh\u00b7ret", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VVINF", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Man h\u00f6rt die Sch\u00f6ppen ja (es sind sehr hohe Sachen)", "tokens": ["Man", "h\u00f6rt", "die", "Sch\u00f6p\u00b7pen", "ja", "(", "es", "sind", "sehr", "ho\u00b7he", "Sa\u00b7chen", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "$(", "PPER", "VAFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom Ent, und vom non Ent im Kretscham Schl\u00fc\u00dfe machen:", "tokens": ["Vom", "Ent", ",", "und", "vom", "non", "Ent", "im", "Kretsc\u00b7ham", "Schl\u00fc\u00b7\u00dfe", "ma\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KON", "APPRART", "ADJA", "NN", "APPRART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein Dorff ist, wo man nicht die schweren Fragen r\u00fchrt,", "tokens": ["Kein", "Dorff", "ist", ",", "wo", "man", "nicht", "die", "schwe\u00b7ren", "Fra\u00b7gen", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$,", "PWAV", "PIS", "PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und endlich in den Stock ein ander dr\u00fcber f\u00fchrt.", "tokens": ["Und", "end\u00b7lich", "in", "den", "Stock", "ein", "an\u00b7der", "dr\u00fc\u00b7ber", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ART", "ADJD", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Zwar Schaaff und K\u00fch und Pferd, und Hoff und Haus u. Leben,", "tokens": ["Zwar", "Schaaff", "und", "K\u00fch", "und", "Pferd", ",", "und", "Hoff", "und", "Haus", "u.", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "KON", "NN", "$,", "KON", "VVFIN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Mu\u00df vor das Lehr Geld er den scharffen Schulherrn geben:", "tokens": ["Mu\u00df", "vor", "das", "Lehr", "Geld", "er", "den", "scharf\u00b7fen", "Schul\u00b7herrn", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "NN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr M\u00fctter eure S\u00f6hn, indem ihr kratzt und schabt,", "tokens": ["Ihr", "M\u00fct\u00b7ter", "eu\u00b7re", "S\u00f6hn", ",", "in\u00b7dem", "ihr", "kratzt", "und", "schabt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verlehnen auch ihr Gut und alles was ihr habt.", "tokens": ["Ver\u00b7leh\u00b7nen", "auch", "ihr", "Gut", "und", "al\u00b7les", "was", "ihr", "habt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "KON", "PIS", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Das ist der Unterscheid: Die Bauern hinterm pfl\u00fcgen", "tokens": ["Das", "ist", "der", "Un\u00b7ter\u00b7scheid", ":", "Die", "Bau\u00b7ern", "hin\u00b7term", "pfl\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Begreiffen ihre Kunst und Wi\u00dfenschafft im Kriegen:", "tokens": ["Be\u00b7greif\u00b7fen", "ih\u00b7re", "Kunst", "und", "Wi\u00b7\u00dfen\u00b7schafft", "im", "Krie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel Bauern Kinder sehn in Finstern Zimmern an,", "tokens": ["Viel", "Bau\u00b7ern", "Kin\u00b7der", "sehn", "in", "Fins\u00b7tern", "Zim\u00b7mern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "APPR", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Draus kaum der Zehnde das, was hier ein Bader kan.", "tokens": ["Draus", "kaum", "der", "Zehn\u00b7de", "das", ",", "was", "hier", "ein", "Ba\u00b7der", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ART", "NN", "PDS", "$,", "PRELS", "ADV", "ART", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}