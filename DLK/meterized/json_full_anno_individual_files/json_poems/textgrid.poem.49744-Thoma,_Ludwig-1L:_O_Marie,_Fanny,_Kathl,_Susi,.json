{"textgrid.poem.49744": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: O Marie, Fanny, Kathl, Susi,", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O Marie, Fanny, Kathl, Susi,", "tokens": ["O", "Ma\u00b7rie", ",", "Fan\u00b7ny", ",", "Kathl", ",", "Su\u00b7si", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr blonden, braunen, runden Gspusi,", "tokens": ["Ihr", "blon\u00b7den", ",", "brau\u00b7nen", ",", "run\u00b7den", "Gs\u00b7pu\u00b7si", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Las't ihr, was jetzt geschrieben war?", "tokens": ["Las't", "ihr", ",", "was", "jetzt", "ge\u00b7schrie\u00b7ben", "war", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr d\u00fcrfet keinen Schatz mehr kriegen,", "tokens": ["Ihr", "d\u00fcr\u00b7fet", "kei\u00b7nen", "Schatz", "mehr", "krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In keinem fremden Bett mehr liegen,", "tokens": ["In", "kei\u00b7nem", "frem\u00b7den", "Bett", "mehr", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist f\u00fcr immer aus und gar.", "tokens": ["Das", "ist", "f\u00fcr", "im\u00b7mer", "aus", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ADV", "PTKVZ", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach ja, wenn man an Ausgehtagen", "tokens": ["Ach", "ja", ",", "wenn", "man", "an", "Aus\u00b7geh\u00b7ta\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "ITJ", "$,", "KOUS", "PIS", "APPR", "NN"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als ein \u00bbVerh\u00e4ltnis\u00ab sozusagen", "tokens": ["Als", "ein", "\u00bb", "Ver\u00b7h\u00e4lt\u00b7nis", "\u00ab", "so\u00b7zu\u00b7sa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "ART", "$(", "NN", "$(", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beim Pschorr und Augustiner sa\u00df,", "tokens": ["Beim", "Pschorr", "und", "Au\u00b7gus\u00b7ti\u00b7ner", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie war man gl\u00fccklich da von Herzen,", "tokens": ["Wie", "war", "man", "gl\u00fcck\u00b7lich", "da", "von", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIS", "ADJD", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man dar\u00fcber alle Schmerzen", "tokens": ["Da\u00df", "man", "da\u00b7r\u00fc\u00b7ber", "al\u00b7le", "Schmer\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PAV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und alle M\u00fchen schnell verga\u00df!", "tokens": ["Und", "al\u00b7le", "M\u00fc\u00b7hen", "schnell", "ver\u00b7ga\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die ganze Woche das Gemuddel", "tokens": ["Die", "gan\u00b7ze", "Wo\u00b7che", "das", "Ge\u00b7mud\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hinter einer Ladenbuddel;", "tokens": ["Und", "hin\u00b7ter", "ei\u00b7ner", "La\u00b7den\u00b7bud\u00b7del", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur einen Tag, da war man frei", "tokens": ["Nur", "ei\u00b7nen", "Tag", ",", "da", "war", "man", "frei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "VAFIN", "PIS", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und durfte ", "tokens": ["Und", "durf\u00b7te"], "token_info": ["word", "word"], "pos": ["KON", "VMFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Und h\u00f6rt' was Liebes nach dem Schelten", "tokens": ["Und", "h\u00f6rt'", "was", "Lie\u00b7bes", "nach", "dem", "Schel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und glaubte, da\u00df man gl\u00fccklich sei.", "tokens": ["Und", "glaub\u00b7te", ",", "da\u00df", "man", "gl\u00fcck\u00b7lich", "sei", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und wenn wir dann nach Hause kamen,", "tokens": ["Und", "wenn", "wir", "dann", "nach", "Hau\u00b7se", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nun freilich und in Gottes Namen, \u2013", "tokens": ["Nun", "frei\u00b7lich", "und", "in", "Got\u00b7tes", "Na\u00b7men", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "KON", "APPR", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man war so jung und war allein.", "tokens": ["Man", "war", "so", "jung", "und", "war", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "KON", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was schiert die Welt sich um uns beide?", "tokens": ["Was", "schiert", "die", "Welt", "sich", "um", "uns", "bei\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PRF", "APPR", "PPER", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geschah doch niemand was zuleide!", "tokens": ["Ge\u00b7schah", "doch", "nie\u00b7mand", "was", "zu\u00b7lei\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Warum denn soll es S\u00fcnde sein?", "tokens": ["Wa\u00b7rum", "denn", "soll", "es", "S\u00fcn\u00b7de", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O Kathi, das ist schlecht verteidigt!", "tokens": ["O", "Ka\u00b7thi", ",", "das", "ist", "schlecht", "ver\u00b7tei\u00b7digt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PDS", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Wer nicht mehr kann, ist bald beleidigt,", "tokens": ["Wer", "nicht", "mehr", "kann", ",", "ist", "bald", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ADV", "VMFIN", "$,", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Tugend liegt im Wackelbein.", "tokens": ["Die", "Tu\u00b7gend", "liegt", "im", "Wa\u00b7ckel\u00b7bein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Zitterknie ist's, was uns heiligt;", "tokens": ["Das", "Zit\u00b7ter\u00b7knie", "ist's", ",", "was", "uns", "hei\u00b7ligt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Lies nur, wer alles sich beteiligt,", "tokens": ["Lies", "nur", ",", "wer", "al\u00b7les", "sich", "be\u00b7tei\u00b7ligt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PWS", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Liste sagt es schon allein.", "tokens": ["Die", "Lis\u00b7te", "sagt", "es", "schon", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "O Marie, Fanny, Kathl, Susi,", "tokens": ["O", "Ma\u00b7rie", ",", "Fan\u00b7ny", ",", "Kathl", ",", "Su\u00b7si", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr blonden, braunen, runden Gspusi,", "tokens": ["Ihr", "blon\u00b7den", ",", "brau\u00b7nen", ",", "run\u00b7den", "Gs\u00b7pu\u00b7si", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Las't ihr, was jetzt geschrieben war?", "tokens": ["Las't", "ihr", ",", "was", "jetzt", "ge\u00b7schrie\u00b7ben", "war", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr d\u00fcrfet keinen Schatz mehr kriegen,", "tokens": ["Ihr", "d\u00fcr\u00b7fet", "kei\u00b7nen", "Schatz", "mehr", "krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In keinem fremden Bett mehr liegen,", "tokens": ["In", "kei\u00b7nem", "frem\u00b7den", "Bett", "mehr", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist f\u00fcr immer aus und gar.", "tokens": ["Das", "ist", "f\u00fcr", "im\u00b7mer", "aus", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ADV", "PTKVZ", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ach ja, wenn man an Ausgehtagen", "tokens": ["Ach", "ja", ",", "wenn", "man", "an", "Aus\u00b7geh\u00b7ta\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "ITJ", "$,", "KOUS", "PIS", "APPR", "NN"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als ein \u00bbVerh\u00e4ltnis\u00ab sozusagen", "tokens": ["Als", "ein", "\u00bb", "Ver\u00b7h\u00e4lt\u00b7nis", "\u00ab", "so\u00b7zu\u00b7sa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "ART", "$(", "NN", "$(", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beim Pschorr und Augustiner sa\u00df,", "tokens": ["Beim", "Pschorr", "und", "Au\u00b7gus\u00b7ti\u00b7ner", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie war man gl\u00fccklich da von Herzen,", "tokens": ["Wie", "war", "man", "gl\u00fcck\u00b7lich", "da", "von", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIS", "ADJD", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man dar\u00fcber alle Schmerzen", "tokens": ["Da\u00df", "man", "da\u00b7r\u00fc\u00b7ber", "al\u00b7le", "Schmer\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PAV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und alle M\u00fchen schnell verga\u00df!", "tokens": ["Und", "al\u00b7le", "M\u00fc\u00b7hen", "schnell", "ver\u00b7ga\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die ganze Woche das Gemuddel", "tokens": ["Die", "gan\u00b7ze", "Wo\u00b7che", "das", "Ge\u00b7mud\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hinter einer Ladenbuddel;", "tokens": ["Und", "hin\u00b7ter", "ei\u00b7ner", "La\u00b7den\u00b7bud\u00b7del", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur einen Tag, da war man frei", "tokens": ["Nur", "ei\u00b7nen", "Tag", ",", "da", "war", "man", "frei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "VAFIN", "PIS", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und durfte ", "tokens": ["Und", "durf\u00b7te"], "token_info": ["word", "word"], "pos": ["KON", "VMFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Und h\u00f6rt' was Liebes nach dem Schelten", "tokens": ["Und", "h\u00f6rt'", "was", "Lie\u00b7bes", "nach", "dem", "Schel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und glaubte, da\u00df man gl\u00fccklich sei.", "tokens": ["Und", "glaub\u00b7te", ",", "da\u00df", "man", "gl\u00fcck\u00b7lich", "sei", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und wenn wir dann nach Hause kamen,", "tokens": ["Und", "wenn", "wir", "dann", "nach", "Hau\u00b7se", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nun freilich und in Gottes Namen, \u2013", "tokens": ["Nun", "frei\u00b7lich", "und", "in", "Got\u00b7tes", "Na\u00b7men", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "KON", "APPR", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man war so jung und war allein.", "tokens": ["Man", "war", "so", "jung", "und", "war", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "KON", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was schiert die Welt sich um uns beide?", "tokens": ["Was", "schiert", "die", "Welt", "sich", "um", "uns", "bei\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PRF", "APPR", "PPER", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geschah doch niemand was zuleide!", "tokens": ["Ge\u00b7schah", "doch", "nie\u00b7mand", "was", "zu\u00b7lei\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Warum denn soll es S\u00fcnde sein?", "tokens": ["Wa\u00b7rum", "denn", "soll", "es", "S\u00fcn\u00b7de", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "O Kathi, das ist schlecht verteidigt!", "tokens": ["O", "Ka\u00b7thi", ",", "das", "ist", "schlecht", "ver\u00b7tei\u00b7digt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PDS", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Wer nicht mehr kann, ist bald beleidigt,", "tokens": ["Wer", "nicht", "mehr", "kann", ",", "ist", "bald", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ADV", "VMFIN", "$,", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Tugend liegt im Wackelbein.", "tokens": ["Die", "Tu\u00b7gend", "liegt", "im", "Wa\u00b7ckel\u00b7bein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Zitterknie ist's, was uns heiligt;", "tokens": ["Das", "Zit\u00b7ter\u00b7knie", "ist's", ",", "was", "uns", "hei\u00b7ligt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Lies nur, wer alles sich beteiligt,", "tokens": ["Lies", "nur", ",", "wer", "al\u00b7les", "sich", "be\u00b7tei\u00b7ligt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PWS", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Liste sagt es schon allein.", "tokens": ["Die", "Lis\u00b7te", "sagt", "es", "schon", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}