{"textgrid.poem.67374": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Stanzen", "genre": "verse", "period": "N.A.", "pub_year": 1789, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im ersten Herbst von meinen Lebensjahren,", "tokens": ["Im", "ers\u00b7ten", "Herbst", "von", "mei\u00b7nen", "Le\u00b7bens\u00b7jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nachdem mich mancher schwere Tag gedr\u00fcckt,", "tokens": ["Nach\u00b7dem", "mich", "man\u00b7cher", "schwe\u00b7re", "Tag", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nachdem ich beiderlei Geschick erfahren,", "tokens": ["Nach\u00b7dem", "ich", "bei\u00b7der\u00b7lei", "Ge\u00b7schick", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das eigne Schuld und fremdes Gl\u00fcck uns schickt,", "tokens": ["Das", "eig\u00b7ne", "Schuld", "und", "frem\u00b7des", "Gl\u00fcck", "uns", "schickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auch mancherlei Gespenst des Wunderbaren", "tokens": ["Auch", "man\u00b7cher\u00b7lei", "Ge\u00b7spenst", "des", "Wun\u00b7der\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und manche Lieb' und Huldgestalt erblickt,", "tokens": ["Und", "man\u00b7che", "Lieb'", "und", "Huld\u00b7ge\u00b7stalt", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Rief eine Stimme mich, jenseit der H\u00f6hen", "tokens": ["Rief", "ei\u00b7ne", "Stim\u00b7me", "mich", ",", "jen\u00b7seit", "der", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPER", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das Land der Abenteu'r und Kunst zu sehen.", "tokens": ["Das", "Land", "der", "A\u00b7ben\u00b7teu'r", "und", "Kunst", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "\u00bblebt,\u00ab sprach ich, \u00bblebet wohl, Ihr, meine Freude,", "tokens": ["\u00bb", "lebt", ",", "\u00ab", "sprach", "ich", ",", "\u00bb", "le\u00b7bet", "wohl", ",", "Ihr", ",", "mei\u00b7ne", "Freu\u00b7de", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "ADV", "$,", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein Trost und meiner W\u00fcnsche kleine Schaar,", "tokens": ["Mein", "Trost", "und", "mei\u00b7ner", "W\u00fcn\u00b7sche", "klei\u00b7ne", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihr, deren Anblick mir in manchem Leide", "tokens": ["Ihr", ",", "de\u00b7ren", "An\u00b7blick", "mir", "in", "man\u00b7chem", "Lei\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "NN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Nektartropfe vom Olympus war;", "tokens": ["Ein", "Nekt\u00b7ar\u00b7trop\u00b7fe", "vom", "O\u00b7lym\u00b7pus", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und Du, an der ich meine Seele weide,", "tokens": ["Und", "Du", ",", "an", "der", "ich", "mei\u00b7ne", "See\u00b7le", "wei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die mir mich selbst, die mir mein Gl\u00fcck gebar \u2013", "tokens": ["Die", "mir", "mich", "selbst", ",", "die", "mir", "mein", "Gl\u00fcck", "ge\u00b7bar", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "$,", "PRELS", "PPER", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Lebt Alle wohl und la\u00dft mich jetzt verschwinden,", "tokens": ["Lebt", "Al\u00b7le", "wohl", "und", "la\u00dft", "mich", "jetzt", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "KON", "VVIMP", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bald neu verj\u00fcngt Euch freudig wiederfinden!\u00ab", "tokens": ["Bald", "neu", "ver\u00b7j\u00fcngt", "Euch", "freu\u00b7dig", "wie\u00b7der\u00b7fin\u00b7den", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "\u00bbleb wohl,\u00ab so sprach mit Schluchzen und mit Weinen", "tokens": ["\u00bb", "leb", "wohl", ",", "\u00ab", "so", "sprach", "mit", "Schluch\u00b7zen", "und", "mit", "Wei\u00b7nen"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVIMP", "ADV", "$,", "$(", "ADV", "VVFIN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gro\u00dfm\u00fcthig Ariadne, \u00bblebe wohl!\u00ab", "tokens": ["Gro\u00df\u00b7m\u00fct\u00b7hig", "A\u00b7riad\u00b7ne", ",", "\u00bb", "le\u00b7be", "wohl", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADJD", "NN", "$,", "$(", "VVFIN", "ADV", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und schlang den Arm um mich und unsre Kleinen;", "tokens": ["Und", "schlang", "den", "Arm", "um", "mich", "und", "uns\u00b7re", "Klei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch h\u00f6r' ich es, wie ihre Stimme scholl,", "tokens": ["Noch", "h\u00f6r'", "ich", "es", ",", "wie", "ih\u00b7re", "Stim\u00b7me", "scholl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "PWAV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch seh' ich mir ihr liebes Bild erscheinen,", "tokens": ["Noch", "seh'", "ich", "mir", "ihr", "lie\u00b7bes", "Bild", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die H\u00e4nde ringend, rufend: \u00bbLebe wohl!\u00ab", "tokens": ["Die", "H\u00e4n\u00b7de", "rin\u00b7gend", ",", "ru\u00b7fend", ":", "\u00bb", "Le\u00b7be", "wohl", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "VVPP", "$.", "$(", "VVIMP", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und bin gewi\u00df, so lang' der Ton mich leitet,", "tokens": ["Und", "bin", "ge\u00b7wi\u00df", ",", "so", "lang'", "der", "Ton", "mich", "lei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "ADV", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df nie mein Schritt, nie meine Hoffnung gleitet.", "tokens": ["Da\u00df", "nie", "mein", "Schritt", ",", "nie", "mei\u00b7ne", "Hoff\u00b7nung", "glei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich schied; und \u00fcber Nebel, Berg' und Thale", "tokens": ["Ich", "schied", ";", "und", "\u00fc\u00b7ber", "Ne\u00b7bel", ",", "Ber\u00b7g'", "und", "Tha\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "KON", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zog mich der Weg ins sch\u00f6ne Frankenland,", "tokens": ["Zog", "mich", "der", "Weg", "ins", "sch\u00f6\u00b7ne", "Fran\u00b7ken\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo ich bei manchem alten Ehrenmale", "tokens": ["Wo", "ich", "bei", "man\u00b7chem", "al\u00b7ten", "Eh\u00b7ren\u00b7ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der deutschen Kunst auch deutsche Sitten fand", "tokens": ["Der", "deut\u00b7schen", "Kunst", "auch", "deut\u00b7sche", "Sit\u00b7ten", "fand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und, wie vor\u00fcbergleitend mit dem Strahle", "tokens": ["Und", ",", "wie", "vor\u00b7\u00fc\u00b7berg\u00b7lei\u00b7tend", "mit", "dem", "Strah\u00b7le"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "PWAV", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Sonne, manches gute Herz gekannt.", "tokens": ["Der", "Son\u00b7ne", ",", "man\u00b7ches", "gu\u00b7te", "Herz", "ge\u00b7kannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So glitt ich sanft hinab, und mit Vergn\u00fcgen", "tokens": ["So", "glitt", "ich", "sanft", "hin\u00b7ab", ",", "und", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sah ich im Geist die Alpen vor mir liegen.", "tokens": ["Sah", "ich", "im", "Geist", "die", "Al\u00b7pen", "vor", "mir", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ach! aber da umfing in Augsburg's Mauern", "tokens": ["Ach", "!", "a\u00b7ber", "da", "um\u00b7fing", "in", "Augs\u00b7bur\u00b7g's", "Mau\u00b7ern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "ADV", "ADV", "VVFIN", "APPR", "NE", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mich welch ein b\u00f6ser, f\u00fcrchterlicher Traum!", "tokens": ["Mich", "welch", "ein", "b\u00f6\u00b7ser", ",", "f\u00fcrch\u00b7ter\u00b7li\u00b7cher", "Traum", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PWAT", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Schreckbilder sah ich vor mir, um mich lauern;", "tokens": ["Schreck\u00b7bil\u00b7der", "sah", "ich", "vor", "mir", ",", "um", "mich", "lau\u00b7ern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPER", "$,", "KOUI", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich sah und traute meinen Augen kaum.", "tokens": ["Ich", "sah", "und", "trau\u00b7te", "mei\u00b7nen", "Au\u00b7gen", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbwas hilft Dir,\u00ab sprach ich, \u00bbDeine Angst, Dein Trauern?", "tokens": ["\u00bb", "was", "hilft", "Dir", ",", "\u00ab", "sprach", "ich", ",", "\u00bb", "Dei\u00b7ne", "Angst", ",", "Dein", "Trau\u00b7ern", "?"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gieb Deinem Herzen, Deinen Blicken Raum!\u00ab", "tokens": ["Gieb", "Dei\u00b7nem", "Her\u00b7zen", ",", "Dei\u00b7nen", "Bli\u00b7cken", "Raum", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und sieh, da kam, von Westen hergetragen,", "tokens": ["Und", "sieh", ",", "da", "kam", ",", "von", "Wes\u00b7ten", "her\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Pandora an auf Epimetheus' Wagen.", "tokens": ["Pan\u00b7do\u00b7ra", "an", "auf", "E\u00b7pi\u00b7me\u00b7theus'", "Wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "APPR", "NN", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbich komme nicht um mich, nur Eurethalben;", "tokens": ["\u00bb", "ich", "kom\u00b7me", "nicht", "um", "mich", ",", "nur", "Eu\u00b7re\u00b7thal\u00b7ben", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "$,", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Versch\u00f6nen will ich Euer Wandeln Euch.\u00ab", "tokens": ["Ver\u00b7sch\u00f6\u00b7nen", "will", "ich", "Eu\u00b7er", "Wan\u00b7deln", "Euch", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VMFIN", "PPER", "PPOSAT", "NN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So sprach sie, duftend ihrer B\u00fcchse Salben,", "tokens": ["So", "sprach", "sie", ",", "duf\u00b7tend", "ih\u00b7rer", "B\u00fcch\u00b7se", "Sal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als \u00f6ffnete sie uns Cytherens Reich.", "tokens": ["Als", "\u00f6ff\u00b7ne\u00b7te", "sie", "uns", "Cy\u00b7the\u00b7rens", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PRF", "NE", "NE", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bbuns werden Rosen bl\u00fchn; die welken, fallen,", "tokens": ["\u00bb", "uns", "wer\u00b7den", "Ro\u00b7sen", "bl\u00fchn", ";", "die", "wel\u00b7ken", ",", "fal\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "NN", "VVINF", "$.", "ART", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verwandeln sich vor uns in Kn\u00f6spchen gleich.\u00ab", "tokens": ["Ver\u00b7wan\u00b7deln", "sich", "vor", "uns", "in", "Kn\u00f6spc\u00b7hen", "gleich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "APPR", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So sprach sie; aber ach, Ihr guten Stunden,", "tokens": ["So", "sprach", "sie", ";", "a\u00b7ber", "ach", ",", "Ihr", "gu\u00b7ten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADV", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ihr waret mir, mir war mein Gl\u00fcck verschwunden!", "tokens": ["Ihr", "wa\u00b7ret", "mir", ",", "mir", "war", "mein", "Gl\u00fcck", "ver\u00b7schwun\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wie zog ich mich auf grauer Alpen R\u00fccken,", "tokens": ["Wie", "zog", "ich", "mich", "auf", "grau\u00b7er", "Al\u00b7pen", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Beschwert im Herzen, m\u00fchsam auf und ab!", "tokens": ["Be\u00b7schwert", "im", "Her\u00b7zen", ",", "m\u00fch\u00b7sam", "auf", "und", "ab", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$,", "ADJD", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Jedweder Fels schien \u00e4chzend mich zu dr\u00fccken,", "tokens": ["Jed\u00b7we\u00b7der", "Fels", "schien", "\u00e4ch\u00b7zend", "mich", "zu", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Jedwedes Thal schien meiner W\u00fcnsche Grab;", "tokens": ["Jed\u00b7we\u00b7des", "Thal", "schien", "mei\u00b7ner", "W\u00fcn\u00b7sche", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und als mit neuem, wonnigem Entz\u00fccken", "tokens": ["Und", "als", "mit", "neu\u00b7em", ",", "won\u00b7ni\u00b7gem", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verona seinen Schoo\u00df dem Blicke gab,", "tokens": ["Ve\u00b7ro\u00b7na", "sei\u00b7nen", "Schoo\u00df", "dem", "Bli\u00b7cke", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Da sprach zu mir, nie werd' ich es vergessen,", "tokens": ["Da", "sprach", "zu", "mir", ",", "nie", "werd'", "ich", "es", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "$,", "ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein Geist herab vom Gipfel der Cypressen.", "tokens": ["Ein", "Geist", "her\u00b7ab", "vom", "Gip\u00b7fel", "der", "Cyp\u00b7res\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Ich stand, der Abendsonne mich zu freuen,", "tokens": ["Ich", "stand", ",", "der", "A\u00b7bend\u00b7son\u00b7ne", "mich", "zu", "freu\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und \u00fcbersah die weite Lombardei.", "tokens": ["Und", "\u00fc\u00b7ber\u00b7sah", "die", "wei\u00b7te", "Lom\u00b7bar\u00b7dei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbwoher,\u00ab sprach ich, \u00bbo Geist, dies Mi\u00dfgedeihen", "tokens": ["\u00bb", "wo\u00b7her", ",", "\u00ab", "sprach", "ich", ",", "\u00bb", "o", "Geist", ",", "dies", "Mi\u00df\u00b7ge\u00b7dei\u00b7hen"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PWAV", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "FM", "NN", "$,", "PDS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schuldloser W\u00fcnsche? sprich, woher es sei?\u00ab", "tokens": ["Schuld\u00b7lo\u00b7ser", "W\u00fcn\u00b7sche", "?", "sprich", ",", "wo\u00b7her", "es", "sei", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "ADJD", "$,", "PWAV", "PPER", "VAFIN", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "\u00bbdie alte Schuld unwahrer Buhlereien!\u00ab", "tokens": ["\u00bb", "die", "al\u00b7te", "Schuld", "un\u00b7wah\u00b7rer", "Buh\u00b7le\u00b7rei\u00b7en", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sprach der Geist und rauschte sanft vorbei.", "tokens": ["So", "sprach", "der", "Geist", "und", "rauschte", "sanft", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbstatt jetzt dies Land in Friede zu genie\u00dfen,", "tokens": ["\u00bb", "statt", "jetzt", "dies", "Land", "in", "Frie\u00b7de", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PDS", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Kommst Du hieher, f\u00fcr alte Schuld zu b\u00fc\u00dfen.", "tokens": ["Kommst", "Du", "hie\u00b7her", ",", "f\u00fcr", "al\u00b7te", "Schuld", "zu", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$,", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Verw\u00f6hnt von Deinen nur zu milden Sternen,", "tokens": ["Ver\u00b7w\u00f6hnt", "von", "Dei\u00b7nen", "nur", "zu", "mil\u00b7den", "Ster\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schien Dir zu arm des Lebens reichstes Gl\u00fcck.", "tokens": ["Schien", "Dir", "zu", "arm", "des", "Le\u00b7bens", "reichs\u00b7tes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKA", "ADJD", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was Du genossen, sollst Du kennen lernen;", "tokens": ["Was", "Du", "ge\u00b7nos\u00b7sen", ",", "sollst", "Du", "ken\u00b7nen", "ler\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn nur im Darben sieht der Thor zur\u00fcck.", "tokens": ["Denn", "nur", "im", "Dar\u00b7ben", "sieht", "der", "Thor", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Drum hie\u00df von Deinen Lieben Dich entfernen", "tokens": ["Drum", "hie\u00df", "von", "Dei\u00b7nen", "Lie\u00b7ben", "Dich", "ent\u00b7fer\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "PPOSAT", "ADJA", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dein g\u00fcnstiges, Dein besserndes Geschick.", "tokens": ["Dein", "g\u00fcns\u00b7ti\u00b7ges", ",", "Dein", "bes\u00b7sern\u00b7des", "Ge\u00b7schick", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Du sollst, um Deine Weisheit neu zu \u00fcben,", "tokens": ["Du", "sollst", ",", "um", "Dei\u00b7ne", "Weis\u00b7heit", "neu", "zu", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUI", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Jetzt ", "tokens": ["Jetzt"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}}, "stanza.10": {"line.1": {"text": "Nie hast Du im Ger\u00e4usch der Welt den Frieden", "tokens": ["Nie", "hast", "Du", "im", "Ge\u00b7r\u00e4usch", "der", "Welt", "den", "Frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des eignen Herzens sittsam Dir bewahrt,", "tokens": ["Des", "eig\u00b7nen", "Her\u00b7zens", "sitt\u00b7sam", "Dir", "be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nie zwischen Mensch und Menschen unterschieden,", "tokens": ["Nie", "zwi\u00b7schen", "Mensch", "und", "Men\u00b7schen", "un\u00b7ter\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nie eingesehn, was f\u00fcr ein Gl\u00fcck Dir ward,", "tokens": ["Nie", "ein\u00b7ge\u00b7sehn", ",", "was", "f\u00fcr", "ein", "Gl\u00fcck", "Dir", "ward", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "PRELS", "APPR", "ART", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Es zu betr\u00fcben, nie genug vermieden,", "tokens": ["Es", "zu", "be\u00b7tr\u00fc\u00b7ben", ",", "nie", "ge\u00b7nug", "ver\u00b7mie\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es zu genie\u00dfen, nie genug gespart;", "tokens": ["Es", "zu", "ge\u00b7nie\u00b7\u00dfen", ",", "nie", "ge\u00b7nug", "ge\u00b7spart", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Daf\u00fcr den treusten Herzen jetzt entnommen,", "tokens": ["Da\u00b7f\u00fcr", "den", "treus\u00b7ten", "Her\u00b7zen", "jetzt", "ent\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bist Du hieher ins Land der K\u00fcnste kommen.\u00ab", "tokens": ["Bist", "Du", "hie\u00b7her", "ins", "Land", "der", "K\u00fcns\u00b7te", "kom\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "PAV", "APPRART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Er sprach's; und ach, wie wahr hast Du gesprochen,", "tokens": ["Er", "sprach's", ";", "und", "ach", ",", "wie", "wahr", "hast", "Du", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KON", "XY", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Geist der Cypresse, wie so grausam wahr!", "tokens": ["Geist", "der", "Cyp\u00b7res\u00b7se", ",", "wie", "so", "grau\u00b7sam", "wahr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PWAV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ihr guten Herzen seid genug gerochen;", "tokens": ["Ihr", "gu\u00b7ten", "Her\u00b7zen", "seid", "ge\u00b7nug", "ge\u00b7ro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich sehe mich und Euch so hell und klar.", "tokens": ["Ich", "se\u00b7he", "mich", "und", "Euch", "so", "hell", "und", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was th\u00e4tig und unth\u00e4tig ich verbrochen,", "tokens": ["Was", "th\u00e4\u00b7tig", "und", "un\u00b7th\u00e4\u00b7tig", "ich", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Macht jeder Schritt mir kund und offenbar.", "tokens": ["Macht", "je\u00b7der", "Schritt", "mir", "kund", "und", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "PPER", "PTKVZ", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich seh', ich mu\u00dfte mich von Euch entfernen", "tokens": ["Ich", "seh'", ",", "ich", "mu\u00df\u00b7te", "mich", "von", "Euch", "ent\u00b7fer\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PRF", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und durch Verlust des Lebens Weisheit lernen.", "tokens": ["Und", "durch", "Ver\u00b7lust", "des", "Le\u00b7bens", "Weis\u00b7heit", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Dank also Euch, Ihr g\u00f6ttlichen Medusen,", "tokens": ["Dank", "al\u00b7so", "Euch", ",", "Ihr", "g\u00f6tt\u00b7li\u00b7chen", "Me\u00b7du\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die mich gelehrt, da\u00df Ihr Medusen seid!", "tokens": ["Die", "mich", "ge\u00b7lehrt", ",", "da\u00df", "Ihr", "Me\u00b7du\u00b7sen", "seid", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "KOUS", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dank Euch, Ihr todten K\u00fcnste, kalte Musen,", "tokens": ["Dank", "Euch", ",", "Ihr", "tod\u00b7ten", "K\u00fcns\u00b7te", ",", "kal\u00b7te", "Mu\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zerfallne Mauern, Grab der Eitelkeit!", "tokens": ["Zer\u00b7fall\u00b7ne", "Mau\u00b7ern", ",", "Grab", "der", "Ei\u00b7tel\u00b7keit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn je dem falschen, je dem Marmorbusen", "tokens": ["Wenn", "je", "dem", "fal\u00b7schen", ",", "je", "dem", "Mar\u00b7mor\u00b7bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Statt wahrer Herzen Weihrauch ich gestreut,", "tokens": ["Statt", "wah\u00b7rer", "Her\u00b7zen", "Weih\u00b7rauch", "ich", "ge\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.7": {"text": "So nehmt von mir den letzten Zoll hienieden,", "tokens": ["So", "nehmt", "von", "mir", "den", "letz\u00b7ten", "Zoll", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der Reue Zoll, und la\u00dft mich ziehn in Frieden!", "tokens": ["Der", "Reu\u00b7e", "Zoll", ",", "und", "la\u00dft", "mich", "ziehn", "in", "Frie\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KON", "VVIMP", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Auch Euch, Ihr der Natur erhabne Scenen,", "tokens": ["Auch", "Euch", ",", "Ihr", "der", "Na\u00b7tur", "er\u00b7hab\u00b7ne", "Sce\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gebirge, Felsen, Ebnen, Ufer, Meer,", "tokens": ["Ge\u00b7bir\u00b7ge", ",", "Fel\u00b7sen", ",", "Eb\u00b7nen", ",", "U\u00b7fer", ",", "Meer", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du Meer von Adria und Ihr Sirenen", "tokens": ["Du", "Meer", "von", "Ad\u00b7ria", "und", "Ihr", "Si\u00b7re\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "APPR", "NE", "KON", "PPOSAT", "NN"], "meter": "-+-+-++---", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Parthenope's, Ihr Inseln um sie her,", "tokens": ["Par\u00b7the\u00b7no\u00b7pe's", ",", "Ihr", "In\u00b7seln", "um", "sie", "her", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Dank Euch, da\u00df, mit mir selbst mich zu vers\u00f6hnen,", "tokens": ["Dank", "Euch", ",", "da\u00df", ",", "mit", "mir", "selbst", "mich", "zu", "ver\u00b7s\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUS", "$,", "APPR", "PPER", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ihr meine Brust von Seufzern machtet schwer!", "tokens": ["Ihr", "mei\u00b7ne", "Brust", "von", "Seuf\u00b7zern", "mach\u00b7tet", "schwer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Mit unschuldsvollem, liebeszartem Sehnen", "tokens": ["Mit", "un\u00b7schulds\u00b7vol\u00b7lem", ",", "lie\u00b7bes\u00b7zar\u00b7tem", "Seh\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "PIS", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Weiht' ich, der Menschheit froh, Euch stille Thr\u00e4nen.", "tokens": ["Weiht'", "ich", ",", "der", "Menschheit", "froh", ",", "Euch", "stil\u00b7le", "Thr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "ADJD", "$,", "PPER", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.14": {"line.1": {"text": "Und Ihr erquicktet mich, als in Verona", "tokens": ["Und", "Ihr", "er\u00b7quick\u00b7tet", "mich", ",", "als", "in", "Ve\u00b7ro\u00b7na"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "KOUS", "APPR", "NE"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die Sonne nieder, als sie aufw\u00e4rts stieg", "tokens": ["Die", "Son\u00b7ne", "nie\u00b7der", ",", "als", "sie", "auf\u00b7w\u00e4rts", "stieg"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KOUS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In Rimini, und ich dann in Ancona", "tokens": ["In", "Ri\u00b7mi\u00b7ni", ",", "und", "ich", "dann", "in", "An\u00b7co\u00b7na"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KON", "PPER", "ADV", "APPR", "NE"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Mich mit dem Meer verm\u00e4hlete und schwieg;", "tokens": ["Mich", "mit", "dem", "Meer", "ver\u00b7m\u00e4h\u00b7le\u00b7te", "und", "schwieg", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Mit Dir verm\u00e4hlt' ich mich, o Dea Bona,", "tokens": ["Mit", "Dir", "ver\u00b7m\u00e4hlt'", "ich", "mich", ",", "o", "Dea", "Bo\u00b7na", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "PRF", "$,", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Du gute G\u00f6ttin, mit der Hoffnung Sieg,", "tokens": ["Du", "gu\u00b7te", "G\u00f6t\u00b7tin", ",", "mit", "der", "Hoff\u00b7nung", "Sieg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wie die Sonne war ich liebestrunken", "tokens": ["Und", "wie", "die", "Son\u00b7ne", "war", "ich", "lie\u00b7be\u00b7strun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Aus Deinem Arm in Deinen Schoo\u00df gesunken.", "tokens": ["Aus", "Dei\u00b7nem", "Arm", "in", "Dei\u00b7nen", "Schoo\u00df", "ge\u00b7sun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "O gute G\u00f6ttin, darf ich, darf ich nennen", "tokens": ["O", "gu\u00b7te", "G\u00f6t\u00b7tin", ",", "darf", "ich", ",", "darf", "ich", "nen\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "VMFIN", "PPER", "$,", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den heil'gen Namen? Nenn' ich Dich Natur?", "tokens": ["Den", "heil'\u00b7gen", "Na\u00b7men", "?", "Nenn'", "ich", "Dich", "Na\u00b7tur", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "VVFIN", "PPER", "PRF", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nenn' ich Dich Liebe? Ach, nur Dich zu kennen,", "tokens": ["Nenn'", "ich", "Dich", "Lie\u00b7be", "?", "Ach", ",", "nur", "Dich", "zu", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "NN", "$.", "ITJ", "$,", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Irr' ich umher auf alles Wissens Spur.", "tokens": ["Irr'", "ich", "um\u00b7her", "auf", "al\u00b7les", "Wis\u00b7sens", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und doch, um reiner Flamm' in Dir zu brennen,", "tokens": ["Und", "doch", ",", "um", "rei\u00b7ner", "Flamm'", "in", "Dir", "zu", "bren\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUI", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bedarf ich reiner Lieb' und Weisheit nur.", "tokens": ["Be\u00b7darf", "ich", "rei\u00b7ner", "Lieb'", "und", "Weis\u00b7heit", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Nicht Kunst, nicht Wissenschaft: die Kunst des Lebens", "tokens": ["Nicht", "Kunst", ",", "nicht", "Wis\u00b7sen\u00b7schaft", ":", "die", "Kunst", "des", "Le\u00b7bens"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "NN", "$,", "PTKNEG", "NN", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ist Wissenschaft; sonst ist die Kunst vergebens.", "tokens": ["Ist", "Wis\u00b7sen\u00b7schaft", ";", "sonst", "ist", "die", "Kunst", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Du, G\u00f6ttin, wei\u00dft, da\u00df ich an jedem Bilde", "tokens": ["Du", ",", "G\u00f6t\u00b7tin", ",", "wei\u00dft", ",", "da\u00df", "ich", "an", "je\u00b7dem", "Bil\u00b7de"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des sch\u00f6nsten Marmors Dich, nur Dich gelernt,", "tokens": ["Des", "sch\u00f6ns\u00b7ten", "Mar\u00b7mors", "Dich", ",", "nur", "Dich", "ge\u00b7lernt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "$,", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df Du, so freundlich und mit Weisheit milde,", "tokens": ["Da\u00df", "Du", ",", "so", "freund\u00b7lich", "und", "mit", "Weis\u00b7heit", "mil\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADJD", "KON", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Durchs Sch\u00f6ne mir nur den Betrug entfernt.", "tokens": ["Durchs", "Sch\u00f6\u00b7ne", "mir", "nur", "den", "Be\u00b7trug", "ent\u00b7fernt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Dann schlich ich mich in andere Gefilde,", "tokens": ["Dann", "schlich", "ich", "mich", "in", "an\u00b7de\u00b7re", "Ge\u00b7fil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als die man mit Palett' und Mei\u00dfel lernt \u2013", "tokens": ["Als", "die", "man", "mit", "Pa\u00b7lett'", "und", "Mei\u00b7\u00dfel", "lernt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich lernt' an Eurem Knie, an Eurem Busen", "tokens": ["Ich", "lernt'", "an", "Eu\u00b7rem", "Knie", ",", "an", "Eu\u00b7rem", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nichts als ", "tokens": ["Nichts", "als"], "token_info": ["word", "word"], "pos": ["PIS", "KOKOM"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.17": {"line.1": {"text": "Und sah sie in den g\u00f6ttlichsten Gestalten,", "tokens": ["Und", "sah", "sie", "in", "den", "g\u00f6tt\u00b7lichs\u00b7ten", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Sah Weisheit, G\u00fcte, Macht als Menschenbild,", "tokens": ["Sah", "Weis\u00b7heit", ",", "G\u00fc\u00b7te", ",", "Macht", "als", "Men\u00b7schen\u00b7bild", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "$,", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sah jeder Sch\u00f6nheit Knospe sich entfalten,", "tokens": ["Sah", "je\u00b7der", "Sch\u00f6n\u00b7heit", "Knos\u00b7pe", "sich", "ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NE", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sah jede Art in Menschenform geh\u00fcllt;", "tokens": ["Sah", "je\u00b7de", "Art", "in", "Men\u00b7schen\u00b7form", "ge\u00b7h\u00fcllt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sah Kr\u00e4fte sprossen, wachsen und veralten", "tokens": ["Sah", "Kr\u00e4f\u00b7te", "spros\u00b7sen", ",", "wach\u00b7sen", "und", "ver\u00b7al\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NN", "VVFIN", "$,", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und jeden Zweig von ", "tokens": ["Und", "je\u00b7den", "Zweig", "von"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Sah hier das Licht aufgehen, steigen, schwinden", "tokens": ["Sah", "hier", "das", "Licht", "auf\u00b7ge\u00b7hen", ",", "stei\u00b7gen", ",", "schwin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVINF", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und lernte stets die Menschheit wiederfinden.", "tokens": ["Und", "lern\u00b7te", "stets", "die", "Menschheit", "wie\u00b7der\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Daneben sah ich \u2013 darf ich Dich auch nennen,", "tokens": ["Da\u00b7ne\u00b7ben", "sah", "ich", "\u2013", "darf", "ich", "Dich", "auch", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$(", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du inhumanes, alt- und neues Rom?", "tokens": ["Du", "in\u00b7hu\u00b7ma\u00b7nes", ",", "al\u00b7t", "und", "neu\u00b7es", "Rom", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "$,", "TRUNC", "KON", "ADJA", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch wer wird Dich im Namen nicht schon kennen,", "tokens": ["Doch", "wer", "wird", "Dich", "im", "Na\u00b7men", "nicht", "schon", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPER", "APPRART", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du Capitol und Du St. Peter's Dom?", "tokens": ["Du", "Ca\u00b7pi\u00b7tol", "und", "Du", "St.", "Pe\u00b7ter's", "Dom", "?"], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "PPER", "NE", "NE", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Du Pfuhl, aus dem, die Erde zu verbrennen,", "tokens": ["Du", "Pfuhl", ",", "aus", "dem", ",", "die", "Er\u00b7de", "zu", "ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "APPR", "ART", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ausging ein alter und ein neuer Strom,", "tokens": ["Aus\u00b7ging", "ein", "al\u00b7ter", "und", "ein", "neu\u00b7er", "Strom", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Von Kriegern einst bewohnt und Senatoren,", "tokens": ["Von", "Krie\u00b7gern", "einst", "be\u00b7wohnt", "und", "Se\u00b7na\u00b7to\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Von Pfaffen jetzt bewohnt und Monsignoren.", "tokens": ["Von", "Pfaf\u00b7fen", "jetzt", "be\u00b7wohnt", "und", "Mon\u00b7sig\u00b7no\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Ich lernte Dich und Deiner theuren Prinzen", "tokens": ["Ich", "lern\u00b7te", "Dich", "und", "Dei\u00b7ner", "theu\u00b7ren", "Prin\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Deiner Prinzessinnen sch\u00f6nes Heer,", "tokens": ["Und", "Dei\u00b7ner", "Prin\u00b7zes\u00b7sin\u00b7nen", "sch\u00f6\u00b7nes", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die W\u00fcsten Deiner darbenden Provinzen", "tokens": ["Die", "W\u00fcs\u00b7ten", "Dei\u00b7ner", "dar\u00b7ben\u00b7den", "Pro\u00b7vin\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Deiner Wissenschaften todtes Meer;", "tokens": ["Und", "Dei\u00b7ner", "Wis\u00b7sen\u00b7schaf\u00b7ten", "tod\u00b7tes", "Meer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Weisheit lernt' ich sehn mit Augen blinzen,", "tokens": ["Die", "Weis\u00b7heit", "lernt'", "ich", "sehn", "mit", "Au\u00b7gen", "blin\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Andacht sehn, von altem Taumel schwer,", "tokens": ["Die", "An\u00b7dacht", "sehn", ",", "von", "al\u00b7tem", "Tau\u00b7mel", "schwer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Heuchelei mit stolzen Sklavenmienen,", "tokens": ["Die", "Heu\u00b7che\u00b7lei", "mit", "stol\u00b7zen", "Skla\u00b7ven\u00b7mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Den Knecht der Knechte, dem die V\u00f6lker dienen.", "tokens": ["Den", "Knecht", "der", "Knech\u00b7te", ",", "dem", "die", "V\u00f6l\u00b7ker", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "O da\u00df mir einst, dies Alles zu verk\u00fcnden,", "tokens": ["O", "da\u00df", "mir", "einst", ",", "dies", "Al\u00b7les", "zu", "ver\u00b7k\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPER", "ADV", "$,", "PDS", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Erdengenius sein Buch verlieh',", "tokens": ["Der", "Er\u00b7den\u00b7ge\u00b7nius", "sein", "Buch", "ver\u00b7lieh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df ich, wie Geister allgemach erblinden", "tokens": ["Da\u00df", "ich", ",", "wie", "Geis\u00b7ter", "all\u00b7ge\u00b7mach", "er\u00b7blin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "PWAV", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Heilige erkranken wie ein Vieh,", "tokens": ["Und", "Hei\u00b7li\u00b7ge", "er\u00b7kran\u00b7ken", "wie", "ein", "Vieh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df ich das gro\u00dfe Buch der Menschens\u00fcnden", "tokens": ["Da\u00df", "ich", "das", "gro\u00b7\u00dfe", "Buch", "der", "Men\u00b7schen\u00b7s\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Entwickeln k\u00f6nnt' mit seinem Wann und Wie:", "tokens": ["Ent\u00b7wi\u00b7ckeln", "k\u00f6nnt'", "mit", "sei\u00b7nem", "Wann", "und", "Wie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "PPOSAT", "NN", "KON", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Vom ganzen Heer Castraten-Nachtigallen", "tokens": ["Vom", "gan\u00b7zen", "Heer", "Cas\u00b7tra\u00b7ten\u00b7Nach\u00b7ti\u00b7gal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sollt' ", "tokens": ["Sollt'"], "token_info": ["word"], "pos": ["VMFIN"], "meter": "+", "measure": "single.up"}}, "stanza.21": {"line.1": {"text": "Jedoch, mein Geist, wohin schwingst Du die Fl\u00fcgel", "tokens": ["Je\u00b7doch", ",", "mein", "Geist", ",", "wo\u00b7hin", "schwingst", "Du", "die", "Fl\u00fc\u00b7gel"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "PWAV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und moderst noch in dieser Todesgruft?", "tokens": ["Und", "mo\u00b7derst", "noch", "in", "die\u00b7ser", "To\u00b7des\u00b7gruft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erst \u00fcber Str\u00f6m' und W\u00fcsten, Berg' und H\u00fcgel,", "tokens": ["Erst", "\u00fc\u00b7ber", "Str\u00f6m'", "und", "W\u00fcs\u00b7ten", ",", "Ber\u00b7g'", "und", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Bis Dich ein neuer mildrer Athem ruft;", "tokens": ["Bis", "Dich", "ein", "neu\u00b7er", "mild\u00b7rer", "A\u00b7them", "ruft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dann f\u00fchle froh der Gottheit gro\u00dfes Siegel,", "tokens": ["Dann", "f\u00fch\u00b7le", "froh", "der", "Got\u00b7theit", "gro\u00b7\u00dfes", "Sie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dann schweb entz\u00fcckt im holden Fr\u00fchlingsduft,", "tokens": ["Dann", "schweb", "ent\u00b7z\u00fcckt", "im", "hol\u00b7den", "Fr\u00fch\u00b7lings\u00b7duft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und dann la\u00df, s\u00fc\u00df umarmt von allen Deinen,", "tokens": ["Und", "dann", "la\u00df", ",", "s\u00fc\u00df", "um\u00b7armt", "von", "al\u00b7len", "Dei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "ADJD", "VVPP", "APPR", "PIAT", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Was in Dir gl\u00e4nzt, auch Andern widerscheinen!", "tokens": ["Was", "in", "Dir", "gl\u00e4nzt", ",", "auch", "An\u00b7dern", "wi\u00b7der\u00b7schei\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVFIN", "$,", "ADV", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Im ersten Herbst von meinen Lebensjahren,", "tokens": ["Im", "ers\u00b7ten", "Herbst", "von", "mei\u00b7nen", "Le\u00b7bens\u00b7jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nachdem mich mancher schwere Tag gedr\u00fcckt,", "tokens": ["Nach\u00b7dem", "mich", "man\u00b7cher", "schwe\u00b7re", "Tag", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nachdem ich beiderlei Geschick erfahren,", "tokens": ["Nach\u00b7dem", "ich", "bei\u00b7der\u00b7lei", "Ge\u00b7schick", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das eigne Schuld und fremdes Gl\u00fcck uns schickt,", "tokens": ["Das", "eig\u00b7ne", "Schuld", "und", "frem\u00b7des", "Gl\u00fcck", "uns", "schickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auch mancherlei Gespenst des Wunderbaren", "tokens": ["Auch", "man\u00b7cher\u00b7lei", "Ge\u00b7spenst", "des", "Wun\u00b7der\u00b7ba\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und manche Lieb' und Huldgestalt erblickt,", "tokens": ["Und", "man\u00b7che", "Lieb'", "und", "Huld\u00b7ge\u00b7stalt", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Rief eine Stimme mich, jenseit der H\u00f6hen", "tokens": ["Rief", "ei\u00b7ne", "Stim\u00b7me", "mich", ",", "jen\u00b7seit", "der", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPER", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das Land der Abenteu'r und Kunst zu sehen.", "tokens": ["Das", "Land", "der", "A\u00b7ben\u00b7teu'r", "und", "Kunst", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "\u00bblebt,\u00ab sprach ich, \u00bblebet wohl, Ihr, meine Freude,", "tokens": ["\u00bb", "lebt", ",", "\u00ab", "sprach", "ich", ",", "\u00bb", "le\u00b7bet", "wohl", ",", "Ihr", ",", "mei\u00b7ne", "Freu\u00b7de", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "ADV", "$,", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mein Trost und meiner W\u00fcnsche kleine Schaar,", "tokens": ["Mein", "Trost", "und", "mei\u00b7ner", "W\u00fcn\u00b7sche", "klei\u00b7ne", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihr, deren Anblick mir in manchem Leide", "tokens": ["Ihr", ",", "de\u00b7ren", "An\u00b7blick", "mir", "in", "man\u00b7chem", "Lei\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "NN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Nektartropfe vom Olympus war;", "tokens": ["Ein", "Nekt\u00b7ar\u00b7trop\u00b7fe", "vom", "O\u00b7lym\u00b7pus", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und Du, an der ich meine Seele weide,", "tokens": ["Und", "Du", ",", "an", "der", "ich", "mei\u00b7ne", "See\u00b7le", "wei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die mir mich selbst, die mir mein Gl\u00fcck gebar \u2013", "tokens": ["Die", "mir", "mich", "selbst", ",", "die", "mir", "mein", "Gl\u00fcck", "ge\u00b7bar", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "$,", "PRELS", "PPER", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Lebt Alle wohl und la\u00dft mich jetzt verschwinden,", "tokens": ["Lebt", "Al\u00b7le", "wohl", "und", "la\u00dft", "mich", "jetzt", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "KON", "VVIMP", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bald neu verj\u00fcngt Euch freudig wiederfinden!\u00ab", "tokens": ["Bald", "neu", "ver\u00b7j\u00fcngt", "Euch", "freu\u00b7dig", "wie\u00b7der\u00b7fin\u00b7den", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "\u00bbleb wohl,\u00ab so sprach mit Schluchzen und mit Weinen", "tokens": ["\u00bb", "leb", "wohl", ",", "\u00ab", "so", "sprach", "mit", "Schluch\u00b7zen", "und", "mit", "Wei\u00b7nen"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVIMP", "ADV", "$,", "$(", "ADV", "VVFIN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gro\u00dfm\u00fcthig Ariadne, \u00bblebe wohl!\u00ab", "tokens": ["Gro\u00df\u00b7m\u00fct\u00b7hig", "A\u00b7riad\u00b7ne", ",", "\u00bb", "le\u00b7be", "wohl", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADJD", "NN", "$,", "$(", "VVFIN", "ADV", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und schlang den Arm um mich und unsre Kleinen;", "tokens": ["Und", "schlang", "den", "Arm", "um", "mich", "und", "uns\u00b7re", "Klei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch h\u00f6r' ich es, wie ihre Stimme scholl,", "tokens": ["Noch", "h\u00f6r'", "ich", "es", ",", "wie", "ih\u00b7re", "Stim\u00b7me", "scholl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "PWAV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch seh' ich mir ihr liebes Bild erscheinen,", "tokens": ["Noch", "seh'", "ich", "mir", "ihr", "lie\u00b7bes", "Bild", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die H\u00e4nde ringend, rufend: \u00bbLebe wohl!\u00ab", "tokens": ["Die", "H\u00e4n\u00b7de", "rin\u00b7gend", ",", "ru\u00b7fend", ":", "\u00bb", "Le\u00b7be", "wohl", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "VVPP", "$.", "$(", "VVIMP", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und bin gewi\u00df, so lang' der Ton mich leitet,", "tokens": ["Und", "bin", "ge\u00b7wi\u00df", ",", "so", "lang'", "der", "Ton", "mich", "lei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "ADV", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df nie mein Schritt, nie meine Hoffnung gleitet.", "tokens": ["Da\u00df", "nie", "mein", "Schritt", ",", "nie", "mei\u00b7ne", "Hoff\u00b7nung", "glei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Ich schied; und \u00fcber Nebel, Berg' und Thale", "tokens": ["Ich", "schied", ";", "und", "\u00fc\u00b7ber", "Ne\u00b7bel", ",", "Ber\u00b7g'", "und", "Tha\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "KON", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zog mich der Weg ins sch\u00f6ne Frankenland,", "tokens": ["Zog", "mich", "der", "Weg", "ins", "sch\u00f6\u00b7ne", "Fran\u00b7ken\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo ich bei manchem alten Ehrenmale", "tokens": ["Wo", "ich", "bei", "man\u00b7chem", "al\u00b7ten", "Eh\u00b7ren\u00b7ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der deutschen Kunst auch deutsche Sitten fand", "tokens": ["Der", "deut\u00b7schen", "Kunst", "auch", "deut\u00b7sche", "Sit\u00b7ten", "fand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und, wie vor\u00fcbergleitend mit dem Strahle", "tokens": ["Und", ",", "wie", "vor\u00b7\u00fc\u00b7berg\u00b7lei\u00b7tend", "mit", "dem", "Strah\u00b7le"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "PWAV", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Sonne, manches gute Herz gekannt.", "tokens": ["Der", "Son\u00b7ne", ",", "man\u00b7ches", "gu\u00b7te", "Herz", "ge\u00b7kannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So glitt ich sanft hinab, und mit Vergn\u00fcgen", "tokens": ["So", "glitt", "ich", "sanft", "hin\u00b7ab", ",", "und", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sah ich im Geist die Alpen vor mir liegen.", "tokens": ["Sah", "ich", "im", "Geist", "die", "Al\u00b7pen", "vor", "mir", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Ach! aber da umfing in Augsburg's Mauern", "tokens": ["Ach", "!", "a\u00b7ber", "da", "um\u00b7fing", "in", "Augs\u00b7bur\u00b7g's", "Mau\u00b7ern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "ADV", "ADV", "VVFIN", "APPR", "NE", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mich welch ein b\u00f6ser, f\u00fcrchterlicher Traum!", "tokens": ["Mich", "welch", "ein", "b\u00f6\u00b7ser", ",", "f\u00fcrch\u00b7ter\u00b7li\u00b7cher", "Traum", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PWAT", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Schreckbilder sah ich vor mir, um mich lauern;", "tokens": ["Schreck\u00b7bil\u00b7der", "sah", "ich", "vor", "mir", ",", "um", "mich", "lau\u00b7ern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPER", "$,", "KOUI", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich sah und traute meinen Augen kaum.", "tokens": ["Ich", "sah", "und", "trau\u00b7te", "mei\u00b7nen", "Au\u00b7gen", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbwas hilft Dir,\u00ab sprach ich, \u00bbDeine Angst, Dein Trauern?", "tokens": ["\u00bb", "was", "hilft", "Dir", ",", "\u00ab", "sprach", "ich", ",", "\u00bb", "Dei\u00b7ne", "Angst", ",", "Dein", "Trau\u00b7ern", "?"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Gieb Deinem Herzen, Deinen Blicken Raum!\u00ab", "tokens": ["Gieb", "Dei\u00b7nem", "Her\u00b7zen", ",", "Dei\u00b7nen", "Bli\u00b7cken", "Raum", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und sieh, da kam, von Westen hergetragen,", "tokens": ["Und", "sieh", ",", "da", "kam", ",", "von", "Wes\u00b7ten", "her\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Pandora an auf Epimetheus' Wagen.", "tokens": ["Pan\u00b7do\u00b7ra", "an", "auf", "E\u00b7pi\u00b7me\u00b7theus'", "Wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "APPR", "NN", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.27": {"line.1": {"text": "\u00bbich komme nicht um mich, nur Eurethalben;", "tokens": ["\u00bb", "ich", "kom\u00b7me", "nicht", "um", "mich", ",", "nur", "Eu\u00b7re\u00b7thal\u00b7ben", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "$,", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Versch\u00f6nen will ich Euer Wandeln Euch.\u00ab", "tokens": ["Ver\u00b7sch\u00f6\u00b7nen", "will", "ich", "Eu\u00b7er", "Wan\u00b7deln", "Euch", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VMFIN", "PPER", "PPOSAT", "NN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So sprach sie, duftend ihrer B\u00fcchse Salben,", "tokens": ["So", "sprach", "sie", ",", "duf\u00b7tend", "ih\u00b7rer", "B\u00fcch\u00b7se", "Sal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als \u00f6ffnete sie uns Cytherens Reich.", "tokens": ["Als", "\u00f6ff\u00b7ne\u00b7te", "sie", "uns", "Cy\u00b7the\u00b7rens", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PRF", "NE", "NE", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bbuns werden Rosen bl\u00fchn; die welken, fallen,", "tokens": ["\u00bb", "uns", "wer\u00b7den", "Ro\u00b7sen", "bl\u00fchn", ";", "die", "wel\u00b7ken", ",", "fal\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "NN", "VVINF", "$.", "ART", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verwandeln sich vor uns in Kn\u00f6spchen gleich.\u00ab", "tokens": ["Ver\u00b7wan\u00b7deln", "sich", "vor", "uns", "in", "Kn\u00f6spc\u00b7hen", "gleich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "APPR", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So sprach sie; aber ach, Ihr guten Stunden,", "tokens": ["So", "sprach", "sie", ";", "a\u00b7ber", "ach", ",", "Ihr", "gu\u00b7ten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADV", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ihr waret mir, mir war mein Gl\u00fcck verschwunden!", "tokens": ["Ihr", "wa\u00b7ret", "mir", ",", "mir", "war", "mein", "Gl\u00fcck", "ver\u00b7schwun\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Wie zog ich mich auf grauer Alpen R\u00fccken,", "tokens": ["Wie", "zog", "ich", "mich", "auf", "grau\u00b7er", "Al\u00b7pen", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Beschwert im Herzen, m\u00fchsam auf und ab!", "tokens": ["Be\u00b7schwert", "im", "Her\u00b7zen", ",", "m\u00fch\u00b7sam", "auf", "und", "ab", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$,", "ADJD", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Jedweder Fels schien \u00e4chzend mich zu dr\u00fccken,", "tokens": ["Jed\u00b7we\u00b7der", "Fels", "schien", "\u00e4ch\u00b7zend", "mich", "zu", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Jedwedes Thal schien meiner W\u00fcnsche Grab;", "tokens": ["Jed\u00b7we\u00b7des", "Thal", "schien", "mei\u00b7ner", "W\u00fcn\u00b7sche", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und als mit neuem, wonnigem Entz\u00fccken", "tokens": ["Und", "als", "mit", "neu\u00b7em", ",", "won\u00b7ni\u00b7gem", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verona seinen Schoo\u00df dem Blicke gab,", "tokens": ["Ve\u00b7ro\u00b7na", "sei\u00b7nen", "Schoo\u00df", "dem", "Bli\u00b7cke", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Da sprach zu mir, nie werd' ich es vergessen,", "tokens": ["Da", "sprach", "zu", "mir", ",", "nie", "werd'", "ich", "es", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "$,", "ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein Geist herab vom Gipfel der Cypressen.", "tokens": ["Ein", "Geist", "her\u00b7ab", "vom", "Gip\u00b7fel", "der", "Cyp\u00b7res\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "Ich stand, der Abendsonne mich zu freuen,", "tokens": ["Ich", "stand", ",", "der", "A\u00b7bend\u00b7son\u00b7ne", "mich", "zu", "freu\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und \u00fcbersah die weite Lombardei.", "tokens": ["Und", "\u00fc\u00b7ber\u00b7sah", "die", "wei\u00b7te", "Lom\u00b7bar\u00b7dei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbwoher,\u00ab sprach ich, \u00bbo Geist, dies Mi\u00dfgedeihen", "tokens": ["\u00bb", "wo\u00b7her", ",", "\u00ab", "sprach", "ich", ",", "\u00bb", "o", "Geist", ",", "dies", "Mi\u00df\u00b7ge\u00b7dei\u00b7hen"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PWAV", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "FM", "NN", "$,", "PDS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schuldloser W\u00fcnsche? sprich, woher es sei?\u00ab", "tokens": ["Schuld\u00b7lo\u00b7ser", "W\u00fcn\u00b7sche", "?", "sprich", ",", "wo\u00b7her", "es", "sei", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "ADJD", "$,", "PWAV", "PPER", "VAFIN", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "\u00bbdie alte Schuld unwahrer Buhlereien!\u00ab", "tokens": ["\u00bb", "die", "al\u00b7te", "Schuld", "un\u00b7wah\u00b7rer", "Buh\u00b7le\u00b7rei\u00b7en", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sprach der Geist und rauschte sanft vorbei.", "tokens": ["So", "sprach", "der", "Geist", "und", "rauschte", "sanft", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbstatt jetzt dies Land in Friede zu genie\u00dfen,", "tokens": ["\u00bb", "statt", "jetzt", "dies", "Land", "in", "Frie\u00b7de", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PDS", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Kommst Du hieher, f\u00fcr alte Schuld zu b\u00fc\u00dfen.", "tokens": ["Kommst", "Du", "hie\u00b7her", ",", "f\u00fcr", "al\u00b7te", "Schuld", "zu", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$,", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Verw\u00f6hnt von Deinen nur zu milden Sternen,", "tokens": ["Ver\u00b7w\u00f6hnt", "von", "Dei\u00b7nen", "nur", "zu", "mil\u00b7den", "Ster\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schien Dir zu arm des Lebens reichstes Gl\u00fcck.", "tokens": ["Schien", "Dir", "zu", "arm", "des", "Le\u00b7bens", "reichs\u00b7tes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKA", "ADJD", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was Du genossen, sollst Du kennen lernen;", "tokens": ["Was", "Du", "ge\u00b7nos\u00b7sen", ",", "sollst", "Du", "ken\u00b7nen", "ler\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn nur im Darben sieht der Thor zur\u00fcck.", "tokens": ["Denn", "nur", "im", "Dar\u00b7ben", "sieht", "der", "Thor", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Drum hie\u00df von Deinen Lieben Dich entfernen", "tokens": ["Drum", "hie\u00df", "von", "Dei\u00b7nen", "Lie\u00b7ben", "Dich", "ent\u00b7fer\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "PPOSAT", "ADJA", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dein g\u00fcnstiges, Dein besserndes Geschick.", "tokens": ["Dein", "g\u00fcns\u00b7ti\u00b7ges", ",", "Dein", "bes\u00b7sern\u00b7des", "Ge\u00b7schick", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Du sollst, um Deine Weisheit neu zu \u00fcben,", "tokens": ["Du", "sollst", ",", "um", "Dei\u00b7ne", "Weis\u00b7heit", "neu", "zu", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUI", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Jetzt ", "tokens": ["Jetzt"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}}, "stanza.31": {"line.1": {"text": "Nie hast Du im Ger\u00e4usch der Welt den Frieden", "tokens": ["Nie", "hast", "Du", "im", "Ge\u00b7r\u00e4usch", "der", "Welt", "den", "Frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des eignen Herzens sittsam Dir bewahrt,", "tokens": ["Des", "eig\u00b7nen", "Her\u00b7zens", "sitt\u00b7sam", "Dir", "be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nie zwischen Mensch und Menschen unterschieden,", "tokens": ["Nie", "zwi\u00b7schen", "Mensch", "und", "Men\u00b7schen", "un\u00b7ter\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nie eingesehn, was f\u00fcr ein Gl\u00fcck Dir ward,", "tokens": ["Nie", "ein\u00b7ge\u00b7sehn", ",", "was", "f\u00fcr", "ein", "Gl\u00fcck", "Dir", "ward", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "PRELS", "APPR", "ART", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Es zu betr\u00fcben, nie genug vermieden,", "tokens": ["Es", "zu", "be\u00b7tr\u00fc\u00b7ben", ",", "nie", "ge\u00b7nug", "ver\u00b7mie\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es zu genie\u00dfen, nie genug gespart;", "tokens": ["Es", "zu", "ge\u00b7nie\u00b7\u00dfen", ",", "nie", "ge\u00b7nug", "ge\u00b7spart", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Daf\u00fcr den treusten Herzen jetzt entnommen,", "tokens": ["Da\u00b7f\u00fcr", "den", "treus\u00b7ten", "Her\u00b7zen", "jetzt", "ent\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bist Du hieher ins Land der K\u00fcnste kommen.\u00ab", "tokens": ["Bist", "Du", "hie\u00b7her", "ins", "Land", "der", "K\u00fcns\u00b7te", "kom\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "PAV", "APPRART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Er sprach's; und ach, wie wahr hast Du gesprochen,", "tokens": ["Er", "sprach's", ";", "und", "ach", ",", "wie", "wahr", "hast", "Du", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KON", "XY", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Geist der Cypresse, wie so grausam wahr!", "tokens": ["Geist", "der", "Cyp\u00b7res\u00b7se", ",", "wie", "so", "grau\u00b7sam", "wahr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PWAV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ihr guten Herzen seid genug gerochen;", "tokens": ["Ihr", "gu\u00b7ten", "Her\u00b7zen", "seid", "ge\u00b7nug", "ge\u00b7ro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich sehe mich und Euch so hell und klar.", "tokens": ["Ich", "se\u00b7he", "mich", "und", "Euch", "so", "hell", "und", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was th\u00e4tig und unth\u00e4tig ich verbrochen,", "tokens": ["Was", "th\u00e4\u00b7tig", "und", "un\u00b7th\u00e4\u00b7tig", "ich", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Macht jeder Schritt mir kund und offenbar.", "tokens": ["Macht", "je\u00b7der", "Schritt", "mir", "kund", "und", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "PPER", "PTKVZ", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich seh', ich mu\u00dfte mich von Euch entfernen", "tokens": ["Ich", "seh'", ",", "ich", "mu\u00df\u00b7te", "mich", "von", "Euch", "ent\u00b7fer\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PRF", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und durch Verlust des Lebens Weisheit lernen.", "tokens": ["Und", "durch", "Ver\u00b7lust", "des", "Le\u00b7bens", "Weis\u00b7heit", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Dank also Euch, Ihr g\u00f6ttlichen Medusen,", "tokens": ["Dank", "al\u00b7so", "Euch", ",", "Ihr", "g\u00f6tt\u00b7li\u00b7chen", "Me\u00b7du\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die mich gelehrt, da\u00df Ihr Medusen seid!", "tokens": ["Die", "mich", "ge\u00b7lehrt", ",", "da\u00df", "Ihr", "Me\u00b7du\u00b7sen", "seid", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "KOUS", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dank Euch, Ihr todten K\u00fcnste, kalte Musen,", "tokens": ["Dank", "Euch", ",", "Ihr", "tod\u00b7ten", "K\u00fcns\u00b7te", ",", "kal\u00b7te", "Mu\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zerfallne Mauern, Grab der Eitelkeit!", "tokens": ["Zer\u00b7fall\u00b7ne", "Mau\u00b7ern", ",", "Grab", "der", "Ei\u00b7tel\u00b7keit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn je dem falschen, je dem Marmorbusen", "tokens": ["Wenn", "je", "dem", "fal\u00b7schen", ",", "je", "dem", "Mar\u00b7mor\u00b7bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Statt wahrer Herzen Weihrauch ich gestreut,", "tokens": ["Statt", "wah\u00b7rer", "Her\u00b7zen", "Weih\u00b7rauch", "ich", "ge\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.7": {"text": "So nehmt von mir den letzten Zoll hienieden,", "tokens": ["So", "nehmt", "von", "mir", "den", "letz\u00b7ten", "Zoll", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der Reue Zoll, und la\u00dft mich ziehn in Frieden!", "tokens": ["Der", "Reu\u00b7e", "Zoll", ",", "und", "la\u00dft", "mich", "ziehn", "in", "Frie\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KON", "VVIMP", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Auch Euch, Ihr der Natur erhabne Scenen,", "tokens": ["Auch", "Euch", ",", "Ihr", "der", "Na\u00b7tur", "er\u00b7hab\u00b7ne", "Sce\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gebirge, Felsen, Ebnen, Ufer, Meer,", "tokens": ["Ge\u00b7bir\u00b7ge", ",", "Fel\u00b7sen", ",", "Eb\u00b7nen", ",", "U\u00b7fer", ",", "Meer", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du Meer von Adria und Ihr Sirenen", "tokens": ["Du", "Meer", "von", "Ad\u00b7ria", "und", "Ihr", "Si\u00b7re\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "APPR", "NE", "KON", "PPOSAT", "NN"], "meter": "-+-+-++---", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Parthenope's, Ihr Inseln um sie her,", "tokens": ["Par\u00b7the\u00b7no\u00b7pe's", ",", "Ihr", "In\u00b7seln", "um", "sie", "her", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Dank Euch, da\u00df, mit mir selbst mich zu vers\u00f6hnen,", "tokens": ["Dank", "Euch", ",", "da\u00df", ",", "mit", "mir", "selbst", "mich", "zu", "ver\u00b7s\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUS", "$,", "APPR", "PPER", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ihr meine Brust von Seufzern machtet schwer!", "tokens": ["Ihr", "mei\u00b7ne", "Brust", "von", "Seuf\u00b7zern", "mach\u00b7tet", "schwer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Mit unschuldsvollem, liebeszartem Sehnen", "tokens": ["Mit", "un\u00b7schulds\u00b7vol\u00b7lem", ",", "lie\u00b7bes\u00b7zar\u00b7tem", "Seh\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "PIS", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Weiht' ich, der Menschheit froh, Euch stille Thr\u00e4nen.", "tokens": ["Weiht'", "ich", ",", "der", "Menschheit", "froh", ",", "Euch", "stil\u00b7le", "Thr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "ADJD", "$,", "PPER", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.35": {"line.1": {"text": "Und Ihr erquicktet mich, als in Verona", "tokens": ["Und", "Ihr", "er\u00b7quick\u00b7tet", "mich", ",", "als", "in", "Ve\u00b7ro\u00b7na"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "KOUS", "APPR", "NE"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die Sonne nieder, als sie aufw\u00e4rts stieg", "tokens": ["Die", "Son\u00b7ne", "nie\u00b7der", ",", "als", "sie", "auf\u00b7w\u00e4rts", "stieg"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KOUS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In Rimini, und ich dann in Ancona", "tokens": ["In", "Ri\u00b7mi\u00b7ni", ",", "und", "ich", "dann", "in", "An\u00b7co\u00b7na"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KON", "PPER", "ADV", "APPR", "NE"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Mich mit dem Meer verm\u00e4hlete und schwieg;", "tokens": ["Mich", "mit", "dem", "Meer", "ver\u00b7m\u00e4h\u00b7le\u00b7te", "und", "schwieg", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Mit Dir verm\u00e4hlt' ich mich, o Dea Bona,", "tokens": ["Mit", "Dir", "ver\u00b7m\u00e4hlt'", "ich", "mich", ",", "o", "Dea", "Bo\u00b7na", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "PRF", "$,", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Du gute G\u00f6ttin, mit der Hoffnung Sieg,", "tokens": ["Du", "gu\u00b7te", "G\u00f6t\u00b7tin", ",", "mit", "der", "Hoff\u00b7nung", "Sieg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wie die Sonne war ich liebestrunken", "tokens": ["Und", "wie", "die", "Son\u00b7ne", "war", "ich", "lie\u00b7be\u00b7strun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Aus Deinem Arm in Deinen Schoo\u00df gesunken.", "tokens": ["Aus", "Dei\u00b7nem", "Arm", "in", "Dei\u00b7nen", "Schoo\u00df", "ge\u00b7sun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "O gute G\u00f6ttin, darf ich, darf ich nennen", "tokens": ["O", "gu\u00b7te", "G\u00f6t\u00b7tin", ",", "darf", "ich", ",", "darf", "ich", "nen\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "VMFIN", "PPER", "$,", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den heil'gen Namen? Nenn' ich Dich Natur?", "tokens": ["Den", "heil'\u00b7gen", "Na\u00b7men", "?", "Nenn'", "ich", "Dich", "Na\u00b7tur", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "VVFIN", "PPER", "PRF", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nenn' ich Dich Liebe? Ach, nur Dich zu kennen,", "tokens": ["Nenn'", "ich", "Dich", "Lie\u00b7be", "?", "Ach", ",", "nur", "Dich", "zu", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "NN", "$.", "ITJ", "$,", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Irr' ich umher auf alles Wissens Spur.", "tokens": ["Irr'", "ich", "um\u00b7her", "auf", "al\u00b7les", "Wis\u00b7sens", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und doch, um reiner Flamm' in Dir zu brennen,", "tokens": ["Und", "doch", ",", "um", "rei\u00b7ner", "Flamm'", "in", "Dir", "zu", "bren\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUI", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bedarf ich reiner Lieb' und Weisheit nur.", "tokens": ["Be\u00b7darf", "ich", "rei\u00b7ner", "Lieb'", "und", "Weis\u00b7heit", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Nicht Kunst, nicht Wissenschaft: die Kunst des Lebens", "tokens": ["Nicht", "Kunst", ",", "nicht", "Wis\u00b7sen\u00b7schaft", ":", "die", "Kunst", "des", "Le\u00b7bens"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "NN", "$,", "PTKNEG", "NN", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ist Wissenschaft; sonst ist die Kunst vergebens.", "tokens": ["Ist", "Wis\u00b7sen\u00b7schaft", ";", "sonst", "ist", "die", "Kunst", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Du, G\u00f6ttin, wei\u00dft, da\u00df ich an jedem Bilde", "tokens": ["Du", ",", "G\u00f6t\u00b7tin", ",", "wei\u00dft", ",", "da\u00df", "ich", "an", "je\u00b7dem", "Bil\u00b7de"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des sch\u00f6nsten Marmors Dich, nur Dich gelernt,", "tokens": ["Des", "sch\u00f6ns\u00b7ten", "Mar\u00b7mors", "Dich", ",", "nur", "Dich", "ge\u00b7lernt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "$,", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df Du, so freundlich und mit Weisheit milde,", "tokens": ["Da\u00df", "Du", ",", "so", "freund\u00b7lich", "und", "mit", "Weis\u00b7heit", "mil\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADJD", "KON", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Durchs Sch\u00f6ne mir nur den Betrug entfernt.", "tokens": ["Durchs", "Sch\u00f6\u00b7ne", "mir", "nur", "den", "Be\u00b7trug", "ent\u00b7fernt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Dann schlich ich mich in andere Gefilde,", "tokens": ["Dann", "schlich", "ich", "mich", "in", "an\u00b7de\u00b7re", "Ge\u00b7fil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Als die man mit Palett' und Mei\u00dfel lernt \u2013", "tokens": ["Als", "die", "man", "mit", "Pa\u00b7lett'", "und", "Mei\u00b7\u00dfel", "lernt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich lernt' an Eurem Knie, an Eurem Busen", "tokens": ["Ich", "lernt'", "an", "Eu\u00b7rem", "Knie", ",", "an", "Eu\u00b7rem", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nichts als ", "tokens": ["Nichts", "als"], "token_info": ["word", "word"], "pos": ["PIS", "KOKOM"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.38": {"line.1": {"text": "Und sah sie in den g\u00f6ttlichsten Gestalten,", "tokens": ["Und", "sah", "sie", "in", "den", "g\u00f6tt\u00b7lichs\u00b7ten", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Sah Weisheit, G\u00fcte, Macht als Menschenbild,", "tokens": ["Sah", "Weis\u00b7heit", ",", "G\u00fc\u00b7te", ",", "Macht", "als", "Men\u00b7schen\u00b7bild", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "$,", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sah jeder Sch\u00f6nheit Knospe sich entfalten,", "tokens": ["Sah", "je\u00b7der", "Sch\u00f6n\u00b7heit", "Knos\u00b7pe", "sich", "ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NE", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sah jede Art in Menschenform geh\u00fcllt;", "tokens": ["Sah", "je\u00b7de", "Art", "in", "Men\u00b7schen\u00b7form", "ge\u00b7h\u00fcllt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sah Kr\u00e4fte sprossen, wachsen und veralten", "tokens": ["Sah", "Kr\u00e4f\u00b7te", "spros\u00b7sen", ",", "wach\u00b7sen", "und", "ver\u00b7al\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NN", "VVFIN", "$,", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und jeden Zweig von ", "tokens": ["Und", "je\u00b7den", "Zweig", "von"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Sah hier das Licht aufgehen, steigen, schwinden", "tokens": ["Sah", "hier", "das", "Licht", "auf\u00b7ge\u00b7hen", ",", "stei\u00b7gen", ",", "schwin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVINF", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und lernte stets die Menschheit wiederfinden.", "tokens": ["Und", "lern\u00b7te", "stets", "die", "Menschheit", "wie\u00b7der\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.39": {"line.1": {"text": "Daneben sah ich \u2013 darf ich Dich auch nennen,", "tokens": ["Da\u00b7ne\u00b7ben", "sah", "ich", "\u2013", "darf", "ich", "Dich", "auch", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$(", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du inhumanes, alt- und neues Rom?", "tokens": ["Du", "in\u00b7hu\u00b7ma\u00b7nes", ",", "al\u00b7t", "und", "neu\u00b7es", "Rom", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "$,", "TRUNC", "KON", "ADJA", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch wer wird Dich im Namen nicht schon kennen,", "tokens": ["Doch", "wer", "wird", "Dich", "im", "Na\u00b7men", "nicht", "schon", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPER", "APPRART", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du Capitol und Du St. Peter's Dom?", "tokens": ["Du", "Ca\u00b7pi\u00b7tol", "und", "Du", "St.", "Pe\u00b7ter's", "Dom", "?"], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "PPER", "NE", "NE", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Du Pfuhl, aus dem, die Erde zu verbrennen,", "tokens": ["Du", "Pfuhl", ",", "aus", "dem", ",", "die", "Er\u00b7de", "zu", "ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "APPR", "ART", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ausging ein alter und ein neuer Strom,", "tokens": ["Aus\u00b7ging", "ein", "al\u00b7ter", "und", "ein", "neu\u00b7er", "Strom", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Von Kriegern einst bewohnt und Senatoren,", "tokens": ["Von", "Krie\u00b7gern", "einst", "be\u00b7wohnt", "und", "Se\u00b7na\u00b7to\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Von Pfaffen jetzt bewohnt und Monsignoren.", "tokens": ["Von", "Pfaf\u00b7fen", "jetzt", "be\u00b7wohnt", "und", "Mon\u00b7sig\u00b7no\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Ich lernte Dich und Deiner theuren Prinzen", "tokens": ["Ich", "lern\u00b7te", "Dich", "und", "Dei\u00b7ner", "theu\u00b7ren", "Prin\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Deiner Prinzessinnen sch\u00f6nes Heer,", "tokens": ["Und", "Dei\u00b7ner", "Prin\u00b7zes\u00b7sin\u00b7nen", "sch\u00f6\u00b7nes", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die W\u00fcsten Deiner darbenden Provinzen", "tokens": ["Die", "W\u00fcs\u00b7ten", "Dei\u00b7ner", "dar\u00b7ben\u00b7den", "Pro\u00b7vin\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Deiner Wissenschaften todtes Meer;", "tokens": ["Und", "Dei\u00b7ner", "Wis\u00b7sen\u00b7schaf\u00b7ten", "tod\u00b7tes", "Meer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Weisheit lernt' ich sehn mit Augen blinzen,", "tokens": ["Die", "Weis\u00b7heit", "lernt'", "ich", "sehn", "mit", "Au\u00b7gen", "blin\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Andacht sehn, von altem Taumel schwer,", "tokens": ["Die", "An\u00b7dacht", "sehn", ",", "von", "al\u00b7tem", "Tau\u00b7mel", "schwer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Heuchelei mit stolzen Sklavenmienen,", "tokens": ["Die", "Heu\u00b7che\u00b7lei", "mit", "stol\u00b7zen", "Skla\u00b7ven\u00b7mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Den Knecht der Knechte, dem die V\u00f6lker dienen.", "tokens": ["Den", "Knecht", "der", "Knech\u00b7te", ",", "dem", "die", "V\u00f6l\u00b7ker", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "O da\u00df mir einst, dies Alles zu verk\u00fcnden,", "tokens": ["O", "da\u00df", "mir", "einst", ",", "dies", "Al\u00b7les", "zu", "ver\u00b7k\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPER", "ADV", "$,", "PDS", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Erdengenius sein Buch verlieh',", "tokens": ["Der", "Er\u00b7den\u00b7ge\u00b7nius", "sein", "Buch", "ver\u00b7lieh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df ich, wie Geister allgemach erblinden", "tokens": ["Da\u00df", "ich", ",", "wie", "Geis\u00b7ter", "all\u00b7ge\u00b7mach", "er\u00b7blin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "PWAV", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Heilige erkranken wie ein Vieh,", "tokens": ["Und", "Hei\u00b7li\u00b7ge", "er\u00b7kran\u00b7ken", "wie", "ein", "Vieh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df ich das gro\u00dfe Buch der Menschens\u00fcnden", "tokens": ["Da\u00df", "ich", "das", "gro\u00b7\u00dfe", "Buch", "der", "Men\u00b7schen\u00b7s\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Entwickeln k\u00f6nnt' mit seinem Wann und Wie:", "tokens": ["Ent\u00b7wi\u00b7ckeln", "k\u00f6nnt'", "mit", "sei\u00b7nem", "Wann", "und", "Wie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "PPOSAT", "NN", "KON", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Vom ganzen Heer Castraten-Nachtigallen", "tokens": ["Vom", "gan\u00b7zen", "Heer", "Cas\u00b7tra\u00b7ten\u00b7Nach\u00b7ti\u00b7gal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sollt' ", "tokens": ["Sollt'"], "token_info": ["word"], "pos": ["VMFIN"], "meter": "+", "measure": "single.up"}}, "stanza.42": {"line.1": {"text": "Jedoch, mein Geist, wohin schwingst Du die Fl\u00fcgel", "tokens": ["Je\u00b7doch", ",", "mein", "Geist", ",", "wo\u00b7hin", "schwingst", "Du", "die", "Fl\u00fc\u00b7gel"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "PWAV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und moderst noch in dieser Todesgruft?", "tokens": ["Und", "mo\u00b7derst", "noch", "in", "die\u00b7ser", "To\u00b7des\u00b7gruft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erst \u00fcber Str\u00f6m' und W\u00fcsten, Berg' und H\u00fcgel,", "tokens": ["Erst", "\u00fc\u00b7ber", "Str\u00f6m'", "und", "W\u00fcs\u00b7ten", ",", "Ber\u00b7g'", "und", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Bis Dich ein neuer mildrer Athem ruft;", "tokens": ["Bis", "Dich", "ein", "neu\u00b7er", "mild\u00b7rer", "A\u00b7them", "ruft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dann f\u00fchle froh der Gottheit gro\u00dfes Siegel,", "tokens": ["Dann", "f\u00fch\u00b7le", "froh", "der", "Got\u00b7theit", "gro\u00b7\u00dfes", "Sie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dann schweb entz\u00fcckt im holden Fr\u00fchlingsduft,", "tokens": ["Dann", "schweb", "ent\u00b7z\u00fcckt", "im", "hol\u00b7den", "Fr\u00fch\u00b7lings\u00b7duft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und dann la\u00df, s\u00fc\u00df umarmt von allen Deinen,", "tokens": ["Und", "dann", "la\u00df", ",", "s\u00fc\u00df", "um\u00b7armt", "von", "al\u00b7len", "Dei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "ADJD", "VVPP", "APPR", "PIAT", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Was in Dir gl\u00e4nzt, auch Andern widerscheinen!", "tokens": ["Was", "in", "Dir", "gl\u00e4nzt", ",", "auch", "An\u00b7dern", "wi\u00b7der\u00b7schei\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVFIN", "$,", "ADV", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}