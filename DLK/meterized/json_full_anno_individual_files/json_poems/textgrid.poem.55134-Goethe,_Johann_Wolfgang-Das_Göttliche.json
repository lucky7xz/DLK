{"textgrid.poem.55134": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Das G\u00f6ttliche", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Edel sei der Mensch,", "tokens": ["E\u00b7del", "sei", "der", "Mensch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00fclfreich und gut!", "tokens": ["H\u00fclf\u00b7reich", "und", "gut", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Denn das allein", "tokens": ["Denn", "das", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PDS", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Unterscheidet ihn", "tokens": ["Un\u00b7ter\u00b7schei\u00b7det", "ihn"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Von allen Wesen,", "tokens": ["Von", "al\u00b7len", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Die wir kennen.", "tokens": ["Die", "wir", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Heil den unbekannten", "tokens": ["Heil", "den", "un\u00b7be\u00b7kann\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00f6hern Wesen,", "tokens": ["H\u00f6\u00b7hern", "We\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Die wir ahnen!", "tokens": ["Die", "wir", "ah\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Ihnen gleiche der Mensch;", "tokens": ["Ih\u00b7nen", "glei\u00b7che", "der", "Mensch", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Sein Beispiel lehr uns", "tokens": ["Sein", "Bei\u00b7spiel", "lehr", "uns"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Jene glauben.", "tokens": ["Je\u00b7ne", "glau\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["PDS", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Denn unf\u00fchlend", "tokens": ["Denn", "un\u00b7f\u00fch\u00b7lend"], "token_info": ["word", "word"], "pos": ["KON", "ADJD"], "meter": "-+--", "measure": "dactylic.init"}, "line.2": {"text": "Ist die Natur:", "tokens": ["Ist", "die", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Es leuchtet die Sonne", "tokens": ["Es", "leuch\u00b7tet", "die", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u00dcber B\u00f6s' und Gute,", "tokens": ["\u00dc\u00b7ber", "B\u00f6s'", "und", "Gu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Und dem Verbrecher", "tokens": ["Und", "dem", "Ver\u00b7bre\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Gl\u00e4nzen wie dem Besten", "tokens": ["Gl\u00e4n\u00b7zen", "wie", "dem", "Bes\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Der Mond und die Sterne.", "tokens": ["Der", "Mond", "und", "die", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Wind und Str\u00f6me,", "tokens": ["Wind", "und", "Str\u00f6\u00b7me", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Donner und Hagel", "tokens": ["Don\u00b7ner", "und", "Ha\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Rauschen ihren Weg", "tokens": ["Rau\u00b7schen", "ih\u00b7ren", "Weg"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Und ergreifen,", "tokens": ["Und", "er\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Vor\u00fcbereilend,", "tokens": ["Vor\u00b7\u00fc\u00b7be\u00b7rei\u00b7lend", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Einen um den andern.", "tokens": ["Ei\u00b7nen", "um", "den", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Auch so das Gl\u00fcck", "tokens": ["Auch", "so", "das", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Tappt unter die Menge,", "tokens": ["Tappt", "un\u00b7ter", "die", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Fa\u00dft bald des Knaben", "tokens": ["Fa\u00dft", "bald", "des", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Lockige Unschuld,", "tokens": ["Lo\u00b7cki\u00b7ge", "Un\u00b7schuld", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Bald auch den kahlen,", "tokens": ["Bald", "auch", "den", "kah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Schuldigen Scheitel.", "tokens": ["Schul\u00b7di\u00b7gen", "Schei\u00b7tel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "Nach ewigen, ehrnen,", "tokens": ["Nach", "e\u00b7wi\u00b7gen", ",", "ehr\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Gro\u00dfen Gesetzen", "tokens": ["Gro\u00b7\u00dfen", "Ge\u00b7set\u00b7zen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "M\u00fcssen wir alle", "tokens": ["M\u00fcs\u00b7sen", "wir", "al\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPER", "PIAT"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Unseres Daseins", "tokens": ["Un\u00b7se\u00b7res", "Da\u00b7seins"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Kreise vollenden.", "tokens": ["Krei\u00b7se", "voll\u00b7en\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.7": {"line.1": {"text": "Nur allein der Mensch", "tokens": ["Nur", "al\u00b7lein", "der", "Mensch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Vermag das Unm\u00f6gliche:", "tokens": ["Ver\u00b7mag", "das", "Un\u00b7m\u00f6g\u00b7li\u00b7che", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Er unterscheidet,", "tokens": ["Er", "un\u00b7ter\u00b7schei\u00b7det", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "W\u00e4hlet und richtet;", "tokens": ["W\u00e4h\u00b7let", "und", "rich\u00b7tet", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Er kann dem Augenblick", "tokens": ["Er", "kann", "dem", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Dauer verleihen.", "tokens": ["Dau\u00b7er", "ver\u00b7lei\u00b7hen", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.8": {"line.1": {"text": "Er allein darf", "tokens": ["Er", "al\u00b7lein", "darf"], "token_info": ["word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Den Guten lohnen,", "tokens": ["Den", "Gu\u00b7ten", "loh\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Den B\u00f6sen strafen,", "tokens": ["Den", "B\u00f6\u00b7sen", "stra\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Heilen und retten,", "tokens": ["Hei\u00b7len", "und", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Alles Irrende, Schweifende", "tokens": ["Al\u00b7les", "Ir\u00b7ren\u00b7de", ",", "Schwei\u00b7fen\u00b7de"], "token_info": ["word", "word", "punct", "word"], "pos": ["PIAT", "NN", "$,", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.6": {"text": "N\u00fctzlich verbinden.", "tokens": ["N\u00fctz\u00b7lich", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.9": {"line.1": {"text": "Und wir verehren", "tokens": ["Und", "wir", "ver\u00b7eh\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Die Unsterblichen,", "tokens": ["Die", "U\u00b7nsterb\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+---", "measure": "dactylic.init"}, "line.3": {"text": "Als w\u00e4ren sie Menschen,", "tokens": ["Als", "w\u00e4\u00b7ren", "sie", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "T\u00e4ten im Gro\u00dfen,", "tokens": ["T\u00e4\u00b7ten", "im", "Gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Was der Beste im Kleinen", "tokens": ["Was", "der", "Bes\u00b7te", "im", "Klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "APPRART", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Tut oder m\u00f6chte.", "tokens": ["Tut", "o\u00b7der", "m\u00f6ch\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VMFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.10": {"line.1": {"text": "Der edle Mensch", "tokens": ["Der", "ed\u00b7le", "Mensch"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Sei h\u00fclfreich und gut!", "tokens": ["Sei", "h\u00fclf\u00b7reich", "und", "gut", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Unerm\u00fcdet schaff er", "tokens": ["Un\u00b7er\u00b7m\u00fc\u00b7det", "schaff", "er"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Das N\u00fctzliche, Rechte,", "tokens": ["Das", "N\u00fctz\u00b7li\u00b7che", ",", "Rech\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Sei uns ein Vorbild", "tokens": ["Sei", "uns", "ein", "Vor\u00b7bild"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Jener geahneten Wesen!", "tokens": ["Je\u00b7ner", "ge\u00b7ah\u00b7ne\u00b7ten", "We\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.11": {"line.1": {"text": "Edel sei der Mensch,", "tokens": ["E\u00b7del", "sei", "der", "Mensch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00fclfreich und gut!", "tokens": ["H\u00fclf\u00b7reich", "und", "gut", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Denn das allein", "tokens": ["Denn", "das", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PDS", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Unterscheidet ihn", "tokens": ["Un\u00b7ter\u00b7schei\u00b7det", "ihn"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Von allen Wesen,", "tokens": ["Von", "al\u00b7len", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Die wir kennen.", "tokens": ["Die", "wir", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "Heil den unbekannten", "tokens": ["Heil", "den", "un\u00b7be\u00b7kann\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00f6hern Wesen,", "tokens": ["H\u00f6\u00b7hern", "We\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Die wir ahnen!", "tokens": ["Die", "wir", "ah\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Ihnen gleiche der Mensch;", "tokens": ["Ih\u00b7nen", "glei\u00b7che", "der", "Mensch", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Sein Beispiel lehr uns", "tokens": ["Sein", "Bei\u00b7spiel", "lehr", "uns"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Jene glauben.", "tokens": ["Je\u00b7ne", "glau\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["PDS", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.13": {"line.1": {"text": "Denn unf\u00fchlend", "tokens": ["Denn", "un\u00b7f\u00fch\u00b7lend"], "token_info": ["word", "word"], "pos": ["KON", "ADJD"], "meter": "-+--", "measure": "dactylic.init"}, "line.2": {"text": "Ist die Natur:", "tokens": ["Ist", "die", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Es leuchtet die Sonne", "tokens": ["Es", "leuch\u00b7tet", "die", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u00dcber B\u00f6s' und Gute,", "tokens": ["\u00dc\u00b7ber", "B\u00f6s'", "und", "Gu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Und dem Verbrecher", "tokens": ["Und", "dem", "Ver\u00b7bre\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Gl\u00e4nzen wie dem Besten", "tokens": ["Gl\u00e4n\u00b7zen", "wie", "dem", "Bes\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Der Mond und die Sterne.", "tokens": ["Der", "Mond", "und", "die", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.14": {"line.1": {"text": "Wind und Str\u00f6me,", "tokens": ["Wind", "und", "Str\u00f6\u00b7me", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Donner und Hagel", "tokens": ["Don\u00b7ner", "und", "Ha\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Rauschen ihren Weg", "tokens": ["Rau\u00b7schen", "ih\u00b7ren", "Weg"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Und ergreifen,", "tokens": ["Und", "er\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Vor\u00fcbereilend,", "tokens": ["Vor\u00b7\u00fc\u00b7be\u00b7rei\u00b7lend", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Einen um den andern.", "tokens": ["Ei\u00b7nen", "um", "den", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Auch so das Gl\u00fcck", "tokens": ["Auch", "so", "das", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Tappt unter die Menge,", "tokens": ["Tappt", "un\u00b7ter", "die", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Fa\u00dft bald des Knaben", "tokens": ["Fa\u00dft", "bald", "des", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Lockige Unschuld,", "tokens": ["Lo\u00b7cki\u00b7ge", "Un\u00b7schuld", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Bald auch den kahlen,", "tokens": ["Bald", "auch", "den", "kah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Schuldigen Scheitel.", "tokens": ["Schul\u00b7di\u00b7gen", "Schei\u00b7tel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.16": {"line.1": {"text": "Nach ewigen, ehrnen,", "tokens": ["Nach", "e\u00b7wi\u00b7gen", ",", "ehr\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Gro\u00dfen Gesetzen", "tokens": ["Gro\u00b7\u00dfen", "Ge\u00b7set\u00b7zen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "M\u00fcssen wir alle", "tokens": ["M\u00fcs\u00b7sen", "wir", "al\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPER", "PIAT"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Unseres Daseins", "tokens": ["Un\u00b7se\u00b7res", "Da\u00b7seins"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Kreise vollenden.", "tokens": ["Krei\u00b7se", "voll\u00b7en\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.17": {"line.1": {"text": "Nur allein der Mensch", "tokens": ["Nur", "al\u00b7lein", "der", "Mensch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Vermag das Unm\u00f6gliche:", "tokens": ["Ver\u00b7mag", "das", "Un\u00b7m\u00f6g\u00b7li\u00b7che", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Er unterscheidet,", "tokens": ["Er", "un\u00b7ter\u00b7schei\u00b7det", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "W\u00e4hlet und richtet;", "tokens": ["W\u00e4h\u00b7let", "und", "rich\u00b7tet", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Er kann dem Augenblick", "tokens": ["Er", "kann", "dem", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Dauer verleihen.", "tokens": ["Dau\u00b7er", "ver\u00b7lei\u00b7hen", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.18": {"line.1": {"text": "Er allein darf", "tokens": ["Er", "al\u00b7lein", "darf"], "token_info": ["word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Den Guten lohnen,", "tokens": ["Den", "Gu\u00b7ten", "loh\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Den B\u00f6sen strafen,", "tokens": ["Den", "B\u00f6\u00b7sen", "stra\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Heilen und retten,", "tokens": ["Hei\u00b7len", "und", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Alles Irrende, Schweifende", "tokens": ["Al\u00b7les", "Ir\u00b7ren\u00b7de", ",", "Schwei\u00b7fen\u00b7de"], "token_info": ["word", "word", "punct", "word"], "pos": ["PIAT", "NN", "$,", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.6": {"text": "N\u00fctzlich verbinden.", "tokens": ["N\u00fctz\u00b7lich", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.19": {"line.1": {"text": "Und wir verehren", "tokens": ["Und", "wir", "ver\u00b7eh\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Die Unsterblichen,", "tokens": ["Die", "U\u00b7nsterb\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+---", "measure": "dactylic.init"}, "line.3": {"text": "Als w\u00e4ren sie Menschen,", "tokens": ["Als", "w\u00e4\u00b7ren", "sie", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "T\u00e4ten im Gro\u00dfen,", "tokens": ["T\u00e4\u00b7ten", "im", "Gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Was der Beste im Kleinen", "tokens": ["Was", "der", "Bes\u00b7te", "im", "Klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "APPRART", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Tut oder m\u00f6chte.", "tokens": ["Tut", "o\u00b7der", "m\u00f6ch\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VMFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.20": {"line.1": {"text": "Der edle Mensch", "tokens": ["Der", "ed\u00b7le", "Mensch"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Sei h\u00fclfreich und gut!", "tokens": ["Sei", "h\u00fclf\u00b7reich", "und", "gut", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Unerm\u00fcdet schaff er", "tokens": ["Un\u00b7er\u00b7m\u00fc\u00b7det", "schaff", "er"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Das N\u00fctzliche, Rechte,", "tokens": ["Das", "N\u00fctz\u00b7li\u00b7che", ",", "Rech\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Sei uns ein Vorbild", "tokens": ["Sei", "uns", "ein", "Vor\u00b7bild"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Jener geahneten Wesen!", "tokens": ["Je\u00b7ner", "ge\u00b7ah\u00b7ne\u00b7ten", "We\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}}}}